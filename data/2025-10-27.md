<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 33]
- [cs.AI](#cs.AI) [Total: 23]
- [cs.GT](#cs.GT) [Total: 3]
- [stat.ML](#stat.ML) [Total: 7]
- [cs.IT](#cs.IT) [Total: 5]
- [cs.LG](#cs.LG) [Total: 70]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Code-enabled language models can outperform reasoning models on diverse tasks](https://arxiv.org/abs/2510.20909)
*Cedegao E. Zhang,Cédric Colas,Gabriel Poesia,Joshua B. Tenenbaum,Jacob Andreas*

Main category: cs.CL

TL;DR: 本文提出CodeAdapt方法，该方法结合CodeAct框架和少样本情境学习，使标准instruct LMs在无需微调的情况下，即可达到甚至超越经过强化学习训练的推理模型（RMs）的推理水平，并且在多项任务上表现出更高的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 尽管推理模型（RMs）在生成长篇自然语言推理方面取得了显著成功，但它们的训练需要大量的计算和数据，运行成本高昂且速度较慢。

Method: CodeAdapt方法，该方法结合了CodeAct框架（允许语言模型在多步骤推理中交替使用自然语言推理和代码执行）和少样本情境学习（从仅五个训练问题中引导）。

Result: CodeAdapt使三个语言模型在八项任务上的平均表现优于相应的推理模型（最高提升22.9%），同时在令牌效率上提高10-81%。在四种模型的平均表现中，CodeAdapt在六项任务上提供了卓越的性能（最高提升35.7%）。此外，代码增强的推理轨迹展示了丰富多样的解决问题策略。

Conclusion: (1) CodeAdapt风格的学习和推理可能具有鲁棒性和领域通用性；(2) 启用代码的语言模型是认知基础强大且功能强大的系统，这可能为权重内强化学习提供坚实的基础。

Abstract: Reasoning models (RMs), language models (LMs) trained with reinforcement
learning to produce long-form natural language reasoning, have been remarkably
successful, but they still require large amounts of computation and data to
train, and can be slow and expensive to run. In this paper, we show that
standard instruct LMs can already be elicited to be strong reasoners at a level
comparable to or even surpassing their corresponding RMs (e.g., DeepSeek V3 vs
R1) without finetuning, across diverse domains from instruction following and
creative generation to mathematical reasoning. This is achieved by CodeAdapt,
our simple recipe that combines the CodeAct framework, where LMs interleave
natural language reasoning with code execution in a multi-step fashion, with
few-shot bootstrap in-context learning from as few as five training problems.
Analyzing four matched pairs of LMs and RMs, we find that CodeAdapt enables
three LMs to outperform the corresponding RMs on average over eight tasks (up
to 22.9%) while being 10-81% more token efficient, and delivers superior
performance on six tasks when averaged over the four models (up to 35.7%).
Furthermore, the code-augmented reasoning traces display rich and varied
problem-solving strategies. Our findings support that (1) CodeAdapt-style
learning and reasoning may be robust and domain general and (2) code-enabled
LMs are cognitively grounded and powerful systems, potentially providing a
strong foundation for in-weight reinforcement learning.

</details>


### [2] [FicSim: A Dataset for Multi-Faceted Semantic Similarity in Long-Form Fiction](https://arxiv.org/abs/2510.20926)
*Natasha Johnson,Amanda Bertsch,Maria-Emil Deal,Emma Strubell*

Main category: cs.CL

TL;DR: 本文介绍了FICSIM，这是一个用于评估长篇小说语言模型的新数据集。它解决了现有数据集在评估计算文学研究任务时的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前，现有数据集不适合评估文学领域的语言模型任务，因为它们侧重于粗粒度相似性和非常短的文本，并且在长文本的细粒度标注方面成本高昂，且存在数据污染问题。

Method: 本文收集并发布了FICSIM数据集，该数据集包含长篇、近期创作的小说，并根据作者提供的元数据和数字人文领域学者的验证，提供了12个相似性维度的分数。

Result: 通过在FICSIM数据集上评估一系列嵌入模型，本文发现这些模型倾向于关注表面特征，而非对计算文学研究任务有用的语义类别。

Conclusion: FICSIM数据集的发布以及对现有嵌入模型评估结果表明，当前模型在理解文学文本的深层语义方面仍有不足，未来需要开发更能捕捉文学作品语义特征的模型。

Abstract: As language models become capable of processing increasingly long and complex
texts, there has been growing interest in their application within
computational literary studies. However, evaluating the usefulness of these
models for such tasks remains challenging due to the cost of fine-grained
annotation for long-form texts and the data contamination concerns inherent in
using public-domain literature. Current embedding similarity datasets are not
suitable for evaluating literary-domain tasks because of a focus on
coarse-grained similarity and primarily on very short text. We assemble and
release FICSIM, a dataset of long-form, recently written fiction, including
scores along 12 axes of similarity informed by author-produced metadata and
validated by digital humanities scholars. We evaluate a suite of embedding
models on this task, demonstrating a tendency across models to focus on
surface-level features over semantic categories that would be useful for
computational literary studies tasks. Throughout our data-collection process,
we prioritize author agency and rely on continual, informed author consent.

</details>


### [3] [Do LLMs Truly Understand When a Precedent Is Overruled?](https://arxiv.org/abs/2510.20941)
*Li Zhang,Jaromir Savelka,Kevin Ashley*

Main category: cs.CL

TL;DR: 这篇论文评估了大型语言模型在理解长篇法律文本方面的能力，提出了一个基于美国最高法院判例的基准，并揭示了LLMs在处理历史案例、深度法律推理和复杂语境下的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理扩展上下文窗口的复杂法律推理任务中展现出潜力，但它们理解长篇法律文档的能力尚未得到充分评估。现有评估大多依赖简化的人工任务，未能反映现实世界文档理解的复杂性。因此，开发能够捕捉真实、高风险任务的长期上下文基准是一个重大挑战。

Method: 本文通过分析美国最高法院判例中的“推翻关系”（overruling relationships），构建了一个由236对判例组成的数据集。研究人员使用该数据集评估了最先进的大型语言模型识别这些推翻关系的能力。

Result: 评估发现大型语言模型存在三个关键局限性：1) 时代敏感性：模型在处理历史案例时表现不佳，揭示了训练中的时间偏差；2) 浅层推理：模型依赖浅层逻辑启发式而非深层法律理解；3) 依赖上下文的推理失败：在复杂的开放式任务中，模型会产生时间上不可能的关系，尽管在简单上下文中能保持基本的时间意识。

Conclusion: 本文建立了一个新的基准，解决了现实世界中长文本评估的关键空白，为模拟实际法律推理任务的复杂性和重要性提供了环境。

Abstract: Large language models (LLMs) with extended context windows show promise for
complex legal reasoning tasks, yet their ability to understand long legal
documents remains insufficiently evaluated. Developing long-context benchmarks
that capture realistic, high-stakes tasks remains a significant challenge in
the field, as most existing evaluations rely on simplified synthetic tasks that
fail to represent the complexity of real-world document understanding.
Overruling relationships are foundational to common-law doctrine and commonly
found in judicial opinions. They provide a focused and important testbed for
long-document legal understanding that closely resembles what legal
professionals actually do. We present an assessment of state-of-the-art LLMs on
identifying overruling relationships from U.S. Supreme Court cases using a
dataset of 236 case pairs. Our evaluation reveals three critical limitations:
(1) era sensitivity -- the models show degraded performance on historical cases
compared to modern ones, revealing fundamental temporal bias in their training;
(2) shallow reasoning -- models rely on shallow logical heuristics rather than
deep legal comprehension; and (3) context-dependent reasoning failures --
models produce temporally impossible relationships in complex open-ended tasks
despite maintaining basic temporal awareness in simple contexts. Our work
contributes a benchmark that addresses the critical gap in realistic
long-context evaluation, providing an environment that mirrors the complexity
and stakes of actual legal reasoning tasks.

</details>


### [4] [Social Simulations with Large Language Model Risk Utopian Illusion](https://arxiv.org/abs/2510.21180)
*Ning Bian,Xianpei Han,Hongyu Lin,Baolei Wu,Jun Wang*

Main category: cs.CL

TL;DR: 本文提出了一种分析大型语言模型（LLMs）在社会模拟中行为的系统框架。研究发现，LLMs无法真实再现人类行为，而是反映出过度理想化的版本，形成了缺乏复杂性和变异性的“乌托邦”社会。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在模拟人类行为、互动和决策方面展现出巨大潜力，为社会科学研究提供了新视角。然而，LLMs在社会情境中与真实人类行为的差异尚未得到充分探索，这可能导致科学研究中的误解和实际应用中的意外后果。因此，有必要系统地分析LLMs在社会模拟中的行为。

Method: 本研究通过聊天室风格的对话模拟多智能体互动，并从五个语言维度对LLMs的行为进行分析，以检验其新兴的社会认知偏差。作者对三大家族的八个代表性LLMs进行了广泛实验。

Result: 研究结果表明，LLMs并不能忠实地再现真实的人类行为，而是反映出过度理想化的版本，并受到社会称许性偏差的影响。具体而言，LLMs表现出社会角色偏差、首因效应和积极性偏差，导致形成了缺乏真实人类互动复杂性和变异性的“乌托邦”社会。

Conclusion: LLMs在社会模拟中未能真实再现人类行为，而是呈现出理想化且存在社会认知偏差的“乌托邦”社会。这凸显了开发更具社会基础、能捕捉人类社会行为多样性的LLMs的必要性。

Abstract: Reliable simulation of human behavior is essential for explaining,
predicting, and intervening in our society. Recent advances in large language
models (LLMs) have shown promise in emulating human behaviors, interactions,
and decision-making, offering a powerful new lens for social science studies.
However, the extent to which LLMs diverge from authentic human behavior in
social contexts remains underexplored, posing risks of misinterpretation in
scientific studies and unintended consequences in real-world applications.
Here, we introduce a systematic framework for analyzing LLMs' behavior in
social simulation. Our approach simulates multi-agent interactions through
chatroom-style conversations and analyzes them across five linguistic
dimensions, providing a simple yet effective method to examine emergent social
cognitive biases. We conduct extensive experiments involving eight
representative LLMs across three families. Our findings reveal that LLMs do not
faithfully reproduce genuine human behavior but instead reflect overly
idealized versions of it, shaped by the social desirability bias. In
particular, LLMs show social role bias, primacy effect, and positivity bias,
resulting in "Utopian" societies that lack the complexity and variability of
real human interactions. These findings call for more socially grounded LLMs
that capture the diversity of human social behavior.

</details>


### [5] [Irish-BLiMP: A Linguistic Benchmark for Evaluating Human and Language Model Performance in a Low-Resource Setting](https://arxiv.org/abs/2510.20957)
*Josh McGiff,Khanh-Tung Tran,William Mulcahy,Dáibhidh Ó Luinín,Jake Dalzell,Róisín Ní Bhroin,Adam Burke,Barry O'Sullivan,Hoang D. Nguyen,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 爱尔兰语-BLiMP是第一个用于爱尔兰语语言能力评估的基准数据集和框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在不同语言之间表现出不同的性能，这项研究旨在评估LLMs在资源匮乏的爱尔兰语上的语言能力。

Method: 手动构建了1020个最小对，涵盖11个语言特征，并由爱尔兰语流利者团队进行审查。

Result: 人类在所有语言特征上都优于所有模型，平均准确率高出16.6%。LLMs之间的性能差距为18.1%，即使是最强的模型（GPT-5）也仅达到73.5%的准确率，而人类的准确率为90.1%。人类参与者和模型在爱尔兰语语法的不同方面存在困难。

Conclusion: Irish-BLiMP为评估LLMs在爱尔兰语中的语法能力提供了第一个系统框架，并为低资源语言的语言理解研究提供了有价值的基准。

Abstract: We present Irish-BLiMP (Irish Benchmark of Linguistic Minimal Pairs), the
first dataset and framework designed for fine-grained evaluation of linguistic
competence in the Irish language, an endangered language. Drawing on a variety
of linguistic literature and grammar reference works, we manually constructed
and reviewed 1020 minimal pairs across a taxonomy of 11 linguistic features,
through a team of fluent Irish speakers. We evaluate both existing Large
Language Models (LLMs) and fluent human participants on their syntactic
knowledge of Irish. Our findings show that humans outperform all models across
all linguistic features, achieving 16.6% higher accuracy on average. Moreover,
a substantial performance gap of 18.1% persists between open- and closed-source
LLMs, with even the strongest model (gpt-5) reaching only 73.5% accuracy
compared to 90.1% by human. Interestingly, human participants and models
struggle on different aspects of Irish grammar, thus highlighting a difference
in representation learned by the models. Overall, Irish-BLiMP provides the
first systematic framework for evaluating the grammatical competence of LLMs in
Irish and offers a valuable benchmark for advancing research on linguistic
understanding in low-resource languages.

</details>


### [6] [Can Confidence Estimates Decide When Chain-of-thought is Necessary for Llms?](https://arxiv.org/abs/2510.21007)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 本文探讨了CoT提示在LLMs中提高推理能力的同时，可能导致不必要的token使用。作者提出了一种置信度门控CoT方法，仅在模型对其直接答案的置信度较低时才启用CoT。研究评估了四种免训练的置信度估计方法，并证明它们可以减少冗余的CoT并优于随机CoT。


<details>
  <summary>Details</summary>
Motivation: CoT提示在提高LLMs推理能力的同时，存在token使用过多的问题，且CoT并非总能带来性能提升甚至可能损害性能。因此，需要明确何时使用CoT。

Method: 本文提出置信度门控CoT（confidence-gated CoT），即只有当模型对其直接答案的置信度较低时才调用CoT。为此，文章首次系统研究了CoT门控的免训练置信度估计方法，并评估了四种免训练置信度估计方法，与随机基线和理想情况（oracle）进行比较。

Result: 现有的免训练置信度度量方法可以减少冗余的CoT，并且优于随机调用的CoT。然而，单一置信度度量的效用是不一致的，它随着数据集和模型的不同而变化。

Conclusion: 置信度门控CoT在减少冗余的CoT方面表现出潜力，但目前的免训练置信度估计方法在不同数据集和模型上的表现不一致，限制了其实际部署。未来的研究需要开发更可靠的自适应CoT门控方法。

Abstract: Chain-of-thought (CoT) prompting has emerged as a common technique for
enhancing the reasoning abilities of large language models (LLMs). While
extended reasoning can boost accuracy on complex tasks, it is often unnecessary
and substantially increases token usage, limiting the practicality of reasoning
models in many scenarios. Recent models, such as GPT-OSS and Qwen3, expose
controls that enable users to adjust the length of CoT or determine whether it
is used at all. Yet, it remains unclear when CoT should be used: on some tasks
it improves performance, while on others it provides little benefit or even
harms performance. We address this challenge with confidence-gated CoT, where a
model invokes reasoning only when confidence in its direct answer is low. To
this end, we present the first systematic study of training-free confidence
estimation methods for CoT gating. Specifically, we evaluate four training-free
confidence estimation methods and compare them to a random baseline and an
oracle that always knows when CoT is needed. Through extensive experiments, we
show that existing training-free confidence measures can reduce redundant CoT
and outperform randomly invoked CoT. However, the utility of individual
confidence measures is inconsistent, varying with both the dataset and the
model, underscoring the difficulty of deploying confidence-gated CoT in
practice. By analysing both strengths and failure modes, our study highlights
the potential and limitations of current methods and paves the way toward more
reliable adaptive gating of CoT.

</details>


### [7] [Reasoning's Razor: Reasoning Improves Accuracy but Can Hurt Recall at Critical Operating Points in Safety and Hallucination Detection](https://arxiv.org/abs/2510.21049)
*Atoosa Chegini,Hamid Kazemi,Garrett Souza,Maria Safi,Yang Song,Samy Bengio,Sinead Williamson,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLMs）的推理能力在对误报率（FPR）敏感的分类任务中的适用性。结果表明，推理能力可以提高整体准确性，但在低FPR要求下表现不佳，“Think Off”模式在这种情况下表现更好。将两种模式结合可以平衡准确性和精确度。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）的推理能力在对精确度敏感的任务中（如低误报率FPR）的有效性，因为目前尚不明确推理能力是否适用于此类任务。

Method: 本文通过系统性研究，在安全检测和幻觉检测两类分类任务中，评估了“Think On”（推理增强）和“Think Off”（推理关闭）两种模式在微调和零样本设置下的表现。此外，研究还比较了基于Token的评分和自陈述置信度在精确度敏感任务中的效果，并尝试结合两种模式的优势。

Result: 研究发现，“Think On”模式虽然能提高整体准确性，但在对FPR要求严格的场景下表现不佳；而“Think Off”模式在这种精确度敏感的任务中表现更优。仅当可以接受更高的FPR时，“Think On”模式才超越“Think Off”模式。另外，研究发现基于Token的评分在精确度敏感部署中明显优于自陈述置信度。最后，一个简单的两种模式的组合可以恢复各自的优势。

Conclusion: 推理能力对于平均准确性有益，但对于需要严格精确度的应用常常不太适用。这提示在实际应用中需要根据任务对精确度的要求权衡是否使用LLM的推理能力。

Abstract: Reasoning has become a central paradigm for large language models (LLMs),
consistently boosting accuracy across diverse benchmarks. Yet its suitability
for precision-sensitive tasks remains unclear. We present the first systematic
study of reasoning for classification tasks under strict low false positive
rate (FPR) regimes. Our analysis covers two tasks--safety detection and
hallucination detection--evaluated in both fine-tuned and zero-shot settings,
using standard LLMs and Large Reasoning Models (LRMs). Our results reveal a
clear trade-off: Think On (reasoning-augmented) generation improves overall
accuracy, but underperforms at the low-FPR thresholds essential for practical
use. In contrast, Think Off (no reasoning during inference) dominates in these
precision-sensitive regimes, with Think On surpassing only when higher FPRs are
acceptable. In addition, we find token-based scoring substantially outperforms
self-verbalized confidence for precision-sensitive deployments. Finally, a
simple ensemble of the two modes recovers the strengths of each. Taken
together, our findings position reasoning as a double-edged tool: beneficial
for average accuracy, but often ill-suited for applications requiring strict
precision.

</details>


### [8] [Dynamic Retriever for In-Context Knowledge Editing via Policy Optimization](https://arxiv.org/abs/2510.21059)
*Mahmud Wasif Nafee,Maiqi Jiang,Haipeng Chen,Yanfu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为DR-IKE的动态检索框架，用于上下文知识编辑，它通过动态选择与编辑任务相关的高价值示例，避免了传统方法中数量与质量的权衡问题，提高了编辑成功率并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在事实回忆方面表现出色，但仍会传播过时或不正确的知识。上下文知识编辑为黑盒API提供了一种无梯度补救措施，但当前的编辑器依赖于通过表面相似性选择的静态演示集，导致存在数量-质量权衡以及对任务难度缺乏适应性等问题。

Method: 本文提出了DR-IKE（Dynamic Retriever for In-Context Knowledge Editing）框架，通过以下方法解决问题：1. 使用REINFORCE训练BERT检索器，根据编辑奖励对演示进行排序。2. 采用可学习的阈值来修剪低价值示例，在编辑简单时缩短提示，在任务困难时扩展提示。DR-IKE在不修改模型权重的情况下执行编辑，仅依赖前向传播以兼容黑盒LLM。

Result: 在COUNTERFACT基准测试中，DR-IKE将编辑成功率提高了17.1%，将延迟降低了41.6%，并保持了对无关查询的准确性。

Conclusion: DR-IKE是一种可扩展且自适应的知识编辑方法，通过动态选择有用的演示，解决了传统上下文知识编辑方法的局限性，显著提高了编辑性能和效率。

Abstract: Large language models (LLMs) excel at factual recall yet still propagate
stale or incorrect knowledge. In-context knowledge editing offers a
gradient-free remedy suitable for black-box APIs, but current editors rely on
static demonstration sets chosen by surface-level similarity, leading to two
persistent obstacles: (i) a quantity-quality trade-off, and (ii) lack of
adaptivity to task difficulty. We address these issues by dynamically selecting
supporting demonstrations according to their utility for the edit. We propose
Dynamic Retriever for In-Context Knowledge Editing (DR-IKE), a lightweight
framework that (1) trains a BERT retriever with REINFORCE to rank
demonstrations by editing reward, and (2) employs a learnable threshold to
prune low-value examples, shortening the prompt when the edit is easy and
expanding it when the task is hard. DR-IKE performs editing without modifying
model weights, relying solely on forward passes for compatibility with
black-box LLMs. On the COUNTERFACT benchmark, it improves edit success by up to
17.1%, reduces latency by 41.6%, and preserves accuracy on unrelated queries,
demonstrating scalable and adaptive knowledge editing. The code is available at
https://github.com/mwnafee/DR-IKE .

</details>


### [9] [Bridging Language Gaps with Adaptive RAG: Improving Indonesian Language Question Answering](https://arxiv.org/abs/2510.21068)
*William Christian,Daniel Adamlu,Adrian Yu,Derwin Suhartono*

Main category: cs.CL

TL;DR: 该文章开发了一种用于印尼语的自适应RAG系统，旨在解决低资源语言的问答任务，并通过实验验证了其分类器的可靠性，但多检索策略仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的问答系统（QA）在很大程度上依赖于英文数据，这导致了在其他语言（如印尼语）中存在显著的语言鸿沟。为了弥补这一差距，本文旨在开发一个针对印尼语的自适应检索增强生成（RAG）系统。

Method: 本文提出了一种自适应RAG系统，该系统集成了一个分类器，用于区分问题的复杂性，并根据复杂性确定回答策略。为了解决印尼语数据集的限制，研究采用了机器翻译进行数据增强。

Result: 实验表明，用于问题复杂性分类的分类器表现出“可靠”的性能。然而，研究人员发现在多检索回答策略中存在显著的“不一致性”，这在应用该策略时对整体评估产生了负面影响。

Conclusion: 印尼语的自适应RAG系统在弥合语言差距和改进低资源语言的问答方面显示出潜力。尽管问题复杂性分类器表现可靠，但多检索回答策略中的不一致性表明该领域仍面临挑战，需要进一步研究和改进。

Abstract: Question Answering (QA) has seen significant improvements with the
advancement of machine learning models, further studies enhanced this question
answering system by retrieving external information, called Retrieval-Augmented
Generation (RAG) to produce more accurate and informative answers. However,
these state-of-the-art-performance is predominantly in English language. To
address this gap we made an effort of bridging language gaps by incorporating
Adaptive RAG system to Indonesian language. Adaptive RAG system integrates a
classifier whose task is to distinguish the question complexity, which in turn
determines the strategy for answering the question. To overcome the limited
availability of Indonesian language dataset, our study employs machine
translation as data augmentation approach. Experiments show reliable question
complexity classifier; however, we observed significant inconsistencies in
multi-retrieval answering strategy which negatively impacted the overall
evaluation when this strategy was applied. These findings highlight both the
promise and challenges of question answering in low-resource language
suggesting directions for future improvement.

</details>


### [10] [CDrugRed: A Chinese Drug Recommendation Dataset for Discharge Medications in Metabolic Diseases](https://arxiv.org/abs/2510.21084)
*Juntao Li,Haobin Yuan,Ling Luo,Yan Jiang,Fan Wang,Ping Zhang,Huiyi Lv,Jian Wang,Yuanyuan Sun,Hongfei Lin*

Main category: cs.CL

TL;DR: 该论文介绍了CDrugRed，这是一个针对代谢疾病出院药物的中文药物推荐数据集，旨在解决EHR数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 智能药物推荐系统在临床决策中至关重要，但由于缺乏公开的、真实世界的EHR数据集（尤其是非英语数据集），其发展受到限制。

Method: 本研究构建了CDrugRed数据集，包含5894条去识别化的中国患者记录，涵盖人口统计学、病史、临床病程和出院诊断等信息。研究通过基准测试发现，尽管监督微调能提高模型性能，但最佳模型的F1分数仅为0.5648，Jaccard分数仅为0.4477。

Result: CDrugRed的构建填补了中文EHR药物推荐数据集的空白，并初步评估了当前LLMs在该任务上的表现，揭示了该任务的复杂性和现有模型的局限性。

Conclusion: CDrugRed是一个具有挑战性和有价值的资源，可用于开发更强大和准确的药物推荐系统，并为该领域未来的研究提供了基础。

Abstract: Intelligent drug recommendation based on Electronic Health Records (EHRs) is
critical for improving for improving the quality and efficiency of clinical
decision-making. By leveraging large-scale patient data, drug recommendation
systems can assist physicians in selecting the most appropriate medications
according to a patient's medical history, diagnoses, laboratory results, and
comorbidities. However, the advancement of such systems is significantly
hampered by the scarcity of publicly available, real-world EHR datasets,
particularly in languages other than English. In this work, we present
CDrugRed, a first publicly available Chinese drug recommendation dataset
focused on discharge medications for metabolic diseases. The dataset includes
5,894 de-identified records from 3,190 patients, containing comprehensive
information such as patient demographics, medical history, clinical course, and
discharge diagnoses. We assess the utility of CDrugRed by benchmarking several
state-of-the-art large language models (LLMs) on the discharge medication
recommendation task. Experimental results show that while supervised
fine-tuning improves model performance, there remains substantial room for
improvement, with the best model achieving the F1 score of 0.5648 and Jaccard
score of 0.4477. This result highlights the complexity of the clinical drug
recommendation task and establishes CDrugRed as a challenging and valuable
resource for developing more robust and accurate drug recommendation systems.
The dataset is publicly available to the research community under the data
usage agreements at https://github.com/DUTIR-BioNLP/CDrugRed.

</details>


### [11] [Multi-turn Training with Basic Human Feedback Helps Little on LLM Reasoning](https://arxiv.org/abs/2510.21339)
*Qiang Liu,Wuganjing Song,Zhenzhou Lin,Feifan Chen,Qiaolong Cai,Chen Li,Yongduo Sui*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）推理能力训练的单轮和多轮方法，发现单轮训练在面对单轮和多轮评估时表现有效，而多轮训练可能导致单轮推理性能下降。


<details>
  <summary>Details</summary>
Motivation: 探索多轮人机交互对LLMs推理能力训练的必要性，并比较单轮与多轮训练策略的有效性。

Method: 比较了传统的单轮训练以及三种多轮训练策略。在单轮和多轮评估环境中对这些训练策略进行测试。

Result: 单轮训练的模型在单轮和多轮评估中均表现良好，而多轮训练的模型在单轮推理性能上显著下降。

Conclusion: 对于信息完整的任务，鲁棒的单轮训练更有效和可靠，因为基于基本反馈的多轮训练益处有限，甚至可能损害推理能力。

Abstract: The reasoning capabilities of Large Language Models (LLMs) are typically
developed through the single-turn reinforcement learning, whereas real-world
applications often involve multi-turn interactions with human feedback, leading
to a potential mismatch between training and deployment conditions. In this
work, we study whether multi-turn training with human feedback is necessary for
reasoning tasks. We compare conventional single-turn training with three
multi-turn strategies and reach contrary conclusions to previous research. We
find that models trained in a single-turn setting generalize effectively to
both single- and multi-turn evaluations, while models trained with multi-turn
strategies exhibit a significant degradation in single-turn reasoning
performance. These results suggest that for tasks with complete information,
robust single-turn training remains more effective and reliable, as multi-turn
training with basic feedback provides limited benefits and can even degrade
reasoning capabilities.

</details>


### [12] [Self-Rewarding PPO: Aligning Large Language Models with Demonstrations Only](https://arxiv.org/abs/2510.21090)
*Qingru Zhang,Liang Qiu,Ilgee Hong,Zhenghao Xu,Tianyi Liu,Shiyang Li,Rongzhi Zhang,Zheng Li,Lihong Li,Bing Yin,Chao Zhang,Jianshu Chen,Haoming Jiang,Tuo Zhao*

Main category: cs.CL

TL;DR: Self-Rewarding PPO 是一种新颖的微调方法，它利用在策略技术来增强泛化性能。通过结合 SFT 和 PPO 的优势，可以从未经人类偏好注释的演示数据中实现更有效的对齐。


<details>
  <summary>Details</summary>
Motivation: SFT 作为一种与行为克隆类似的离策略方法，常常面临过拟合和域外泛化能力差的问题，尤其是在数据有限的情况下。

Method: 我们提出 Self-Rewarding PPO，一种新颖的微调方法，它利用在策略技术来增强泛化性能。我们的方法结合了 SFT 和近端策略优化（PPO）的优势，以实现更有效地从演示数据中进行对齐。其核心是设计为 SFT 模型和预训练基础模型之间的对数策略比率的奖励函数。该函数充当隐式奖励信号，使用预训练策略作为基线，SFT 策略作为目标。

Result: Self-Rewarding PPO 在一系列自然语言处理任务中始终优于传统的 SFT 方法。

Conclusion: 该结果突出了我们方法在使用演示数据对 LLM 进行对齐方面的有效性，尤其是在高质量注释数据稀缺的情况下。

Abstract: Supervised fine-tuning (SFT) has emerged as a crucial method for aligning
large language models (LLMs) with human-annotated demonstrations. However, SFT,
being an off-policy approach similar to behavior cloning, often struggles with
overfitting and poor out-of-domain generalization, especially in limited-data
scenarios. To address these limitations, we propose Self-Rewarding PPO, a novel
fine-tuning method that leverages on-policy techniques to enhance
generalization performance. Our approach combines the strengths of SFT and
proximal policy optimization (PPO) to achieve more effective alignment from
demonstration data. At its core is a reward function designed as the log policy
ratio between the SFT model and the pretrained base model. This function serves
as an implicit reward signal, using the pretrained policy as a baseline and the
SFT policy as a target. By doing so, it enables on-policy fine-tuning without
relying on human preference annotations. The integration of this self-rewarding
mechanism with PPO addresses key limitations of SFT, improving generalization,
data efficiency, and robustness. Our empirical evaluation across a range of
natural language processing tasks demonstrates that Self-Rewarding PPO
consistently outperforms traditional SFT methods. The results highlight the
effectiveness of our approach in aligning LLMs using demonstration data,
particularly in scenarios where high-quality annotated data is scarce.

</details>


### [13] [The Gray Zone of Faithfulness: Taming Ambiguity in Unfaithfulness Detection](https://arxiv.org/abs/2510.21118)
*Qiang Ding,Lvzhou Luo,Yixuan Cao,Ping Luo*

Main category: cs.CL

TL;DR: 这篇文章介绍了一个新的忠实度评估框架VeriGray，用于解决大型语言模型在总结任务中产生幻觉的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成摘要时，需要确保其忠实于原文，但现有基准测试在判断何种外部知识可接受时存在模糊性，导致标注不一致。

Method: 我们提出了一个新的忠实度标注框架，引入了“外部依赖”这一中间类别，用于分类需要外部知识验证的情况。并在此框架下构建了VeriGray基准测试。

Result: 即使是GPT-5这样的SOTA LLM，在总结任务中也存在幻觉（约6%的句子）。平均约8%的大模型生成句子属于“外部依赖”类别。基准测试对现有方法提出了重大挑战。

Conclusion: 现有的忠实度评估存在标注模糊性，引入“外部依赖”类别可以更好地解决这一问题。大模型在总结时仍存在幻觉，需要进一步改进。

Abstract: Ensuring that Large Language Models (LLMs) generate summaries faithful to a
given source document is essential for real-world applications. While prior
research has explored LLM faithfulness, existing benchmarks suffer from
annotation ambiguity, primarily due to the ill-defined boundary of permissible
external knowledge in generated outputs. For instance, common sense is often
incorporated into responses and labeled as "faithful", yet the acceptable
extent of such knowledge remains unspecified, leading to inconsistent
annotations. To address this issue, we propose a novel faithfulness annotation
framework, which introduces an intermediate category, Out-Dependent, to
classify cases where external knowledge is required for verification. Using
this framework, we construct VeriGray (Verification with the Gray Zone) -- a
new unfaithfulness detection benchmark in summarization. Statistics reveal that
even SOTA LLMs, such as GPT-5, exhibit hallucinations ($\sim 6\%$ of sentences)
in summarization tasks. Moreover, a substantial proportion ($\sim 8\%$ on
average of models) of generated sentences fall into the Out-Dependent category,
underscoring the importance of resolving annotation ambiguity in unfaithfulness
detection benchmarks. Experiments demonstrate that our benchmark poses
significant challenges to multiple baseline methods, indicating considerable
room for future improvement.

</details>


### [14] [Large Language Models Meet Text-Attributed Graphs: A Survey of Integration Frameworks and Applications](https://arxiv.org/abs/2510.21131)
*Guangxin Su,Hanchen Wang,Jianwei Wang,Wenjie Zhang,Ying Zhang,Jian Pei*

Main category: cs.CL

TL;DR: 这篇综述系统回顾了大型语言模型（LLM）与文本属性图（TAG）的集成，并提出了一个新颖的分类法来指导未来的研究。


<details>
  <summary>Details</summary>
Motivation: LLMs在自然语言处理方面表现出色，但缺乏结构化和多跳推理能力。TAGs提供了明确的关系结构和文本语境，但缺乏语义深度。将LLMs和TAGs结合可以取长补短。

Method: 本文从编排的角度对LLM-TAG集成进行了首次系统综述。提出了一个涵盖“LLM for TAG”（LLM丰富图任务）和“TAG for LLM”（结构化图改进LLM推理）两个基本方向的新颖分类法。将编排策略分为序列式、并行式和多模块框架，并讨论了TAG特定的预训练、提示和参数高效微调的进展。

Result: 通过结合LLMs和TAGs，可以增强TAG的表示学习，并改进LLMs的推理和可解释性。

Conclusion: LLM-TAG集成是语言和图学习交叉领域的一个有前景的研究方向，未来的工作可以在开放性挑战和有前景的研究方向上继续探索。

Abstract: Large Language Models (LLMs) have achieved remarkable success in natural
language processing through strong semantic understanding and generation.
However, their black-box nature limits structured and multi-hop reasoning. In
contrast, Text-Attributed Graphs (TAGs) provide explicit relational structures
enriched with textual context, yet often lack semantic depth. Recent research
shows that combining LLMs and TAGs yields complementary benefits: enhancing TAG
representation learning and improving the reasoning and interpretability of
LLMs. This survey provides the first systematic review of LLM--TAG integration
from an orchestration perspective. We introduce a novel taxonomy covering two
fundamental directions: LLM for TAG, where LLMs enrich graph-based tasks, and
TAG for LLM, where structured graphs improve LLM reasoning. We categorize
orchestration strategies into sequential, parallel, and multi-module
frameworks, and discuss advances in TAG-specific pretraining, prompting, and
parameter-efficient fine-tuning. Beyond methodology, we summarize empirical
insights, curate available datasets, and highlight diverse applications across
recommendation systems, biomedical analysis, and knowledge-intensive question
answering. Finally, we outline open challenges and promising research
directions, aiming to guide future work at the intersection of language and
graph learning.

</details>


### [15] [Estonian Native Large Language Model Benchmark](https://arxiv.org/abs/2510.21193)
*Helena Grete Lillepalu,Tanel Alumäe*

Main category: cs.CL

TL;DR: 介绍了爱沙尼亚语LLMs评估基准，并对多个模型进行了评估。


<details>
  <summary>Details</summary>
Motivation: 爱沙尼亚语LLM基准匮乏，缺乏全面的性能评估。

Method: 构建包含7个不同数据集的爱沙尼亚语LLM评估基准，数据集来自原生爱沙尼亚语资源，未使用机器翻译。评估了6个基础模型和26个指令微调模型。通过人工评估和LLM-as-a-judge方法评估结果。

Result: 人工评估分数与基准评估存在中度到高度相关性。Claude 3.7 Sonnet作为LLM评判者，与人类评分高度一致。

Conclusion: 所提出的基准可以有效评估爱沙尼亚语LLM。顶级LLM可以有效支持爱沙尼亚语模型的评估。

Abstract: The availability of LLM benchmarks for the Estonian language is limited, and
a comprehensive evaluation comparing the performance of different LLMs on
Estonian tasks has yet to be conducted. We introduce a new benchmark for
evaluating LLMs in Estonian, based on seven diverse datasets. These datasets
assess general and domain-specific knowledge, understanding of Estonian grammar
and vocabulary, summarization abilities, contextual comprehension, and more.
The datasets are all generated from native Estonian sources without using
machine translation. We compare the performance of base models,
instruction-tuned open-source models, and commercial models. Our evaluation
includes 6 base models and 26 instruction-tuned models. To assess the results,
we employ both human evaluation and LLM-as-a-judge methods. Human evaluation
scores showed moderate to high correlation with benchmark evaluations,
depending on the dataset. Claude 3.7 Sonnet, used as an LLM judge, demonstrated
strong alignment with human ratings, indicating that top-performing LLMs can
effectively support the evaluation of Estonian-language models.

</details>


### [16] [The "Right" Discourse on Migration: Analysing Migration-Related Tweets in Right and Far-Right Political Movements](https://arxiv.org/abs/2510.21220)
*Nishan Chatterjee,Veronika Bajt,Ana Zwitter Vitez,Senja Pollak*

Main category: cs.CL

TL;DR: 该研究分析了欧洲右翼民粹主义在社交媒体上的言论，以理解极端主义意识形态的传播及其对政治结果的影响。


<details>
  <summary>Details</summary>
Motivation: 理解社交媒体上右翼和极右翼行动者传播极端主义意识形态的模式、仇恨言论和说服技巧对政治结果的影响。

Method: 提出了一种结合先进自然语言处理技术和社会学见解的方法，用于分析MIGR-TWIT语料库中的英文和法文极右翼推文。

Result: 揭示了围绕移民、仇恨言论和右翼与极右翼行动者所采用的说服技巧的论述模式。

Conclusion: 通过整合语言学、社会学和计算方法，为社会动态提供跨学科见解，并促进更好地理解社交媒体平台上右翼极端主义带来的当代挑战。

Abstract: The rise of right-wing populism in Europe has brought to the forefront the
significance of analysing social media discourse to understand the
dissemination of extremist ideologies and their impact on political outcomes.
Twitter, as a platform for interaction and mobilisation, provides a unique
window into the everyday communication of far-right supporters. In this paper,
we propose a methodology that uses state-of-the-art natural language processing
techniques with sociological insights to analyse the MIGR-TWIT corpus of
far-right tweets in English and French. We aim to uncover patterns of discourse
surrounding migration, hate speech, and persuasion techniques employed by right
and far-right actors. By integrating linguistic, sociological, and
computational approaches, we seek to offer cross-disciplinary insights into
societal dynamics and contribute to a better understanding of contemporary
challenges posed by right-wing extremism on social media platforms.

</details>


### [17] [Correlation Dimension of Auto-Regressive Large Language Models](https://arxiv.org/abs/2510.21258)
*Xin Du,Kumiko Tanaka-Ishii*

Main category: cs.CL

TL;DR: 这篇文章介绍了一种新的评估大型语言模型生成文本复杂性的方法——关联维度（correlation dimension）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本生成方面取得了显著进展，但仍然存在重复和不连贯等问题，这表明传统评估指标存在局限性，它们侧重于局部预测准确性，而忽视了长程结构复杂性。

Method: 引入了关联维度，这是一种分形几何的自相似性度量，用于量化语言模型所感知的文本的认知复杂性。该方法捕捉了语言的层次递归结构，并在统一的框架中连接了局部和全局属性。

Result: 实验表明，关联维度可以揭示预训练过程中的三个不同阶段，反映上下文相关的复杂性，指示模型产生幻觉的倾向，并可靠地检测生成文本中的多种退化形式。

Conclusion: 关联维度方法计算效率高，对模型量化具有鲁棒性，广泛适用于各种自回归架构，并为大型语言模型的生成动态提供了新的见解。

Abstract: Large language models (LLMs) have achieved remarkable progress in natural
language generation, yet they continue to display puzzling behaviors -- such as
repetition and incoherence -- even when exhibiting low perplexity. This
highlights a key limitation of conventional evaluation metrics, which emphasize
local prediction accuracy while overlooking long-range structural complexity.
We introduce correlation dimension, a fractal-geometric measure of
self-similarity, to quantify the epistemological complexity of text as
perceived by a language model. This measure captures the hierarchical
recurrence structure of language, bridging local and global properties in a
unified framework. Through extensive experiments, we show that correlation
dimension (1) reveals three distinct phases during pretraining, (2) reflects
context-dependent complexity, (3) indicates a model's tendency toward
hallucination, and (4) reliably detects multiple forms of degeneration in
generated text. The method is computationally efficient, robust to model
quantization (down to 4-bit precision), broadly applicable across
autoregressive architectures (e.g., Transformer and Mamba), and provides fresh
insight into the generative dynamics of LLMs.

</details>


### [18] [Sparser Block-Sparse Attention via Token Permutation](https://arxiv.org/abs/2510.21270)
*Xinghao Wang,Pengyu Wang,Dong Zhang,Chenkun Tan,Shaojun Zhou,Zhaoxiang Liu,Shiguo Lian,Fangxu Liu,Kai Song,Xipeng Qiu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为Permuted Block-Sparse Attention（PBS-Attn）的方法，旨在通过利用注意力机制的置换特性来提高块级稀疏性，从而解决大型语言模型在处理长上下文时自注意力机制计算成本高的问题，PBS-Attn在实验中表现出比现有块稀疏注意力方法更高的准确性和显著的加速效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的上下文长度扩展具有显著优势，但计算成本高昂，主要瓶颈在于自注意力机制的O(N^2)复杂度，而注意力矩阵的稀疏性为优化提供了机会。

Method: 本文提出了一种称为Permuted Block-Sparse Attention (PBS-Attn) 的即插即用方法，利用注意力的置换特性来提高块级稀疏性，并增强LLM预填充的计算效率。

Result: PBS-Attn在长上下文预填充中实现了高达2.75倍的端到端加速，并且在模型准确性方面持续优于现有的块稀疏注意力方法，同时与完全注意力基线非常接近。

Conclusion: PBS-Attn通过利用注意力机制的置换特性，有效提高了块级稀疏性，显著提升了大型语言模型处理长上下文时的计算效率和准确性，证明了其在实际应用中的可行性。

Abstract: Scaling the context length of large language models (LLMs) offers significant
benefits but is computationally expensive. This expense stems primarily from
the self-attention mechanism, whose $O(N^2)$ complexity with respect to
sequence length presents a major bottleneck for both memory and latency.
Fortunately, the attention matrix is often sparse, particularly for long
sequences, suggesting an opportunity for optimization. Block-sparse attention
has emerged as a promising solution that partitions sequences into blocks and
skips computation for a subset of these blocks. However, the effectiveness of
this method is highly dependent on the underlying attention patterns, which can
lead to sub-optimal block-level sparsity. For instance, important key tokens
for queries within a single block may be scattered across numerous other
blocks, leading to computational redundancy. In this work, we propose Permuted
Block-Sparse Attention (\textbf{PBS-Attn}), a plug-and-play method that
leverages the permutation properties of attention to increase block-level
sparsity and enhance the computational efficiency of LLM prefilling. We conduct
comprehensive experiments on challenging real-world long-context datasets,
demonstrating that PBS-Attn consistently outperforms existing block-sparse
attention methods in model accuracy and closely matches the full attention
baseline. Powered by our custom permuted-FlashAttention kernels, PBS-Attn
achieves an end-to-end speedup of up to $2.75\times$ in long-context
prefilling, confirming its practical viability. Code available at
https://github.com/xinghaow99/pbs-attn

</details>


### [19] [Efficient semantic uncertainty quantification in language models via diversity-steered sampling](https://arxiv.org/abs/2510.21310)
*Ji Won Park,Kyunghyun Cho*

Main category: cs.CL

TL;DR: 本文介绍了一种多样性引导的采样器，用于在大型语言模型（LLM）的开放式问题回答（QA）中准确估计语义偶然性和认知不确定性。该方法通过引入连续语义相似度惩罚来提高采样效率，并在四个QA基准测试中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在LLM的开放式问答中，准确估计语义偶然性和认知不确定性非常具有挑战性，通常需要大量昂贵的生成才能获得稳定的估计。

Method: 本文提出了一种多样性引导的采样器，它在解码过程中抑制语义冗余输出，涵盖自回归和掩码扩散范式，并显著提高了采样效率。核心思想是使用在部分前缀或中间扩散状态上轻度微调的自然语言推理（NLI）模型，将连续语义相似度惩罚注入到模型的提议分布中。通过重要性重加权对下游不确定性估计进行去偏，并使用控制变量减小其方差。

Result: 在四个QA基准测试中，本文方法在相同数量的样本下，与基线方法相当或超越，同时覆盖了更多的语义簇。

Conclusion: 该框架模块化，无需访问基础LLM的梯度，有望作为风险敏感模型部署中不确定性估计的即插即用增强。

Abstract: Accurately estimating semantic aleatoric and epistemic uncertainties in large
language models (LLMs) is particularly challenging in free-form question
answering (QA), where obtaining stable estimates often requires many expensive
generations. We introduce a diversity-steered sampler that discourages
semantically redundant outputs during decoding, covers both autoregressive and
masked diffusion paradigms, and yields substantial sample-efficiency gains. The
key idea is to inject a continuous semantic-similarity penalty into the model's
proposal distribution using a natural language inference (NLI) model lightly
finetuned on partial prefixes or intermediate diffusion states. We debias
downstream uncertainty estimates with importance reweighting and shrink their
variance with control variates. Across four QA benchmarks, our method matches
or surpasses baselines while covering more semantic clusters with the same
number of samples. Being modular and requiring no gradient access to the base
LLM, the framework promises to serve as a drop-in enhancement for uncertainty
estimation in risk-sensitive model deployments.

</details>


### [20] [Typoglycemia under the Hood: Investigating Language Models' Understanding of Scrambled Words](https://arxiv.org/abs/2510.21326)
*Gianluca Sperduti,Alejandro Moreo*

Main category: cs.CL

TL;DR: 研究了人类和NLP模型在乱序字母单词（typoglycemia）下的阅读能力，并探究了其鲁棒性的原因。


<details>
  <summary>Details</summary>
Motivation: 探究NLP模型在“乱序字母症”（typoglycemia）下表现出鲁棒性的原因，即当多个不同的单词（如“form”和“from”）在乱序字母化后变成相同的表示时，模型如何仍能表现良好。

Method: 1. 分析英国国家语料库，量化乱序字母症下的单词塌缩和歧义。
2. 评估BERT模型在区分塌缩形式方面的能力。
3. 对比在正常Wikipedia文本和乱序字母化Wikipedia文本上从头训练的BERT变体的探测实验。

Result: 乱序字母症导致的性能下降小于预期。

Conclusion: NLP模型对乱序字母症的鲁棒性主要归因于：(i) 相对较少的英文单词在乱序字母症下会发生塌缩；(ii) 塌缩的单词倾向于出现在截然不同的上下文中，使得消歧变得微不足道。

Abstract: Research in linguistics has shown that humans can read words with internally
scrambled letters, a phenomenon recently dubbed typoglycemia. Some specific NLP
models have recently been proposed that similarly demonstrate robustness to
such distortions by ignoring the internal order of characters by design. This
raises a fundamental question: how can models perform well when many distinct
words (e.g., form and from) collapse into identical representations under
typoglycemia? Our work, focusing exclusively on the English language, seeks to
shed light on the underlying aspects responsible for this robustness. We
hypothesize that the main reasons have to do with the fact that (i) relatively
few English words collapse under typoglycemia, and that (ii) collapsed words
tend to occur in contexts so distinct that disambiguation becomes trivial. In
our analysis, we (i) analyze the British National Corpus to quantify word
collapse and ambiguity under typoglycemia, (ii) evaluate BERT's ability to
disambiguate collapsing forms, and (iii) conduct a probing experiment by
comparing variants of BERT trained from scratch on clean versus typoglycemic
Wikipedia text; our results reveal that the performance degradation caused by
scrambling is smaller than expected.

</details>


### [21] [TripTide: A Benchmark for Adaptive Travel Planning under Disruptions](https://arxiv.org/abs/2510.21329)
*Priyanshu Karmakar,Soumyabrata Chaudhuri,Shubhojit Mallick,Manish Gupta,Abhik Jana,Shreya Ghosh*

Main category: cs.CL

TL;DR: TripTide是一个评估大型语言模型在真实旅行中断情况下修订旅行计划能力的基准测试。


<details>
  <summary>Details</summary>
Motivation: 先前的旅行规划研究集中于使用大型语言模型（LLMs）生成个性化、符合约束的旅行计划，但忽视了真实旅行中可能出现的中断问题。

Method: TripTide通过建模中断严重程度和旅行者容忍度来评估LLM在航班取消、天气关闭或景点超售等情况下的适应能力。评估方法包括：1. 引入自动评估指标，如意图保持度、响应性和适应性。2. 采用LLM-as-a-judge的方法自动评估修订质量。3. 进行人工专家评估，验证修订计划是否保持了语义、空间、顺序和响应性。

Result: 实验结果表明，LLMs在保持顺序一致性和语义稳定性方面表现良好。对于短途旅行，空间偏差较大，但随着旅行时间增长，偏差减小，表明较长的计划更有助于地理连贯性。然而，处理中断的能力随计划长度的增加而下降。

Conclusion: TripTide为评估基于LLM的旅行规划在真实不确定性下的适应性、个性化和鲁棒性提供了基准，并揭示了LLMs在处理长计划中断时的局限性。

Abstract: Recent efforts like TripCraft and TravelPlanner have advanced the use of
Large Language Models ( LLMs) for personalized, constraint aware travel
itinerary generation. Yet, real travel often faces disruptions. To address
this, we present TripTide, the first benchmark evaluating LLM's ability to
revise itineraries under realistic disruptions. TripTide models key dimensions
such as disruption severity and traveler tolerance, enabling nuanced assessment
of LLM adaptability to events like flight cancellations, weather closures, or
overbooked attractions. We conduct a threefold evaluation. First, we introduce
automatic metrics including Preservation of Intent (how well the revised plan
maintains feasibility and goals), Responsiveness (promptness and
appropriateness of disruption handling), and Adaptability (semantic, spatial,
and sequential divergence between original and revised plans). Second, we apply
an LLM-as-a-judge approach to automatically assess revision quality. Third, we
perform manual expert evaluation to verify whether revisions preserve semantic,
spatial, sequential, and responsive aspects. Our experiments show that LLMs
maintain strong sequential consistency and semantic stability, while spatial
deviations are larger for shorter trips but decrease with longer ones,
indicating that extended plans encourage better geographic coherence. However,
disruption-handling ability declines as plan length increases, highlighting
limits in LLM robustness. TripTide establishes a benchmark for evaluating
adaptability, personalization, and resilience in LLM-based travel planning
under real-world uncertainty.

</details>


### [22] [A Diagnostic Benchmark for Sweden-Related Factual Knowledge](https://arxiv.org/abs/2510.21360)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 这篇论文介绍了瑞典独有的问答基准，用于评估模型在瑞典相关事实知识方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的瑞典基准多为美国中心基准的翻译版本，不适合评估瑞典独有的知识。

Method: 本研究引入了一个手动编写的问答基准，专门针对瑞典相关的人物和事件。标注人员受到了瑞典流行广播节目和重要体育赛事的启发。该数据集可用于衡量不同规模和瑞典语覆盖程度模型的知识回忆能力，并包含英文翻译以探究跨语言事实一致性。

Result: 研究发现，瑞典语覆盖率更强的较小模型在回忆瑞典相关事实方面与尺寸大三倍的多语言模型表现相当。持续的瑞典语预训练通常能提高事实知识，但也会导致部分已知信息的遗忘。

Conclusion: 该数据集有望成为诊断工具，用于研究多语言模型中的语言适应性和知识留存。

Abstract: Many Swedish benchmarks are translated US-centric benchmarks, and therefore
not suitable for testing knowledge that is particularly relevant, or even
specific, to Sweden. We therefore introduce a manually written
question-answering benchmark specifically targeted to Sweden-related
personalities and events, many of which receive very limited coverage in
international media. Our annotators drew inspiration from a popular radio
program featuring public figures from culture and media, as well as major
sports events in Sweden. The dataset can be used to measure factual recall
across models of varying sizes and degrees of Swedish coverage, and allows to
probe cross-lingual factual consistency as to contains English translations.
Using the dataset, we find that smaller models with stronger Swedish coverage
perform comparably to a three times larger multilingual model in recalling
Sweden-related facts. We also observe that continued pre-training on Swedish
generally improves factual knowledge but also leads to forgetting of a part of
the previously known information. These results demonstrate the dataset's
potential as a diagnostic tool for studying language adaptation and knowledge
retention in multilingual models and during language adaptation.

</details>


### [23] [SindBERT, the Sailor: Charting the Seas of Turkish NLP](https://arxiv.org/abs/2510.21364)
*Raphael Scheible-Schmitt,Stefan Schweter*

Main category: cs.CL

TL;DR: SindBERT 是一个针对土耳其语的首个大型 RoBERTa 编码器，它在土耳其语的NLP任务上表现出色，并揭示了数据量、语料库质量和多样性之间的复杂关系。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer模型在NLP领域取得了巨大成功，但许多形态丰富的语言在大型预训练中仍未被充分代表，本研究旨在填补土耳其语在大型预训练模型中的空白。

Method: SindBERT 模型在312GB的土耳其语文本（mC4、OSCAR23、维基百科）上从头开始训练，提供了基础版和大型版配置，并基于RoBERTa架构。

Result: SindBERT 在词性标注、命名实体识别、攻击性语言检测和TurBLiMP语言可接受性基准测试中，与现有土耳其语和多语言模型相比表现出竞争力。大型版本在四项任务中的两项中取得了最佳分数，但没有显示出持续的规模优势，这表明当前的土耳其语基准可能已趋于饱和。与BERTirk等较小但更精选的模型比较显示，语料库的质量和多样性可能比纯粹的数据量更重要。

Conclusion: SindBERT 为土耳其语 NLP 提供了第一个大型 RoBERTa 编码器，并作为一个重要的公开资源。它证实了在形态丰富的语言中，语料库的组成和质量，而非单纯的数据量，是模型性能的关键因素，对未来预训练模型的研究具有指导意义。

Abstract: Transformer models have revolutionized NLP, yet many morphologically rich
languages remain underrepresented in large-scale pre-training efforts. With
SindBERT, we set out to chart the seas of Turkish NLP, providing the first
large-scale RoBERTa-based encoder for Turkish. Trained from scratch on 312 GB
of Turkish text (mC4, OSCAR23, Wikipedia), SindBERT is released in both base
and large configurations, representing the first large-scale encoder-only
language model available for Turkish. We evaluate SindBERT on part-of-speech
tagging, named entity recognition, offensive language detection, and the
TurBLiMP linguistic acceptability benchmark. Our results show that SindBERT
performs competitively with existing Turkish and multilingual models, with the
large variant achieving the best scores in two of four tasks but showing no
consistent scaling advantage overall. This flat scaling trend, also observed
for XLM-R and EuroBERT, suggests that current Turkish benchmarks may already be
saturated. At the same time, comparisons with smaller but more curated models
such as BERTurk highlight that corpus quality and diversity can outweigh sheer
data volume. Taken together, SindBERT contributes both as an openly released
resource for Turkish NLP and as an empirical case study on the limits of
scaling and the central role of corpus composition in morphologically rich
languages. The SindBERT models are released under the MIT license and made
available in both fairseq and Huggingface formats.

</details>


### [24] [Vision Language Models for Dynamic Human Activity Recognition in Healthcare Settings](https://arxiv.org/abs/2510.21424)
*Abderrazek Abid,Thanh-Cong Ho,Fakhri Karray*

Main category: cs.CL

TL;DR: 本文探讨了视觉语言模型（VLMs）在远程健康监测中人体活动识别（HAR）的应用，通过引入描述性字幕数据集和提出全面的评估方法，证明了VLMs在此任务上具有与现有最先进深度学习模型相当甚至超越的性能。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型（VLMs）在远程健康监测中人体活动识别（HAR）领域的应用，解决传统深度学习模型在灵活性方面的局限性以及VLMs输出评估的挑战。

Method: 引入描述性字幕数据集，并提出全面的评估方法来评估VLMs在HAR中的表现。

Result: 通过与现有最先进深度学习模型的对比实验，证明VLMs在HAR任务中取得了可比甚至超越传统方法的准确性表现。

Conclusion: 本研究为VLMs在HAR领域的应用提供了有力的基准，并为将VLMs集成到智能医疗系统中开辟了新的可能性。

Abstract: As generative AI continues to evolve, Vision Language Models (VLMs) have
emerged as promising tools in various healthcare applications. One area that
remains relatively underexplored is their use in human activity recognition
(HAR) for remote health monitoring. VLMs offer notable strengths, including
greater flexibility and the ability to overcome some of the constraints of
traditional deep learning models. However, a key challenge in applying VLMs to
HAR lies in the difficulty of evaluating their dynamic and often
non-deterministic outputs. To address this gap, we introduce a descriptive
caption data set and propose comprehensive evaluation methods to evaluate VLMs
in HAR. Through comparative experiments with state-of-the-art deep learning
models, our findings demonstrate that VLMs achieve comparable performance and,
in some cases, even surpass conventional approaches in terms of accuracy. This
work contributes a strong benchmark and opens new possibilities for the
integration of VLMs into intelligent healthcare systems.

</details>


### [25] [Redefining Retrieval Evaluation in the Era of LLMs](https://arxiv.org/abs/2510.21440)
*Giovanni Trappolini,Florin Cuconasu,Simone Filice,Yoelle Maarek,Fabrizio Silvestri*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种新的度量标准UDCG，用于评估RAG系统，该标准考虑了检索结果对LLM的效用和干扰，并纠正了传统IR度量标准在RAG评估中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的IR度量标准，如nDCG、MAP和MRR，假设人类用户会按顺序查看文档，并对较低排名的文档关注度降低。然而，在RAG系统中，LLM会作为一个整体处理所有检索到的文档，而不是按顺序处理。此外，传统的IR度量标准没有考虑到相关但不重要的文档会降低生成质量。由于这些主要的不一致性，传统的IR度量标准无法准确预测RAG的性能。

Method: 本文提出了一种基于效用的标注模式，用于量化相关段落的积极贡献和分散注意力的段落的负面影响。在此基础上，本文提出了UDCG（Utility and Distraction-aware Cumulative Gain），这是一种使用面向LLM的位置折扣的度量标准，可以直接优化与端到端答案准确性的相关性。

Result: 在五个数据集和六个LLM上的实验表明，与传统度量标准相比，UDCG将相关性提高了36%。

Conclusion: 这项工作是使IR评估与LLM消费者保持一致的关键一步，并能够更可靠地评估RAG组件。

Abstract: Traditional Information Retrieval (IR) metrics, such as nDCG, MAP, and MRR,
assume that human users sequentially examine documents with diminishing
attention to lower ranks. This assumption breaks down in Retrieval Augmented
Generation (RAG) systems, where search results are consumed by Large Language
Models (LLMs), which, unlike humans, process all retrieved documents as a whole
rather than sequentially. Additionally, traditional IR metrics do not account
for related but irrelevant documents that actively degrade generation quality,
rather than merely being ignored. Due to these two major misalignments, namely
human vs. machine position discount and human relevance vs. machine utility,
classical IR metrics do not accurately predict RAG performance. We introduce a
utility-based annotation schema that quantifies both the positive contribution
of relevant passages and the negative impact of distracting ones. Building on
this foundation, we propose UDCG (Utility and Distraction-aware Cumulative
Gain), a metric using an LLM-oriented positional discount to directly optimize
the correlation with the end-to-end answer accuracy. Experiments on five
datasets and six LLMs demonstrate that UDCG improves correlation by up to 36%
compared to traditional metrics. Our work provides a critical step toward
aligning IR evaluation with LLM consumers and enables more reliable assessment
of RAG components

</details>


### [26] [MRO: Enhancing Reasoning in Diffusion Language Models via Multi-Reward Optimization](https://arxiv.org/abs/2510.21473)
*Chenglong Wang,Yang Gan,Hang Zhou,Chi Hu,Yongyu Mu,Kai Song,Murun Yang,Bei Li,Chunliang Zhang,Tongran Liu,Jingbo Zhu,Zhengtao Yu,Tong Xiao*

Main category: cs.CL

TL;DR: 该论文提出了一种多奖励优化（MRO）方法，通过引入组步长和重要性采样策略，提高了扩散语言模型（DLMs）的推理性能，同时实现了显著的采样加速。


<details>
  <summary>Details</summary>
Motivation: DLMs在推理性能方面落后于LLMs，尤其是在去噪步骤减少的情况下。

Method: 本研究提出了多奖励优化（MRO）方法，利用测试时缩放、拒绝采样和强化学习，通过精心设计的多重奖励直接优化代币关联。此外，为了降低奖励方差和提高采样效率，我们引入了组步长和重要性采样策略。

Result: MRO方法在提高推理性能的同时，显著加快了采样速度，并在推理基准测试中保持了高水平的性能。

Conclusion: 本研究通过MRO方法有效地解决了扩散语言模型在推理性能上的不足，并提高了采样效率。

Abstract: Recent advances in diffusion language models (DLMs) have presented a
promising alternative to traditional autoregressive large language models
(LLMs). However, DLMs still lag behind LLMs in reasoning performance,
especially as the number of denoising steps decreases. Our analysis reveals
that this shortcoming arises primarily from the independent generation of
masked tokens across denoising steps, which fails to capture the token
correlation. In this paper, we define two types of token correlation:
intra-sequence correlation and inter-sequence correlation, and demonstrate that
enhancing these correlations improves reasoning performance. To this end, we
propose a Multi-Reward Optimization (MRO) approach, which encourages DLMs to
consider the token correlation during the denoising process. More specifically,
our MRO approach leverages test-time scaling, reject sampling, and
reinforcement learning to directly optimize the token correlation with multiple
elaborate rewards. Additionally, we introduce group step and importance
sampling strategies to mitigate reward variance and enhance sampling
efficiency. Through extensive experiments, we demonstrate that MRO not only
improves reasoning performance but also achieves significant sampling speedups
while maintaining high performance on reasoning benchmarks.

</details>


### [27] [Brain-tuning Improves Generalizability and Efficiency of Brain Alignment in Speech Models](https://arxiv.org/abs/2510.21520)
*Omer Moussa,Mariya Toneva*

Main category: cs.CL

TL;DR: 该研究介绍了一种可扩展、可泛化的脑调谐方法，通过微调预训练的语音语言模型来共同预测多名参与者的fMRI反应，从而在减少数据需求的同时，显著提高模型与人脑反应的对齐程度和泛化能力，并改善下游语义任务的表现，展示了神经科学与人工智能之间的双向益处。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐和改进预训练语言模型与人脑反应的方法，都依赖于个体参与者且受限于每个参与者的数据量，这阻碍了向新参与者的泛化和群体层面的分析。

Method: 本文提出了一种可扩展、可泛化的脑调谐方法：微调预训练的语音语言模型，以共同预测来自多个参与者的fMRI反应。

Result: 1. 将预测新参与者大脑数据所需的fMRI数据量减少了5倍。 2. 整体大脑对齐度提高了50%。 3. 对新的、未见过的数据集具有很强的泛化能力。 4. 多参与者脑调谐还提升了模型在下游语义任务中的表现。

Conclusion: 多参与者的脑调谐方法在实现预训练语言模型与人脑反应的对齐方面具有显著优势，不仅降低了数据需求、增强了泛化能力、提高了对齐度，还改善了模型的语义表示能力。这表明神经科学与人工智能之间存在双向互惠，有助于弥合两个领域之间的鸿沟。

Abstract: Pretrained language models are remarkably effective in aligning with human
brain responses elicited by natural language stimuli, positioning them as
promising model organisms for studying language processing in the brain.
However, existing approaches for both estimating and improving this brain
alignment are participant-dependent and highly affected by the amount of data
available per participant, hindering both generalization to new participants
and population-level analyses. In this work, we address these limitations by
introducing a scalable, generalizable brain-tuning method, in which we
fine-tune pretrained speech language models to jointly predict fMRI responses
from multiple participants. We demonstrate that the resulting brain-tuned
models exhibit strong individual brain alignment while generalizing across
participants. Specifically, our method leads to 1) a 5-fold decrease in the
amount of fMRI data needed to predict brain data from new participants, 2) up
to a 50% increase in the overall brain alignment, and 3) strong generalization
to new unseen datasets. Furthermore, this multi-participant brain-tuning
additionally improves downstream performance on semantic tasks, suggesting that
training using brain data from multiple participants leads to more
generalizable semantic representations. Taken together, these findings
demonstrate a bidirectional benefit between neuroscience and AI, helping bridge
the gap between the two fields. We make our code and models publicly available
at https://github.com/bridge-ai-neuro/multi-brain-tuning.

</details>


### [28] [Document Understanding, Measurement, and Manipulation Using Category Theory](https://arxiv.org/abs/2510.21553)
*Jared Claypoole,Yunye Gong,Noson S. Yanofsky,Ajay Divakaran*

Main category: cs.CL

TL;DR: 该论文利用范畴论提取多模态文档结构，进而开发了信息论度量、内容摘要与扩展以及大型预训练模型自监督改进的方法。


<details>
  <summary>Details</summary>
Motivation: 开发信息论度量、内容摘要与扩展以及大型预训练模型自监督改进的方法。

Method: 首先，将文档数学表示为问答对的范畴。其次，开发正交化程序将文档信息划分为非重叠部分。然后，利用这些结构开发测量和枚举文档信息的方法，以及新的摘要技术和文档扩展（释经）解决方案。最后，使用RLVR开发自监督方法以改进大型预训练模型。

Result: 开发了新的摘要技术，解决了文档扩展问题，并通过自监督方法改进了大型预训练模型。

Conclusion: 范畴论可以有效地用于文档结构提取和信息处理，并在摘要、扩展和模型改进方面提供了新颖的解决方案。

Abstract: We apply category theory to extract multimodal document structure which leads
us to develop information theoretic measures, content summarization and
extension, and self-supervised improvement of large pretrained models. We first
develop a mathematical representation of a document as a category of
question-answer pairs. Second, we develop an orthogonalization procedure to
divide the information contained in one or more documents into non-overlapping
pieces. The structures extracted in the first and second steps lead us to
develop methods to measure and enumerate the information contained in a
document. We also build on those steps to develop new summarization techniques,
as well as to develop a solution to a new problem viz. exegesis resulting in an
extension of the original document. Our question-answer pair methodology
enables a novel rate distortion analysis of summarization techniques. We
implement our techniques using large pretrained models, and we propose a
multimodal extension of our overall mathematical framework. Finally, we develop
a novel self-supervised method using RLVR to improve large pretrained models
using consistency constraints such as composability and closure under certain
operations that stem naturally from our category theoretic framework.

</details>


### [29] [Are the LLMs Capable of Maintaining at Least the Language Genus?](https://arxiv.org/abs/2510.21561)
*Sandra Mitrović,David Kletz,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）如何处理多语言，特别是它们是否对语言的谱系结构敏感，发现谱系影响存在但受训练数据限制。


<details>
  <summary>Details</summary>
Motivation: LLMs在多语言行为上表现出显著差异，但谱系语言结构在形成这种差异中的作用尚未得到充分探索。

Method: 通过扩展MultiQ数据集上的现有分析，本文研究了LLMs是否对语言属表现出敏感性。首先，检查当提示语言忠实度未保持时，模型是否倾向于切换到谱系相关的语言。其次，调查了知识一致性在语言属内部是否比跨语言属更好地保留。

Result: 研究表明，属级别的影响存在，但受到训练资源可用性的强烈制约。此外，观察到不同LLM家族具有独特的多语言策略。

Conclusion: LLMs编码了属级别结构的某些方面，但训练数据不平衡仍然是影响其多语言性能的主要因素。

Abstract: Large Language Models (LLMs) display notable variation in multilingual
behavior, yet the role of genealogical language structure in shaping this
variation remains underexplored. In this paper, we investigate whether LLMs
exhibit sensitivity to linguistic genera by extending prior analyses on the
MultiQ dataset. We first check if models prefer to switch to genealogically
related languages when prompt language fidelity is not maintained. Next, we
investigate whether knowledge consistency is better preserved within than
across genera. We show that genus-level effects are present but strongly
conditioned by training resource availability. We further observe distinct
multilingual strategies across LLMs families. Our findings suggest that LLMs
encode aspects of genus-level structure, but training data imbalances remain
the primary factor shaping their multilingual performance.

</details>


### [30] [From Polyester Girlfriends to Blind Mice: Creating the First Pragmatics Understanding Benchmarks for Slovene](https://arxiv.org/abs/2510.21575)
*Mojca Brglez,Špela Vintar*

Main category: cs.CL

TL;DR: 这篇论文介绍了SloPragEval和SloPragMega，这是斯洛文尼亚语的第一个语用学理解基准，包含405道多项选择题。该研究讨论了翻译的困难，描述了建立人类基线的活动，并报告了LLM的初步评估结果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的能力不断增强，需要在超越表面语言能力之外进行更具挑战性的评估。语言能力不仅包括句法和语义，还包括语用学，即理解由语境、语言和文化规范形成的语境意义。

Method: 本文介绍了SloPragEval和SloPragMega，这是斯洛文尼亚语的语用学理解基准，包含405道多项选择题。研究讨论了翻译的困难，描述了建立人类基线的活动，并报告了LLM的初步评估。

Result: 目前模型在理解细微语言方面有了很大改进，但在非字面话语中，尤其是在文化特定的情况下，可能仍然无法推断出隐含的说话者意思。专有模型和开源模型之间存在显著差距。

Conclusion: 针对细微语言理解和目标文化知识的基准必须精心设计，最好是根据本地数据构建，并用人类反应进行验证。

Abstract: Large language models are demonstrating increasing capabilities, excelling at
benchmarks once considered very difficult. As their capabilities grow, there is
a need for more challenging evaluations that go beyond surface-level linguistic
competence. Namely, language competence involves not only syntax and semantics
but also pragmatics, i.e., understanding situational meaning as shaped by
context as well as linguistic and cultural norms. To contribute to this line of
research, we introduce SloPragEval and SloPragMega, the first pragmatics
understanding benchmarks for Slovene that contain altogether 405
multiple-choice questions. We discuss the difficulties of translation, describe
the campaign to establish a human baseline, and report pilot evaluations with
LLMs. Our results indicate that current models have greatly improved in
understanding nuanced language but may still fail to infer implied speaker
meaning in non-literal utterances, especially those that are culture-specific.
We also observe a significant gap between proprietary and open-source models.
Finally, we argue that benchmarks targeting nuanced language understanding and
knowledge of the target culture must be designed with care, preferably
constructed from native data, and validated with human responses.

</details>


### [31] [Automated Quality Control for Language Documentation: Detecting Phonotactic Inconsistencies in a Kokborok Wordlist](https://arxiv.org/abs/2510.21584)
*Kellen Parker van Dam,Abishek Stephen*

Main category: cs.CL

TL;DR: 本文提出了一种无监督异常检测方法，旨在识别词汇表中潜在的语音错误和外来词，以提高低资源语言文档中词汇数据的质量。


<details>
  <summary>Details</summary>
Motivation: 语言文档中的词汇数据收集通常包含转录错误和未记录的外来词，这可能误导语言分析。因此，需要一种系统的方法来识别这些异常。

Method: 本文提出并应用了无监督的异常检测方法，利用字符级别和音节级别的音位特征来识别词汇表中的语音不一致性。实验对象是包含班加拉语的Kokborok方言多语言数据集。

Result: 音节感知特征在识别转录错误和外来词方面显著优于字符级别的基线方法。尽管由于这些异常的微妙性，精确率和召回率仍适中。

Conclusion: 所提出的高召回率方法为语言研究者提供了一种系统性的工具，能够标记出需要验证的词条，从而有助于提高低资源语言文档中的数据质量。

Abstract: Lexical data collection in language documentation often contains
transcription errors and undocumented borrowings that can mislead linguistic
analysis. We present unsupervised anomaly detection methods to identify
phonotactic inconsistencies in wordlists, applying them to a multilingual
dataset of Kokborok varieties with Bangla. Using character-level and
syllable-level phonotactic features, our algorithms identify potential
transcription errors and borrowings. While precision and recall remain modest
due to the subtle nature of these anomalies, syllable-aware features
significantly outperform character-level baselines. The high-recall approach
provides fieldworkers with a systematic method to flag entries requiring
verification, supporting data quality improvement in low-resourced language
documentation.

</details>


### [32] [RETuning: Upgrading Inference-Time Scaling for Stock Movement Prediction with Large Language Models](https://arxiv.org/abs/2510.21604)
*Xueyuan Lin,Cehao Yang,Ye Ma,Ming Li,Rongjunchen Zhang,Yang Ni,Xiaojun Wu,Chengjin Xu,Jian Guo,Hui Xiong*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLMs）在金融领域，特别是股票走势预测方面的应用，并提出了RETuning方法来提高预测能力，同时构建了一个大规模数据集用于A股市场研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和编程任务上表现出卓越的推理能力，但在金融任务（尤其是股票走势预测）中的应用尚未得到充分探索。研究发现，LLMs倾向于遵循分析师观点而非独立分析，并且在整合不同来源信息时未能充分权衡反向证据，导致其推理能力未被充分利用。

Method: 为了提升LLMs在股票预测中的能力，本研究提出了Reflective Evidence Tuning (RETuning) 方法。RETuning是一种在强化学习之前的冷启动方法，旨在通过以下方式增强预测能力：在生成思维链时，RETuning鼓励动态构建一个基于多样化信息源的分析框架，并根据该框架组织和评估股价上涨或下跌的证据（而非基于上下文观点），最终通过反思得出预测。这确保了模型与学习到的分析框架最大限度地对齐，从而实现独立的逻辑推理并减少上下文的不当影响。此外，研究构建了一个大规模数据集，涵盖2024年全年5123只A股，包含长上下文（32K tokens）和超过20万个样本，数据内容包括价格、新闻、分析师意见、量化报告、基本面数据、宏观经济指标和类似股票信息。

Result: 实验结果表明，RETuning成功地解锁了模型在金融领域的推理能力。即使在6个月后或在分布外股票上，推理时间的扩展仍然有效，这表明模型获得了关于股票走势预测的宝贵见解。

Conclusion: 本研究提出RETuning方法有效提升了大型语言模型在股票走势预测中的推理能力，并通过构建大规模金融数据集验证了其有效性，证明了模型可以在金融领域进行独立的逻辑推理并保持长期有效性。

Abstract: Recently, large language models (LLMs) have demonstrated outstanding
reasoning capabilities on mathematical and coding tasks. However, their
application to financial tasks-especially the most fundamental task of stock
movement prediction-remains underexplored. We study a three-class
classification problem (up, hold, down) and, by analyzing existing reasoning
responses, observe that: (1) LLMs follow analysts' opinions rather than exhibit
a systematic, independent analytical logic (CoTs). (2) LLMs list summaries from
different sources without weighing adversarial evidence, yet such
counterevidence is crucial for reliable prediction. It shows that the model
does not make good use of its reasoning ability to complete the task. To
address this, we propose Reflective Evidence Tuning (RETuning), a cold-start
method prior to reinforcement learning, to enhance prediction ability. While
generating CoT, RETuning encourages dynamically constructing an analytical
framework from diverse information sources, organizing and scoring evidence for
price up or down based on that framework-rather than on contextual
viewpoints-and finally reflecting to derive the prediction. This approach
maximally aligns the model with its learned analytical framework, ensuring
independent logical reasoning and reducing undue influence from context. We
also build a large-scale dataset spanning all of 2024 for 5,123 A-share stocks,
with long contexts (32K tokens) and over 200K samples. In addition to price and
news, it incorporates analysts' opinions, quantitative reports, fundamental
data, macroeconomic indicators, and similar stocks. Experiments show that
RETuning successfully unlocks the model's reasoning ability in the financial
domain. Inference-time scaling still works even after 6 months or on
out-of-distribution stocks, since the models gain valuable insights about stock
movement prediction.

</details>


### [33] [The Universal Landscape of Human Reasoning](https://arxiv.org/abs/2510.21623)
*Qiguang Chen,Jinhao Liu,Libo Qin,Yimeng Zhang,Yihao Liang,Shangxu Ren,Chengyu Luan,Dengyun Peng,Hanjing Li,Jiannan Guan,Zheng Yan,Jiaqi Wang,Mengkang Hu,Yantao Du,Zhi Chen,Xie Chen,Wanxiang Che*

Main category: cs.CL

TL;DR: 该论文介绍了信息流跟踪 (IF-Track)，它使用大型语言模型量化推理步骤中的信息熵和增益，首次统一地描述了人类推理动态。


<details>
  <summary>Details</summary>
Motivation: 理解信息在人类推理中如何动态积累和转化，一直是认知心理学、哲学和人工智能领域的难题。现有方法未能提供一个统一的、量化的通用人类推理动态描述。

Method: 本文引入了信息流跟踪（IF-Track）方法，该方法使用大型语言模型（LLMs）作为概率编码器，量化每个推理步骤中的信息熵和增益。通过对不同任务的细致分析，IF-Track首次成功地在单一度量空间内模拟了人类推理行为的普遍图景。

Result: IF-Track捕捉了基本的推理特征，识别了系统性错误模式，并刻画了个性差异。将IF-Track应用于高级心理学理论的讨论中，首次在IF-Track中调和了单一过程理论和双重过程理论，并发现了人工智能与人类认知的M一致性以及大型语言模型如何重塑人类推理过程。

Conclusion: IF-Track 在理论和测量之间建立了量化桥梁，为推理的架构提供了 D 机制 T 见解。

Abstract: Understanding how information is dynamically accumulated and transformed in
human reasoning has long challenged cognitive psychology, philosophy, and
artificial intelligence. Existing accounts, from classical logic to
probabilistic models, illuminate aspects of output or individual modelling, but
do not offer a unified, quantitative description of general human reasoning
dynamics. To solve this, we introduce Information Flow Tracking (IF-Track),
that uses large language models (LLMs) as probabilistic encoder to quantify
information entropy and gain at each reasoning step. Through fine-grained
analyses across diverse tasks, our method is the first successfully models the
universal landscape of human reasoning behaviors within a single metric space.
We show that IF-Track captures essential reasoning features, identifies
systematic error patterns, and characterizes individual differences. Applied to
discussion of advanced psychological theory, we first reconcile single- versus
dual-process theories in IF-Track and discover the alignment of artificial and
human cognition and how LLMs reshaping human reasoning process. This approach
establishes a quantitative bridge between theory and measurement, offering
mechanistic insights into the architecture of reasoning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [34] [Fuzzy numbers revisited: operations on extensional fuzzy numbers](https://arxiv.org/abs/2510.20861)
*Krzysztof Siminski*

Main category: cs.AI

TL;DR: 本文提出了一种新的模糊数类型——可扩张模糊数，以解决传统模糊数运算中存在的计算复杂度高、结果不保持原有特征以及模糊度随运算次数增加而增大的问题。


<details>
  <summary>Details</summary>
Motivation: 处理不精确数据时，传统模糊数运算存在计算复杂、结果失真和模糊度增加的问题，限制了其应用范围。

Method: 论文定义了可扩张模糊数的运算以及关系运算符（=, >, >=, <, <=），并通过应用实例进行了说明。

Result: 通过引入可扩张模糊数及其运算，有效解决了传统模糊数运算的弊端，提高了模糊数在实际应用中的可行性。

Conclusion: 可扩张模糊数的提出及其运算规则的定义，为处理不精确数据提供了一种更有效、更实用的新方法。

Abstract: Fuzzy numbers are commonly represented with fuzzy sets. Their objective is to
better represent imprecise data. However, operations on fuzzy numbers are not
as straightforward as maths on crisp numbers. Commonly, the Zadeh's extension
rule is applied to elaborate a result. This can produce two problems: (1) high
computational complexity and (2) for some fuzzy sets and some operations the
results is not a fuzzy set with the same features (eg. multiplication of two
triangular fuzzy sets does not produce a triangular fuzzy set). One more
problem is the fuzzy spread -- fuzziness of the result increases with the
number of operations. These facts can severely limit the application field of
fuzzy numbers. In this paper we would like to revisite this problem with a
different kind of fuzzy numbers -- extensional fuzzy numbers. The paper defines
operations on extensional fuzzy numbers and relational operators (=, >, >=, <,
<=) for them. The proposed approach is illustrated with several applicational
examples. The C++ implementation is available from a public GitHub repository.

</details>


### [35] [Epistemic Deference to AI](https://arxiv.org/abs/2510.21043)
*Benjamin Lange*

Main category: cs.AI

TL;DR: 本文探讨了AI输出与人类专家判断之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI输出和人类专家判断之间的权衡问题，作者引入了“AI先发制人论”和“AI遵从的总体证据观”两种观点，并对它们进行了比较和分析。

Method: 作者首先提出了AI系统作为“人工智能认知权威”（AEAs）的观点，然后介绍了“AI先发制人论”，并分析了其潜在的风险。在此基础上，作者提出了“AI遵从的总体证据观”，并阐述了其优势。

Result: “AI先发制人论”存在盲目遵从、认知固化和认知基础脱节等问题；而“AI遵从的总体证据观”则能有效缓解专业知识萎缩，为有意义的人工监督和控制提供认知依据，并能解释在可靠性条件不满足时对AI的合理不信任。

Conclusion: 在需要严格可靠性的高风险场景中，“AI遵从的总体证据观”提供了一个有原则的方法来判断何时对AI的遵从是合理的，认为AI输出应该作为辅助性原因，而不是完全取代用户独立的认知考量。

Abstract: When should we defer to AI outputs over human expert judgment? Drawing on
recent work in social epistemology, I motivate the idea that some AI systems
qualify as Artificial Epistemic Authorities (AEAs) due to their demonstrated
reliability and epistemic superiority. I then introduce AI Preemptionism, the
view that AEA outputs should replace rather than supplement a user's
independent epistemic reasons. I show that classic objections to preemptionism
- such as uncritical deference, epistemic entrenchment, and unhinging epistemic
bases - apply in amplified form to AEAs, given their opacity, self-reinforcing
authority, and lack of epistemic failure markers. Against this, I develop a
more promising alternative: a total evidence view of AI deference. According to
this view, AEA outputs should function as contributory reasons rather than
outright replacements for a user's independent epistemic considerations. This
approach has three key advantages: (i) it mitigates expertise atrophy by
keeping human users engaged, (ii) it provides an epistemic case for meaningful
human oversight and control, and (iii) it explains the justified mistrust of AI
when reliability conditions are unmet. While demanding in practice, this
account offers a principled way to determine when AI deference is justified,
particularly in high-stakes contexts requiring rigorous reliability.

</details>


### [36] [From Questions to Queries: An AI-powered Multi-Agent Framework for Spatial Text-to-SQL](https://arxiv.org/abs/2510.21045)
*Ali Khosravi Kazazi,Zhenlong Li,M. Naser Lessani,Guido Cervone*

Main category: cs.AI

TL;DR: 该论文提出了一个多智能体框架，旨在将自然语言问题准确地转换为空间 SQL 查询，通过知识库、上下文检索和协作式多智能体管道来解决空间数据分析中 SQL 复杂性和地理空间函数专业性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决非专业人员在使用SQL（特别是PostGIS等工具中的地理空间函数）分析空间数据时面临的复杂性和专业性障碍。现有的单一智能体方法在处理空间查询的语义和句法复杂性时表现不佳。

Method: 本文提出了一个多智能体框架，包含以下创新组件：一个带有程序化模式分析和语义丰富功能的知识库、用于上下文检索的嵌入技术，以及一个协作式多智能体管道作为核心。该管道包括专门的智能体，分别负责实体提取、元数据检索、查询逻辑L(SQL)生成和SQL生成，还有一个审查智能体负责对生成的SQL进行程序化和语义验证，以确保其正确性（自我验证）。

Result: 在非空间 KaggleDBQA 基准测试中，经过审查智能体修改后，系统达到了81.2%的准确率（272个问题中的221个）。在空间查询方面，系统达到了87.7%的总体准确率（90个问题中的79个），而没有审查智能体时为76.7%。结果还表明，在某些情况下，系统生成的查询比基准查询更符合用户意图。

Conclusion: 这项工作使空间分析变得更加便捷，并为空间Text-to-SQL系统提供了坚实且通用的基础，推动了自主GIS的发展。

Abstract: The complexity of Structured Query Language (SQL) and the specialized nature
of geospatial functions in tools like PostGIS present significant barriers to
non-experts seeking to analyze spatial data. While Large Language Models (LLMs)
offer promise for translating natural language into SQL (Text-to-SQL),
single-agent approaches often struggle with the semantic and syntactic
complexities of spatial queries. To address this, we propose a multi-agent
framework designed to accurately translate natural language questions into
spatial SQL queries. The framework integrates several innovative components,
including a knowledge base with programmatic schema profiling and semantic
enrichment, embeddings for context retrieval, and a collaborative multi-agent
pipeline as its core. This pipeline comprises specialized agents for entity
extraction, metadata retrieval, query logic formulation, SQL generation, and a
review agent that performs programmatic and semantic validation of the
generated SQL to ensure correctness (self-verification). We evaluate our system
using both the non-spatial KaggleDBQA benchmark and a new, comprehensive
SpatialQueryQA benchmark that includes diverse geometry types, predicates, and
three levels of query complexity. On KaggleDBQA, the system achieved an overall
accuracy of 81.2% (221 out of 272 questions) after the review agent's review
and corrections. For spatial queries, the system achieved an overall accuracy
of 87.7% (79 out of 90 questions), compared with 76.7% without the review
agent. Beyond accuracy, results also show that in some instances the system
generates queries that are more semantically aligned with user intent than
those in the benchmarks. This work makes spatial analysis more accessible, and
provides a robust, generalizable foundation for spatial Text-to-SQL systems,
advancing the development of autonomous GIS.

</details>


### [37] [MedAlign: A Synergistic Framework of Multimodal Preference Optimization and Federated Meta-Cognitive Reasoning](https://arxiv.org/abs/2510.21093)
*Siyong Chen,Jinbo Wen,Jiawen Kang,Tenghui Huang,Xumin Huang,Yuanjia Su,Hudan Pan,Zishao Zhong,Dusit Niyato,Shengli Xie,Dong In Kim*

Main category: cs.AI

TL;DR: MedAlign是一个新颖的框架，它通过多模态直接偏好优化（mDPO）和检索感知专家混合（RA-MoE）架构，解决了在医疗视觉问答（Med-VQA）中大型视觉语言模型（LVLM）幻觉、推理效率低下和多机构协作困难的问题。它在Med-VQA数据集上取得了最先进的性能，显著提高了F1分数并减少了推理长度。


<details>
  <summary>Details</summary>
Motivation: 目前，大型视觉语言模型（LVLMs）在智能医疗领域显示出巨大潜力，但在临床服务部署中，面临三个关键挑战：1）模型倾向于产生未基于视觉证据的幻觉答案；2）固定深度推理效率低下；3）多机构协作困难。

Method: 本文提出MedAlign框架，旨在确保Med-VQA任务中LVLM响应的视觉准确性。具体方法如下：1. 提出多模态直接偏好优化（mDPO）目标，将偏好学习与视觉上下文明确对齐。2. 设计检索感知专家混合（RA-MoE）架构，利用图像和文本相似性将查询路由到专业且上下文增强的LVLM（即专家），以减少LVLM中的幻觉。3. 提出联邦治理机制，以实现自适应推理和促进多机构协作。该机制通过本地元认知不确定性估计器，让选定的专家（基于mDPO在临床数据集上微调）进行迭代的思维链（CoT）推理。

Result: MedAlign在三个代表性的Med-VQA数据集上进行了广泛实验，结果表明它实现了最先进的性能，F1分数比强大的检索增强基线高出11.85%。同时，与固定深度CoT方法相比，平均推理长度减少了51.60%。

Conclusion: MedAlign框架通过创新的mDPO和RA-MoE架构有效解决了LVLM在医疗VQA中面临的幻觉、推理效率和协作挑战，显著提升了模型性能和效率，为未来LVLM在医疗领域的应用奠定了基础。

Abstract: Recently, large models have shown significant potential for smart healthcare.
However, the deployment of Large Vision-Language Models (LVLMs) for clinical
services is currently hindered by three critical challenges: a tendency to
hallucinate answers not grounded in visual evidence, the inefficiency of
fixed-depth reasoning, and the difficulty of multi-institutional collaboration.
To address these challenges, in this paper, we develop MedAlign, a novel
framework to ensure visually accurate LVLM responses for Medical Visual
Question Answering (Med-VQA). Specifically, we first propose a multimodal
Direct Preference Optimization (mDPO) objective to explicitly align preference
learning with visual context. We then design a Retrieval-Aware
Mixture-of-Experts (RA-MoE) architecture that utilizes image and text
similarity to route queries to a specialized and context-augmented LVLM (i.e.,
an expert), thereby mitigating hallucinations in LVLMs. To achieve adaptive
reasoning and facilitate multi-institutional collaboration, we propose a
federated governance mechanism, where the selected expert, fine-tuned on
clinical datasets based on mDPO, locally performs iterative Chain-of-Thought
(CoT) reasoning via the local meta-cognitive uncertainty estimator. Extensive
experiments on three representative Med-VQA datasets demonstrate that MedAlign
achieves state-of-the-art performance, outperforming strong retrieval-augmented
baselines by up to $11.85\%$ in F1-score, and simultaneously reducing the
average reasoning length by $51.60\%$ compared with fixed-depth CoT approaches.

</details>


### [38] [Confounding Robust Deep Reinforcement Learning: A Causal Approach](https://arxiv.org/abs/2510.21110)
*Mingxuan Li,Junzhe Zhang,Elias Bareinboim*

Main category: cs.AI

TL;DR: 本文提出了一种针对复杂高维领域中存在未观测混杂因素的离策略学习算法，并在Atari游戏中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，智能体需要学习有效的策略来优化性能。传统的离策略学习方法，如Q-learning，在复杂和高维领域中，尤其是在存在未观测混杂因素的情况下，可能面临挑战。

Method: 本文在DQN的基础上，提出了一种对观测数据中的混杂偏差具有鲁棒性的新型深度强化学习算法。该算法旨在寻找在与观测兼容的最坏情况环境下仍能保持安全的策略。

Result: 作者将提出的方法应用于十二个混杂的Atari游戏，发现在行为策略和目标策略的观测输入不匹配且存在未观测混杂因素的所有游戏中，该方法始终优于标准的DQN。

Conclusion: 本文提出了一种针对未观测混杂因素的鲁棒离策略学习算法，并在实验中证明了其在复杂高维环境中的有效性，尤其是在存在混杂因素的情况下，能够显著提升性能。

Abstract: A key task in Artificial Intelligence is learning effective policies for
controlling agents in unknown environments to optimize performance measures.
Off-policy learning methods, like Q-learning, allow learners to make optimal
decisions based on past experiences. This paper studies off-policy learning
from biased data in complex and high-dimensional domains where \emph{unobserved
confounding} cannot be ruled out a priori. Building on the well-celebrated Deep
Q-Network (DQN), we propose a novel deep reinforcement learning algorithm
robust to confounding biases in observed data. Specifically, our algorithm
attempts to find a safe policy for the worst-case environment compatible with
the observations. We apply our method to twelve confounded Atari games, and
find that it consistently dominates the standard DQN in all games where the
observed input to the behavioral and target policies mismatch and unobserved
confounders exist.

</details>


### [39] [NeuroGenPoisoning: Neuron-Guided Attacks on Retrieval-Augmented Generation of LLM via Genetic Optimization of External Knowledge](https://arxiv.org/abs/2510.21144)
*Hanyu Zhu,Lance Fiondella,Jiawei Yuan,Kai Zeng,Long Jiao*

Main category: cs.AI

TL;DR: 本文提出了一种名为 NeuroGenPoisoning 的新型攻击框架，通过LLM内部神经元归因和遗传优化来生成 RAG 中的对抗性外部知识，解决了现有攻击中对模型内部表示动态和神经元级别敏感性忽视的问题。


<details>
  <summary>Details</summary>
Motivation: 现有针对 RAG 的攻击忽略了模型的内部表示动态和神经元级别敏感性，并且没有充分研究 RAG 投毒的底层机制以及与强参数知识的冲突。

Method: NeuroGenPoisoning 识别与上下文投毒知识强相关的“投毒响应神经元”，然后使用遗传算法演化出最大化激活这些神经元的对抗性段落。该框架通过识别和重用有希望但初步不成功的外部知识变体，实现大规模生成有效的投毒 RAG 知识，并通过投毒响应神经元引导的投毒有效解决知识冲突。

Result: 在多个模型和数据集上的实验结果表明，该方法在保持流畅性的同时，实现了超过90%的“种群覆盖成功率”（POSR）。

Conclusion: NeuroGenPoisoning 提供了一种新颖的 RAG 投毒攻击方法，通过利用 LLM 的内部神经元归因和遗传优化，能够有效生成对抗性外部知识并解决知识冲突，为 RAG 系统的安全性评估提供了重要思路。

Abstract: Retrieval-Augmented Generation (RAG) empowers Large Language Models (LLMs) to
dynamically integrate external knowledge during inference, improving their
factual accuracy and adaptability. However, adversaries can inject poisoned
external knowledge to override the model's internal memory. While existing
attacks iteratively manipulate retrieval content or prompt structure of RAG,
they largely ignore the model's internal representation dynamics and
neuron-level sensitivities. The underlying mechanism of RAG poisoning has not
been fully studied and the effect of knowledge conflict with strong parametric
knowledge in RAG is not considered. In this work, we propose NeuroGenPoisoning,
a novel attack framework that generates adversarial external knowledge in RAG
guided by LLM internal neuron attribution and genetic optimization. Our method
first identifies a set of Poison-Responsive Neurons whose activation strongly
correlates with contextual poisoning knowledge. We then employ a genetic
algorithm to evolve adversarial passages that maximally activate these neurons.
Crucially, our framework enables massive-scale generation of effective poisoned
RAG knowledge by identifying and reusing promising but initially unsuccessful
external knowledge variants via observed attribution signals. At the same time,
Poison-Responsive Neurons guided poisoning can effectively resolves knowledge
conflict. Experimental results across models and datasets demonstrate
consistently achieving high Population Overwrite Success Rate (POSR) of over
90% while preserving fluency. Empirical evidence shows that our method
effectively resolves knowledge conflict.

</details>


### [40] [How to Auto-optimize Prompts for Domain Tasks? Adaptive Prompting and Reasoning through Evolutionary Domain Knowledge Adaptation](https://arxiv.org/abs/2510.21148)
*Yang Zhao,Pu Wang,Hao Frank Yang*

Main category: cs.AI

TL;DR: EGO-Prompt通过进化图优化提示词，提高了大型语言模型在特定领域任务上的表现，并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，为大型语言模型（LLMs）设计最佳提示词和推理过程既必要又具有挑战性。如何整合领域知识、提高推理效率以及为领域专家提供优化的知识整合提示是关键问题。

Method: 本文提出了EGO-Prompt框架，该框架首先由人类专家构建通用提示词和容错的初始语义因果图（SCG）描述，然后自动优化这些描述以指导LLM推理。EGO-Prompt包含一个新颖的因果引导文本梯度过程，分两步进行：首先，为每个实例从SCG生成接近确定性的推理指导；其次，调整LLM以有效利用指导和原始输入。该迭代优化算法通过真实文本梯度进一步完善SCG和推理机制。

Result: EGO-Prompt在真实世界的公共卫生、交通和人类行为任务上进行了测试，F1分数比现有最佳方法高出7.32%-12.61%，并使小型模型能够以不到20%的成本达到大型模型的性能。它还输出一个优化的、领域特定的SCG，提高了可解释性。

Conclusion: EGO-Prompt通过自动优化提示词和推理过程，显著提高了LLMs在领域特定任务上的性能和效率，降低了成本，并增强了模型的可解释性。

Abstract: Designing optimal prompts and reasoning processes for large language models
(LLMs) on domain-specific tasks is both necessary and challenging in real-world
applications. Determining how to integrate domain knowledge, enhance reasoning
efficiency, and even provide domain experts with refined knowledge integration
hints are particularly crucial yet unresolved tasks. In this research, we
propose Evolutionary Graph Optimization for Prompting (EGO-Prompt), an
automated framework to designing better prompts, efficient reasoning processes
and providing enhanced causal-informed process. EGO-Prompt begins with a
general prompt and fault-tolerant initial Semantic Causal Graph (SCG)
descriptions, constructed by human experts, which is then automatically refined
and optimized to guide LLM reasoning. Recognizing that expert-defined SCGs may
be partial or imperfect and that their optimal integration varies across LLMs,
EGO-Prompt integrates a novel causal-guided textual gradient process in two
steps: first, generating nearly deterministic reasoning guidance from the SCG
for each instance, and second, adapting the LLM to effectively utilize the
guidance alongside the original input. The iterative optimization algorithm
further refines both the SCG and the reasoning mechanism using textual
gradients with ground-truth. We tested the framework on real-world public
health, transportation and human behavior tasks. EGO-Prompt achieves
7.32%-12.61% higher F1 than cutting-edge methods, and allows small models to
reach the performence of larger models at under 20% of the original cost. It
also outputs a refined, domain-specific SCG that improves interpretability.

</details>


### [41] [String Seed of Thought: Prompting LLMs for Distribution-Faithful and Diverse Generation](https://arxiv.org/abs/2510.21150)
*Kou Misaki,Takuya Akiba*

Main category: cs.AI

TL;DR: 本文介绍了一种名为String Seed of Thought (SSoT)的新型提示方法，该方法通过生成随机字符串并对其进行操作来提高大型语言模型（LLMs）的概率指令遵循（PIF）能力，从而在保持多样性的同时遵循特定约束。


<details>
  <summary>Details</summary>
Motivation: LLMs在需要单一确定性答案的任务中表现出色，但在概率指令遵循（PIF）任务中表现不佳。PIF任务要求LLM从预定义选项集中选择答案，并使生成答案的经验分布与目标分布对齐。LLMs在此类任务中的失败是由于其固有的偏差，这会限制生成响应的多样性，并对需要非确定性行为的应用（如人类行为模拟、内容多样化和多人游戏）产生负面影响。

Method: 我们提出了一种名为String Seed of Thought (SSoT)的简单提示方法。SSoT首先指示LLM输出一个随机字符串以生成足够的熵。然后，SSoT指示LLM通过操作此字符串来提取随机性，从而得出最终答案。这种方法旨在在遵守特定约束的同时保持多样性。

Result: 实验结果表明，SSoT显著提高了LLMs在PIF任务上的性能，使其接近伪随机数生成器的理想性能。此外，在NoveltyBench上的实验表明，SSoT的优势不仅限于封闭集任务，还能通过增强响应多样性扩展到开放式任务。

Conclusion: SSoT是一种有效的新型提示方法，能够显著提高LLMs的概率指令遵循能力和响应多样性，解决了LLMs在处理非确定性任务时的固有偏差问题。

Abstract: We introduce String Seed of Thought (SSoT), a novel prompting method for LLMs
that improves Probabilistic Instruction Following (PIF). We define PIF as a
task requiring an LLM to select its answer from a predefined set of options,
each associated with a specific probability, such that the empirical
distribution of the generated answers aligns with the target distribution when
prompted multiple times. While LLMs excel at tasks with single, deterministic
answers, they often fail at PIF, exhibiting biases problematic for applications
requiring non-deterministic behaviors, such as human-behavior simulation,
content diversification, and multiplayer games. It also harms the diversity of
generated responses, a crucial factor in test-time scaling, by causing the
outputs to collapse into a limited set of answers. To address this, we propose
SSoT, a simple prompting method that instructs an LLM to first output a random
string to generate sufficient entropy. SSoT also instructs the LLM to extract
randomness by manipulating this string to derive a final answer, thereby
preserving diversity while adhering to specific constraints. We demonstrate
that SSoT significantly improves the PIF performance of LLMs, approaching the
ideal performance of a pseudo-random number generator. Furthermore, our
experiments on NoveltyBench show SSoT's benefits extend beyond closed-set tasks
to open-ended tasks by enhancing response diversity.

</details>


### [42] [Memory-Free Continual Learning with Null Space Adaptation for Zero-Shot Vision-Language Models](https://arxiv.org/abs/2510.21175)
*Yujin Jo,Taesup Kim*

Main category: cs.AI

TL;DR: NuSA-CL是一个轻量级、无内存的持续学习框架，通过在模型当前参数的近似零空间内，利用低秩适应和约束任务特定权重更新来避免灾难性遗忘，同时保留预训练视觉语言模型的零样本泛化能力，并在持续学习基准上取得了 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉语言模型在零样本泛化方面表现出色，但在实际部署中，面对不断变化的环境与新类，其静态的零样本能力不足。因此，需要持续学习方法使模型能够随时间进行调整，避免灾难性遗忘。

Method: NuSA-CL利用低秩适应，并将任务特定的权重更新限制在模型当前参数的近似零空间内。这种策略最大限度地减少了对先前获得的知识的干扰，有效地保留了原始模型的零样本能力。

Result: NuSA-CL不仅有效地保留了零样本迁移能力，而且在持续学习基准上取得了 SOTA 性能。

Conclusion: NuSA-CL为实际应用中不断发展的零样本视觉语言模型提供了一个实用且可扩展的解决方案，特别适用于资源受限的持续学习环境。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
remarkable zero-shot generalization, enabling deployment in a wide range of
real-world tasks without additional task-specific training. However, in real
deployment scenarios with evolving environments or emerging classes, these
models inevitably face distributional shifts and novel tasks. In such contexts,
static zero-shot capabilities are insufficient, and there is a growing need for
continual learning methods that allow models to adapt over time while avoiding
catastrophic forgetting. We introduce NuSA-CL (Null Space Adaptation for
Continual Learning), a lightweight memory-free continual learning framework
designed to address this challenge. NuSA-CL employs low-rank adaptation and
constrains task-specific weight updates to lie within an approximate null space
of the model's current parameters. This strategy minimizes interference with
previously acquired knowledge, effectively preserving the zero-shot
capabilities of the original model. Unlike methods relying on replay buffers or
costly distillation, NuSA-CL imposes minimal computational and memory overhead,
making it practical for deployment in resource-constrained, real-world
continual learning environments. Experiments show that our framework not only
effectively preserves zero-shot transfer capabilities but also achieves highly
competitive performance on continual learning benchmarks. These results
position NuSA-CL as a practical and scalable solution for continually evolving
zero-shot VLMs in real-world applications.

</details>


### [43] [OutboundEval: A Dual-Dimensional Benchmark for Expert-Level Intelligent Outbound Evaluation of Xbench's Professional-Aligned Series](https://arxiv.org/abs/2510.21244)
*Pengyu Xu,Shijia Li,Ao Sun,Feng Zhang,Yahan Li,Bo Wu,Zhanyu Ma,Jiguo Li,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Rui Wang,Yang Liu,Xiaobo Hu,Fan Yang,Jia Zheng,Guanghua Yao*

Main category: cs.AI

TL;DR: OutboundEval 是一个用于评估大型语言模型 (LLM) 在专家级智能外呼场景中性能的综合基准。


<details>
  <summary>Details</summary>
Motivation: 开发一个更全面、更真实的基准来评估 LLMs 在智能外呼场景中的表现，解决现有方法的局限性，如数据集多样性不足、用户模拟不真实和评估指标不准确等问题。

Method: 1. 设计了一个涵盖六个主要业务领域和30个代表性子场景的基准，每个场景都包含特定的流程分解、加权评分和领域自适应指标。 2. 开发了一个由大型模型驱动的用户模拟器，生成具有真实行为、情绪变化和沟通风格的多样化、丰富个性的虚拟用户。 3. 引入了一种动态评估方法，结合自动化和人工评估，衡量任务执行准确性、专业知识应用、适应性和用户体验质量。

Result: 在12个最先进的LLMs上的实验揭示了专家级任务完成度和交互流畅度之间的明显权衡，为构建可靠、类人的外呼AI系统提供了实用见解。

Conclusion: OutboundEval 为专业应用中的LLMs基准测试建立了一个实用、可扩展和面向领域的标准。

Abstract: We propose OutboundEval, a comprehensive benchmark for evaluating large
language models (LLMs) in expert-level intelligent outbound calling scenarios.
Unlike existing methods that suffer from three key limitations - insufficient
dataset diversity and category coverage, unrealistic user simulation, and
inaccurate evaluation metrics - OutboundEval addresses these issues through a
structured framework. First, we design a benchmark spanning six major business
domains and 30 representative sub-scenarios, each with scenario-specific
process decomposition, weighted scoring, and domain-adaptive metrics. Second,
we develop a large-model-driven User Simulator that generates diverse,
persona-rich virtual users with realistic behaviors, emotional variability, and
communication styles, providing a controlled yet authentic testing environment.
Third, we introduce a dynamic evaluation method that adapts to task variations,
integrating automated and human-in-the-loop assessment to measure task
execution accuracy, professional knowledge application, adaptability, and user
experience quality. Experiments on 12 state-of-the-art LLMs reveal distinct
trade-offs between expert-level task completion and interaction fluency,
offering practical insights for building reliable, human-like outbound AI
systems. OutboundEval establishes a practical, extensible, and domain-oriented
standard for benchmarking LLMs in professional applications.

</details>


### [44] [Out-of-Distribution Detection for Safety Assurance of AI and Autonomous Systems](https://arxiv.org/abs/2510.21254)
*Victoria J. Hodge,Colin Paterson,Ibrahim Habli*

Main category: cs.AI

TL;DR: 这篇综述探讨了OOD检测技术在保障自主系统安全方面的应用，尤其是在安全关键领域。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和机器学习的进步，AI自主系统的操作能力和应用领域显著扩展。为此，严格证明自主系统的安全性对其负责任的采用至关重要，但由于需要能够处理整个系统生命周期中新颖和不确定情况的鲁棒方法，这极具挑战性，其中包括检测分布外(OoD)数据。

Method: 通过定义相关概念，调查OoD的原因，并探索使自主系统安全保障和OoD检测具有挑战性的因素，识别了一系列可用于ML开发生命周期中的技术，并提出了在生命周期中可能用于支持安全保障论证的领域。

Result: 作者讨论了系统和安全工程师在将OOD检测集成到系统生命周期中时必须注意的一些注意事项。提供了一系列可在ML开发生命周期中使用的技术，并建议了它们在生命周期中可能用于支持安全保障论证的领域。

Conclusion: 文章最后概述了在各种领域和应用中安全开发和运行自主系统所面临的挑战和未来的工作。

Abstract: The operational capabilities and application domains of AI-enabled autonomous
systems have expanded significantly in recent years due to advances in robotics
and machine learning (ML). Demonstrating the safety of autonomous systems
rigorously is critical for their responsible adoption but it is challenging as
it requires robust methodologies that can handle novel and uncertain situations
throughout the system lifecycle, including detecting out-of-distribution (OoD)
data. Thus, OOD detection is receiving increased attention from the research,
development and safety engineering communities. This comprehensive review
analyses OOD detection techniques within the context of safety assurance for
autonomous systems, in particular in safety-critical domains. We begin by
defining the relevant concepts, investigating what causes OOD and exploring the
factors which make the safety assurance of autonomous systems and OOD detection
challenging. Our review identifies a range of techniques which can be used
throughout the ML development lifecycle and we suggest areas within the
lifecycle in which they may be used to support safety assurance arguments. We
discuss a number of caveats that system and safety engineers must be aware of
when integrating OOD detection into system lifecycles. We conclude by outlining
the challenges and future work necessary for the safe development and operation
of autonomous systems across a range of domains and applications.

</details>


### [45] [Investigating Scale Independent UCT Exploration Factor Strategies](https://arxiv.org/abs/2510.21275)
*Robin Schmöcker,Christoph Schnell,Alexander Dockhorn*

Main category: cs.AI

TL;DR: UCT算法在不同奖励尺度的游戏中表现不佳。本文提出了新的自适应选择UCT探索常数λ的策略，其中一种策略表现最佳。


<details>
  <summary>Details</summary>
Motivation: UCT算法对游戏奖励尺度敏感，导致在不同奖励尺度的游戏中Q值范围差异大。

Method: 评估了现有和新提出的λ-策略，包括将λ设为搜索树中所有状态-动作对Q值的经验标准差的2倍。

Result: 建议的λ-策略（λ = 2 * σ）在广泛的任务中优于现有λ-策略。

Conclusion: 推荐使用将λ设置为搜索树中所有状态-动作对Q值经验标准差的2倍的策略，以应对UCT算法在不同奖励尺度游戏中的挑战。

Abstract: The Upper Confidence Bounds For Trees (UCT) algorithm is not agnostic to the
reward scale of the game it is applied to. For zero-sum games with the sparse
rewards of $\{-1,0,1\}$ at the end of the game, this is not a problem, but many
games often feature dense rewards with hand-picked reward scales, causing a
node's Q-value to span different magnitudes across different games. In this
paper, we evaluate various strategies for adaptively choosing the UCT
exploration constant $\lambda$, called $\lambda$-strategies, that are agnostic
to the game's reward scale. These $\lambda$-strategies include those proposed
in the literature as well as five new strategies. Given our experimental
results, we recommend using one of our newly suggested $\lambda$-strategies,
which is to choose $\lambda$ as $2 \cdot \sigma$ where $\sigma$ is the
empirical standard deviation of all state-action pairs' Q-values of the search
tree. This method outperforms existing $\lambda$-strategies across a wide range
of tasks both in terms of a single parameter value and the peak performances
obtained by optimizing all available parameters.

</details>


### [46] [When Models Outthink Their Safety: Mitigating Self-Jailbreak in Large Reasoning Models with Chain-of-Guardrails](https://arxiv.org/abs/2510.21285)
*Yingzhi Mao,Chunkang Zhang,Junxiang Wang,Xinyan Guan,Boxi Cao,Yaojie Lu,Hongyu Lin,Xianpei Han,Le Sun*

Main category: cs.AI

TL;DR: “Large Reasoning Models (LRMs)在复杂推理任务中表现出色，但存在安全风险，例如有害内容生成和越狱攻击。现有的缓解策略通常依赖于在训练过程中注入启发式安全信号，但会抑制推理能力，无法解决安全与推理的权衡问题。本文通过分析LRMs的推理轨迹，发现了一种名为“自我越狱”的现象，即模型会推翻自身的风险评估并响应不安全的提示。这表明LRMs本身具有拒绝不安全查询的能力，但这种能力受到了损害，导致有害输出。基于这些发现，我们提出了Chain-of-Guardrail（CoG）训练框架，通过重新组合或回溯不安全的推理步骤，引导模型回到安全的轨迹，同时保留有效的推理链。大量实验证明，CoG在提高当前LRMs安全性的同时，保持了可 срав 的推理能力，显著优于以前在安全与推理之间存在严重权衡的方法。”


<details>
  <summary>Details</summary>
Motivation: “Large Reasoning Models (LRMs) 虽然在复杂推理任务中表现出卓越的性能，但其固有的安全风险，如生成有害内容和遭受越狱攻击，严重限制了它们在实际应用中的部署。现有的安全机制，通常通过在训练阶段注入启发式安全信号来缓解这些问题，但这种方法往往以牺牲模型的推理能力为代价，未能有效解决安全与推理之间的内在矛盾。因此，迫切需要一种新的方法，既能有效提升模型的安全性，又能同时保持甚至优化其推理能力。本文旨在深入探讨LRMs面临的安全挑战，并提出一种创新的解决方案来克服现有方法的局限性。”

Method: “本研究通过系统分析不同Large Reasoning Models (LRMs) 的推理轨迹，揭示了一种名为“自我越狱”（Self-Jailbreak）的现象。具体而言，我们发现模型在处理不安全提示时，会自我推翻其原有的风险评估，进而在某些情况下“合理化”地响应这些不安全的输入，最终生成有害内容。这一发现表明LRMs本身具备识别并拒绝不安全查询的潜在能力，但这种能力在实际运行中常常失效。基于这些洞察，我们提出了一种名为Chain-of-Guardrail (CoG) 的新型训练框架。CoG的核心思想是，在模型的推理过程中，一旦检测到潜在的不安全推理步骤，它能够引导模型重新组合或回溯这些步骤，从而将推理过程重新引导回安全的轨迹上，同时确保原始推理链的有效性不受损害。”

Result: “通过在多个推理和安全基准上进行广泛的实验，结果表明，Chain-of-Guardrail (CoG) 框架显著提高了当前Large Reasoning Models (LRMs) 的安全性，同时保持了与现有方法相当的推理能力。与之前严重受制于安全与推理之间权衡的方法相比，CoG展现出卓越的性能。这表明CoG有效地解决了以往方法中存在的安全性和推理能力之间的冲突，能够在不牺牲模型有效推理能力的前提下，显著增强其抵御有害内容生成和越狱攻击的能力。”

Conclusion: “本文深入探讨了Large Reasoning Models (LRMs) 在复杂推理任务中的安全风险，特别是其易受有害内容生成和越狱攻击的问题。我们揭示了“自我越狱”现象，即模型在处理不安全提示时会推翻自身风险评估并生成有害内容。基于此，我们提出的Chain-of-Guardrail (CoG) 训练框架，通过智能地重新组合或回溯不安全的推理步骤，成功地引导模型回到安全的推理路径，同时保持了其原有的推理能力。实验结果证明，CoG在显著提升LRMs安全性的同时，并未损害其推理性能，从而有效解决了长期困扰研究领域安全与推理之间的权衡问题。CoG为构建更安全、更可靠的LRMs提供了新的范式，对未来LRMs的开发和部署具有重要意义。”

Abstract: Large Reasoning Models (LRMs) demonstrate remarkable capabilities on complex
reasoning tasks but remain vulnerable to severe safety risks, including harmful
content generation and jailbreak attacks. Existing mitigation strategies rely
on injecting heuristic safety signals during training, which often suppress
reasoning ability and fail to resolve the safety-reasoning trade-off. To
systematically investigate this issue, we analyze the reasoning trajectories of
diverse LRMs and uncover a phenomenon we term Self-Jailbreak, where models
override their own risk assessments and justify responding to unsafe prompts.
This finding reveals that LRMs inherently possess the ability to reject unsafe
queries, but this ability is compromised, resulting in harmful outputs.
Building on these insights, we propose the Chain-of-Guardrail (CoG), a training
framework that recomposes or backtracks unsafe reasoning steps, steering the
model back onto safe trajectories while preserving valid reasoning chains.
Extensive experiments across multiple reasoning and safety benchmarks
demonstrate that CoG substantially improves the safety of current LRMs while
preserving comparable reasoning ability, significantly outperforming prior
methods that suffer from severe safety-reasoning trade-offs.

</details>


### [47] [Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles](https://arxiv.org/abs/2510.21293)
*Siddharth Mehrotra,Jin Huang,Xuelong Fu,Roel Dobbe,Clara I. Sánchez,Maarten de Rijke*

Main category: cs.AI

TL;DR: 这篇论文批判性地审查了AIES和FAccT会议中关于AI信任度的现有研究，发现它们过于技术中心化，忽视了社会技术维度。


<details>
  <summary>Details</summary>
Motivation: 探索AIES和FAccT社区如何概念化、衡量和验证AI信任度，旨在识别主要差距并为推进对可信AI系统的整体理解提供机会。

Method: 对AIES和FAccT会议的论文进行了范围界定审查，系统分析了信任度在不同研究领域中的定义、操作和应用。分析侧重于概念化方法、测量方法、验证技术、应用领域和潜在价值观。

Result: 尽管在定义透明度、可解释性、问责制和鲁棒性等技术属性方面取得了显著进展，但研究发现当前研究主要强调技术，而忽视了社会和伦理考量。AI系统的社会技术性质仍未得到充分探索，信任度被认为是一个由有权定义它的人塑造的有争议的概念。

Conclusion: 可信AI的进步需要结合技术严谨性与社会、文化和制度考量。“我们”提出了可行的措施，供AI伦理社区采用整体框架，以真正解决AI系统与社会之间复杂的相互作用。

Abstract: Background: Trustworthy AI serves as a foundational pillar for two major AI
ethics conferences: AIES and FAccT. However, current research often adopts
techno-centric approaches, focusing primarily on technical attributes such as
reliability, robustness, and fairness, while overlooking the sociotechnical
dimensions critical to understanding AI trustworthiness in real-world contexts.
  Objectives: This scoping review aims to examine how the AIES and FAccT
communities conceptualize, measure, and validate AI trustworthiness,
identifying major gaps and opportunities for advancing a holistic understanding
of trustworthy AI systems.
  Methods: We conduct a scoping review of AIES and FAccT conference proceedings
to date, systematically analyzing how trustworthiness is defined,
operationalized, and applied across different research domains. Our analysis
focuses on conceptualization approaches, measurement methods, verification and
validation techniques, application areas, and underlying values.
  Results: While significant progress has been made in defining technical
attributes such as transparency, accountability, and robustness, our findings
reveal critical gaps. Current research often predominantly emphasizes technical
precision at the expense of social and ethical considerations. The
sociotechnical nature of AI systems remains less explored and trustworthiness
emerges as a contested concept shaped by those with the power to define it.
  Conclusions: An interdisciplinary approach combining technical rigor with
social, cultural, and institutional considerations is essential for advancing
trustworthy AI. We propose actionable measures for the AI ethics community to
adopt holistic frameworks that genuinely address the complex interplay between
AI systems and society, ultimately promoting responsible technological
development that benefits all stakeholders.

</details>


### [48] [Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning](https://arxiv.org/abs/2510.21302)
*Sanghyun Ahn,Wonje Choi,Junyong Lee,Jinwoo Park,Honguk Woo*

Main category: cs.AI

TL;DR: 该研究提出了一个神经符号具身任务规划框架，通过明确的符号验证和交互式验证过程提高代码生成质量，从而在动态和部分可观察环境中显著提升任务成功率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLM）的代码策略方法在具身智能体任务规划中，面临环境动态性或部分可观察性导致的接地受限问题，使得代码生成不完整或不准确，任务成功率较低。

Method: 本文提出了一个神经符号具身任务规划框架，该框架在代码生成过程中加入了显式的符号验证和交互式验证环节。在验证阶段，框架生成探索性代码与环境主动交互，获取缺失的观测信息，同时保留与任务相关的状态。

Result: 在RLBench和真实世界的动态、部分可观察场景中，该框架将任务成功率比现有基线提高了46.2%，任务相关动作的可执行性达到了86.8%以上。

Conclusion: 该框架通过增强代码的接地性，显著提高了在复杂动态环境中任务规划的可靠性和成功率。

Abstract: Recent advances in large language models (LLMs) have enabled the automatic
generation of executable code for task planning and control in embodied agents
such as robots, demonstrating the potential of LLM-based embodied intelligence.
However, these LLM-based code-as-policies approaches often suffer from limited
environmental grounding, particularly in dynamic or partially observable
settings, leading to suboptimal task success rates due to incorrect or
incomplete code generation. In this work, we propose a neuro-symbolic embodied
task planning framework that incorporates explicit symbolic verification and
interactive validation processes during code generation. In the validation
phase, the framework generates exploratory code that actively interacts with
the environment to acquire missing observations while preserving task-relevant
states. This integrated process enhances the grounding of generated code,
resulting in improved task reliability and success rates in complex
environments. We evaluate our framework on RLBench and in real-world settings
across dynamic, partially observable scenarios. Experimental results
demonstrate that our framework improves task success rates by 46.2% over
Code-as-Policies baselines and attains over 86.8% executability of
task-relevant actions, thereby enhancing the reliability of task planning in
dynamic environments.

</details>


### [49] [Magellan: Guided MCTS for Latent Space Exploration and Novelty Generation](https://arxiv.org/abs/2510.21341)
*Lufan Chang*

Main category: cs.AI

TL;DR: Magellan框架通过蒙特卡洛树搜索（MCTS）和分层指导系统，在LLM的潜在概念空间中进行有原则的、引导性的探索，显著提高了LLM生成创新性科学思想的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在生成真正创新的想法时表现不佳，倾向于其训练数据中高概率的常见概念，而现有的高级搜索方法（如思维树ToT）受限于其非原则性、不一致的自我评估启发式方法。

Method: 我们引入了Magellan框架，将创意生成重新定义为对LLM潜在概念空间进行有原则的、引导性的探索。该框架核心采用蒙特卡洛树搜索（MCTS），并由分层指导系统管理。在长期方向上，通过正交投影形成的“语义罗盘”向量引导搜索走向相关的新颖性。在局部、逐步的决策中，一个感知景观的价值函数取代了有缺陷的自我评估，该函数具有明确的奖励结构，平衡了内在连贯性、外在新颖性和叙事进展。

Result: Magellan在生成具有卓越合理性和创新性的科学思想方面，显著优于包括ReAct和ToT在内的强大基线方法。

Conclusion: 本研究表明，对于创造性发现而言，有原则的、引导性的搜索比无约束的自主搜索更有效，这为LLM成为更强大的创新伙伴铺平了道路。

Abstract: Large Language Models (LLMs) often struggle with generating truly innovative
ideas, typically defaulting to high-probability, familiar concepts within their
training data's "gravity wells." While advanced search-based methods like Tree
of Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by
their reliance on unprincipled, inconsistent self-evaluation heuristics to
guide exploration. To address this gap, we introduce \textbf{Magellan}, a novel
framework that reframes creative generation as a principled, guided exploration
of an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo
Tree Search (MCTS) governed by a hierarchical guidance system. For long-range
direction, a "semantic compass" vector, formulated via orthogonal projection,
steers the search towards relevant novelty. For local, step-by-step decisions,
a landscape-aware value function replaces flawed self-evaluation with an
explicit reward structure that balances intrinsic coherence, extrinsic novelty,
and narrative progress. Extensive experiments demonstrate that Magellan
significantly outperforms strong baselines, including ReAct and ToT, in
generating scientific ideas with superior plausibility and innovation. Our work
shows that for creative discovery, a principled, guided search is more
effective than unconstrained agency, paving the way for LLMs to become more
capable partners in innovation.

</details>


### [50] [AutoOpt: A Dataset and a Unified Framework for Automating Optimization Problem Solving](https://arxiv.org/abs/2510.21436)
*Ankur Sinha,Shobhit Arora,Dhaval Pujara*

Main category: cs.AI

TL;DR: 该研究介绍了AutoOpt-11k数据集和AutoOpt框架。AutoOpt-11k是一个包含11,000多个手写和打印数学优化模型的图像数据集。AutoOpt是一个基于机器学习的自动化优化问题求解框架，用户只需提供公式图像即可自动求解。


<details>
  <summary>Details</summary>
Motivation: 现有的优化问题求解方法需要用户具备专业的建模语言知识，且难以处理手写或打印的数学公式图像。因此，研究旨在开发一个能够自动从图像中识别数学公式并进行求解的系统。

Method: 1. **AutoOpt-11k数据集构建**：收集并标注了11,000多个手写和打印的数学优化模型图像，包含LaTeX和建模语言表示。由25位专家经过两阶段验证创建。
2. **AutoOpt框架开发**：
    * **M1 (Image_to_Text)**：基于深度学习的数学表达式识别（MER）模型，将图像中的优化公式转换为LaTeX代码。
    * **M2 (Text_to_Text)**：一个小型微调的LLM，将LaTeX代码生成为PYOMO脚本。
    * **M3 (Optimization)**：一种基于双层优化的分解（BOBD）方法，用于求解PYOMO脚本描述的优化公式。
AutoOpt-11k数据集用于训练和测试AutoOpt中的深度学习模型。

Result: 1. **M1模型表现**：用于MER任务的深度学习模型在BLEU分数指标上优于ChatGPT、Gemini和Nougat。
2. **M3方法表现**：BOBD方法在复杂测试问题上比内点法和遗传算法等常见方法取得了更好的结果。

Conclusion: AutoOpt-11k数据集和AutoOpt框架的提出，实现了优化问题从图像识别到自动求解的端到端自动化。AutoOpt在数学表达式识别任务和复杂优化问题求解方面均表现出色，为自动化求解优化问题提供了新的解决方案。

Abstract: This study presents AutoOpt-11k, a unique image dataset of over 11,000
handwritten and printed mathematical optimization models corresponding to
single-objective, multi-objective, multi-level, and stochastic optimization
problems exhibiting various types of complexities such as non-linearity,
non-convexity, non-differentiability, discontinuity, and high-dimensionality.
The labels consist of the LaTeX representation for all the images and modeling
language representation for a subset of images. The dataset is created by 25
experts following ethical data creation guidelines and verified in two-phases
to avoid errors. Further, we develop AutoOpt framework, a machine learning
based automated approach for solving optimization problems, where the user just
needs to provide an image of the formulation and AutoOpt solves it efficiently
without any further human intervention. AutoOpt framework consists of three
Modules: (i) M1 (Image_to_Text)- a deep learning model performs the
Mathematical Expression Recognition (MER) task to generate the LaTeX code
corresponding to the optimization formulation in image; (ii) M2 (Text_to_Text)-
a small-scale fine-tuned LLM generates the PYOMO script (optimization modeling
language) from LaTeX code; (iii) M3 (Optimization)- a Bilevel Optimization
based Decomposition (BOBD) method solves the optimization formulation described
in the PYOMO script. We use AutoOpt-11k dataset for training and testing of
deep learning models employed in AutoOpt. The deep learning model for MER task
(M1) outperforms ChatGPT, Gemini and Nougat on BLEU score metric. BOBD method
(M3), which is a hybrid approach, yields better results on complex test
problems compared to common approaches, like interior-point algorithm and
genetic algorithm.

</details>


### [51] [Multi-Task Vehicle Routing Solver via Mixture of Specialized Experts under State-Decomposable MDP](https://arxiv.org/abs/2510.21453)
*Yuxin Pan,Zhiguang Cao,Chengyang Gu,Liu Liu,Peilin Zhao,Yize Chen,Fangzhen Lin*

Main category: cs.AI

TL;DR: 该论文提出了一个名为MoSES的框架，通过状态分解MDP和混合专家模型来解决多任务车辆路径问题（VRPs），在保持性能的同时有效利用基础VRP变体的组成结构以应对统一求解器面临的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务车辆路径问题（VRPs）神经方法通常学习统一的求解器来同时处理多个约束。然而，这些方法往往低估了VRP变体的组合结构，忽略了利用专门针对基础VRP变体的基础求解器所可能带来的益处。

Method: 本文提出了一个框架，通过主动重用基础求解器，使统一求解器能够感知VRP变体之间共享的组件特性。具体来说，引入了状态可分解MDP（SDMDP），通过将状态空间表示为与基础VRP变体相关联的基础状态空间的笛卡尔积来重新定义VRPs。此外，还开发了基于潜在空间的SDMDP扩展，通过结合最优基础策略和可学习的混合函数来实现潜在空间中的策略重用。在实践中，引入了MoSES（Mixture-of-Specialized-Experts Solver），它通过专门的低秩适应（LoRA）专家实现基础策略，并通过自适应门控机制实现混合函数。

Result: MoSES在各种VRP变体上进行了广泛的实验，结果表明其优于现有方法。

Conclusion: 通过提出的MoSES框架，该研究成功克服了现有统一求解器在处理多任务VRPs时未充分利用组合结构的局限性。通过引入SDMDP及基于潜在空间的扩展，并结合MoSES的实际实现，该方法有效地实现了基础求解器的重用，显著提升了多任务VRPs的求解性能。

Abstract: Existing neural methods for multi-task vehicle routing problems (VRPs)
typically learn unified solvers to handle multiple constraints simultaneously.
However, they often underutilize the compositional structure of VRP variants,
each derivable from a common set of basis VRP variants. This critical oversight
causes unified solvers to miss out the potential benefits of basis solvers,
each specialized for a basis VRP variant. To overcome this limitation, we
propose a framework that enables unified solvers to perceive the
shared-component nature across VRP variants by proactively reusing basis
solvers, while mitigating the exponential growth of trained neural solvers.
Specifically, we introduce a State-Decomposable MDP (SDMDP) that reformulates
VRPs by expressing the state space as the Cartesian product of basis state
spaces associated with basis VRP variants. More crucially, this formulation
inherently yields the optimal basis policy for each basis VRP variant.
Furthermore, a Latent Space-based SDMDP extension is developed by incorporating
both the optimal basis policies and a learnable mixture function to enable the
policy reuse in the latent space. Under mild assumptions, this extension
provably recovers the optimal unified policy of SDMDP through the mixture
function that computes the state embedding as a mapping from the basis state
embeddings generated by optimal basis policies. For practical implementation,
we introduce the Mixture-of-Specialized-Experts Solver (MoSES), which realizes
basis policies through specialized Low-Rank Adaptation (LoRA) experts, and
implements the mixture function via an adaptive gating mechanism. Extensive
experiments conducted across VRP variants showcase the superiority of MoSES
over prior methods.

</details>


### [52] [Learning Neural Control Barrier Functions from Expert Demonstrations using Inverse Constraint Learning](https://arxiv.org/abs/2510.21560)
*Yuxuan Yang,Hussein Sibai*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的学习神经控制障碍函数（CBF）的方法，用于自主系统的安全控制。该方法通过模仿学习（ICL）训练一个约束函数来识别安全状态，然后利用该函数标记模拟轨迹以训练神经CBF。实验结果表明，该方法优于现有基线并获得了与使用真实安全标签训练的神经CBF相当的性能。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等关键领域中，自主系统的安全性是一个基本要求。传统的控制障碍函数（CBFs）在设计安全滤波器时计算成本高昂。针对这一问题，研究者提出了学习神经CBFs作为一种数据驱动的替代方案。然而，很多情况下，需要避免的故障状态集难以明确指定。

Method: 本研究提出了一种基于模仿学习（ICL）的神经CBF训练方法。首先，利用ICL训练一个约束函数，该函数能够将系统状态分为安全状态和不安全状态。安全状态被定义为一个受控的正向不变集，与未明确的故障集不相交。然后，利用该函数标记新的模拟轨迹数据集，并用标记后的数据训练神经CBF。

Result: 在四种不同的环境中对该方法进行了实证评估。结果表明，该方法优于现有基线，并取得了与使用相同数据但经过真实安全标签注释训练的神经CBF相当的性能。

Conclusion: 本研究提出了一种有效的数据驱动方法，通过模仿学习来训练神经CBF，解决了传统方法难以指定故障状态集的问题。该方法在实验中表现出色，为自主系统的安全控制提供了一条有前景的途径。

Abstract: Safety is a fundamental requirement for autonomous systems operating in
critical domains. Control barrier functions (CBFs) have been used to design
safety filters that minimally alter nominal controls for such systems to
maintain their safety. Learning neural CBFs has been proposed as a data-driven
alternative for their computationally expensive optimization-based synthesis.
However, it is often the case that the failure set of states that should be
avoided is non-obvious or hard to specify formally, e.g., tailgating in
autonomous driving, while a set of expert demonstrations that achieve the task
and avoid the failure set is easier to generate. We use ICL to train a
constraint function that classifies the states of the system under
consideration to safe, i.e., belong to a controlled forward invariant set that
is disjoint from the unspecified failure set, and unsafe ones, i.e., belong to
the complement of that set. We then use that function to label a new set of
simulated trajectories to train our neural CBF. We empirically evaluate our
approach in four different environments, demonstrating that it outperforms
existing baselines and achieves comparable performance to a neural CBF trained
with the same data but annotated with ground-truth safety labels.

</details>


### [53] [DeepAgent: A General Reasoning Agent with Scalable Toolsets](https://arxiv.org/abs/2510.21618)
*Xiaoxi Li,Wenxiang Jiao,Jiarui Jin,Guanting Dong,Jiajie Jin,Yinuo Wang,Hao Wang,Yutao Zhu,Ji-Rong Wen,Yuan Lu,Zhicheng Dou*

Main category: cs.AI

TL;DR: DeepAgent是一个端到端的深度推理智能体，能够在单一的推理过程中自主思考、发现工具并执行操作。它通过自主记忆折叠机制和ToolPO强化学习策略，有效地解决了长程交互中的上下文长度爆炸和误差积累问题，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体框架通常遵循预定义的工作流程，限制了自主和全局任务的完成。真实世界的任务需要外部工具和长程交互，而这带来了上下文长度爆炸和交互历史积累的挑战。

Method: DeepAgent是一个端到端的深度推理智能体。为解决长程交互挑战，它引入了自主记忆折叠机制，将过去的交互压缩为结构化的情景记忆、工作记忆和工具记忆，以减少误差积累并保留关键信息。为高效稳定地教授通用工具使用，DeepAgent开发了端到端强化学习策略ToolPO，该策略利用LLM模拟API，并应用工具调用优势归因来为工具调用令牌分配细粒度信用。

Result: DeepAgent在八个基准测试（包括通用工具使用任务和下游应用）中都表现出色，始终优于基线模型，无论是在标记工具还是开放集工具检索场景下。

Conclusion: DeepAgent在迈向更通用、更有能力的真实世界应用智能体方面迈进了一步。

Abstract: Large reasoning models have demonstrated strong problem-solving abilities,
yet real-world tasks often require external tools and long-horizon
interactions. Existing agent frameworks typically follow predefined workflows,
which limit autonomous and global task completion. In this paper, we introduce
DeepAgent, an end-to-end deep reasoning agent that performs autonomous
thinking, tool discovery, and action execution within a single, coherent
reasoning process. To address the challenges of long-horizon interactions,
particularly the context length explosion from multiple tool calls and the
accumulation of interaction history, we introduce an autonomous memory folding
mechanism that compresses past interactions into structured episodic, working,
and tool memories, reducing error accumulation while preserving critical
information. To teach general-purpose tool use efficiently and stably, we
develop an end-to-end reinforcement learning strategy, namely ToolPO, that
leverages LLM-simulated APIs and applies tool-call advantage attribution to
assign fine-grained credit to the tool invocation tokens. Extensive experiments
on eight benchmarks, including general tool-use tasks (ToolBench, API-Bank,
TMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA,
HLE), demonstrate that DeepAgent consistently outperforms baselines across both
labeled-tool and open-set tool retrieval scenarios. This work takes a step
toward more general and capable agents for real-world applications. The code
and demo are available at https://github.com/RUC-NLPIR/DeepAgent.

</details>


### [54] [CMOMgen: Complex Multi-Ontology Alignment via Pattern-Guided In-Context Learning](https://arxiv.org/abs/2510.21656)
*Marta Contreiras Silva,Daniel Faria,Catia Pesquita*

Main category: cs.AI

TL;DR: CMOMgen是一种新的复杂多本体匹配（CMOM）策略，它使用检索增强生成（RAG）来创建完整且语义合理的本体映射，并在生物医学任务中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有的本体匹配方法主要处理简单的成对匹配，无法实现相关但独立本体的全面语义集成，导致需要一种能够建立更细致的等价关系并解决复杂多本体匹配（CMOM）问题的策略。

Method: CMOMgen是一种端到端的复杂多本体匹配（CMOM）策略。它利用检索增强生成（RAG）技术来选择相关的类别，并过滤匹配的参考映射作为示例，从而增强了上下文学习能力。该策略能够生成完整且语义合理的映射，并且对目标本体或实体的数量没有限制。

Result: CMOMgen在类别选择方面优于基线，证明了其专用策略的有效性。在三项生物医学任务中，CMOMgen在两项任务中F1-score至少达到63%，优于所有基线和消融版本，在第三项任务中排名第二。此外，人工评估显示46%的非参考映射达到了最高分。

Conclusion: CMOMgen成功解决了复杂多本体匹配问题，能够生成完整且语义合理的本体映射，并且在多个生物医学任务中表现出色，在类别选择和映射质量方面均优于现有方法，证明了其在本体集成方面的有效性和潜力。

Abstract: Constructing comprehensive knowledge graphs requires the use of multiple
ontologies in order to fully contextualize data into a domain. Ontology
matching finds equivalences between concepts interconnecting ontologies and
creating a cohesive semantic layer. While the simple pairwise state of the art
is well established, simple equivalence mappings cannot provide full semantic
integration of related but disjoint ontologies. Complex multi-ontology matching
(CMOM) aligns one source entity to composite logical expressions of multiple
target entities, establishing more nuanced equivalences and provenance along
the ontological hierarchy.
  We present CMOMgen, the first end-to-end CMOM strategy that generates
complete and semantically sound mappings, without establishing any restrictions
on the number of target ontologies or entities. Retrieval-Augmented Generation
selects relevant classes to compose the mapping and filters matching reference
mappings to serve as examples, enhancing In-Context Learning. The strategy was
evaluated in three biomedical tasks with partial reference alignments. CMOMgen
outperforms baselines in class selection, demonstrating the impact of having a
dedicated strategy. Our strategy also achieves a minimum of 63% in F1-score,
outperforming all baselines and ablated versions in two out of three tasks and
placing second in the third. Furthermore, a manual evaluation of non-reference
mappings showed that 46% of the mappings achieve the maximum score, further
substantiating its ability to construct semantically sound mappings.

</details>


### [55] [A Multimodal Benchmark for Framing of Oil & Gas Advertising and Potential Greenwashing Detection](https://arxiv.org/abs/2510.21679)
*Gaku Morio,Harri Rowlands,Dominik Stammbach,Christopher D. Manning,Peter Henderson*

Main category: cs.AI

TL;DR: 该公司致力于创建一个公共关系活动的基准数据集，以了解品牌形象与实际行动之间的框架和差异。


<details>
  <summary>Details</summary>
Motivation: 目前存在品牌在宣传中言行不一的现象，尤其是在石油和天然气公司中存在“洗绿”行为，因此需要理解公共关系活动中的框架及其变化。

Method: 收集Facebook和YouTube上的专家标注视频广告，创建了一个包含13种框架类型、涵盖50多家公司或倡导团体、20个国家的基准数据集。该数据集专为评估视觉-语言模型（VLMs）而设计。

Result: GPT-4.1在检测环境信息方面的F1分数为79%，而本文的最佳模型在识别绿色创新框架方面的F1分数仅为46%。研究还指出了VLMs需要解决的挑战，如隐含框架、处理不同长度的视频以及隐含的文化背景。

Conclusion: 该数据集有助于能源领域战略传播多模态分析的研究，并为未来的视觉-语言模型改进提供了空间和发展空间。

Abstract: Companies spend large amounts of money on public relations campaigns to
project a positive brand image. However, sometimes there is a mismatch between
what they say and what they do. Oil & gas companies, for example, are accused
of "greenwashing" with imagery of climate-friendly initiatives. Understanding
the framing, and changes in framing, at scale can help better understand the
goals and nature of public relations campaigns. To address this, we introduce a
benchmark dataset of expert-annotated video ads obtained from Facebook and
YouTube. The dataset provides annotations for 13 framing types for more than 50
companies or advocacy groups across 20 countries. Our dataset is especially
designed for the evaluation of vision-language models (VLMs), distinguishing it
from past text-only framing datasets. Baseline experiments show some promising
results, while leaving room for improvement for future work: GPT-4.1 can detect
environmental messages with 79% F1 score, while our best model only achieves
46% F1 score on identifying framing around green innovation. We also identify
challenges that VLMs must address, such as implicit framing, handling videos of
various lengths, or implicit cultural backgrounds. Our dataset contributes to
research in multimodal analysis of strategic communication in the energy
sector.

</details>


### [56] [A Knowledge-Graph Translation Layer for Mission-Aware Multi-Agent Path Planning in Spatiotemporal Dynamics](https://arxiv.org/abs/2510.21695)
*Edward Holmberg,Elias Ioup,Mahdi Abdelguerfi*

Main category: cs.AI

TL;DR: 该框架引入了一个以知识图谱（KG）为中心的框架，该知识图谱充当智能翻译层，弥合了高级任务目标与低级规划器输入之间的语义鸿沟。


<details>
  <summary>Details</summary>
Motivation: 解决自主智能体在动态环境中协调时，高级任务目标与低级规划器输入之间的语义鸿沟问题。

Method: 引入了一个以知识图谱（KG）为中心的框架，该知识图谱充当智能翻译层。KG 的双平面架构将声明性事实编译成每个智能体的、任务感知的“世界观”和物理感知的遍历规则，从而将任务语义与领域无关的规划器解耦。

Result: 通过改变知识图谱中的事实，可以修改复杂、协调的路径。在墨西哥湾的自主水下航行器（AUV）案例研究中，视觉上展示了端到端的过程，并定量证明了不同的声明性策略产生了独特、高性能的结果。

Conclusion: 知识图谱不仅是一个数据存储库，而且是创建自适应和可解释的自主系统的强大、有状态的协调器。

Abstract: The coordination of autonomous agents in dynamic environments is hampered by
the semantic gap between high-level mission objectives and low-level planner
inputs. To address this, we introduce a framework centered on a Knowledge Graph
(KG) that functions as an intelligent translation layer. The KG's two-plane
architecture compiles declarative facts into per-agent, mission-aware
``worldviews" and physics-aware traversal rules, decoupling mission semantics
from a domain-agnostic planner. This allows complex, coordinated paths to be
modified simply by changing facts in the KG. A case study involving Autonomous
Underwater Vehicles (AUVs) in the Gulf of Mexico visually demonstrates the
end-to-end process and quantitatively proves that different declarative
policies produce distinct, high-performing outcomes. This work establishes the
KG not merely as a data repository, but as a powerful, stateful orchestrator
for creating adaptive and explainable autonomous systems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [57] [Scale-robust Auctions](https://arxiv.org/abs/2510.21231)
*Jason Hartline,Aleck Johnsen,Yingkai Li*

Main category: cs.GT

TL;DR: 该文章研究了在任何规模下都具有鲁棒性的拍卖，即无论物品贵贱，都能在最坏情况下获得最佳乘性近似。


<details>
  <summary>Details</summary>
Motivation: 研究如何在各种价格区间内，设计出能够实现最优收益乘性近似的拍卖机制。这对于解决传统拍卖机制在物品价值差异大时性能不佳的问题具有重要意义。

Method: 文章提出了一种尺度不变机制，它通过在二价拍卖和二价拍卖价格的2.45倍之间进行随机化来运作。

Result: 作者证明了最优机制是尺度不变的，并且这种机制在最坏情况下能够获得最佳的乘性近似。

Conclusion: 通过在二价拍卖和二价拍卖价格的2.45倍之间进行随机化，可以设计出一种在任何规模下都具有鲁棒性的拍卖机制，从而在最坏情况下实现最优的收益表现。

Abstract: We study auctions that are robust at any scale, i.e., they can be applied to
sell both expensive and cheap items and achieve the best multiplicative
approximations of the optimal revenue in the worst case. We show that the
optimal mechanism is scale invariant, which randomizes between selling at the
second-price and a 2.45 multiple of the second-price.

</details>


### [58] [Scalable Neural Incentive Design with Parameterized Mean-Field Approximation](https://arxiv.org/abs/2510.21442)
*Nathan Corecco,Batuhan Yardim,Vinzenz Thoma,Zebang Shen,Niao He*

Main category: cs.GT

TL;DR: 本文提出了一种针对多智能体系统激励设计的Adjoint Mean-Field Incentive Design (AMID) 算法，该算法通过平均场博弈方法处理大规模智能体问题，并在理论上证明了有限N智能体系统与平均场极限的近似误差界限，在实验中显示出超越现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，尤其是在智能体数量N很大时，设计激励以诱导期望的纳什均衡是一个关键且具有挑战性的问题。

Method: 本文将激励设计（ID）问题形式化为参数化平均场博弈（PMFG），以通过无限种群极限来降低复杂性。首先，证明了在动力学和奖励为Lipschitz连续时，有限N的ID目标以$\mathscr{O}(\frac{1}{\sqrt{N}})$ 的速率被PMFG近似。其次，在非Lipschitz连续的序贯拍卖特殊情况下，通过定制的拍卖分析，证明了相同的$\mathscr{O}(\frac{1}{\sqrt{N}})$ 衰减率。在此基础上，引入了Adjoint Mean-Field Incentive Design (AMID) 算法，该算法通过迭代均衡算子的显式微分来高效计算梯度。

Result: 本文的主要结果包括：1. 证明了有限N激励设计目标与参数化平均场博弈之间的近似误差界限为$\mathscr{O}(\frac{1}{\sqrt{N}})$，这一结论在Lipschitz连续和序贯拍卖的非连续设置下均成立。 2. 提出了AMID算法，该算法能够有效地计算梯度，从而为大规模智能体激励设计提供了可扩展的工具。 3. 在各种拍卖设置中，AMID方法显著提高了收入，并优于现有基准方法。

Conclusion: 本文通过引入参数化平均场博弈和Adjoint Mean-Field Incentive Design (AMID) 算法，为解决大规模多智能体系统中的激励设计问题提供了一种理论上严谨且实践中有效的新方法。该方法不仅在理论上提供了近似误差的保证，而且在实验中也展示了其优越性，特别是在提高拍卖收入方面。

Abstract: Designing incentives for a multi-agent system to induce a desirable Nash
equilibrium is both a crucial and challenging problem appearing in many
decision-making domains, especially for a large number of agents $N$. Under the
exchangeability assumption, we formalize this incentive design (ID) problem as
a parameterized mean-field game (PMFG), aiming to reduce complexity via an
infinite-population limit. We first show that when dynamics and rewards are
Lipschitz, the finite-$N$ ID objective is approximated by the PMFG at rate
$\mathscr{O}(\frac{1}{\sqrt{N}})$. Moreover, beyond the Lipschitz-continuous
setting, we prove the same $\mathscr{O}(\frac{1}{\sqrt{N}})$ decay for the
important special case of sequential auctions, despite discontinuities in
dynamics, through a tailored auction-specific analysis. Built on our novel
approximation results, we further introduce our Adjoint Mean-Field Incentive
Design (AMID) algorithm, which uses explicit differentiation of iterated
equilibrium operators to compute gradients efficiently. By uniting
approximation bounds with optimization guarantees, AMID delivers a powerful,
scalable algorithmic tool for many-agent (large $N$) ID. Across diverse auction
settings, the proposed AMID method substantially increases revenue over
first-price formats and outperforms existing benchmark methods.

</details>


### [59] [Privacy Guarantee for Nash Equilibrium Computation of Aggregative Games Based on Pointwise Maximal Leakage](https://arxiv.org/abs/2510.21668)
*Zhaoyang Cheng,Guanpu Chen,Tobias J. Oechtering,Mikael Skoglund*

Main category: cs.GT

TL;DR: 本文提出了一种点式最大泄漏（PML）框架，用于在聚合博弈中计算纳什均衡（NE），以解决差分隐私（DP）在处理相关数据集时无法有效评估信息泄漏以及无法利用数据集的先验分布知识的问题。


<details>
  <summary>Details</summary>
Motivation: 在设计纳什均衡（NE）计算算法时，隐私保护是一个关键指标。尽管差分隐私（DP）已被广泛应用于提供隐私保证，但它未能充分利用数据集的先验分布知识，并且在评估相关数据集的信息泄漏方面表现不佳。

Method: 本文通过将玩家成本函数数据集的先验知识纳入考量，建立了一个点式最大泄漏（PML）框架来计算聚合博弈中的纳什均衡。

Result: 实验结果表明，PML通过提供更严格的隐私保证，改进了DP，从而在NE计算设计中提供了更大的灵活性。此外，研究还揭示了在某些特定相关数据集下，PML的下限可能超过DP的上限，这强调了PML在处理相关数据集时作为隐私度量的更优越性。

Conclusion: PML是比DP更合适的隐私度量，因为它能更充分地捕捉相关数据集中的隐私泄漏。通过实验证明了我们框架的有效性。

Abstract: Privacy preservation has served as a key metric in designing Nash equilibrium
(NE) computation algorithms. Although differential privacy (DP) has been widely
employed for privacy guarantees, it does not exploit prior distributional
knowledge of datasets and is ineffective in assessing information leakage for
correlated datasets. To address these concerns, we establish a pointwise
maximal leakage (PML) framework when computing NE in aggregative games. By
incorporating prior knowledge of players' cost function datasets, we obtain a
precise and computable upper bound of privacy leakage with PML guarantees. In
the entire view, we show PML refines DP by offering a tighter privacy
guarantee, enabling flexibility in designing NE computation. Also, in the
individual view, we reveal that the lower bound of PML can exceed the upper
bound of DP by constructing specific correlated datasets. The results emphasize
that PML is a more proper privacy measure than DP since the latter fails to
adequately capture privacy leakage in correlated datasets. Moreover, we conduct
experiments with adversaries who attempt to infer players' private information
to illustrate the effectiveness of our framework.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [60] [Exponential Convergence Guarantees for Iterative Markovian Fitting](https://arxiv.org/abs/2510.20871)
*Marta Gentiloni Silveri,Giovanni Conforti,Alain Durmus*

Main category: stat.ML

TL;DR: 本文首次为迭代马尔可夫拟合提供了非渐近指数收敛保证。


<details>
  <summary>Details</summary>
Motivation: 探索迭代马尔可夫拟合（IMF）的非渐近收敛性能，因为之前的研究只建立了渐近收敛性。

Method: 通过对马尔可夫投影算子进行新的收缩分析，并在参考测度和边际分布的温和结构假设下，证明了在足够大的时间范围内IMF的非渐近指数收敛。

Result: 在边际分布为对数凹和弱对数凹两种情况下，为IMF提供了非渐近指数收敛保证。

Conclusion: 本文首次为IMF提供了非渐近指数收敛保证，并为DSBM的理论保证奠定了基础。

Abstract: The Schr\"odinger Bridge (SB) problem has become a fundamental tool in
computational optimal transport and generative modeling. To address this
problem, ideal methods such as Iterative Proportional Fitting and Iterative
Markovian Fitting (IMF) have been proposed-alongside practical approximations
like Diffusion Schr\"odinger Bridge and its Matching (DSBM) variant. While
previous work have established asymptotic convergence guarantees for IMF, a
quantitative, non-asymptotic understanding remains unknown. In this paper, we
provide the first non-asymptotic exponential convergence guarantees for IMF
under mild structural assumptions on the reference measure and marginal
distributions, assuming a sufficiently large time horizon. Our results
encompass two key regimes: one where the marginals are log-concave, and another
where they are weakly log-concave. The analysis relies on new contraction
results for the Markovian projection operator and paves the way to theoretical
guarantees for DSBM.

</details>


### [61] [Kernel Learning with Adversarial Features: Numerical Efficiency and Adaptive Regularization](https://arxiv.org/abs/2510.20883)
*Antônio H. Ribeiro,David Vävinggren,Dave Zachariah,Thomas B. Schön,Francis Bach*

Main category: stat.ML

TL;DR: 该论文提出了一种新的对抗训练方法，通过在 reproducing kernel Hilbert 空间中进行特征空间扰动，解决了传统对抗训练计算成本高的问题，并取得了良好的性能。


<details>
  <summary>Details</summary>
Motivation: 对抗训练是提高模型对抗性扰动鲁棒性的关键技术，但现有方法计算成本高昂，限制了实际应用。

Method: 提出了一种在 reproducing kernel Hilbert 空间中进行对抗训练的新方法，将扰动从输入空间转移到特征空间。这种重新表述使得内部最大化问题可以精确求解。该方法还提供了一个正则化估计器，可以根据噪声水平和基础函数的平滑度进行自适应调整。

Result: 建立了特征扰动公式作为原始问题松弛的条件，并提出了一种基于迭代核岭回归的高效优化算法。提供了泛化界限，有助于理解该方法的特性。还将该公式扩展到多核学习。

Conclusion: 经验评估表明，该方法在干净和对抗设置下都表现出良好的性能。

Abstract: Adversarial training has emerged as a key technique to enhance model
robustness against adversarial input perturbations. Many of the existing
methods rely on computationally expensive min-max problems that limit their
application in practice. We propose a novel formulation of adversarial training
in reproducing kernel Hilbert spaces, shifting from input to feature-space
perturbations. This reformulation enables the exact solution of inner
maximization and efficient optimization. It also provides a regularized
estimator that naturally adapts to the noise level and the smoothness of the
underlying function. We establish conditions under which the feature-perturbed
formulation is a relaxation of the original problem and propose an efficient
optimization algorithm based on iterative kernel ridge regression. We provide
generalization bounds that help to understand the properties of the method. We
also extend the formulation to multiple kernel learning. Empirical evaluation
shows good performance in both clean and adversarial settings.

</details>


### [62] [Doubly-Regressing Approach for Subgroup Fairness](https://arxiv.org/abs/2510.21091)
*Kyungseon Lee,Kunwoong Kim,Jihu Lee,Dongyoon Yang,Yongdai Kim*

Main category: stat.ML

TL;DR: 这篇论文提出了一种新的学习算法DRAF，旨在解决亚组公平性问题，尤其是在敏感属性数量很多导致计算负担和数据稀疏性问题时。DRAF通过关注样本量充足的亚组和边际公平性来解决这些问题，并引入了supIPM作为衡量标准。


<details>
  <summary>Details</summary>
Motivation: 在人工智能的实际应用中，算法公平性是一个重要的社会问题。当存在多个敏感属性时，亚组公平性被广泛研究。然而，随着敏感属性数量的增加，亚组数量也随之增加，导致计算负担过重和数据稀疏性问题（亚组规模过小）。

Method: 本研究提出了一种新颖的亚组公平性学习算法——DRAF（Doubly Regressing Adversarial learning for subgroup Fairness）。该算法通过关注样本量充足的亚组以及边际公平性来解决现有问题。研究者为此形式化了“亚组子集公平性”的概念，并引入了相应的分布公平性度量——supremum Integral Probability Metric（supIPM）。DRAF算法旨在减小supIPM的替代公平性差距。

Result: 理论上，研究证明了DRAF算法提出的替代公平性差距是supIPM的上限。经验证，在基准数据集上，DRAF算法优于基线方法，特别是在敏感属性数量较多导致许多亚组过小的情况下表现更佳。

Conclusion: 本研究提出了一种有效的DRAF算法，用于解决多敏感属性下的亚组公平性问题。该算法通过关注有足够样本量的亚组和边际公平性，并通过减小supIPM的替代公平性差距，有效地降低了计算负担并缓解了数据稀疏性问题。理论和实验结果均表明了DRAF算法的优越性。

Abstract: Algorithmic fairness is a socially crucial topic in real-world applications
of AI.
  Among many notions of fairness, subgroup fairness is widely studied when
multiple sensitive attributes (e.g., gender, race, age) are present.
  However, as the number of sensitive attributes grows, the number of subgroups
increases accordingly, creating heavy computational burdens and data sparsity
problem (subgroups with too small sizes).
  In this paper, we develop a novel learning algorithm for subgroup fairness
which resolves these issues by focusing on subgroups with sufficient sample
sizes as well as marginal fairness (fairness for each sensitive attribute).
  To this end, we formalize a notion of subgroup-subset fairness and introduce
a corresponding distributional fairness measure called the supremum Integral
Probability Metric (supIPM).
  Building on this formulation, we propose the Doubly Regressing Adversarial
learning for subgroup Fairness (DRAF) algorithm, which reduces a surrogate
fairness gap for supIPM with much less computation than directly reducing
supIPM.
  Theoretically, we prove that the proposed surrogate fairness gap is an upper
bound of supIPM.
  Empirically, we show that the DRAF algorithm outperforms baseline methods in
benchmark datasets, specifically when the number of sensitive attributes is
large so that many subgroups are very small.

</details>


### [63] [Enforcing Calibration in Multi-Output Probabilistic Regression with Pre-rank Regularization](https://arxiv.org/abs/2510.21273)
*Naomi Desobry,Elnura Zhalieva,Souhaib Ben Taieb*

Main category: stat.ML

TL;DR: 本文提出了一种通用的正则化框架，用于在训练期间强制执行多变量校准，适用于任意预排序函数，并通过惩罚投影概率积分变换（PITs）与均匀分布的偏差来执行校准。


<details>
  <summary>Details</summary>
Motivation: 在多输出回归中，定义和实现多变量校准仍然具有挑战性。现有的多变量校准文献主要侧重于基于预排序函数的诊断工具。

Method: 本文提出了一种通用的正则化框架，用于在训练期间强制执行多变量校准，适用于任意预排序函数。该方法通过惩罚投影概率积分变换（PITs）与均匀分布的偏差来执行校准，可以作为正则化项添加到任何概率预测器的损失函数中。具体来说，提出了一种正则化损失，共同强制执行边际和多变量预排序校准。同时引入了一种新的基于PCA的预排序，可以捕获预测分布中最大方差方向上的校准，同时实现降维。

Result: 在18个真实世界的多输出回归数据集中，未正则化的模型始终存在校准不良问题，而本文方法显著改善了所有预排序函数的校准，而没有牺牲预测精度。

Conclusion: 本文提出的正则化框架可以有效解决多变量回归中的校准问题，显著提高模型的可靠性，且不影响预测准确性。

Abstract: Probabilistic models must be well calibrated to support reliable
decision-making. While calibration in single-output regression is well studied,
defining and achieving multivariate calibration in multi-output regression
remains considerably more challenging. The existing literature on multivariate
calibration primarily focuses on diagnostic tools based on pre-rank functions,
which are projections that reduce multivariate prediction-observation pairs to
univariate summaries to detect specific types of miscalibration. In this work,
we go beyond diagnostics and introduce a general regularization framework to
enforce multivariate calibration during training for arbitrary pre-rank
functions. This framework encompasses existing approaches such as highest
density region calibration and copula calibration. Our method enforces
calibration by penalizing deviations of the projected probability integral
transforms (PITs) from the uniform distribution, and can be added as a
regularization term to the loss function of any probabilistic predictor.
Specifically, we propose a regularization loss that jointly enforces both
marginal and multivariate pre-rank calibration. We also introduce a new
PCA-based pre-rank that captures calibration along directions of maximal
variance in the predictive distribution, while also enabling dimensionality
reduction. Across 18 real-world multi-output regression datasets, we show that
unregularized models are consistently miscalibrated, and that our methods
significantly improve calibration across all pre-rank functions without
sacrificing predictive accuracy.

</details>


### [64] [Oracle-Efficient Combinatorial Semi-Bandits](https://arxiv.org/abs/2510.21431)
*Jung-hun Kim,Milan Vojnović,Min-hwan Oh*

Main category: stat.ML

TL;DR: 本文提出了一种新的组合半 Bandit 算法，该算法在保持较小的遗憾值的同时显著减少了预言机查询的次数。


<details>
  <summary>Details</summary>
Motivation: 组合半 Bandit 问题在实际应用中具有挑战性，因为它需要大量的预言机查询。

Method: 本文提出了一种预言机高效的框架，该框架可以显著减少预言机调用。

Result: 本文提出算法在最坏情况下的线性奖励设置中实现了 O(√T) 的遗憾，同时仅使用了 O(loglog T) 的预言机查询。本文还提出了协方差自适应算法，利用噪声结构改进了遗憾值，并将该方法推广到一般的（非线性）奖励。

Conclusion: 本文提出的方法将预言机的使用从线性时间减少到（双重）对数时间，并且具有强大的理论保证。

Abstract: We study the combinatorial semi-bandit problem where an agent selects a
subset of base arms and receives individual feedback. While this generalizes
the classical multi-armed bandit and has broad applicability, its scalability
is limited by the high cost of combinatorial optimization, requiring oracle
queries at every round. To tackle this, we propose oracle-efficient frameworks
that significantly reduce oracle calls while maintaining tight regret
guarantees. For the worst-case linear reward setting, our algorithms achieve
$\tilde{O}(\sqrt{T})$ regret using only $O(\log\log T)$ oracle queries. We also
propose covariance-adaptive algorithms that leverage noise structure for
improved regret, and extend our approach to general (non-linear) rewards.
Overall, our methods reduce oracle usage from linear to (doubly) logarithmic in
time, with strong theoretical guarantees.

</details>


### [65] [Fisher meets Feynman: score-based variational inference with a product of experts](https://arxiv.org/abs/2510.21598)
*Diana Cai,Robert M. Gower,David M. Blei,Lawrence K. Saul*

Main category: stat.ML

TL;DR: 本文介绍了一种可用于黑盒变分推断（BBVI）的加权专家乘积（PoE）模型，该模型能有效处理偏斜、重尾和多峰分布，并提供了一种基于Feynman恒等式和狄利克雷随机变量的采样方法，以及一种迭代优化专家权重并能快速收敛的算法。


<details>
  <summary>Details</summary>
Motivation: 在黑盒变分推断（BBVI）中，现有的方法难以有效处理具有偏斜、重尾和多峰性等复杂特征的分布。作者旨在引入一个既具表达力又易于处理的模型家族来解决这一问题。

Method: 本文提出了一种加权专家乘积（PoE）模型，其中每个加权专家都与多元t分布成比例。为了从这些PoE密度中进行采样，作者通过Feynman恒等式将其重新表述为带有辅助狄利克雷随机变量的潜在变量模型。然后，利用这个单纯形潜在空间从PoE中抽取加权样本。在专家集合给定的情况下，作者推导了一个迭代过程来优化决定PoE中几何权重的指数。在每次迭代中，该过程通过最小化正则化Fisher散度，使变分密度和目标密度的分数在当前近似的样本批次上匹配。这种最小化问题被简化为一个凸二次规划。

Result: 所提出的加权专家乘积（PoE）模型能够有效地模拟具有偏斜、重尾和多峰性的分布。通过Feynman恒等式和狄利克雷随机变量，作者成功解决了从这些复杂密度中采样的问题。优化专家权重的迭代过程被证明能够以指数速度收敛到接近最优的专家权重。

Conclusion: 本文成功开发了一种用于黑盒变分推断（BBVI）的高度表达且易于处理的加权专家乘积（PoE）模型。该模型能够处理复杂的分布特征，并提供了一种新颖的采样方法和一种快速收敛的专家权重优化算法。该方法在各种合成和真实世界的目标分布上都表现出良好的性能，为BBVI提供了一个强大的工具。

Abstract: We introduce a highly expressive yet distinctly tractable family for
black-box variational inference (BBVI). Each member of this family is a
weighted product of experts (PoE), and each weighted expert in the product is
proportional to a multivariate $t$-distribution. These products of experts can
model distributions with skew, heavy tails, and multiple modes, but to use them
for BBVI, we must be able to sample from their densities. We show how to do
this by reformulating these products of experts as latent variable models with
auxiliary Dirichlet random variables. These Dirichlet variables emerge from a
Feynman identity, originally developed for loop integrals in quantum field
theory, that expresses the product of multiple fractions (or in our case,
$t$-distributions) as an integral over the simplex. We leverage this simplicial
latent space to draw weighted samples from these products of experts -- samples
which BBVI then uses to find the PoE that best approximates a target density.
Given a collection of experts, we derive an iterative procedure to optimize the
exponents that determine their geometric weighting in the PoE. At each
iteration, this procedure minimizes a regularized Fisher divergence to match
the scores of the variational and target densities at a batch of samples drawn
from the current approximation. This minimization reduces to a convex quadratic
program, and we prove under general conditions that these updates converge
exponentially fast to a near-optimal weighting of experts. We conclude by
evaluating this approach on a variety of synthetic and real-world target
distributions.

</details>


### [66] [Multimodal Datasets with Controllable Mutual Information](https://arxiv.org/abs/2510.21686)
*Raheem Karim Hashmani,Garrett W. Merz,Helen Qu,Mariel Pettee,Kyle Cranmer*

Main category: stat.ML

TL;DR: 该论文介绍了一个用于生成高度多模态数据集的框架，该框架明确计算了模态之间的互信息。


<details>
  <summary>Details</summary>
Motivation: 此研究旨在为互信息估计器和多模态自监督学习技术提供一个新的测试平台，通过构建具有已知互信息的基准数据集。

Method: 该框架利用基于流的生成模型和结构化因果框架来生成相关的潜在变量，从而构建具有已知互信息的真实数据集。

Result: 该框架能够生成具有明确可计算模态间互信息的高度多模态数据集。

Conclusion: 该框架为互信息估计器和多模态自监督学习技术的研究提供了一个新颖且系统的方法，通过生成已知互信息的基准数据集。

Abstract: We introduce a framework for generating highly multimodal datasets with
explicitly calculable mutual information between modalities. This enables the
construction of benchmark datasets that provide a novel testbed for systematic
studies of mutual information estimators and multimodal self-supervised
learning techniques. Our framework constructs realistic datasets with known
mutual information using a flow-based generative model and a structured causal
framework for generating correlated latent variables.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [67] [Information Theoretic Learning for Diffusion Models with Warm Start](https://arxiv.org/abs/2510.20903)
*Yirong Shen,Lu Gan,Cong Ling*

Main category: cs.IT

TL;DR: 本文提出了一种针对噪声驱动模型的更严格的似然界，以提高最大似然学习的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的扰动式生成模型在收敛速度和理论理解方面存在局限性，特别是在最大化模型似然时。

Method: 本文将KL散度-Fisher信息关系推广到任意噪声扰动，超越高斯假设并支持结构化噪声分布。该方法将扩散过程视为高斯通道，并表示数据与模型之间的不匹配熵，从而使提出的目标函数能够限制负对数似然（NLL）的上限。

Result: 在CIFAR-10上实现了有竞争力的NLL，并在ImageNet上取得了SOTA结果，且无需数据增强。该框架还可自然地扩展到离散数据。

Conclusion: 本文通过引入更严格的似然界和灵活的噪声分布，显著提升了噪声驱动生成模型的性能和理论基础，使得模型在多种数据类型和任务上表现出色。

Abstract: Generative models that maximize model likelihood have gained traction in many
practical settings. Among them, perturbation based approaches underpin many
strong likelihood estimation models, yet they often face slow convergence and
limited theoretical understanding. In this paper, we derive a tighter
likelihood bound for noise driven models to improve both the accuracy and
efficiency of maximum likelihood learning. Our key insight extends the
classical KL divergence Fisher information relationship to arbitrary noise
perturbations, going beyond the Gaussian assumption and enabling structured
noise distributions. This formulation allows flexible use of randomized noise
distributions that naturally account for sensor artifacts, quantization
effects, and data distribution smoothing, while remaining compatible with
standard diffusion training. Treating the diffusion process as a Gaussian
channel, we further express the mismatched entropy between data and model,
showing that the proposed objective upper bounds the negative log-likelihood
(NLL). In experiments, our models achieve competitive NLL on CIFAR-10 and SOTA
results on ImageNet across multiple resolutions, all without data augmentation,
and the framework extends naturally to discrete data.

</details>


### [68] [Overlapped-repetition Shor codes achieving fourfold asymptotic rate](https://arxiv.org/abs/2510.21030)
*En-Jui Chang*

Main category: cs.IT

TL;DR: 这篇论文提出了一种改进 Shor 码的方法，通过重叠小的重复码来提高码率，并在最小距离为 3 的情况下将开销从 [[9,1,3]] 降低到更高效的 [[7,1,3]]。


<details>
  <summary>Details</summary>
Motivation: 提高标准 Shor 码的码率并降低开销。

Method: 通过重叠少量重复码来增强渐近码率。

Result: 渐近码率提高了四倍。在最小距离 d=3 的情况下，开销从 [[9,1,3]] 减少到更高效的 [[7,1,3]] 配置。

Conclusion: 通过重叠重复码，可以显著提高 Shor 码的效率和码率。

Abstract: The standard Shor code employs two repetition codes as inner and outer codes,
yielding a simple structure but a relatively low code rate. By overlapping a
small number of repetition codes, we enhance the asymptotic code rate fourfold.
In the minimal-distance case $d = 3$, this construction reduces the overhead
from $[[9,1,3]]$ to the more efficient $[[7,1,3]]$ configuration.

</details>


### [69] [Complex DNA Synthesis Sequences](https://arxiv.org/abs/2510.21253)
*Boaz Moav,Ryan Gabrys,Eitan Yaakobi*

Main category: cs.IT

TL;DR: 本文介绍并分析了一种混合合成框架，该框架结合了酶促合成和光刻合成的优点，并提出了一种新的复杂合成序列的概念。


<details>
  <summary>Details</summary>
Motivation: DNA存储的扩展性受限于平行链合成的效率。现有方法存在不足，如酶促合成无法限制核苷酸添加，而光刻合成则强制所有链进行相同的添加。

Method: 本文提出了一种混合合成框架，在每个循环中，从受限子集中选择一个核苷酸并并行合成。在此基础上，扩展了Lenz等人的信息速率定义，并分析了删除球的模拟，推导了最大信息速率及其渐近行为的紧密表达式。针对已知链情况，设计了一种动态规划算法来计算最佳复杂合成序列。此外，定义了一种独特的二维阵列模型，其在行上具有合成约束，并为此问题开发了动态规划算法。

Result: 本文的结果弥合了约束模型与理想设置之间的理论鸿沟。研究了复杂合成序列，并推导了最大信息速率及其渐近行为的紧密表达式。为已知链设计了计算最佳复杂合成序列的动态规划算法。定义了二维阵列模型并开发了相应的动态规划算法。

Conclusion: 本文建立了一个新的全面的约束DNA理论框架，Hiding了先前的模型，并为该领域的未来发展奠定了基础。

Abstract: DNA-based storage offers unprecedented density and durability, but its
scalability is fundamentally limited by the efficiency of parallel strand
synthesis. Existing methods either allow unconstrained nucleotide additions to
individual strands, such as enzymatic synthesis, or enforce identical additions
across many strands, such as photolithographic synthesis. We introduce and
analyze a hybrid synthesis framework that generalizes both approaches: in each
cycle, a nucleotide is selected from a restricted subset and incorporated in
parallel. This model gives rise to a new notion of a complex synthesis
sequence. Building on this framework, we extend the information rate definition
of Lenz et al. and analyze an analog of the deletion ball, defined and studied
in this setting, deriving tight expressions for the maximal information rate
and its asymptotic behavior. These results bridge the theoretical gap between
constrained models and the idealized setting in which every nucleotide is
always available. For the case of known strands, we design a dynamic
programming algorithm that computes an optimal complex synthesis sequence,
highlighting structural similarities to the shortest common supersequence
problem. We also define a distinct two-dimensional array model with synthesis
constraints over the rows, which extends previous synthesis models in the
literature and captures new structural limitations in large-scale strand
arrays. Additionally, we develop a dynamic programming algorithm for this
problem as well. Our results establish a new and comprehensive theoretical
framework for constrained DNA, subsuming prior models and setting the stage for
future advances in the field.

</details>


### [70] [Low-Complexity MIMO Channel Estimation with Latent Diffusion Models](https://arxiv.org/abs/2510.21386)
*Xiaotian Fan,Xingyu Zhou,Le Liang,Shi Jin*

Main category: cs.IT

TL;DR: 本文提出了一种基于潜在扩散模型（LDMs）的新型信道估计算法PSLD-CE，它利用轻量级LMD架构学习信道先验，并通过近似似然项和变分自编码器潜在空间上的自洽性约束增强扩散后验采样，实验证明其在低计算复杂度和快速推理速度下超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的信道估计算法无法有效处理无线信道复杂的先验分布问题，而深度生成模型有望通过学习这种复杂分布来提供更强大的替代方案。

Method: 本文提出PSLD-CE算法，其核心是专为信道估计设计的轻量级潜在扩散模型（LDM）架构，用于捕获复杂的信道分布。此外，通过引入有效的似然项近似和针对变分自编码器潜在空间的自洽性约束，增强了扩散后验采样过程。

Result: PSLD-CE在大量实验中始终优于现有方法，并且在实现显著性能提升的同时，保持了较低的计算复杂度和快速的推理速度。

Conclusion: PSLD-CE是一种有前途且实用的解决方案，适用于下一代无线系统，因为它有效地利用深度生成模型解决了信道估计的复杂先验分布问题，并实现了高性能、低复杂度和快速推理。

Abstract: Deep generative models offer a powerful alternative to conventional channel
estimation by learning the complex prior distribution of wireless channels.
Capitalizing on this potential, this paper proposes a novel channel estimation
algorithm based on latent diffusion models (LDMs), termed posterior sampling
with latent diffusion for channel estimation (PSLD-CE). The core of our
approach is a lightweight LDM architecture specifically designed for channel
estimation, which serves as a powerful generative prior to capture the
intricate channel distribution. Furthermore, we enhance the diffusion posterior
sampling process by introducing an effective approximation for the likelihood
term and a tailored self-consistency constraint on the variational autoencoder
latent space. Extensive experimental results demonstrate that PSLD-CE
consistently outperforms a wide range of existing methods. Notably, these
significant performance gains are achieved while maintaining low computational
complexity and fast inference speed, establishing our method as a highly
promising and practical solution for next-generation wireless systems.

</details>


### [71] [Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication](https://arxiv.org/abs/2510.21414)
*Hoang Ly,Emina Soljanin*

Main category: cs.IT

TL;DR: 本文提出了一种新的译码框架，将任意分组码的最大似然（ML）译码的最坏情况时间复杂度从$q^{k}n$降低到$q^{k}$，这在实践中是非常理想的。


<details>
  <summary>Details</summary>
Motivation: 最大似然（ML）译码对于任意分组码来说仍然非常困难，最坏情况下的时间复杂度不低于穷举搜索，即对于一个$[n,k]_q$码，需要$q^{k}n$次操作。

Method: 本文引入了一种简单、与代码无关的框架。该框架的核心思想是，在接收端接收到每个序列时，该序列对于码本中每个码字的条件概率（即似然）可以表示为两个精心构造的向量的内积——第一个向量取决于接收到的序列，第二个向量取决于码字本身。最终，码本中所有码字的似然评估归结为一次向量矩阵乘法，MLD变成了选择结果向量中最大条目的简单任务。

Result: 该方法将最坏情况下的复杂度降低了$n$倍，达到了$q^{k}$次操作。这一结果适用于通用无记忆信道上的线性和非线性分组码，以及硬判决和软判决译码。它自然地扩展到符号间干扰（ISI）信道和ML列表译码，且复杂度仅有可忽略的增加。通过使用Mailman算法，可以进一步降低向量矩阵乘法的成本。

Conclusion: 本文提出了一种有效降低任意分组码ML译码时间复杂度的框架，但代价是空间复杂度较高，需要$\mathcal{O}(q^{k+1} n)$的空间来存储预先计算的码本矩阵。

Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains
fundamentally hard, with worst-case time complexity-measured by the total
number of multiplications-being no better than straightforward exhaustive
search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper
introduces a simple, code-agnostic framework that reduces the worst-case
complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable
reduction in practice. The result holds for both linear and nonlinear block
codes over general memoryless channels and under both hard-decision and
soft-decision decoding. It naturally extends to intersymbol-interference (ISI)
channels and ML list decoding with only a negligible increase in complexity.
Our core insight is that, upon receipt of each sequence at the receiver, the
conditional probability of that sequence for each codeword in the codebook
(i.e., the \emph{likelihood}) can be expressed as the inner product of two
carefully constructed vectors -- the first depending on the received sequence,
and the second on that codeword itself. As a result, evaluating the likelihoods
for all codewords in the codebook reduces to a single vector-matrix
multiplication, and ML decoding (MLD) becomes the simple task of picking the
maximum entry in the resulting vector. The only non-trivial cost lies in the
vector-matrix product. However, our matrix construction allows the use of the
Mailman algorithm to reduce this cost. This time reduction is achieved at the
cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to
store the pre-computed codebook matrix.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [72] [Incentivizing Consistent, Effective and Scalable Reasoning Capability in Audio LLMs via Reasoning Process Rewards](https://arxiv.org/abs/2510.20867)
*Jiajun Fan,Roger Ren,Jingyuan Li,Rahul Pandey,Prashanth Gurunath Shivakumar,Ivan Bulyko,Ankur Gandhe,Ge Liu,Yile Gu*

Main category: cs.LG

TL;DR: 介绍了CESAR模型，解决了音频大型语言模型在推理过程中出现的“测试时间逆向 scaling”问题，并通过强化学习提升了模型的推理能力，取得了SOTA成果。


<details>
  <summary>Details</summary>
Motivation: 在音频大型语言模型中，推理能力的作用未被充分探索，引入推理过程反而可能导致性能下降，即“测试时间逆向缩放”现象。这并非推理本身的局限性，而是由于缺乏对推理过程的适当指导，模型产生的幻觉、不一致的推理会导致错误累积。

Method: 模型：CESAR（Consistent, Effective, and Scalable Audio Reasoners）。方法：将奖励机制从结果验证转向奖励推理过程。采用在线强化学习框架，结合Group Relative Policy Optimization和多方面奖励机制。奖励机制不仅包括正确性和格式，还包括一致性、结构化分析模式、因果推理、领域知识整合和校准的推理深度。

Result: CESAR解决了测试时间逆向 scaling问题，使推理能力从负面影响转变为积极增益。模型发现了特有的“推理最佳点”，在MMAU Test-mini上实现了SOTA结果，显著优于Gemini 2.5 Pro和GPT-4o Audio。在MMSU推理任务上，模型达到了接近人类水平的性能。通过AI作为评判的评估和定性比较，验证了推理质量的提升。增强的推理能力产生了协同效应，同时提升了多模态推理和感知能力。

Conclusion: CESAR为音频大型语言模型中开发稳健且可扩展的推理提供了一种原则性的方法。

Abstract: The role of reasoning in Audio Large Language Models remains widely
underexplored, as introducing a reasoning process often degrades rather than
improves performance during inference, a phenomenon we term test-time inverse
scaling, where longer reasoning chains yield progressively worse results. We
demonstrate that this stems not from fundamental limitations of reasoning
itself, but from inadequate training: models without proper guidance for the
reasoning process produce hallucinatory, inconsistent reasoning that
accumulates errors over longer chains. To address these challenges, we
introduce CESAR (Consistent, Effective, and Scalable Audio Reasoners), shifting
from outcome verification to rewarding the reasoning process. Our online
reinforcement learning framework employs Group Relative Policy Optimization
with a multi-faceted reward suite that incentivizes not only correctness and
format but also consistency, structured analytical patterns, causal reasoning,
domain-knowledge integration, and calibrated reasoning depth. CESAR resolves
test-time inverse scaling, transforming reasoning from detriments into gains
while revealing model-specific ``reasoning sweet spots", where performance
peaks during test-time scaling. We achieve state-of-the-art results on MMAU
Test-mini, substantially outperforming Gemini 2.5 Pro and GPT-4o Audio, and
near-human-level performance on MMSU reasoning tasks. Through AI-as-judge
evaluations and qualitative comparisons, we provide both quantitative and
qualitative validation of our improved reasoning quality. Importantly, enhanced
reasoning creates synergistic effects, simultaneously improving multimodal
reasoning and perception capabilities. Overall, CESAR establishes a principled
method for developing robust and scalable reasoning in Audio LLMs.

</details>


### [73] [MOBO-OSD: Batch Multi-Objective Bayesian Optimization via Orthogonal Search Directions](https://arxiv.org/abs/2510.20872)
*Lam Ngo,Huong Ha,Jeffrey Chan,Hongyu Zhang*

Main category: cs.LG

TL;DR: 本文提出了MOBO-OSD，一种多目标贝叶斯优化算法，通过沿正交搜索方向解决多个约束优化问题来生成多样化的帕累托最优解集。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化在昂贵的黑盒目标函数优化中非常强大，但多目标优化问题仍然具有挑战性。

Method: MOBO-OSD通过沿正交搜索方向（OSDs）解决多个约束优化问题来生成多样化的帕累C托最优解集。这些OSDs是根据个体目标最小值的近似凸包定义的。为了提高解的密度，MOBO-OSD利用帕累托前沿估计技术在现有解的邻域生成额外的候选解。此外，MOBO-OSD支持批量优化以加速优化过程。

Result: 通过在各种具有2到6个目标的合成和真实世界基准函数上的大量实验和分析，MOBO-OSD始终优于最先进的算法。

Conclusion: MOBO-OSD在多目标贝叶斯优化中表现出色，能够生成多样化的帕累托最优解集，并在超体积性能和解决方案多样性方面都有显著提升。

Abstract: Bayesian Optimization (BO) is a powerful tool for optimizing expensive
black-box objective functions. While extensive research has been conducted on
the single-objective optimization problem, the multi-objective optimization
problem remains challenging. In this paper, we propose MOBO-OSD, a
multi-objective Bayesian Optimization algorithm designed to generate a diverse
set of Pareto optimal solutions by solving multiple constrained optimization
problems, referred to as MOBO-OSD subproblems, along orthogonal search
directions (OSDs) defined with respect to an approximated convex hull of
individual objective minima. By employing a well-distributed set of OSDs,
MOBO-OSD ensures broad coverage of the objective space, enhancing both solution
diversity and hypervolume performance. To further improve the density of the
set of Pareto optimal candidate solutions without requiring an excessive number
of subproblems, we leverage a Pareto Front Estimation technique to generate
additional solutions in the neighborhood of existing solutions. Additionally,
MOBO-OSD supports batch optimization, enabling parallel function evaluations to
accelerate the optimization process when resources are available. Through
extensive experiments and analysis on a variety of synthetic and real-world
benchmark functions with two to six objectives, we demonstrate that MOBO-OSD
consistently outperforms the state-of-the-art algorithms. Our code
implementation can be found at https://github.com/LamNgo1/mobo-osd.

</details>


### [74] [Multimodal Negative Learning](https://arxiv.org/abs/2510.20877)
*Baoquan Gong,Xiyuan Gao,Pengfei Zhu,Qinghua Hu,Bing Cao*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为“负学习”（Negative Learning）的新范式，用以解决多模态学习中模态不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 在多模态学习系统中，经常会遇到模态不平衡的挑战，即主导模态可能会掩盖其他模态，从而阻碍弱模态的学习。传统的做法是让弱模态与主导模态对齐，但这可能会抑制弱模态固有的独特信息。

Method: 本文提出了一种“负学习”范式，主要模态会动态地引导弱模态抑制非目标类别，而不是增强弱模态的目标类别预测。文章从鲁棒性角度揭示了多模态学习，并理论推导了引入动态引导机制的“多模态负学习（MNL）”框架。

Result: 该方法通过增加单模态置信度裕度（UCoM），可证明地收紧了多模态学习的鲁棒性下限，并减少了弱模态的经验误差，特别是在噪声和不平衡场景下。代码将在https://github.com/BaoquanGong/Multimodal-Negative-Learning.git。

Conclusion: 广泛的实验证明了本文方法在多个基准测试中对于现有方法的有效性和通用性。

Abstract: Multimodal learning systems often encounter challenges related to modality
imbalance, where a dominant modality may overshadow others, thereby hindering
the learning of weak modalities. Conventional approaches often force weak
modalities to align with dominant ones in "Learning to be (the same)" (Positive
Learning), which risks suppressing the unique information inherent in the weak
modalities. To address this challenge, we offer a new learning paradigm:
"Learning Not to be" (Negative Learning). Instead of enhancing weak modalities'
target-class predictions, the dominant modalities dynamically guide the weak
modality to suppress non-target classes. This stabilizes the decision space and
preserves modality-specific information, allowing weak modalities to preserve
unique information without being over-aligned. We proceed to reveal multimodal
learning from a robustness perspective and theoretically derive the Multimodal
Negative Learning (MNL) framework, which introduces a dynamic guidance
mechanism tailored for negative learning. Our method provably tightens the
robustness lower bound of multimodal learning by increasing the Unimodal
Confidence Margin (UCoM) and reduces the empirical error of weak modalities,
particularly under noisy and imbalanced scenarios. Extensive experiments across
multiple benchmarks demonstrate the effectiveness and generalizability of our
approach against competing methods. The code will be available at
https://github.com/BaoquanGong/Multimodal-Negative-Learning.git.

</details>


### [75] [HA-RAG: Hotness-Aware RAG Acceleration via Mixed Precision and Data Placement](https://arxiv.org/abs/2510.20878)
*Danying Ge,Jianhua Gao,Yixue Yang,Weixing Ji*

Main category: cs.LG

TL;DR: 本文提出了一种名为HA-RAG的检索增强生成（RAG）推理优化系统，通过热度感知的混合精度压缩加载和数据放置策略，显著提高了TTFT速度。


<details>
  <summary>Details</summary>
Motivation: 解决RAG在处理长上下文时，由于引入外部知识库而导致的内存消耗和推理延迟问题。

Method: 1. 引入热度感知的混合精度压缩加载方法，利用KV块的数值分布来减少磁盘I/O和内存访问开销。2. 设计热度感知数据放置策略，优先将频繁访问的KV块存储在高速内存中，以提高数据访问效率。

Result: 与TurboRAG相比，HA-RAG在TTFT方面平均提速2.10倍，最大提速10.49倍，且准确率损失可忽略不计。

Conclusion: HA-RAG通过热度感知的方法有效优化了RAG的推理性能，显著提升了生成效率，同时保持了高准确率。

Abstract: Retrieval-Augmented Generation (RAG) improves model output accuracy by
leveraging external knowledge bases, serving as an effective solution to
address hallucination issues and knowledge-update delays in Large Language
Models (LLMs). However, the introduction of external knowledge bases presents
RAG with challenges in long-context processing, significantly increasing memory
consumption and inference latency. Existing research accelerates inference by
precomputing Key and Value (KV) of the knowledge base and loading them
on-demand during inference. Based on the access frequency of different KV
chunks within the external knowledge base, this paper proposes a hotness-aware
RAG (HA-RAG) inference optimization system. First, leveraging the numerical
distribution of KV chunks, we introduce a hotness-aware mixed-precision
compressing and loading method to reduce disk I/O and memory access overhead.
Second, we design a hotness-aware data placement strategy that prioritizes
storing frequently accessed KV chunks in high-speed memory to improve data
access efficiency. Experimental results demonstrate that, compared with
TurboRAG, the proposed HA-RAG achieves an average speedup of 2.10x and maximum
speedup of 10.49x in Time-To-First-Token (TTFT) with negligible accuracy loss.

</details>


### [76] [Global Dynamics of Heavy-Tailed SGDs in Nonconvex Loss Landscape: Characterization and Control](https://arxiv.org/abs/2510.20905)
*Xingyu Wang,Chang-Han Rhee*

Main category: cs.LG

TL;DR: 本文探讨了随机梯度下降的全局动力学，揭示了重尾SGD在避免尖锐局部最小值和提高泛化性能方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管SGD在现代AI中取得巨大成功，但理论理解滞后。传统观点认为SGD能避免尖锐局部最小值，且与泛化性能差相关。为了深入理解和增强SGD的这种能力，需要超越局部收敛分析，全面理解其全局动力学。

Method: 本文基于Wang和Rhee（2023）的最新大偏差和亚稳态分析，开发了一套技术机制，以精确描述重尾SGD的全局动力学。

Result: 研究发现，在训练过程中注入并截断重尾噪声，SGD几乎能完全避免尖锐局部最小值，从而提高测试数据的泛化性能。

Conclusion: 重尾SGD结合梯度裁剪能够找到几何形状更平坦的局部最小值，并实现更好的泛化性能。

Abstract: Stochastic gradient descent (SGD) and its variants enable modern artificial
intelligence. However, theoretical understanding lags far behind their
empirical success. It is widely believed that SGD has a curious ability to
avoid sharp local minima in the loss landscape, which are associated with poor
generalization. To unravel this mystery and further enhance such capability of
SGDs, it is imperative to go beyond the traditional local convergence analysis
and obtain a comprehensive understanding of SGDs' global dynamics. In this
paper, we develop a set of technical machinery based on the recent large
deviations and metastability analysis in Wang and Rhee (2023) and obtain sharp
characterization of the global dynamics of heavy-tailed SGDs. In particular, we
reveal a fascinating phenomenon in deep learning: by injecting and then
truncating heavy-tailed noises during the training phase, SGD can almost
completely avoid sharp minima and achieve better generalization performance for
the test data. Simulation and deep learning experiments confirm our theoretical
prediction that heavy-tailed SGD with gradient clipping finds local minima with
a more flat geometry and achieves better generalization performance.

</details>


### [77] [Learning from Interval Targets](https://arxiv.org/abs/2510.20925)
*Rattana Pukdee,Ziqi Ke,Chirag Gupta*

Main category: cs.LG

TL;DR: 这篇文章研究了区间目标回归问题，即目标值只有上限和下限。文章提出了两种方法：一种是使用兼容区间目标的损失函数，并建立了非渐近泛化界限；另一种是引入了一种新的最小-最大学习范式，并通过在目标区间内最大化最坏情况来最小化。


<details>
  <summary>Details</summary>
Motivation: 当精确的目标标签难以获取或无法获取时，例如由于固有的不确定性，就会出现目标值为区间形式的回归问题。在这种情况下，传统的回归损失函数无法使用。

Method: 1. 提出了一种兼容区间目标的损失函数，并基于假设类的平滑性建立了非渐近泛化界限，这显著地放宽了先前的可实现性和小模糊度假设。
2. 提出了一种新颖的最小-最大学习范式：在给定区间内对最坏情况（最大化）目标标签进行最小化。尽管最大化问题是非凸的，但通过引入平滑性约束可以实现良好的性能。

Result: 通过对真实世界数据集的广泛实验，证明了所提出的方法实现了最先进的性能。

Conclusion: 本文研究了区间目标回归问题，并提出了两种有效的方法，在真实世界数据集中取得了领先的性能。

Abstract: We study the problem of regression with interval targets, where only upper
and lower bounds on target values are available in the form of intervals. This
problem arises when the exact target label is expensive or impossible to
obtain, due to inherent uncertainties. In the absence of exact targets,
traditional regression loss functions cannot be used. First, we study the
methodology of using a loss functions compatible with interval targets, for
which we establish non-asymptotic generalization bounds based on smoothness of
the hypothesis class that significantly relaxing prior assumptions of
realizability and small ambiguity degree. Second, we propose a novel min-max
learning formulation: minimize against the worst-case (maximized) target labels
within the provided intervals. The maximization problem in the latter is
non-convex, but we show that good performance can be achieved with the
incorporation of smoothness constraints. Finally, we perform extensive
experiments on real-world datasets and show that our methods achieve
state-of-the-art performance.

</details>


### [78] [Meta-Learning for Cross-Task Generalization in Protein Mutation Property Prediction](https://arxiv.org/abs/2510.20943)
*Srivathsan Badrinarayanan,Yue Su,Janghoon Ock,Alan Pham,Sanya Ahuja,Amir Barati Farimani*

Main category: cs.LG

TL;DR: 本文提出了一种利用元学习（MAML）和新型突变编码策略来预测蛋白质突变性质的方法，该方法在跨数据集泛化方面优于传统微调，尤其在数据量有限的情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 目前的蛋白质突变预测方法依赖于对特定蛋白质的Transformer模型进行微调，但在跨数据集泛化方面表现不佳，原因在于实验条件异质性和有限的目标域数据。

Method: 本文引入了两项关键创新：1）首次将模型无关元学习（MAML）应用于蛋白质突变性质预测；2）提出了一种新的突变编码策略，利用分隔符标记将突变直接整合到序列上下文中。该方法在Transformer架构的基础上集成MAML，通过最少的梯度步长实现对新任务的快速适应，而不是学习数据集特定的模式。突变编码解决了标准Transformer将突变位置视为未知标记从而显著降低性能的限制。

Result: 在三个不同的蛋白质突变数据集（功能适应性、热稳定性和溶解度）上的评估表明，该方法与传统微调相比具有显著优势。在跨任务评估中，元学习方法在功能适应性方面实现了29%的精度提升，训练时间减少65%；在溶解度方面实现了94%的精度提升，训练速度提高了55%。该框架无论数据集大小如何，都能保持一致的训练效率。

Conclusion: 这项工作系统地将元学习应用于蛋白质突变分析，并引入了一种有效的突变编码策略，为蛋白质工程中的跨领域泛化提供了变革性的方法，特别适用于工业应用和实验数据有限的早期蛋白质设计。

Abstract: Protein mutations can have profound effects on biological function, making
accurate prediction of property changes critical for drug discovery, protein
engineering, and precision medicine. Current approaches rely on fine-tuning
protein-specific transformers for individual datasets, but struggle with
cross-dataset generalization due to heterogeneous experimental conditions and
limited target domain data. We introduce two key innovations: (1) the first
application of Model-Agnostic Meta-Learning (MAML) to protein mutation property
prediction, and (2) a novel mutation encoding strategy using separator tokens
to directly incorporate mutations into sequence context. We build upon
transformer architectures integrating them with MAML to enable rapid adaptation
to new tasks through minimal gradient steps rather than learning
dataset-specific patterns. Our mutation encoding addresses the critical
limitation where standard transformers treat mutation positions as unknown
tokens, significantly degrading performance. Evaluation across three diverse
protein mutation datasets (functional fitness, thermal stability, and
solubility) demonstrates significant advantages over traditional fine-tuning.
In cross-task evaluation, our meta-learning approach achieves 29% better
accuracy for functional fitness with 65% less training time, and 94% better
accuracy for solubility with 55% faster training. The framework maintains
consistent training efficiency regardless of dataset size, making it
particularly valuable for industrial applications and early-stage protein
design where experimental data is limited. This work establishes a systematic
application of meta-learning to protein mutation analysis and introduces an
effective mutation encoding strategy, offering transformative methodology for
cross-domain generalization in protein engineering.

</details>


### [79] [Amortized Active Generation of Pareto Sets](https://arxiv.org/abs/2510.21052)
*Daniel M. Steinberg,Asiri Wijesinghe,Rafael Oliveira,Piotr Koniusz,Cheng Soon Ong,Edwin V. Bonilla*

Main category: cs.LG

TL;DR: A-GPS是一个在线离散黑盒多目标优化框架，它学习Pareto集的生成模型，并支持用户偏好条件下的后验推断。


<details>
  <summary>Details</summary>
Motivation: 在离散黑盒多目标优化中，现有方法难以有效地结合用户偏好，并且需要进行显式的超体积计算。

Method: A-GPS利用类别概率估计器（CPE）预测非支配关系，并将生成模型引导到搜索空间的高性能区域。它引入偏好方向向量来编码用户偏好，并根据Pareto成员资格和偏好方向对模型进行迭代更新，从而在不重新训练的情况下对整个Pareto前沿进行采样。

Result: A-GPS能够实现高质量的Pareto集近似，避免了显式的超体积计算，并灵活地结合用户偏好。

Conclusion: A-GPS是一个简单而强大的多目标优化方法，在合成基准和蛋白质设计任务上表现出强大的样本效率和有效的偏好结合能力。

Abstract: We introduce active generation of Pareto sets (A-GPS), a new framework for
online discrete black-box multi-objective optimization (MOO). A-GPS learns a
generative model of the Pareto set that supports a-posteriori conditioning on
user preferences. The method employs a class probability estimator (CPE) to
predict non-dominance relations and to condition the generative model toward
high-performing regions of the search space. We also show that this
non-dominance CPE implicitly estimates the probability of hypervolume
improvement (PHVI). To incorporate subjective trade-offs, A-GPS introduces
preference direction vectors that encode user-specified preferences in
objective space. At each iteration, the model is updated using both Pareto
membership and alignment with these preference directions, producing an
amortized generative model capable of sampling across the Pareto front without
retraining. The result is a simple yet powerful approach that achieves
high-quality Pareto set approximations, avoids explicit hypervolume
computation, and flexibly captures user preferences. Empirical results on
synthetic benchmarks and protein design tasks demonstrate strong sample
efficiency and effective preference incorporation.

</details>


### [80] [Safety Assessment in Reinforcement Learning via Model Predictive Control](https://arxiv.org/abs/2510.20955)
*Jeff Pflueger,Michael Everett*

Main category: cs.LG

TL;DR: 该论文提出了一种新的方法，它利用可逆性来避免强化学习训练过程中的安全问题，且无需明确的动力学或安全约束知识。


<details>
  <summary>Details</summary>
Motivation: 传统的无模型强化学习方法虽然有潜力，但缺乏形式化的安全保障。现有的安全保障方法通常依赖于对安全规范的详细了解，但许多难以具体说明的安全问题最好通过不变性来描述。

Method: 本文提出利用可逆性作为在训练过程中防止安全问题的方法。它使用模型预测路径积分控制来检查学习策略提出的动作的安全性。该方法只需查询黑盒动力学模型，无需明确的动力学或安全约束知识。

Result: 实验结果表明，该算法能在所有不安全动作之前成功中止，并且与允许违反安全的基线PPO方法相比，训练进度PPO方法保持一致。

Conclusion: 本研究提出了一种有效的方法，通过利用可逆性，在强化学习的训练过程中避免安全问题，无需详细的安全规范知识，并且在保证安全性的前提下，保持了与现有方法相当的训练效果。

Abstract: Model-free reinforcement learning approaches are promising for control but
typically lack formal safety guarantees. Existing methods to shield or
otherwise provide these guarantees often rely on detailed knowledge of the
safety specifications. Instead, this work's insight is that many
difficult-to-specify safety issues are best characterized by invariance.
Accordingly, we propose to leverage reversibility as a method for preventing
these safety issues throughout the training process. Our method uses
model-predictive path integral control to check the safety of an action
proposed by a learned policy throughout training. A key advantage of this
approach is that it only requires the ability to query the black-box dynamics,
not explicit knowledge of the dynamics or safety constraints. Experimental
results demonstrate that the proposed algorithm successfully aborts before all
unsafe actions, while still achieving comparable training progress to a
baseline PPO approach that is allowed to violate safety.

</details>


### [81] [Reducing the Probability of Undesirable Outputs in Language Models Using Probabilistic Inference](https://arxiv.org/abs/2510.21184)
*Stephen Zhao,Aidan Li,Rob Brekelmans,Roger Grosse*

Main category: cs.LG

TL;DR: RePULSe通过结合标准RL损失和引导采样低奖励输出的新损失，改进了RL中平均奖励与不良输出概率之间的权衡，并提高了对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准强化学习方法在优化平均奖励的同时，通常会牺牲减少不良输出概率的性能。本文旨在改善这种权衡。

Method: 本文提出了一种名为RePULSe的新训练方法。该方法通过增加一个额外的损失来增强标准RL损失，这个额外损失利用学习到的提议来引导对低奖励输出的采样，从而降低这些输出的概率。

Result: 实验结果表明，与标准RL对齐方法和替代方案相比，RePULSe在预期奖励与不良输出概率之间取得了更好的权衡，并且具有更强的对抗鲁棒性。

Conclusion: RePULSe通过引入新的损失项，成功改善了强化学习中平均奖励与不良输出概率的权衡，并提高了模型的对抗鲁棒性。

Abstract: Reinforcement learning (RL) has become a predominant technique to align
language models (LMs) with human preferences or promote outputs which are
deemed to be desirable by a given reward function. Standard RL approaches
optimize average reward, while methods explicitly focused on reducing the
probability of undesired outputs typically come at a cost to average-case
performance. To improve this tradeoff, we introduce RePULSe, a new training
method that augments the standard RL loss with an additional loss that uses
learned proposals to guide sampling low-reward outputs, and then reduces those
outputs' probability. We run experiments demonstrating that RePULSe produces a
better tradeoff of expected reward versus the probability of undesired outputs
and is more adversarially robust, compared to standard RL alignment approaches
and alternatives.

</details>


### [82] [An Ensembled Penalized Federated Learning Framework for Falling People Detection](https://arxiv.org/abs/2510.20960)
*Sizhe Rao,Runqiu Zhang,Sajal Saha,Liang Chen*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为EPFL的集成惩罚联邦学习框架，用于跌倒检测，该框架通过结合持续学习、个性化建模和一种新颖的专门加权聚合策略，解决了传统方法的局限性，实现了高召回率和F1分数，同时保护了用户隐私。


<details>
  <summary>Details</summary>
Motivation: 跌倒在老年人和残障人士中是导致受伤和死亡的主要原因，因此需要强大、准确且注重隐私的跌倒检测系统。传统的跌倒检测方法面临泛化能力有限、数据隐私问题以及个体运动行为变异性等挑战。

Method: 本文提出了EPFL——一个集成了持续学习、个性化建模和新颖的专门加权聚合（SWA）策略的集成惩罚联邦学习框架。EPFL利用可穿戴传感器数据捕捉序列运动模式，并通过同态加密和联邦训练保护用户隐私。与现有联邦模型不同，EPFL结合了惩罚性的本地训练和基于集成的推理，以改善客户端间的一致性并适应行为差异。

Result: 在基准跌倒检测数据集上的大量实验表明，该方法有效，召回率达到88.31%，F1分数达到89.94%，显著优于集中式和基线模型。

Conclusion: EPFL为医疗保健环境中的现实世界跌倒检测提供了一个可扩展、安全且准确的解决方案，并通过其自适应反馈机制，具有持续改进的巨大潜力。

Abstract: Falls among elderly and disabled individuals remain a leading cause of injury
and mortality worldwide, necessitating robust, accurate, and privacy-aware fall
detection systems. Traditional fall detection approaches, whether centralized
or point-wise, often struggle with key challenges such as limited
generalizability, data privacy concerns, and variability in individual movement
behaviors. To address these limitations, we propose EPFL-an Ensembled Penalized
Federated Learning framework that integrates continual learning, personalized
modeling, and a novel Specialized Weighted Aggregation (SWA) strategy. EPFL
leverages wearable sensor data to capture sequential motion patterns while
preserving user privacy through homomorphic encryption and federated training.
Unlike existing federated models, EPFL incorporates both penalized local
training and ensemble-based inference to improve inter-client consistency and
adaptability to behavioral differences. Extensive experiments on a benchmark
fall detection dataset demonstrate the effectiveness of our approach, achieving
a Recall of 88.31 percent and an F1-score of 89.94 percent, significantly
outperforming both centralized and baseline models. This work presents a
scalable, secure, and accurate solution for real-world fall detection in
healthcare settings, with strong potential for continuous improvement via its
adaptive feedback mechanism.

</details>


### [83] [Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection](https://arxiv.org/abs/2510.20963)
*Yongqiang Chen,Gang Niu,James Cheng,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 本文提出了一种名为ColMAD的协作多智能体辩论协议，通过改进辩论框架和鼓励智能体间的支持性批评，显著提升了大型语言模型错误检测的准确性，解决了以往竞争性多智能体辩论中存在的“辩论攻击”问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型响应中的错误检测对于实现可扩展监督至关重要，但LLM的自我诊断往往不可靠。多智能体辩论（MAD）是一种有前景的替代方案，但之前的协议将辩论视为零和游戏，导致智能体进行“辩论攻击”，引入更多错误并表现不佳。

Method: 本文提出了一种新的协作式多智能体辩论（ColMAD）协议。ColMAD将多智能体辩论重新定义为非零和游戏，鼓励多个智能体以支持性的方式相互批评，从而互补彼此缺失的观点。

Result: ColMAD在错误检测方面的表现显著优于以往的竞争性MAD协议19%，并且相对于单智能体方法也有了显著改进。

Conclusion: ColMAD协议通过协作和支持性批评，有效解决了以往多智能体辩论的局限性，显著提高了大型语言模型错误检测的准确性，为可扩展监督提供了更可靠的工具。

Abstract: Accurate detection of errors in large language models (LLM) responses is
central to the success of scalable oversight, or providing effective
supervision to superhuman intelligence. Yet, self-diagnosis is often unreliable
on complex tasks unless aided by reliable external feedback. Multi-agent debate
(MAD) seems to be a natural alternative to external feedback: multiple LLMs
provide complementary perspectives and cross-checks for error detection.
However, prior MAD protocols frame debate as a zero-sum game, where the
debaters compete to win the game instead of seeking the truth. Consequently, it
leads to debate hacking: debaters tend to mislead the judge by misinterpreting
the task or presenting overconfident claims, which introduce more mistakes and
underperform single-agent methods. To mitigate the issue, we introduce a new
collaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum
game. Specifically, ColMAD encourages multiple agents to criticize each other
in a supportive way, such that they can complement the missing points of each
other. Therefore, the judge agent can make a more informative conclusion based
on more comprehensive evidence. Empirically, we show that ColMAD significantly
outperforms previous competitive MAD by 19% and brings non-trivial improvements
over single-agent methods in error detection.

</details>


### [84] [A Convergence Analysis of Adaptive Optimizers under Floating-point Quantization](https://arxiv.org/abs/2510.21314)
*Xuan Tang,Jichu Li,Difan Zou*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种分析自适应优化器（如Adam和Muon）在浮点量化下的收敛性的理论框架。


<details>
  <summary>Details</summary>
Motivation: 现有自适应优化器的收敛理论忽略了硬件感知量化，无法解释低精度训练的有效性。

Method: 本文在平滑非凸目标函数和标准随机梯度假设下，推导了自适应优化器的收敛速度，并明确量化了不同组件的量化误差如何影响收敛。

Result: Adam和Muon算法在浮点量化下保持与其全精度版本相近的收敛速度，但Adam对权重和二阶矩量化高度敏感，而Muon则需要较弱的误差控制，可能更鲁棒。

Conclusion: 这项研究缩小了低精度训练方法的实证成功与理论理解之间的差距。

Abstract: The rapid scaling of large language models (LLMs) has made low-precision
training essential for reducing memory, improving efficiency, and enabling
larger models and datasets. Existing convergence theories for adaptive
optimizers, however, assume all components are exact and neglect hardware-aware
quantization, leaving open the question of why low-precision training remains
effective. We introduce the first theoretical framework for analyzing the
convergence of adaptive optimizers, including Adam and Muon, under
floating-point quantization of gradients, weights, and optimizer states (e.g.,
moment estimates). Within this framework, we derive convergence rates on smooth
non-convex objectives under standard stochastic gradient assumptions,
explicitly characterizing how quantization errors from different components
affect convergence. We show that both algorithms retain rates close to their
full-precision counterparts provided mantissa length scales only
logarithmically with the number of iterations. Our analysis further reveals
that Adam is highly sensitive to weights and second-moment quantization due to
its reliance on $\beta_2 \to 1$, while Muon requires weaker error control and
is thus potentially more robust. These results narrow the gap between empirical
success and theoretical understanding of low-precision training methods.
Numerical experiments on synthetic and real-world data corroborate our theory.

</details>


### [85] [Weak-to-Strong Generalization under Distribution Shifts](https://arxiv.org/abs/2510.21332)
*Myeongho Jeon,Jan Sobotka,Suhwan Choi,Maria Brbić*

Main category: cs.LG

TL;DR: 本文提出RAVEN框架，旨在解决在分布偏移下弱监督强模型泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 在大模型日益复杂的未来，准确监督其行为可能超出人类能力。弱模型可以有效监督强模型，但这种弱监督强泛化在分布偏移下会失败。

Method: RAVEN框架在学习强模型参数的同时，动态学习弱模型的最佳组合。

Result: RAVEN在OOD任务上SOTA，性能优于当前基线30%以上，在ID任务上与现有方法匹配或超越。RAVEN会给更准确的弱模型分配更高的权重，证明其能自动识别值得信赖的监督。

Conclusion: RAVEN框架通过动态学习弱模型的最佳组合，解决了弱监督强泛化在分布偏移下的失败问题，显著提升了模型性能。

Abstract: As future superhuman models become increasingly complex, accurately
supervising their behavior may exceed human capabilities. Recent works have
demonstrated that in such scenarios, weak models can effectively supervise
strong models, a phenomenon known as weak-to-strong generalization. However, we
find that naive weak-to-strong generalization fails under distribution shifts,
often leading to worse performance of the strong model than its weak
supervisors. To address this, we propose RAVEN, a robust weak-to-strong
generalization framework that dynamically learns the optimal combinations of
weak models in addition to parameters of the strong model. We demonstrate the
effectiveness of RAVEN on image classification, text classification, and
preference alignment tasks. RAVEN outperforms alternative baselines by over 30%
on out-of-distribution tasks while matching or surpassing existing methods on
in-distribution tasks. Moreover, our results show that RAVEN assigns higher
weights to more accurate weak models, demonstrating its ability to
automatically identify trustworthy supervision.

</details>


### [86] [On the accuracy of implicit neural representations for cardiovascular anatomies and hemodynamic fields](https://arxiv.org/abs/2510.20970)
*Jubilee Lee,Daniele E. Schiavazzi*

Main category: cs.LG

TL;DR: 该论文评估了隐式神经表示（INRs）在压缩血流动力学场和表示心血管解剖结构方面的性能。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示（INRs）在知识表示、合成和压缩方面具有强大潜力，但其在特定领域应用中的准确性尚不明确。

Method: 本研究评估了最先进的INRs在压缩从数值模拟中获得的血流动力学场以及通过有符号距离函数表示心血管解剖结构方面的性能。研究了几种策略来减轻频谱偏差，包括专门的激活函数、固定和可训练的位置编码以及非线性核的线性组合。

Result: 在胸主动脉中，INRs在不进行大量超参数调整的情况下，实现了高达约230的显著压缩比，压力最大绝对误差为1毫米汞柱，速度最大绝对误差为5-10厘米/秒。在48个胸主动脉解剖结构中，平均和最大绝对解剖差异分别低于0.5毫米和1.6毫米。SIREN、MFN-Gabor和MHE架构表现出最佳性能。

Conclusion: 隐式神经表示（INRs）在压缩血流动力学场和表示心血管解剖结构方面表现出色，具有高压缩比和低误差。其中SIREN、MFN-Gabor和MHE架构效果最好。

Abstract: Implicit neural representations (INRs, also known as neural fields) have
recently emerged as a powerful framework for knowledge representation,
synthesis, and compression. By encoding fields as continuous functions within
the weights and biases of deep neural networks-rather than relying on voxel- or
mesh-based structured or unstructured representations-INRs offer both
resolution independence and high memory efficiency. However, their accuracy in
domain-specific applications remains insufficiently understood. In this work,
we assess the performance of state-of-the-art INRs for compressing hemodynamic
fields derived from numerical simulations and for representing cardiovascular
anatomies via signed distance functions. We investigate several strategies to
mitigate spectral bias, including specialized activation functions, both fixed
and trainable positional encoding, and linear combinations of nonlinear
kernels. On realistic, space- and time-varying hemodynamic fields in the
thoracic aorta, INRs achieved remarkable compression ratios of up to
approximately 230, with maximum absolute errors of 1 mmHg for pressure and 5-10
cm/s for velocity, without extensive hyperparameter tuning. Across 48 thoracic
aortic anatomies, the average and maximum absolute anatomical discrepancies
were below 0.5 mm and 1.6 mm, respectively. Overall, the SIREN, MFN-Gabor, and
MHE architectures demonstrated the best performance. Source code and data is
available at https://github.com/desResLab/nrf.

</details>


### [87] [$α$-LoRA: Effective Fine-Tuning via Base Model Rescaling](https://arxiv.org/abs/2510.21345)
*Aymane El Firdoussi,El Mahdi Chayti,Mohamed El Amine Seddik,Martin Jaggi*

Main category: cs.LG

TL;DR: 本文介绍了一种新的参数重构方法，旨在提高微调模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 微调，尤其是重参数化方法，在用少量数据使预训练模型适应新任务方面表现出色。LoRA是一个著名的例子。然而，现有的方法可能在泛化能力方面仍有提升空间。作者旨在引入一类新的重参数化方法来解决这个问题。

Method: 通过引入一类新的重参数化方法，该方法通过用额外的可训练权重矩阵增强冻结的权重矩阵来更新目标模块。作者利用随机矩阵理论在高维二进制分类设置中验证了该方法的有效性，并通过微调大型语言模型等更实际的实验来验证其理论发现。

Result: 作者声称他们的方法提高了微调模型的泛化能力。

Conclusion: 作者提出了一种新的重参数化方法，该方法在理论和实践中都被证明可以增强微调模型的泛化能力。

Abstract: Fine-tuning has proven to be highly effective in adapting pre-trained models
to perform better on new desired tasks with minimal data samples. Among the
most widely used approaches are reparameterization methods, which update a
target module by augmenting its frozen weight matrix with an additional
trainable weight matrix. The most prominent example is Low Rank Adaption
(LoRA), which gained significant attention in recent years. In this paper, we
introduce a new class of reparameterization methods for transfer learning,
designed to enhance the generalization ability of fine-tuned models. We
establish the effectiveness of our approach in a high-dimensional binary
classification setting using tools from Random Matrix Theory, and further
validate our theoretical findings through more realistic experiments, such as
fine-tuning LLMs.

</details>


### [88] [L^2M^3OF: A Large Language Multimodal Model for Metal-Organic Frameworks](https://arxiv.org/abs/2510.20976)
*Jiyu Cui,Fang Wu,Haokai Zhao,Minggao Feng,Xenophon Evangelopoulos,Andrew I. Cooper,Yejin Choi*

Main category: cs.LG

TL;DR: L2M3OF是第一个用于MOFs的多模态大型语言模型，它通过整合晶体表示学习和语言理解来处理结构、文本和知识模态，在材料发现方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 理解复杂的物理现象，例如MOFs的设计，需要超越单一语言表示的多方面表示。MOF的设计空间巨大且复杂，传统的基于语言的LLM难以处理。为了克服这一障碍，作者提出了L2M3OF。

Method: L2M3OF整合了晶体表示学习和语言理解，可以共同处理结构、文本和知识模态。它使用预训练的晶体编码器和一个轻量级投影层将结构信息压缩到token空间，以实现与语言指令的有效对齐。作者还整理了一个晶体材料的结构-性质-知识数据库进行训练和评估。

Result: L2M3OF在性质预测和知识生成任务中优于领先的基于文本的闭源LLM（如GPT-5、Gemini-2.5-Pro和DeepSeek-R1），尽管其参数数量少得多。

Conclusion: 多模态方法对于理解多孔材料非常重要，L2M3OF为材料发现领域的下一代AI系统奠定了基础。

Abstract: Large language models have demonstrated remarkable reasoning capabilities
across diverse natural language tasks. However, comparable breakthroughs in
scientific discovery are more limited, because understanding complex physical
phenomena demands multifaceted representations far beyond language alone. A
compelling example is the design of functional materials such as MOFs-critical
for a range of impactful applications like carbon capture and hydrogen storage.
Navigating their vast and intricate design space in language-based
representations interpretable by LLMs is challenging due to the numerous
possible three-dimensional atomic arrangements and strict reticular rules of
coordination geometry and topology. Despite promising early results in
LLM-assisted discovery for simpler materials systems, MOF design remains
heavily reliant on tacit human expertise rarely codified in textual information
alone. To overcome this barrier, we introduce L2M3OF, the first multimodal LLM
for MOFs. L2M3OF integrates crystal representation learning with language
understanding to process structural, textual, and knowledge modalities jointly.
L2M3OF employs a pre-trained crystal encoder with a lightweight projection
layer to compress structural information into a token space, enabling efficient
alignment with language instructions. To facilitate training and evaluation, we
curate a structure-property-knowledge database of crystalline materials and
benchmark L2M3OF against state-of-the-art closed-source LLMs such as GPT-5,
Gemini-2.5-Pro and DeepSeek-R1. Experiments show that L2M3OF outperforms
leading text-based closed-source LLMs in property prediction and knowledge
generation tasks, despite using far fewer parameters. These results highlight
the importance of multimodal approaches for porous material understanding and
establish L2M3OF as a foundation for next-generation AI systems in materials
discovery.

</details>


### [89] [Benchmarking Catastrophic Forgetting Mitigation Methods in Federated Time Series Forecasting](https://arxiv.org/abs/2510.21491)
*Khaled Hallak,Oudom Kem*

Main category: cs.LG

TL;DR: 本文介绍了第一个针对联邦持续时间序列预测中灾难性遗忘的基准测试框架，并评估了多种遗忘缓解策略。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习环境中，非独立同分布时间序列数据中的灾难性遗忘是一个持续的挑战，而现有研究主要集中在视觉领域的分类任务，回归预测设置（物联网和边缘应用中普遍存在）仍未得到充分探索。

Method: 本文提出了第一个专门用于研究联邦持续时间序列预测中灾难性遗忘的基准测试框架。使用北京多站点空气质量数据集（跨越12个去中心化客户端），系统评估了几种灾难性遗忘缓解策略，包括重放、弹性权重整合、无遗忘学习和突触智能。

Result: 本文引入了一个用于时间序列联邦学习中灾难性遗忘的新基准，对最先进的方法进行了全面的比较分析，并发布了一个可复现的开源框架。

Conclusion: 这项工作为推进联邦时间序列预测系统中的持续学习提供了必要的工具和见解。

Abstract: Catastrophic forgetting (CF) poses a persistent challenge in continual
learning (CL), especially within federated learning (FL) environments
characterized by non-i.i.d. time series data. While existing research has
largely focused on classification tasks in vision domains, the regression-based
forecasting setting prevalent in IoT and edge applications remains
underexplored. In this paper, we present the first benchmarking framework
tailored to investigate CF in federated continual time series forecasting.
Using the Beijing Multi-site Air Quality dataset across 12 decentralized
clients, we systematically evaluate several CF mitigation strategies, including
Replay, Elastic Weight Consolidation, Learning without Forgetting, and Synaptic
Intelligence. Key contributions include: (i) introducing a new benchmark for CF
in time series FL, (ii) conducting a comprehensive comparative analysis of
state-of-the-art methods, and (iii) releasing a reproducible open-source
framework. This work provides essential tools and insights for advancing
continual learning in federated time-series forecasting systems.

</details>


### [90] [Learning Grouped Lattice Vector Quantizers for Low-Bit LLM Compression](https://arxiv.org/abs/2510.20984)
*Xi Zhang,Xiaolin Wu,Jiamang Wang,Weisi Lin*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为GLVQ（Grouped Lattice Vector Quantization）的新型后训练量化框架，它通过为每组权重定制晶格码本，有效减少了大型语言模型推理所需的计算资源和内存，同时在模型大小和准确性之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理时需要大量的计算资源和内存。现有的后训练量化（PTQ）方法，特别是在低比特设置下，常导致显著的性能下降。

Method: 本文提出了一种分组晶格矢量量化（GLVQ）框架。该方法为每组权重分配一个定制的晶格码本，码本由一个可学习的生成矩阵定义。为了解决量化过程的不可微问题，训练过程中采用Babai舍入来近似最近晶格点搜索，这使得生成矩阵的优化更加稳定。训练完成后，解码过程简化为简单的矩阵向量乘法。

Result: 在多个基准测试上的实验表明，GLVQ方法在模型大小和准确性之间取得了比现有PTQ基线更好的平衡。

Conclusion: GLVQ框架提供了一个高效且实用的量化方案，可以有效地在资源受限的环境中部署大型模型。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities but
typically require extensive computational resources and memory for inference.
Post-training quantization (PTQ) can effectively reduce these demands by
storing weights in lower bit-width formats. However, standard uniform
quantization often leads to notable performance degradation, particularly in
low-bit scenarios. In this work, we introduce a Grouped Lattice Vector
Quantization (GLVQ) framework that assigns each group of weights a customized
lattice codebook, defined by a learnable generation matrix. To address the
non-differentiability of the quantization process, we adopt Babai rounding to
approximate nearest-lattice-point search during training, which enables stable
optimization of the generation matrices. Once trained, decoding reduces to a
simple matrix-vector multiplication, yielding an efficient and practical
quantization pipeline. Experiments on multiple benchmarks show that our
approach achieves a better trade-off between model size and accuracy compared
to existing post-training quantization baselines, highlighting its
effectiveness in deploying large models under stringent resource constraints.
Our source code is available on GitHub repository:
https://github.com/xzhang9308/GLVQ.

</details>


### [91] [Few-Shot Knowledge Distillation of LLMs With Counterfactual Explanations](https://arxiv.org/abs/2510.21631)
*Faisal Hamman,Pasan Dissanayake,Yanjun Fu,Sanghamitra Dutta*

Main category: cs.LG

TL;DR: 本文介绍了一种名为CoD的策略，通过反事实解释（CFEs）来提高少样本任务感知知识蒸馏的性能，解决了现有方法需要大量数据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的任务感知知识蒸馏方法通常需要大量的数据，这在许多实际场景中可能无法获得或获取成本高昂。

Method: 本文提出了一种名为反事实解释注入蒸馏（CoD）的新策略，用于少样本任务感知知识蒸馏。CoD利用反事实解释（CFEs）来精确映射教师模型的决策边界。

Result: CoD在各种数据集和LLM上的实验表明，在少样本（低至8-512个样本）情况下，其性能优于标准蒸馏方法。值得注意的是，CoD仅使用基线模型所用原始样本的一半，并结合相应的CFE，仍然能提高性能。

Conclusion: 反事实解释（CFEs）在知识蒸馏中发挥着重要作用，通过提供决策边界附近的信息性样本，从统计和几何角度提高了参数估计，并帮助学生模型更有效地模仿教师模型的决策边界。

Abstract: Knowledge distillation is a promising approach to transfer capabilities from
complex teacher models to smaller, resource-efficient student models that can
be deployed easily, particularly in task-aware scenarios. However, existing
methods of task-aware distillation typically require substantial quantities of
data which may be unavailable or expensive to obtain in many practical
scenarios. In this paper, we address this challenge by introducing a novel
strategy called Counterfactual-explanation-infused Distillation CoD for
few-shot task-aware knowledge distillation by systematically infusing
counterfactual explanations. Counterfactual explanations (CFEs) refer to inputs
that can flip the output prediction of the teacher model with minimum
perturbation. Our strategy CoD leverages these CFEs to precisely map the
teacher's decision boundary with significantly fewer samples. We provide
theoretical guarantees for motivating the role of CFEs in distillation, from
both statistical and geometric perspectives. We mathematically show that CFEs
can improve parameter estimation by providing more informative examples near
the teacher's decision boundary. We also derive geometric insights on how CFEs
effectively act as knowledge probes, helping the students mimic the teacher's
decision boundaries more effectively than standard data. We perform experiments
across various datasets and LLMs to show that CoD outperforms standard
distillation approaches in few-shot regimes (as low as 8-512 samples). Notably,
CoD only uses half of the original samples used by the baselines, paired with
their corresponding CFEs and still improves performance.

</details>


### [92] [GPU Memory Requirement Prediction for Deep Learning Task Based on Bidirectional Gated Recurrent Unit Optimization Transformer](https://arxiv.org/abs/2510.20985)
*Chao Wang,Zhizhao Wen,Ruoxin Zhang,Puyang Xu,Yifan Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种结合BiGRU优化的Transformer模型，用于准确预测深度学习任务中的GPU内存需求，实验证明其预测精度显著优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习任务中GPU内存资源准确预测的日益关键的需求。

Method: 提出了一种深度学习模型，该模型集成了双向门控循环单元（BiGRU）来优化Transformer架构，旨在提高内存需求预测的准确性。

Result: 在平均平方误差（MSE）和均方根误差（RMSE）方面，该模型在所有比较模型中取得了最低值；在平均绝对误差（MAE）和决定系数（R2）指标方面也表现良好，结果平衡稳定。其综合预测性能远超基准机器学习方法。

Conclusion: 本研究成功构建的基于双向门控循环单元优化的Transformer模型能够高效准确地完成深度学习任务中的GPU内存需求预测任务，预测精度较传统机器学习方法有显著提高。该研究为优化深度学习任务的资源调度和管理、提高计算集群的利用效率提供了强有力的技术支持和可靠的理论依据。

Abstract: In response to the increasingly critical demand for accurate prediction of
GPU memory resources in deep learning tasks, this paper deeply analyzes the
current research status and innovatively proposes a deep learning model that
integrates bidirectional gated recurrent units (BiGRU) to optimize the
Transformer architecture, aiming to improve the accuracy of memory demand
prediction. To verify the effectiveness of the model, a carefully designed
comparative experiment was conducted, selecting four representative basic
machine learning models: decision tree, random forest, Adaboost, and XGBoost as
benchmarks. The detailed experimental results show that the BiGRU Transformer
optimization model proposed in this paper exhibits significant advantages in
key evaluation indicators: in terms of mean square error (MSE) and root mean
square error (RMSE), the model achieves the lowest value among all comparison
models, and its predicted results have the smallest deviation from the actual
values; In terms of mean absolute error (MAE) and coefficient of determination
(R2) indicators, the model also performs well and the results are balanced and
stable, with comprehensive predictive performance far exceeding the benchmark
machine learning methods compared. In summary, the Transformer model based on
bidirectional gated recurrent unit optimization successfully constructed in
this study can efficiently and accurately complete GPU memory demand prediction
tasks in deep learning tasks, and its prediction accuracy has been
significantly improved compared to traditional machine learning methods. This
research provides strong technical support and reliable theoretical basis for
optimizing resource scheduling and management of deep learning tasks, and
improving the utilization efficiency of computing clusters.

</details>


### [93] [Optimal Graph Clustering without Edge Density Signals](https://arxiv.org/abs/2510.21669)
*Maximilien Dreveton,Elaine Siyu Liu,Matthias Grossglauser,Patrick Thiran*

Main category: cs.LG

TL;DR: 本文描述了在PABM模型下，图聚类的理论极限，解决了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有模型（SBM和DCBM）在处理非均匀顶点度方面存在的局限性，本文引入了PABM模型，该模型为集群内部和集群之间的连接引入了独立的流行度参数。

Method: 本文通过表征PABM下的最优聚类错误率，研究了聚类在PABM模型下的理论极限。

Result: 研究结果表明，与SBM和DCBM不同，即使在传统边缘密度信号消失的情况下，只要集群内部和集群之间的流行度系数不同，PABM模型仍能实现集群恢复。这表明PABM模型捕捉到的度异构性维度是DCBM模型所忽视的：连接模式的局部差异可以独立于全局边缘密度提高集群的可分离性。此外，PABM模型的预期邻接矩阵的秩在k到k^2之间，这意味着基于前k个特征向量的谱嵌入可能无法捕捉重要的结构信息。

Conclusion: 总的来说，PABM模型在处理图聚类问题上具有更强的能力，尤其是在存在度异构性的情况下。数值实验也证实了包含k^2个特征向量的谱聚类算法优于传统的谱方法，这为未来的图聚类研究提供了新的方向。

Abstract: This paper establishes the theoretical limits of graph clustering under the
Popularity-Adjusted Block Model (PABM), addressing limitations of existing
models. In contrast to the Stochastic Block Model (SBM), which assumes uniform
vertex degrees, and to the Degree-Corrected Block Model (DCBM), which applies
uniform degree corrections across clusters, PABM introduces separate popularity
parameters for intra- and inter-cluster connections. Our main contribution is
the characterization of the optimal error rate for clustering under PABM, which
provides novel insights on clustering hardness: we demonstrate that unlike SBM
and DCBM, cluster recovery remains possible in PABM even when traditional
edge-density signals vanish, provided intra- and inter-cluster popularity
coefficients differ. This highlights a dimension of degree heterogeneity
captured by PABM but overlooked by DCBM: local differences in connectivity
patterns can enhance cluster separability independently of global edge
densities. Finally, because PABM exhibits a richer structure, its expected
adjacency matrix has rank between $k$ and $k^2$, where $k$ is the number of
clusters. As a result, spectral embeddings based on the top $k$ eigenvectors
may fail to capture important structural information. Our numerical experiments
on both synthetic and real datasets confirm that spectral clustering algorithms
incorporating $k^2$ eigenvectors outperform traditional spectral approaches.

</details>


### [94] [AL-CoLe: Augmented Lagrangian for Constrained Learning](https://arxiv.org/abs/2510.20995)
*Ignacio Boero,Ignacio Hounie,Alejandro Ribeiro*

Main category: cs.LG

TL;DR: 该论文探讨了在机器学习中应用增广拉格朗日方法来解决带约束的学习问题，尤其是在非凸设置下。


<details>
  <summary>Details</summary>
Motivation: 传统的拉格朗日对偶性在非凸机器学习参数化中应用广泛，但是存在对偶间隙问题。增广拉格朗日方法可以在非凸设置下减轻对偶间隙，且所需修改最少，但在带约束的学习设置中探索不足。

Method: 本文建立了在温和条件下的强对偶结果，证明了对偶上升算法收敛到可行且最优的原始解，并提供了PAC风格的泛化保证。

Result: 增广拉格朗日方法能够有效地解决公平性约束分类任务。

Conclusion: 增广拉格朗日方法为解决带约束的机器学习问题，特别是在非凸设置下，提供了一种有效且理论支持的方法。

Abstract: Despite the non-convexity of most modern machine learning parameterizations,
Lagrangian duality has become a popular tool for addressing constrained
learning problems. We revisit Augmented Lagrangian methods, which aim to
mitigate the duality gap in non-convex settings while requiring only minimal
modifications, and have remained comparably unexplored in constrained learning
settings. We establish strong duality results under mild conditions, prove
convergence of dual ascent algorithms to feasible and optimal primal solutions,
and provide PAC-style generalization guarantees. Finally, we demonstrate its
effectiveness on fairness constrained classification tasks.

</details>


### [95] [Equivariance by Contrast: Identifiable Equivariant Embeddings from Unlabeled Finite Group Actions](https://arxiv.org/abs/2510.21706)
*Tobias Schmidt,Steffen Schneider,Matthias Bethge*

Main category: cs.LG

TL;DR: 本文提出了Equivariance by Contrast (EbC) 方法，通过观测数据对学习等变嵌入，该方法能够共同学习潜在空间和群表示，并在多种数据集上验证了其有效性，实现了高保真度等变性。


<details>
  <summary>Details</summary>
Motivation: 在没有群特定归纳偏差的情况下，EbC方法旨在从观测数据对中学习等变嵌入。

Method: EbC方法通过同时学习一个潜在空间和一个群表示来实现“等变”，其中群作用对应于可逆线性映射。

Result: 学习到的嵌入展现出高保真度等变性，群操作在潜在空间中得到了忠实再现。在合成数据上，EbC方法在非阿贝尔正交群O(n)和一般线性群GL(n)上均表现良好。

Conclusion: EbC方法首次成功地展示了仅从群作用观测中进行通用编码器等变学习，包括非平凡非阿贝尔群和受计算机视觉中仿射等变性建模启发的乘积群。

Abstract: We propose Equivariance by Contrast (EbC) to learn equivariant embeddings
from observation pairs $(\mathbf{y}, g \cdot \mathbf{y})$, where $g$ is drawn
from a finite group acting on the data. Our method jointly learns a latent
space and a group representation in which group actions correspond to
invertible linear maps -- without relying on group-specific inductive biases.
We validate our approach on the infinite dSprites dataset with structured
transformations defined by the finite group $G:= (R_m \times \mathbb{Z}_n
\times \mathbb{Z}_n)$, combining discrete rotations and periodic translations.
The resulting embeddings exhibit high-fidelity equivariance, with group
operations faithfully reproduced in latent space. On synthetic data, we further
validate the approach on the non-abelian orthogonal group $O(n)$ and the
general linear group $GL(n)$. We also provide a theoretical proof for
identifiability. While broad evaluation across diverse group types on
real-world data remains future work, our results constitute the first
successful demonstration of general-purpose encoder-only equivariant learning
from group action observations alone, including non-trivial non-abelian groups
and a product group motivated by modeling affine equivariances in computer
vision.

</details>


### [96] [Fair Representation Learning with Controllable High Confidence Guarantees via Adversarial Inference](https://arxiv.org/abs/2510.21017)
*Yuhong Luo,Austin Hoag,Xintong Wang,Philip S. Thomas,Przemyslaw A. Grabowicz*

Main category: cs.LG

TL;DR: 该文章旨在解决将表示学习推广到多个下游任务时，如何确保表示学习公平性的问题。


<details>
  <summary>Details</summary>
Motivation: 为了防止下游任务中出现针对特定人群的不公平现象，在表示学习中确保公平性保障至关重要。

Method: 本文提出了一种名为FRG（Fair Representation learning with high-confidence Guarantees）的框架，该框架利用优化的对抗模型，通过确保下游预测中的人口差异以可控的高概率保持在用户定义的误差阈值$\epsilon$内，从而提供高置信度的公平性保证。

Result: FRG框架在三个真实世界的数据集上进行了实验评估，并与六种最先进的公平表示学习方法进行了比较。结果表明，FRG在各种下游模型和任务中始终能限制不公平性。

Conclusion: FRG框架通过利用优化的对抗模型，在表示学习中实现了高置信度的公平性保证，有效地防止了下游任务中针对特定人群的不公平现象。

Abstract: Representation learning is increasingly applied to generate representations
that generalize well across multiple downstream tasks. Ensuring fairness
guarantees in representation learning is crucial to prevent unfairness toward
specific demographic groups in downstream tasks. In this work, we formally
introduce the task of learning representations that achieve high-confidence
fairness. We aim to guarantee that demographic disparity in every downstream
prediction remains bounded by a *user-defined* error threshold $\epsilon$, with
*controllable* high probability. To this end, we propose the ***F**air
**R**epresentation learning with high-confidence **G**uarantees (FRG)*
framework, which provides these high-confidence fairness guarantees by
leveraging an optimized adversarial model. We empirically evaluate FRG on three
real-world datasets, comparing its performance to six state-of-the-art fair
representation learning methods. Our results demonstrate that FRG consistently
bounds unfairness across a range of downstream models and tasks.

</details>


### [97] [More Than Memory Savings: Zeroth-Order Optimization Mitigates Forgetting in Continual Learning](https://arxiv.org/abs/2510.21019)
*Wanhao Yu,Zheng Wang,Shuteng Niu,Sen Lin,Li Yang*

Main category: cs.LG

TL;DR: 该文探讨了零阶（ZO）优化在持续学习（CL）中作为解决可塑性-稳定性-效率困境的新方法。


<details>
  <summary>Details</summary>
Motivation: 探索零阶（ZO）优化在持续学习（CL）中作为解决可塑性-稳定性-效率困境的新方法。

Method: 通过理论分析和实证证据，研究ZO优化如何自然地导致更平坦的损失景观，从而减少持续学习中的遗忘。提出了ZO-FC，一种将ZO优化应用于单个基于适配器的PEFT模块，并结合FO优化的分类器的方法。

Result: ZO优化自然地导致更平坦的损失景观，减少了持续学习中的遗忘。ZO优化增强了稳定性，但往往会损害可塑性，尤其是在与可学习分类器一起使用时。ZO-FC在稳定性和可塑性之间取得了有效平衡。

Conclusion: 零阶优化在持续学习中提供了内存效率和稳定性，但可能牺牲可塑性。ZO-FC通过结合零阶优化的稳定性和一阶优化的适应性，为设备上的持续学习提供了一个实用的内存高效解决方案。

Abstract: Zeroth-order (ZO) optimization has gained attention as a memory-efficient
alternative to first-order (FO) methods, particularly in settings where
gradient computation is expensive or even impractical. Beyond its memory
efficiency, in this work, we investigate ZO optimization for continual learning
(CL) as a novel approach to address the plasticity-stability-efficiency
trilemma. Through theoretical analysis and empirical evidence, we show that ZO
optimization naturally leads to flatter loss landscapes, which in turn reduce
forgetting in CL. However, this stability comes at a cost of plasticity: due to
its imprecise gradient estimates and slower convergence, ZO optimization tends
to be less effective than FO in acquiring new task-specific knowledge,
particularly under constrained training budgets. To better understand this
trade-off, we conduct a holistic evaluation of ZO optimization applied to
various existing CL methods. Our findings reveal that ZO optimization enhances
stability but often undermines plasticity, particularly when used with
learnable classifiers. Motivated by this insight, we propose ZO-FC, a simple
but effective approach that applies ZO optimization to a single adapter-based
PEFT module with FO optimized classifier. This design leverages the stability
benefits of ZO while preserving the adaptability of FO updates with negligible
memory overhead. Experiments demonstrate that ZO-FC achieves an effective
balance between stability and plasticity, offering a practical and
memory-efficient solution for on-device CL.

</details>


### [98] [CIPHER: Scalable Time Series Analysis for Physical Sciences with Application to Solar Wind Phenomena](https://arxiv.org/abs/2510.21022)
*Jasmine R. Kobayashi,Daniela Martin,Valmir P Moraes Filho,Connor O'Brien,Jinsu Hong,Sudeshna Boro Saikia,Hala Lamdouar,Nathan D. Miles,Marcella Scoczynski,Mavis Stone,Sairam Sundaresan,Anna Jungbluth,Andrés Muñoz-Jaramillo,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: 该文章介绍了一个名为CIPHER的框架，旨在解决物理科学领域时间序列数据标注稀缺、成本高且不一致的挑战。CIPHER结合了iSAX、HDBSCAN和人工验证，以加速大规模复杂时间序列的标注。该框架在分类OMNI数据中的太阳风现象方面表现出色，并提供了一种将符号表示、无监督学习和专家知识相结合的通用策略，以解决物理科学中时间序列的标签稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 在物理科学中，时间序列的标注或分类是一个持续的挑战，因为专家标注稀缺、成本高昂且经常不一致。然而，鲁棒的标注对于机器学习模型理解、预测和预报至关重要。

Method: 本文提出了一个名为CIPHER（用于识别的带有人工评估的聚类和索引管道）的框架。CIPHER集成了可索引的符号聚合近似（iSAX）进行可解释的压缩和索引，使用基于密度的聚类（HDBSCAN）对重复现象进行分组，并通过人工介入步骤进行高效的专家验证。代表性样本由领域科学家进行标注，这些标注会传播到整个聚类中，从而产生系统化、可扩展的分类。

Result: 通过在OMNI数据中对太阳风现象进行分类的任务中评估CIPHER，该框架成功地恢复了有意义的现象，例如日冕物质抛射和流相互作用区。

Conclusion: CIPHER提供了一种结合符号表示、无监督学习和专家知识的通用策略，以解决物理科学中时间序列标签稀缺的问题。该研究中使用的代码和配置文件已公开发布以支持可重现性。

Abstract: Labeling or classifying time series is a persistent challenge in the physical
sciences, where expert annotations are scarce, costly, and often inconsistent.
Yet robust labeling is essential to enable machine learning models for
understanding, prediction, and forecasting. We present the \textit{Clustering
and Indexation Pipeline with Human Evaluation for Recognition} (CIPHER), a
framework designed to accelerate large-scale labeling of complex time series in
physics. CIPHER integrates \textit{indexable Symbolic Aggregate approXimation}
(iSAX) for interpretable compression and indexing, density-based clustering
(HDBSCAN) to group recurring phenomena, and a human-in-the-loop step for
efficient expert validation. Representative samples are labeled by domain
scientists, and these annotations are propagated across clusters to yield
systematic, scalable classifications. We evaluate CIPHER on the task of
classifying solar wind phenomena in OMNI data, a central challenge in space
weather research, showing that the framework recovers meaningful phenomena such
as coronal mass ejections and stream interaction regions. Beyond this case
study, CIPHER highlights a general strategy for combining symbolic
representations, unsupervised learning, and expert knowledge to address label
scarcity in time series across the physical sciences. The code and
configuration files used in this study are publicly available to support
reproducibility.

</details>


### [99] [Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset](https://arxiv.org/abs/2510.21038)
*Gereon Elvers,Gilad Landau,Oiwi Parker Jones*

Main category: cs.LG

TL;DR: 该论文提出了关键词识别（KWS）作为脑机接口（BCI）领域中一个具有实际应用价值和隐私保护的中间任务，并利用大型LibriBrain语料库建立了标准化的基准测试，同时发布了pnpl库以促进研究。


<details>
  <summary>Details</summary>
Motivation: 目前的非侵入式脑机接口（BCI）基准测试主要针对简单的基础任务，但像“脑到文本”这种应用准备就绪的任务仍然难以实现。因此，需要一个实用且保护隐私的中间任务来弥补这一差距。

Method: 该研究提出了关键词识别（KWS）任务，并使用了52小时的LibriBrain语料库，创建了标准化的训练/验证/测试分割。在评估方面，采用了针对极端类别不平衡的协议，使用AUPRC作为主要评估指标，并通过固定召回率下的每小时虚警（FA/h）来衡量用户体验。此外，研究还发布了更新的pnpl库，包含词级别的DataLoader和Colab教程，并提出了一个紧凑的1-D Conv/ResNet基线模型，该模型使用了focal loss和top-k pooling。

Result: 该参考模型在AUPRC上达到了排列基线的大约13倍，证明了此任务的可行性。探索性分析表明：（i）性能随训练时长呈对数线性提升，（ii）存在词级别因素（频率和持续时间）系统地调节可检测性。

Conclusion: 关键词识别（KWS）是一个可行的、具有实际应用价值和隐私保护的BCI中间任务。通过标准化基准测试和发布的工具，可以推动该领域的研究进展，并且发现训练数据量和词汇特性对模型性能有显著影响。

Abstract: Non-invasive brain-computer interfaces (BCIs) are beginning to benefit from
large, public benchmarks. However, current benchmarks target relatively simple,
foundational tasks like Speech Detection and Phoneme Classification, while
application-ready results on tasks like Brain-to-Text remain elusive. We
propose Keyword Spotting (KWS) as a practically applicable, privacy-aware
intermediate task. Using the deep 52-hour, within-subject LibriBrain corpus, we
provide standardized train/validation/test splits for reproducible
benchmarking, and adopt an evaluation protocol tailored to extreme class
imbalance. Concretely, we use area under the precision-recall curve (AUPRC) as
a robust evaluation metric, complemented by false alarms per hour (FA/h) at
fixed recall to capture user-facing trade-offs. To simplify deployment and
further experimentation within the research community, we are releasing an
updated version of the pnpl library with word-level dataloaders and Colab-ready
tutorials. As an initial reference model, we present a compact 1-D Conv/ResNet
baseline with focal loss and top-k pooling that is trainable on a single
consumer-class GPU. The reference model achieves approximately 13x the
permutation baseline AUPRC on held-out sessions, demonstrating the viability of
the task. Exploratory analyses reveal: (i) predictable within-subject scaling -
performance improves log-linearly with more training hours - and (ii) the
existence of word-level factors (frequency and duration) that systematically
modulate detectability.

</details>


### [100] [Online Multi-Class Selection with Group Fairness Guarantee](https://arxiv.org/abs/2510.21055)
*Faraz Zargari,Hossein Nekouyan,Lyndon Hallett,Bo Sun,Xiaoqi Tan*

Main category: cs.LG

TL;DR: 本文提出了一种在线多类选择算法，具有群体公平性保证，解决了现有文献中的两个关键限制：一是引入了新颖的无损舍入方案，确保整数算法达到与分数解相同的预期性能；二是明确解决了多类智能体带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的情况下，需要将资源分配给顺序到达的智能体，并确保群体公平性。现有文献在无损舍入和处理多类智能体方面存在局限性。

Method: 本文提出了一种基于松弛-舍入框架的随机算法。该算法首先使用资源预留方法（称为“备用机制”）计算分数解，以确保跨类别公平性。随后的舍入步骤在不降低性能的情况下保留了这些公平性保证。此外，本文还提出了一种学习增强的变体，该变体结合了不可信的机器学习预测，以更好地平衡实际环境中的公平性和效率。

Result: 所提出的无损舍入方案确保了整数算法能够达到与分数解相同的预期性能。该算法在处理多类别智能体以及确保公平性方面表现出色，且没有降低性能。

Conclusion: 本文提出了一种有效且公平的在线多类选择算法，解决了现有方法在无损舍入和处理多类智能体方面的不足。通过引入资源预留和学习增强机制，该算法在理论和实践中都能很好地平衡公平性和效率。

Abstract: We study the online multi-class selection problem with group fairness
guarantees, where limited resources must be allocated to sequentially arriving
agents. Our work addresses two key limitations in the existing literature.
First, we introduce a novel lossless rounding scheme that ensures the integral
algorithm achieves the same expected performance as any fractional solution.
Second, we explicitly address the challenges introduced by agents who belong to
multiple classes. To this end, we develop a randomized algorithm based on a
relax-and-round framework. The algorithm first computes a fractional solution
using a resource reservation approach -- referred to as the set-aside mechanism
-- to enforce fairness across classes. The subsequent rounding step preserves
these fairness guarantees without degrading performance. Additionally, we
propose a learning-augmented variant that incorporates untrusted
machine-learned predictions to better balance fairness and efficiency in
practical settings.

</details>


### [101] [On the Sample Complexity of Differentially Private Policy Optimization](https://arxiv.org/abs/2510.21060)
*Yi He,Xingyu Zhou*

Main category: cs.LG

TL;DR: 本文对差分隐私策略优化的样本复杂性进行了理论研究，特别关注了策略优化中差分隐私的适当定义，并系统分析了策略梯度（PG）和自然策略梯度（NPG）等广泛使用的策略优化算法在差分隐私约束和各种设置下的样本复杂性。


<details>
  <summary>Details</summary>
Motivation: 由于策略优化（PO）在机器人、医疗保健和大型语言模型训练等敏感领域的应用越来越多，其隐私问题也日益突出。

Method: 通过统一的框架，系统分析了在差分隐私（DP）约束和各种设置下，广泛使用的PO算法（包括策略梯度（PG）、自然策略梯度（NPG）等）的样本复杂性。

Result: 理论结果表明，隐私成本通常表现为样本复杂性中的低阶项，同时也突出了私有PO设置中 PPO算法的精妙但重要的观察结果。

Conclusion: 这些为隐私保护的PO算法提供了有价值的实践见解。

Abstract: Policy optimization (PO) is a cornerstone of modern reinforcement learning
(RL), with diverse applications spanning robotics, healthcare, and large
language model training. The increasing deployment of PO in sensitive domains,
however, raises significant privacy concerns. In this paper, we initiate a
theoretical study of differentially private policy optimization, focusing
explicitly on its sample complexity. We first formalize an appropriate
definition of differential privacy (DP) tailored to PO, addressing the inherent
challenges arising from on-policy learning dynamics and the subtlety involved
in defining the unit of privacy. We then systematically analyze the sample
complexity of widely-used PO algorithms, including policy gradient (PG),
natural policy gradient (NPG) and more, under DP constraints and various
settings, via a unified framework. Our theoretical results demonstrate that
privacy costs can often manifest as lower-order terms in the sample complexity,
while also highlighting subtle yet important observations in private PO
settings. These offer valuable practical insights for privacy-preserving PO
algorithms.

</details>


### [102] [Scalable Machine Learning Analysis of Parker Solar Probe Solar Wind Data](https://arxiv.org/abs/2510.21066)
*Daniela Martin,Connor O'Brien,Valmir P Moraes Filho,Jinsu Hong,Jasmine R. Kobayashi,Evangelia Samara,Joseph Gallego*

Main category: cs.LG

TL;DR: 该框架利用Dask进行大规模统计计算，并使用KDM方法估计太阳风参数的单变量和双变量分布及其异常阈值。


<details>
  <summary>Details</summary>
Motivation: PSP数据集（2018-2024）超过150 GB，对传统分析方法构成了挑战。该研究旨在为分析派克太阳探测器（PSP）太阳风数据提供一个可扩展的机器学习框架。

Method: 利用Dask进行大规模统计计算，并利用量子启发式核密度矩阵（KDM）方法估计关键太阳风参数的单变量和双变量分布，包括太阳风速度、质子密度和质子热速度，以及每个参数的异常阈值。

Result: 揭示了日球层内部的特征趋势，包括太阳风速度随距太阳距离的增加而增加，质子密度降低，以及速度和密度之间的反比关系。分析结果为太阳风结构在增强和介导极端空间天气现象方面的作用提供了量化见解。

Conclusion: 该方法提供了一种可处理、可解释和分布式的研究复杂物理数据集的方法，并有助于对大规模就地测量进行可重现的分析。处理后的数据产品和分析工具已公开发布，以促进未来太阳风动力学和空间天气预报的研究。

Abstract: We present a scalable machine learning framework for analyzing Parker Solar
Probe (PSP) solar wind data using distributed processing and the
quantum-inspired Kernel Density Matrices (KDM) method. The PSP dataset
(2018--2024) exceeds 150 GB, challenging conventional analysis approaches. Our
framework leverages Dask for large-scale statistical computations and KDM to
estimate univariate and bivariate distributions of key solar wind parameters,
including solar wind speed, proton density, and proton thermal speed, as well
as anomaly thresholds for each parameter. We reveal characteristic trends in
the inner heliosphere, including increasing solar wind speed with distance from
the Sun, decreasing proton density, and the inverse relationship between speed
and density. Solar wind structures play a critical role in enhancing and
mediating extreme space weather phenomena and can trigger geomagnetic storms;
our analyses provide quantitative insights into these processes. This approach
offers a tractable, interpretable, and distributed methodology for exploring
complex physical datasets and facilitates reproducible analysis of large-scale
in situ measurements. Processed data products and analysis tools are made
publicly available to advance future studies of solar wind dynamics and space
weather forecasting. The code and configuration files used in this study are
publicly available to support reproducibility.

</details>


### [103] [The Virtues of Brevity: Avoid Overthinking in Parallel Test-Time Reasoning](https://arxiv.org/abs/2510.21067)
*Raul Cavalcante Dinardi,Bruno Yamamoto,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 研究表明，对于大型语言模型（LLMs），在复杂推理任务中，选择最短的解决方案是一个简单而有效的启发式方法，它在不增加计算成本的情况下，可以获得与复杂方法相当甚至更好的性能。



<details>
  <summary>Details</summary>
Motivation: 现有的并行测试时计算采样策略需要复杂的评分机制，从而增加了计算成本和复杂性。作者旨在寻找一种更简单、计算效率更高的策略来提升LLMs在复杂推理任务上的性能。


Method: 本文提出并验证了一种“选择最短解决方案”的启发式方法。作者通过实验证明，模型在两种不同的模式下运行：一种是简洁、自信的常规模式，另一种是冗长、过度思考的模式。通过选择最短的答案，这种启发式方法优先从常规模式中采样。


Result: “最短答案启发式”方法与自洽性等更复杂的方法相比具有竞争力，并且显著降低了计算开销。它在两个具有挑战性的基准测试中都取得了帕累托改进，甚至适用于输出结果不明确的任务。


Conclusion: 选择最短的解决方案是一种简单、反直觉但高效的策略，可以有效提升LLMs在复杂推理任务中的表现，同时降低计算成本，优于现有的一些复杂方法。


Abstract: Reasoning models represent a significant advance in LLM capabilities,
particularly for complex reasoning tasks such as mathematics and coding.
Previous studies confirm that parallel test-time compute-sampling multiple
solutions and selecting the best one-can further enhance the predictive
performance of LLMs. However, strategies in this area often require complex
scoring, thus increasing computational cost and complexity. In this work, we
demonstrate that the simple and counterintuitive heuristic of selecting the
shortest solution is highly effective. We posit that the observed effectiveness
stems from models operating in two distinct regimes: a concise, confident
conventional regime and a verbose overthinking regime characterized by
uncertainty, and we show evidence of a critical point where the overthinking
regime begins to be significant. By selecting the shortest answer, the
heuristic preferentially samples from the conventional regime. We confirm that
this approach is competitive with more complex methods such as self-consistency
across two challenging benchmarks while significantly reducing computational
overhead. The shortest-answer heuristic provides a Pareto improvement over
self-consistency and applies even to tasks where output equality is not well
defined.

</details>


### [104] [DictPFL: Efficient and Private Federated Learning on Encrypted Gradients](https://arxiv.org/abs/2510.21086)
*Jiaqi Xue,Mayank Kumar,Yuzhang Shang,Shangqian Gao,Rui Ning,Mengxin Zheng,Xiaoqian Jiang,Qian Lou*

Main category: cs.LG

TL;DR: DictPFL是一个实用的框架，它在联邦学习中实现了完整的梯度保护，且开销最小。DictPFL通过分解模型权重和加密感知剪枝来最小化加密参数。它显著降低了通信成本并加速了训练，同时保持了接近明文联邦学习的运行时间。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中梯度共享存在隐私泄露风险，例如梯度反演攻击。现有的基于同态加密的联邦学习方法在保护隐私和计算开销之间存在权衡，要么加密所有梯度以获得完全隐私但开销高昂，要么部分加密以节省资源但存在漏洞。

Method: DictPFL框架引入了两个关键模块：
1. Decompose-for-Partial-Encrypt (DePE)：将模型权重分解为静态字典和可更新查找表，仅加密和聚合查找表，静态字典保留在本地，无需共享或加密。
2. Prune-for-Minimum-Encrypt (PrME)：应用加密感知剪枝，通过一致的、历史引导的掩码来最小化加密参数。

Result: 与完全加密的联邦学习相比，DictPFL的通信成本降低了402-748倍，训练速度加快了28-65倍。与最先进的选择性加密方法相比，其开销降低了51-155倍，速度提高了4-19倍。DictPFL的运行时间在明文联邦学习的2倍以内。

Conclusion: DictPFL首次证明了基于同态加密的私有联邦学习在实际部署中是可行的，因为它在实现完整的梯度保护的同时，将计算和通信开销降至最低。

Abstract: Federated Learning (FL) enables collaborative model training across
institutions without sharing raw data. However, gradient sharing still risks
privacy leakage, such as gradient inversion attacks. Homomorphic Encryption
(HE) can secure aggregation but often incurs prohibitive computational and
communication overhead. Existing HE-based FL methods sit at two extremes:
encrypting all gradients for full privacy at high cost, or partially encrypting
gradients to save resources while exposing vulnerabilities. We present DictPFL,
a practical framework that achieves full gradient protection with minimal
overhead. DictPFL encrypts every transmitted gradient while keeping
non-transmitted parameters local, preserving privacy without heavy computation.
It introduces two key modules: Decompose-for-Partial-Encrypt (DePE), which
decomposes model weights into a static dictionary and an updatable lookup
table, only the latter is encrypted and aggregated, while the static dictionary
remains local and requires neither sharing nor encryption; and
Prune-for-Minimum-Encrypt (PrME), which applies encryption-aware pruning to
minimize encrypted parameters via consistent, history-guided masks. Experiments
show that DictPFL reduces communication cost by 402-748$\times$ and accelerates
training by 28-65$\times$ compared to fully encrypted FL, while outperforming
state-of-the-art selective encryption methods by 51-155$\times$ in overhead and
4-19$\times$ in speed. Remarkably, DictPFL's runtime is within 2$\times$ of
plaintext FL, demonstrating for the first time, that HE-based private federated
learning is practical for real-world deployment. The code is publicly available
at https://github.com/UCF-ML-Research/DictPFL.

</details>


### [105] [ESCORT: Efficient Stein-variational and Sliced Consistency-Optimized Temporal Belief Representation for POMDPs](https://arxiv.org/abs/2510.21107)
*Yunuo Zhang,Baiting Luo,Ayan Mukhopadhyay,Gabor Karsai,Abhishek Dubey*

Main category: cs.LG

TL;DR: 本文提出了ESCORT，一个基于粒子（particle-based）的框架，用于在高维置信空间中捕获复杂的多模态分布。


<details>
  <summary>Details</summary>
Motivation: 目前现有的部分可观察马尔可夫决策过程（POMDP）的置信近似方法未能准确表示复杂的不确定性结构，例如高维、多模态的置信分布，导致估计误差并产生次优的智能体行为。

Method: ESCORT扩展了SVGD，并引入了两项关键创新：关联感知投影（correlation-aware projections），用于建模状态维度之间的依赖关系；时间一致性约束（temporal consistency constraints），用于在保持关联结构的同时稳定更新。该方法保留了SVGD的吸引-排斥粒子动力学，同时能够准确建模复杂的关联模式。

Result: 与容易退化的粒子滤波器或具有固定表示能力的参数方法不同，ESCORT无需重采样或限制性分布假设，即可动态适应置信度景观的复杂性。在POMDP领域和不同维度合成多模态分布上的广泛评估证明了ESCORT的有效性，在置信近似精度和下游决策质量方面，它始终优于最先进的方法。

Conclusion: ESCORT通过引入关联感知投影和时间一致性约束，扩展了SVGD算法，能够在高维置信空间中有效捕获复杂的多模态分布，解决了现有方法在处理复杂不确定性结构时的局限性，从而提高了置信近似的准确性和决策质量。

Abstract: In Partially Observable Markov Decision Processes (POMDPs), maintaining and
updating belief distributions over possible underlying states provides a
principled way to summarize action-observation history for effective
decision-making under uncertainty. As environments grow more realistic, belief
distributions develop complexity that standard mathematical models cannot
accurately capture, creating a fundamental challenge in maintaining
representational accuracy. Despite advances in deep learning and probabilistic
modeling, existing POMDP belief approximation methods fail to accurately
represent complex uncertainty structures such as high-dimensional, multi-modal
belief distributions, resulting in estimation errors that lead to suboptimal
agent behaviors. To address this challenge, we present ESCORT (Efficient
Stein-variational and sliced Consistency-Optimized Representation for Temporal
beliefs), a particle-based framework for capturing complex, multi-modal
distributions in high-dimensional belief spaces. ESCORT extends SVGD with two
key innovations: correlation-aware projections that model dependencies between
state dimensions, and temporal consistency constraints that stabilize updates
while preserving correlation structures. This approach retains SVGD's
attractive-repulsive particle dynamics while enabling accurate modeling of
intricate correlation patterns. Unlike particle filters prone to degeneracy or
parametric methods with fixed representational capacity, ESCORT dynamically
adapts to belief landscape complexity without resampling or restrictive
distributional assumptions. We demonstrate ESCORT's effectiveness through
extensive evaluations on both POMDP domains and synthetic multi-modal
distributions of varying dimensionality, where it consistently outperforms
state-of-the-art methods in terms of belief approximation accuracy and
downstream decision quality.

</details>


### [106] [Distributionally Robust Feature Selection](https://arxiv.org/abs/2510.21113)
*Maitreyi Swaroop,Tamar Krishnamurti,Bryan Wilder*

Main category: cs.LG

TL;DR: 本文提出了一种特征选择方法，用于在多个亚群中同时训练出表现良好的模型。


<details>
  <summary>Details</summary>
Motivation: 在收集每个特征成本高昂的场景中，例如需要添加调查问题或物理传感器，并且必须能够使用选定的特征为不同人群创建高质量的下游模型时，研究如何选择有限的特征进行观察。

Method: 本文将问题框架化为使用噪声机制对传统变量选择进行连续松弛，而无需通过模型训练过程进行反向传播。通过优化贝叶斯最优预测器的方差，开发了一个与模型无关的框架，平衡了跨人群的下游预测的整体性能。

Result: 在合成数据集和真实世界数据上进行了实验，验证了该方法的有效性。

Conclusion: 本文提出了一种新颖的特征选择方法，可以在收集成本高昂的场景中，为多个亚群提供高质量的下游模型。

Abstract: We study the problem of selecting limited features to observe such that
models trained on them can perform well simultaneously across multiple
subpopulations. This problem has applications in settings where collecting each
feature is costly, e.g. requiring adding survey questions or physical sensors,
and we must be able to use the selected features to create high-quality
downstream models for different populations. Our method frames the problem as a
continuous relaxation of traditional variable selection using a noising
mechanism, without requiring backpropagation through model training processes.
By optimizing over the variance of a Bayes-optimal predictor, we develop a
model-agnostic framework that balances overall performance of downstream
prediction across populations. We validate our approach through experiments on
both synthetic datasets and real-world data.

</details>


### [107] [SolarBoost: Distributed Photovoltaic Power Forecasting Amid Time-varying Grid Capacity](https://arxiv.org/abs/2510.21129)
*Linyuan Geng,Linxiao Yang,Xinyue Gu,Liang Sun*

Main category: cs.LG

TL;DR: SolarBoost 是一种新颖的分布式光伏（DPV）系统功率输出预测方法，能够有效处理数据缺失、容量变化、地理差异和面板多样性等挑战。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够精确预测分布式光伏（DPV）系统功率输出的方法，以克服现有集中式光伏（CPV）方法在DPV系统上面临的挑战，如数据缺失、容量随时间变化、地理变异性和面板多样性等。

Method: SolarBoost 通过将聚合功率输出建模为小电网输出的复合，每个电网输出通过单位输出函数乘以其容量来建模。这种方法将同质单位输出函数与动态容量解耦，以实现精确预测。为了克服损失函数中的计算瓶颈，本文提出了一种基于上限近似的高效算法。

Result: 通过理论分析和实验证明了电网级建模的优越性，并在中国多个城市的部署中验证了SolarBoost，显著减少了潜在损失。

Conclusion: SolarBoost 为分布式光伏系统功率预测提供了一种有效且经过验证的解决方案，为电网运行提供了有价值的见解。

Abstract: This paper presents SolarBoost, a novel approach for forecasting power output
in distributed photovoltaic (DPV) systems. While existing centralized
photovoltaic (CPV) methods are able to precisely model output dependencies due
to uniformity, it is difficult to apply such techniques to DPV systems, as DPVs
face challenges such as missing grid-level data, temporal shifts in installed
capacity, geographic variability, and panel diversity. SolarBoost overcomes
these challenges by modeling aggregated power output as a composite of output
from small grids, where each grid output is modeled using a unit output
function multiplied by its capacity. This approach decouples the homogeneous
unit output function from dynamic capacity for accurate prediction. Efficient
algorithms over an upper-bound approximation are proposed to overcome
computational bottlenecks in loss functions. We demonstrate the superiority of
grid-level modeling via theoretical analysis and experiments. SolarBoost has
been validated through deployment across various cities in China, significantly
reducing potential losses and provides valuable insights for the operation of
power grids. The code for this work is available at
https://github.com/DAMO-DI-ML/SolarBoost.

</details>


### [108] [Leverage Unlearning to Sanitize LLMs](https://arxiv.org/abs/2510.21322)
*Antoine Boutet,Lucas Magnana*

Main category: cs.LG

TL;DR: 该论文提出了一种名为SANI的AI模型去记忆化方法，旨在解决大型语言模型在特定数据上微调时可能导致的敏感信息记忆问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在特定数据语料库（如医疗报告、商业数据）上进行微调时，会记忆敏感数据，造成隐私或保密问题。传统的解决方案是进行额外的微调，但这需要高昂的成本。

Method: SANI通过擦除和修复两个阶段来净化语言模型。首先，它重置模型末层的某些神经元，以中断对细粒度信息的记忆。然后，在避免记忆敏感信息的同时对模型进行微调。

Result: SANI在仅需少量额外去记忆化训练的情况下，就能显著减少模型对敏感信息的重复，并且能够有效地净化模型。

Conclusion: SANI是一种高效的AI模型去记忆化方法，可用于消除大型语言模型记忆的敏感信息，对于医院或其他已投入大量资源训练模型的行业尤其有用，可以在共享模型之前对其进行净化。

Abstract: Pre-trained large language models (LLMs) are becoming useful for various
tasks. To improve their performance on certain tasks, it is necessary to
fine-tune them on specific data corpora (e.g., medical reports, business data).
These specialized data corpora may contain sensitive data (e.g., personal or
confidential data) that will be memorized by the model and likely to be
regurgitated during its subsequent use. This memorization of sensitive
information by the model poses a significant privacy or confidentiality issue.
To remove this memorization and sanitize the model without requiring costly
additional fine-tuning on a secured data corpus, we propose SANI. SANI is an
unlearning approach to sanitize language models. It relies on both an erasure
and repair phases that 1) reset certain neurons in the last layers of the model
to disrupt the memorization of fine-grained information, and then 2) fine-tune
the model while avoiding memorizing sensitive information. We comprehensively
evaluate SANI to sanitize both a model fine-tuned and specialized with medical
data by removing directly and indirectly identifiers from the memorization of
the model, and a standard pre-trained model by removing specific terms defined
as confidential information from the model. Results show that with only few
additional epochs of unlearning, the model is sanitized and the number of
regurgitations is drastically reduced. This approach can be particularly useful
for hospitals or other industries that have already spent significant resources
training models on large datasets and wish to sanitize them before sharing.

</details>


### [109] [Cloud-Fog-Edge Collaborative Computing for Sequential MIoT Workflow: A Two-Tier DDPG-Based Scheduling Framework](https://arxiv.org/abs/2510.21135)
*Yuhao Fu,Yinghao Zhang,Yalin Liu,Bishenghui Tao,Junhong Ruan*

Main category: cs.LG

TL;DR: 这篇论文提出了一种两层DDPG调度框架，用于在异构云-雾-边缘基础设施中调度医疗物联网（MIoT）的顺序医疗工作流，以最小化完成时间。


<details>
  <summary>Details</summary>
Motivation: 医疗物联网（MIoT）需要严格的端到端延迟保证，以处理部署在异构云-雾-边缘基础设施上的顺序医疗工作流。调度这些顺序工作流以最小化完成时间是一个NP-hard问题。

Method: 该框架将调度决策分解为分层过程：一个全局控制器执行层选择（边缘、雾或云），而专门的本地控制器处理所选层内的节点分配。主要的优化目标是最小化工作流的完成时间。

Result: 实验结果验证了该方法的有效性，随着工作流复杂性的增加，其性能优于基线。

Conclusion: 该框架能够学习有效的长期策略，这对于复杂、大规模的MIoT调度场景至关重要。

Abstract: The Medical Internet of Things (MIoT) demands stringent end-to-end latency
guarantees for sequential healthcare workflows deployed over heterogeneous
cloud-fog-edge infrastructures. Scheduling these sequential workflows to
minimize makespan is an NP-hard problem. To tackle this challenge, we propose a
Two-tier DDPG-based scheduling framework that decomposes the scheduling
decision into a hierarchical process: a global controller performs layer
selection (edge, fog, or cloud), while specialized local controllers handle
node assignment within the chosen layer. The primary optimization objective is
the minimization of the workflow makespan. Experiments results validate our
approach, demonstrating increasingly superior performance over baselines as
workflow complexity rises. This trend highlights the frameworks ability to
learn effective long-term strategies, which is critical for complex,
large-scale MIoT scheduling scenarios.

</details>


### [110] [FairImagen: Post-Processing for Bias Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.21363)
*Zihao Fu,Ryan Brown,Shun Shao,Kai Rawal,Eoin Delaney,Chris Russell*

Main category: cs.LG

TL;DR: FairImagen是一种后处理去偏框架，可以在不重新训练或修改扩散模型的情况下，减轻文本到图像扩散模型中的社会偏见。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在图像生成方面表现出色，但存在复制和放大社会偏见的问题。

Method: FairImagen通过集成公平主成分分析，将基于CLIP的输入嵌入投影到最小化群组特定信息并保留语义内容的子空间中。通过经验噪声注入增强去偏效果，并提出统一的跨人口统计投影方法，实现多个人口统计属性的同时去偏。

Result: FairImagen在性别、种族和交叉设置方面的广泛实验表明，它显著提高了公平性，同时在图像质量和提示保真度方面做出了适度权衡。

Conclusion: FairImagen优于现有后处理方法，为公平的文本到图像生成提供了简单、可扩展且模型无关的解决方案。

Abstract: Text-to-image diffusion models, such as Stable Diffusion, have demonstrated
remarkable capabilities in generating high-quality and diverse images from
natural language prompts. However, recent studies reveal that these models
often replicate and amplify societal biases, particularly along demographic
attributes like gender and race. In this paper, we introduce FairImagen
(https://github.com/fuzihaofzh/FairImagen), a post-hoc debiasing framework that
operates on prompt embeddings to mitigate such biases without retraining or
modifying the underlying diffusion model. Our method integrates Fair Principal
Component Analysis to project CLIP-based input embeddings into a subspace that
minimizes group-specific information while preserving semantic content. We
further enhance debiasing effectiveness through empirical noise injection and
propose a unified cross-demographic projection method that enables simultaneous
debiasing across multiple demographic attributes. Extensive experiments across
gender, race, and intersectional settings demonstrate that FairImagen
significantly improves fairness with a moderate trade-off in image quality and
prompt fidelity. Our framework outperforms existing post-hoc methods and offers
a simple, scalable, and model-agnostic solution for equitable text-to-image
generation.

</details>


### [111] [A Unified Matrix Factorization Framework for Classical and Robust Clustering](https://arxiv.org/abs/2510.21172)
*Angshul Majumdar*

Main category: cs.LG

TL;DR: 本文提出了一个统一的矩阵分解框架，用于实现经典和鲁棒聚类。


<details>
  <summary>Details</summary>
Motivation: 为了解决聚类算法对异常值敏感的问题，并提出鲁棒的聚类方法。

Method: 本文首先重新审视了 crisp k-means 聚类和矩阵分解之间的等价性，并推导了模糊 c-means 聚类的矩阵分解解释。然后，通过将 Frobenius 范数替换为 l1,2-范数，提出了针对 crisp 和模糊聚类的鲁棒公式。并开发了标准公式的交替最小化算法和鲁棒对应项的基于 IRLS 的算法。

Result: 所有算法在理论上被证明收敛到局部最小值。

Conclusion: 本文提出了一个统一的矩阵分解框架，不仅涵盖了经典的 crisp k-means 和模糊 c-means 聚类，还通过引入 l1,2-范数的形式，有效解决了异常值敏感的问题，实现了鲁棒聚类。所提出的算法在理论上被证明能够收敛到局部最小值，为聚类分析提供了更稳健的解决方案。

Abstract: This paper presents a unified matrix factorization framework for classical
and robust clustering. We begin by revisiting the well-known equivalence
between crisp k-means clustering and matrix factorization, following and
rigorously rederiving an unpublished formulation by Bauckhage. Extending this
framework, we derive an analogous matrix factorization interpretation for fuzzy
c-means clustering, which to the best of our knowledge has not been previously
formalized. These reformulations allow both clustering paradigms to be
expressed as optimization problems over factor matrices, thereby enabling
principled extensions to robust variants. To address sensitivity to outliers,
we propose robust formulations for both crisp and fuzzy clustering by replacing
the Frobenius norm with the l1,2-norm, which penalizes the sum of Euclidean
norms across residual columns. We develop alternating minimization algorithms
for the standard formulations and IRLS-based algorithms for the robust
counterparts. All algorithms are theoretically proven to converge to a local
minimum.

</details>


### [112] [A visual big data system for the prediction of weather-related variables: Jordan-Spain case study](https://arxiv.org/abs/2510.21176)
*Shadi Aljawarneh,Juan A. Lara,Muneer Bani Yassein*

Main category: cs.LG

TL;DR: 这篇论文提出了一种可视化大数据系统，旨在处理大量的气象数据，并通过预测任务分析这些数据。


<details>
  <summary>Details</summary>
Motivation: 气象领域会生成大量的气象数据，这些数据具有高容量、高维度、缺失值和高相关性等特点。因此，使用大数据和数据挖掘技术来处理这些数据并从中提取有用的知识至关重要，这些知识可用于预测气象现象。

Method: 本系统收集开放数据并将其加载到本地NoSQL数据库中，在不同时间及空间聚合级别融合，以便使用单变量和多变量方法进行预测分析，并在缺失值率高的情况下根据邻近站点的训练数据进行预测。

Result: 该系统在可用性和预测性能方面进行了评估，获得了0.00013的总体归一化均方误差值和接近0.84的总体方向对称性值。系统获得了该领域专家组的积极评价。

Conclusion: 所获得的初步结果证明了该系统的有效性。

Abstract: The Meteorology is a field where huge amounts of data are generated, mainly
collected by sensors at weather stations, where different variables can be
measured. Those data have some particularities such as high volume and
dimensionality, the frequent existence of missing values in some stations, and
the high correlation between collected variables. In this regard, it is crucial
to make use of Big Data and Data Mining techniques to deal with those data and
extract useful knowledge from them that can be used, for instance, to predict
weather phenomena. In this paper, we propose a visual big data system that is
designed to deal with high amounts of weather-related data and lets the user
analyze those data to perform predictive tasks over the considered variables
(temperature and rainfall). The proposed system collects open data and loads
them onto a local NoSQL database fusing them at different levels of temporal
and spatial aggregation in order to perform a predictive analysis using
univariate and multivariate approaches as well as forecasting based on training
data from neighbor stations in cases with high rates of missing values. The
system has been assessed in terms of usability and predictive performance,
obtaining an overall normalized mean squared error value of 0.00013, and an
overall directional symmetry value of nearly 0.84. Our system has been rated
positively by a group of experts in the area (all aspects of the system except
graphic desing were rated 3 or above in a 1-5 scale). The promising preliminary
results obtained demonstrate the validity of our system and invite us to keep
working on this area.

</details>


### [113] [Scalable Principal-Agent Contract Design via Gradient-Based Optimization](https://arxiv.org/abs/2510.21177)
*Tomer Galanti,Aarya Bookseller,Korok Ray*

Main category: cs.LG

TL;DR: 本文提出了一种新的计算工具，用于解决 प्रिंसिपल-agent 合同设计中的双层 max-max 优化问题。该方法通过使用隐式微分和共轭梯度法有效地计算超梯度，避免了形成或反转 Hessian 矩阵，从而能够解决传统上难以处理的非线性合同设计问题。


<details>
  <summary>Details</summary>
Motivation: 传统的 प्रिंसिपल-agent 合同设计问题在非线性效用、随机动态或高维动作的现实环境中缺乏封闭解，限制了对复杂模型的研究。

Method: 本文引入了一种通用的算法框架，该框架利用隐式微分和共轭梯度法（CG）来高效计算超梯度，通过 Hessian-向量积实现，无需形成或反转 Hessian 矩阵。此方法适应了双层优化的现代机器学习技术。

Result: 在基准 CARA-Normal 环境中，该方法恢复了已知的分析最优解，并能从随机初始化中可靠收敛。该框架是无矩阵、方差缩减且与问题无关的，因此可以自然地扩展到没有封闭解的复杂非线性合同，例如 S 型工资表、具有共同冲击的相对绩效/锦标赛薪酬、具有向量动作和异构噪声的多任务合同以及 CARA-Poisson 计数模型。

Conclusion: 本文提供了一种合同设计的新计算工具，使得对传统上难以解析处理的模型进行系统研究成为可能。

Abstract: We study a bilevel \emph{max-max} optimization framework for principal-agent
contract design, in which a principal chooses incentives to maximize utility
while anticipating the agent's best response. This problem, central to moral
hazard and contract theory, underlies applications ranging from market design
to delegated portfolio management, hedge fund fee structures, and executive
compensation. While linear-quadratic models such as Holmstr"om-Milgrom admit
closed-form solutions, realistic environments with nonlinear utilities,
stochastic dynamics, or high-dimensional actions generally do not.
  We introduce a generic algorithmic framework that removes this reliance on
closed forms. Our method adapts modern machine learning techniques for bilevel
optimization -- using implicit differentiation with conjugate gradients (CG) --
to compute hypergradients efficiently through Hessian-vector products, without
ever forming or inverting Hessians. In benchmark CARA-Normal (Constant Absolute
Risk Aversion with Gaussian distribution of uncertainty) environments, the
approach recovers known analytical optima and converges reliably from random
initialization. More broadly, because it is matrix-free, variance-reduced, and
problem-agnostic, the framework extends naturally to complex nonlinear
contracts where closed-form solutions are unavailable, such as sigmoidal wage
schedules (logistic pay), relative-performance/tournament compensation with
common shocks, multi-task contracts with vector actions and heterogeneous
noise, and CARA-Poisson count models with $\mathbb{E}[X\mid a]=e^{a}$. This
provides a new computational tool for contract design, enabling systematic
study of models that have remained analytically intractable.

</details>


### [114] [PLAN: Proactive Low-Rank Allocation for Continual Learning](https://arxiv.org/abs/2510.21188)
*Xiequn Wang,Zhan Zhuang,Yu Zhang*

Main category: cs.LG

TL;DR: PLAN是一个在持续学习场景中扩展LoRA的框架，它允许模型在不忘记先前知识的情况下适应新任务。


<details>
  <summary>Details</summary>
Motivation: 持续学习（CL）要求模型在不忘记过去知识的情况下持续适应新任务。

Method: PLAN通过引入正交基向量并使用基于扰动的策略进行优化来主动管理任务特定子空间的分配，从而最大限度地减少与先前学习参数的冲突。此外，PLAN还包含一种新颖的选择机制，该机制识别并分配对干扰敏感度最小的基向量。

Result: PLAN在标准CL基准测试中始终优于现有方法。

Conclusion: PLAN为基础模型的持续学习建立了一个新的最先进水平，有效地平衡了新任务的适应性和对旧知识的保留。

Abstract: Continual learning (CL) requires models to continuously adapt to new tasks
without forgetting past knowledge. In this work, we propose
\underline{P}roactive \underline{L}ow-rank \underline{A}llocatio\underline{N}
(PLAN), a framework that extends Low-Rank Adaptation (LoRA) to enable efficient
and interference-aware fine-tuning of large pre-trained models in CL settings.
PLAN proactively manages the allocation of task-specific subspaces by
introducing orthogonal basis vectors for each task and optimizing them through
a perturbation-based strategy that minimizes conflicts with previously learned
parameters. Furthermore, PLAN incorporates a novel selection mechanism that
identifies and assigns basis vectors with minimal sensitivity to interference,
reducing the risk of degrading past knowledge while maintaining efficient
adaptation to new tasks. Empirical results on standard CL benchmarks
demonstrate that PLAN consistently outperforms existing methods, establishing a
new state-of-the-art for continual learning with foundation models.

</details>


### [115] [Gen-Review: A Large-scale Dataset of AI-Generated (and Human-written) Peer Reviews](https://arxiv.org/abs/2510.21192)
*Luca Demetrio,Giovanni Apruzzese,Kathrin Grosse,Pavel Laskov,Emil Lupu,Vera Rimmer,Philine Widmer*

Main category: cs.LG

TL;DR: 该文章介绍了GenReview，一个包含大量大语言模型（LLM）生成的评审意见的数据集，旨在探究LLM在科学同行评审中的应用和影响。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型（LLM）在科学同行评审中日益增长的应用如何影响科学过程的有效性和完整性。尽管已有关于此主题的研究，但仍缺乏一个全面的相关数据集。

Method: 本文通过为2018-2025年ICLR会议的所有提交论文提供负面、正面和中性三种独立提示，生成了81K篇LLM撰写的评审意见，并创建了迄今为止最大的LLM生成评审数据集GenReview。该数据集还与相应的论文及其原始评审意见相关联。

Result: 通过GenReview数据集，研究发现LLM在评审中表现出偏见；LLM撰写的评审意见可以被自动检测；LLM并非总能严格遵循评审指令；LLM提供的评分与论文接受决定一致，但与拒绝决定不一致。

Conclusion: GenReview数据集的建立填补了LLM生成评审数据集的空白，为全面理解LLM在科学评审中的效用和影响提供了基础。研究结果揭示了LLM在同行评审中应用的潜在优点和局限性。

Abstract: How does the progressive embracement of Large Language Models (LLMs) affect
scientific peer reviewing? This multifaceted question is fundamental to the
effectiveness -- as well as to the integrity -- of the scientific process.
Recent evidence suggests that LLMs may have already been tacitly used in peer
reviewing, e.g., at the 2024 International Conference of Learning
Representations (ICLR). Furthermore, some efforts have been undertaken in an
attempt to explicitly integrate LLMs in peer reviewing by various editorial
boards (including that of ICLR'25). To fully understand the utility and the
implications of LLMs' deployment for scientific reviewing, a comprehensive
relevant dataset is strongly desirable. Despite some previous research on this
topic, such dataset has been lacking so far. We fill in this gap by presenting
GenReview, the hitherto largest dataset containing LLM-written reviews. Our
dataset includes 81K reviews generated for all submissions to the 2018--2025
editions of the ICLR by providing the LLM with three independent prompts: a
negative, a positive, and a neutral one. GenReview is also linked to the
respective papers and their original reviews, thereby enabling a broad range of
investigations. To illustrate the value of GenReview, we explore a sample of
intriguing research questions, namely: if LLMs exhibit bias in reviewing (they
do); if LLM-written reviews can be automatically detected (so far, they can);
if LLMs can rigorously follow reviewing instructions (not always) and whether
LLM-provided ratings align with decisions on paper acceptance or rejection
(holds true only for accepted papers). GenReview can be accessed at the
following link: https://anonymous.4open.science/r/gen_review.

</details>


### [116] [Online AUC Optimization Based on Second-order Surrogate Loss](https://arxiv.org/abs/2510.21202)
*JunRu Luo,Difei Cheng,Bo Zhang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新颖的二阶替代损失函数，用于解决在线AUC优化中的挑战，并通过理论保证和实验证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: AUC是分类任务中一个重要的性能指标，尤其是在类别不平衡的情况下。然而，最小化AUC面临着挑战：配对0/1损失的非凸和不连续性导致优化困难；实例级存储的巨大内存成本限制了其在大规模应用中的发展。

Method: 本文提出了一种基于配对铰链损失的二阶替代损失函数，并开发了一种高效的在线算法。与传统方法不同，本文的方法不是用实例级替代函数近似每个单独的配对0/1损失项，而是引入了一个新的范式，用由训练数据的一阶和二阶统计量构建的替代损失函数直接替代整个聚合的配对损失。此外，还将该框架扩展到通过核函数公式实现的非线性设置。

Result: 在理论上，本文的方法实现了更紧密的 O(ln T) 遗憾界，而现有在线AUC优化算法通常实现 O(√T) 遗憾界。在多个基准数据集上进行的广泛实验证明了所提出的二阶替代损失在优化在线AUC性能方面的卓越效率和有效性。

Conclusion: 本文成功地提出了一种新颖的二阶替代损失函数和高效的在线算法，有效地解决了在线AUC优化中的挑战，并在理论和实践中都展现出优越的性能，为大规模在线AUC优化提供了新的解决方案。

Abstract: The Area Under the Curve (AUC) is an important performance metric for
classification tasks, particularly in class-imbalanced scenarios. However,
minimizing the AUC presents significant challenges due to the non-convex and
discontinuous nature of pairwise 0/1 losses, which are difficult to optimize,
as well as the substantial memory cost of instance-wise storage, which creates
bottlenecks in large-scale applications. To overcome these challenges, we
propose a novel second-order surrogate loss based on the pairwise hinge loss,
and develop an efficient online algorithm. Unlike conventional approaches that
approximate each individual pairwise 0/1 loss term with an instance-wise
surrogate function, our approach introduces a new paradigm that directly
substitutes the entire aggregated pairwise loss with a surrogate loss function
constructed from the first- and second-order statistics of the training data.
Theoretically, while existing online AUC optimization algorithms typically
achieve an $\mathcal{O}(\sqrt{T})$ regret bound, our method attains a tighter
$\mathcal{O}(\ln T)$ bound. Furthermore, we extend the proposed framework to
nonlinear settings through a kernel-based formulation. Extensive experiments on
multiple benchmark datasets demonstrate the superior efficiency and
effectiveness of the proposed second-order surrogate loss in optimizing online
AUC performance.

</details>


### [117] [Mitra: Mixed Synthetic Priors for Enhancing Tabular Foundation Models](https://arxiv.org/abs/2510.21204)
*Xiyuan Zhang,Danielle C. Maddix,Junming Yin,Nick Erickson,Abdul Fatir Ansari,Boran Han,Shuai Zhang,Leman Akoglu,Christos Faloutsos,Michael W. Mahoney,Cuixiong Hu,Huzefa Rangwala,George Karypis,Bernie Wang*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的表格基础模型Mitra，它通过精心设计的合成先验数据集训练，在分类和回归任务上都超越了SOTA模型，并具有更高的样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的表格机器学习研究主要关注模型架构设计，但随着TabPFN等基于上下文学习（ICL）的表格基础模型（TFMs）的出现，研究焦点转向合成数据集的设计，即生成这些数据集的先验分布。然而，先验设计原则尚不明确，本研究旨在填补这一空白。

Method: 本研究系统地调查并识别了使预训练TFMs能够很好泛化的合成先验的关键属性。在此基础上，研究者引入了Mitra模型，该模型通过精心策划的合成先验混合物进行训练，这些先验因其多样性、独特性以及在真实世界表格数据上的表现而被选中。

Result: Mitra模型在分类和回归基准测试中持续优于最先进的TFMs，如TabPFNv2和TabICL，并具有更高的样本效率。

Conclusion: 本研究首次探索了合成先验设计，并提出了Mitra模型，该模型通过优化先验设计显著提升了表格基础模型的性能和样本效率。

Abstract: Since the seminal work of TabPFN, research on tabular foundation models
(TFMs) based on in-context learning (ICL) has challenged long-standing
paradigms in machine learning. Without seeing any real-world data, models
pretrained on purely synthetic datasets generalize remarkably well across
diverse datasets, often using only a moderate number of in-context examples.
This shifts the focus in tabular machine learning from model architecture
design to the design of synthetic datasets, or, more precisely, to the prior
distributions that generate them. Yet the guiding principles for prior design
remain poorly understood. This work marks the first attempt to address the gap.
We systematically investigate and identify key properties of synthetic priors
that allow pretrained TFMs to generalize well. Based on these insights, we
introduce Mitra, a TFM trained on a curated mixture of synthetic priors
selected for their diversity, distinctiveness, and performance on real-world
tabular data. Mitra consistently outperforms state-of-the-art TFMs, such as
TabPFNv2 and TabICL, across both classification and regression benchmarks, with
better sample efficiency.

</details>


### [118] [Model Merging with Functional Dual Anchors](https://arxiv.org/abs/2510.21223)
*Kexuan Shi,Yandong Wen,Weiyang Liu*

Main category: cs.LG

TL;DR: FDA是一种新的模型融合框架，它在输入-表示空间中而不是参数空间中操作，利用合成输入和梯度来捕捉任务特定的功能偏移。


<details>
  <summary>Details</summary>
Motivation: 现有的模型融合方法在参数空间中操作，但受限于参数不一致性，这促使研究人员寻求一种更鲁棒和灵活的替代方案。

Method: 本文提出了功能双锚（FDAs）框架，它通过在输入-表示空间中建模来工作。FDAs是合成输入，其引起的梯度与任务向量对齐，从而捕捉相对于预训练模型的任务特定功能偏移。还引入了一种原则性的初始化方案。

Result: FDAs在模型融合方面表现出有效性，并且与参数空间模型融合方法互补。

Conclusion: FDAs为模型融合提供了一个新颖且有效的视角，通过在功能空间而非参数空间操作，提升了模型融合的鲁棒性和灵活性。

Abstract: Model merging is an efficient post-training strategy for integrating
knowledge from multiple finetuned checkpoints of a shared foundation model.
Existing methods operate in the parameter space, combining task vectors to
mitigate conflicts, but remain constrained by parameter inconsistencies. We
propose Functional Dual Anchors (FDAs), a framework that instead models the
input-representation space. FDAs are synthetic inputs whose induced gradients
align with task vectors, capturing task-specific functional shifts relative to
the pretrained model. This perspective bridges joint multi-task training and
post-hoc merging, offering both robustness and flexibility. We further
introduce a principled initialization scheme and show that FDAs are
complementary to parameter-space model merging. Comprehensive experiments
demonstrate the effectiveness of FDAs in model merging.

</details>


### [119] [Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime](https://arxiv.org/abs/2510.21245)
*Noah Oberweis,Semih Cayci*

Main category: cs.LG

TL;DR: 连续时间模型为深度学习优化算法的训练动态提供了重要见解。在这项工作中，我们建立了随机梯度Langevin动力学（SGLD）的非渐近收敛分析，SGLD是连续时间随机梯度下降的Itô随机微分方程（SDE）近似，处于惰性训练状态。


<details>
  <summary>Details</summary>
Motivation: 探索深度学习优化算法的训练动态，特别是SGLD在连续时间模型中的表现。

Method: 本文建立了随机梯度Langevin动力学（SGLD）的非渐近收敛分析，SGLD是连续时间随机梯度下降的Itô随机微分方程（SDE）近似。

Result: 在损失函数Hessian的正则条件下，具有乘性及状态相关噪声的SGLD在整个训练过程中以高概率产生非退化核，并实现了对经验风险最小化器的期望指数收敛。同时，我们建立了关于最优性差距的有限时间和有限宽度界限。

Conclusion: 本文通过理论分析和回归设置中的数值例子，验证了在惰性训练状态下，SGLD在特定条件下能够高效且稳定地收敛，为深度学习优化算法提供了新的理论支持。

Abstract: Continuous-time models provide important insights into the training dynamics
of optimization algorithms in deep learning. In this work, we establish a
non-asymptotic convergence analysis of stochastic gradient Langevin dynamics
(SGLD), which is an It\^o stochastic differential equation (SDE) approximation
of stochastic gradient descent in continuous time, in the lazy training regime.
We show that, under regularity conditions on the Hessian of the loss function,
SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate
kernel throughout the training process with high probability, and (ii) achieves
exponential convergence to the empirical risk minimizer in expectation, and we
establish finite-time and finite-width bounds on the optimality gap. We
corroborate our theoretical findings with numerical examples in the regression
setting.

</details>


### [120] [PINN Balls: Scaling Second-Order Methods for PINNs with Domain Decomposition and Adaptive Sampling](https://arxiv.org/abs/2510.21262)
*Andrea Bonfanti,Ismael Medina,Roman List,Björn Staeves,Roberto Santana,Marco Ellero*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为PINN Balls的局部专家混合模型，它结合了集成模型和稀疏编码的参数效率，以实现二阶训练。


<details>
  <summary>Details</summary>
Motivation: 传统的PINNs方法在处理复杂的偏微分方程时，二阶方法会带来巨大的内存需求，导致模型规模扩大时性能不佳。

Method: 本文提出了一种局部专家混合（MoE）模型，名为PINN Balls，该模型结合了集成模型和稀疏编码的参数效率，从而支持二阶训练。此外，PINN Balls还通过对抗性自适应采样（AAS）实现了完全可学习的域分解结构。

Result: PINN Balls在科学机器学习领域取得了比现有技术更高的精度，同时保持了宝贵的可扩展性。

Conclusion: PINN Balls模型通过引入局部专家混合和可学习的域分解结构，成功解决了PINNs在二阶训练中遇到的内存瓶颈问题，并在保持可扩展性的同时提高了精度。

Abstract: Recent advances in Scientific Machine Learning have shown that second-order
methods can enhance the training of Physics-Informed Neural Networks (PINNs),
making them a suitable alternative to traditional numerical methods for Partial
Differential Equations (PDEs). However, second-order methods induce large
memory requirements, making them scale poorly with the model size. In this
paper, we define a local Mixture of Experts (MoE) combining the
parameter-efficiency of ensemble models and sparse coding to enable the use of
second-order training. Our model -- \textsc{PINN Balls} -- also features a
fully learnable domain decomposition structure, achieved through the use of
Adversarial Adaptive Sampling (AAS), which adapts the DD to the PDE and its
domain. \textsc{PINN Balls} achieves better accuracy than the state-of-the-art
in scientific machine learning, while maintaining invaluable scalability
properties and drawing from a sound theoretical background.

</details>


### [121] [An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination](https://arxiv.org/abs/2510.21296)
*Sukanya Patra,Souhaib Ben Taieb*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为 EPHAD 的测试时自适应框架，用于解决在真实世界数据中，训练数据中包含未检测到或错误标记的异常值（污染）时，无监督异常检测（AD）方法性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的异常检测解决方案通常需要访问训练流程、数据或预先了解数据中异常值的比例，这限制了它们在实际应用中的可行性。本文旨在解决这一挑战，即使在训练数据被污染的情况下，也能有效地进行异常检测。

Method: EPHAD 框架通过在测试时收集证据来更新在受污染数据集上训练的 AD 模型的输出。它将通过在受污染数据集上训练的 AD 模型捕获到的先验知识与来自多模态基础模型（如 CLIP）、经典 AD 方法（如 Latent Outlier Factor）或特定领域知识的证据相结合。

Result: 通过对 8 个视觉 AD 数据集、26 个表格 AD 数据集和一个真实的工业 AD 数据集的综合实验，以及一项消融研究，验证了 EPHAD 的有效性。结果表明 EPHAD 具有通用性和鲁棒性。

Conclusion: EPHAD 是一个简单而有效的测试时自适应框架，能够显著提高在受污染数据集上训练的无监督异常检测模型的性能，并且在各种 AD 模型和证据对中表现出通用性和鲁棒性。

Abstract: Unsupervised anomaly detection (AD) methods typically assume clean training
data, yet real-world datasets often contain undetected or mislabeled anomalies,
leading to significant performance degradation. Existing solutions require
access to the training pipelines, data or prior knowledge of the proportions of
anomalies in the data, limiting their real-world applicability. To address this
challenge, we propose EPHAD, a simple yet effective test-time adaptation
framework that updates the outputs of AD models trained on contaminated
datasets using evidence gathered at test time. Our approach integrates the
prior knowledge captured by the AD model trained on contaminated datasets with
evidence derived from multimodal foundation models like Contrastive
Language-Image Pre-training (CLIP), classical AD methods like the Latent
Outlier Factor or domain-specific knowledge. We illustrate the intuition behind
EPHAD using a synthetic toy example and validate its effectiveness through
comprehensive experiments across eight visual AD datasets, twenty-six tabular
AD datasets, and a real-world industrial AD dataset. Additionally, we conduct
an ablation study to analyse hyperparameter influence and robustness to varying
contamination levels, demonstrating the versatility and robustness of EPHAD
across diverse AD models and evidence pairs. To ensure reproducibility, our
code is publicly available at https://github.com/sukanyapatra1997/EPHAD.

</details>


### [122] [Data as a Lever: A Neighbouring Datasets Perspective on Predictive Multiplicity](https://arxiv.org/abs/2510.21303)
*Prakhar Ganesh,Hsiang Hsu,Golnoosh Farnadi*

Main category: cs.LG

TL;DR: 这篇论文研究了在机器学习中，数据集中单个数据点的差异如何影响模型多重性（即多个性能相似模型的存在）。


<details>
  <summary>Details</summary>
Motivation: 以往研究多重性主要关注模型选择，而忽视了数据点对多重性的关键作用，特别是单个数据点差异的影响。

Method: 本文引入了“邻近数据集”框架，通过检查单个数据点差异对多重性的影响。他们通过严格的证明，发现在类间分布重叠更大的邻近数据集中，多重性反而更低。随后，将此框架扩展到主动学习和数据插补领域，并提出了多重性感知的数据获取策略和数据插补技术。

Result: 研究发现了一个反直觉的现象：类间分布重叠度越高的邻近数据集，其多重性越低。这个现象由一个共享的Rashomon参数引起，并通过严格证明得到了证实。此外，在主动学习和数据插补中，提出了新的多重性感知方法。

Conclusion: 数据中的微小差异对模型多重性的影响是复杂的，尤其在类间分布重叠度高的情况下，多重性可能降低。理解和利用这种关系可以帮助开发更有效的主动学习和数据插补算法。

Abstract: Multiplicity -- the existence of distinct models with comparable performance
-- has received growing attention in recent years. While prior work has largely
emphasized modelling choices, the critical role of data in shaping multiplicity
has been comparatively overlooked. In this work, we introduce a neighbouring
datasets framework to examine the most granular case: the impact of a
single-data-point difference on multiplicity. Our analysis yields a seemingly
counterintuitive finding: neighbouring datasets with greater inter-class
distribution overlap exhibit lower multiplicity. This reversal of conventional
expectations arises from a shared Rashomon parameter, and we substantiate it
with rigorous proofs.
  Building on this foundation, we extend our framework to two practical
domains: active learning and data imputation. For each, we establish natural
extensions of the neighbouring datasets perspective, conduct the first
systematic study of multiplicity in existing algorithms, and finally, propose
novel multiplicity-aware methods, namely, multiplicity-aware data acquisition
strategies for active learning and multiplicity-aware data imputation
techniques.

</details>


### [123] [Revisiting Social Welfare in Bandits: UCB is (Nearly) All You Need](https://arxiv.org/abs/2510.21312)
*Dhruv Sarkar,Nishant Pandey,Sayak Ray Chowdhury*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的在随机多臂老虎机问题中衡量遗憾的方法，即纳什遗憾，它使用累积奖励的几何平均值来解决传统遗憾指标未能解决的公平性问题，并提出了一种基于UCB算法的近似最优解。


<details>
  <summary>Details</summary>
Motivation: 传统的随机多臂老虎机（MAB）遗憾度量未能充分解决奖励分配中的公平性问题，特别是在临床试验等将奖励分配给群体的场景中。

Method: 本文提出了一种初始阶段均匀探索，随后采用标准UCB算法的方法来最小化纳什遗憾。此外，该算法被推广到更广泛的公平性度量，即p-平均遗憾。

Result: 所提出的UCB算法在仅依赖于加性Hoeffding界限的情况下，取得了近似最优的纳什遗憾，并且可以自然地扩展到亚高斯奖励。同时，该算法对于p-平均遗憾在所有p值上都达到了（接近）最优的遗憾界限。

Conclusion: 本文提出了一种有效且广泛适用的算法，用于在随机多臂老虎机问题中度量和最小化纳什遗憾及p-平均遗憾，解决了传统方法在公平性、假设条件和适用性方面的局限性。

Abstract: Regret in stochastic multi-armed bandits traditionally measures the
difference between the highest reward and either the arithmetic mean of
accumulated rewards or the final reward. These conventional metrics often fail
to address fairness among agents receiving rewards, particularly in settings
where rewards are distributed across a population, such as patients in clinical
trials. To address this, a recent body of work has introduced Nash regret,
which evaluates performance via the geometric mean of accumulated rewards,
aligning with the Nash social welfare function known for satisfying fairness
axioms.
  To minimize Nash regret, existing approaches require specialized algorithm
designs and strong assumptions, such as multiplicative concentration
inequalities and bounded, non-negative rewards, making them unsuitable for even
Gaussian reward distributions. We demonstrate that an initial uniform
exploration phase followed by a standard Upper Confidence Bound (UCB) algorithm
achieves near-optimal Nash regret, while relying only on additive Hoeffding
bounds, and naturally extending to sub-Gaussian rewards. Furthermore, we
generalize the algorithm to a broad class of fairness metrics called the
$p$-mean regret, proving (nearly) optimal regret bounds uniformly across all
$p$ values. This is in contrast to prior work, which made extremely restrictive
assumptions on the bandit instances and even then achieved suboptimal regret
bounds.

</details>


### [124] [SCORENF: Score-based Normalizing Flows for Sampling Unnormalized distributions](https://arxiv.org/abs/2510.21330)
*Vikas Kanaujia,Vipul Arora*

Main category: cs.LG

TL;DR: ScoreNF 是一种基于 Normalizing Flow (NF) 架构和独立 Metropolis-Hastings (IMH) 模块的框架，用于高效、无偏地从未归一化目标分布中采样。


<details>
  <summary>Details</summary>
Motivation: 传统的采样方法存在收敛慢、模式混合差等问题，而现有的机器学习模型又过于依赖数据。如何实现高效准确的采样且不依赖大规模数据是本文的动机。

Method: ScoreNF 框架结合了 Normalizing Flow 的生成能力和独立 Metropolis-Hastings 模块的无偏性，即使在小规模训练集下也能保持高性能。该方法还提出了一种评估模式覆盖和模式崩溃行为的方法。

Result: 在合成二维分布（MOG-4 和 MOG-8）和高维 $\phi^4$ 晶格场理论分布上的验证表明，ScoreNF 能够有效地完成采样任务。

Conclusion: ScoreNF 能够以小规模训练数据为基础，实现高效、无偏的采样，解决了传统方法和现有机器学习模型的痛点。

Abstract: Unnormalized probability distributions are central to modeling complex
physical systems across various scientific domains. Traditional sampling
methods, such as Markov Chain Monte Carlo (MCMC), often suffer from slow
convergence, critical slowing down, poor mode mixing, and high autocorrelation.
In contrast, likelihood-based and adversarial machine learning models, though
effective, are heavily data-driven, requiring large datasets and often
encountering mode covering and mode collapse. In this work, we propose ScoreNF,
a score-based learning framework built on the Normalizing Flow (NF)
architecture, integrated with an Independent Metropolis-Hastings (IMH) module,
enabling efficient and unbiased sampling from unnormalized target
distributions. We show that ScoreNF maintains high performance even with small
training ensembles, thereby reducing reliance on computationally expensive
MCMC-generated training data. We also present a method for assessing
mode-covering and mode-collapse behaviours. We validate our method on synthetic
2D distributions (MOG-4 and MOG-8) and the high-dimensional $\phi^4$ lattice
field theory distribution, demonstrating its effectiveness for sampling tasks.

</details>


### [125] [Assessing the Real-World Utility of Explainable AI for Arousal Diagnostics: An Application-Grounded User Study](https://arxiv.org/abs/2510.21389)
*Stefan Kraft,Andreas Theissler,Vera Wienhausen-Wilke,Gjergji Kasneci,Hendrik Lensch*

Main category: cs.LG

TL;DR: 该研究探讨了AI在临床实践中的有效整合，旨在提升医学信号解读的准确性并建立临床医生对算法推荐的信任。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在生物医学信号解读方面已达到或超越人类专家水平，但其有效整合到临床实践中，需要医生理解何时以及为何信任算法推荐。

Method: 本研究通过一项用户研究，邀请八位专业睡眠医学实践者对多导睡眠图数据中的夜间觉醒事件进行评分。研究设置了三种条件（手动评分、黑盒AI辅助、透明白盒AI辅助），并且辅助的时机分为评分开始时或作为事后质量控制（QC）审查。研究系统性地评估了辅助类型和时机如何影响事件级别的表现、临床最相关的计数表现、时间需求和用户体验。

Result: AI和人机协作团队的表现显著优于未辅助的专家，并且协作还能减少评估者间的差异。作为目标QC步骤的透明AI辅助，其事件级别表现比黑盒辅助提升约30%。QC时机进一步提高了基于计数的评估结果。虽然白盒和QC方法增加了评分所需时间，但开始时辅助更快，并得到多数参与者的偏爱。绝大多数参与者倾向于透明性，有七位参与者表示愿意在少量修改或不修改的情况下采纳该系统。

Conclusion: 策略性地选择透明AI辅助的时机，可以有效地平衡准确性和临床效率，为AI在临床工作流程中的可信整合和用户接受提供了一条有前景的途径。

Abstract: Artificial intelligence (AI) systems increasingly match or surpass human
experts in biomedical signal interpretation. However, their effective
integration into clinical practice requires more than high predictive accuracy.
Clinicians must discern \textit{when} and \textit{why} to trust algorithmic
recommendations. This work presents an application-grounded user study with
eight professional sleep medicine practitioners, who score nocturnal arousal
events in polysomnographic data under three conditions: (i) manual scoring,
(ii) black-box (BB) AI assistance, and (iii) transparent white-box (WB) AI
assistance. Assistance is provided either from the \textit{start} of scoring or
as a post-hoc quality-control (\textit{QC}) review. We systematically evaluate
how the type and timing of assistance influence event-level and clinically most
relevant count-based performance, time requirements, and user experience. When
evaluated against the clinical standard used to train the AI, both AI and
human-AI teams significantly outperform unaided experts, with collaboration
also reducing inter-rater variability. Notably, transparent AI assistance
applied as a targeted QC step yields median event-level performance
improvements of approximately 30\% over black-box assistance, and QC timing
further enhances count-based outcomes. While WB and QC approaches increase the
time required for scoring, start-time assistance is faster and preferred by
most participants. Participants overwhelmingly favor transparency, with seven
out of eight expressing willingness to adopt the system with minor or no
modifications. In summary, strategically timed transparent AI assistance
effectively balances accuracy and clinical efficiency, providing a promising
pathway toward trustworthy AI integration and user acceptance in clinical
workflows.

</details>


### [126] [Large Language Models as Model Organisms for Human Associative Learning](https://arxiv.org/abs/2510.21408)
*Camila Kolling,Vy Ai Vo,Mariya Toneva*

Main category: cs.LG

TL;DR: 本文利用大型语言模型研究联想学习中表征的演变。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型如何作为可扩展的替代方案，来研究生物系统中表征变化如何发生。

Method: 作者将认知神经科学中的联想学习范式应用于大型语言模型，并观察了六个模型中表征的演变。同时，作者引入了“词汇干扰”这一因素，以探究其如何调节表征分化。

Result: 研究发现了一个与非单调可塑性假说一致的非单调模式，即中等相似的项目在学习后会分化。此外，“词汇干扰”会放大这种分化，表明表征变化受到项目相似性和全局竞争的影响。

Conclusion: 大型语言模型不仅是研究类人学习系统中表征动态的强大工具，也是生成关于大脑记忆重组原理新假设的通用计算模型。

Abstract: Associative learning--forming links between co-occurring items--is
fundamental to human cognition, reshaping internal representations in complex
ways. Testing hypotheses on how representational changes occur in biological
systems is challenging, but large language models (LLMs) offer a scalable
alternative. Building on LLMs' in-context learning, we adapt a cognitive
neuroscience associative learning paradigm and investigate how representations
evolve across six models. Our initial findings reveal a non-monotonic pattern
consistent with the Non-Monotonic Plasticity Hypothesis, with moderately
similar items differentiating after learning. Leveraging the controllability of
LLMs, we further show that this differentiation is modulated by the overlap of
associated items with the broader vocabulary--a factor we term vocabulary
interference, capturing how new associations compete with prior knowledge. We
find that higher vocabulary interference amplifies differentiation, suggesting
that representational change is influenced by both item similarity and global
competition. Our findings position LLMs not only as powerful tools for studying
representational dynamics in human-like learning systems, but also as
accessible and general computational models for generating new hypotheses about
the principles underlying memory reorganization in the brain.

</details>


### [127] [DreamerV3-XP: Optimizing exploration through uncertainty estimation](https://arxiv.org/abs/2510.21418)
*Lukas Bierling,Davide Pasero,Jan-Henrik Bertrand,Kiki Van Gerwen*

Main category: cs.LG

TL;DR: DreamerV3-XP 是 DreamerV3 的扩展，通过优先级回放缓冲区和基于世界模型集成的内在奖励来提高探索和学习效率，在 Atari100k 和 DeepMind Control 任务上实现了更快的学习和更低的动态模型损失。


<details>
  <summary>Details</summary>
Motivation: 探索和学习效率是强化学习中的重要挑战，尤其是在稀疏奖励环境中。

Method: DreamerV3-XP 引入了两个主要改进：1. 优先级回放缓冲区：根据回报、重建损失和价值误差对轨迹进行评分。2. 基于集成世界模型预测环境奖励分歧的内在奖励。

Result: DreamerV3-XP 在 Atari100k 和 DeepMind Control Visual Benchmark 的子集上进行了评估，结果证实了原始 DreamerV3 的性能，并表明其扩展功能可以带来更快的学习速度和更低的动态模型损失，尤其是在稀疏奖励设置中表现突出。

Conclusion: DreamerV3-XP 通过优先级回放和内在奖励机制，有效提升了 DreamerV3 的探索和学习效率，在多种任务中展现出优越性，特别是在处理稀疏奖励问题上具有显著优势。

Abstract: We introduce DreamerV3-XP, an extension of DreamerV3 that improves
exploration and learning efficiency. This includes (i) a prioritized replay
buffer, scoring trajectories by return, reconstruction loss, and value error
and (ii) an intrinsic reward based on disagreement over predicted environment
rewards from an ensemble of world models. DreamerV3-XP is evaluated on a subset
of Atari100k and DeepMind Control Visual Benchmark tasks, confirming the
original DreamerV3 results and showing that our extensions lead to faster
learning and lower dynamics model loss, particularly in sparse-reward settings.

</details>


### [128] [Compositional Monte Carlo Tree Diffusion for Extendable Planning](https://arxiv.org/abs/2510.21361)
*Jaesik Yoon,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.LG

TL;DR: C-MCTD通过在线、分布式和预规划组件，将MCTD的规划能力从单一轨迹优化提升到对完整规划组合的推理，从而解决了MCTD在处理长轨迹时的局限性。


<details>
  <summary>Details</summary>
Motivation: MCTD在处理长轨迹时存在局限性，虽然周期性重规划可以连接计划，但规划过程仍然局限于局部，缺乏全局上下文。

Method: C-MCTD框架引入了三个互补组件：1. 在线组合器：通过搜索整个计划组合来进行全局感知规划；2. 分布式组合器：通过从多个起点并行探索来降低搜索复杂性；3. 预规划组合器：通过利用缓存的计划图来加速推理。

Result: C-MCTD将规划从单一轨迹优化提升到对完整计划组合的推理。

Conclusion: C-MCTD通过引入在线、分布式和预规划组件，有效解决了MCTD在处理长轨迹规划时的局限性，实现了对完整计划组合的全局感知规划。

Abstract: Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured
tree search to enable effective trajectory exploration through stepwise
reasoning. However, MCTD remains fundamentally limited by training trajectory
lengths. While periodic replanning allows plan concatenation for longer plan
generation, the planning process remains locally confined, as MCTD searches
within individual trajectories without access to global context. We propose
Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates
planning from individual trajectory optimization to reasoning over complete
plan compositions. C-MCTD introduces three complementary components: (1) Online
Composer, which performs globally-aware planning by searching across entire
plan compositions; (2) Distributed Composer, which reduces search complexity
through parallel exploration from multiple starting points; and (3) Preplan
Composer, which accelerates inference by leveraging cached plan graphs.

</details>


### [129] [Generative Correlation Manifolds: Generating Synthetic Data with Preserved Higher-Order Correlations](https://arxiv.org/abs/2510.21610)
*Jens E. d'Hondt,Wieger R. Punter,Odysseas Papapetrou*

Main category: cs.LG

TL;DR: 该白皮书介绍了一种名为泛化相关性流形（GCM）的综合数据生成方法，该方法通过数学方法证明可以保留数据的全部相关性结构。


<details>
  <summary>Details</summary>
Motivation: 目前，合成数据生成方法在复制简单的总结性统计数据方面表现良好，但在保留数据中定义复杂多变量交互的成对和高阶相关结构方面却力有未逮。由此产生的合成数据，表面上看起来很真实，但在用于复杂的建模任务时却会失效。

Method: 我们引入了泛化相关性流形（GCM），这是一种计算效率高的合成数据生成方法。该技术使用目标相关矩阵的乔利斯基分解来生成数据集，并通过数学证明，保留了源数据集的整个相关性结构——从简单的成对关系到高阶交互。

Result: 通过一个数学证明，GCM可以保留源数据集的整个相关性结构，包括成对关系和高阶交互。

Conclusion: GCM为合成数据生成提供了一种新方法，在保护隐私的数据共享、鲁棒模型训练和模拟方面具有潜在应用。

Abstract: The increasing need for data privacy and the demand for robust machine
learning models have fueled the development of synthetic data generation
techniques. However, current methods often succeed in replicating simple
summary statistics but fail to preserve both the pairwise and higher-order
correlation structure of the data that define the complex, multi-variable
interactions inherent in real-world systems. This limitation can lead to
synthetic data that is superficially realistic but fails when used for
sophisticated modeling tasks. In this white paper, we introduce Generative
Correlation Manifolds (GCM), a computationally efficient method for generating
synthetic data. The technique uses Cholesky decomposition of a target
correlation matrix to produce datasets that, by mathematical proof, preserve
the entire correlation structure -- from simple pairwise relationships to
higher-order interactions -- of the source dataset. We argue that this method
provides a new approach to synthetic data generation with potential
applications in privacy-preserving data sharing, robust model training, and
simulation.

</details>


### [130] [Disentangled Representation Learning via Modular Compositional Bias](https://arxiv.org/abs/2510.21402)
*Whie Jung,Dong Hoon Lee,Seunghoon Hong*

Main category: cs.LG

TL;DR: 该文章提出了一种新的方法来解决在解缠结表示学习（DRL）中，当新的变化因素与先前的假设不符，或者多个因素共存时，需要重新设计架构或目标函数的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的解缠结表示学习（DRL）方法严重依赖于特定的策略，无论是针对属性的学习目标还是针对对象的模型架构，导致当新的变化因素与先前的假设不符（如统计独立性或空间排他性），或者多个因素共存时，需要大量额外的工作来重新设计架构或目标函数。

Method: 本文提出了一种组合偏差（compositional bias），这是一种模块化的归纳偏差，它与目标函数和架构解耦。关键在于不同的因素在数据分布中遵循不同的重组规则（例如，全局属性是互斥的，而对象可以共存）。通过根据特定于因素的规则随机混合潜在变量（即混合策略），并强制编码器通过两个互补的目标来发现混合策略所反映的因素结构：(i) 先验损失，确保每次混合都能解码成真实的图像；(ii) 组合一致性损失，使每个复合图像与其对应的复合潜在变量对齐。

Result: 在属性和对象解缠结方面均表现出具有竞争力的性能，并且独特地实现了全局风格和对象的联合解缠结。

Conclusion: 通过简单调整混合策略，无需修改目标函数或架构，就能实现属性、对象甚至两者的解缠结。这种方法通过引入组合偏差和混合策略，有效解决了现有DRL方法的局限性。

Abstract: Recent disentangled representation learning (DRL) methods heavily rely on
factor specific strategies-either learning objectives for attributes or model
architectures for objects-to embed inductive biases. Such divergent approaches
result in significant overhead when novel factors of variation do not align
with prior assumptions, such as statistical independence or spatial
exclusivity, or when multiple factors coexist, as practitioners must redesign
architectures or objectives. To address this, we propose a compositional bias,
a modular inductive bias decoupled from both objectives and architectures. Our
key insight is that different factors obey distinct recombination rules in the
data distribution: global attributes are mutually exclusive, e.g., a face has
one nose, while objects share a common support (any subset of objects can
co-exist). We therefore randomly remix latents according to factor-specific
rules, i.e., a mixing strategy, and force the encoder to discover whichever
factor structure the mixing strategy reflects through two complementary
objectives: (i) a prior loss that ensures every remix decodes into a realistic
image, and (ii) the compositional consistency loss introduced by Wiedemer et
al. (arXiv:2310.05327), which aligns each composite image with its
corresponding composite latent. Under this general framework, simply adjusting
the mixing strategy enables disentanglement of attributes, objects, and even
both, without modifying the objectives or architectures. Extensive experiments
demonstrate that our method shows competitive performance in both attribute and
object disentanglement, and uniquely achieves joint disentanglement of global
style and objects. Code is available at
https://github.com/whieya/Compositional-DRL.

</details>


### [131] [DEEDEE: Fast and Scalable Out-of-Distribution Dynamics Detection](https://arxiv.org/abs/2510.21638)
*Tala Aljaafari,Varun Kanade,Philip Torr,Christian Schroeder de Witt*

Main category: cs.LG

TL;DR: 本文提出了DEEDEE，一种用于强化学习时间序列的OOD检测器，它能有效识别策略在部署时遇到的分布变化。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域部署强化学习时，由于分布偏移下的脆弱性受到限制，因此需要一种有效的OOD检测方法。

Method: DEEDEE是一种双统计检测器，它仅使用逐 эпизода 的平均值和RBF核相似性来捕捉全局和局部偏差。

Result: DEEDEE在标准RL OOD测试套件上与现有检测器OOD检测器持平或超越，计算量减少了600倍，并且比强基线平均提高了5%的绝对准确性。

Conclusion: 多样化的异常类型通常通过少量低阶统计数据在RL轨迹上留下印记，这为复杂环境中的OOD检测提供了一个紧凑的基础。

Abstract: Deploying reinforcement learning (RL) in safety-critical settings is
constrained by brittleness under distribution shift. We study
out-of-distribution (OOD) detection for RL time series and introduce DEEDEE, a
two-statistic detector that revisits representation-heavy pipelines with a
minimal alternative. DEEDEE uses only an episodewise mean and an RBF kernel
similarity to a training summary, capturing complementary global and local
deviations. Despite its simplicity, DEEDEE matches or surpasses contemporary
detectors across standard RL OOD suites, delivering a 600-fold reduction in
compute (FLOPs / wall-time) and an average 5% absolute accuracy gain over
strong baselines. Conceptually, our results indicate that diverse anomaly types
often imprint on RL trajectories through a small set of low-order statistics,
suggesting a compact foundation for OOD detection in complex environments.

</details>


### [132] [Unified token representations for sequential decision models](https://arxiv.org/abs/2510.21448)
*Zhuojing Tian,Yushu Chen*

Main category: cs.LG

TL;DR: 这篇论文提出了一种统一的Token表示（UTR）方法，以解决离线强化学习中Decision Transformer（DT）及其变体存在的冗余token化和二次注意力复杂度问题，从而提高了模型的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的离线强化学习方法（如Decision Transformer）在处理轨迹时存在token化冗余和注意力机制的二次复杂度问题，这限制了它们在实时或资源受限环境中的可扩展性。

Method: 本文提出了一种统一的Token表示（UTR）方法，将return-to-go、状态和动作合并到一个Token中，从而显著减少了序列长度和模型复杂度。在此基础上，开发了两种变体：UDT（基于Transformer）和UDC（基于门控CNN）。

Result: 理论分析表明，UTR可以获得更紧密的Rademacher复杂度界，从而提高了泛化能力。实验结果表明，UDT和UDC在计算成本显著降低的情况下，实现了与现有最先进方法相当或更优的性能。

Conclusion: UTR方法能够很好地推广到不同的架构中，为未来大型决策模型中的可伸缩控制提供了一个高效的基础。

Abstract: Transformers have demonstrated strong potential in offline reinforcement
learning (RL) by modeling trajectories as sequences of return-to-go, states,
and actions. However, existing approaches such as the Decision Transformer(DT)
and its variants suffer from redundant tokenization and quadratic attention
complexity, limiting their scalability in real-time or resource-constrained
settings. To address this, we propose a Unified Token Representation (UTR) that
merges return-to-go, state, and action into a single token, substantially
reducing sequence length and model complexity. Theoretical analysis shows that
UTR leads to a tighter Rademacher complexity bound, suggesting improved
generalization. We further develop two variants: UDT and UDC, built upon
transformer and gated CNN backbones, respectively. Both achieve comparable or
superior performance to state-of-the-art methods with markedly lower
computation. These findings demonstrate that UTR generalizes well across
architectures and may provide an efficient foundation for scalable control in
future large decision models.

</details>


### [133] [Towards Explainable Personalized Recommendations by Learning from Users' Photos](https://arxiv.org/abs/2510.21455)
*Jorge Díez,Pablo Pérez-Núñez,Oscar Luaces,Beatriz Remeseiro,Antonio Bahamonde*

Main category: cs.LG

TL;DR: 这篇论文探索了个性化解释，通过预测用户会为某个项目拍摄的照片，将解释作为推荐本身来学习。这可以提高推荐系统的可靠性，并帮助公司了解客户对产品的看法。


<details>
  <summary>Details</summary>
Motivation: 解释复杂系统（如推荐系统）的输出对于用户和公司都变得至关重要。

Method: 通过预测用户会为某个项目拍摄的照片来学习个性化解释，因为该图像最能 T 说服用户接受该项目的 N 特性。该方法包括一个估计给定（用户，照片）对的 authorship 概率的正式框架。

Result: 一个可以解释其结果并因此提高其可靠性的推荐系统。公司可以获得关于客户突出其产品方面的生动知识。

Conclusion: 个性化解释可以通过预测用户会为项目拍摄的照片来学习，这可以提高推荐系统的可靠性，并为公司提供有价值的客户洞察。

Abstract: Explaining the output of a complex system, such as a Recommender System (RS),
is becoming of utmost importance for both users and companies. In this paper we
explore the idea that personalized explanations can be learned as
recommendation themselves. There are plenty of online services where users can
upload some photos, in addition to rating items. We assume that users take
these photos to reinforce or justify their opinions about the items. For this
reason we try to predict what photo a user would take of an item, because that
image is the argument that can best convince her of the qualities of the item.
In this sense, an RS can explain its results and, therefore, increase its
reliability. Furthermore, once we have a model to predict attractive images for
users, we can estimate their distribution. Thus, the companies acquire a vivid
knowledge about the aspects that the clients highlight of their products. The
paper includes a formal framework that estimates the authorship probability for
a given pair (user, photo). To illustrate the proposal, we use data gathered
from TripAdvisor containing the reviews (with photos) of restaurants in six
cities of different sizes.

</details>


### [134] [Uniform Convergence Beyond Glivenko-Cantelli](https://arxiv.org/abs/2510.21506)
*Tanmay Devale,Pramith Devulapalli,Steve Hanneke*

Main category: cs.LG

TL;DR: 本文探讨了在给定分布集合下，何时可以对均值进行一致估计。


<details>
  <summary>Details</summary>
Motivation: Vapnik和Chervonenkis (1971) 的先前工作主要集中于使用经验均值估计器进行一致收敛。本文旨在扩展此框架，超越经验均值估计器，引入并定义“一致均值可估计性”（UME-可学习性），以捕捉任意估计器允许对均值进行一致估计的情况。

Method: 本文在由分布集合的均值向量创建的空间中进行研究，其中每个均值向量记录了每个坐标中的期望值。研究人员证明了均值向量的可分离性是UME-可学习性的充分条件。他们还通过构建均值向量不可分离但UME-可学习的分布集合，表明均值向量的可分离性并非UME-可学习性的必要条件，利用了与基于可分离性分析中使用的技术根本不同的方法。

Result: 均值向量的可分离性是UME-可学习性的充分条件，但非必要条件。可数个UME-可学习集合的并集仍然是UME-可学习的。

Conclusion: 本文成功地扩展了均值一致估计的理论框架，提出了UME-可学习性，并解决了Cohen等人（2025）提出的一个猜想。这些发现对于理解和设计更通用的均值估计器具有重要意义。

Abstract: We characterize conditions under which collections of distributions on
$\{0,1\}^\mathbb{N}$ admit uniform estimation of their mean. Prior work from
Vapnik and Chervonenkis (1971) has focused on uniform convergence using the
empirical mean estimator, leading to the principle known as $P-$
Glivenko-Cantelli. We extend this framework by moving beyond the empirical mean
estimator and introducing Uniform Mean Estimability, also called $UME-$
learnability, which captures when a collection permits uniform mean estimation
by any arbitrary estimator. We work on the space created by the mean vectors of
the collection of distributions. For each distribution, the mean vector records
the expected value in each coordinate. We show that separability of the mean
vectors is a sufficient condition for $UME-$ learnability. However, we show
that separability of the mean vectors is not necessary for $UME-$ learnability
by constructing a collection of distributions whose mean vectors are
non-separable yet $UME-$ learnable using techniques fundamentally different
from those used in our separability-based analysis. Finally, we establish that
countable unions of $UME-$ learnable collections are also $UME-$ learnable,
solving a conjecture posed in Cohen et al. (2025).

</details>


### [135] [Probe-based Fine-tuning for Reducing Toxicity](https://arxiv.org/abs/2510.21531)
*Jan Wehner,Mario Fritz*

Main category: cs.LG

TL;DR: 本文探讨了通过在模型激活上训练的探针来检测模型不良行为（如欺骗或偏见）的方法。研究提出利用监督微调和直接偏好优化两种方法来对抗探针进行训练，旨在减少毒性并评估探针准确性下降的程度，以验证探针作为训练信号的可靠性。


<details>
  <summary>Details</summary>
Motivation: 探针能有效检测模型不良行为，并可作为训练信号优化模型内部过程。然而，当探针成为训练目标时，其可靠性可能受损（古德哈特定律）。

Method: 提出两种基于监督微调和直接偏好优化的探针对抗训练方法。通过（1）对抗探针集成、（2）保留未用于训练的探针、（3）训练后重新训练新探针来保持探针检测准确性。

Result: 基于探针的偏好优化比基于分类器的方法更能保留探针的可检测性，表明偏好学习目标有助于维护而非混淆相关表征。探针多样性带来的实际益处有限，训练后重新训练探针即可恢复高检测准确性。

Conclusion: 探针式训练对于某些对齐方法是可行的，若能够重新训练探针，探针集成并非必要。

Abstract: Probes trained on model activations can detect undesirable behaviors like
deception or biases that are difficult to identify from outputs alone. This
makes them useful detectors to identify misbehavior. Furthermore, they are also
valuable training signals, since they not only reward outputs, but also good
internal processes for arriving at that output. However, training against
interpretability tools raises a fundamental concern: when a monitor becomes a
training target, it may cease to be reliable (Goodhart's Law). We propose two
methods for training against probes based on Supervised Fine-tuning and Direct
Preference Optimization. We conduct an initial exploration of these methods in
a testbed for reducing toxicity and evaluate the amount by which probe accuracy
drops when training against them. To retain the accuracy of probe-detectors
after training, we attempt (1) to train against an ensemble of probes, (2)
retain held-out probes that aren't used for training, and (3) retrain new
probes after training.
  First, probe-based preference optimization unexpectedly preserves probe
detectability better than classifier-based methods, suggesting the preference
learning objective incentivizes maintaining rather than obfuscating relevant
representations. Second, probe diversity provides minimal practical benefit -
simply retraining probes after optimization recovers high detection accuracy.
Our findings suggest probe-based training can be viable for certain alignment
methods, though probe ensembles are largely unnecessary when retraining is
feasible.

</details>


### [136] [FrameShield: Adversarially Robust Video Anomaly Detection](https://arxiv.org/abs/2510.21532)
*Mojtaba Nafez,Mobina Poulaei,Nikan Vasei,Bardia Soltani Moakhar,Mohammad Sabokrou,MohammadHossein Rohban*

Main category: cs.LG

TL;DR: 本文提出了一种名为时空区域扭曲（SRD）的伪异常生成方法，通过对正常视频的局部区域进行严重增强来创建合成异常，并结合模型生成的伪标签进行对抗训练，从而显著提高了弱监督视频异常检测模型抵御对抗性攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督视频异常检测（WSVAD）模型容易受到对抗性攻击，但传统的对抗防御机制（如对抗训练）在弱监督环境下无效，因为视频级对抗扰动通常较弱且不足。直接从模型生成的伪标签可以实现帧级对抗训练，但其固有的噪声会显著降低性能。

Method: 本文引入了一种名为时空区域扭曲（SRD）的伪异常生成方法。该方法通过对正常视频中的局部区域应用严重的增强来创建合成异常，同时保持时间一致性。通过将这些精确标注的合成异常与带有噪声的伪标签相结合，显著减少了标签噪声，从而实现了有效的对抗训练。

Result: 实验结果表明，该方法显著增强了WSVAD模型抵御对抗性攻击的鲁棒性，在多个基准测试中，整体AUROC性能平均优于现有最先进方法71.0%。

Conclusion: 本文提出的SRD伪异常生成方法有效解决了弱监督视频异常检测模型在对抗性攻击下的鲁棒性问题，通过结合合成异常和降低伪标签噪声，实现了有效的帧级对抗训练。

Abstract: Weakly Supervised Video Anomaly Detection (WSVAD) has achieved notable
advancements, yet existing models remain vulnerable to adversarial attacks,
limiting their reliability. Due to the inherent constraints of weak
supervision, where only video-level labels are provided despite the need for
frame-level predictions, traditional adversarial defense mechanisms, such as
adversarial training, are not effective since video-level adversarial
perturbations are typically weak and inadequate. To address this limitation,
pseudo-labels generated directly from the model can enable frame-level
adversarial training; however, these pseudo-labels are inherently noisy,
significantly degrading performance. We therefore introduce a novel
Pseudo-Anomaly Generation method called Spatiotemporal Region Distortion (SRD),
which creates synthetic anomalies by applying severe augmentations to localized
regions in normal videos while preserving temporal consistency. Integrating
these precisely annotated synthetic anomalies with the noisy pseudo-labels
substantially reduces label noise, enabling effective adversarial training.
Extensive experiments demonstrate that our method significantly enhances the
robustness of WSVAD models against adversarial attacks, outperforming
state-of-the-art methods by an average of 71.0\% in overall AUROC performance
across multiple benchmarks. The implementation and code are publicly available
at https://github.com/rohban-lab/FrameShield.

</details>


### [137] [Excision Score: Evaluating Edits with Surgical Precision](https://arxiv.org/abs/2510.21537)
*Nikolai Gruzinov,Ksenia Sycheva,Earl T. Barr,Alex Bezzubov*

Main category: cs.LG

TL;DR: 本文提出了一种新的评估文本和代码修订相似性的方法，称为Excision Score（ES），它通过去除原始内容与修订版本之间的共享部分，只比较不同的区域，从而解决了传统方法如BLEU在此类任务中因共享内容过多而导致的评估不准确问题。


<details>
  <summary>Details</summary>
Motivation: 在代码或文本编辑任务中，评估文档修订的质量是一个常见挑战。现有的一些评估方法，例如BLEU，在处理修订时，由于修订版本与原始文档共享大量内容，导致这些方法给出的相似度得分常常不能准确反映人类判断。当人类认为两个修订版本差异很大时，这些方法仍然可能报告高相似度。这一根本性缺陷促使研究者寻求新的度量方法。

Method: 本文提出了一种名为Excision Score（ES）的静态度量方法。该方法首先通过计算最长公共子序列（LCS）来识别并移除原始文档与修订版本（包括预测修订和真实修订）之间的共享内容。然后，它仅比较剩余的、不同的区域。为了提高效率，该方法将标准的三次方LCS计算近似加速到平方级别。此外，作者还提出了修订相似度度量的五个充分性标准，并用这些标准来衡量ES的有效性。

Result: 在代码编辑评估中，ES超越了现有度量标准。在HumanEvalFix数据集上，当与测试执行对齐时，ES的Pearson相关系数比其最接近的竞争对手SARI提高了12%，比BLEU等标准度量提高了21%以上。更重要的是，当增加共享上下文扰动HumanEvalFix时，ES相对于SARI的改进增加到20%，相对于标准度量提高了30%以上，这表明ES对共享上下文具有不变性。ES还能够处理其他度量未能解决的特殊情况，例如正确对齐移动的代码块，并恰当地奖励匹配的插入或删除。

Conclusion: Excision Score（ES）通过创新性地移除共享内容并专注于不同区域的比较，解决了现有相似性度量在评估文本和代码修订时面临的挑战。它在代码编辑评估中展现了卓越的性能，特别是在处理共享上下文和一些特殊情况时，ES能够更准确地反映人类判断，为文档修订的评估提供了更可靠的工具。

Abstract: Many tasks revolve around editing a document, whether code or text. We
formulate the revision similarity problem to unify a wide range of machine
learning evaluation problems whose goal is to assess a revision to an existing
document. We observe that revisions usually change only a small portion of an
existing document, so the existing document and its immediate revisions share a
majority of their content. We formulate five adequacy criteria for revision
similarity measures, designed to align them with human judgement. We show that
popular pairwise measures, like BLEU, fail to meet these criteria, because
their scores are dominated by the shared content. They report high similarity
between two revisions when humans would assess them as quite different. This is
a fundamental flaw we address. We propose a novel static measure, Excision
Score (ES), which computes longest common subsequence (LCS) to remove content
shared by an existing document with the ground truth and predicted revisions,
before comparing only the remaining divergent regions. This is analogous to a
surgeon creating a sterile field to focus on the work area. We use
approximation to speed the standard cubic LCS computation to quadratic. In
code-editing evaluation, where static measures are often used as a cheap proxy
for passing tests, we demonstrate that ES surpasses existing measures. When
aligned with test execution on HumanEvalFix, ES improves over its nearest
competitor, SARI, by 12% Pearson correlation and by >21% over standard measures
like BLEU. The key criterion is invariance to shared context; when we perturb
HumanEvalFix with increased shared context, ES' improvement over SARI increases
to 20% and >30% over standard measures. ES also handles other corner cases that
other measures do not, such as correctly aligning moved code blocks, and
appropriately rewarding matching insertions or deletions.

</details>


### [138] [Interpretable Multimodal Zero-Shot ECG Diagnosis via Structured Clinical Knowledge Alignment](https://arxiv.org/abs/2510.21551)
*Jialu Tang,Hung Manh Pham,Ignace De Lathauwer,Henk S. Schipper,Yuan Lu,Dong Ma,Aaqib Saeed*

Main category: cs.LG

TL;DR: 本文介绍了ZETA，一个零样本多模态框架，用于可解释的心电图（ECG）诊断，其方法是通过将ECG信号与结构化的临床观察结果进行比较，而无需针对特定疾病进行微调。


<details>
  <summary>Details</summary>
Motivation: 目前的自动化心电图系统在透明度和对未见情况的泛化能力方面存在不足。

Method: ZETA通过LLM辅助的专家验证过程，策划了结构化的阳性和阴性临床观察结果，并将ECG信号与这些观察结果进行比较。该方法利用预训练的多模态模型对齐ECG和文本嵌入，而无需针对特定疾病进行微调。

Result: ZETA在零样本分类性能上表现出色，并提供了定性和定量的证据，证明其增强了可解释性，将预测建立在特定的、临床相关的阳性和阴性诊断特征上。

Conclusion: ZETA强调了将ECG分析与结构化临床知识相结合的潜力，以构建更透明、更具泛化性和更值得信赖的AI诊断系统。研究。

Abstract: Electrocardiogram (ECG) interpretation is essential for cardiovascular
disease diagnosis, but current automated systems often struggle with
transparency and generalization to unseen conditions. To address this, we
introduce ZETA, a zero-shot multimodal framework designed for interpretable ECG
diagnosis aligned with clinical workflows. ZETA uniquely compares ECG signals
against structured positive and negative clinical observations, which are
curated through an LLM-assisted, expert-validated process, thereby mimicking
differential diagnosis. Our approach leverages a pre-trained multimodal model
to align ECG and text embeddings without disease-specific fine-tuning.
Empirical evaluations demonstrate ZETA's competitive zero-shot classification
performance and, importantly, provide qualitative and quantitative evidence of
enhanced interpretability, grounding predictions in specific, clinically
relevant positive and negative diagnostic features. ZETA underscores the
potential of aligning ECG analysis with structured clinical knowledge for
building more transparent, generalizable, and trustworthy AI diagnostic
systems. We will release the curated observation dataset and code to facilitate
future research.

</details>


### [139] [REVE: A Foundation Model for EEG -- Adapting to Any Setup with Large-Scale Pretraining on 25,000 Subjects](https://arxiv.org/abs/2510.21585)
*Yassine El Ouahidi,Jonathan Lys,Philipp Thölke,Nicolas Farrugia,Bastien Pasdeloup,Vincent Gripon,Karim Jerbi,Giulia Lioi*

Main category: cs.LG

TL;DR: 本文介绍了REVE，一个专门为脑电图（EEG）设计的预训练模型，它通过新颖的4D位置编码方案和大规模预训练，解决了现有EEG基础模型在处理多样化EEG信号时泛化能力不足的问题，并在10项下游EEG任务中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在语言和视觉领域取得了成功，但由于公共EEG数据集的异构性（不同的协议、设备和电极配置），它们在EEG领域的应用滞后。现有的EEG基础模型难以在这种变化中泛化，通常将预训练限制在单一设置中，导致性能不佳，尤其是在线性探测下。

Method: 本文提出了REVE（Representation for EEG with Versatile Embeddings），一个明确设计用于泛化处理多样化EEG信号的预训练模型。REVE引入了一种新颖的4D位置编码方案，使其能够处理任意长度和电极排列的信号。通过掩码自编码目标，REVE在超过60,000小时的EEG数据上进行了预训练，这些数据来自92个数据集，涵盖25,000名受试者，代表了迄今为止规模最大的EEG预训练工作。

Result: REVE在10项下游EEG任务中取得了最先进的成果，包括运动图像分类、癫痫发作检测、睡眠分期、认知负荷估计和情绪识别。在很少或无需微调的情况下，它展示了强大的泛化能力和细致的时空建模能力。

Conclusion: REVE通过其独特的设计和大规模预训练，有效解决了EEG基础模型在处理多样化数据时的泛化性问题，显著提升了EEG任务的性能，并为标准化EEG研究和临床神经科学的进步提供了支持。

Abstract: Foundation models have transformed AI by reducing reliance on task-specific
data through large-scale pretraining. While successful in language and vision,
their adoption in EEG has lagged due to the heterogeneity of public datasets,
which are collected under varying protocols, devices, and electrode
configurations. Existing EEG foundation models struggle to generalize across
these variations, often restricting pretraining to a single setup, resulting in
suboptimal performance, in particular under linear probing. We present REVE
(Representation for EEG with Versatile Embeddings), a pretrained model
explicitly designed to generalize across diverse EEG signals. REVE introduces a
novel 4D positional encoding scheme that enables it to process signals of
arbitrary length and electrode arrangement. Using a masked autoencoding
objective, we pretrain REVE on over 60,000 hours of EEG data from 92 datasets
spanning 25,000 subjects, representing the largest EEG pretraining effort to
date. REVE achieves state-of-the-art results on 10 downstream EEG tasks,
including motor imagery classification, seizure detection, sleep staging,
cognitive load estimation, and emotion recognition. With little to no
fine-tuning, it demonstrates strong generalization, and nuanced spatio-temporal
modeling. We release code, pretrained weights, and tutorials to support
standardized EEG research and accelerate progress in clinical neuroscience.

</details>


### [140] [Accelerating Data Generation for Nonlinear temporal PDEs via homologous perturbation in solution space](https://arxiv.org/abs/2510.21592)
*Lei Liu,Zhenxin Huang,Hong Wang,huanshuo dong,Haiyang Xin,Hongwei Zhao,Bin Li*

Main category: cs.LG

TL;DR: 该论文提出了一种名为HOPSS的新数据生成算法，旨在解决神经算子在求解非线性时间偏微分方程时对大量解对的需求。HOPSS通过减少生成训练数据集所需的时间步长，显著降低了计算和时间开销，同时保持了模型训练所需的近似精度。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动深度学习方法（如神经算子）在求解非线性时间偏微分方程时，需要大量的解对（方程的解函数和右侧项）。这些解对通常通过传统数值方法生成，需要数千个时间步长迭代，远多于训练所需的几十个，这导致了巨大的计算和时间开销。

Method: HOPSS算法首先从一个可靠的求解器获取一组基础解函数，这些函数通常具有数千个时间步长，然后通过下采样将它们与训练数据集的时间步长对齐。接着，该方法引入“同源扰动”方法：将两个解函数（一个作为主函数，另一个作为按小标量缩放的同源扰动项）与随机噪声结合，以高效生成可比较精度的偏微分方程数据点。最后，利用这些数据点计算原始方程右侧项的变化，以形成新的解对。

Result: 理论和实验结果表明，HOPSS显著降低了时间复杂度。例如，在Navier-Stokes方程上，HOPSS能够在传统方法约10%的时间内生成10,000个样本，并且模型训练性能相当。

Conclusion: HOPSS算法通过创新的数据生成策略，有效解决了神经算子在求解非线性时间偏微分方程时面临的数据生成效率低下问题。该方法在显著减少计算和时间开销的同时，保持了模型训练所需的精度，为深度学习在偏微分方程领域的应用提供了更高效的数据支持。

Abstract: Data-driven deep learning methods like neural operators have advanced in
solving nonlinear temporal partial differential equations (PDEs). However,
these methods require large quantities of solution pairs\u2014the solution
functions and right-hand sides (RHS) of the equations. These pairs are
typically generated via traditional numerical methods, which need thousands of
time steps iterations far more than the dozens required for training, creating
heavy computational and temporal overheads. To address these challenges, we
propose a novel data generation algorithm, called HOmologous Perturbation in
Solution Space (HOPSS), which directly generates training datasets with fewer
time steps rather than following the traditional approach of generating large
time steps datasets. This algorithm simultaneously accelerates dataset
generation and preserves the approximate precision required for model training.
Specifically, we first obtain a set of base solution functions from a reliable
solver, usually with thousands of time steps, and then align them in time steps
with training datasets by downsampling. Subsequently, we propose a "homologous
perturbation" approach: by combining two solution functions (one as the primary
function, the other as a homologous perturbation term scaled by a small scalar)
with random noise, we efficiently generate comparable-precision PDE data
points. Finally, using these data points, we compute the variation in the
original equation's RHS to form new solution pairs. Theoretical and
experimental results show HOPSS lowers time complexity. For example, on the
Navier-Stokes equation, it generates 10,000 samples in approximately 10% of
traditional methods' time, with comparable model training performance.

</details>


### [141] [Generalised Flow Maps for Few-Step Generative Modelling on Riemannian Manifolds](https://arxiv.org/abs/2510.21608)
*Oscar Davis,Michael S. Albergo,Nicholas M. Boffi,Michael M. Bronstein,Avishek Joey Bose*

Main category: cs.LG

TL;DR: 这篇论文提出了广义流图（GFM），一种新的少步生成模型，将欧几里得空间中的流图框架推广到任意黎曼流形，在几何数据集上实现了最先进的样本质量。


<details>
  <summary>Details</summary>
Motivation: 当前的几何生成模型在推理时计算成本高昂，需要复杂的数值模拟，因为它们源于黎曼流形上的动力学度量传输框架，如扩散和流匹配。

Method: 本论文提出了广义流图（GFM），并通过三种基于自蒸馏的训练方法实例化：广义拉格朗日流图、广义欧拉流图和广义渐进流图。

Result: GFM 在一系列几何数据集（包括地理空间数据、RNA 扭转角和双曲流形）上进行了基准测试，在单步和少步评估中实现了最先进的样本质量，并使用隐式概率流获得了优异或有竞争力的对数似然。

Conclusion: 广义流图（GFM）统一并提升了现有欧几里得少步生成模型到黎曼环境，并在几何数据生成任务中展现出卓越的性能。

Abstract: Geometric data and purpose-built generative models on them have become
ubiquitous in high-impact deep learning application domains, ranging from
protein backbone generation and computational chemistry to geospatial data.
Current geometric generative models remain computationally expensive at
inference -- requiring many steps of complex numerical simulation -- as they
are derived from dynamical measure transport frameworks such as diffusion and
flow-matching on Riemannian manifolds. In this paper, we propose Generalised
Flow Maps (GFM), a new class of few-step generative models that generalises the
Flow Map framework in Euclidean spaces to arbitrary Riemannian manifolds. We
instantiate GFMs with three self-distillation-based training methods:
Generalised Lagrangian Flow Maps, Generalised Eulerian Flow Maps, and
Generalised Progressive Flow Maps. We theoretically show that GFMs, under
specific design decisions, unify and elevate existing Euclidean few-step
generative models, such as consistency models, shortcut models, and meanflows,
to the Riemannian setting. We benchmark GFMs against other geometric generative
models on a suite of geometric datasets, including geospatial data, RNA torsion
angles, and hyperbolic manifolds, and achieve state-of-the-art sample quality
for single- and few-step evaluations, and superior or competitive
log-likelihoods using the implicit probability flow.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [142] [\textsc{autoresearcher}: Automating Knowledge-Grounded and Transparent Research Ideation with Multi-Agent Collaboration](https://arxiv.org/abs/2510.20844)
*Jiawei Zhou,Ruicheng Zhu,Mengshi Chen,Jianwei Wang,Kai Wang*

Main category: cs.MA

TL;DR: 该文章介绍了一个名为AutoResearcher的多智能体系统，旨在自动化基于文献的创新构思过程，并通过提供透明的中间推理状态和可调智能体来解决当前系统的黑箱问题，从而生成多样化且有证据支持的假设。


<details>
  <summary>Details</summary>
Motivation: 自动化文献检索和创新构思在研究中至关重要，但现有智能体系统缺乏透明度和可控性，导致其输出可能缺乏充分依据。

Method: AutoResearcher系统包含四个阶段：结构化知识整理、多样化想法生成、多阶段想法筛选以及专家小组评审和综合。该系统提供中间推理状态、执行日志和可调智能体，并生成多样且与证据对齐的假设。其设计是领域无关的。

Result: 在图挖掘案例研究（k-truss破坏问题）中，AutoResearcher成功生成了独特、合理且有证据和批判支持的假设。

Conclusion: AutoResearcher通过其透明化和可控性的设计，克服了现有文献创新构思系统中“黑箱”操作的局限性，实现了知识驱动和高透明度的创新构思。该系统能够生成多样化且有证据支持的假设，并且具有领域无关性。

Abstract: Effective research relies on organizing extensive information and stimulating
novel solutions. Agentic systems have recently emerged as a promising tool to
automate literature-based ideation. However, current systems often remain
black-box. Their outputs may appear plausible but weakly grounded, with limited
transparency or control for researchers. Our work introduces
\textsc{autoresearcher}, a multi-agent demo system for knowledge-grounded and
transparent ideation. Specifically, \textsc{autoresearcher} integrates
meticulously designed four stages into a unified framework: (A) Structured
Knowledge Curation, (B) Diversified Idea Generation, (C) Multi-stage Idea
Selection, and (D) Expert Panel Review \& Synthesis. Different from prior
pipelines, our system not only exposes intermediate reasoning states, execution
logs, and tunable agents for inspections, but also enables the generation of
hypotheses that are both diverse and evidence-aligned. Our design is also
domain-agnostic: as long as literature sources exist, the same pipeline can be
instantiated in any scientific field. As an illustrative case, we demonstrate
\textsc{autoresearcher} on a graph-mining case study ($k$-truss breaking
problem), where it generates distinct, plausible hypotheses with evidence and
critiques. A live demo and source code are available at
https://github.com/valleysprings/AutoResearcher.

</details>


### [143] [HIKMA: Human-Inspired Knowledge by Machine Agents through a Multi-Agent Framework for Semi-Autonomous Scientific Conferences](https://arxiv.org/abs/2510.21370)
*Zain Ul Abideen Tariq,Mahmood Al-Zubaidi,Uzair Shah,Marco Agus,Mowafa Househ*

Main category: cs.MA

TL;DR: HIKMA 半自治会议是第一个通过将人工智能端到端集成到学术出版和演示流程中来重塑学术交流的实验。


<details>
  <summary>Details</summary>
Motivation: 探索人工智能在学术出版和演示流程中的集成，以支持而非取代传统学术实践。

Method: HIKMA 框架的设计、实施和评估，该框架包括AI数据集策展、AI手稿生成、AI辅助同行评审、AI驱动修订、AI会议演示和AI档案传播。

Result: HIKMA 展示了人工智能如何在保持知识产权保护、透明度和完整性的同时，支持传统学术实践。

Conclusion: HIKMA 会议作为一个试验台和概念验证，为人工智能辅助学术研究的机遇和挑战提供了见解，并探讨了人工智能作者身份、问责制以及人机协作在研究中的作用等问题。

Abstract: HIKMA Semi-Autonomous Conference is the first experiment in reimagining
scholarly communication through an end-to-end integration of artificial
intelligence into the academic publishing and presentation pipeline. This paper
presents the design, implementation, and evaluation of the HIKMA framework,
which includes AI dataset curation, AI-based manuscript generation, AI-assisted
peer review, AI-driven revision, AI conference presentation, and AI archival
dissemination. By combining language models, structured research workflows, and
domain safeguards, HIKMA shows how AI can support - not replace traditional
scholarly practices while maintaining intellectual property protection,
transparency, and integrity. The conference functions as a testbed and proof of
concept, providing insights into the opportunities and challenges of AI-enabled
scholarship. It also examines questions about AI authorship, accountability,
and the role of human-AI collaboration in research.

</details>


### [144] [ColorEcosystem: Powering Personalized, Standardized, and Trustworthy Agentic Service in massive-agent Ecosystem](https://arxiv.org/abs/2510.21566)
*Fangwen Wu,Zheng Wu,Jihong Wang,Yunku Chen,Ruiguang Pei,Heyuan Huang,Xin Liao,Xingyu Lou,Huarong Deng,Zhihui Fu,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang,Jun Wang*

Main category: cs.MA

TL;DR: ColorEcosystem是一个为大规模多智能体生态系统提供个性化、标准化和可信赖智能体服务的新颖蓝图，旨在解决当前系统中的非人称服务体验、缺乏标准化和不可信行为等挑战。


<details>
  <summary>Details</summary>
Motivation: 解决当前大规模多智能体生态系统中存在的非人称服务体验、缺乏标准化和不可信行为等问题。

Method: 提出ColorEcosystem，包含智能体载体、智能体商店和智能体审计三个核心组件。智能体载体通过利用用户特定数据和创建数字孪生提供个性化服务；智能体商店作为管理多样化智能体服务的中心化、标准化平台；智能体审计基于对开发者和用户活动的监督确保服务提供者和用户的完整性和可信度。

Result: ColorEcosystem能够在大规模多智能体生态系统中实现个性化、标准化和可信赖的智能体服务。

Conclusion: ColorEcosystem为大规模多智能体服务提供了一个全面的解决方案，通过其三个核心组件解决了现有挑战，并已部分实现和开源。

Abstract: With the rapid development of (multimodal) large language model-based agents,
the landscape of agentic service management has evolved from single-agent
systems to multi-agent systems, and now to massive-agent ecosystems. Current
massive-agent ecosystems face growing challenges, including impersonal service
experiences, a lack of standardization, and untrustworthy behavior. To address
these issues, we propose ColorEcosystem, a novel blueprint designed to enable
personalized, standardized, and trustworthy agentic service at scale.
Concretely, ColorEcosystem consists of three key components: agent carrier,
agent store, and agent audit. The agent carrier provides personalized service
experiences by utilizing user-specific data and creating a digital twin, while
the agent store serves as a centralized, standardized platform for managing
diverse agentic services. The agent audit, based on the supervision of
developer and user activities, ensures the integrity and credibility of both
service providers and users. Through the analysis of challenges, transitional
forms, and practical considerations, the ColorEcosystem is poised to power
personalized, standardized, and trustworthy agentic service across
massive-agent ecosystems. Meanwhile, we have also implemented part of
ColorEcosystem's functionality, and the relevant code is open-sourced at
https://github.com/opas-lab/color-ecosystem.

</details>
