{"id": "2511.21624", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21624", "abs": "https://arxiv.org/abs/2511.21624", "authors": ["Kay Liu", "Yuwei Han", "Haoyan Xu", "Henry Peng Zou", "Yue Zhao", "Philip S. Yu"], "title": "TAGFN: A Text-Attributed Graph Dataset for Fake News Detection in the Age of LLMs", "comment": "Preprint. Under review", "summary": "Large Language Models (LLMs) have recently revolutionized machine learning on text-attributed graphs, but the application of LLMs to graph outlier detection, particularly in the context of fake news detection, remains significantly underexplored. One of the key challenges is the scarcity of large-scale, realistic, and well-annotated datasets that can serve as reliable benchmarks for outlier detection. To bridge this gap, we introduce TAGFN, a large-scale, real-world text-attributed graph dataset for outlier detection, specifically fake news detection. TAGFN enables rigorous evaluation of both traditional and LLM-based graph outlier detection methods. Furthermore, it facilitates the development of misinformation detection capabilities in LLMs through fine-tuning. We anticipate that TAGFN will be a valuable resource for the community, fostering progress in robust graph-based outlier detection and trustworthy AI. The dataset is publicly available at https://huggingface.co/datasets/kayzliu/TAGFN and our code is available at https://github.com/kayzliu/tagfn.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86TAGFN\uff0c\u4e00\u4e2a\u7528\u4e8e\u5f02\u5e38\u503c\u68c0\u6d4b\uff08\u7279\u522b\u662f\u5047\u65b0\u95fb\u68c0\u6d4b\uff09\u7684\u5927\u89c4\u6a21\u771f\u5b9e\u4e16\u754c\u6587\u672c\u5c5e\u6027\u56fe\u6570\u636e\u96c6\uff0c\u65e8\u5728\u89e3\u51b3\u8be5\u9886\u57df\u7f3a\u4e4f\u53ef\u9760\u57fa\u51c6\u6570\u636e\u96c6\u7684\u95ee\u9898\u3002\u8be5\u6570\u636e\u96c6\u652f\u6301\u4f20\u7edf\u548c\u57fa\u4e8eLLM\u7684\u56fe\u5f02\u5e38\u503c\u68c0\u6d4b\u65b9\u6cd5\u7684\u8bc4\u4f30\uff0c\u5e76\u4fc3\u8fdb\u901a\u8fc7\u5fae\u8c03LLM\u6765\u5f00\u53d1\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5f7b\u5e95\u6539\u53d8\u4e86\u6587\u672c\u5c5e\u6027\u56fe\u4e0a\u7684\u673a\u5668\u5b66\u4e60\uff0c\u4f46\u5b83\u4eec\u5728\u56fe\u5f02\u5e38\u503c\u68c0\u6d4b\uff0c\u7279\u522b\u662f\u5728\u5047\u65b0\u95fb\u68c0\u6d4b\u4e2d\u7684\u5e94\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u4e3b\u8981\u6311\u6218\u5728\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u771f\u5b9e\u4e14\u6807\u6ce8\u826f\u597d\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u53ef\u4ee5\u4f5c\u4e3a\u5f02\u5e38\u503c\u68c0\u6d4b\u7684\u53ef\u9760\u57fa\u51c6\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5f15\u5165TAGFN\u6570\u636e\u96c6\u6765\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u8be5\u6570\u636e\u96c6\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u771f\u5b9e\u4e16\u754c\u7684\u6587\u672c\u5c5e\u6027\u56fe\u6570\u636e\u96c6\uff0c\u4e13\u4e3a\u5f02\u5e38\u503c\uff08\u5c24\u5176\u662f\u5047\u65b0\u95fb\uff09\u68c0\u6d4b\u800c\u8bbe\u8ba1\u3002", "result": "TAGFN\u6570\u636e\u96c6\u7684\u5f15\u5165\uff0c\u4f7f\u5f97\u80fd\u591f\u5bf9\u4f20\u7edf\u548c\u57fa\u4e8eLLM\u7684\u56fe\u5f02\u5e38\u503c\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u4e25\u683c\u8bc4\u4f30\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03LLM\u6765\u4fc3\u8fdb\u9519\u8bef\u4fe1\u606f\u68c0\u6d4b\u80fd\u529b\u7684\u53d1\u5c55\u3002", "conclusion": "TAGFN\u5c06\u6210\u4e3a\u793e\u533a\u7684\u5b9d\u8d35\u8d44\u6e90\uff0c\u63a8\u52a8\u9c81\u68d2\u7684\u56fe\u57fa\u5f02\u5e38\u503c\u68c0\u6d4b\u548c\u53ef\u4fe1\u4efb\u4eba\u5de5\u667a\u80fd\u7684\u8fdb\u5c55\u3002"}}
{"id": "2511.21637", "categories": ["cs.GT", "cs.DS", "econ.TH"], "pdf": "https://arxiv.org/pdf/2511.21637", "abs": "https://arxiv.org/abs/2511.21637", "authors": ["Vijay V. Vazirani"], "title": "Arctic Auctions, Linear Fisher Markets, and Rational Convex Programs", "comment": "24 pages", "summary": "This paper unifies two foundational constructs from economics and algorithmic game theory, the Arctic Auction and the linear Fisher market, to address the efficient allocation of differentiated goods in complex markets. Our main contributions are showing that an equilibrium for the Arctic Auction is captured by a Rational Convex Program, and deriving the first combinatorial polynomial-time algorithm for computing Arctic Auction equilibria.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5317\u6781\u62cd\u5356\u548c\u7ebf\u6027\u8d39\u96ea\u5e02\u573a\u8fd9\u4e24\u79cd\u7ecf\u6d4e\u5b66\u548c\u7b97\u6cd5\u535a\u5f08\u8bba\u4e2d\u7684\u57fa\u7840\u7ed3\u6784\u5728\u5dee\u5f02\u5316\u5546\u54c1\u9ad8\u6548\u914d\u7f6e\u4e2d\u7684\u7edf\u4e00\u5e94\u7528\u3002", "motivation": "\u5728\u590d\u6742\u5e02\u573a\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u914d\u7f6e\u5dee\u5f02\u5316\u5546\u54c1\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u7406\u8bba\u6846\u67b6\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8bc1\u660e\u5317\u6781\u62cd\u5356\u7684\u5747\u8861\u53ef\u4ee5\u901a\u8fc7\u6709\u7406\u51f8\u89c4\u5212\u6765\u6355\u6349\uff0c\u5e76\u63a8\u5bfc\u51fa\u4e86\u7b2c\u4e00\u4e2a\u7ec4\u5408\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u8ba1\u7b97\u5317\u6781\u62cd\u5356\u5747\u8861\uff0c\u4ece\u800c\u5c06\u5317\u6781\u62cd\u5356\u548c\u7ebf\u6027\u8d39\u96ea\u5e02\u573a\u8fdb\u884c\u7edf\u4e00\u3002", "result": "\u5317\u6781\u62cd\u5356\u7684\u5747\u8861\u80fd\u591f\u88ab\u6709\u7406\u51f8\u89c4\u5212\u6240\u6355\u6349\uff1b\u83b7\u5f97\u4e86\u7b2c\u4e00\u4e2a\u7528\u4e8e\u8ba1\u7b97\u5317\u6781\u62cd\u5356\u5747\u8861\u7684\u7ec4\u5408\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u5c06\u5317\u6781\u62cd\u5356\u548c\u7ebf\u6027\u8d39\u96ea\u5e02\u573a\u8fd9\u4e24\u79cd\u7406\u8bba\u7ed3\u6784\u7edf\u4e00\u8d77\u6765\uff0c\u5e76\u4e3a\u5dee\u5f02\u5316\u5546\u54c1\u5728\u590d\u6742\u5e02\u573a\u4e2d\u7684\u9ad8\u6548\u914d\u7f6e\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u5de5\u5177\u548c\u7b97\u6cd5\u3002"}}
{"id": "2511.21689", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.21689", "abs": "https://arxiv.org/abs/2511.21689", "authors": ["Hongjin Su", "Shizhe Diao", "Ximing Lu", "Mingjie Liu", "Jiacheng Xu", "Xin Dong", "Yonggan Fu", "Peter Belcak", "Hanrong Ye", "Hongxu Yin", "Yi Dong", "Evelina Bakhturina", "Tao Yu", "Yejin Choi", "Jan Kautz", "Pavlo Molchanov"], "title": "ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration", "comment": "21 pages, 6 figures", "summary": "Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools. ToolOrchestra explicitly uses reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards. Using ToolOrchestra, we produce Orchestrator, an 8B model that achieves higher accuracy at lower cost than previous tool-use agents while aligning with user preferences on which tools are to be used for a given query. On HLE, Orchestrator achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being 2.5x more efficient. On tau2-Bench and FRAMES, Orchestrator surpasses GPT-5 by a wide margin while using only about 30% of the cost. Extensive analysis shows that Orchestrator achieves the best trade-off between performance and cost under multiple metrics, and generalizes robustly to unseen tools. These results demonstrate that composing diverse tools with a lightweight orchestration model is both more efficient and more effective than existing methods, paving the way for practical and scalable tool-augmented reasoning systems.", "AI": {"tldr": "ToolOrchestra \u662f\u4e00\u79cd\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5c0f\u578b\u7f16\u6392\u5668\u6765\u534f\u8c03\u667a\u80fd\u5de5\u5177\u7684\u65b9\u6cd5\uff0c\u5b83\u5728\u89e3\u51b3\u590d\u6742\u95ee\u9898\u65b9\u9762\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u548c\u6709\u6548\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u6df1\u5ea6\u590d\u6742\u95ee\u9898\u65f6\u9762\u4e34\u6982\u5ff5\u6027\u548c\u8ba1\u7b97\u4e0a\u7684\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u63d0\u5347\u6548\u7387\u548c\u667a\u80fd\u4e0a\u9650\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86 ToolOrchestra\uff0c\u5b83\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5c0f\u578b\u7f16\u6392\u5668\u6765\u7ba1\u7406\u5176\u4ed6\u6a21\u578b\u548c\u5de5\u5177\u3002\u8be5\u65b9\u6cd5\u8003\u8651\u4e86\u7ed3\u679c\u3001\u6548\u7387\u548c\u7528\u6237\u504f\u597d\u7b49\u65b9\u9762\u7684\u5956\u52b1\u3002", "result": "\u901a\u8fc7 ToolOrchestra\uff0c\u672c\u6587\u8bad\u7ec3\u4e86\u4e00\u4e2a 8B \u7684 Orchestrator \u6a21\u578b\u3002\u8be5\u6a21\u578b\u5728 HLE \u4e0a\u7684\u5f97\u5206\u8fbe\u5230 37.1%\uff0c\u8d85\u8fc7\u4e86 GPT-5 (35.1%)\uff0c\u540c\u65f6\u6548\u7387\u63d0\u5347\u4e86 2.5 \u500d\u3002\u5728 tau2-Bench \u548c FRAMES \u4e0a\uff0cOrchestrator \u4e5f\u5927\u5e45\u8d85\u8d8a GPT-5\uff0c\u800c\u6210\u672c\u4ec5\u4e3a\u5176 30%\u3002", "conclusion": "ToolOrchestra \u7684\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7f16\u6392\u6a21\u578b\u7ec4\u5408\u4e0d\u540c\u7684\u5de5\u5177\uff0c\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u9ad8\u6548\u548c\u6709\u6548\uff0c\u4e3a\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u5de5\u5177\u589e\u5f3a\u63a8\u7406\u7cfb\u7edf\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2511.21636", "categories": ["cs.AI", "stat.AP", "stat.CO", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.21636", "abs": "https://arxiv.org/abs/2511.21636", "authors": ["Peter S. Hovmand", "Kari O'Donnell", "Callie Ogland-Hand", "Brian Biroscak", "Douglas D. Gunzler"], "title": "Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling", "comment": "Presented at 43rd Conference of the International System Dynamics Society in Boston, United States", "summary": "AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's \"the unavoidable a priori\"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86AI/ML\u6a21\u578b\u4e2d\u4eba\u7c7b\u504f\u89c1\u7684\u653e\u5927\u6548\u5e94\uff0c\u5e76\u63d0\u51fa\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u4e0e\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u76f8\u7ed3\u5408\uff0c\u4ee5\u671f\u5f25\u5408\u4e0d\u540c\u5b66\u79d1\u65b9\u6cd5\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u4e3a\u6570\u636e\u79d1\u5b66\u548cAI/ML\u5e94\u7528\u63d0\u4f9b\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\u548c\u8ba4\u77e5\u57fa\u7840\u3002", "motivation": "AI/ML\u6a21\u578b\u5728\u89e3\u51b3\u95ee\u9898\u7684\u540c\u65f6\uff0c\u4e5f\u65e0\u610f\u4e2d\u653e\u5927\u4e86\u4eba\u7c7b\u504f\u89c1\u3002\u8d1f\u8d23\u4efb\u7684AI/ML\u5021\u5bfc\u8005\u8bd5\u56fe\u5229\u7528\u7cfb\u7edf\u52a8\u529b\u5b66\u66f4\u4e30\u5bcc\u7684\u56e0\u679c\u6a21\u578b\u6765\u6307\u5bfc\u8d1f\u8d23\u4efb\u7684AI/ML\u5f00\u53d1\u3002\u7136\u800c\uff0c\u4e0d\u540c\u5b66\u79d1\u65b9\u6cd5\uff08\u5982\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\uff09\u4e4b\u95f4\u6f5c\u5728\u5047\u8bbe\u7684\u5dee\u5f02\u963b\u788d\u4e86\u8fd9\u9879\u5de5\u4f5c\u7684\u8fdb\u5c55\u3002", "method": "\u672c\u6587\u5c06\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\u6574\u5408\u5230\u4e00\u4e2a\u5171\u540c\u7684\u6570\u5b66\u6846\u67b6\u4e2d\u3002", "result": "\u8fd9\u4e2a\u5171\u540c\u7684\u6570\u5b66\u6846\u67b6\u53ef\u4ee5\u7528\u4e8e\u4ece\u5206\u5e03\u4e2d\u751f\u6210\u7cfb\u7edf\u3001\u5f00\u53d1\u65b9\u6cd5\u548c\u6bd4\u8f83\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u65e8\u5728\u901a\u8fc7\u7ed3\u5408\u7cfb\u7edf\u52a8\u529b\u5b66\u548c\u7ed3\u6784\u65b9\u7a0b\u6a21\u578b\uff0c\u4e3a\u6570\u636e\u79d1\u5b66\u548cAI/ML\u5e94\u7528\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6570\u5b66\u6846\u67b6\uff0c\u6765\u5f25\u5408\u4e0d\u540c\u65b9\u6cd5\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u5e76\u4e3a\u7cfb\u7edf\u52a8\u529b\u5b66\u5e94\u7528\u4e8e\u6570\u636e\u79d1\u5b66\u548cAI/ML\u7684\u8ba4\u77e5\u57fa\u7840\u63d0\u4f9b\u4fe1\u606f\u3002"}}
{"id": "2511.21591", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21591", "abs": "https://arxiv.org/abs/2511.21591", "authors": ["Charles Schepanowski", "Charles Ling"], "title": "On the Limits of Innate Planning in Large Language Models", "comment": "33 pages, 7 figures", "summary": "Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0d\u4f7f\u7528\u5de5\u5177\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u89c4\u5212\u548c\u72b6\u6001\u63a8\u7406\u7684\u80fd\u529b\u3002\u901a\u8fc78-puzzle\u4efb\u52a1\u8bc4\u4f30\uff0c\u53d1\u73b0LLMs\u5728\u6b64\u7c7b\u4efb\u52a1\u4e2d\u5b58\u5728\u8106\u6027\u5185\u90e8\u72b6\u6001\u8868\u793a\u548c\u5f31\u542f\u53d1\u5f0f\u89c4\u5212\u7b49\u663e\u8457\u5c40\u9650\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u89c4\u5212\u548c\u6709\u72b6\u6001\u63a8\u7406\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u76f4\u63a5\u7814\u7a76LLMs\u7684\u8fd9\u4e9b\u80fd\u529b\uff0c\u4e0d\u4f9d\u8d56\u4ee3\u7801\u6267\u884c\u6216\u5176\u4ed6\u5916\u90e8\u5de5\u5177\u3002", "method": "\u672c\u6587\u4f7f\u75288-puzzle\uff08\u516b\u6570\u7801\u95ee\u9898\uff09\u4f5c\u4e3a\u6d4b\u8bd5\u4efb\u52a1\uff0c\u8be5\u4efb\u52a1\u8981\u6c42\u8ddf\u8e2a\u72b6\u6001\u548c\u8fdb\u884c\u76ee\u6807\u5bfc\u5411\u7684\u89c4\u5212\uff0c\u5e76\u5141\u8bb8\u7cbe\u786e\u3001\u9010\u6b65\u7684\u8bc4\u4f30\u3002\u5728\u5e38\u89c1\u7684\u63d0\u793a\u6761\u4ef6\uff08Zero-Shot, Chain-of-Thought, Algorithm-of-Thought\uff09\u4ee5\u53ca\u5206\u5c42\u7ea0\u6b63\u53cd\u9988\u4e0b\u6d4b\u8bd5\u4e86\u56db\u79cd\u6a21\u578b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u5916\u90e8\u79fb\u52a8\u9a8c\u8bc1\u5668\uff0c\u53ea\u63d0\u4f9b\u6709\u6548\u79fb\u52a8\uff0c\u4ee5\u8fdb\u4e00\u6b65\u8bc4\u4f30\u6a21\u578b\u7684\u80fd\u529b\u3002", "result": "\u7ea0\u6b63\u53cd\u9988\u5728\u67d0\u4e9b\u6a21\u578b-\u63d0\u793a\u7ec4\u5408\u4e0b\u63d0\u9ad8\u4e86\u6210\u529f\u7387\uff0c\u4f46\u8bb8\u591a\u6210\u529f\u7684\u8fd0\u884c\u662f\u6f2b\u957f\u3001\u8ba1\u7b97\u6602\u8d35\u4e14\u95f4\u63a5\u7684\u3002\u5373\u4f7f\u5728\u5916\u90e8\u79fb\u52a8\u9a8c\u8bc1\u5668\u63d0\u4f9b\u5e2e\u52a9\u7684\u60c5\u51b5\u4e0b\uff0c\u6240\u6709\u6a21\u578b\u90fd\u672a\u80fd\u89e3\u51b3\u4efb\u4f55\u8c1c\u9898\u3002\u5b9a\u6027\u5206\u6790\u63ed\u793a\u4e86\u6240\u6709\u6a21\u578b\u666e\u904d\u5b58\u5728\u7684\u4e24\u4e2a\u4e3b\u8981\u7f3a\u9677\uff1a1\uff09\u8106\u6027\u5185\u90e8\u72b6\u6001\u8868\u793a\uff0c\u5bfc\u81f4\u9891\u7e41\u7684\u65e0\u6548\u79fb\u52a8\uff1b2\uff09\u5f31\u542f\u53d1\u5f0f\u89c4\u5212\uff0c\u6a21\u578b\u7ecf\u5e38\u9677\u5165\u5faa\u73af\u6216\u9009\u62e9\u4e0d\u80fd\u7f29\u77ed\u4e0e\u76ee\u6807\u72b6\u6001\u8ddd\u79bb\u7684\u884c\u52a8\u3002", "conclusion": "\u5728\u6ca1\u6709\u5916\u90e8\u5de5\u5177\uff08\u5982\u4ee3\u7801\u89e3\u91ca\u5668\uff09\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u524dLLMs\u5728\u89c4\u5212\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\u3002\u672a\u6765\u7684\u8fdb\u5c55\u53ef\u80fd\u9700\u8981\u7ef4\u62a4\u663e\u5f0f\u72b6\u6001\u548c\u6267\u884c\u7ed3\u6784\u5316\u641c\u7d22\u7684\u673a\u5236\u3002"}}
{"id": "2511.21678", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21678", "abs": "https://arxiv.org/abs/2511.21678", "authors": ["Weihao Bo", "Shan Zhang", "Yanpeng Sun", "Jingjing Wu", "Qunyi Xie", "Xiao Tan", "Kunbin Chen", "Wei He", "Xiaofan Li", "Na Zhao", "Jingdong Wang", "Zechao Li"], "title": "Agentic Learner with Grow-and-Refine Multimodal Semantic Memory", "comment": null, "summary": "MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.", "AI": {"tldr": "ViLoMem\u662f\u4e00\u4e2a\u53cc\u6d41\u8bb0\u5fc6\u6846\u67b6\uff0c\u53ef\u4ee5\u5e2e\u52a9MLLM\u907f\u514d\u91cd\u590d\u72af\u9519\uff0c\u5e76\u5728\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u63d0\u9ad8\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLMs\uff09\u5728\u89e3\u51b3\u72ec\u7acb\u67e5\u8be2\u65f6\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u4ece\u5934\u5f00\u59cb\u89e3\u51b3\u6bcf\u4e2a\u95ee\u9898\uff0c\u5bb9\u6613\u91cd\u590d\u72af\u9519\u3002\u73b0\u6709\u7684\u8bb0\u5fc6\u589e\u5f3a\u667a\u80fd\u4f53\u4e3b\u8981\u5b58\u50a8\u8fc7\u53bb\u7684\u8f68\u8ff9\u4ee5\u4f9b\u91cd\u7528\uff0c\u4f46\u8fd9\u79cd\u8bb0\u5fc6\u5b58\u5728\u7b80\u6d01\u6027\u504f\u5dee\uff0c\u5e76\u4e14\u65e0\u6cd5\u4fdd\u5b58\u89c6\u89c9\u6ce8\u610f\u529b\u548c\u903b\u8f91\u63a8\u7406\u5982\u4f55\u5171\u540c\u4fc3\u8fdb\u89e3\u51b3\u65b9\u6848\u3002\u8fd9\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u4e0d\u7b26\uff0c\u4eba\u7c7b\u7684\u8bed\u4e49\u8bb0\u5fc6\u662f\u591a\u6a21\u6001\u548c\u6574\u5408\u7684\u3002", "method": "\u6211\u4eec\u5f15\u5165\u4e86ViLoMem\uff0c\u8fd9\u662f\u4e00\u4e2a\u53cc\u6d41\u8bb0\u5fc6\u6846\u67b6\uff0c\u5b83\u6784\u5efa\u4e86\u7d27\u51d1\u7684\u3001\u57fa\u4e8e\u6a21\u5f0f\u7684\u8bb0\u5fc6\u3002\u5b83\u5206\u522b\u7f16\u7801\u89c6\u89c9\u5206\u6563\u6a21\u5f0f\u548c\u903b\u8f91\u63a8\u7406\u9519\u8bef\uff0c\u4f7fMLLM\u80fd\u591f\u4ece\u6210\u529f\u548c\u5931\u8d25\u7684\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u3002\u9075\u5faa\u201c\u589e\u957f\u548c\u5b8c\u5584\u201d\u7684\u539f\u5219\uff0c\u7cfb\u7edf\u9010\u6b65\u79ef\u7d2f\u548c\u66f4\u65b0\u591a\u6a21\u6001\u8bed\u4e49\u77e5\u8bc6\uff0c\u4ee5\u4fdd\u6301\u7a33\u5b9a\u3001\u53ef\u63a8\u5e7f\u7684\u7b56\u7565\uff0c\u540c\u65f6\u907f\u514d\u707e\u96be\u6027\u9057\u5fd8\u3002", "result": "\u5728\u516d\u4e2a\u591a\u6a21\u6001\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cViLoMem\u6301\u7eed\u63d0\u9ad8\u4e86pass@1\u51c6\u786e\u6027\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u4e86\u91cd\u590d\u7684\u89c6\u89c9\u548c\u903b\u8f91\u9519\u8bef\u3002\u6d88\u878d\u5b9e\u9a8c\u8bc1\u5b9e\u4e86\u5177\u6709\u660e\u786e\u5206\u6563-\u5e7b\u89c9\u5206\u79bb\u7684\u53cc\u6d41\u8bb0\u5fc6\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "ViLoMem\u662f\u4e00\u4e2a\u6709\u6548\u7684\u53cc\u6a21\u6001\u8bb0\u5fc6\u6846\u67b6\uff0c\u53ef\u4ee5\u5e2e\u52a9MLLM\u4ece\u9519\u8bef\u4e2d\u5b66\u4e60\u5e76\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u53d6\u5f97\u66f4\u597d\u7684\u8868\u73b0\u3002\u8fd9\u79cd\u9519\u8bef\u611f\u77e5\u591a\u6a21\u6001\u8bb0\u5fc6\u5bf9\u4e8e\u7ec8\u8eab\u548c\u8de8\u9886\u57df\u667a\u80fd\u5b66\u4e60\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2511.21610", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21610", "abs": "https://arxiv.org/abs/2511.21610", "authors": ["Yixiu Zhao", "Xiaozhi Wang", "Zijun Yao", "Lei Hou", "Juanzi Li"], "title": "Auxiliary Metrics Help Decoding Skill Neurons in the Wild", "comment": "7 pages, 7 figures. Includes additional appendix", "summary": "Large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, yet their internal mechanisms remain largely opaque. In this paper, we introduce a simple, lightweight, and broadly applicable method with a focus on isolating neurons that encode specific skills. Building upon prior work that identified \"skill neurons\" via soft prompt training on classification tasks, our approach extends the analysis to complex scenarios involving multiple skills. We correlate neuron activations with auxiliary metrics -- such as external labels and the model's own confidence score -- thereby uncovering interpretable and task-specific behaviors without the need for manual token aggregation. We empirically validate our method on tasks spanning open-ended text generation and natural language inference, demonstrating its ability to detect neurons that not only drive known skills but also reveal previously unidentified shortcuts in arithmetic reasoning on BigBench.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u8bc6\u522b\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7f16\u7801\u7279\u5b9a\u6280\u80fd\u7684\u795e\u7ecf\u5143\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5173\u8054\u795e\u7ecf\u5143\u6fc0\u6d3b\u4e0e\u5916\u90e8\u6807\u7b7e\u548c\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7b49\u8f85\u52a9\u6307\u6807\uff0c\u63ed\u793a\u53ef\u89e3\u91ca\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u884c\u4e3a\uff0c\u5e76\u5728\u5f00\u653e\u5f0f\u6587\u672c\u751f\u6210\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u4efb\u52a1\u4e0a\u5f97\u5230\u9a8c\u8bc1\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u80fd\u529b\u5f3a\u5927\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4e0d\u900f\u660e\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u3001\u8f7b\u91cf\u7ea7\u4e14\u5e7f\u6cdb\u9002\u7528\u7684\u65b9\u6cd5\uff0c\u4e13\u6ce8\u4e8e\u5206\u79bb\u7f16\u7801\u7279\u5b9a\u6280\u80fd\u7684\u795e\u7ecf\u5143\u3002\u8be5\u65b9\u6cd5\u5efa\u7acb\u5728\u901a\u8fc7\u5bf9\u5206\u7c7b\u4efb\u52a1\u8fdb\u884c\u8f6f\u63d0\u793a\u8bad\u7ec3\u6765\u8bc6\u522b\u201c\u6280\u80fd\u795e\u7ecf\u5143\u201d\u7684\u5148\u524d\u5de5\u4f5c\u4e4b\u4e0a\uff0c\u5e76\u5c06\u5206\u6790\u6269\u5c55\u5230\u6d89\u53ca\u591a\u79cd\u6280\u80fd\u7684\u590d\u6742\u573a\u666f\u3002\u7814\u7a76\u4eba\u5458\u5c06\u795e\u7ecf\u5143\u6fc0\u6d3b\u4e0e\u8f85\u52a9\u6307\u6807\uff08\u5982\u5916\u90e8\u6807\u7b7e\u548c\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u5206\u6570\uff09\u5173\u8054\u8d77\u6765\uff0c\u4ece\u800c\u63ed\u793a\u4e86\u53ef\u89e3\u91ca\u548c\u4efb\u52a1\u7279\u5b9a\u7684\u884c\u4e3a\uff0c\u800c\u65e0\u9700\u624b\u52a8\u8fdb\u884c\u3002", "result": "\u5728\u5f00\u653e\u5f0f\u6587\u672c\u751f\u6210\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5b83\u4e0d\u4ec5\u80fd\u68c0\u6d4b\u9a71\u52a8\u5df2\u77e5\u6280\u80fd\u7684\u795e\u7ecf\u5143\uff0c\u8fd8\u80fd\u53d1\u73b0BigBench\u7b97\u672f\u63a8\u7406\u4e2d\u4ee5\u524d\u672a\u8bc6\u522b\u7684\u6377\u5f84\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522bLLMs\u4e2d\u7684\u7279\u5b9a\u6280\u80fd\u795e\u7ecf\u5143\uff0c\u63ed\u793a\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u884c\u4e3a\u548c\u6f5c\u5728\u6377\u5f84\u3002"}}
{"id": "2511.21613", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21613", "abs": "https://arxiv.org/abs/2511.21613", "authors": ["Dongyang Fan", "Diba Hashemi", "Sai Praneeth Karimireddy", "Martin Jaggi"], "title": "Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining", "comment": null, "summary": "Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63a2\u8ba8\u4e86\u5c06\u5143\u6570\u636e\u7eb3\u5165\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9884\u8bad\u7ec3\u4ee5\u52a0\u901f\u8bad\u7ec3\u7684\u65b9\u6cd5\u3002", "motivation": "\u4ee5\u5f80\u7684\u5de5\u4f5c\u53ea\u5173\u6ce8\u4e86URL\u8fd9\u4e00\u4e2a\u5143\u6570\u636e\u4fe1\u53f7\uff0c\u8fd9\u7bc7\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u5176\u4ed6\u7c7b\u578b\u7684\u5143\u6570\u636e\u662f\u5426\u80fd\u5e26\u6765\u66f4\u5927\u7684\u76ca\u5904\u3002", "method": "\u4f5c\u8005\u7814\u7a76\u4e86\u66f4\u5e7f\u6cdb\u7684\u5143\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u5f15\u5165\u4e86\u5143\u6570\u636e\u8ffd\u52a0\uff08metadata appending\uff09\u7684\u65b9\u6cd5\uff0c\u5c06\u9884\u6d4b\u9002\u5f53\u5143\u6570\u636e\u4f5c\u4e3a\u8f85\u52a9\u4efb\u52a1\uff0c\u4ee5\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002\u6b64\u5916\uff0c\u8fd8\u4f7f\u7528\u4e86\u901a\u8fc7\u63a9\u7801\u635f\u5931\u8bad\u7ec3\u7684\u53ef\u5b66\u4e60\u5143\u6807\u8bb0\uff08learnable meta-tokens\uff09\u6765\u6062\u590d\u90e8\u5206\u52a0\u901f\u6548\u679c\u3002", "result": "\u4f5c\u8005\u53d1\u73b0\uff0c\u8bf8\u5982\u6587\u6863\u8d28\u91cf\u7684\u7ec6\u7c92\u5ea6\u6307\u6807\u7b49\u5176\u4ed6\u7c7b\u578b\u7684\u5143\u6570\u636e\u4e5f\u80fd\u5728\u9884\u8bad\u7ec3\u65f6\u52a0\u901f\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u8bc6\u522b\u51fa\u6709\u6548\u5143\u6570\u636e\u7684\u5171\u540c\u7279\u5f81\uff1a\u5b83\u4eec\u4ee5\u66f4\u7ec6\u7684\u7c92\u5ea6\u7f16\u7801\u4fe1\u606f\u3002\u901a\u8fc7\u63a2\u7a76\uff0c\u4f5c\u8005\u5206\u6790\u4e86\u6f5c\u5728\u8868\u793a\uff0c\u4ee5\u7406\u89e3\u5143\u6570\u636e\u5982\u4f55\u5f71\u54cd\u5b66\u4e60\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u6574\u5408\u5143\u6570\u636e\u4ee5\u63d0\u9ad8LLM\u9884\u8bad\u7ec3\u7684\u6548\u7387\u548c\u6709\u6548\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6307\u5bfc\u3002"}}
{"id": "2511.21629", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.21629", "abs": "https://arxiv.org/abs/2511.21629", "authors": ["Anna Marklov\u00e1", "Ond\u0159ej Vin\u0161", "Martina Vok\u00e1\u010dov\u00e1", "Ji\u0159\u00ed Mili\u010dka"], "title": "The author is dead, but what if they never lived? A reception experiment on Czech AI- and human-authored poetry", "comment": null, "summary": "Large language models are increasingly capable of producing creative texts, yet most studies on AI-generated poetry focus on English -- a language that dominates training data. In this paper, we examine the perception of AI- and human-written Czech poetry. We ask if Czech native speakers are able to identify it and how they aesthetically judge it. Participants performed at chance level when guessing authorship (45.8\\% correct on average), indicating that Czech AI-generated poems were largely indistinguishable from human-written ones. Aesthetic evaluations revealed a strong authorship bias: when participants believed a poem was AI-generated, they rated it as less favorably, even though AI poems were in fact rated equally or more favorably than human ones on average. The logistic regression model uncovered that the more the people liked a poem, the less probable was that they accurately assign the authorship. Familiarity with poetry or literary background had no effect on recognition accuracy. Our findings show that AI can convincingly produce poetry even in a morphologically complex, low-resource (with respect of the training data of AI models) Slavic language such as Czech. The results suggest that readers' beliefs about authorship and the aesthetic evaluation of the poem are interconnected.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u6377\u514b\u8bed\u4f7f\u7528\u8005\u5bf9AI\u751f\u6210\u8bd7\u6b4c\u7684\u611f\u77e5\uff0c\u53d1\u73b0\u4eba\u4eec\u5728\u8bc6\u522b\u4f5c\u8005\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u5b58\u5728\u5bf9AI\u4f5c\u54c1\u7684\u504f\u89c1\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u975e\u82f1\u8bed\u3001\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u6377\u514b\u8bed\uff09\u4e2d\u751f\u6210\u8bd7\u6b4c\u7684\u80fd\u529b\uff0c\u4ee5\u53ca\u4eba\u7c7b\u5bf9\u5176\u7684\u611f\u77e5\u548c\u8bc4\u4ef7\u3002", "method": "\u53c2\u4e0e\u8005\u5bf9AI\u548c\u4eba\u7c7b\u521b\u4f5c\u7684\u6377\u514b\u8bed\u8bd7\u6b4c\u8fdb\u884c\u4f5c\u8005\u8bc6\u522b\u548c\u5ba1\u7f8e\u5224\u65ad\u3002\u901a\u8fc7\u903b\u8f91\u56de\u5f52\u6a21\u578b\u5206\u6790\u4eba\u4eec\u5bf9\u8bd7\u6b4c\u7684\u559c\u597d\u4e0e\u4f5c\u8005\u8bc6\u522b\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u8003\u5bdf\u4e86\u8bd7\u6b4c\u719f\u6089\u5ea6\u548c\u6587\u5b66\u80cc\u666f\u7684\u5f71\u54cd\u3002", "result": "\u53c2\u4e0e\u8005\u5728\u8bc6\u522b\u4f5c\u8005\u65b9\u9762\u7684\u51c6\u786e\u7387\u63a5\u8fd1\u968f\u673a\u6c34\u5e73\uff08\u5e73\u574745.8%\uff09\uff0c\u8868\u660eAI\u751f\u6210\u7684\u6377\u514b\u8bed\u8bd7\u6b4c\u4e0e\u4eba\u7c7b\u521b\u4f5c\u7684\u8bd7\u6b4c\u57fa\u672c\u65e0\u6cd5\u533a\u5206\u3002\u5ba1\u7f8e\u8bc4\u4ef7\u663e\u793a\u51fa\u5f3a\u70c8\u7684\u4f5c\u8005\u504f\u89c1\uff1a\u5f53\u53c2\u4e0e\u8005\u8ba4\u4e3a\u4e00\u9996\u8bd7\u662fAI\u751f\u6210\u65f6\uff0c\u5373\u4f7fAI\u8bd7\u6b4c\u5728\u5e73\u5747\u6c34\u5e73\u4e0a\u4e0e\u4eba\u7c7b\u8bd7\u6b4c\u76f8\u5f53\u6216\u66f4\u53d7\u6b22\u8fce\uff0c\u4ed6\u4eec\u4e5f\u4f1a\u66f4\u4e0d\u559c\u6b22AI\u8bd7\u6b4c\u3002\u559c\u6b22\u4e00\u9996\u8bd7\u7684\u4eba\u8d8a\u5c11\uff0c\u4ed6\u4eec\u51c6\u786e\u8bc6\u522b\u4f5c\u8005\u7684\u53ef\u80fd\u6027\u5c31\u8d8a\u4f4e\u3002\u5bf9\u8bd7\u6b4c\u7684\u719f\u6089\u5ea6\u6216\u6587\u5b66\u80cc\u666f\u5bf9\u8bc6\u522b\u51c6\u786e\u6027\u6ca1\u6709\u5f71\u54cd\u3002", "conclusion": "AI\u5373\u4f7f\u5728\u5f62\u6001\u590d\u6742\u3001\u4f4e\u8d44\u6e90\u7684\u65af\u62c9\u592b\u8bed\uff08\u5982\u6377\u514b\u8bed\uff09\u4e2d\u4e5f\u80fd\u4ee4\u4eba\u4fe1\u670d\u5730\u521b\u4f5c\u8bd7\u6b4c\u3002\u8bfb\u8005\u7684\u4f5c\u8005\u4fe1\u5ff5\u548c\u8bd7\u6b4c\u5ba1\u7f8e\u8bc4\u4ef7\u4e4b\u95f4\u5b58\u5728\u76f8\u4e92\u5173\u8054\u3002"}}
{"id": "2511.21692", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21692", "abs": "https://arxiv.org/abs/2511.21692", "authors": ["Yeganeh Kordi", "Nihal V. Nayak", "Max Zuo", "Ilana Nguyen", "Stephen H. Bach"], "title": "Revisiting Generalization Across Difficulty Levels: It's Not So Easy", "comment": null, "summary": "We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' generalization across models, datasets, and fine-grained groups of example difficulty. We rank examples in six datasets using the outputs of thousands of different LLMs and Item Response Theory (IRT), a well-established difficulty metric in educational testing. Unlike prior work, our difficulty ratings are therefore determined solely by the abilities of many different LLMs, excluding human opinions of difficulty. With a more objective, larger-scale, and finer-grained analysis, we show that cross-difficulty generalization is often limited; training on either easy or hard data cannot achieve consistent improvements across the full range of difficulties. These results show the importance of having a range of difficulties in both training and evaluation data for LLMs, and that taking shortcuts with respect to difficulty is risky.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e0d\u540c\u4efb\u52a1\u96be\u5ea6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u8de8\u96be\u5ea6\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u8bad\u7ec3\u6216\u8bc4\u4f30\u6570\u636e\u4e2d\u90fd\u5e94\u5305\u542b\u4e0d\u540c\u96be\u5ea6\u8303\u56f4\u7684\u793a\u4f8b\u4ee5\u907f\u514d\u98ce\u9669\u3002", "motivation": "\u63a2\u8ba8LLM\u5982\u4f55\u8de8\u4e0d\u540c\u4efb\u52a1\u96be\u5ea6\u8fdb\u884c\u6cdb\u5316\uff0c\u4ee5\u6709\u6548\u8fdb\u884c\u6570\u636e\u6574\u7406\u548c\u8bc4\u4f30\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u8bad\u7ec3\u6570\u636e\u96be\u5ea6\u5982\u4f55\u5f71\u54cdLLM\u8868\u73b0\u53ca\u5176\u5728\u4e0d\u540c\u96be\u5ea6\u6d4b\u8bd5\u6570\u636e\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u5b58\u5728\u4e89\u8bae\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u6027\u5730\u89e3\u51b3\u6b64\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5bf9\u6a21\u578b\u3001\u6570\u636e\u96c6\u548c\u7ec6\u7c92\u5ea6\u793a\u4f8b\u96be\u5ea6\u7ec4\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u6765\u89e3\u51b3\u95ee\u9898\u3002\u672c\u6587\u4f7f\u7528\u6570\u5343\u4e2a\u4e0d\u540cLLM\u7684\u8f93\u51fa\u548c\u9879\u76ee\u53cd\u5e94\u7406\u8bba\uff08IRT\uff09\u5bf9\u516d\u4e2a\u6570\u636e\u96c6\u4e2d\u7684\u793a\u4f8b\u8fdb\u884c\u96be\u5ea6\u6392\u5e8f\uff0c\u8fd9\u79cd\u96be\u5ea6\u8bc4\u5206\u5b8c\u5168\u7531LLM\u7684\u80fd\u529b\u51b3\u5b9a\uff0c\u6392\u9664\u4e86\u4eba\u7c7b\u7684\u4e3b\u89c2\u5224\u65ad\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8de8\u96be\u5ea6\u6cdb\u5316\u80fd\u529b\u901a\u5e38\u662f\u6709\u9650\u7684\u3002\u65e0\u8bba\u662f\u5728\u7b80\u5355\u6570\u636e\u8fd8\u662f\u56f0\u96be\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u90fd\u65e0\u6cd5\u5728\u6240\u6709\u96be\u5ea6\u8303\u56f4\u5185\u5b9e\u73b0\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "LLM\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u6570\u636e\u4e2d\u90fd\u5e94\u5305\u542b\u4e0d\u540c\u96be\u5ea6\u7684\u793a\u4f8b\u3002\u5728\u5904\u7406\u6570\u636e\u96be\u5ea6\u65f6\u91c7\u53d6\u6377\u5f84\u5b58\u5728\u98ce\u9669\u3002"}}
{"id": "2511.21594", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21594", "abs": "https://arxiv.org/abs/2511.21594", "authors": ["Alex Ning", "Vainateya Rangaraju"], "title": "Visualizing LLM Latent Space Geometry Through Dimensionality Reduction", "comment": "24 pages, 16 figures", "summary": "Large language models (LLMs) achieve state-of-the-art results across many natural language tasks, but their internal mechanisms remain difficult to interpret. In this work, we extract, process, and visualize latent state geometries in Transformer-based language models through dimensionality reduction. We capture layerwise activations at multiple points within Transformer blocks and enable systematic analysis through Principal Component Analysis (PCA) and Uniform Manifold Approximation (UMAP). We demonstrate experiments on GPT-2 and LLaMa models, where we uncover interesting geometric patterns in latent space. Notably, we identify a clear separation between attention and MLP component outputs across intermediate layers, a pattern not documented in prior work to our knowledge. We also characterize the high norm of latent states at the initial sequence position and visualize the layerwise evolution of latent states. Additionally, we demonstrate the high-dimensional helical structure of GPT-2's positional embeddings, the sequence-wise geometric patterns in LLaMa, and experiment with repeating token sequences. We aim to support systematic analysis of Transformer internals with the goal of enabling further reproducible interpretability research. We make our code available at https://github.com/Vainateya/Feature_Geometry_Visualization.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u964d\u7ef4\u65b9\u6cd5\uff08PCA\u548cUMAP\uff09\u63d0\u53d6\u3001\u5904\u7406\u548c\u53ef\u89c6\u5316\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5185\u90e8\u673a\u5236\uff0c\u7279\u522b\u662fTransformer\u6a21\u578b\u4e2d\u7684\u6f5c\u5728\u72b6\u6001\u51e0\u4f55\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u96be\u4ee5\u89e3\u91ca\u3002", "method": "\u672c\u6587\u5728Transformer\u5757\u5185\u7684\u591a\u4e2a\u70b9\u6355\u83b7\u9010\u5c42\u6fc0\u6d3b\uff0c\u5e76\u901a\u8fc7\u4e3b\u6210\u5206\u5206\u6790\uff08PCA\uff09\u548c\u5747\u5300\u6d41\u5f62\u903c\u8fd1\uff08UMAP\uff09\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff1a1. \u5728\u4e2d\u95f4\u5c42\u4e2d\uff0c\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u5c42\u611f\u77e5\u5668\uff08MLP\uff09\u7ec4\u4ef6\u7684\u8f93\u51fa\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u5206\u79bb\u30022. \u521d\u59cb\u5e8f\u5217\u4f4d\u7f6e\u7684\u6f5c\u5728\u72b6\u6001\u89c4\u8303\u8f83\u9ad8\u30023. \u6f5c\u5728\u72b6\u6001\u7684\u9010\u5c42\u6f14\u53d8\u53ef\u89c6\u5316\u30024. GPT-2\u7684\u4f4d\u7f6e\u5d4c\u5165\u5177\u6709\u9ad8\u7ef4\u87ba\u65cb\u7ed3\u6784\u30025. LLaMa\u6a21\u578b\u4e2d\u5b58\u5728\u5e8f\u5217\u51e0\u4f55\u6a21\u5f0f\u30026. \u5bf9\u91cd\u590d\u7684token\u5e8f\u5217\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002", "conclusion": "\u672c\u7814\u7a76\u65e8\u5728\u652f\u6301\u5bf9Transformer\u5185\u90e8\u673a\u5236\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u4ee5\u671f\u63a8\u52a8\u53ef\u590d\u73b0\u7684\u89e3\u91ca\u6027\u7814\u7a76\u3002"}}
{"id": "2511.21622", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21622", "abs": "https://arxiv.org/abs/2511.21622", "authors": ["Hans Gundlach", "Alex Fogelson", "Jayson Lynch", "Ana Trisovic", "Jonathan Rosenfeld", "Anmol Sandhu", "Neil Thompson"], "title": "On the Origin of Algorithmic Progress in AI", "comment": null, "summary": "Algorithms have been estimated to increase AI training FLOP efficiency by a factor of 22,000 between 2012 and 2023 [Ho et al., 2024]. Running small-scale ablation experiments on key innovations from this time period, we are able to account for less than 10x of these gains. Surveying the broader literature, we estimate that additional innovations not included in our ablations account for less than 10x, yielding a total under 100x. This leads us to conduct scaling experiments, which reveal that much of this efficiency gap can be explained by algorithms with scale-dependent efficiency improvements. In particular, we conduct scaling experiments between LSTMs and Transformers, finding exponent differences in their compute-optimal scaling law while finding little scaling difference for many other innovations. These experiments demonstrate that - contrary to standard assumptions - an algorithm's efficiency gains are tied to compute scale. Using experimental extrapolation and literature estimates, we account for 6,930x efficiency gains over the same time period, with the scale-dependent LSTM-to-Transformer transition accounting for the majority of gains. Our results indicate that algorithmic progress for small models has been far slower than previously assumed, and that measures of algorithmic efficiency are strongly reference-dependent.", "AI": {"tldr": "\u8be5\u6587\u7ae0\u5206\u6790\u4e862012\u5e74\u81f32023\u5e74\u95f4AI\u8bad\u7ec3FLOP\u6548\u7387\u7684\u63d0\u9ad8\uff0c\u53d1\u73b0\u5176\u4e2d\u5927\u90e8\u5206\u6548\u7387\u63d0\u5347\u6765\u81ea\u7b97\u6cd5\u7684\u89c4\u6a21\u4f9d\u8d56\u6027\u6548\u7387\u6539\u8fdb\uff0c\u7279\u522b\u662f\u4eceLSTM\u5230Transformer\u7684\u8f6c\u53d8\uff0c\u5e76\u6307\u51fa\u5c0f\u578b\u6a21\u578b\u7684\u7b97\u6cd5\u8fdb\u5c55\u6bd4\u4e4b\u524d\u5047\u8bbe\u7684\u8981\u6162\u3002", "motivation": "\u7814\u7a762012\u5e74\u81f32023\u5e74AI\u8bad\u7ec3FLOP\u6548\u7387\u663e\u8457\u63d0\u5347\u7684\u539f\u56e0\uff0c\u7279\u522b\u662f\u4f20\u7edf\u6d88\u878d\u5b9e\u9a8c\u672a\u80fd\u5b8c\u5168\u89e3\u91ca\u8fd9\u4e9b\u589e\u957f\uff0c\u4ece\u800c\u5f15\u5165\u4e86\u89c4\u6a21\u4f9d\u8d56\u6027\u6548\u7387\u6539\u8fdb\u7684\u89c6\u89d2\u3002", "method": "\u4f5c\u8005\u9996\u5148\u8fdb\u884c\u4e86\u5c0f\u89c4\u6a21\u6d88\u878d\u5b9e\u9a8c\uff0c\u4ee5\u91cf\u5316\u5173\u952e\u521b\u65b0\u5e26\u6765\u7684\u6548\u7387\u589e\u76ca\u3002\u968f\u540e\uff0c\u4ed6\u4eec\u8fdb\u884c\u4e86\u5c3a\u5ea6\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86LSTM\u548cTransformer\u7b49\u7b97\u6cd5\u5728\u4e0d\u540c\u8ba1\u7b97\u89c4\u6a21\u4e0b\u7684\u6548\u7387\u8868\u73b0\u3002\u6700\u540e\uff0c\u7ed3\u5408\u5b9e\u9a8c\u5916\u63a8\u548c\u6587\u732e\u4f30\u8ba1\uff0c\u91cf\u5316\u4e86\u89c4\u6a21\u4f9d\u8d56\u6027\u6548\u7387\u6539\u8fdb\u7684\u603b\u8d21\u732e\u3002", "result": "\u4f20\u7edf\u6d88\u878d\u5b9e\u9a8c\u548c\u6587\u732e\u8c03\u7814\u53ea\u80fd\u89e3\u91ca22,000\u500d\u6548\u7387\u63d0\u5347\u4e2d\u7684\u4e0d\u5230100\u500d\u3002\u901a\u8fc7\u5c3a\u5ea6\u5b9e\u9a8c\uff0c\u4f5c\u8005\u53d1\u73b0\u7b97\u6cd5\u7684\u6548\u7387\u589e\u76ca\u4e0e\u8ba1\u7b97\u89c4\u6a21\u5bc6\u5207\u76f8\u5173\uff0c\u7279\u522b\u662fLSTM\u5230Transformer\u7684\u8f6c\u53d8\u5e26\u6765\u4e86\u663e\u8457\u7684\u89c4\u6a21\u4f9d\u8d56\u6027\u6548\u7387\u63d0\u5347\u3002\u6700\u7ec8\uff0c\u4ed6\u4eec\u89e3\u91ca\u4e86\u540c\u671f6,930\u500d\u7684\u6548\u7387\u63d0\u5347\uff0c\u5176\u4e2d\u5927\u90e8\u5206\u5f52\u56e0\u4e8e\u89c4\u6a21\u4f9d\u8d56\u6027\u7684LSTM\u5230Transformer\u7684\u8f6c\u53d8\u3002", "conclusion": "\u7b97\u6cd5\u6548\u7387\u7684\u63d0\u9ad8\u4e0e\u8ba1\u7b97\u89c4\u6a21\u5bc6\u5207\u76f8\u5173\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5927\u578b\u6a21\u578b\u800c\u8a00\uff0c\u7b97\u6cd5\u521b\u65b0\u5e26\u6765\u4e86\u5de8\u5927\u7684\u6548\u7387\u63d0\u5347\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5c0f\u578b\u6a21\u578b\u7684\u7b97\u6cd5\u8fdb\u5c55\u76f8\u5bf9\u8f83\u6162\uff0c\u5e76\u4e14\u7b97\u6cd5\u6548\u7387\u7684\u8861\u91cf\u4e0e\u53c2\u7167\u7cfb\u5bc6\u5207\u76f8\u5173\u3002"}}
{"id": "2511.21635", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.21635", "abs": "https://arxiv.org/abs/2511.21635", "authors": ["Anantha Padmanaban Krishna Kumar"], "title": "Mechanisms of Non-Monotonic Scaling in Vision Transformers", "comment": "16 pages total (11 pages main text, 1 pages references, 4 pages appendix), 5 figures, 11 tables. Code available at https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb", "summary": "Deeper Vision Transformers often perform worse than shallower ones, which challenges common scaling assumptions. Through a systematic empirical analysis of ViT-S, ViT-B, and ViT-L on ImageNet, we identify a consistent three-phase Cliff-Plateau-Climb pattern that governs how representations evolve with depth. We observe that better performance is associated with progressive marginalization of the [CLS] token, originally designed as a global aggregation hub, in favor of distributed consensus among patch tokens. We quantify patterns of information mixing with an Information Scrambling Index, and show that in ViT-L the information-task tradeoff emerges roughly 10 layers later than in ViT-B, and that these additional layers correlate with increased information diffusion rather than improved task performance. Taken together, these results suggest that transformer architectures in this regime may benefit more from carefully calibrated depth that executes clean phase transitions than from simply increasing parameter count. The Information Scrambling Index provides a useful diagnostic for existing models and suggests a potential design target for future architectures. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86Vision Transformer\uff08ViT\uff09\u4e2d\u6df1\u5ea6\u589e\u52a0\u6709\u65f6\u53cd\u800c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u7684\u73b0\u8c61\uff0c\u5e76\u63d0\u51fa\u4e86\u201cCliff-Plateau-Climb\u201d\u4e09\u9636\u6bb5\u6a21\u5f0f\u6765\u63cf\u8ff0\u8868\u5f81\u968f\u6df1\u5ea6\u7684\u6f14\u53d8\u3002", "motivation": "\u63a2\u7d22\u4e3a\u4ec0\u4e48\u66f4\u6df1\u7684Vision Transformers\u5728\u6027\u80fd\u4e0a\u4e0d\u5982\u66f4\u6d45\u7684 counterparts\uff0c\u8fd9\u4e0e\u4f20\u7edf\u7684\u7f29\u653e\u5047\u8bbe\u76f8\u6096\u3002", "method": "\u901a\u8fc7\u5bf9ViT-S\u3001ViT-B\u548cViT-L\u5728ImageNet\u4e0a\u7684\u7cfb\u7edf\u5b9e\u8bc1\u5206\u6790\uff0c\u672c\u6587\u53d1\u73b0\u6df1\u5c42ViT\u4e2d[CLS] token\u7684\u4f5c\u7528\u9010\u6e10\u88ab\u8fb9\u7f18\u5316\uff0c\u5e76\u5f15\u5165\u201c\u4fe1\u606f\u6df7\u6dc6\u6307\u6570\u201d\u6765\u91cf\u5316\u4fe1\u606f\u6df7\u5408\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u6027\u80fd\u7684\u63d0\u5347\u4e0e[CLS] token\u9010\u6e10\u8fb9\u7f18\u5316\uff0c\u8f6c\u800c\u7531patch tokens\u4e4b\u95f4\u7684\u5206\u5e03\u5f0f\u5171\u8bc6\u76f8\u5173\u3002\u5728ViT-L\u4e2d\uff0c\u4fe1\u606f-\u4efb\u52a1\u6743\u8861\u6bd4ViT-B\u665a\u4e86\u5927\u7ea610\u5c42\u51fa\u73b0\uff0c\u8fd9\u4e9b\u989d\u5916\u7684\u5c42\u4e0e\u4fe1\u606f\u6269\u6563\u7684\u589e\u52a0\u800c\u975e\u4efb\u52a1\u6027\u80fd\u7684\u63d0\u5347\u76f8\u5173\u3002", "conclusion": "\u6df1\u5c42Transformer\u67b6\u6784\u53ef\u80fd\u53d7\u76ca\u4e8e\u7cbe\u5fc3\u6821\u51c6\u7684\u6df1\u5ea6\uff0c\u4ee5\u5b9e\u73b0\u6e05\u6670\u7684\u9636\u6bb5\u6027\u8f6c\u6362\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u589e\u52a0\u53c2\u6570\u6570\u91cf\u3002\u4fe1\u606f\u6df7\u6dc6\u6307\u6570\u4e3a\u73b0\u6709\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u7528\u7684\u8bca\u65ad\u65b9\u6cd5\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u67b6\u6784\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6f5c\u5728\u76ee\u6807\u3002"}}
{"id": "2511.21668", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.21668", "abs": "https://arxiv.org/abs/2511.21668", "authors": ["Shruti Bothe", "Illyyne Saffar", "Aurelie Boisbunon", "Hasan Farooq", "Julien Forgeat", "Md Moin Uddin Chowdhury"], "title": "Through the telecom lens: Are all training samples important?", "comment": "8pages, 1 table, 8 figures", "summary": "The rise of AI in telecommunications, from optimizing Radio Access Networks to managing user experience, has sharply increased data volumes and training demands. Telecom data is often noisy, high-dimensional, costly to store, process, and label. Despite Ai's critical role, standard workflows still assume all training samples contribute equally. On the other hand, next generation systems require AI models that are accurate, efficient, and sustainable.The paper questions the assumptions of equal importance by focusing on applying and analyzing the roles of individual samples in telecom training and assessing whether the proposed model optimizes computation and energy use. we perform sample-level gradient analysis across epochs to identify patterns of influence and redundancy in model learning. Based on this, we propose a sample importance framework thats electively prioritizes impactful data and reduces computation without compromising accuracy. Experiments on three real-world telecom datasets show that our method [reserves performance while reducing data needs and computational overhead while advancing the goals of sustainable AI in telecommunications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u65e8\u5728\u901a\u8fc7\u9009\u62e9\u6027\u5730\u4f18\u5148\u5904\u7406\u6709\u5f71\u54cd\u529b\u7684\u6837\u672c\u6765\u4f18\u5316\u7535\u4fe1\u6570\u636e\u8bad\u7ec3\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002\u8fd9\u6709\u52a9\u4e8e\u5b9e\u73b0\u7535\u4fe1\u9886\u57dfAI\u7684\u53ef\u6301\u7eed\u53d1\u5c55\u3002", "motivation": "\u4f20\u7edf\u7684AI\u8bad\u7ec3\u5de5\u4f5c\u6d41\u7a0b\u5047\u8bbe\u6240\u6709\u8bad\u7ec3\u6837\u672c\u90fd\u540c\u7b49\u91cd\u8981\uff0c\u4f46\u7535\u4fe1\u6570\u636e\u901a\u5e38\u5608\u6742\u3001\u9ad8\u7ef4\u4e14\u5904\u7406\u6210\u672c\u9ad8\u6602\u3002\u8be5\u7814\u7a76\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u5047\u8bbe\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u6837\u672c\u9009\u62e9\u6765\u63d0\u9ad8AI\u6a21\u578b\u7684\u6548\u7387\u3001\u51c6\u786e\u6027\u548c\u53ef\u6301\u7eed\u6027\uff0c\u4ee5\u9002\u5e94\u4e0b\u4e00\u4ee3\u7cfb\u7edf\u7684\u9700\u6c42\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5bf9\u4e0d\u540c\u8bad\u7ec3\u5468\u671f\u7684\u6837\u672c\u7ea7\u522b\u68af\u5ea6\u8fdb\u884c\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u6a21\u578b\u5b66\u4e60\u8fc7\u7a0b\u4e2d\u7684\u5f71\u54cd\u6a21\u5f0f\u548c\u5197\u4f59\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u91cd\u8981\u6027\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u9009\u62e9\u6027\u5730\u4f18\u5148\u8003\u8651\u6709\u5f71\u54cd\u529b\u7684\u6837\u672c\u6570\u636e\uff0c\u4ece\u800c\u51cf\u5c11\u8ba1\u7b97\u91cf\u3002", "result": "\u5728\u4e09\u4e2a\u771f\u5b9e\u7684\u7535\u4fe1\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u6570\u636e\u9700\u6c42\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6837\u672c\u91cd\u8981\u6027\u6846\u67b6\uff0c\u901a\u8fc7\u5173\u6ce8\u6837\u672c\u5bf9\u6a21\u578b\u5b66\u4e60\u7684\u5f71\u54cd\uff0c\u63d0\u9ad8\u4e86\u7535\u4fe1\u9886\u57dfAI\u8bad\u7ec3\u7684\u6548\u7387\u548c\u53ef\u6301\u7eed\u6027\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
