<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 32]
- [cs.LG](#cs.LG) [Total: 52]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.IT](#cs.IT) [Total: 4]
- [stat.ML](#stat.ML) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models](https://arxiv.org/abs/2511.13722)
*William Guo,Adaku Uchendu,Ana Smith*

Main category: cs.CL

TL;DR: 为了减轻大型语言模型（LLM）生成文本的潜在危害，研究人员提出了数字水印技术。然而，最近的研究发现，这些技术通常会对生成文本的质量产生负面影响，而且对抗性攻击可以消除水印信号，导致文本可能逃避检测。


<details>
  <summary>Details</summary>
Motivation: 探索数字水印技术在 LLM 生成文本检测中的应用，并解决其在质量、鲁棒性和风格保持方面的挑战。

Method: 本文评估了几种数字水印技术在对抗性攻击下的鲁棒性，并通过比较释义和回译攻击来检测其抗攻击性。同时，为了衡量其对未加水印文本质量和写作风格的影响，本文采用了语言学指标。

Result: 这些数字水印技术能保持文本语义，但是会改变未加水印文本的写作风格，并且容易受到对抗性攻击，尤其是回译攻击。

Conclusion: 数字水印技术在 LLM 生成文本检测方面仍面临挑战，尤其是在保持写作风格和抵御对抗性攻击方面。未来的研究方向应侧重于开发更鲁棒的水印技术，以确保在保持文本质量和风格的同时，有效地检测 LLM 生成的文本。

Abstract: To mitigate the potential harms of Large Language Models (LLMs)generated text, researchers have proposed watermarking, a process of embedding detectable signals within text. With watermarking, we can always accurately detect LLM-generated texts. However, recent findings suggest that these techniques often negatively affect the quality of the generated texts, and adversarial attacks can strip the watermarking signals, causing the texts to possibly evade detection. These findings have created resistance in the wide adoption of watermarking by LLM creators. Finally, to encourage adoption, we evaluate the robustness of several watermarking techniques to adversarial attacks by comparing paraphrasing and back translation (i.e., English $\to$ another language $\to$ English) attacks; and their ability to preserve quality and writing style of the unwatermarked texts by using linguistic metrics to capture quality and writing style of texts. Our results suggest that these watermarking techniques preserve semantics, deviate from the writing style of the unwatermarked texts, and are susceptible to adversarial attacks, especially for the back translation attack.

</details>


### [2] [Refine Thought: A Test-Time Inference Method for Embedding Model Reasoning](https://arxiv.org/abs/2511.13726)
*Guangzhi Wang,Kai Li,Yinghao Jiao,Zhi Liu*

Main category: cs.CL

TL;DR: 该文章提出了一种名为RT（Refine Thought）的方法，通过多次前向传递来增强文本嵌入模型的语义推理能力，并在BRIGHT、PJBenchmark和C-MTEB等基准测试中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 目前文本嵌入模型在语义推理能力方面存在不足，RT方法旨在提升其语义推理能力。

Method: RT方法通过对文本嵌入模型进行多次前向传递来获取最终的语义表示，从而增强模型的语义推理能力。

Result: 实验结果表明，RT方法在BRIGHT和PJBenchmark的语义推理任务上取得了显著改进，并在C-MTEB等通用语义理解任务上保持了稳定的性能。这表明RT能够进一步激活解码器专用文本嵌入模型在预训练期间学习到的语义推理能力。

Conclusion: RT是一种有效的测试时间推理方法，能够显著提升文本嵌入模型的语义推理能力，尤其是在特定基准测试中表现出色。

Abstract: We propose RT (Refine Thought), a method that can enhance the semantic rea-soning ability of text embedding models. The method obtains the final semanticrepresentation by running multiple forward passes of the text embedding model.Experiments show that RT achieves significant improvements on semantic reason-ing tasks in BRIGHT and the person job matching benchmark PJBenchmark1, while maintaining consistent performance on general-purpose semantic under-standing tasks such as C-MTEB. Our results indicate that RT is effective becauseit further activates the semantic reasoning ability learned during pretraining bydecoder-only text embedding models(e.g., Qwen3-Embedding-8B). RT canbe seen as a test-time inference method.

</details>


### [3] [Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities](https://arxiv.org/abs/2511.14631)
*Kahaan Gandhi,Boris Bolliet,Inigo Zubeldia*

Main category: cs.CL

TL;DR: 该论文介绍了一种由视觉语言模型（VLM）引导的多智能体系统，用于改进端到端自主科学发现，它通过将图表作为可验证的检查点，并利用VLM作为评判者来评估，使智能体能够实时纠正错误和引导探索性数据分析。


<details>
  <summary>Details</summary>
Motivation: 现有的自主科学发现系统在处理复杂数据和避免错误推理路径方面存在挑战，因此需要一种能自我纠正并适应新数据的方法。

Method: 该方法的核心是一个多智能体系统，它将图表视为可验证的检查点。一个VLM作为评判者，根据动态生成的领域特定评估标准来评估图表，使智能体能够实时纠正自身的错误并引导探索性数据分析。

Result: 在宇宙学和天体化学案例研究中，此系统展示了从错误推理路径中恢复并适应新数据集的能力，无需人工干预。在包含10个任务的数据驱动发现基准测试中，VLM增强系统的通过测试分数为0.7-0.8，而仅使用代码的基线为0.2-0.3，代码加文本基线为0.4-0.5。此外，该系统还提供了可审计的推理轨迹，提高了可解释性。

Conclusion: 由视觉语言模型引导的多智能体系统可以显著提升自主科学发现的效率和准确性，通过实时纠错和适应性学习，超越了传统方法，并为科学研究提供了更可靠的工具。

Abstract: We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: https://github.com/CMBAgents/cmbagent

</details>


### [4] [Can QE-informed (Re)Translation lead to Error Correction?](https://arxiv.org/abs/2511.13884)
*Govardhan Padmanabhan*

Main category: cs.CL

TL;DR: 本文提出了两种QE信息辅助的段落级别错误纠正方法，并比较了它们在训练无关范式下的性能。其中，获胜方法通过选择LLM生成的多个候选翻译中质量最好的一个，实现了Delta COMET分数0.0201。


<details>
  <summary>Details</summary>
Motivation: 开发或改进大模型机器翻译的后编辑能力，提升翻译质量。

Method: 本文提出了两种方法：1. QE辅助的重翻译：从LLM生成的多个候选翻译中选择质量最高的翻译。2. 基于LLM的错误替换：LLM根据QE解释替换错误的子字符串。

Result: 获胜方法（QE辅助的重翻译）取得了0.0201的Delta COMET分数，并在任务排行榜上名列前茅。另一种方法获得了-0.0108的Delta COMET分数。

Conclusion: QE辅助的重翻译方法在段落级别错误纠正任务中表现出色，通过选择高质量的LLM生成候选项，有效提升了翻译质量。

Abstract: The paper presents two approaches submitted to the WMT 2025 Automated Translation Quality Evaluation Systems Task 3 - Quality Estimation (QE)-informed Segment-level Error Correction. While jointly training QE systems with Automatic Post-Editing (APE) has shown improved performance for both tasks, APE systems are still known to overcorrect the output of Machine Translation (MT), leading to a degradation in performance. We investigate a simple training-free approach - QE-informed Retranslation, and compare it with another within the same training-free paradigm. Our winning approach selects the highest-quality translation from multiple candidates generated by different LLMs. The second approach, more akin to APE, instructs an LLM to replace error substrings as specified in the provided QE explanation(s). A conditional heuristic was employed to minimise the number of edits, with the aim of maximising the Gain-to-Edit ratio. The two proposed approaches achieved a Delta COMET score of 0.0201 and -0.0108, respectively, leading the first approach to achieve the winning position on the subtask leaderboard.

</details>


### [5] [What Works for 'Lost-in-the-Middle' in LLMs? A Study on GM-Extract and Mitigations](https://arxiv.org/abs/2511.13900)
*Mihir Gupte,Eshan Dixit,Muhammad Tayyab,Arun Adiththan*

Main category: cs.CL

TL;DR: 本文介绍了GM-Extract，一个用于评估大型语言模型在检索控制变量方面“中间遗失”现象的新基准数据集。研究发现，通过改变数据在上下文窗口中的表示方式，检索性能会发生显著变化，并评估了不同的缓解方法及其效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理长距离上下文时表现出的“中间遗失”现象对基于检索的LLM应用构成了重大挑战。本研究旨在通过一个新颖的基准数据集GM-Extract来研究这种现象在实际应用中的影响。

Method: 引入了GM-Extract数据集，该数据集专门设计用于评估LLM在检索控制变量方面的性能。提出了两种评估指标：文档度量（Document Metric）用于衡量空间检索能力，变量提取度量（Variable Extraction Metric）用于衡量语义检索能力。对7-8B参数模型在两个多文档任务（键值提取和问答）上进行了系统评估。此外，还对缓解“中间遗失”现象的方法进行了文献综述，并将其分为黑盒和白盒方法，然后将这些方法应用于GM-Extract基准进行评估。

Result: 检索性能随着数据在上下文窗口中表示方式的改变而显著变化。虽然没有持续观察到明显的U形曲线，但分析揭示了模型性能的清晰模式，并与困惑度分数相关联。缓解方法的有效性是高度细致的：在某些情况下能成功提高性能，但在另一些情况下会导致负面影响。

Conclusion: “中间遗失”现象是LLM在长距离上下文处理中的一个关键挑战，GM-Extract基准和提出的评估方法为此提供了一个有力的研究工具。研究结果表明，数据表示方式对检索性能有显著影响，且现有缓解方法的实际效用复杂且有待深入理解。未来的研究应关注如何在不同情境下优化数据表示和缓解策略。

Abstract: The diminishing ability of large language models (LLMs) to effectively utilize long-range context-the "lost-in-the-middle" phenomenon-poses a significant challenge in retrieval-based LLM applications. To study the impact of this phenomenon in a real-world application setting, we introduce GM-Extract, a novel benchmark dataset meticulously designed to evaluate LLM performance on retrieval of control variables. To accurately diagnose failure modes, we propose a simple yet elegant evaluation system using two distinct metrics: one for spatial retrieval capability (Document Metric) and the other for semantic retrieval capability (Variable Extraction Metric). We conduct a systematic evaluation of 7-8B parameter models on two multi-document tasks (key-value extraction and question-answering), demonstrating a significant change in retrieval performance simply by altering how the data is represented in the context window. While a distinct U-shaped curve was not consistently observed, our analysis reveals a clear pattern of performance across models, which we further correlate with perplexity scores. Furthermore, we perform a literature survey of mitigation methods, which we categorize into two distinct approaches: black-box and white-box methods. We then apply these techniques to our benchmark, finding that their efficacy is highly nuanced. Our evaluation highlights scenarios where these strategies successfully improve performance, as well as surprising cases where they lead to a negative impact, providing a comprehensive understanding of their utility in a practical context.

</details>


### [6] [Hint-Augmented Re-ranking: Efficient Product Search using LLM-Based Query Decomposition](https://arxiv.org/abs/2511.13994)
*Yilun Zhu,Nikhita Vedula,Shervin Malmasi*

Main category: cs.CL

TL;DR: 这篇论文提出了一种通过大型语言模型（LLMs）处理带有最高级词汇（如“最好”、“最流行”）的搜索查询的方法，旨在解决在电子商务搜索中理解多维度比较和领域知识的需求。


<details>
  <summary>Details</summary>
Motivation: 处理包含最高级词汇的搜索查询需要深入理解语言和领域知识，现有方法可能难以有效处理这类复杂查询。

Method: 该研究提出一个框架，利用LLMs为搜索查询生成结构化解释或“提示”，将查询分解为属性-值提示。这些提示在检索的同时生成，并能高效地整合到排序流程中。为了解决LLM直接重排序导致的延迟问题，研究团队开发了一种将最高级解释转移到轻量级模型中的高效方法。

Result: 与基线相比，该方法在平均精度均值（MAP）上提升了10.9个点，在平均倒数排名（MRR）上提升了5.9个点。

Conclusion: 本研究展示了如何表示最高级语义并将其在不同模型间转移，从而在解决实际部署限制的同时，提升了检索系统中的语言理解能力。

Abstract: Search queries with superlatives (e.g., best, most popular) require comparing candidates across multiple dimensions, demanding linguistic understanding and domain knowledge. We show that LLMs can uncover latent intent behind these expressions in e-commerce queries through a framework that extracts structured interpretations or hints. Our approach decomposes queries into attribute-value hints generated concurrently with retrieval, enabling efficient integration into the ranking pipeline. Our method improves search performanc eby 10.9 points in MAP and ranking by 5.9 points in MRR over baselines. Since direct LLM-based reranking faces prohibitive latency, we develop an efficient approach transferring superlative interpretations to lightweight models. Our findings provide insights into how superlative semantics can be represented and transferred between models, advancing linguistic interpretation in retrieval systems while addressing practical deployment constraints.

</details>


### [7] [HiEAG: Evidence-Augmented Generation for Out-of-Context Misinformation Detection](https://arxiv.org/abs/2511.14027)
*Junjie Wu,Yumeng Fu,Nan Yu,Guohong Fu*

Main category: cs.CL

TL;DR: 该论文提出了HiEAG框架，利用多模态大型语言模型（MLLMs）和分层证据增强生成来改进OOC错误信息检测中的外部一致性检查，并在实验中取得了优于现有SOTA方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的OOC错误信息检测方法侧重于内部一致性，忽视了图像-文本对与外部证据之间的外部一致性的重要性。

Method: HiEAG框架将外部一致性检查分解为一个综合的引擎管道，集成了检索、重新排序和重写。证据重新排序模块利用自动证据选择提示（AESP）从证据检索结果中获取相关证据项。随后，证据重写模块利用自动证据生成提示（AEGP）来改进基于MLLM的OOC错误信息检测器的任务适应性。

Result: HiEAG方法在不同的基准数据集上均优于现有的最新（SOTA）方法，提高了所有样本的准确性，并支持判断解释。

Conclusion: HiEAG框架通过增强外部一致性检查，显著提升了多模态OOC错误信息检测的性能，并通过 instruction tuning 实现了令人印象深刻的性能，为未来的研究提供了新的方向。

Abstract: Recent advancements in multimodal out-of-context (OOC) misinformation detection have made remarkable progress in checking the consistencies between different modalities for supporting or refuting image-text pairs. However, existing OOC misinformation detection methods tend to emphasize the role of internal consistency, ignoring the significant of external consistency between image-text pairs and external evidence. In this paper, we propose HiEAG, a novel Hierarchical Evidence-Augmented Generation framework to refine external consistency checking through leveraging the extensive knowledge of multimodal large language models (MLLMs). Our approach decomposes external consistency checking into a comprehensive engine pipeline, which integrates reranking and rewriting, apart from retrieval. Evidence reranking module utilizes Automatic Evidence Selection Prompting (AESP) that acquires the relevant evidence item from the products of evidence retrieval. Subsequently, evidence rewriting module leverages Automatic Evidence Generation Prompting (AEGP) to improve task adaptation on MLLM-based OOC misinformation detectors. Furthermore, our approach enables explanation for judgment, and achieves impressive performance with instruction tuning. Experimental results on different benchmark datasets demonstrate that our proposed HiEAG surpasses previous state-of-the-art (SOTA) methods in the accuracy over all samples.

</details>


### [8] [Based on Data Balancing and Model Improvement for Multi-Label Sentiment Classification Performance Enhancement](https://arxiv.org/abs/2511.14073)
*Zijin Su,Huanzhu Lv,Yuren Niu,Yiming Liu*

Main category: cs.CL

TL;DR: 本文提出了一种解决多标签情感分类中类别不平衡问题的方法，通过构建平衡数据集和开发增强的多标签分类模型，显著提高了分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多标签情感分类数据集（如GoEmotions）存在严重的类别不平衡问题，这会影响模型的性能，尤其是对于代表性不足的情感类别。

Method: 1. 构建平衡的多标签情感数据集：整合原始GoEmotions数据、使用RoBERTa-base-GoEmotions模型从Sentiment140中提取的情感标注样本，以及人工标注的GPT-4 mini生成的文本。确保28个情感类别的均匀分布。2. 开发增强的多标签分类模型：结合预训练的FastText嵌入、用于局部特征提取的卷积层、用于上下文学习的双向LSTM以及用于突出情感相关词的注意力机制。使用sigmoid激活输出层进行多标签预测，并通过混合精度训练提高计算效率。

Result: 与在不平衡数据上训练的模型相比，本文提出的方法在准确率、精确率、召回率、F1分数和AUC方面均取得了显著的改进。

Conclusion: 通过构建平衡数据集和开发增强的多标签分类模型，可以有效解决多标签情感分类中的类别不平衡问题，并显著提高模型性能。

Abstract: Multi-label sentiment classification plays a vital role in natural language processing by detecting multiple emotions within a single text. However, existing datasets like GoEmotions often suffer from severe class imbalance, which hampers model performance, especially for underrepresented emotions. To address this, we constructed a balanced multi-label sentiment dataset by integrating the original GoEmotions data, emotion-labeled samples from Sentiment140 using a RoBERTa-base-GoEmotions model, and manually annotated texts generated by GPT-4 mini. Our data balancing strategy ensured an even distribution across 28 emotion categories. Based on this dataset, we developed an enhanced multi-label classification model that combines pre-trained FastText embeddings, convolutional layers for local feature extraction, bidirectional LSTM for contextual learning, and an attention mechanism to highlight sentiment-relevant words. A sigmoid-activated output layer enables multi-label prediction, and mixed precision training improves computational efficiency. Experimental results demonstrate significant improvements in accuracy, precision, recall, F1-score, and AUC compared to models trained on imbalanced data, highlighting the effectiveness of our approach.

</details>


### [9] [Stealth Fine-Tuning: Efficiently Breaking Alignment in RVLMs Using Self-Generated CoT](https://arxiv.org/abs/2511.14106)
*Le Yu,Zhengyue Zhao,Yawen Zheng,Yunhao Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为“隐形微调”的新型攻击方法，通过分段干扰诱导有害推理轨迹，并利用自生成的输出作为微调数据，从而有效绕过RVLM的安全对齐。


<details>
  <summary>Details</summary>
Motivation: RVLM的安全对齐容易受到攻击。

Method: 通过分段干扰诱导有害推理轨迹，并将自生成的输出作为监督微调数据。采用回合制加权损失设计，实现轻量级、分布一致的微调。

Result: 在仅499个样本和不到3小时的A100（QLoRA）训练下，“隐形微调”的攻击成功率（ASR）超过IDEATOR 38.52%，同时保持了通用推理能力，调整后的模型保留了原始表示分布。

Conclusion: “隐形微调”是一种低成本、高效绕过对齐防御的方法。

Abstract: Reasoning-augmented Vision-Language Models (RVLMs) rely on safety alignment to prevent harmful behavior, yet their exposed chain-of-thought (CoT) traces introduce new attack surfaces. In this work, we find that the safety alignment of RVLMs can be easily break through a novel attack method termed \textbf{Stealth Fine-Tuning}. Our method elicits harmful reasoning traces through \textbf{segment-level interference} and reuses the self-generated outputs as supervised fine-tuning data. Through a \textbf{turn-based weighted} loss design, yielding a lightweight, distribution-consistent finetuning method. In our experiment, with only 499 samples and under 3 hours on a single A100 (QLoRA), Stealth Fine-Tuning outperforms IDEATOR by 38.52\% ASR while preserving general reasoning ability, as the tuned model retains the original representation distribution. Experiments on AdvBench and several general benchmarks demonstrate that Stealth Fine-Tuning is a low-cost and highly effective way to bypass alignment defenses. \textcolor{red}{\textbf{Disclaimer: This paper contains content that may be disturbing or offensive.}}

</details>


### [10] [Synthetic Clinical Notes for Rare ICD Codes: A Data-Centric Framework for Long-Tail Medical Coding](https://arxiv.org/abs/2511.14112)
*Truong Vo,Weiyi Wu,Kaize Ding*

Main category: cs.CL

TL;DR: 为了解决ICD诊断编码长尾分布问题导致的低F1分数，本研究提出了一个数据中心框架，通过生成高质量的合成出院总结来缓解数据不平衡。该方法构建了以罕见代码为锚点的多标签代码集，并利用真实世界共现模式、ICD描述、同义词、分类法和相似临床笔记来生成90,000个合成笔记，覆盖7,902个ICD代码，显著扩大了训练分布。在原始和扩展数据集上微调了PLM-ICD和GKI-ICD两个模型。实验表明，该方法在保持高微F1的同时，适度提高了宏F1，优于之前的最新技术。


<details>
  <summary>Details</summary>
Motivation: 自动ICD编码在医疗NLP中至关重要，但目前的诊断代码长尾分布问题导致宏F1分数较低，特别是对于数千个罕见和零样本的ICD代码，这在MIMIC-III等数据集中严重不足。

Method: 本研究提出了一个数据中心框架，通过生成高质量的合成出院总结来缓解数据不平衡。具体方法包括：构建以罕见代码为锚点的多标签代码集，利用真实世界的共现模式、ICD描述、同义词、分类法和相似临床笔记生成结构化提示，然后生成90,000个合成笔记，覆盖7,902个ICD代码，显著扩大训练分布。最后，在原始和扩展数据集上微调了PLM-ICD和GKI-ICD两个SOTA变压器模型。

Result: 实验结果显示，本方法在保持强微F1分数的同时，适度提高了宏F1分数，并且优于之前的最新技术（SOTA）。

Conclusion: 尽管相对于计算成本而言，性能提升可能看似微不足道，但研究结果表明精心制作的合成数据可以增强长尾ICD代码预测的公平性。

Abstract: Automatic ICD coding from clinical text is a critical task in medical NLP but remains hindered by the extreme long-tail distribution of diagnostic codes. Thousands of rare and zero-shot ICD codes are severely underrepresented in datasets like MIMIC-III, leading to low macro-F1 scores. In this work, we propose a data-centric framework that generates high-quality synthetic discharge summaries to mitigate this imbalance. Our method constructs realistic multi-label code sets anchored on rare codes by leveraging real-world co-occurrence patterns, ICD descriptions, synonyms, taxonomy, and similar clinical notes. Using these structured prompts, we generate 90,000 synthetic notes covering 7,902 ICD codes, significantly expanding the training distribution. We fine-tune two state-of-the-art transformer-based models, PLM-ICD and GKI-ICD, on both the original and extended datasets. Experiments show that our approach modestly improves macro-F1 while maintaining strong micro-F1, outperforming prior SOTA. While the gain may seem marginal relative to the computational cost, our results demonstrate that carefully crafted synthetic data can enhance equity in long-tail ICD code prediction.

</details>


### [11] [Applying Relation Extraction and Graph Matching to Answering Multiple Choice Questions](https://arxiv.org/abs/2511.14144)
*Naoki Shimoda,Akihiro Yamamoto*

Main category: cs.CL

TL;DR: 本文结合基于Transformer的关系抽取和知识图谱匹配来回答选择题，并强调输出过程的可追踪性。


<details>
  <summary>Details</summary>
Motivation: 以往知识图谱由于构建成本高昂被视为静态数据库。但最近Transformer关系抽取方法使动态生成知识图谱成为可能，从而能够用知识图谱表示输入语句的含义。

Method: 提出了一种回答“填空”式选择题的方法。该方法通过将问题语句转换为关系图，并在事实正确的知识图谱下进行验证，以衡量每个问题语句的真实性。

Result: 实验结果表明，该方法正确回答了大约70%的问题，并提供了过程的可追溯性。

Conclusion: 问题类别对准确性有巨大影响。

Abstract: In this research, we combine Transformer-based relation extraction with matching of knowledge graphs (KGs) and apply them to answering multiple-choice questions (MCQs) while maintaining the traceability of the output process. KGs are structured representations of factual knowledge consisting of entities and relations. Due to the high construction cost, they had been regarded as static databases with validated links. However, the recent development of Transformer-based relation extraction (RE) methods has enabled us to generate KGs dynamically by giving them natural language texts, and thereby opened the possibility for representing the meaning of the input sentences with the created KGs. Using this effect, we propose a method that answers MCQs in the "fill-in-the-blank" format, taking care of the point that RE methods generate KGs that represent false information if provided with factually incorrect texts. We measure the truthfulness of each question sentence by (i) converting the sentence into a relational graph using an RE method and (ii) verifying it against factually correct KGs under the closed-world assumption. The experimental results demonstrate that our method correctly answers up to around 70% of the questions, while providing traceability of the procedure. We also highlight that the question category has a vast influence on the accuracy.

</details>


### [12] [Selective Weak-to-Strong Generalization](https://arxiv.org/abs/2511.14166)
*Hao Lang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 该论文提出了一种选择性弱到强泛化（W2SG）框架，用以解决超人模型在弱监督场景下鲁棒性差的问题。通过训练二元分类器来识别强模型可回答的问题，并利用图平滑方法优化弱标签，该方法在三个基准测试中均优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 为了缓解模型对齐时高质量数据不足的问题，现有的弱到强泛化（W2SG）方法通过弱监督微调强大的预训练模型，以使其超越弱监督。但是，现有方法中弱监督的持续使用会导致鲁棒性问题，其中一部分弱标签甚至对模型有害。

Method: 本研究提出了一种选择性W2SG框架，以避免在不必要时使用弱监督。具体而言，该方法训练了一个二元分类器P(IK)来识别强模型可以回答的问题，并利用模型自生成的标签进行对齐。此外，该方法还通过图平滑方法进一步优化了弱标签。

Result: 在三个基准测试上进行了广泛的实验，结果表明所提出的方法始终优于具有竞争力的基线方法。

Conclusion: 进一步分析表明，P(IK)可以很好地泛化到不同的任务和难度，这表明选择性W2SG有助于实现超级对齐。

Abstract: Future superhuman models will surpass the ability of humans and humans will only be able to \textit{weakly} supervise superhuman models. To alleviate the issue of lacking high-quality data for model alignment, some works on weak-to-strong generalization (W2SG) finetune a strong pretrained model with a weak supervisor so that it can generalize beyond weak supervision. However, the invariable use of weak supervision in existing methods exposes issues in robustness, with a proportion of weak labels proving harmful to models. In this paper, we propose a selective W2SG framework to avoid using weak supervision when unnecessary. We train a binary classifier P(IK) to identify questions that a strong model can answer and use its self-generated labels for alignment. We further refine weak labels with a graph smoothing method. Extensive experiments on three benchmarks show that our method consistently outperforms competitive baselines. Further analyses show that P(IK) can generalize across tasks and difficulties, which indicates selective W2SG can help superalignment.

</details>


### [13] [SymLoc: Symbolic Localization of Hallucination across HaluEval and TruthfulQA](https://arxiv.org/abs/2511.14172)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 本文提出了一种符号定位框架，用于追踪大型语言模型中幻觉的产生和发展，发现幻觉是符号语言处理失败，而非一个普遍的生成问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理修饰符、否定、数字、例外和命名实体等符号触发器时，仍旧存在幻觉问题。目前对这些符号幻觉的起源缺乏清晰的理解，这使得系统性地处理这些触发器并定位模型内部幻觉的出现变得至关重要。

Method: 本文提出了第一个符号定位框架，该框架利用符号语言和语义知识，有意义地追踪所有模型层中幻觉的发展。研究人员通过HaluEval和TruthfulQA分析了五个模型，重点关注模型如何处理符号触发器。

Result: 研究发现，对于这些语言元素，注意力方差在早期层（2-4层）就达到了临界不稳定状态，其中否定会引发灾难性的方差水平，表明符号语义处理从一开始就出现故障。尽管模型规模更大，但幻觉率仍然很高（Gemma变体为78.3%-83.7%），并且在深层中符号语义触发器的注意力显著下降。

Conclusion: 幻觉本质上是符号语言处理失败，而不是一个普遍的生成问题。符号语义知识为理解和定位大型语言模型中的幻觉机制提供了关键。

Abstract: LLMs still struggle with hallucination, especially when confronted with symbolic triggers like modifiers, negation, numbers, exceptions, and named entities. Yet, we lack a clear understanding of where these symbolic hallucinations originate, making it crucial to systematically handle such triggers and localize the emergence of hallucination inside the model. While prior work explored localization using statistical techniques like LSC and activation variance analysis, these methods treat all tokens equally and overlook the role symbolic linguistic knowledge plays in triggering hallucinations. So far, no approach has investigated how symbolic elements specifically drive hallucination failures across model layers, nor has symbolic linguistic knowledge been used as the foundation for a localization framework. We propose the first symbolic localization framework that leverages symbolic linguistic and semantic knowledge to meaningfully trace the development of hallucinations across all model layers. By focusing on how models process symbolic triggers, we analyze five models using HaluEval and TruthfulQA. Our symbolic knowledge approach reveals that attention variance for these linguistic elements explodes to critical instability in early layers (2-4), with negation triggering catastrophic variance levels, demonstrating that symbolic semantic processing breaks down from the very beginning. Through the lens of symbolic linguistic knowledge, despite larger model sizes, hallucination rates remain consistently high (78.3%-83.7% across Gemma variants), with steep attention drops for symbolic semantic triggers throughout deeper layers. Our findings demonstrate that hallucination is fundamentally a symbolic linguistic processing failure, not a general generation problem, revealing that symbolic semantic knowledge provides the key to understanding and localizing hallucination mechanisms in LLMs.

</details>


### [14] [Harnessing Deep LLM Participation for Robust Entity Linking](https://arxiv.org/abs/2511.14181)
*Jiajun Hou,Chenyu Zhang,Rui Meng*

Main category: cs.CL

TL;DR: DeepEL是一个将大型语言模型（LLM）整合到实体链接（EL）任务各个阶段的框架，通过引入自验证机制和全局上下文信息，显著提高了EL的性能，尤其是在域外数据集上。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在实体链接（EL）任务中的应用通常局限于EL任务的独立阶段，未能充分整合其能力。孤立地消除实体歧义不足以获得最佳性能。

Method: 我们引入了DeepEL，一个将LLM整合到实体链接任务各个阶段的框架。此外，我们提出了一种新颖的自验证机制，该机制利用全局上下文信息，使LLM能够纠正自身的预测，并更好地识别同一句子中实体之间的内聚关系。

Result: 在十个基准数据集上的广泛实证评估表明，DeepEL显著优于现有最先进的方法，整体F1分数平均提高了2.6%，在域外数据集上更是取得了4%的显著提升。

Conclusion: 这些结果强调了深度LLM集成在推动实体链接领域最先进技术方面的有效性。

Abstract: Entity Linking (EL), the task of mapping textual entity mentions to their corresponding entries in knowledge bases, constitutes a fundamental component of natural language understanding. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable potential for enhancing EL performance. Prior research has leveraged LLMs to improve entity disambiguation and input representation, yielding significant gains in accuracy and robustness. However, these approaches typically apply LLMs to isolated stages of the EL task, failing to fully integrate their capabilities throughout the entire process.
  In this work, we introduce DeepEL, a comprehensive framework that incorporates LLMs into every stage of the entity linking task. Furthermore, we identify that disambiguating entities in isolation is insufficient for optimal performance. To address this limitation, we propose a novel self-validation mechanism that utilizes global contextual information, enabling LLMs to rectify their own predictions and better recognize cohesive relationships among entities within the same sentence.
  Extensive empirical evaluation across ten benchmark datasets demonstrates that DeepEL substantially outperforms existing state-of-the-art methods, achieving an average improvement of 2.6\% in overall F1 score and a remarkable 4% gain on out-of-domain datasets. These results underscore the efficacy of deep LLM integration in advancing the state-of-the-art in entity linking.

</details>


### [15] [ArbESC+: Arabic Enhanced Edit Selection System Combination for Grammatical Error Correction Resolving conflict and improving system combination in Arabic GEC](https://arxiv.org/abs/2511.14230)
*Ahlam Alrehili,Areej Alhothali*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个针对阿拉伯语语法纠错的多系统方法，该方法通过结合不同的模型来提高纠错性能。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语语法纠错具有挑战性，传统的单一模型方法不足以处理其复杂的形态和句法结构。

Method: 该论文提出了一个名为ArbESC+的多系统方法，它通过整合多种模型（如AraT5、ByT5、mT5、AraBART、AraBART+Morph+GEC和文本编辑系统）来收集纠错建议。这些建议被表示为数值特征，然后由分类器决定和实施纠正。为了提高输出质量，该框架还使用了支持技术来过滤重叠的纠正并估计决策的可靠性。

Result: ArbESC+在QALB-14测试数据上获得了82.63%的F0.5分数，在QALB-15 L1数据上获得了84.64%的F0.5分数，在QALB-15 L2数据上获得了65.55%的F0.5分数。这些结果表明，多系统方法优于单一模型。

Conclusion: 这项工作首次尝试集成语言错误纠正的阿拉伯语方法，并为开发先进的阿拉伯语文本处理工具提供了实用步骤。

Abstract: Grammatical Error Correction (GEC) is an important aspect of natural language processing. Arabic has a complicated morphological and syntactic structure, posing a greater challenge than other languages. Even though modern neural models have improved greatly in recent years, the majority of previous attempts used individual models without taking into account the potential benefits of combining different systems. In this paper, we present one of the first multi-system approaches for correcting grammatical errors in Arabic, the Arab Enhanced Edit Selection System Complication (ArbESC+). Several models are used to collect correction proposals, which are represented as numerical features in the framework. A classifier determines and implements the appropriate corrections based on these features. In order to improve output quality, the framework uses support techniques to filter overlapping corrections and estimate decision reliability. A combination of AraT5, ByT5, mT5, AraBART, AraBART+Morph+GEC, and Text editing systems gave better results than a single model alone, with F0.5 at 82.63% on QALB-14 test data, 84.64% on QALB-15 L1 data, and 65.55% on QALB-15 L2 data. As one of the most significant contributions of this work, it's the first Arab attempt to integrate linguistic error correction. Improving existing models provides a practical step towards developing advanced tools that will benefit users and researchers of Arabic text processing.

</details>


### [16] [MuCPT: Music-related Natural Language Model Continued Pretraining](https://arxiv.org/abs/2511.14245)
*Kai Tian,Yirong Mao,Wendong Bi,Hanjie Wang,Que Wenhui*

Main category: cs.CL

TL;DR: 为了解决LLM在音乐领域应用的限制，本文构建了一个大型音乐相关自然语言语料库（40B tokens），并设计了领域优先数据管线和基于参考模型（RM）的token级别软评分进行质量控制，同时提出了MusicSimpleQA基准测试来评估事实性，最终提供了一个可扩展的数据训练框架和可重用的评估工具。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在音乐等专业领域表现受限，尤其在音乐娱乐领域，语料库规模、纯度和数据与训练目标的匹配度至关重要。

Method: 构建了一个包含开源和内部数据的40B token音乐相关自然语言语料库；
实现了一个领域优先的数据管线，包括：轻量级分类器筛选和加权领域内文本、多阶段清洗、去重和隐私保护掩码。
整合多源音乐文本和相关元数据以形成更广泛、结构更好的领域知识基础。
引入基于参考模型（RM）的token级软评分进行质量控制：使用统一的损失比标准进行数据选择和优化过程中的动态降权，以减少噪声梯度并放大任务对齐信号。
设计了MusicSimpleQA基准测试，采用简短、单答案提示和自动一致性评分来评估事实性。
进行了数据组成方面的系统比较。

Result: 通过构建合适的语料库和优化训练目标，本文提供了一个可扩展的数据训练框架和可重用的评估工具。

Conclusion: 本文在音乐领域为构建领域特定的大型语言模型提供了数据和训练方法上的重要进展，并通过新颖的数据处理和评估工具，有效提升了模型在该领域的性能和事实性。

Abstract: Large language models perform strongly on general tasks but remain constrained in specialized settings such as music, particularly in the music-entertainment domain, where corpus scale, purity, and the match between data and training objectives are critical. We address this by constructing a large, music-related natural language corpus (40B tokens) that combines open source and in-house data, and by implementing a domain-first data pipeline: a lightweight classifier filters and weights in-domain text, followed by multi-stage cleaning, de-duplication, and privacy-preserving masking. We further integrate multi-source music text with associated metadata to form a broader, better-structured foundation of domain knowledge. On the training side, we introduce reference-model (RM)-based token-level soft scoring for quality control: a unified loss-ratio criterion is used both for data selection and for dynamic down-weighting during optimization, reducing noise gradients and amplifying task-aligned signals, thereby enabling more effective music-domain continued pretraining and alignment. To assess factuality, we design the MusicSimpleQA benchmark, which adopts short, single-answer prompts with automated agreement scoring. Beyond the benchmark design, we conduct systematic comparisons along the axes of data composition. Overall, this work advances both the right corpus and the right objective, offering a scalable data-training framework and a reusable evaluation tool for building domain LLMs in the music field.

</details>


### [17] [Towards Authentic Movie Dubbing with Retrieve-Augmented Director-Actor Interaction Learning](https://arxiv.org/abs/2511.14249)
*Rui Liu,Yuan Zhao,Zhenqi Jia*

Main category: cs.CL

TL;DR: 该论文提出了一种名为 Authentic-Dubber 的自动电影配音模型，通过模拟导演与演员的互动，实现了更真实的、富有情感的配音。


<details>
  <summary>Details</summary>
Motivation: 现有自动配音模型忽略了导演与演员之间关键的互动环节，仅模拟了演员无准备地直接配音的简化工作流程，从而导致配音缺乏情感表达。

Method: 1. 构建多模态参考素材库：利用大型语言模型（LLMs）深度理解多模态情感表达，模拟导演提供的学习素材。2. 基于情感相似度的检索增强策略：模拟演员内化导演素材的过程，检索与目标无声视频最相关的多模态信息。3. 渐进式图基语音生成方法：逐步融入检索到的多模态情感知识，模拟演员的最终配音过程。

Result: Authentic-Dubber 模型能够忠实地复制真实的配音工作流程，在情感表达方面取得了全面的改进。

Conclusion: Authentic-Dubber 模型通过模拟真实的导演与演员互动流程，显著提升了自动电影配音的情感表现力，为未来自动配音技术的发展提供了新的方向。

Abstract: The automatic movie dubbing model generates vivid speech from given scripts, replicating a speaker's timbre from a brief timbre prompt while ensuring lip-sync with the silent video. Existing approaches simulate a simplified workflow where actors dub directly without preparation, overlooking the critical director-actor interaction. In contrast, authentic workflows involve a dynamic collaboration: directors actively engage with actors, guiding them to internalize the context cues, specifically emotion, before performance. To address this issue, we propose a new Retrieve-Augmented Director-Actor Interaction Learning scheme to achieve authentic movie dubbing, termed Authentic-Dubber, which contains three novel mechanisms: (1) We construct a multimodal Reference Footage library to simulate the learning footage provided by directors. Note that we integrate Large Language Models (LLMs) to achieve deep comprehension of emotional representations across multimodal signals. (2) To emulate how actors efficiently and comprehensively internalize director-provided footage during dubbing, we propose an Emotion-Similarity-based Retrieval-Augmentation strategy. This strategy retrieves the most relevant multimodal information that aligns with the target silent video. (3) We develop a Progressive Graph-based speech generation approach that incrementally incorporates the retrieved multimodal emotional knowledge, thereby simulating the actor's final dubbing process. The above mechanisms enable the Authentic-Dubber to faithfully replicate the authentic dubbing workflow, achieving comprehensive improvements in emotional expressiveness. Both subjective and objective evaluations on the V2C Animation benchmark dataset validate the effectiveness. The code and demos are available at https://github.com/AI-S2-Lab/Authentic-Dubber.

</details>


### [18] [AfriSpeech-MultiBench: A Verticalized Multidomain Multicountry Benchmark Suite for African Accented English ASR](https://arxiv.org/abs/2511.14255)
*Gabrial Zencha Ashungafac,Mardhiyah Sanni,Busayo Awobade,Alex Gichamba,Tobi Olatunji*

Main category: cs.CL

TL;DR: “AfriSpeech-MultiBench”是首个针对非洲100多种英语口音的领域特定评估套件。该套件基于包含10多个国家和7个应用领域的数据，对各种语音识别系统进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 为了解决非洲语言多样性在语音AI领域中，缺乏公开可用的特定应用模型评估的问题。

Method: 提出并构建了AfriSpeech-MultiBench，这是一个针对非洲英语口音的领域特定评估套件。该套件涵盖了10多个非洲国家的100多种英语口音以及金融、法律、医疗等七个应用领域。利用来自开放非洲英语口音语音数据集的自发和非自发语音对话，对开放、封闭、单模态ASR和多模态基于LLM的语音识别系统进行了基准测试。

Result: 开源ASR模型在自发语音方面表现出色，但在嘈杂、非母语对话中性能下降。多模态LLM在口音方面更具鲁棒性，但在领域特定的命名实体方面存在不足。专有模型在清晰语音上准确率高，但会因国家和领域不同而差异很大。在非洲英语上进行微调的模型能以较低的延迟实现有竞争力的准确性。幻觉仍然是大多数SOTA模型的最大问题。

Conclusion: AfriSpeech-MultiBench填补了非洲语言多样性在语音AI领域中，缺乏公开可用的特定应用模型评估的空白。该基准测试为从业者和研究人员提供了选择适合非洲用例的语音技术的能力，从而为服务不足的社区提供包容性的语音应用。

Abstract: Recent advances in speech-enabled AI, including Google's NotebookLM and OpenAI's speech-to-speech API, are driving widespread interest in voice interfaces globally. Despite this momentum, there exists no publicly available application-specific model evaluation that caters to Africa's linguistic diversity. We present AfriSpeech-MultiBench, the first domain-specific evaluation suite for over 100 African English accents across 10+ countries and seven application domains: Finance, Legal, Medical, General dialogue, Call Center, Named Entities and Hallucination Robustness. We benchmark a diverse range of open, closed, unimodal ASR and multimodal LLM-based speech recognition systems using both spontaneous and non-spontaneous speech conversation drawn from various open African accented English speech datasets. Our empirical analysis reveals systematic variation: open-source ASR models excels in spontaneous speech contexts but degrades on noisy, non-native dialogue; multimodal LLMs are more accent-robust yet struggle with domain-specific named entities; proprietary models deliver high accuracy on clean speech but vary significantly by country and domain. Models fine-tuned on African English achieve competitive accuracy with lower latency, a practical advantage for deployment, hallucinations still remain a big problem for most SOTA models. By releasing this comprehensive benchmark, we empower practitioners and researchers to select voice technologies suited to African use-cases, fostering inclusive voice applications for underserved communities.

</details>


### [19] [Entropy-Guided Reasoning Compression](https://arxiv.org/abs/2511.14258)
*Hourun Zhu,Yang Gao,Wenlong Fei,Jiawei Li,Huashan Sun*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的压缩大型推理模型推理链的方法，通过解决训练过程中的熵冲突问题，在保持或超越基线精度的同时，将推理长度压缩到原来的20%。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中表现出色，但其过长的思维链输出导致计算成本高昂且部署困难，现有的压缩方法仍存在局限性，并且忽略了训练过程中的熵冲突现象。

Method: 本文提出了一种熵冲突的起源分析，发现许多高熵token是逻辑连接词，在性能目标下梯度更大，但在压缩目标下却被惩罚。为了解决这个问题，本文提出了一种熵引导的训练框架，通过在熵下降时鼓励简洁的思维步骤来引导模型进行高效推理；在熵上升时，在紧凑推理模式下加强探索以提高鲁棒性。

Result: 在六个数学基准测试中，该方法将推理长度压缩到原来的20%，同时保持或超越了基线精度。

Conclusion: 本文提出了一种有效的熵引导训练框架，成功解决了大型推理模型推理链过长的问题，实现了推理长度的大幅压缩，同时保持了高精度。

Abstract: Large reasoning models have demonstrated remarkable performance on complex reasoning tasks, yet the excessive length of their chain-of-thought outputs remains a major practical bottleneck due to high computation cost and poor deployability. Existing compression methods have achieved partial success but overlook a crucial phenomenon in the training process -- the entropy conflict. During compression training, entropy decreases, leading to shorter reasoning but limited exploration, while accuracy-oriented objectives increase entropy, lengthening reasoning chains. This can cause the model to get stuck in a local dilemma. Our analysis further reveals the origin of the entropy conflict: many high-entropy tokens are logical connectors that receive larger gradients and are encouraged under the performance objective, while the compression objective simultaneously penalizes these potentially redundant connectors. This opposing pressure creates a direct source of entropy conflict. To address these issues, we adopt an entropy-guided training framework. As entropy descends, the model is guided toward efficient reasoning by encouraging concise thought steps; as entropy rises, exploration is reinforced under the compact reasoning mode to improve robustness. Experiments on six mathematical benchmarks show that our method compresses reasoning length to 20% of the original while maintaining or even surpassing baseline accuracy. Code and models will be released publicly.

</details>


### [20] [Don't Miss the Forest for the Trees: In-Depth Confidence Estimation for LLMs via Reasoning over the Answer Space](https://arxiv.org/abs/2511.14275)
*Ante Wang,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: 为了判断大语言模型（LLM）回答的可靠性，本文提出了一种通过预测口头概率分布来估计模型置信度的方法。


<details>
  <summary>Details</summary>
Motivation: 研究现有的大语言模型（LLM）的置信度，并且想找到一种用推理策略来更有效的估计置信度。

Method: 通过预测口头概率分布来估计模型置信度，这需要LLM考虑答案空间中的所有候选，而不是基于单一猜测，并仔细分配置信度分数以满足分布要求。

Result: 这方法适用于不同的模型和任务，无论答案空间是否已知，并且在强化学习后仍保持优势。实验结果表明，该方法的推理模式与人类预期一致。

Conclusion: 口头概率分布可以有效地促进深度推理，提高LLM置信度估计的准确性和透明度，使其更可靠地应用于实际场景。

Abstract: Knowing the reliability of a model's response is essential in application. With the strong generation capabilities of LLMs, research has focused on generating verbalized confidence. This is further enhanced by combining chain-of-thought reasoning, which provides logical and transparent estimation. However, how reasoning strategies affect the estimated confidence is still under-explored. In this work, we demonstrate that predicting a verbalized probability distribution can effectively encourage in-depth reasoning for confidence estimation. Intuitively, it requires an LLM to consider all candidates within the answer space instead of basing on a single guess, and to carefully assign confidence scores to meet the requirements of a distribution. This method shows an advantage across different models and various tasks, regardless of whether the answer space is known. Its advantage is maintained even after reinforcement learning, and further analysis shows its reasoning patterns are aligned with human expectations.

</details>


### [21] [AraLingBench A Human-Annotated Benchmark for Evaluating Arabic Linguistic Capabilities of Large Language Models](https://arxiv.org/abs/2511.14295)
*Mohammad Zbib,Hasan Abed Al Kader Hammoud,Sina Mukalled,Nadine Rizk,Fatima Karnib,Issam Lakkis,Ammar Mohanna,Bernard Ghanem*

Main category: cs.CL

TL;DR: AraLingBench是一个评估大型语言模型阿拉伯语语言能力的基准，涵盖语法、形态学、拼写、阅读理解和句法五个核心类别，通过150个专家设计的多项选择题来评估模型表层能力和深层理解之间的差距。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一个全面评估大型语言模型阿拉伯语语言能力的基准，特别是对深层语言理解能力的评估。现有基准可能通过记忆或模式识别来取得高分，而非真正的理解。

Method: 设计了一个名为AraLingBench的基准测试，包含150个专家设计的多项选择题，涵盖语法、形态学、拼写、阅读理解和句法五个核心类别。该基准通过人类专家进行全面标注，直接评估大型语言模型的结构化语言理解能力。

Result: 评估了35个阿拉伯语和双语大型语言模型，发现当前模型在表面层面的熟练度较高，但在更深层次的语法和句法推理方面存在不足。基准测试结果表明，高分在基于知识的基准测试中可能通过记忆或模式识别获得，而非真正的语言掌握。

Conclusion: AraLingBench提供了一个诊断框架，用于开发阿拉伯语大型语言模型，通过隔离和测量基本的语言技能，揭示了模型在深层语言理解方面的持续差距。

Abstract: We present AraLingBench: a fully human annotated benchmark for evaluating the Arabic linguistic competence of large language models (LLMs). The benchmark spans five core categories: grammar, morphology, spelling, reading comprehension, and syntax, through 150 expert-designed multiple choice questions that directly assess structural language understanding. Evaluating 35 Arabic and bilingual LLMs reveals that current models demonstrate strong surface level proficiency but struggle with deeper grammatical and syntactic reasoning. AraLingBench highlights a persistent gap between high scores on knowledge-based benchmarks and true linguistic mastery, showing that many models succeed through memorization or pattern recognition rather than authentic comprehension. By isolating and measuring fundamental linguistic skills, AraLingBench provides a diagnostic framework for developing Arabic LLMs. The full evaluation code is publicly available on GitHub.

</details>


### [22] [ConInstruct: Evaluating Large Language Models on Conflict Detection and Resolution in Instructions](https://arxiv.org/abs/2511.14342)
*Xingwei He,Qianru Zhang,Pengfei Chen,Guanhua Chen,Linlin Yu,Yuan Yuan,Siu-Ming Yiu*

Main category: cs.CL

TL;DR: 本文介绍了ConInstruct，这是一个用于评估大型语言模型（LLMs）在处理包含冲突约束的用户指令时的性能基准。研究发现，大多数专有LLM和部分开源LLM在冲突检测方面表现出色，但它们很少明确通知用户存在冲突。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM遵循指令的能力，但往往忽视指令中包含冲突约束的场景。这在复杂提示中很常见，而LLM在此类条件下的行为尚未得到充分探索。

Method: 本文引入了ConInstruct基准测试，专门用于评估LLM检测和解决用户指令中冲突的能力。作者使用该数据集评估了LLM的冲突检测性能并分析了它们的冲突解决行为。

Result: 1. 大多数专有LLM表现出强大的冲突检测能力，在开源模型中，只有DeepSeek-R1表现出同样强大的性能。DeepSeek-R1和Claude-4.5-Sonnet的平均F1分数最高，分别为91.5%和87.3%，总体排名第一和第二。 2. 尽管LLM具有很强的冲突检测能力，但它们在面对冲突约束时很少明确通知用户冲突或请求澄清。

Conclusion: 目前的LLM存在一个关键缺陷，即在检测到指令冲突时未能明确告知用户或寻求澄清。这为未来设计遵循指令的LLM提供了重要的改进方向。

Abstract: Instruction-following is a critical capability of Large Language Models (LLMs). While existing works primarily focus on assessing how well LLMs adhere to user instructions, they often overlook scenarios where instructions contain conflicting constraints-a common occurrence in complex prompts. The behavior of LLMs under such conditions remains under-explored. To bridge this gap, we introduce ConInstruct, a benchmark specifically designed to assess LLMs' ability to detect and resolve conflicts within user instructions. Using this dataset, we evaluate LLMs' conflict detection performance and analyze their conflict resolution behavior. Our experiments reveal two key findings: (1) Most proprietary LLMs exhibit strong conflict detection capabilities, whereas among open-source models, only DeepSeek-R1 demonstrates similarly strong performance. DeepSeek-R1 and Claude-4.5-Sonnet achieve the highest average F1-scores at 91.5% and 87.3%, respectively, ranking first and second overall. (2) Despite their strong conflict detection abilities, LLMs rarely explicitly notify users about the conflicts or request clarification when faced with conflicting constraints. These results underscore a critical shortcoming in current LLMs and highlight an important area for future improvement when designing instruction-following LLMs.

</details>


### [23] [ATLAS: A High-Difficulty, Multidisciplinary Benchmark for Frontier Scientific Reasoning](https://arxiv.org/abs/2511.14366)
*Hongwei Liu,Junnan Liu,Shudong Liu,Haodong Duan,Yuqiang Li,Mao Su,Xiaohong Liu,Guangtao Zhai,Xinyu Fang,Qianhong Ma,Taolin Zhang,Zihan Ma,Yufeng Zhao,Peiheng Zhou,Linchen Xiao,Wenlong Zhang,Shijie Zhou,Xingjian Ma,Siqi Sun,Jiaye Ge,Meng Li,Yuhong Liu,Jianxin Dong,Jiaying Li,Hui Wu,Hanwen Liang,Jintai Lin,Yanting Wang,Jie Dong,Tong Zhu,Tianfan Fu,Conghui He,Qi Zhang,Songyang Zhang,Lei Bai,Kai Chen*

Main category: cs.CL

TL;DR: ATLAS是一个大型的、高难度的、跨学科的评估套件，旨在解决现有基准测试的局限性，并提供一个可靠的“标尺”来衡量通用人工智能的进展。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估大型语言模型（LLMs）方面存在性能饱和、学科范围窄、答案格式过于简化以及容易受到数据污染等问题，导致无法有效区分前沿模型，且与真实的科学探究存在差距。

Method: ATLAS评估套件包含约800个原创问题，由博士及以上水平的领域专家开发，涵盖数学、物理、化学、生物、计算机科学、地球科学和材料科学等七个核心科学领域。其主要特点包括：高原创性和抗污染性、跨学科焦点、高保真度答案（涉及多步推理和LaTeX格式的复杂开放式答案），以及严格的质量控制（多阶段专家同行评审和对抗性测试）。此外，还提出了一种使用LLM评审团进行自动化、细致评估的范式。

Result: 初步结果表明，ATLAS能够有效区分领先模型在高级科学推理能力方面的差异。

Conclusion: ATLAS旨在成为一个长期、开放、社区驱动的平台，为通用人工智能的进展提供一个可靠的“衡量标准”。

Abstract: The rapid advancement of Large Language Models (LLMs) has led to performance saturation on many established benchmarks, questioning their ability to distinguish frontier models. Concurrently, existing high-difficulty benchmarks often suffer from narrow disciplinary focus, oversimplified answer formats, and vulnerability to data contamination, creating a fidelity gap with real-world scientific inquiry. To address these challenges, we introduce ATLAS (AGI-Oriented Testbed for Logical Application in Science), a large-scale, high-difficulty, and cross-disciplinary evaluation suite composed of approximately 800 original problems. Developed by domain experts (PhD-level and above), ATLAS spans seven core scientific fields: mathematics, physics, chemistry, biology, computer science, earth science, and materials science. Its key features include: (1) High Originality and Contamination Resistance, with all questions newly created or substantially adapted to prevent test data leakage; (2) Cross-Disciplinary Focus, designed to assess models' ability to integrate knowledge and reason across scientific domains; (3) High-Fidelity Answers, prioritizing complex, open-ended answers involving multi-step reasoning and LaTeX-formatted expressions over simple multiple-choice questions; and (4) Rigorous Quality Control, employing a multi-stage process of expert peer review and adversarial testing to ensure question difficulty, scientific value, and correctness. We also propose a robust evaluation paradigm using a panel of LLM judges for automated, nuanced assessment of complex answers. Preliminary results on leading models demonstrate ATLAS's effectiveness in differentiating their advanced scientific reasoning capabilities. We plan to develop ATLAS into a long-term, open, community-driven platform to provide a reliable "ruler" for progress toward Artificial General Intelligence.

</details>


### [24] [Mitigating Label Length Bias in Large Language Models](https://arxiv.org/abs/2511.14385)
*Mario Sanz-Guerrero,Katharina von der Wense*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为归一化上下文校准（NCC）的方法，用于解决大型语言模型中多令牌类别标签引起的标签长度偏差问题，并在多个数据集和模型上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在零样本和少样本学习方面表现出色，但在处理候选选项集时存在标签偏差。现有校准方法忽略了多令牌类别标签引起的偏差，导致即使经过标准长度归一化后，不同长度标签的处理仍然不一致，即存在标签长度偏差。

Method: 本文提出了一种归一化上下文校准（NCC）方法。该方法在完整标签层面进行预测的归一化和校准，以减轻标签长度偏差。

Result: NCC在多个数据集和模型上比现有方法取得了显著的统计学改进，F1分数提升高达10%。此外，NCC将偏差缓解扩展到多项选择问答等更广泛的任务。当与上下文学习结合使用时，NCC对少样本示例选择的敏感性较低，需要更少的示例即可达到有竞争力的性能，并能产生更可靠的置信度估计。

Conclusion: 缓解完整标签偏差对于提高基于LLM的方法的性能和鲁棒性至关重要，特别是C在类别标签自然由多个令牌组成的实际应用中。

Abstract: Large language models (LLMs) are powerful zero- and few-shot learners. However, when predicting over a set of candidate options, LLMs suffer from label biases, and existing calibration methods overlook biases arising from multi-token class labels. We tackle an issue we call label length bias, where labels of different lengths are treated inconsistently, even after standard length normalization. To mitigate it, we propose normalized contextual calibration (NCC), an effective method that normalizes and calibrates predictions at the full-label level. NCC achieves statistically significant improvements over prior approaches across multiple datasets and models, with gains of up to 10% F1. Moreover, NCC extends bias mitigation to broader tasks such as multiple-choice question answering. Our analysis shows that, when combined with in-context learning, NCC is less sensitive to few-shot example selection, requires fewer examples for competitive performance, and produces more reliable confidence estimates. These findings highlight the importance of mitigating full-label biases to improve the performance and robustness of LLM-based methods, particularly in real-world applications where class labels naturally consist of multiple tokens.

</details>


### [25] [Unified Defense for Large Language Models against Jailbreak and Fine-Tuning Attacks in Education](https://arxiv.org/abs/2511.14423)
*Xin Yi,Yue Li,Dongsheng Shi,Linlin Wang,Xiaoling Wang,Liang He*

Main category: cs.CL

TL;DR: 该论文提出了EduHarm基准测试和三阶段安全框架TSSF，用于提高教育领域大型语言模型抵御越狱和微调攻击的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在教育应用中易受越狱和微调攻击，现有安全评估方法较少关注教育场景的特殊安全需求。

Method: 1. 构建了EduHarm基准测试，包含五个代表性教育场景中的安全-不安全指令对。
2. 提出了三阶段安全框架（TSSF），包括安全感知注意力重校准、逐层安全判断和防御驱动双重路由，以减轻越狱和微调攻击。

Result: 1. EduHarm基准测试能够系统地评估教育大型语言模型的安全性。
2. TSSF框架在八种越狱攻击策略下有效增强了安全性，并防止了对良性查询的过度拒绝。
3. 在三个微调攻击数据集上，TSSF对有害查询实现了鲁棒防御，同时保持了良性微调带来的效用增益。

Conclusion: 本研究通过EduHarm基准测试和TSSF框架，为教育领域大型语言模型的安全性评估和攻击防御提供了有效的解决方案，确保了模型在教育场景中的安全应用。

Abstract: Large Language Models (LLMs) are increasingly integrated into educational applications. However, they remain vulnerable to jailbreak and fine-tuning attacks, which can compromise safety alignment and lead to harmful outputs. Existing studies mainly focus on general safety evaluations, with limited attention to the unique safety requirements of educational scenarios. To address this gap, we construct EduHarm, a benchmark containing safe-unsafe instruction pairs across five representative educational scenarios, enabling systematic safety evaluation of educational LLMs. Furthermore, we propose a three-stage shield framework (TSSF) for educational LLMs that simultaneously mitigates both jailbreak and fine-tuning attacks. First, safety-aware attention realignment redirects attention toward critical unsafe tokens, thereby restoring the harmfulness feature that discriminates between unsafe and safe inputs. Second, layer-wise safety judgment identifies harmfulness features by aggregating safety cues across multiple layers to detect unsafe instructions. Finally, defense-driven dual routing separates safe and unsafe queries, ensuring normal processing for benign inputs and guarded responses for harmful ones. Extensive experiments across eight jailbreak attack strategies demonstrate that TSSF effectively strengthens safety while preventing over-refusal of benign queries. Evaluations on three fine-tuning attack datasets further show that it consistently achieves robust defense against harmful queries while maintaining preserving utility gains from benign fine-tuning.

</details>


### [26] [Tell Me: An LLM-powered Mental Well-being Assistant with RAG, Synthetic Dialogue Generation, and Agentic Planning](https://arxiv.org/abs/2511.14445)
*Trishala Jayesh Ahalpara*

Main category: cs.CL

TL;DR: Tell Me是一个利用大型语言模型为用户和研究人员提供心理健康支持的系统，它包含RAG助手、合成对话生成器和Well-being AI智能体，旨在降低心理健康支持的门槛。


<details>
  <summary>Details</summary>
Motivation: 此研究旨在通过利用大型语言模型在心理健康支持方面的最新进展，降低获得支持的障碍，补充现有护理，并扩大心理健康资源的获取。特别是，它试图解决保密的治疗数据稀缺问题，并通过动态适应性、个性化自我护理弥补静态心理健康工具的局限性。

Method: Tell Me系统集成了三个组件：1. 一个检索增强生成（RAG）助手，用于提供个性化、基于知识的对话支持。2. 一个合成的客户-治疗师对话生成器，它根据客户档案生成对话，旨在促进治疗语言研究和数据增强。3. 一个Well-being AI智能体（使用CrewAI实现），用于生成每周自我护理计划和引导式冥想音频。该系统还包括对RAG助手在精选心理健康场景中的评估，评估方法涉及自动LLM判断和人工用户研究。

Result: Tell Me系统成功地展示了对话助手如何降低心理健康支持的门槛，补充现有护理，并扩大心理健康资源的获取。通过引入合成客户-治疗师对话生成，解决了保密治疗数据短缺的问题。该规划器展示了一个创新的智能体工作流，实现了动态适应的个性化自我护理，弥补了静态心理健康工具的局限性。RAG助手在策展的心理健康场景中表现良好，并通过自动LLM评估和人类用户研究得到了验证。

Conclusion: Tell Me系统展示了大型语言模型在提供可访问、情境感知心理健康支持方面的潜力，它通过RAG助手、合成对话生成器和智能体工作流实现了个性化、动态的护理。这项工作强调了自然语言处理研究人员和心理健康专业人员之间进行跨学科合作的重要性，以推动人工智能在心理健康领域负责任的创新。

Abstract: We present Tell Me, a mental well-being system that leverages advances in large language models to provide accessible, context-aware support for users and researchers. The system integrates three components: (i) a retrieval-augmented generation (RAG) assistant for personalized, knowledge-grounded dialogue; (ii) a synthetic client-therapist dialogue generator conditioned on client profiles to facilitate research on therapeutic language and data augmentation; and (iii) a Well-being AI crew, implemented with CrewAI, that produces weekly self-care plans and guided meditation audio. The system is designed as a reflective space for emotional processing rather than a substitute for professional therapy. It illustrates how conversational assistants can lower barriers to support, complement existing care, and broaden access to mental health resources. To address the shortage of confidential therapeutic data, we introduce synthetic client-therapist dialogue generation conditioned on client profiles. Finally, the planner demonstrates an innovative agentic workflow for dynamically adaptive, personalized self-care, bridging the limitations of static well-being tools. We describe the architecture, demonstrate its functionalities, and report evaluation of the RAG assistant in curated well-being scenarios using both automatic LLM-based judgments and a human-user study. This work highlights opportunities for interdisciplinary collaboration between NLP researchers and mental health professionals to advance responsible innovation in human-AI interaction for well-being.

</details>


### [27] [LiveRAG: A diverse Q&A dataset with varying difficulty level for RAG evaluation](https://arxiv.org/abs/2511.14531)
*David Carmel,Simone Filice,Guy Horowitz,Yoelle Maarek,Alex Shtoff,Oren Somekh,Ran Tavory*

Main category: cs.CL

TL;DR: LiveRAG基准是SIGIR'2025 LiveRAG挑战赛的Q&A数据集，旨在评估基于RAG的问答系统的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着RAG在生成式AI解决方案中日益突出，需要系统地评估其有效性。LiveRAG基准旨在解决这一需求。

Method: LiveRAG基准包含895个合成的问题和答案，来源于SIGIR'2025 LiveRAG挑战赛。它补充了地面实况答案和支持性声明，并根据项目反应理论模型为每个问题分配了难度和区分度评分。

Result: LiveRAG基准展示了问题多样性、广泛的难度级别以及区分系统能力的有效性。

Conclusion: LiveRAG基准有望帮助社区推进RAG研究，进行系统评估，并开发更强大的问答系统。

Abstract: With Retrieval Augmented Generation (RAG) becoming more and more prominent in generative AI solutions, there is an emerging need for systematically evaluating their effectiveness. We introduce the LiveRAG benchmark, a publicly available dataset of 895 synthetic questions and answers designed to support systematic evaluation of RAG-based Q&A systems. This synthetic benchmark is derived from the one used during the SIGIR'2025 LiveRAG Challenge, where competitors were evaluated under strict time constraints. It is augmented with information that was not made available to competitors during the Challenge, such as the ground-truth answers, together with their associated supporting claims which were used for evaluating competitors' answers. In addition, each question is associated with estimated difficulty and discriminability scores, derived from applying an Item Response Theory model to competitors' responses. Our analysis highlights the benchmark's questions diversity, the wide range of their difficulty levels, and their usefulness in differentiating between system capabilities. The LiveRAG benchmark will hopefully help the community advance RAG research, conduct systematic evaluation, and develop more robust Q&A systems.

</details>


### [28] [Examining the Metrics for Document-Level Claim Extraction in Czech and Slovak](https://arxiv.org/abs/2511.14566)
*Lucia Makaiová,Martin Fajčík,Antonín Jarolím*

Main category: cs.CL

TL;DR: 本文提出了一种评估文档级事实核查中提取声明的方法，通过对齐和比较声明集来衡量模型性能和标注者间的一致性。


<details>
  <summary>Details</summary>
Motivation: 目前文档级声明提取仍是事实核查领域的开放挑战，且对提取声明的评估方法关注有限。

Method: 本文研究了比对声明集并计算相似度的技术，旨在提供可靠的评估框架，以比较模型提取和人工标注的声明集，并作为评估模型提取性能和标注者间一致性的指标。

Result: 在从捷克语和斯洛伐克语新闻文章评论中提取的声明数据集上进行的实验表明，当前评估方法在文档级声明提取方面存在局限性，需要更先进的方法来捕捉语义相似性并评估声明的关键属性。

Conclusion: 当前评估方法在文档级声明提取上存在局限性，需要更先进的方法来捕获语义相似性，并评估原子性、可核实性和去语境化等关键声明属性。

Abstract: Document-level claim extraction remains an open challenge in the field of fact-checking, and subsequently, methods for evaluating extracted claims have received limited attention. In this work, we explore approaches to aligning two sets of claims pertaining to the same source document and computing their similarity through an alignment score. We investigate techniques to identify the best possible alignment and evaluation method between claim sets, with the aim of providing a reliable evaluation framework. Our approach enables comparison between model-extracted and human-annotated claim sets, serving as a metric for assessing the extraction performance of models and also as a possible measure of inter-annotator agreement. We conduct experiments on newly collected dataset-claims extracted from comments under Czech and Slovak news articles-domains that pose additional challenges due to the informal language, strong local context, and subtleties of these closely related languages. The results draw attention to the limitations of current evaluation approaches when applied to document-level claim extraction and highlight the need for more advanced methods-ones able to correctly capture semantic similarity and evaluate essential claim properties such as atomicity, checkworthiness, and decontextualization.

</details>


### [29] [A Method for Characterizing Disease Progression from Acute Kidney Injury to Chronic Kidney Disease](https://arxiv.org/abs/2511.14603)
*Yilu Fang,Jordan G. Nestor,Casey N. Ta,Jerard Z. Kneifati-Hayek,Chunhua Weng*

Main category: cs.CL

TL;DR: 该研究使用电子健康记录数据，通过聚类分析和多状态建模，识别了急性肾损伤（AKI）患者的临床演变轨迹和慢性肾脏病（CKD）进展风险因素。


<details>
  <summary>Details</summary>
Motivation: 尽管急性肾损伤患者发展为慢性肾脏病的风险很高，但识别出高风险患者仍然具有挑战性。

Method: 该研究通过对纵向医疗编码和肌酐测量数据进行聚类分析，识别了AKI后的临床状态。随后，使用多状态模型评估了状态之间的转换概率以及向CKD的进展。最后，通过生存分析确定了AKI亚群中CKD的风险因素。

Result: 在20699名入院时患有AKI的患者中，有3491名（17%）发展为CKD。研究识别了15种不同的AKI后状态，每种状态发展为CKD的概率不同。大多数患者（75%）在研究期间保持单一状态或仅发生一次转变。研究还发现了一些已知的（如AKI严重程度、糖尿病、高血压、心力衰竭、肝病）和新的CKD风险因素，这些因素的影响在不同临床状态下有所不同。

Conclusion: 该研究展示了一种数据驱动的方法，用于识别高风险AKI患者，支持开发早期CKD检测和干预的决策支持工具。

Abstract: Patients with acute kidney injury (AKI) are at high risk of developing chronic kidney disease (CKD), but identifying those at greatest risk remains challenging. We used electronic health record (EHR) data to dynamically track AKI patients' clinical evolution and characterize AKI-to-CKD progression. Post-AKI clinical states were identified by clustering patient vectors derived from longitudinal medical codes and creatinine measurements. Transition probabilities between states and progression to CKD were estimated using multi-state modeling. After identifying common post-AKI trajectories, CKD risk factors in AKI subpopulations were identified through survival analysis. Of 20,699 patients with AKI at admission, 3,491 (17%) developed CKD. We identified fifteen distinct post-AKI states, each with different probabilities of CKD development. Most patients (75%, n=15,607) remained in a single state or made only one transition during the study period. Both established (e.g., AKI severity, diabetes, hypertension, heart failure, liver disease) and novel CKD risk factors, with their impact varying across these clinical states. This study demonstrates a data-driven approach for identifying high-risk AKI patients, supporting the development of decision-support tools for early CKD detection and intervention.

</details>


### [30] [Bridging Human and Model Perspectives: A Comparative Analysis of Political Bias Detection in News Media Using Large Language Models](https://arxiv.org/abs/2511.14606)
*Shreya Adrita Banik,Niaz Nafi Rahman,Tahsina Moiukh,Farig Sadeque*

Main category: cs.CL

TL;DR: 这篇论文评估了大型语言模型在新闻媒体中检测政治偏见的能力，并将其与人类判断进行比较。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）与人类判断在检测新闻媒体政治偏见方面的一致性，目前这方面仍然没有得到充分的探索和理解。

Method: 构建了一个人工标注的新闻文章数据集，并评估了标注一致性、偏见极性和模型间一致性。将GPT、BERT、RoBERTa和FLAN等大型语言模型的表现与人类标注进行了比较。

Result: RoBERTa在传统Transformer模型中与人类标注的一致性最高。GPT等生成模型在零样本设置下与人类标注的整体一致性最强。经过微调的RoBERTa模型在所有基于Transformer的基线模型中获得了最高的准确性，并与人类标注标签具有最强的一致性。

Conclusion: 人类和大型语言模型在感知政治倾向方面存在系统性差异，强调需要结合人类可解释性和模型可扩展性的混合评估框架进行自动化媒体偏见检测。

Abstract: Detecting political bias in news media is a complex task that requires interpreting subtle linguistic and contextual cues. Although recent advances in Natural Language Processing (NLP) have enabled automatic bias classification, the extent to which large language models (LLMs) align with human judgment still remains relatively underexplored and not yet well understood. This study aims to present a comparative framework for evaluating the detection of political bias across human annotations and multiple LLMs, including GPT, BERT, RoBERTa, and FLAN. We construct a manually annotated dataset of news articles and assess annotation consistency, bias polarity, and inter-model agreement to quantify divergence between human and model perceptions of bias. Experimental results show that among traditional transformer-based models, RoBERTa achieves the highest alignment with human labels, whereas generative models such as GPT demonstrate the strongest overall agreement with human annotations in a zero-shot setting. Among all transformer-based baselines, our fine-tuned RoBERTa model acquired the highest accuracy and the strongest alignment with human-annotated labels. Our findings highlight systematic differences in how humans and LLMs perceive political slant, underscoring the need for hybrid evaluation frameworks that combine human interpretability with model scalability in automated media bias detection.

</details>


### [31] [A Specialized Large Language Model for Clinical Reasoning and Diagnosis in Rare Diseases](https://arxiv.org/abs/2511.14638)
*Tao Yang,Dandan Huang,Yunting Lin,Pengfei Wu,Zhikun Wu,Gangyuan Ma,Yulan Lu,Xinran Dong,Dingpeng Li,Junshuang Ge,Zhiyan Zhang,Xuanzhao Huang,Wenyan Nong,Yao Zhou,Hui Tang,Hongxi Yang,Shijie Zhang,Juan Li,Xiaojun Cao,Lin Yang,Xia Gao,Kaishou Xu,Xiaoqiong Gu,Wen Zhang,Huimin Xia,Li Liu,Wenhao Zhou,Mulin Jun Li*

Main category: cs.CL

TL;DR: 本文介绍了一种名为 RareSeek R1 的新型诊断工具，旨在解决罕见病诊断时间长的问题。该工具通过结合领域专业语料库、指令微调、思维链学习和图谱检索，在多中心 EHR 叙述和公共基准测试中取得了最先进的准确性，并能泛化到噪声或重叠表型。该工具的性能与经验丰富的医生相当，并且支持可审计的临床可转化决策。


<details>
  <summary>Details</summary>
Motivation: 目前罕见病诊断时间长，传统诊断流程将噪声证据提取与下游推断诊断分离，而通用/医学大型语言模型（LLMs）面临真实世界电子健康记录（EHRs）稀缺、领域知识陈旧和幻觉等问题。

Method: 1. 组建大型、领域专业的临床语料库和临床医生验证的推理集。
2. 通过分阶段指令微调、思维链学习和图谱检索开发 RareSeek R1。
3. 在多中心 EHR 叙述和公共基准测试中进行评估，并对噪声或重叠表型下的鲁棒性进行测试。
4. 进行人体研究，评估其性能与经验丰富的医生相比的水平，以及在辅助使用中的收益。

Result: 1. RareSeek R1 在多中心 EHR 叙述和公共基准测试中达到了最先进的准确性，并具有强大的泛化能力和在嘈杂或重叠表型下的稳定性。
2. 增强型检索在叙述与优先变体结合时取得了最大收益，通过解决歧义并将候选者与机制对齐。
3. 人体研究表明，其性能与经验丰富的医生相当，并在辅助使用中持续获得收益。
4. 透明推理突出显示了许多正确诊断的决定性非表型证据（中位数 23.1%，例如影像学、干预措施、功能测试）。

Conclusion: 本文提出了一种“叙述优先，知识集成推理”的范式，可以缩短诊断时间，并提供可审计、临床可转化的决策支持。

Abstract: Rare diseases affect hundreds of millions worldwide, yet diagnosis often spans years. Convectional pipelines decouple noisy evidence extraction from downstream inferential diagnosis, and general/medical large language models (LLMs) face scarce real world electronic health records (EHRs), stale domain knowledge, and hallucinations. We assemble a large, domain specialized clinical corpus and a clinician validated reasoning set, and develop RareSeek R1 via staged instruction tuning, chain of thought learning, and graph grounded retrieval. Across multicenter EHR narratives and public benchmarks, RareSeek R1 attains state of the art accuracy, robust generalization, and stability under noisy or overlapping phenotypes. Augmented retrieval yields the largest gains when narratives pair with prioritized variants by resolving ambiguity and aligning candidates to mechanisms. Human studies show performance on par with experienced physicians and consistent gains in assistive use. Notably, transparent reasoning highlights decisive non phenotypic evidence (median 23.1%, such as imaging, interventions, functional tests) underpinning many correct diagnoses. This work advances a narrative first, knowledge integrated reasoning paradigm that shortens the diagnostic odyssey and enables auditable, clinically translatable decision support.

</details>


### [32] [Graded strength of comparative illusions is explained by Bayesian inference](https://arxiv.org/abs/2511.14642)
*Yuhan Zhang,Erxiao Wang,Cory Shain*

Main category: cs.CL

TL;DR: 本文分析了比较错觉现象，并提出基于噪声信道理论的计算模型解释了其产生原因和强度变化。


<details>
  <summary>Details</summary>
Motivation: 比较错觉是一种语言处理中的错觉，尽管句子在语义上不合理，但人们却倾向于接受它。先前的研究认为这是由于对噪声信道进行贝叶斯推断的解释，但缺乏直接的量化模型来预测错觉的强度。

Method: 本文通过结合统计语言模型和人类行为数据，构建了一个量化模型来预测比较错觉的强度。该模型基于对合理解释的后验概率的计算。

Result: 该模型不仅解释了比较错觉强度的细微差别，还解释了代词与完整名词短语在“than-clause”主语中导致的先前无法解释的效应。

Conclusion: 研究结果支持了句子理解的噪声信道理论，并表明该理论可以对比较错觉做出新的预测，并得到了实证支持。这进一步证明了噪声信道推断可以作为统一的计算水平理论来解释不同的语言处理现象。

Abstract: Like visual processing, language processing is susceptible to illusions in which people systematically misperceive stimuli. In one such case--the comparative illusion (CI), e.g., More students have been to Russia than I have--comprehenders tend to judge the sentence as acceptable despite its underlying nonsensical comparison. Prior research has argued that this phenomenon can be explained as Bayesian inference over a noisy channel: the posterior probability of an interpretation of a sentence is proportional to both the prior probability of that interpretation and the likelihood of corruption into the observed (CI) sentence. Initial behavioral work has supported this claim by evaluating a narrow set of alternative interpretations of CI sentences and showing that comprehenders favor interpretations that are more likely to have been corrupted into the illusory sentence. In this study, we replicate and go substantially beyond this earlier work by directly predicting the strength of illusion with a quantitative model of the posterior probability of plausible interpretations, which we derive through a novel synthesis of statistical language models with human behavioral data. Our model explains not only the fine gradations in the strength of CI effects, but also a previously unexplained effect caused by pronominal vs. full noun phrase than-clause subjects. These findings support a noisy-channel theory of sentence comprehension by demonstrating that the theory makes novel predictions about the comparative illusion that bear out empirically. This outcome joins related evidence of noisy channel processing in both illusory and non-illusory contexts to support noisy channel inference as a unified computational-level theory of diverse language processing phenomena.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [33] [Fair-GNE : Generalized Nash Equilibrium-Seeking Fairness in Multiagent Healthcare Automation](https://arxiv.org/abs/2511.14135)
*Promise Ekpo,Saesha Agarwal,Felix Grimm,Lekan Molu,Angelique Taylor*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为 Fair-GNE 的多智能体强化学习（MARL）方法，用于在医疗保健工作负载分配中实现公平性。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习方法通过事后协调来规范奖励以实现公平性，但缺乏可证明的、个体智能体在运行时不可改变的自我强制公平性。

Method: Fair-GNE 模型将 MARL 视为一个受约束的广义纳什均衡（GNE）寻优博弈，旨在实现一个理想的公平集体均衡。

Result: 在定制的高保真复苏模拟器中，Fair-GNE 在工作负载平衡方面比固定惩罚基线显着改进（0.89 vs. 0.33 JFI，$p < 0.01$），同时保持 86% 的任务成功率。

Conclusion: Fair-GNE 通过自适应约束执行实现了统计上显著的公平性收益，为大型多智能体学习医疗系统带来了清晰且原则性的公平性执行。

Abstract: Enforcing a fair workload allocation among multiple agents tasked to achieve an objective in learning enabled demand side healthcare worker settings is crucial for consistent and reliable performance at runtime. Existing multi-agent reinforcement learning (MARL) approaches steer fairness by shaping reward through post hoc orchestrations, leaving no certifiable self-enforceable fairness that is immutable by individual agents at runtime. Contextualized within a setting where each agent shares resources with others, we address this shortcoming with a learning enabled optimization scheme among self-interested decision makers whose individual actions affect those of other agents. This extends the problem to a generalized Nash equilibrium (GNE) game-theoretic framework where we steer group policy to a safe and locally efficient equilibrium, so that no agent can improve its utility function by unilaterally changing its decisions. Fair-GNE models MARL as a constrained generalized Nash equilibrium-seeking (GNE) game, prescribing an ideal equitable collective equilibrium within the problem's natural fabric. Our hypothesis is rigorously evaluated in our custom-designed high-fidelity resuscitation simulator. Across all our numerical experiments, Fair-GNE achieves significant improvement in workload balance over fixed-penalty baselines (0.89 vs.\ 0.33 JFI, $p < 0.01$) while maintaining 86\% task success, demonstrating statistically significant fairness gains through adaptive constraint enforcement. Our results communicate our formulations, evaluation metrics, and equilibrium-seeking innovations in large multi-agent learning-based healthcare systems with clarity and principled fairness enforcement.

</details>


### [34] [Blurred Encoding for Trajectory Representation Learning](https://arxiv.org/abs/2511.13741)
*Silin Zhou,Yao Chen,Shuo Shang,Lisi Chen,Bingsheng He,Ryosuke Shibasaki*

Main category: cs.LG

TL;DR: BLUE是一种轨迹表示学习方法，它通过多尺度模糊编码保留了GPS轨迹的细粒度时空细节和整体出行模式，并在各种下游任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的轨迹表示学习方法在将原始GPS轨迹转换为网格或道路轨迹时，会丢失细粒度的时空细节，尽管它们能捕捉高层次的出行语义。

Method: BLUE方法逐步降低GPS坐标的精度，创建多层次的层次化补丁。低层补丁小，保留细粒度时空细节；高层补丁大，捕捉整体出行模式。BLUE是一个带有金字塔结构的编码器-解码器模型，在每个补丁级别使用Transformer学习轨迹嵌入，并通过池化和上采样在不同级别间传递信息。模型使用轨迹重建任务和MSE损失进行训练。

Result: BLUE在3个下游任务中与8种SOTA轨迹表示学习方法进行比较，结果显示BLUE始终比所有基线方法具有更高的准确度，平均优于表现最好的基线30.90%。

Conclusion: BLUE通过其独特的多尺度模糊编码和金字塔形编码器-解码器架构，有效解决了现有轨迹表示学习方法在细粒度时空细节上的不足，并在多个应用场景中取得了显著的性能提升。

Abstract: Trajectory representation learning (TRL) maps trajectories to vector embeddings and facilitates tasks such as trajectory classification and similarity search. State-of-the-art (SOTA) TRL methods transform raw GPS trajectories to grid or road trajectories to capture high-level travel semantics, i.e., regions and roads. However, they lose fine-grained spatial-temporal details as multiple GPS points are grouped into a single grid cell or road segment. To tackle this problem, we propose the BLUrred Encoding method, dubbed BLUE, which gradually reduces the precision of GPS coordinates to create hierarchical patches with multiple levels. The low-level patches are small and preserve fine-grained spatial-temporal details, while the high-level patches are large and capture overall travel patterns. To complement different patch levels with each other, our BLUE is an encoder-decoder model with a pyramid structure. At each patch level, a Transformer is used to learn the trajectory embedding at the current level, while pooling prepares inputs for the higher level in the encoder, and up-resolution provides guidance for the lower level in the decoder. BLUE is trained using the trajectory reconstruction task with the MSE loss. We compare BLUE with 8 SOTA TRL methods for 3 downstream tasks, the results show that BLUE consistently achieves higher accuracy than all baselines, outperforming the best-performing baselines by an average of 30.90%. Our code is available at https://github.com/slzhou-xy/BLUE.

</details>


### [35] [SCALEX: Scalable Concept and Latent Exploration for Diffusion Models](https://arxiv.org/abs/2511.13750)
*E. Zhixuan Zeng,Yuhao Chen,Alexander Wong*

Main category: cs.LG

TL;DR: SCALEX是一个评估扩散模型中社会偏见的框架，它使用自然语言提示从潜在空间中提取语义方向，以实现可扩展和自动化的分析。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型偏见分析方法在可扩展性和检测细微或意外模式方面存在局限性，因为它们过于关注预定义类别或依赖手动解释。

Method: SCALEX框架通过使用自然语言提示从H空间中提取语义上有意义的方向，实现零样本解释，无需重新训练或标注。

Result: SCALEX成功检测到专业提示中的性别偏见，对身份描述符的语义对齐进行排序，并在没有监督的情况下揭示了聚集的概念结构。

Conclusion: SCALEX通过将提示直接链接到潜在方向，使得扩散模型中的偏见分析比以前的方法更具可扩展性、可解释性和可扩展性。

Abstract: Image generation models frequently encode social biases, including stereotypes tied to gender, race, and profession. Existing methods for analyzing these biases in diffusion models either focus narrowly on predefined categories or depend on manual interpretation of latent directions. These constraints limit scalability and hinder the discovery of subtle or unanticipated patterns.
  We introduce SCALEX, a framework for scalable and automated exploration of diffusion model latent spaces. SCALEX extracts semantically meaningful directions from H-space using only natural language prompts, enabling zero-shot interpretation without retraining or labelling. This allows systematic comparison across arbitrary concepts and large-scale discovery of internal model associations. We show that SCALEX detects gender bias in profession prompts, ranks semantic alignment across identity descriptors, and reveals clustered conceptual structure without supervision. By linking prompts to latent directions directly, SCALEX makes bias analysis in diffusion models more scalable, interpretable, and extensible than prior approaches.

</details>


### [36] [Radial Compensation: Stable and Semantically Decoupled Generative Models on Riemannian Manifolds](https://arxiv.org/abs/2511.14056)
*Marios Papamichals,Regina Ruane*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为径向补偿（RC）的新方法，用于在弯曲空间上构建生成模型，旨在解耦模型参数和曲率。RC通过在切线空间中选择基础密度，使得似然性仅依赖于到极点的测地距离，从而实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 现有的弯曲空间生成模型在处理测地线和体积保存方面存在挑战，导致梯度方差大，在高维流中可能出现半径膨胀，影响模型性能。

Method: 论文提出了径向补偿（RC）方法，该方法通过信息几何学原理，选择切线空间中的基础密度，使得似然性仅依赖于到极点的测地距离，从而使径向参数保留其在测地单位中的通常意义，并使图表可以作为数值预条件器进行调整。论文还将RC扩展到已知测地极坐标体积的流形，并推导了平衡指数（bExp）图表族。

Result: RC方法允许径向参数在测地单位中保持其通常意义，并能有效解耦参数语义和曲率。在RC下，所有bExp设置都保持相同的流形密度和Fisher信息，较小的拨号值可以减少梯度方差和流成本。

Conclusion: 径向补偿（RC）是一种有效的方法，可以改善弯曲空间上生成模型的性能，提高似然性，恢复清晰的测地半径，并防止高维流中的半径膨胀，使得RC-bExp成为流形上似然训练生成模型的稳健默认选择。

Abstract: Generative models on curved spaces rely on charts to map Euclidean spaces to manifolds. Exponential maps preserve geodesics but have stiff, radius-dependent Jacobians, while volume-preserving charts maintain densities but distort geodesic distances. Both approaches entangle curvature with model parameters, inflating gradient variance. In high-dimensional latent normalizing flows, the wrapped exponential prior can stretch radii far beyond the curvature scale, leading to poor test likelihoods and stiff solvers. We introduce Radial Compensation (RC), an information-geometric method that selects the base density in the tangent space so that the likelihood depends only on geodesic distance from a pole, decoupling parameter semantics from curvature. RC lets radial parameters retain their usual meaning in geodesic units, while the chart can be tuned as a numerical preconditioner. We extend RC to manifolds with known geodesic polar volume and show that RC is the only construction for geodesic-radial likelihoods with curvature-invariant Fisher information. We derive the Balanced-Exponential (bExp) chart family, balancing volume distortion and geodesic error. Under RC, all bExp settings preserve the same manifold density and Fisher information, with smaller dial values reducing gradient variance and flow cost. Empirically, RC yields stable generative models across densities, VAEs, flows on images and graphs, and protein models. RC improves likelihoods, restores clean geodesic radii, and prevents radius blow-ups in high-dimensional flows, making RC-bExp a robust default for likelihood-trained generative models on manifolds.

</details>


### [37] [Robustness of LLM-enabled vehicle trajectory prediction under data security threats](https://arxiv.org/abs/2511.13753)
*Feilong Wang,Fuqiang Liu*

Main category: cs.LG

TL;DR: 本文探讨了将大型语言模型（LLMs）应用于自动驾驶车辆轨迹预测的鲁棒性问题，设计了一种单特征差分进化攻击方法，发现LLM在这种攻击下缺乏鲁棒性，并分析了其失效机制和潜在缓解方案。


<details>
  <summary>Details</summary>
Motivation: 目前虽然有研究表明LLMs可以准确预测车辆轨迹和车道变换意图，但LLM-based预测模型在安全关键型驾驶系统中的鲁棒性尚未被探索，这引发了人们对LLMs可信度的担忧。

Method: 本文提出了一种单特征差分进化攻击，在黑盒设置下，通过扰动LLM输入提示中周围车辆的单个运动学特征，以评估LLM-enabled车辆轨迹预测模型的脆弱性。

Result: 在highD数据集上的实验表明，即使是轻微的、物理上合理的扰动，也能显著干扰模型输出，这突显了基于LLM的预测器容易受到对抗性攻击的弱点。进一步分析揭示了准确性和鲁棒性之间的权衡，检查了失效机制，并探索了潜在的缓解解决方案。

Conclusion: 本研究首次深入探讨了LLM驱动的自动驾驶车辆模型在车辆交互环境中的对抗性漏洞，并强调了未来基于LLM的智能交通系统在设计时需要注重鲁棒性。

Abstract: The integration of large language models (LLMs) into automated driving systems has opened new possibilities for reasoning and decision-making by transforming complex driving contexts into language-understandable representations. Recent studies demonstrate that fine-tuned LLMs can accurately predict vehicle trajectories and lane-change intentions by gathering and transforming data from surrounding vehicles. However, the robustness of such LLM-based prediction models for safety-critical driving systems remains unexplored, despite the increasing concerns about the trustworthiness of LLMs. This study addresses this gap by conducting a systematic vulnerability analysis of LLM-enabled vehicle trajectory prediction. We propose a one-feature differential evolution attack that perturbs a single kinematic feature of surrounding vehicles within the LLM's input prompts under a black-box setting. Experiments on the highD dataset reveal that even minor, physically plausible perturbations can significantly disrupt model outputs, underscoring the susceptibility of LLM-based predictors to adversarial manipulation. Further analyses reveal a trade-off between accuracy and robustness, examine the failure mechanism, and explore potential mitigation solutions. The findings provide the very first insights into adversarial vulnerabilities of LLM-driven automated vehicle models in the context of vehicular interactions and highlight the need for robustness-oriented design in future LLM-based intelligent transportation systems.

</details>


### [38] [Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement](https://arxiv.org/abs/2511.13755)
*Zhe Yang,Wenrui Li,Hongtao Chen,Penghong Wang,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.LG

TL;DR: 该文章提出了一种名为 RedReg 的自适应冗余调节方法，用于解决多模态学习中模态偏差导致的优化不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 在多模态学习中，由于模态偏差，优势模态会主导反向传播，导致优化不平衡，进而出现冗余信息积累和跨模态语义与方向性被忽视的问题。

Method: RedReg 方法包含：1. 冗余阶段监测器，在冗余度高时触发干预。2. 协同信息 L_1 门控机制，根据跨模态语义估计当前主导模态的贡献。3. 将主导模态的梯度投影到联合多模态梯度子空间的 A 正交补上，并根据冗余度抑制梯度。

Result: 实验结果表明，RedReg 在大多数情况下优于当前主流方法，并且消融实验验证了我们方法的有效性。

Conclusion: RedReg 通过自适应地调节和抑制优势模态的梯度，有效地解决了多模态学习中的模态偏差和冗余信息积累问题，实现了平衡的多模态信息细化。

Abstract: Multimodal learning aims to improve performance by leveraging data from multiple sources. During joint multimodal training, due to modality bias, the advantaged modality often dominates backpropagation, leading to imbalanced optimization. Existing methods still face two problems: First, the long-term dominance of the dominant modality weakens representation-output coupling in the late stages of training, resulting in the accumulation of redundant information. Second, previous methods often directly and uniformly adjust the gradients of the advantaged modality, ignoring the semantics and directionality between modalities. To address these limitations, we propose Adaptive Redundancy Regulation for Balanced Multimodal Information Refinement (RedReg), which is inspired by information bottleneck principle. Specifically, we construct a redundancy phase monitor that uses a joint criterion of effective gain growth rate and redundancy to trigger intervention only when redundancy is high. Furthermore, we design a co-information gating mechanism to estimate the contribution of the current dominant modality based on cross-modal semantics. When the task primarily relies on a single modality, the suppression term is automatically disabled to preserve modality-specific information. Finally, we project the gradient of the dominant modality onto the orthogonal complement of the joint multimodal gradient subspace and suppress the gradient according to redundancy. Experiments show that our method demonstrates superiority among current major methods in most scenarios. Ablation experiments verify the effectiveness of our method. The code is available at https://github.com/xia-zhe/RedReg.git

</details>


### [39] [VitalBench: A Rigorous Multi-Center Benchmark for Long-Term Vital Sign Prediction in Intraoperative Care](https://arxiv.org/abs/2511.13757)
*Xiuding Cai,Xueyao Wang,Sen Wang,Yaoyao Zhu,Jiao Chen,Yu Yao*

Main category: cs.LG

TL;DR: 该文章介绍了VitalBench，这是一个新的基准，用于解决术中生命体征预测中存在的挑战，包括缺乏标准化基准、数据不完整和有限的跨中心验证。


<details>
  <summary>Details</summary>
Motivation: 开发一个标准化的基准VitalBench，用于术中生命体征预测，以解决现有挑战，如缺乏标准化基准、数据不完整和有限的跨中心验证。

Method: VitalBench包含来自两个独立医疗中心的4000多例手术数据，并提供三个评估轨道：完整数据、不完整数据和跨中心泛化。该框架通过减少对大量预处理的依赖和结合掩码损失技术来确保稳健和无偏的模型评估。

Result: VitalBench为模型开发和比较提供了一个标准化和统一的平台，使研究人员能够专注于架构创新，同时确保数据处理的一致性。

Conclusion: 这项工作为推进术中生命体征预测模型奠定了基础，确保这些模型不仅准确，而且在不同临床环境中具有鲁棒性和适应性。

Abstract: Intraoperative monitoring and prediction of vital signs are critical for ensuring patient safety and improving surgical outcomes. Despite recent advances in deep learning models for medical time-series forecasting, several challenges persist, including the lack of standardized benchmarks, incomplete data, and limited cross-center validation. To address these challenges, we introduce VitalBench, a novel benchmark specifically designed for intraoperative vital sign prediction. VitalBench includes data from over 4,000 surgeries across two independent medical centers, offering three evaluation tracks: complete data, incomplete data, and cross-center generalization. This framework reflects the real-world complexities of clinical practice, minimizing reliance on extensive preprocessing and incorporating masked loss techniques for robust and unbiased model evaluation. By providing a standardized and unified platform for model development and comparison, VitalBench enables researchers to focus on architectural innovation while ensuring consistency in data handling. This work lays the foundation for advancing predictive models for intraoperative vital sign forecasting, ensuring that these models are not only accurate but also robust and adaptable across diverse clinical environments. Our code and data are available at https://github.com/XiudingCai/VitalBench.

</details>


### [40] [ChemFixer: Correcting Invalid Molecules to Unlock Previously Unseen Chemical Space](https://arxiv.org/abs/2511.13758)
*Jun-Hyoung Park,Ho-Jun Song,Seong-Whan Lee*

Main category: cs.LG

TL;DR: ChemFixer是一个基于Transformer的框架，通过预训练和微调，能将无效分子修正为有效分子，同时保留化学和生物学特性，并在药物发现中表现出应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习分子生成模型在生成潜在药物候选物方面表现出巨大潜力，但常产生化学上无效的分子，限制了其应用。

Method: ChemFixer是一个基于Transformer架构的框架。它通过掩码技术进行预训练，并利用我们构建的大规模有效/无效分子对数据集进行微调。

Result: ChemFixer显著提高了分子的有效性，同时有效保留了原始输出的化学和生物学分布特性，表明它能恢复以前无法生成的分子，从而扩大了潜在药物候选物的多样性。它在药物-靶点相互作用预测任务中也被有效应用，提高了生成配体的有效性，并发现了有前景的配体-蛋白质对。

Conclusion: ChemFixer是一个实用的工具，能应用于深度学习药物发现的各个阶段，提高分子有效性并扩展可访问的化学空间。

Abstract: Deep learning-based molecular generation models have shown great potential in efficiently exploring vast chemical spaces by generating potential drug candidates with desired properties. However, these models often produce chemically invalid molecules, which limits the usable scope of the learned chemical space and poses significant challenges for practical applications. To address this issue, we propose ChemFixer, a framework designed to correct invalid molecules into valid ones. ChemFixer is built on a transformer architecture, pre-trained using masking techniques, and fine-tuned on a large-scale dataset of valid/invalid molecular pairs that we constructed. Through comprehensive evaluations across diverse generative models, ChemFixer improved molecular validity while effectively preserving the chemical and biological distributional properties of the original outputs. This indicates that ChemFixer can recover molecules that could not be previously generated, thereby expanding the diversity of potential drug candidates. Furthermore, ChemFixer was effectively applied to a drug-target interaction (DTI) prediction task using limited data, improving the validity of generated ligands and discovering promising ligand-protein pairs. These results suggest that ChemFixer is not only effective in data-limited scenarios, but also extensible to a wide range of downstream tasks. Taken together, ChemFixer shows promise as a practical tool for various stages of deep learning-based drug discovery, enhancing molecular validity and expanding accessible chemical space.

</details>


### [41] [Multi-Agent VLMs Guided Self-Training with PNU Loss for Low-Resource Offensive Content Detection](https://arxiv.org/abs/2511.13759)
*Han Wang,Deyi Ji,Junyu Lu,Lanyun Zhu,Hailong Zhang,Haiyang Wu,Liqun Liu,Peng Shu,Roy Ka-Wei Lee*

Main category: cs.LG

TL;DR: 该论文提出了一个用于社交媒体冒犯性内容检测的自训练框架，通过协同伪标注利用大量的未标注数据，解决了高质量标注数据稀缺的问题，并在有限监督下显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决社交媒体冒犯性内容检测中高质量标注数据稀缺的问题，因为冒犯性内容的实例很少，且手动标注成本高。

Method: 提出一个自训练框架，利用协同伪标注来利用大量的未标注数据。该方法从一个通过有限标注数据训练的轻量级分类器开始，然后通过多智能体视觉-语言模型（MA-VLMs）支持，迭代地为未标注实例分配伪标签。分类器和MA-VLMs一致的未标注数据被指定为“Agreed-Unknown”集，冲突的样本形成“Disagreed-Unknown”集。MA-VLMs模拟版主和用户双重视角，捕捉监管和主观观点以增强标签可靠性。分类器使用新颖的正-负-未标注（PNU）损失进行优化，该损失共同利用标注数据、Agreed-Unknown数据和Disagreed-Unknown数据，同时减轻伪标签噪声。

Result: 在基准数据集上的实验表明，该框架在有限监督下显著优于基线模型，并接近大型模型的性能。

Conclusion: 该自训练框架通过协同伪标注和新颖的PNU损失，有效解决了社交媒体冒犯性内容检测中数据稀缺的挑战，并在有限标注数据的情况下取得了优异的性能。

Abstract: Accurate detection of offensive content on social media demands high-quality labeled data; however, such data is often scarce due to the low prevalence of offensive instances and the high cost of manual annotation. To address this low-resource challenge, we propose a self-training framework that leverages abundant unlabeled data through collaborative pseudo-labeling. Starting with a lightweight classifier trained on limited labeled data, our method iteratively assigns pseudo-labels to unlabeled instances with the support of Multi-Agent Vision-Language Models (MA-VLMs). Un-labeled data on which the classifier and MA-VLMs agree are designated as the Agreed-Unknown set, while conflicting samples form the Disagreed-Unknown set. To enhance label reliability, MA-VLMs simulate dual perspectives, moderator and user, capturing both regulatory and subjective viewpoints. The classifier is optimized using a novel Positive-Negative-Unlabeled (PNU) loss, which jointly exploits labeled, Agreed-Unknown, and Disagreed-Unknown data while mitigating pseudo-label noise. Experiments on benchmark datasets demonstrate that our framework substantially outperforms baselines under limited supervision and approaches the performance of large-scale models

</details>


### [42] [MoETTA: Test-Time Adaptation Under Mixed Distribution Shifts with MoE-LayerNorm](https://arxiv.org/abs/2511.13760)
*Xiao Fan,Jingyan Jiang,Zhaoru Chen,Fanding Huang,Xiao Chen,Qinting Jiang,Bowen Zhang,Xing Tang,Zhi Wang*

Main category: cs.LG

TL;DR: 该论文提出了MoETTA，一个基于熵的测试时间适应（TTA）框架，能够通过混合专家（MoE）架构处理混合分布偏移，并在新的potpourri和potpourri+基准测试上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时间适应（TTA）方法在单一领域分布偏移下表现良好，但在真实世界中面临的混合分布偏移（测试样本受到多样且可能冲突的领域因素影响）方面存在显著挑战。主要限制在于它们依赖统一的适应路径，未能考虑到最佳梯度方向在不同领域间可能存在显著差异。此外，当前的基准测试侧重于合成或同质偏移，未能捕捉真实世界异构混合分布偏移的复杂性。

Method: 本文提出了MoETTA，这是一个新颖的、基于熵的TTA框架，它集成了混合专家（MoE）架构。MoETTA引入了一组结构上解耦的专家，而不是为所有测试样本强制执行单一的参数更新规则，从而允许模型沿不同的梯度方向进行适应。这种设计通过灵活和解耦的参数更新，能够更好地适应异构偏移。此外，论文还引入了两个新的基准测试：potpourri和potpourri+，以模拟实际部署条件。

Result: MoETTA在三个混合分布偏移设置下进行了广泛实验，结果表明它始终优于强大的基线模型，建立了最先进的性能，并突出了通过专家级多样性建模多个适应方向的优势。

Conclusion: MoETTA通过引入混合专家架构实现了灵活和解耦的参数更新，从而有效解决了混合分布偏移的问题。新的基准测试potpourri和potpourri+为更真实的部署条件提供了评估平台，进一步验证了MoETTA的有效性。

Abstract: Test-Time adaptation (TTA) has proven effective in mitigating performance drops under single-domain distribution shifts by updating model parameters during inference. However, real-world deployments often involve mixed distribution shifts, where test samples are affected by diverse and potentially conflicting domain factors, posing significant challenges even for SOTA TTA methods. A key limitation in existing approaches is their reliance on a unified adaptation path, which fails to account for the fact that optimal gradient directions can vary significantly across different domains. Moreover, current benchmarks focus only on synthetic or homogeneous shifts, failing to capture the complexity of real-world heterogeneous mixed distribution shifts. To address this, we propose MoETTA, a novel entropy-based TTA framework that integrates the Mixture-of-Experts (MoE) architecture. Rather than enforcing a single parameter update rule for all test samples, MoETTA introduces a set of structurally decoupled experts, enabling adaptation along diverse gradient directions. This design allows the model to better accommodate heterogeneous shifts through flexible and disentangled parameter updates. To simulate realistic deployment conditions, we introduce two new benchmarks: potpourri and potpourri+. While classical settings focus solely on synthetic corruptions, potpourri encompasses a broader range of domain shifts--including natural, artistic, and adversarial distortions--capturing more realistic deployment challenges. Additionally, potpourri+ further includes source-domain samples to evaluate robustness against catastrophic forgetting. Extensive experiments across three mixed distribution shifts settings show that MoETTA consistently outperforms strong baselines, establishing SOTA performance and highlighting the benefit of modeling multiple adaptation directions via expert-level diversity.

</details>


### [43] [Synthetic Survival Control: Extending Synthetic Controls for "When-If" Decision](https://arxiv.org/abs/2511.14133)
*Jessy Xinyi Han,Devavrat Shah*

Main category: cs.LG

TL;DR: 出ICML2024的论文，提出了一种新的因果推断方法SSC，用于解决观察数据中对时间相关事件结果进行因果效应估计的挑战。SSC在面板数据设置中估计反事实风险轨迹，并进行了理论证明。通过在癌症治疗数据集上的实验，证实了SSC的有效性。


<details>
  <summary>Details</summary>
Motivation: 在观察数据中估计时间事件结果的因果效应面临多重挑战，包括审查、样本量限制以及非随机治疗分配。 SSC正是为了解决这些挑战，以回答“如果何时”的问题：在特定干预下，事件的时间会如何变化？

Method: 合成生存控制（SSC）方法：在面板数据设置中，通过将目标单元的反事实风险轨迹估计为来自其他单元的观测轨迹的加权组合来估计反事实风险轨迹。SSC引入了一个具有低秩结构的面板框架，用于因果生存分析，并在该框架内，为因果估计量建立了识别和有限样本保证。

Result: 在新疗法错开引入的准实验设置下，通过使用癌症治疗结果的多国临床数据集验证了该方法。实证发现，获得新疗法与生存率提高相关，这反映在干预后风险轨迹相对于合成对应物更低。

Conclusion: SSC提供了一个通用且可解释的工具，用于使用观察数据进行反事实生存推断，在医学、经济学和公共政策等领域具有广泛的相关性。

Abstract: Estimating causal effects on time-to-event outcomes from observational data is particularly challenging due to censoring, limited sample sizes, and non-random treatment assignment. The need for answering such "when-if" questions--how the timing of an event would change under a specified intervention--commonly arises in real-world settings with heterogeneous treatment adoption and confounding. To address these challenges, we propose Synthetic Survival Control (SSC) to estimate counterfactual hazard trajectories in a panel data setting where multiple units experience potentially different treatments over multiple periods. In such a setting, SSC estimates the counterfactual hazard trajectory for a unit of interest as a weighted combination of the observed trajectories from other units. To provide formal justification, we introduce a panel framework with a low-rank structure for causal survival analysis. Indeed, such a structure naturally arises under classical parametric survival models. Within this framework, for the causal estimand of interest, we establish identification and finite sample guarantees for SSC. We validate our approach using a multi-country clinical dataset of cancer treatment outcomes, where the staggered introduction of new therapies creates a quasi-experimental setting. Empirically, we find that access to novel treatments is associated with improved survival, as reflected by lower post-intervention hazard trajectories relative to their synthetic counterparts. Given the broad relevance of survival analysis across medicine, economics, and public policy, our framework offers a general and interpretable tool for counterfactual survival inference using observational data.

</details>


### [44] [Gene Incremental Learning for Single-Cell Transcriptomics](https://arxiv.org/abs/2511.13762)
*Jiaxin Qi,Yan Cui,Jianqiang Huang,Gaogang Xie*

Main category: cs.LG

TL;DR: 本文提出了一种基因增量学习方法，以解决单细胞转录组数据中基因的遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 传统的增量学习主要关注计算机视觉中的类别，而对在许多研究领域中扮演重要角色的token（如基因）的增量学习关注较少。这主要是因为语言中token的整体性对设计增量学习框架带来了挑战。

Method: 本文利用单细胞转录组数据中的基因作为token，设计了一个基因增量学习流程并建立了相应的评估方法。同时，本文还借鉴了现有的类别增量学习方法，以缓解基因增量学习中的遗忘问题。

Result: 实验证明了本文提出的框架设计和评估方法的合理性以及方法适应性的有效性。

Conclusion: 本文为单细胞转录组数据中的基因增量学习提供了一个完整的基准。

Abstract: Classes, as fundamental elements of Computer Vision, have been extensively studied within incremental learning frameworks. In contrast, tokens, which play essential roles in many research fields, exhibit similar characteristics of growth, yet investigations into their incremental learning remain significantly scarce. This research gap primarily stems from the holistic nature of tokens in language, which imposes significant challenges on the design of incremental learning frameworks for them. To overcome this obstacle, in this work, we turn to a type of token, gene, for a large-scale biological dataset--single-cell transcriptomics--to formulate a pipeline for gene incremental learning and establish corresponding evaluations. We found that the forgetting problem also exists in gene incremental learning, thus we adapted existing class incremental learning methods to mitigate the forgetting of genes. Through extensive experiments, we demonstrated the soundness of our framework design and evaluations, as well as the effectiveness of our method adaptations. Finally, we provide a complete benchmark for gene incremental learning in single-cell transcriptomics.

</details>


### [45] [Library Liberation: Competitive Performance Matmul Through Compiler-composed Nanokernels](https://arxiv.org/abs/2511.13764)
*Arun Thangamani,Md Asghar Ahmad Shahid,Adam Siemieniuk,Rolf Morel,Renato Golin,Alexander Heinecke*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种编译方案，通过利用MLIR方言自动生成可扩展的高性能微内核，以弥合领域操作与处理器能力之间的差距。


<details>
  <summary>Details</summary>
Motivation: AI和机器学习工作负载的快速发展，使得高级领域操作与高效硬件利用之间的差距增大。实现接近峰值的性能仍然需要深厚的硬件专业知识，这增加了复杂性并限制了可扩展性。

Method: 本文引入了一种编译方案，通过利用MLIR方言来连接领域级操作和处理器能力，自动生成可扩展、高性能的微内核。其核心是一种从低级IR构造中组合纳米内核的机制，具有接近最优的寄存器利用率，形成针对每个目标量身定制的高效微内核。

Result: 生成的纳米内核具有生产质量，并且与最先进的微内核库具有竞争力。

Conclusion: 该编译方案通过自动生成高效微内核，消除了对低级库的依赖，并使MLIR编译器能够直接自动生成接近最优的代码。

Abstract: The rapidly evolving landscape of AI and machine learning workloads has widened the gap between high-level domain operations and efficient hardware utilization. Achieving near-peak performance still demands deep hardware expertise-experts either handcraft target-specific kernels (e.g., DeepSeek) or rely on specialized libraries (e.g., CUTLASS)-both of which add complexity and limit scalability for most ML practitioners.
  This paper introduces a compilation scheme that automatically generates scalable, high-performance microkernels by leveraging the MLIR dialects to bridge domain-level operations and processor capabilities. Our approach removes dependence on low-level libraries by enabling the compiler to auto-generate near-optimal code directly. At its core is a mechanism for composing nanokernels from low-level IR constructs with near-optimal register utilization, forming efficient microkernels tailored to each target. We implement this technique in an MLIR-based compiler supporting both vector and tile based CPU instructions. Experiments show that the generated nanokernels are of production-quality, and competitive with state-of-the-art microkernel libraries.

</details>


### [46] [PROF: An LLM-based Reward Code Preference Optimization Framework for Offline Imitation Learning](https://arxiv.org/abs/2511.13765)
*Shengjie Sun,Jiafei Lyu,Runze Liu,Mengbei Yan,Bo Liu,Deheng Ye,Xiu Li*

Main category: cs.LG

TL;DR: PROF是一种新颖的框架，它利用大型语言模型（LLM）从自然语言描述和单一专家轨迹生成和改进可执行奖励函数代码。


<details>
  <summary>Details</summary>
Motivation: 传统的离线模仿学习方法通常假设轨迹与专家演示之间的相似性与奖励呈正相关，这过度简化了潜在的奖励结构。

Method: PROF利用LLM生成和改进奖励函数代码，并提出奖励偏好排序（RPR）策略来评估和排序奖励函数质量，无需环境交互或强化学习训练。RPR计算奖励函数的主导分数，高分数表示与专家偏好更好的一致性。PROF通过RPR和基于文本的梯度优化交替进行，实现奖励函数选择和优化的全自动化。

Result: D4RL上的实证结果表明，PROF在众多数据集和领域中超越或 SOTA（State Of The Art） 现有的基线方法。

Conclusion: PROF框架通过利用大型语言模型生成和改进奖励函数，并结合奖励偏好排序策略，有效地解决了离线模仿学习中奖励函数估计的挑战，取得了显著的性能提升。

Abstract: Offline imitation learning (offline IL) enables training effective policies without requiring explicit reward annotations. Recent approaches attempt to estimate rewards for unlabeled datasets using a small set of expert demonstrations. However, these methods often assume that the similarity between a trajectory and an expert demonstration is positively correlated with the reward, which oversimplifies the underlying reward structure. We propose PROF, a novel framework that leverages large language models (LLMs) to generate and improve executable reward function codes from natural language descriptions and a single expert trajectory. We propose Reward Preference Ranking (RPR), a novel reward function quality assessment and ranking strategy without requiring environment interactions or RL training. RPR calculates the dominance scores of the reward functions, where higher scores indicate better alignment with expert preferences. By alternating between RPR and text-based gradient optimization, PROF fully automates the selection and refinement of optimal reward functions for downstream policy learning. Empirical results on D4RL demonstrate that PROF surpasses or matches recent strong baselines across numerous datasets and domains, highlighting the effectiveness of our approach.

</details>


### [47] [Credal Ensemble Distillation for Uncertainty Quantification](https://arxiv.org/abs/2511.13766)
*Kaizheng Wang,Fabio Cuzzolin,David Moens,Hans Hallez*

Main category: cs.LG

TL;DR: 该论文提出了一种名为credal ensemble distillation（CED）的新框架，用于将深度集成（DE）压缩成单个模型CREDIT，以降低计算和内存成本，同时保持或提高不确定性估计的性能。


<details>
  <summary>Details</summary>
Motivation: 深度集成（DE）在量化预测不确定性和区分其偶然及认知成分方面表现出色，提升了模型的鲁棒性和可靠性。然而，其高昂的推理计算和内存成本限制了实际应用。

Method: 本文提出了一种credal ensemble distillation（CED）框架，将深度集成（DE）压缩成一个名为CREDIT的单一模型，用于分类任务。CREDIT模型不输出单一的softmax概率分布，而是预测类别概率区间，这些区间定义了一个credal set，用于量化不确定性。

Result: 在分布外检测基准上的实证结果表明，与现有的几个基线相比，CED实现了优越或相当的不确定性估计。与深度集成（DE）相比，CED显著降低了推理开销。

Conclusion: CED框架能够有效压缩深度集成模型，大大降低了计算和内存成本，同时在不确定性估计方面表现出竞争甚至更优的性能，从而为深度集成模型的广泛实际应用铺平了道路。

Abstract: Deep ensembles (DE) have emerged as a powerful approach for quantifying predictive uncertainty and distinguishing its aleatoric and epistemic components, thereby enhancing model robustness and reliability. However, their high computational and memory costs during inference pose significant challenges for wide practical deployment. To overcome this issue, we propose credal ensemble distillation (CED), a novel framework that compresses a DE into a single model, CREDIT, for classification tasks. Instead of a single softmax probability distribution, CREDIT predicts class-wise probability intervals that define a credal set, a convex set of probability distributions, for uncertainty quantification. Empirical results on out-of-distribution detection benchmarks demonstrate that CED achieves superior or comparable uncertainty estimation compared to several existing baselines, while substantially reducing inference overhead compared to DE.

</details>


### [48] [Dynamic Temperature Scheduler for Knowledge Distillation](https://arxiv.org/abs/2511.13767)
*Sibgat Ul Islam,Jawad Ibn Ahad,Fuad Rahman,Mohammad Ruhul Amin,Nabeel Mohammed,Shafin Rahman*

Main category: cs.LG

TL;DR: 本文提出了一种动态温度调度器（DTS），通过解决大型教师模型和小型学生模型之间软输出概率的学习问题，优化了知识蒸馏（KD）在视觉和NLP任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法使用固定的温度超参数，这对于训练过程来说并不是最优的。此外，教师模型和学生模型之间的体系结构差异可能导致输出logit幅度的不匹配，因此需要一种动态调整温度的方法来优化软输出概率的学习。

Method: 本研究提出了动态温度调度器（DTS）。该调度器根据教师模型和学生模型之间的交叉熵损失差距动态调整温度。DTS与现有的KD框架无缝集成。

Result: DTS在视觉任务（CIFAR-100、Tiny-ImageNet）和NLP任务（GLUE、Dolly、SelfIns、UnNI、S-NI）的多种KD策略中都优于静态温度基线。

Conclusion: DTS通过在训练的早期阶段提供更软的概率，并在后期阶段提供更清晰的概率，从而提高了学生模型的性能。这是首个根据教师和学生模型之间分布差异进行调整的温度调度方法，为知识蒸馏提供了更优的解决方案。

Abstract: Knowledge Distillation (KD) trains a smaller student model using a large, pre-trained teacher model, with temperature as a key hyperparameter controlling the softness of output probabilities. Traditional methods use a fixed temperature throughout training, which is suboptimal. Moreover, architectural differences between teacher and student often result in mismatched logit magnitudes. We demonstrate that students benefit from softer probabilities early in training but require sharper probabilities in later stages. We introduce Dynamic Temperature Scheduler (DTS), which adjusts temperature dynamically based on the cross-entropy loss gap between teacher and student. To our knowledge, this is the first temperature scheduling method that adapts based on the divergence between teacher and student distributions. Our method integrates seamlessly with existing KD frameworks. We validate DTS across multiple KD strategies on vision (CIFAR-100, Tiny-ImageNet) and NLP tasks (GLUE, Dolly, SelfIns, UnNI, S-NI), consistently outperforming static-temperature baselines. Code is available at https://github.com/Sibgat-Ul/DTS.

</details>


### [49] [Self-Attention as Distributional Projection: A Unified Interpretation of Transformer Architecture](https://arxiv.org/abs/2511.13780)
*Nihal Mehta*

Main category: cs.LG

TL;DR: 这篇论文将自注意力机制与分布语义学原理联系起来，对其进行了数学解释。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制在自然语言处理中取得了显著成功，其背后的数学原理和为何如此有效尚不完全清楚。

Method: 通过将自注意力机制与语料库级别的共现统计量联系起来，并利用GloVe嵌入的基础共现矩阵，作者展示了自注意力机制如何投射这些统计量来捕捉上下文影响。此外，论文还解释了查询-键-值机制、位置编码和多头注意力的产生。

Result: 自注意力机制可以被理解为将语料库级别的共现统计量投射到序列上下文中。查询-键-值机制是建模方向性关系的自然不对称扩展。位置编码和多头注意力是这种投射原理的结构化改进。

Conclusion: Transformer架构的特殊代数形式来源于其投影原理，而非任意设计。

Abstract: This paper presents a mathematical interpretation of self-attention by connecting it to distributional semantics principles. We show that self-attention emerges from projecting corpus-level co-occurrence statistics into sequence context. Starting from the co-occurrence matrix underlying GloVe embeddings, we demonstrate how the projection naturally captures contextual influence, with the query-key-value mechanism arising as the natural asymmetric extension for modeling directional relationships. Positional encodings and multi-head attention then follow as structured refinements of this same projection principle. Our analysis demonstrates that the Transformer architecture's particular algebraic form follows from these projection principles rather than being an arbitrary design choice.

</details>


### [50] [ScoresActivation: A New Activation Function for Model Agnostic Global Explainability by Design](https://arxiv.org/abs/2511.13809)
*Emanuel Covaci,Fabian Galis,Radu Balan,Daniela Zaharie,Darian Onchis*

Main category: cs.LG

TL;DR: 该研究提出了一种新的可微分的全局可解释性方法，将特征重要性估计直接集成到模型训练中，通过ScoresActivation函数实现，从而在保持预测性能的同时，提供忠实、稳定的特征排序，并且比传统SHAP方法快150倍。


<details>
  <summary>Details</summary>
Motivation: 构建透明和值得信赖的系统，但现有事后解释方法与模型训练过程脱节，限制了其忠实性和效用。

Method: 引入了一种新颖的、可微分的全局可解释性设计方法，将特征重要性估计直接整合到模型训练中。该方法的核心是ScoresActivation函数，一个嵌入在学习管线中的特征排序机制。

Result: 该方法产生了全局忠实、稳定的特征排序，与SHAP值和真实特征重要性一致，同时保持了高预测性能。特征评分速度比经典SHAP方法快150倍，仅需2秒。在不同特征数量下，分类准确率分别提高了11.24%和29.33%。

Conclusion: 这项工作弥合了模型准确性和可解释性之间的鸿沟，提供了一个可扩展的、本质上可解释的机器学习框架。

Abstract: Understanding the decision of large deep learning models is a critical challenge for building transparent and trustworthy systems. Although the current post hoc explanation methods offer valuable insights into feature importance, they are inherently disconnected from the model training process, limiting their faithfulness and utility. In this work, we introduce a novel differentiable approach to global explainability by design, integrating feature importance estimation directly into model training. Central to our method is the ScoresActivation function, a feature-ranking mechanism embedded within the learning pipeline. This integration enables models to prioritize features according to their contribution to predictive performance in a differentiable and end-to-end trainable manner. Evaluations across benchmark datasets show that our approach yields globally faithful, stable feature rankings aligned with SHAP values and ground-truth feature importance, while maintaining high predictive performance. Moreover, feature scoring is 150 times faster than the classical SHAP method, requiring only 2 seconds during training compared to SHAP's 300 seconds for feature ranking in the same configuration. Our method also improves classification accuracy by 11.24% with 10 features (5 relevant) and 29.33% with 16 features (5 relevant, 11 irrelevant), demonstrating robustness to irrelevant inputs. This work bridges the gap between model accuracy and interpretability, offering a scalable framework for inherently explainable machine learning.

</details>


### [51] [Beat the long tail: Distribution-Aware Speculative Decoding for RL Training](https://arxiv.org/abs/2511.13841)
*Zelei Shao,Vikranth Srivatsa,Sanjana Srivastava,Qingyang Wu,Alpay Ariyak,Xiaoxia Wu,Ameen Patel,Jue Wang,Percy Liang,Tri Dao,Ce Zhang,Yiying Zhang,Ben Athiwaratkun,Chenfeng Xu,Junxiong Wang*

Main category: cs.LG

TL;DR: 本文提出了一种名为DAS的分布感知推测解码框架，它通过利用历史经验和长度感知策略来加速强化学习的推出过程，尤其针对长序列，从而将推出时间缩短了50%且不影响模型输出。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）后训练在对大型语言模型（LLM）进行对齐时至关重要，但其效率受到推出阶段的限制，特别是长轨迹。我们发现主要瓶颈在于推出长度的长尾分布：一小部分长生成主导了运行时间，同时存在一个互补的机会，即历史推出揭示了跨训练周期的稳定提示级别模式。

Method: 本文提出了DAS（Distribution Aware Speculative decoding）框架，旨在加速RL推出，且不改变模型输出。DAS整合了两个关键思想：1. 一个自适应的、非参数的草案器，该草案器利用近期推出的结果，并通过增量维护的后缀树构建而成。2. 一个长度感知的推测策略，该策略为在总运行时间中占主导地位的长轨迹分配更积极的草案预算。该设计利用推出历史来维持接受率，同时平衡解码过程中的基本和令牌级别成本。

Result: 在数学和代码推理任务上的实验表明，DAS将推出时间减少了50%，同时保留了相同的训练曲线。

Conclusion: 分布感知推测解码可以显著加速RL后训练过程，而不会损害学习质量。

Abstract: Reinforcement learning(RL) post-training has become essential for aligning large language models (LLMs), yet its efficiency is increasingly constrained by the rollout phase, where long trajectories are generated token by token. We identify a major bottleneck:the long-tail distribution of rollout lengths, where a small fraction of long generations dominates wall clock time and a complementary opportunity; the availability of historical rollouts that reveal stable prompt level patterns across training epochs. Motivated by these observations, we propose DAS, a Distribution Aware Speculative decoding framework that accelerates RL rollouts without altering model outputs. DAS integrates two key ideas: an adaptive, nonparametric drafter built from recent rollouts using an incrementally maintained suffix tree, and a length aware speculation policy that allocates more aggressive draft budgets to long trajectories that dominate makespan. This design exploits rollout history to sustain acceptance while balancing base and token level costs during decoding. Experiments on math and code reasoning tasks show that DAS reduces rollout time up to 50% while preserving identical training curves, demonstrating that distribution-aware speculative decoding can significantly accelerate RL post training without compromising learning quality.

</details>


### [52] [AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection](https://arxiv.org/abs/2511.13880)
*Saleh Momeni,Changnan Xiao,Bing Liu*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的方法 AnaCP，它在保持分析分类器效率的同时，实现了增量特征适应，从而在类增量学习任务中超越现有基线，达到联合训练的准确水平。


<details>
  <summary>Details</summary>
Motivation: 传统的类增量学习方法（不使用预训练模型）在增量学习特征表示和分类器时存在灾难性遗忘问题。将预训练模型集成到类增量学习中虽然提高了性能，但仍面临一个主要限制：无法持续调整特征表示以适应类增量学习任务，导致次优性能。

Method: 本文提出了一种名为 AnaCP（Analytic Contrastive Projection）的新方法。该方法在保留分析分类器效率的同时，实现了增量特征适应，并且无需基于梯度的训练，从而消除了由梯度更新引起的灾难性遗忘。

Result: 实验结果表明，AnaCP 不仅优于现有的基线方法，而且达到了联合训练的准确性水平，而联合训练被认为是类增量学习的性能上限。

Conclusion: AnaCP 是一种有效解决类增量学习中灾难性遗忘和特征适应问题的方法，它通过无需梯度训练的增量特征适应，实现了与联合训练相媲美的性能。

Abstract: This paper studies the problem of class-incremental learning (CIL), a core setting within continual learning where a model learns a sequence of tasks, each containing a distinct set of classes. Traditional CIL methods, which do not leverage pre-trained models (PTMs), suffer from catastrophic forgetting (CF) due to the need to incrementally learn both feature representations and the classifier. The integration of PTMs into CIL has recently led to efficient approaches that treat the PTM as a fixed feature extractor combined with analytic classifiers, achieving state-of-the-art performance. However, they still face a major limitation: the inability to continually adapt feature representations to best suit the CIL tasks, leading to suboptimal performance. To address this, we propose AnaCP (Analytic Contrastive Projection), a novel method that preserves the efficiency of analytic classifiers while enabling incremental feature adaptation without gradient-based training, thereby eliminating the CF caused by gradient updates. Our experiments show that AnaCP not only outperforms existing baselines but also achieves the accuracy level of joint training, which is regarded as the upper bound of CIL.

</details>


### [53] [The Impact of Bootstrap Sampling Rate on Random Forest Performance in Regression Tasks](https://arxiv.org/abs/2511.13952)
*Michał Iwaniuk,Mateusz Jarosz,Bartłomiej Borycki,Bartosz Jezierski,Jan Cwalina,Stanisław Kaźmierczak,Jacek Mańdziuk*

Main category: cs.LG

TL;DR: 本文探讨了随机森林中bootstrap采样率对模型性能的影响，并发现调整采样率可以显著提升模型效果，尤其是在不同数据集特性下。


<details>
  <summary>Details</summary>
Motivation: 此研究旨在系统性地探究bootstrap采样率（BR）如何影响随机森林（RF）的性能，并找出最优的BR设置，而非简单采纳默认值。

Method: 研究者在39个不同的回归数据集和16种RF配置上，通过调整BR（从0.2到5.0）评估了RF的性能。他们使用重复的二折交叉验证和均方误差进行评估。此外，还在合成数据集上进行了实验，以研究数据集特性与BR之间的关系。

Result: 结果表明，调整BR可以显著提升模型性能，其中24个数据集的最佳BR不大于1.0，15个数据集的最佳BR大于1.0，在4个数据集中BR=1.0是最佳选择。研究者发现，全局特征-目标关系强的数据集偏好更高的BR，而局部目标方差大的数据集则受益于更低的BR。在低噪声场景中，提高BR可有效降低模型偏差；在高噪声场景中，降低BR有助于减少模型方差。

Conclusion: bootstrap采样率是一个重要的超参数，应该对其进行调整以优化随机森林回归模型。

Abstract: Random Forests (RFs) typically train each tree on a bootstrap sample of the same size as the training set, i.e., bootstrap rate (BR) equals 1.0. We systematically examine how varying BR from 0.2 to 5.0 affects RF performance across 39 heterogeneous regression datasets and 16 RF configurations, evaluating with repeated two-fold cross-validation and mean squared error. Our results demonstrate that tuning the BR can yield significant improvements over the default: the best setup relied on BR \leq 1.0 for 24 datasets, BR > 1.0 for 15, and BR = 1.0 was optimal in 4 cases only. We establish a link between dataset characteristics and the preferred BR: datasets with strong global feature-target relationships favor higher BRs, while those with higher local target variance benefit from lower BRs. To further investigate this relationship, we conducted experiments on synthetic datasets with controlled noise levels. These experiments reproduce the observed bias-variance trade-off: in low-noise scenarios, higher BRs effectively reduce model bias, whereas in high-noise settings, lower BRs help reduce model variance. Overall, BR is an influential hyperparameter that should be tuned to optimize RF regression models.

</details>


### [54] [Node-Level Uncertainty Estimation in LLM-Generated SQL](https://arxiv.org/abs/2511.13984)
*Hilaf Hasson,Ruocheng Guo*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种通过估计查询抽象语法树（AST）中各个节点的置信度来检测大型语言模型（LLM）生成的SQL错误的方法。


<details>
  <summary>Details</summary>
Motivation: LLM生成的SQL错误检测和不确定性估计的传统方法存在缺陷，例如对结构性容器或别名变化的过度惩罚，以及 token log-probabilities 的性能不佳。

Method: 该方法分为两个阶段。首先，提出了一个语义感知的标注算法，该算法在给定生成的SQL和黄金参考的情况下，分配节点级别的正确性，而不会过度惩罚结构性容器或别名变化。其次，使用丰富的模式感知和词法特征表示每个节点，并训练一个监督分类器来预测每个节点的错误概率。

Result: 在多个数据库和数据集上，该方法在平均AUC方面优于 token log-probabilities 27.44％，并且在跨数据库评估下保持鲁棒性。

Conclusion: 节点级不确定性估计不仅可以作为准确性信号，还可以支持有针对性的修复、人工审查和下游选择性执行。这证明了以节点为中心、语义驱动的不确定性估计是聚合序列级别置信度测量的一种强大且可解释的替代方案。

Abstract: We present a practical framework for detecting errors in LLM-generated SQL by estimating uncertainty at the level of individual nodes in the query's abstract syntax tree (AST). Our approach proceeds in two stages. First, we introduce a semantically aware labeling algorithm that, given a generated SQL and a gold reference, assigns node-level correctness without over-penalizing structural containers or alias variation. Second, we represent each node with a rich set of schema-aware and lexical features - capturing identifier validity, alias resolution, type compatibility, ambiguity in scope, and typo signals - and train a supervised classifier to predict per-node error probabilities. We interpret these probabilities as calibrated uncertainty, enabling fine-grained diagnostics that pinpoint exactly where a query is likely to be wrong. Across multiple databases and datasets, our method substantially outperforms token log-probabilities: average AUC improves by +27.44% while maintaining robustness under cross-database evaluation. Beyond serving as an accuracy signal, node-level uncertainty supports targeted repair, human-in-the-loop review, and downstream selective execution. Together, these results establish node-centric, semantically grounded uncertainty estimation as a strong and interpretable alternative to aggregate sequence level confidence measures.

</details>


### [55] [Certified but Fooled! Breaking Certified Defences with Ghost Certificates](https://arxiv.org/abs/2511.14003)
*Quoc Viet Vo,Tashreque M. Haq,Paul Montague,Tamas Abraham,Ehsan Abbasnejad,Damith C. Ranasinghe*

Main category: cs.LG

TL;DR: 本文研究了在认证防御中，利用概率认证框架的漏洞来生成虚假鲁棒性保证的方法，并探讨了如何通过微小扰动实现这一目标，以更好地理解鲁棒性认证方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 探索如何恶意利用概率认证框架来伪造鲁棒性保证，以深入了解保证机制的潜在局限性。

Method: 通过“区域聚焦对抗样本”技术生成微小的、难以察觉的扰动，这些扰动能够欺骗认证模型为目标类别生成虚假且较大的鲁棒性半径，甚至比源类别的“影子证书”的认证半径更大。

Result: 在ImageNet上进行的广泛评估表明，该方法能够有效地绕过最先进的认证防御（如Densepure）。

Conclusion: 这项工作强调了需要更好地理解鲁棒性认证方法的局限性。

Abstract: Certified defenses promise provable robustness guarantees. We study the malicious exploitation of probabilistic certification frameworks to better understand the limits of guarantee provisions. Now, the objective is to not only mislead a classifier, but also manipulate the certification process to generate a robustness guarantee for an adversarial input certificate spoofing. A recent study in ICLR demonstrated that crafting large perturbations can shift inputs far into regions capable of generating a certificate for an incorrect class. Our study investigates if perturbations needed to cause a misclassification and yet coax a certified model into issuing a deceptive, large robustness radius for a target class can still be made small and imperceptible. We explore the idea of region-focused adversarial examples to craft imperceptible perturbations, spoof certificates and achieve certification radii larger than the source class ghost certificates. Extensive evaluations with the ImageNet demonstrate the ability to effectively bypass state-of-the-art certified defenses such as Densepure. Our work underscores the need to better understand the limits of robustness certification methods.

</details>


### [56] [A Machine Learning-Based Multimodal Framework for Wearable Sensor-Based Archery Action Recognition and Stress Estimation](https://arxiv.org/abs/2511.14057)
*Xianghe Liu,Jiajia Liu,Chuxian Xu,Minghan Wang,Hongbo Peng,Tao Sun,Jiaqi Xu*

Main category: cs.LG

TL;DR: 本文提出了一个机器学习框架，其通过可穿戴传感器数据进行同步动作识别和压力估计，提高了运动员在精准运动中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的运动分析系统昂贵且具有侵入性，限制了其在自然训练环境中的使用。

Method: 将加速度计和PPG传感器集成到腕戴设备中，收集同步运动和生理数据。引入平滑差分加速度（SmoothDiff）作为新特征，并使用长短期记忆（LSTM）模型识进行动作识别（准确率为96.8%）。从PPG信号中提取心率变异性（HRV）特征，并应用多层感知器（MLP）分类器进行压力估计（准确率为80%）。

Result: 在动作识别方面，实现了96.8%的准确率和95.9%的F1分数。在压力估计方面，区分高低压力水平的准确率达到80%。

Conclusion: 该框架通过整合运动和生理传感，为运动员的技术和心理状态提供了有意义的见解，并为精准运动训练优化中的智能实时反馈系统奠定了基础。

Abstract: In precision sports such as archery, athletes' performance depends on both biomechanical stability and psychological resilience. Traditional motion analysis systems are often expensive and intrusive, limiting their use in natural training environments. To address this limitation, we propose a machine learning-based multimodal framework that integrates wearable sensor data for simultaneous action recognition and stress estimation. Using a self-developed wrist-worn device equipped with an accelerometer and photoplethysmography (PPG) sensor, we collected synchronized motion and physiological data during real archery sessions. For motion recognition, we introduce a novel feature--Smoothed Differential Acceleration (SmoothDiff)--and employ a Long Short-Term Memory (LSTM) model to identify motion phases, achieving 96.8% accuracy and 95.9% F1-score. For stress estimation, we extract heart rate variability (HRV) features from PPG signals and apply a Multi-Layer Perceptron (MLP) classifier, achieving 80% accuracy in distinguishing high- and low-stress levels. The proposed framework demonstrates that integrating motion and physiological sensing can provide meaningful insights into athletes' technical and mental states. This approach offers a foundation for developing intelligent, real-time feedback systems for training optimization in archery and other precision sports.

</details>


### [57] [CafeMed: Causal Attention Fusion Enhanced Medication Recommendation](https://arxiv.org/abs/2511.14064)
*Kelin Ren,Chan-Yang Ju,Dong-Ho Lee*

Main category: cs.LG

TL;DR: CafeMed是一个通过整合动态因果推理和跨模态注意力，提升药物推荐安全性和准确性的框架，它通过Causal Weight Generator实现动态因果效应，并通过Channel Harmonized Attention Refinement Module捕获诊断和程序间的复杂关联。


<details>
  <summary>Details</summary>
Motivation: 现有药物推荐系统在学习药物表征方面取得进展，但存在两个局限性：1. 将医学实体视为独立特征，未对其协同效应进行建模；2. 采用静态因果关系，无法适应患者特异性背景和健康状况。

Method: CafeMed框架包含两个关键组件：Causal Weight Generator（CWG）根据个体患者状态将静态因果效应转化为动态调制权重；Channel Harmonized Attention Refinement Module（CHARM）捕获诊断和程序之间复杂的相互依赖关系。

Result: 在MIMIC-III和MIMIC-IV数据集上的大量实验表明，CafeMed显著优于现有基线，在药物预测方面实现了卓越的准确性，同时保持了较低的药物间相互作用率。

Conclusion: CafeMed通过结合动态因果关系和跨模态协同作用，能够提供更符合临床实际且个性化的药物推荐。

Abstract: Medication recommendation systems play a crucial role in assisting clinicians with personalized treatment decisions. While existing approaches have made significant progress in learning medication representations, they suffer from two fundamental limitations: (i) treating medical entities as independent features without modeling their synergistic effects on medication selection; (ii) employing static causal relationships that fail to adapt to patient-specific contexts and health states. To address these challenges, we propose CafeMed, a framework that integrates dynamic causal reasoning with cross-modal attention for safe and accurate medication recommendation. CafeMed introduces two key components: the Causal Weight Generator (CWG) that transforms static causal effects into dynamic modulation weights based on individual patient states, and the Channel Harmonized Attention Refinement Module (CHARM) that captures complex interdependencies between diagnoses and procedures. This design enables CafeMed to model how different medical conditions jointly influence treatment decisions while maintaining medication safety constraints. Extensive experiments on MIMIC-III and MIMIC-IV datasets demonstrate that CafeMed significantly outperforms state-of-the-art baselines, achieving superior accuracy in medication prediction while maintaining the lower drug--drug interaction rates. Our results indicate that incorporating dynamic causal relationships and cross-modal synergies leads to more clinically-aligned and personalized medication recommendations. Our code is released publicly at https://github.com/rkl71/CafeMed.

</details>


### [58] [CFG-EC: Error Correction Classifier-Free Guidance](https://arxiv.org/abs/2511.14075)
*Nakkyu Yang,Yechan Lee,SooJean Han*

Main category: cs.LG

TL;DR: 本文提出了一种名为 CFG-EC 的方法，通过校正无条件噪声预测来改进 Classifier-Free Guidance (CFG)，从而在图像生成中实现更高的保真度。


<details>
  <summary>Details</summary>
Motivation: 在条件生成模型中，Classifier-Free Guidance (CFG) 已成为提高提示保真度和生成质量的主流方法。然而，CFG 在训练和采样过程中存在不一致的噪声估计，导致输出不准确。

Method: CFG-EC 通过重新调整无条件噪声误差分量使其与条件误差分量正交，从而纠正了无条件噪声预测。这种校正操作可以防止两个指导分量之间的干扰，从而约束采样误差的上限并建立更可靠的指导轨迹。

Result: 数值实验表明，CFG-EC 比 CFG 和 CFG++ 更有效地处理无条件分量，在低指导采样机制下显著提高了性能，并在各种场景下始终保持更高的提示对齐。

Conclusion: CFG-EC 通过改进无条件噪声预测，解决了 CFG 在训练和采样过程中的噪声估计不一致问题，从而提升了图像生成的质量和提示对齐。

Abstract: Classifier-Free Guidance (CFG) has become a mainstream approach for simultaneously improving prompt fidelity and generation quality in conditional generative models. During training, CFG stochastically alternates between conditional and null prompts to enable both conditional and unconditional generation. However, during sampling, CFG outputs both null and conditional prompts simultaneously, leading to inconsistent noise estimates between the training and sampling processes. To reduce this error, we propose CFG-EC, a versatile correction scheme augmentable to any CFG-based method by refining the unconditional noise predictions. CFG-EC actively realigns the unconditional noise error component to be orthogonal to the conditional error component. This corrective maneuver prevents interference between the two guidance components, thereby constraining the sampling error's upper bound and establishing more reliable guidance trajectories for high-fidelity image generation. Our numerical experiments show that CFG-EC handles the unconditional component more effectively than CFG and CFG++, delivering a marked performance increase in the low guidance sampling regime and consistently higher prompt alignment across the board.

</details>


### [59] [Observational Auditing of Label Privacy](https://arxiv.org/abs/2511.14084)
*Iden Kalemaj,Luca Melis,Maxime Boucher,Ilya Mironov,Saeed Mahloujifar*

Main category: cs.LG

TL;DR: 该论文介绍了一种新颖的观察性审计框架，即使不改变原始数据集，也可以评估机器学习系统中的差分隐私（DP）保证。


<details>
  <summary>Details</summary>
Motivation: 传统的差分隐私（DP）审计方法需要修改训练数据集，例如注入异常值或删除样本，这在大规模系统中会带来高昂的资源成本和工程开销。

Method: 该论文提出了一种新颖的观察性审计框架，利用数据分布的固有随机性，在不改变原始数据集的情况下进行隐私评估。它将隐私审计从传统的成员推理扩展到受保护的属性，其中标签作为一种特殊情况。

Result: 在Criteo和CIFAR-10数据集上进行的实验表明，该方法在审计标签隐私保证方面是有效的。

Conclusion: 这项工作为大规模生产环境中的实际隐私审计开辟了新途径。

Abstract: Differential privacy (DP) auditing is essential for evaluating privacy guarantees in machine learning systems. Existing auditing methods, however, pose a significant challenge for large-scale systems since they require modifying the training dataset -- for instance, by injecting out-of-distribution canaries or removing samples from training. Such interventions on the training data pipeline are resource-intensive and involve considerable engineering overhead. We introduce a novel observational auditing framework that leverages the inherent randomness of data distributions, enabling privacy evaluation without altering the original dataset. Our approach extends privacy auditing beyond traditional membership inference to protected attributes, with labels as a special case, addressing a key gap in existing techniques. We provide theoretical foundations for our method and perform experiments on Criteo and CIFAR-10 datasets that demonstrate its effectiveness in auditing label privacy guarantees. This work opens new avenues for practical privacy auditing in large-scale production environments.

</details>


### [60] [MoE-SpeQ: Speculative Quantized Decoding with Proactive Expert Prefetching and Offloading for Mixture-of-Experts](https://arxiv.org/abs/2511.14102)
*Wenfeng Wang,Jiacheng Liu,Xiaofeng Hou,Xinfeng Xia,Peng Tang,Mingxuan Zhang,Chao Li,Minyi Guo*

Main category: cs.LG

TL;DR: MoE-SpeQ通过推测执行和专家卸载，在内存受限设备上有效加速MoE模型推理，I/O速度提升高达2.34倍。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型推理时巨大的内存需求导致的I/O瓶颈问题，尤其是在单加速器容量不足时。

Method: 提出MoE-SpeQ系统，利用小型设备内草稿模型预测未来tokens所需专家序列，运行时调度器预取专家，将I/O与计算重叠。采用自适应调速器和均摊屋脊线模型动态调整推测策略。

Result: 在内存受限设备上，MoE-SpeQ相较于现有最先进的卸载框架，对于Phi-MoE模型实现了最高2.34倍的加速。

Conclusion: MoE-SpeQ为资源受限环境下管理数据依赖性内存访问提供了一种新颖且原则性的方法，使MoE推理在商用硬件上的可及性更高。

Abstract: The immense memory requirements of state-of-the-art Mixture-of-Experts (MoE) models present a significant challenge for inference, often exceeding the capacity of a single accelerator. While offloading experts to host memory is a common solution, it introduces a severe I/O bottleneck over the PCIe bus, as the data-dependent nature of expert selection places these synchronous transfers directly on the critical path of execution, crippling performance.
  This paper argues that the I/O bottleneck can be overcome by trading a small amount of cheap, on-device computation to hide the immense cost of data movement. We present MoE-SpeQ, a new inference system built on a novel co-design of speculative execution and expert offloading. MoE-SpeQ employs a small, on-device draft model to predict the sequence of required experts for future tokens. This foresight enables a runtime orchestrator to prefetch these experts from host memory, effectively overlapping the expensive I/O with useful computation and hiding the latency from the critical path. To maximize performance, an adaptive governor, guided by an Amortization Roofline Model, dynamically tunes the speculation strategy to the underlying hardware. Our evaluation on memory-constrained devices shows that for the Phi-MoE model, MoE-SpeQ achieves at most 2.34x speedup over the state-of-the-art offloading framework. Our work establishes a new, principled approach for managing data-dependent memory access in resource-limited environments, making MoE inference more accessible on commodity hardware.

</details>


### [61] [Soft-Label Training Preserves Epistemic Uncertainty](https://arxiv.org/abs/2511.14117)
*Agamdeep Singh,Ashish Tiwari,Hosein Hasanbeig,Priyanshu Gupta*

Main category: cs.LG

TL;DR: 这篇论文认为，在存在固有主观性的机器学习任务中，应当将标注分布视为真实情况。研究表明，软标签训练能够保留认知不确定性，并在视觉和自然语言处理任务中取得更好的效果。


<details>
  <summary>Details</summary>
Motivation: 传统的机器学习方法将多样化的人工判断聚合成单一标签，导致模型对模糊数据表达错误的置信度。作者认为这种方法存在认知偏差。

Method: 通过软标签训练，将标注分布视为真实情况，让模型学习重现认知不确定性。

Result: 软标签训练使模型与人类标注之间的KL散度降低了32%，模型熵与标注熵之间的相关性提高了61%，同时保持了与硬标签训练相同的准确性。

Conclusion: 标注分布不应被视为需要消除的噪声信号，而应被视为模型应该学习重现的认知不确定性的忠实表示。

Abstract: Many machine learning tasks involve inherent subjectivity, where annotators naturally provide varied labels. Standard practice collapses these label distributions into single labels, aggregating diverse human judgments into point estimates. We argue that this approach is epistemically misaligned for ambiguous data--the annotation distribution itself should be regarded as the ground truth. Training on collapsed single labels forces models to express false confidence on fundamentally ambiguous cases, creating a misalignment between model certainty and the diversity of human perception. We demonstrate empirically that soft-label training, which treats annotation distributions as ground truth, preserves epistemic uncertainty. Across both vision and NLP tasks, soft-label training achieves 32% lower KL divergence from human annotations and 61% stronger correlation between model and annotation entropy, while matching the accuracy of hard-label training. Our work repositions annotation distributions from noisy signals to be aggregated away, to faithful representations of epistemic uncertainty that models should learn to reproduce.

</details>


### [62] [A Comprehensive Study of Implicit and Explicit Biases in Large Language Models](https://arxiv.org/abs/2511.14153)
*Fatima Kazi,Alex Young,Yash Inani,Setareh Rafatirad*

Main category: cs.LG

TL;DR: 该研究探讨了大型语言模型（LLMs）中存在的偏见，并提出了一个自动偏见识别框架和增强策略，以提升模型在偏见识别和规避方面的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）从其训练数据中继承了显性和隐性偏见，这些偏见可能导致有害的刻板印象和错误信息，因此识别和缓解LLMs中的偏见对于确保公平的输出至关重要。

Method: 该研究使用了StereoSet和CrowSPairs等偏见特定基准来评估BERT和GPT 3.5等生成模型中存在的各种偏见。研究提出了一个自动偏见识别框架，用于识别LLMs中的性别、种族、职业和宗教等社会偏见。该研究采用了双管齐下的方法来检测文本数据中的显性和隐性偏见。此外，研究还通过提示技术和偏见基准数据增强对模型进行了微调，以提升模型性能。

Result: 研究结果表明，微调模型在性别偏见方面表现不佳，但在识别和避免种族偏见方面表现出色。尽管取得了一定的成功，但LLMs通常过度依赖关键词。词袋分析揭示了词汇中隐含的刻板印象。通过增强策略，微调模型在跨数据集测试中表现出良好的适应性，并在隐性偏见基准上的性能提升了高达20%。

Conclusion: 这项研究强调了解决LLMs偏见问题的必要性，并提出了有效的偏见识别框架和增强策略，以提高模型在检测和规避偏见方面的能力。未来的工作应继续关注LLMs偏见的缓解。

Abstract: Large Language Models (LLMs) inherit explicit and implicit biases from their training datasets. Identifying and mitigating biases in LLMs is crucial to ensure fair outputs, as they can perpetuate harmful stereotypes and misinformation. This study highlights the need to address biases in LLMs amid growing generative AI. We studied bias-specific benchmarks such as StereoSet and CrowSPairs to evaluate the existence of various biases in multiple generative models such as BERT and GPT 3.5. We proposed an automated Bias-Identification Framework to recognize various social biases in LLMs such as gender, race, profession, and religion. We adopted a two-pronged approach to detect explicit and implicit biases in text data. Results indicated fine-tuned models struggle with gender biases but excelled at identifying and avoiding racial biases. Our findings illustrated that despite having some success, LLMs often over-relied on keywords. To illuminate the capability of the analyzed LLMs in detecting implicit biases, we employed Bag-of-Words analysis and unveiled indications of implicit stereotyping within the vocabulary. To bolster the model performance, we applied an enhancement strategy involving fine-tuning models using prompting techniques and data augmentation of the bias benchmarks. The fine-tuned models exhibited promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.

</details>


### [63] [Bridging the Gap Between Bayesian Deep Learning and Ensemble Weather Forecasts](https://arxiv.org/abs/2511.14218)
*Xinlei Xiong,Wenbo Hu,Shuxun Zhou,Kaifeng Bi,Lingxi Xie,Ying Liu,Richang Hong,Qi Tian*

Main category: cs.LG

TL;DR: 这篇论文提出了一种混合贝叶斯深度学习框架，用于集合天气预报，它结合了变分推断和物理信息随机扰动方案，以分解预测不确定性为认知不确定性和偶然不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统集合预测系统（EPS）在量化不确定性时计算成本高昂，而贝叶斯深度学习（BDL）提供了一种有前景但独立的方法。本文旨在弥合这两种范式之间的差距，用于集合天气预报。

Method: 本文提出了一种统一的混合贝叶斯深度学习框架，通过变分推断学习认知不确定性，并通过建模流依赖大气动力学的物理信息随机扰动方案学习偶然不确定性。此外，本文还建立了一个统一的理论框架，将贝叶斯深度学习和集合预测系统严格联系起来。

Result: 在40年的ERA5再分析数据集上进行验证，实验结果表明，该方法不仅提高了预测精度，产生了更好校准的不确定性量化，而且与最先进的概率扩散模型相比，计算效率更高。

Conclusion: 本文成功地将贝叶斯深度学习和集合预测系统相结合，提出了一个有效且高效的混合框架，用于集合天气预报，并提供了明确的不确定性分解，为天气预报领域带来了显著的改进。

Abstract: Weather forecasting is fundamentally challenged by the chaotic nature of the atmosphere, necessitating probabilistic approaches to quantify uncertainty. While traditional ensemble prediction (EPS) addresses this through computationally intensive simulations, recent advances in Bayesian Deep Learning (BDL) offer a promising but often disconnected alternative. We bridge these paradigms through a unified hybrid Bayesian Deep Learning framework for ensemble weather forecasting that explicitly decomposes predictive uncertainty into epistemic and aleatoric components, learned via variational inference and a physics-informed stochastic perturbation scheme modeling flow-dependent atmospheric dynamics, respectively. We further establish a unified theoretical framework that rigorously connects BDL and EPS, providing formal theorems that decompose total predictive uncertainty into epistemic and aleatoric components under the hybrid BDL framework. We validate our framework on the large-scale 40-year ERA5 reanalysis dataset (1979-2019) with 0.25° spatial resolution. Experimental results show that our method not only improves forecast accuracy and yields better-calibrated uncertainty quantification but also achieves superior computational efficiency compared to state-of-the-art probabilistic diffusion models. We commit to making our code open-source upon acceptance of this paper.

</details>


### [64] [EBind: a practical approach to space binding](https://arxiv.org/abs/2511.14229)
*Jim Broadbent,Felix Cohen,Frederik Hvilshøj,Eric Landau,Eren Sasoglu*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为 EBind 的方法，通过简化空间绑定并关注单一编码器和高质量数据，从而在单个 GPU 上快速训练出最先进的多模态模型。


<details>
  <summary>Details</summary>
Motivation: 现有的通过绑定空间来提升多模态模型性能的方法训练时间长，需要大量计算资源，并且模型规模庞大。

Method: EBind 方法基于以下核心思想：1) 每个模态使用单一编码器；2) 使用高质量数据。该方法利用了三类精心策划的数据集：1) 670万个全自动多模态五元组数据；2) 100万个多样化、半自动的，由人类标注为负、部分或正匹配的三元组数据；3) 340万个现有的带字幕数据项。

Result: 1. EBind 训练的1.8B参数图像-文本-视频-音频-3D模型，其性能优于比其大4到17倍的模型。 
2. 通过13种不同的评估，证明了每种数据源的价值。 
3. 引入了第一个高质量、共识标注的音频和PC之间的零样本分类基准。

Conclusion: EBind 通过简化空间绑定和侧重高质量数据，有效提高了多模态模型的训练效率和性能。该方法不仅在更小的模型规模上实现了更优的性能，还通过新的基准测试解决了现有评估的局限性。未来将开源代码、模型权重和数据集。

Abstract: We simplify space binding by focusing on two core components, a single encoder per modality and high-quality data; enabling training state-of-the-art models on a single GPU in a few hours as opposed to multiple days. We present EBind, an Easy, data-centric, and parameter-efficient method to Bind the embedding spaces of multiple contrastive models. We demonstrate that a simple 1.8B-parameter image-text-video-audio-3D model can outperform models 4 to 17x the size. The key to achieving this is a carefully curated dataset of three complementary data sources: i) 6.7M fully-automated multimodal quintuples sourced via SOTA retrieval models, ii) 1M diverse, semi-automated triples annotated by humans as negative, partial, or positive matches, and iii) 3.4M pre-existing captioned data items. We use 13 different evaluations to demonstrate the value of each data source. Due to limitations with existing benchmarks, we further introduce the first high-quality, consensus-annotated zero-shot classification benchmark between audio and PCs. In contrast to related work, we will open-source our code, model weights, and datasets.

</details>


### [65] [Unified Multimodal Vessel Trajectory Prediction with Explainable Navigation Intention](https://arxiv.org/abs/2511.14265)
*Rui Zhang,Chao Li,Kezhong Liu,Chen Wang,Bolong Zheng,Hongbo Jiang*

Main category: cs.LG

TL;DR: 本文提出了一种新的多模态船舶轨迹预测框架，该框架通过结合可解释的航行意图来提高预测的适用性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的船舶多模态轨迹预测方法在场景适用性和可解释性方面存在局限性。

Method: 该方法构建了持续意图树，并使用条件变分自编码器（CVAE）建模动态瞬态意图，同时使用非局部注意力机制保持全局场景一致性。

Result: 在真实的AIS数据集上，该方法在ADE和FDE方面都取得了显著改进，并具有广泛的场景适用性。

Conclusion: 该框架通过显式揭示每次预测轨迹背后的航行意图来提高可解释性，并对多模态船舶轨迹预测具有重要意义。

Abstract: Vessel trajectory prediction is fundamental to intelligent maritime systems. Within this domain, short-term prediction of rapid behavioral changes in complex maritime environments has established multimodal trajectory prediction (MTP) as a promising research area. However, existing vessel MTP methods suffer from limited scenario applicability and insufficient explainability. To address these challenges, we propose a unified MTP framework incorporating explainable navigation intentions, which we classify into sustained and transient categories. Our method constructs sustained intention trees from historical trajectories and models dynamic transient intentions using a Conditional Variational Autoencoder (CVAE), while using a non-local attention mechanism to maintain global scenario consistency. Experiments on real Automatic Identification System (AIS) datasets demonstrates our method's broad applicability across diverse scenarios, achieving significant improvements in both ADE and FDE. Furthermore, our method improves explainability by explicitly revealing the navigational intentions underlying each predicted trajectory.

</details>


### [66] [H-LDM: Hierarchical Latent Diffusion Models for Controllable and Interpretable PCG Synthesis from Clinical Metadata](https://arxiv.org/abs/2511.14312)
*Chenyang Xu,Siming Li,Hao Wang*

Main category: cs.LG

TL;DR: H-LDM（分层潜在扩散模型）能够根据结构化元数据生成临床准确且可控的心音图（PCG）信号，有效缓解了标记病理数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 心音图（PCG）分析对于心血管疾病诊断至关重要，但标记过的病理数据稀缺，这限制了人工智能系统的能力。

Method: 我们引入了H-LDM，一个分层潜在扩散模型，用于从结构化元数据生成临床准确且可控的PCG信号。我们的方法具有：(1) 一个多尺度变分自编码器（VAE），它学习一个生理学上解耦的潜在空间，分离心律、心音和杂音；(2) 一个分层文本到生物信号的管道，利用丰富的临床元数据对17种不同病症进行细粒度控制；(3) 一个由新型医学注意力模块引导的可解释扩散过程。

Result: 在PhysioNet CirCor数据集上的实验表明，H-LDM实现了最先进的性能，达到9.7的Fréchet音频距离，92%的属性解耦分数，以及87.1%的临床有效性（经心脏病专家确认）。使用我们的合成数据增强诊断模型，将罕见疾病分类的准确性提高了11.3%。

Conclusion: H-LDM为心脏诊断中的数据增强开辟了新方向，弥合了数据稀缺与可解释临床洞察之间的鸿沟。

Abstract: Phonocardiogram (PCG) analysis is vital for cardiovascular disease diagnosis, yet the scarcity of labeled pathological data hinders the capability of AI systems. To bridge this, we introduce H-LDM, a Hierarchical Latent Diffusion Model for generating clinically accurate and controllable PCG signals from structured metadata. Our approach features: (1) a multi-scale VAE that learns a physiologically-disentangled latent space, separating rhythm, heart sounds, and murmurs; (2) a hierarchical text-to-biosignal pipeline that leverages rich clinical metadata for fine-grained control over 17 distinct conditions; and (3) an interpretable diffusion process guided by a novel Medical Attention module. Experiments on the PhysioNet CirCor dataset demonstrate state-of-the-art performance, achieving a Fréchet Audio Distance of 9.7, a 92% attribute disentanglement score, and 87.1% clinical validity confirmed by cardiologists. Augmenting diagnostic models with our synthetic data improves the accuracy of rare disease classification by 11.3\%. H-LDM establishes a new direction for data augmentation in cardiac diagnostics, bridging data scarcity with interpretable clinical insights.

</details>


### [67] [Intervention Efficiency and Perturbation Validation Framework: Capacity-Aware and Robust Clinical Model Selection under the Rashomon Effect](https://arxiv.org/abs/2511.14317)
*Yuwen Zhang,Viet Tran,Paul Weng*

Main category: cs.LG

TL;DR: 该文章针对临床机器学习中“Rashomon效应”导致的模型部署和评估挑战，提出了Intervention Efficiency (IE)和Perturbation Validation Framework (PVF)两个方法。


<details>
  <summary>Details</summary>
Motivation: 文章指出，在临床机器学习中，由于小型、不平衡和噪声数据以及高维特征，导致了多个性能相似的模型并存（Rashomon效应），使得可信赖的部署和评估面临挑战。传统的验证方法在这种情况下变得不可靠，模型的选择也因此不确定，特别是当模型评估指标（如F1分数）未考虑资源限制和操作优先级时。

Method: 本文提出了两种互补的工具来解决这些问题：
1. Intervention Efficiency (IE)：一个衡量模型在有限干预能力下识别可操作真阳性效率的指标，将预测性能与临床实用性结合起来。
2. Perturbation Validation Framework (PVF)：一个评估模型在数据扰动下稳定性的结构化方法，用于识别在噪声或偏移验证集下性能最不变的模型。

Result: 在合成和真实医疗数据集上的实证结果表明，使用IE和PVF有助于选择泛化能力更强、更符合容量限制的模型。

Conclusion: 通过引入IE和PVF，为解决临床环境中“Rashomon效应”带来的挑战提供了新的方向，能够选出更稳健并符合实际约束的模型。

Abstract: In clinical machine learning, the coexistence of multiple models with comparable performance -- a manifestation of the Rashomon Effect -- poses fundamental challenges for trustworthy deployment and evaluation. Small, imbalanced, and noisy datasets, coupled with high-dimensional and weakly identified clinical features, amplify this multiplicity and make conventional validation schemes unreliable. As a result, selecting among equally performing models becomes uncertain, particularly when resource constraints and operational priorities are not considered by conventional metrics like F1 score. To address these issues, we propose two complementary tools for robust model assessment and selection: Intervention Efficiency (IE) and the Perturbation Validation Framework (PVF). IE is a capacity-aware metric that quantifies how efficiently a model identifies actionable true positives when only limited interventions are feasible, thereby linking predictive performance with clinical utility. PVF introduces a structured approach to assess the stability of models under data perturbations, identifying models whose performance remains most invariant across noisy or shifted validation sets. Empirical results on synthetic and real-world healthcare datasets show that using these tools facilitates the selection of models that generalize more robustly and align with capacity constraints, offering a new direction for tackling the Rashomon Effect in clinical settings.

</details>


### [68] [Learning with Statistical Equality Constraints](https://arxiv.org/abs/2511.14320)
*Aneesh Barthakur,Luiz F. O. Chamon*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的通用理论和算法，用于解决机器学习中带有等式约束的问题，解决了以前方法在公平性和边界值问题上的局限性。


<details>
  <summary>Details</summary>
Motivation: 机器学习应用日益复杂，除了准确性之外，还需要满足更多的要求。现有的方法通过将要求违反惩罚的加权组合纳入训练目标来处理这些挑战，但这需要仔细调整超参数，并且在要求涉及奇偶性或等式时会变得无效。交替技术使用约束优化来解决这些学习问题，但现有的近似和泛化保证不适用于涉及等式约束的问题。

Method: 我们推导了一个等式约束统计学习问题的泛化理论，表明它们的解决方案可以使用样本和丰富的参数化来近似。基于这些结果，我们提出了一种实用的算法，该算法基于解决一系列无约束的经验学习问题。

Result: 所提出的算法在公平学习、插值分类器和边界值问题中显示出其有效性和等式约束所带来的新公式。

Conclusion: 该工作为等式约束统计学习问题推导了泛化理论，并提出了一种实用的算法，能够有效解决公平学习、插值分类器和边界值问题中的等式约束。

Abstract: As machine learning applications grow increasingly ubiquitous and complex, they face an increasing set of requirements beyond accuracy. The prevalent approach to handle this challenge is to aggregate a weighted combination of requirement violation penalties into the training objective. To be effective, this approach requires careful tuning of these hyperparameters (weights), involving trial-and-error and cross-validation, which becomes ineffective even for a moderate number of requirements. These issues are exacerbated when the requirements involve parities or equalities, as is the case in fairness and boundary value problems. An alternative technique uses constrained optimization to formulate these learning problems. Yet, existing approximation and generalization guarantees do not apply to problems involving equality constraints. In this work, we derive a generalization theory for equality-constrained statistical learning problems, showing that their solutions can be approximated using samples and rich parametrizations. Using these results, we propose a practical algorithm based on solving a sequence of unconstrained, empirical learning problems. We showcase its effectiveness and the new formulations enabled by equality constraints in fair learning, interpolating classifiers, and boundary value problems.

</details>


### [69] [Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation](https://arxiv.org/abs/2511.14406)
*Bastien Vuillod,Pierre-Alain Moellic,Jean-Max Dutertre*

Main category: cs.LG

TL;DR: 本文探讨了联邦学习（FL）中，参数高效微调技术（如LoRA）对模型适应性后门攻击的影响，发现较低的LoRA秩可以使后门持续更长时间。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中模型适应性面临的完整性安全威胁，特别是后门攻击，并分析LoRA对后门攻击的影响。

Method: 首次分析了LoRA对针对联邦学习中模型适应性的最先进后门攻击的影响，重点关注后门寿命，并进行了实验。

Result: 一个关键发现是，在最优注入后门的情况下，LoRA的秩越低，攻击后后门的持久性越长。

Conclusion: LoRA的秩会影响后门在联邦学习中的持久性，这对于设计更健壮和公平的后门攻击评估方法至关重要，从而提高关键联邦学习系统风险评估的可靠性。

Abstract: Large models adaptation through Federated Learning (FL) addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats, particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local training steps of certain clients. We present the first analysis of the influence of LoRA on state-of-the-art backdoor attacks targeting model adaptation in FL. Specifically, we focus on backdoor lifespan, a critical characteristic in FL, that can vary depending on the attack scenario and the attacker's ability to effectively inject the backdoor. A key finding in our experiments is that for an optimally injected backdoor, the backdoor persistence after the attack is longer when the LoRA's rank is lower. Importantly, our work highlights evaluation issues of backdoor attacks against FL and contributes to the development of more robust and fair evaluations of backdoor attacks, enhancing the reliability of risk assessments for critical FL systems. Our code is publicly available.

</details>


### [70] [Toward Robust and Harmonious Adaptation for Cross-modal Retrieval](https://arxiv.org/abs/2511.14416)
*Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为REST的新方法，旨在解决跨模态检索（CMR）中普遍存在的查询偏移（QS）问题。


<details>
  <summary>Details</summary>
Motivation: 现有的通用到定制的跨模态检索方法无法处理在线和多样化的查询偏移问题，这导致了共同空间的破坏和通用知识的遗忘。

Method: REST方法通过两阶段策略解决QS问题。首先，为了应对在线偏移，它优化检索结果以形成查询预测，并设计了一个QS鲁棒的目标函数来在线维护公共空间。其次，为了解决更具挑战性的多样化偏移，REST采用梯度解耦模块来控制梯度，从而防止CMR模型遗忘通用知识。

Result: 在20个基准测试中进行的大量实验验证了所提出的REST方法在解决QS问题方面的有效性。

Conclusion: REST方法通过在线和谐适应策略，有效地解决了跨模态检索中的查询偏移问题，既保护了共同空间又保留了通用知识。

Abstract: Recently, the general-to-customized paradigm has emerged as the dominant approach for Cross-Modal Retrieval (CMR), which reconciles the distribution shift problem between the source domain and the target domain. However, existing general-to-customized CMR methods typically assume that the entire target-domain data is available, which is easily violated in real-world scenarios and thus inevitably suffer from the query shift (QS) problem. Specifically, query shift embraces the following two characteristics and thus poses new challenges to CMR. i) Online Shift: real-world queries always arrive in an online manner, rendering it impractical to access the entire query set beforehand for customization approaches; ii) Diverse Shift: even with domain customization, the CMR models struggle to satisfy queries from diverse users or scenarios, leaving an urgent need to accommodate diverse queries. In this paper, we observe that QS would not only undermine the well-structured common space inherited from the source model, but also steer the model toward forgetting the indispensable general knowledge for CMR. Inspired by the observations, we propose a novel method for achieving online and harmonious adaptation against QS, dubbed Robust adaptation with quEry ShifT (REST). To deal with online shift, REST first refines the retrieval results to formulate the query predictions and accordingly designs a QS-robust objective function on these predictions to preserve the well-established common space in an online manner. As for tackling the more challenging diverse shift, REST employs a gradient decoupling module to dexterously manipulate the gradients during the adaptation process, thus preventing the CMR model from forgetting the general knowledge. Extensive experiments on 20 benchmarks across three CMR tasks verify the effectiveness of our method against QS.

</details>


### [71] [FlowRoI A Fast Optical Flow Driven Region of Interest Extraction Framework for High-Throughput Image Compression in Immune Cell Migration Analysis](https://arxiv.org/abs/2511.14419)
*Xiaowei Xu,Justin Sonneck,Hongxiao Wang,Roman Burkard,Hendrik Wohrle,Anton Grabmasier,Matthias Gunzer,Jianxu Chen*

Main category: cs.LG

TL;DR: FlowRoI是一种基于光流的感兴趣区域（RoI）提取框架，专为高通量免疫细胞迁移研究中的图像压缩而设计。它通过估计连续帧之间的光流来生成RoI掩模，然后使用JPEG2000对原始图像和掩模进行联合编码，从而实现在保证图像质量的同时，显着提高压缩率。


<details>
  <summary>Details</summary>
Motivation: 解决高通量成像平台（如ComplexEye）在免疫细胞迁移研究中产生数据量过大，对存储和传输造成巨大负担的问题。

Method: FlowRoI通过以下步骤实现： 1. 估计连续帧之间的光流。 2. 从光流中提取可靠覆盖迁移细胞的感兴趣区域（RoI）掩模。 3. 使用JPEG2000对原始图像和相应的RoI掩模进行联合编码，实现RoI感知的压缩。

Result: 1. 计算效率高：运行时间与标准JPEG2000相当，在配备Intel i7-1255U CPU的现代笔记本电脑上，平均吞吐量达到约30帧/秒。 2. 图像质量好：在细胞区域产生更高的峰值信噪比（PSNR）。 3. 压缩率高：在相同PSNR下，与标准JPEG2000相比，压缩率提高2.0-2.2倍。

Conclusion: FlowRoI提供了一种高效且高质量的解决方案，用于解决高通量免疫细胞迁移成像数据存储和传输的挑战，具有实际应用前景。

Abstract: Autonomous migration is essential for the function of immune cells such as neutrophils and plays a pivotal role in diverse diseases. Recently, we introduced ComplexEye, a multi-lens array microscope comprising 16 independent aberration-corrected glass lenses arranged at the pitch of a 96-well plate, capable of capturing high-resolution movies of migrating cells. This architecture enables high-throughput live-cell video microscopy for migration analysis, supporting routine quantification of autonomous motility with strong potential for clinical translation. However, ComplexEye and similar high-throughput imaging platforms generate data at an exponential rate, imposing substantial burdens on storage and transmission. To address this challenge, we present FlowRoI, a fast optical-flow-based region of interest (RoI) extraction framework designed for high-throughput image compression in immune cell migration studies. FlowRoI estimates optical flow between consecutive frames and derives RoI masks that reliably cover nearly all migrating cells. The raw image and its corresponding RoI mask are then jointly encoded using JPEG2000 to enable RoI-aware compression. FlowRoI operates with high computational efficiency, achieving runtimes comparable to standard JPEG2000 and reaching an average throughput of about 30 frames per second on a modern laptop equipped with an Intel i7-1255U CPU. In terms of image quality, FlowRoI yields higher peak signal-to-noise ratio (PSNR) in cellular regions and achieves 2.0-2.2x higher compression rates at matched PSNR compared to standard JPEG2000.

</details>


### [72] [MiAD: Mirage Atom Diffusion for De Novo Crystal Generation](https://arxiv.org/abs/2511.14426)
*Andrey Okhotin,Maksim Nakhodnov,Nikita Kazeev,Andrey E Ustyuzhanin,Dmitry Vetrov*

Main category: cs.LG

TL;DR: 介绍了MiAD模型，一种能够改变晶体中原子数量的扩散模型，提高了S.U.N.晶体材料的生成质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在生成晶体材料时无法改变原子数量，限制了模型采样轨迹的多样性。

Method: 提出了“幻影注入”（mirage infusion）技术，使扩散模型能够在生成过程中改变晶体中原子的存在状态，从而改变原子数量。

Result: MiAD模型将模型质量提高了2.5倍，并在MP-20数据集上实现了8.2%的S.U.N.率，超过了现有最先进的方法。

Conclusion: 幻影注入技术有效解决了扩散模型在晶体生成过程中原子数量不可变的问题，显著提升了生成S.U.N.晶体材料的性能。

Abstract: In recent years, diffusion-based models have demonstrated exceptional performance in searching for simultaneously stable, unique, and novel (S.U.N.) crystalline materials. However, most of these models don't have the ability to change the number of atoms in the crystal during the generation process, which limits the variability of model sampling trajectories. In this paper, we demonstrate the severity of this restriction and introduce a simple yet powerful technique, mirage infusion, which enables diffusion models to change the state of the atoms that make up the crystal from existent to non-existent (mirage) and vice versa. We show that this technique improves model quality by up to $\times2.5$ compared to the same model without this modification. The resulting model, Mirage Atom Diffusion (MiAD), is an equivariant joint diffusion model for de novo crystal generation that is capable of altering the number of atoms during the generation process. MiAD achieves an $8.2\%$ S.U.N. rate on the MP-20 dataset, which substantially exceeds existing state-of-the-art approaches. The source code can be found at \href{https://github.com/andrey-okhotin/miad.git}{\texttt{github.com/andrey-okhotin/miad}}.

</details>


### [73] [Hybrid Modeling of Photoplethysmography for Non-invasive Monitoring of Cardiovascular Parameters](https://arxiv.org/abs/2511.14452)
*Emanuele Palumbo,Sorawit Saengkyongam,Maria R. Cervera,Jens Behrmann,Andrew C. Miller,Guillermo Sapiro,Christina Heinze-Deml,Antoine Wehenkel*

Main category: cs.LG

TL;DR: 该文章提出了一种混合方法，利用血流动力学模拟和未标记的临床数据，直接从PPG信号中估计心血管生物标志物。


<details>
  <summary>Details</summary>
Motivation: 中风量和心输出量等心脏生物标志物需要侵入性测量，而PPG提供了一种非侵入性的替代方案，但从PPG预测这些生物标志物是一个开放的挑战，并且带注释的PPG测量数据稀缺。

Method: 该方法结合了在成对PPG-APW数据上训练的条件变分自动编码器，以及在标记的模拟APW片段上训练的心脏生物标志物条件密度估计器。

Result: 实验证明，该方法可以检测心输出量和中风量的波动，并且在监测这些生物标志物的时间变化方面优于有监督的基线。

Conclusion: 该研究提出了一种混合模型，可以从PPG信号中估计心血管生物标志物，克服了侵入性测量的局限性和带注释PPG数据稀缺的挑战。

Abstract: Continuous cardiovascular monitoring can play a key role in precision health. However, some fundamental cardiac biomarkers of interest, including stroke volume and cardiac output, require invasive measurements, e.g., arterial pressure waveforms (APW). As a non-invasive alternative, photoplethysmography (PPG) measurements are routinely collected in hospital settings. Unfortunately, the prediction of key cardiac biomarkers from PPG instead of APW remains an open challenge, further complicated by the scarcity of annotated PPG measurements. As a solution, we propose a hybrid approach that uses hemodynamic simulations and unlabeled clinical data to estimate cardiovascular biomarkers directly from PPG signals. Our hybrid model combines a conditional variational autoencoder trained on paired PPG-APW data with a conditional density estimator of cardiac biomarkers trained on labeled simulated APW segments. As a key result, our experiments demonstrate that the proposed approach can detect fluctuations of cardiac output and stroke volume and outperform a supervised baseline in monitoring temporal changes in these biomarkers.

</details>


### [74] [nnterp: A Standardized Interface for Mechanistic Interpretability of Transformers](https://arxiv.org/abs/2511.14465)
*Clément Dumas*

Main category: cs.LG

TL;DR: nnterp是一个轻量级库，它为HuggingFace模型提供统一的接口，以实现可解释性研究，从而在使用原始模型实现的同时提供跨各种架构的标准化。


<details>
  <summary>Details</summary>
Motivation: 现有的机械可解释性研究工具在接口一致性和保留原始模型行为之间存在矛盾。自定义实现通常需要针对每个新架构进行手动调整，这可能导致数值不匹配，而直接访问HuggingFace虽然保留了精确的行为，但缺乏标准化。

Method: nnterp通过作为NNsight的轻量级包装器来解决这个问题。它通过自动模块重命名实现跨不同变压器架构的统一接口，并维护HuggingFace的原始实现以确保行为的准确性。

Result: nnterp允许研究人员编写一次干预代码，并将其部署到涵盖16个架构系列的50多种模型变体中。它包括常见可解释性方法的内置实现，如logit lens、patchscope和激活 steering，并提供对注意力概率的直接访问。

Conclusion: nnterp通过提供一个既能确保跨不同Transformer架构的分析工具的正确性又能保证其可用性的统一接口，弥合了机械可解释性工具中的差距。

Abstract: Mechanistic interpretability research requires reliable tools for analyzing transformer internals across diverse architectures. Current approaches face a fundamental tradeoff: custom implementations like TransformerLens ensure consistent interfaces but require coding a manual adaptation for each architecture, introducing numerical mismatch with the original models, while direct HuggingFace access through NNsight preserves exact behavior but lacks standardization across models. To bridge this gap, we develop nnterp, a lightweight wrapper around NNsight that provides a unified interface for transformer analysis while preserving original HuggingFace implementations. Through automatic module renaming and comprehensive validation testing, nnterp enables researchers to write intervention code once and deploy it across 50+ model variants spanning 16 architecture families. The library includes built-in implementations of common interpretability methods (logit lens, patchscope, activation steering) and provides direct access to attention probabilities for models that support it. By packaging validation tests with the library, researchers can verify compatibility with custom models locally. nnterp bridges the gap between correctness and usability in mechanistic interpretability tooling.

</details>


### [75] [Notes on Kernel Methods in Machine Learning](https://arxiv.org/abs/2511.14485)
*Diego Armando Pérez-Rosero,Danna Valentina Salazar-Dubois,Juan Camilo Lugo-Rojas,Andrés Marino Álvarez-Meza,Germán Castellanos-Dominguez*

Main category: cs.LG

TL;DR: 这篇论文介绍了机器学习中核方法及其几何基础。


<details>
  <summary>Details</summary>
Motivation: 探索核方法在机器学习中的应用，特别是其在统计估计和概率测度表示中的作用，并为更高级主题奠定基础。

Method: 从希尔伯特空间的构建开始，逐步发展正定核、再生核希尔伯特空间（RKHS）和希尔伯特-施密特算子的理论。通过希尔伯特空间几何的视角重新审视了协方差、回归和信息度量等经典概念。引入了核密度估计、分布的核嵌入以及最大均值差异（MMD）。

Result: 在机器学习中建立了一套完整的核方法理论框架，涵盖从基础概念到高级应用的过渡。

Conclusion: 核方法提供了一种强大的工具，能够统一和扩展机器学习中的多种概念和技术，为统计估计和概率测度表示提供了坚实的几何基础。

Abstract: These notes provide a self-contained introduction to kernel methods and their geometric foundations in machine learning. Starting from the construction of Hilbert spaces, we develop the theory of positive definite kernels, reproducing kernel Hilbert spaces (RKHS), and Hilbert-Schmidt operators, emphasizing their role in statistical estimation and representation of probability measures. Classical concepts such as covariance, regression, and information measures are revisited through the lens of Hilbert space geometry. We also introduce kernel density estimation, kernel embeddings of distributions, and the Maximum Mean Discrepancy (MMD). The exposition is designed to serve as a foundation for more advanced topics, including Gaussian processes, kernel Bayesian inference, and functional analytic approaches to modern machine learning.

</details>


### [76] [Towards Stable and Structured Time Series Generation with Perturbation-Aware Flow Matching](https://arxiv.org/abs/2511.14488)
*Jintao Zhang,Mingyue Cheng,Zirui Liu,Xianquan Wang,Yitong Zhou,Qi Liu*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为PAFM的扰动感知流匹配框架，用于生成结构一致的时间序列，解决了现有流匹配模型在处理受扰动时间序列时捕捉突变能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 时间序列生成对于下游分析和决策任务至关重要，但局部扰动引起的固有时间异质性给生成结构一致的时间序列带来了挑战。现有的流匹配方法在捕捉受扰动时间序列中的突变时表现不佳，因为其全局共享参数限制了速度场的统一表示。

Method: PAFM框架通过扰动引导训练来模拟局部扰动。它利用双路径速度场来捕捉扰动下的轨迹偏差，从而增强结构一致性。此外，PAFM还采用了一个带有流路由的专家混合解码器，以根据不同的轨迹动态分配建模能力，从而提高对轨迹扰动的敏感性和表达能力。

Result: 在无条件和有条件生成任务上的大量实验表明，PAFM始终优于现有的强大基线模型。

Conclusion: PAFM框架通过引入扰动感知机制和专家混合解码器，有效解决了时间序列生成中局部扰动带来的挑战，显著提升了生成时间序列的结构一致性和鲁棒性。

Abstract: Time series generation is critical for a wide range of applications, which greatly supports downstream analytical and decision-making tasks. However, the inherent temporal heterogeneous induced by localized perturbations present significant challenges for generating structurally consistent time series. While flow matching provides a promising paradigm by modeling temporal dynamics through trajectory-level supervision, it fails to adequately capture abrupt transitions in perturbed time series, as the use of globally shared parameters constrains the velocity field to a unified representation. To address these limitations, we introduce \textbf{PAFM}, a \textbf{P}erturbation-\textbf{A}ware \textbf{F}low \textbf{M}atching framework that models perturbed trajectories to ensure stable and structurally consistent time series generation. The framework incorporates perturbation-guided training to simulate localized disturbances and leverages a dual-path velocity field to capture trajectory deviations under perturbation, enabling refined modeling of perturbed behavior to enhance the structural coherence. In order to further improve sensitivity to trajectory perturbations while enhancing expressiveness, a mixture-of-experts decoder with flow routing dynamically allocates modeling capacity in response to different trajectory dynamics. Extensive experiments on both unconditional and conditional generation tasks demonstrate that PAFM consistently outperforms strong baselines. Code is available at https://anonymous.4open.science/r/PAFM-03B2.

</details>


### [77] [CLO: Efficient LLM Inference System with CPU-Light KVCache Offloading via Algorithm-System Co-Design](https://arxiv.org/abs/2511.14510)
*Jiawei Yi,Ping Gong,Youhui Bai,Jiaqi Ruan,Shengnan Wang,Pengcheng Wang,Haibo Wang,Weiguang Wang,Xia Zhu,Feng Wu,Cheng Li*

Main category: cs.LG

TL;DR: CLO是一种CPU轻量级KVCache卸载系统，它通过算法与系统协同设计，解决了现有系统中CPU瓶颈问题，从而在保证精度的前提下，显著提升了解码吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理系统在处理长序列时，KVCache的内存占用和数据传输开销成为瓶颈。尽管有offloading系统将KVCache迁移到CPU内存并采用top-k注意力机制，但它们忽视了CPU在动态缓存管理、PCIe带宽利用和GPU同步方面的瓶颈。

Method: CLO通过算法与系统协同设计来解决现有offloading系统中的CPU瓶颈。它主要包含三个特点：1. 粗粒度的head-wise近似片上GPU缓存策略，大大降低了缓存管理开销。2. 无缝结合数据预取和片上GPU持久缓存，以降低传输开销。3. 零拷贝传输引擎以充分利用PCIe带宽，以及以GPU为中心的同步方法以消除GPU停顿。

Result: 在两个主流LLM上的评估表明，CLO在保持与SOTA系统相当的精度的同时，显著降低了CPU开销，充分利用了PCIe带宽，从而将解码吞吐量提高了9.3%-66.6%。

Conclusion: 算法与系统协同设计对于在现代GPU平台上进行内存受限的LLM推理至关重要。

Abstract: The growth of million-token LLMs exposes the scalability limits of inference systems, where the KVCache dominates memory usage and data transfer overhead. Recent offloading systems migrate the KVCache to CPU memory and incorporate top-k attention to reduce the volume of data transferred from the CPU, while further applying system-level optimizations such as on-GPU caching and prefetching to lower transfer overhead. However, they overlook the CPU bottleneck in three aspects: (1) substantial overhead of fine-grained dynamic cache management performed on the CPU side, (2) significant transfer overhead from poor PCIe bandwidth utilization caused by heavy gathering operations at the CPU side, and (3) GPU runtime bubbles introduced by coarse-grained CPU-centric synchronization. To address these challenges, we propose CLO, a CPU-light KVCache offloading system via algorithm-system co-design. CLO features: (1) a coarse-grained head-wise approximate on-GPU caching strategy with negligible cache management cost, (2) seamless combination of data prefetching and on-GPU persistent caching for lower transfer overhead, (3) a zero-copy transfer engine to fully exploit PCIe bandwidth, and a GPU-centric synchronization method to eliminate GPU stalls. Evaluation on two widely-used LLMs demonstrates that CLO achieves comparable accuracy to state-of-the-art systems, while substantially minimizing CPU overhead, fully utilizing PCIe bandwidth, thus improving decoding throughput by 9.3%-66.6%. Our results highlight that algorithm-system co-design is essential for memory-constrained LLM inference on modern GPU platforms. We open source CLO at https://github.com/CommediaJW/CLO.

</details>


### [78] [MissHDD: Hybrid Deterministic Diffusion for Hetrogeneous Incomplete Data Imputation](https://arxiv.org/abs/2511.14543)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: 该文章提出了一种混合确定性扩散框架，用于处理实际表格数据中常见的异构不完整数据。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在处理混合类型表格数据时存在局限性，特别是在保持条件一致性、处理分类变量的信息崩溃以及数值变量更新的不稳定性方面。

Method: 提出了一种混合确定性扩散框架，该框架将异构特征分为两个互补的生成通道：一个基于DDIM的连续通道用于数值变量的确定性去噪，另一个离散潜在路径扩散通道用于分类和离散特征的建模。这两个通道在统一的条件归因目标下进行训练。

Result: 在多个真实世界数据集上的广泛实验表明，该框架比现有方法具有更高的归因精度、更稳定的采样轨迹和更好的鲁棒性。

Conclusion: 结构感知扩散过程对于推动深度学习方法处理不完整表格数据至关重要。

Abstract: Incomplete data are common in real-world tabular applications, where numerical, categorical, and discrete attributes coexist within a single dataset. This heterogeneous structure presents significant challenges for existing diffusion-based imputation models, which typically assume a homogeneous feature space and rely on stochastic denoising trajectories. Such assumptions make it difficult to maintain conditional consistency, and they often lead to information collapse for categorical variables or instability when numerical variables require deterministic updates. These limitations indicate that a single diffusion process is insufficient for mixed-type tabular imputation.
  We propose a hybrid deterministic diffusion framework that separates heterogeneous features into two complementary generative channels. A continuous DDIM-based channel provides efficient and stable deterministic denoising for numerical variables, while a discrete latent-path diffusion channel, inspired by loopholing-based discrete diffusion, models categorical and discrete features without leaving their valid sample manifolds. The two channels are trained under a unified conditional imputation objective, enabling coherent reconstruction of mixed-type incomplete data.
  Extensive experiments on multiple real-world datasets show that the proposed framework achieves higher imputation accuracy, more stable sampling trajectories, and improved robustness across MCAR, MAR, and MNAR settings compared with existing diffusion-based and classical methods. These results demonstrate the importance of structure-aware diffusion processes for advancing deep learning approaches to incomplete tabular data.

</details>


### [79] [Mind the Gaps: Measuring Visual Artifacts in Dimensionality Reduction](https://arxiv.org/abs/2511.14544)
*Jaume Ros,Alessio Arleo,Fernando Paulovich*

Main category: cs.LG

TL;DR: 本文介绍了一种新的降维投影质量度量指标——Warping Index (WI)，用于评估二维平面降维投影的质量，主要关注投影中空区域的保存。


<details>
  <summary>Details</summary>
Motivation: 现有的降维（DR）技术在将高维数据投影到二维平面时会产生失真，而现有的投影质量度量（PQMs）大多只关注全局或局部结构，忽略了可能误导视觉分析的视觉失真、异常值或伪影。

Method: 本文提出了一种新的度量指标Warping Index (WI)，用于衡量降维投影到二维平面的质量。该方法基于一个假设：正确保存点之间的空区域对于数据的忠实视觉表示至关重要。

Result: 本文介绍了Warping Index (WI) 这项工作，其结果是一个新的投影质量度量指标。

Conclusion: Warping Index (WI) 通过关注投影中空区域的保存，提供了一种新的方法来评估降维投影的质量，以避免视觉失真带来的误导。

Abstract: Dimensionality Reduction (DR) techniques are commonly used for the visual exploration and analysis of high-dimensional data due to their ability to project datasets of high-dimensional points onto the 2D plane. However, projecting datasets in lower dimensions often entails some distortion, which is not necessarily easy to recognize but can lead users to misleading conclusions. Several Projection Quality Metrics (PQMs) have been developed as tools to quantify the goodness-of-fit of a DR projection; however, they mostly focus on measuring how well the projection captures the global or local structure of the data, without taking into account the visual distortion of the resulting plots, thus often ignoring the presence of outliers or artifacts that can mislead a visual analysis of the projection. In this work, we introduce the Warping Index (WI), a new metric for measuring the quality of DR projections onto the 2D plane, based on the assumption that the correct preservation of empty regions between points is of crucial importance towards a faithful visual representation of the data.

</details>


### [80] [Task Addition and Weight Disentanglement in Closed-Vocabulary Models](https://arxiv.org/abs/2511.14569)
*Adam Hazimeh,Alessandro Favero,Pascal Frossard*

Main category: cs.LG

TL;DR: 本文探讨了任务算术在闭词汇图像分类模型中的应用，发现权重解耦是预训练的普遍结果，即使是闭词汇视觉Transformer也能通过任务算术进行编辑。


<details>
  <summary>Details</summary>
Motivation: 任务算术为编辑预训练的开放词汇模型提供了一种经济高效的替代方案，但尚未应用于闭词汇模型，因此探索其在闭词汇模型中的应用。

Method: 部署和研究闭词汇图像分类模型中的任务加法，考虑不同的预训练方案，并与线性探测基线进行比较。

Result: 权重解耦是预训练的普遍结果，这使得可以通过任务算术编辑闭词汇视觉Transformer，实现高任务加法性能，并能够高效部署多任务模型。线性探测是一个有竞争力的任务加法基线。

Conclusion: 任务算术的适用性可以扩展到更广泛的预训练模型，这为在不同设置中更有效地使用预训练模型提供了可能性。

Abstract: Task arithmetic has recently emerged as a promising method for editing pre-trained \textit{open-vocabulary} models, offering a cost-effective alternative to standard multi-task fine-tuning. However, despite the abundance of \textit{closed-vocabulary} models that are not pre-trained with language supervision, applying task arithmetic to these models remains unexplored. In this paper, we deploy and study task addition in closed-vocabulary image classification models. We consider different pre-training schemes and find that \textit{weight disentanglement} -- the property enabling task arithmetic -- is a general consequence of pre-training, as it appears in different pre-trained closed-vocabulary models. In fact, we find that pre-trained closed-vocabulary vision transformers can also be edited with task arithmetic, achieving high task addition performance and enabling the efficient deployment of multi-task models. Finally, we demonstrate that simple linear probing is a competitive baseline to task addition. Overall, our findings expand the applicability of task arithmetic to a broader class of pre-trained models and open the way for more efficient use of pre-trained models in diverse settings.

</details>


### [81] [ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents](https://arxiv.org/abs/2511.14584)
*Ankush Kadu,Ashwanth Krishnan*

Main category: cs.LG

TL;DR: ReflexGrad统一了三种互补机制，克服了在强化学习中，让智能体从经验中学习并在没有任务特定训练的情况下泛化到不同任务的挑战。


<details>
  <summary>Details</summary>
Motivation: 作者希望通过一种新的架构来解决强化学习和决策制定领域中，智能体从经验中学习并泛化到不同任务的根本性挑战。

Method: ReflexGrad架构紧密结合了LLM（大型语言模型）的分层TODO分解、历史感知因果反思以及基于梯度的优化。

Result: 在ALFWorld基准任务上，ReflexGrad在没有先验任务经验或演示的情况下，在试验0中实现了67%的零样本成功率。

Conclusion: 互补学习机制的协同整合能够实现稳健的零样本泛化，这种泛化能力接近于先前工作中少样本基线的性能。

Abstract: Enabling agents to learn from experience and generalize across diverse tasks without task-specific training remains a fundamental challenge in reinforcement learning and decision-making. While recent approaches have explored episodic memory (Reflexion), gradient-based prompt optimization (TextGrad),and hierarchical task decomposition independently, their potential for synergistic integration remains unexplored. We introduce ReflexGrad, a novel architecture that tightly couples three complementary mechanisms: (1) LLM-based hierarchical TODO decomposition for strategic planning, (2) history-aware causal reflection that analyzes recent action patterns to identify failure root causes and enable within-trial learning, and (3) gradient-based optimization for systematic improvement. Unlike prior work relying on few-shot demonstrations, our system achieves true zero-shot generalization through pure LLM semantic reasoning,requiring no task-specific examples, fine-tuning, or hardcoded similarity metrics. Evaluated on ALFWorld benchmark tasks, ReflexGrad demonstrates 67% zero-shot success rate on Trial 0 without any prior task experience or demonstrations, establishing effective performance on first exposure. Through empirical analysis, we identify the architectural mechanisms underlying stable convergence (zero action loops) and effective cross-task transfer (67% to 78% improvement).Our work demonstrates that synergistic integration of complementary learning mechanisms enables robust zero-shot generalization that approaches few-shot baselines from prior work.

</details>


### [82] [Expert-Guided POMDP Learning for Data-Efficient Modeling in Healthcare](https://arxiv.org/abs/2511.14619)
*Marco Locatelli,Arjen Hommersom,Roberto Clemens Cerioli,Daniela Besozzi,Fabio Stella*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为Fuzzy MAP EM的新算法，它通过模糊伪计数将专家知识融入EM框架，以解决有限数据下POMDP参数学习的挑战，并在医学模拟中展现出优于标准EM算法的性能。


<details>
  <summary>Details</summary>
Motivation: 在数据有限的情况下，从部分可观察马尔可夫决策过程（POMDP）中学习参数是一个难题。

Method: 通过融合专家定义的模糊模型，Fuzzy MAP EM算法将模糊伪计数整合到EM框架中，从而将问题重新定义为最大后验（MAP）估计，以指导有限数据环境下的学习。

Result: 在合成医学模拟中，该方法在低数据和高噪声条件下均优于标准EM算法。此外，在重症肌无力病例研究中，Fuzzy MAP EM算法成功恢复了临床上一致的POMDP。

Conclusion: Fuzzy MAP EM算法通过整合专家知识和模糊伪计数，有效解决了有限数据下POMDP参数学习的挑战，并在医学领域展现出作为数据高效建模工具的巨大潜力。

Abstract: Learning the parameters of Partially Observable Markov Decision Processes (POMDPs) from limited data is a significant challenge. We introduce the Fuzzy MAP EM algorithm, a novel approach that incorporates expert knowledge into the parameter estimation process by enriching the Expectation Maximization (EM) framework with fuzzy pseudo-counts derived from an expert-defined fuzzy model. This integration naturally reformulates the problem as a Maximum A Posteriori (MAP) estimation, effectively guiding learning in environments with limited data. In synthetic medical simulations, our method consistently outperforms the standard EM algorithm under both low-data and high-noise conditions. Furthermore, a case study on Myasthenia Gravis illustrates the ability of the Fuzzy MAP EM algorithm to recover a clinically coherent POMDP, demonstrating its potential as a practical tool for data-efficient modeling in healthcare.

</details>


### [83] [Failure to Mix: Large language models struggle to answer according to desired probability distributions](https://arxiv.org/abs/2511.14630)
*Ivy Yuqian Yang,David Yu Zhang*

Main category: cs.LG

TL;DR: 大语言模型在生成遵循特定概率分布的输出时表现不佳，倾向于以接近100%的确定性生成概率略高的输出，即使存在强烈的内置偏差。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在遵循目标概率分布进行探索时的表现。

Method: 通过要求LLMs生成遵循简单概率分布的输出来进行系统实验。

Result: 所有测试的现代LLM都严重未能遵循概率分布。例如，当要求二元输出“1”的概率为49%时，模型几乎100%的时间会生成“0”。这种阶梯函数式的行为表明，LLM倾向于排他性地生成概率略高的输出。

Conclusion: LLMs在需要遵循特定概率分布进行探索性生成任务时存在显著缺陷，这对于需要概率探索的科学思想生成和选择等应用是一个限制。

Abstract: Scientific idea generation and selection requires exploration following a target probability distribution. In contrast, current AI benchmarks have objectively correct answers, and training large language models (LLMs) via reinforcement learning against these benchmarks discourages probabilistic exploration. Here, we conducted systematic experiments requesting LLMs to produce outputs following simple probabilistic distributions, and found that all modern LLMs tested grossly fail to follow the distributions. For example, requesting a binary output of "1" 49% of the time produces an answer of "0" nearly 100% of the time. This step function-like behavior of near-exclusively generating the output with marginally highest probability even overrules even strong in-built LLM biases.

</details>


### [84] [Adapformer: Adaptive Channel Management for Multivariate Time Series Forecasting](https://arxiv.org/abs/2511.14632)
*Yuchen Luo,Xinyu Li,Liuhua Peng,Mingming Gong*

Main category: cs.LG

TL;DR: Adapformer是一种先进的基于Transformer的多元时间序列预测（MTSF）框架，它通过自适应的通道管理策略，融合了通道独立（CI）和通道依赖（CD）方法的优点，实现了卓越的预测性能和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的多元时间序列预测方法在建模复杂变量间依赖关系时存在局限性。通道独立（CI）方法未能利用通道间相互作用的潜在信息，而通道依赖（CD）方法常包含过多无关信息导致过拟合和预测效率低下。

Method: Adapformer采用双阶段编码器-解码器架构，包括自适应通道增强器（ACE）和自适应通道预测器（ACF）。ACE通过选择性地整合关键依赖关系来丰富嵌入表示，ACF通过关注最相关的协变量来简化解码过程，从而减少噪声和冗余。

Result: Adapformer在多样的数据集上进行了严格测试，结果表明其性能优于现有模型，在预测准确性和计算效率方面都有所提升。

Conclusion: Adapformer通过有效融合CI和CD方法的优点，并采用双阶段编码器-解码器架构和自适应通道管理，成为MTSF领域最先进的模型，显著提升了预测准确性和计算效率。

Abstract: In multivariate time series forecasting (MTSF), accurately modeling the intricate dependencies among multiple variables remains a significant challenge due to the inherent limitations of traditional approaches. Most existing models adopt either \textbf{channel-independent} (CI) or \textbf{channel-dependent} (CD) strategies, each presenting distinct drawbacks. CI methods fail to leverage the potential insights from inter-channel interactions, resulting in models that may not fully exploit the underlying statistical dependencies present in the data. Conversely, CD approaches often incorporate too much extraneous information, risking model overfitting and predictive inefficiency. To address these issues, we introduce the Adaptive Forecasting Transformer (\textbf{Adapformer}), an advanced Transformer-based framework that merges the benefits of CI and CD methodologies through effective channel management. The core of Adapformer lies in its dual-stage encoder-decoder architecture, which includes the \textbf{A}daptive \textbf{C}hannel \textbf{E}nhancer (\textbf{ACE}) for enriching embedding processes and the \textbf{A}daptive \textbf{C}hannel \textbf{F}orecaster (\textbf{ACF}) for refining the predictions. ACE enhances token representations by selectively incorporating essential dependencies, while ACF streamlines the decoding process by focusing on the most relevant covariates, substantially reducing noise and redundancy. Our rigorous testing on diverse datasets shows that Adapformer achieves superior performance over existing models, enhancing both predictive accuracy and computational efficiency, thus making it state-of-the-art in MTSF.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [85] [Imagine in Space: Exploring the Frontier of Spatial Intelligence and Reasoning Efficiency in Vision Language Models](https://arxiv.org/abs/2511.13782)
*Xiaoxing Lian,Aidong Yang,Jun Zhu,Peng Wang,Yue Zhang*

Main category: cs.AI

TL;DR: 本文分析了大型语言模型(LLMs)和视觉语言模型(VLMs)在空间推理方面的局限性，并提出了一个名为SpatiaLite的合成基准来系统地评估它们的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）和视觉语言模型（VLMs）在逻辑推理、问题解决和决策制定方面表现出卓越的推理能力，但空间推理仍然是当前高级VLM面临的重大挑战。作者假设“想象”是空间世界模型中主要的推理机制。

Method: 本文引入了一个名为SpatiaLite的完全合成基准，该基准联合衡量空间推理的准确性和推理效率。此外，还提出了一个名为Imagery Driven Framework (IDF) 的框架用于数据合成和训练。

Result: 实验结果显示了三个关键发现：1. 高级VLM主要依赖于语言表征进行推理和想象，导致在需要感知空间关系和3D几何变换的视觉中心任务上存在显著缺陷。2. 高级VLM在当前的空间推理机制中表现出严重的低效率，随着变换复杂性的增加，token使用量迅速增长。3. 提出了一个 Imagery Driven Framework (IDF) 用于数据合成和训练，该框架可以隐式构建对VLM空间推理至关重要的内部世界模型。

Conclusion: 这项工作描绘了高级VLM的空间推理限制和模式，指出了关键缺陷，并为未来的发展提供了信息。

Abstract: Large language models (LLMs) and vision language models (VLMs), such as DeepSeek R1,OpenAI o3, and Gemini 2.5 Pro, have demonstrated remarkable reasoning capabilities across logical inference, problem solving, and decision making. However, spatial reasoning:a fundamental component of human cognition that includes mental rotation, navigation, and spatial relationship comprehension remains a significant challenge for current advanced VLMs. We hypothesize that imagination, the internal simulation of spatial states, is the dominant reasoning mechanism within a spatial world model. To test this hypothesis and systematically probe current VLM spatial reasoning mechanisms, we introduce SpatiaLite, a fully synthetic benchmark that jointly measures spatial reasoning accuracy and reasoning efficiency. Comprehensive experiments reveal three key findings. First, advanced VLMs predominantly rely on linguistic representations for reasoning and imagination, resulting in significant deficiencies on visual centric tasks that demand perceptual spatial relations and 3D geometry transformations such as mental rotation or projection prediction. Second, advanced VLMs exhibit severe inefficiency in their current spatial reasoning mechanisms, with token usage growing rapidly as transformation complexity increases. Third, we propose an Imagery Driven Framework (IDF) for data synthesis and training, which can implicitly construct an internal world model that is critical for spatial reasoning in VLMs. Building on SpatiaLite, this work delineates the spatial reasoning limits and patterns of advanced VLMs, identifies key shortcomings, and informs future advances

</details>


### [86] [Causal computations in Semi Markovian Structural Causal Models using divide and conquer](https://arxiv.org/abs/2511.13852)
*Anna Rodum Bjøru,Rafael Cabañas,Helge Langseth,Antonio Salmerón*

Main category: cs.AI

TL;DR: 本文探讨了将Bjøru等人提出的因果模型反事实概率算法扩展到半马尔可夫结构因果模型（SCM）的问题。


<details>
  <summary>Details</summary>
Motivation: Bjøru等人提出的算法在马尔可夫模型中表现良好，但无法处理外生变量影响多个内生变量的半马尔可夫SCM，而这种模型能够表示混杂关系。

Method: 本文通过一个最小示例说明了扩展该方法的挑战，并提出了一系列替代解决方案策略。

Result: 这些策略通过理论分析和计算研究进行了评估。

Conclusion: 本文成功地将Bjøru等人提出的方法扩展到半马尔可夫SCM，并提出了有效的解决方案。

Abstract: Recently, Bjøru et al. proposed a novel divide-and-conquer algorithm for bounding counterfactual probabilities in structural causal models (SCMs). They assumed that the SCMs were learned from purely observational data, leading to an imprecise characterization of the marginal distributions of exogenous variables. Their method leveraged the canonical representation of structural equations to decompose a general SCM with high-cardinality exogenous variables into a set of sub-models with low-cardinality exogenous variables. These sub-models had precise marginals over the exogenous variables and therefore admitted efficient exact inference. The aggregated results were used to bound counterfactual probabilities in the original model. The approach was developed for Markovian models, where each exogenous variable affects only a single endogenous variable. In this paper, we investigate extending the methodology to \textit{semi-Markovian} SCMs, where exogenous variables may influence multiple endogenous variables. Such models are capable of representing confounding relationships that Markovian models cannot. We illustrate the challenges of this extension using a minimal example, which motivates a set of alternative solution strategies. These strategies are evaluated both theoretically and through a computational study.

</details>


### [87] [Jailbreaking Large Vision Language Models in Intelligent Transportation Systems](https://arxiv.org/abs/2511.13892)
*Badhan Chandra Das,Md Tasnim Jawad,Md Jueal Mia,M. Hadi Amini,Yanzhao Wu*

Main category: cs.AI

TL;DR: 本文系统性地分析了集成在智能交通系统（ITS）中的大型视觉语言模型（LVLMs）在精心设计的越狱攻击下的漏洞。文章提出了一种新颖的越狱攻击方法，利用图像排版操纵和多轮提示来攻击LVLMs。同时，文章也提出了一种多层响应过滤防御技术来防止模型生成不适当的响应。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多模态推理和实际应用中表现出强大的能力，但它们极易受到越狱攻击。本文旨在系统地分析集成在智能交通系统（ITS）中的LVLMs在精心设计的越狱攻击下的漏洞，并提出相应的攻击和防御策略。

Method: 1. 构建有害查询数据集：遵循OpenAI的禁用类别，构建与交通相关的有害查询数据集。
2. 提出新型越狱攻击：利用图像排版操纵（image typography manipulation）和多轮提示（multi-turn prompting）来攻击LVLMs。
3. 提出多层响应过滤防御技术：通过多层过滤来阻止模型生成不适当的响应。

Result: 1. 进行了广泛的实验，验证了所提出的攻击和防御方法在最先进的LVLMs（包括开源和闭源）上的有效性。
2. 使用GPT-4的判断和人工验证来评估生成响应的毒性分数。
3. 将所提出的越狱方法与现有技术进行了比较，强调了图像排版操纵和多轮提示攻击在集成到ITS中的LVLMs中带来的严重安全风险。

Conclusion: LVLMs在ITS中易受越狱攻击，特别是通过图像排版操纵和多轮提示。本文提出的攻击方法揭示了这些漏洞，而多层响应过滤防御技术为缓解这些风险提供了一条有效途径。研究结果强调了提升LVLMs安全性的重要性，尤其是在ITS这类关键应用领域。

Abstract: Large Vision Language Models (LVLMs) demonstrate strong capabilities in multimodal reasoning and many real-world applications, such as visual question answering. However, LVLMs are highly vulnerable to jailbreaking attacks. This paper systematically analyzes the vulnerabilities of LVLMs integrated in Intelligent Transportation Systems (ITS) under carefully crafted jailbreaking attacks. First, we carefully construct a dataset with harmful queries relevant to transportation, following OpenAI's prohibited categories to which the LVLMs should not respond. Second, we introduce a novel jailbreaking attack that exploits the vulnerabilities of LVLMs through image typography manipulation and multi-turn prompting. Third, we propose a multi-layered response filtering defense technique to prevent the model from generating inappropriate responses. We perform extensive experiments with the proposed attack and defense on the state-of-the-art LVLMs (both open-source and closed-source). To evaluate the attack method and defense technique, we use GPT-4's judgment to determine the toxicity score of the generated responses, as well as manual verification. Further, we compare our proposed jailbreaking method with existing jailbreaking techniques and highlight severe security risks involved with jailbreaking attacks with image typography manipulation and multi-turn prompting in the LVLMs integrated in ITS.

</details>


### [88] [CORGI: Efficient Pattern Matching With Quadratic Guarantees](https://arxiv.org/abs/2511.13942)
*Daniel Weitekamp*

Main category: cs.AI

TL;DR: CORGI: 一种针对规则匹配的新型算法，解决了RETE算法在实时AI应用中指数级时间和空间复杂性问题，在组合匹配任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在实时应用中（如AI规划、响应式控制和低延迟关系数据库查询），基于规则的系统需要解决复杂的匹配问题。然而，在规则复杂、变量未充分约束或产生组合中间部分匹配时，现有模式匹配系统可能面临指数级时间和空间需求，尤其在AI系统自动生成规则时，容易导致程序执行缓慢或内存溢出。

Method: 本文提出了一种名为CORGI（Collection-Oriented Relational Graph Iteration）的新型匹配算法。与基于RETE的方法不同，CORGI不使用传统的β-内存来收集部分匹配。CORGI采用两步法：首先，在前向传递中构建/维护一个接地关系的图；然后，迭代器通过反向遍历图来按需生成匹配。

Result: CORGI算法在查找单个满意匹配方面提供了二次时间复杂度保障和空间复杂度保障，并且能够迭代地流式传输后续匹配，而无需将整个冲突集提交到内存中。

Conclusion: CORGI算法通过消除填充完整冲突集导致的高延迟和内存溢出，解决了RETE类方法的局限性。在性能评估中，CORGI在简单的组合匹配任务上显著优于SOAR和OPS5的RETE实现。

Abstract: Rule-based systems must solve complex matching problems within tight time constraints to be effective in real-time applications, such as planning and reactive control for AI agents, as well as low-latency relational database querying. Pattern-matching systems can encounter issues where exponential time and space are required to find matches for rules with many underconstrained variables, or which produce combinatorial intermediate partial matches (but are otherwise well-constrained). When online AI systems automatically generate rules from example-driven induction or code synthesis, they can easily produce worst-case matching patterns that slow or halt program execution by exceeding available memory. In our own work with cognitive systems that learn from example, we've found that aggressive forms of anti-unification-based generalization can easily produce these circumstances. To make these systems practical without hand-engineering constraints or succumbing to unpredictable failure modes, we introduce a new matching algorithm called CORGI (Collection-Oriented Relational Graph Iteration). Unlike RETE-based approaches, CORGI offers quadratic time and space guarantees for finding single satisficing matches, and the ability to iteratively stream subsequent matches without committing entire conflict sets to memory. CORGI differs from RETE in that it does not have a traditional $β$-memory for collecting partial matches. Instead, CORGI takes a two-step approach: a graph of grounded relations is built/maintained in a forward pass, and an iterator generates matches as needed by working backward through the graph. This approach eliminates the high-latency delays and memory overflows that can result from populating full conflict sets. In a performance evaluation, we demonstrate that CORGI significantly outperforms RETE implementations from SOAR and OPS5 on a simple combinatorial matching task.

</details>


### [89] [Rate-Distortion Guided Knowledge Graph Construction from Lecture Notes Using Gromov-Wasserstein Optimal Transport](https://arxiv.org/abs/2511.14595)
*Yuan An,Ruhma Hashmi,Michelle Rogers,Jane Greenberg,Brian K. Smith*

Main category: cs.AI

TL;DR: 该框架提出了一种基于率失真理论和最优输运几何来构建和优化教学知识图谱的方法，并通过生成选择题进行评估。


<details>
  <summary>Details</summary>
Motivation: 将非结构化教学材料转换为能捕捉关键教学内容的知识图谱仍然很困难，但这对于AI辅助学习系统自动生成高质量多选题至关重要。

Method: 该框架将讲义内容建模为度量-测度空间，捕捉语义和关系结构。候选知识图谱通过融合Gromov-Wasserstein（FGW）耦合进行对齐，以量化语义失真。率项通过知识图谱的大小表示复杂性和紧凑性。通过细化操作（添加、合并、拆分、删除、重组）最小化率失真拉格朗日量，从而产生紧凑、信息保留的知识图谱。

Result: 原型应用于数据科学讲座，产生了可解释的率失真曲线，并表明从优化后的知识图谱生成的多选题在十五个质量标准上始终优于从原始笔记生成的多选题。

Conclusion: 这项研究为个性化和AI辅助教育中的信息论知识图谱优化奠定了原则性基础。

Abstract: Task-oriented knowledge graphs (KGs) enable AI-powered learning assistant systems to automatically generate high-quality multiple-choice questions (MCQs). Yet converting unstructured educational materials, such as lecture notes and slides, into KGs that capture key pedagogical content remains difficult. We propose a framework for knowledge graph construction and refinement grounded in rate-distortion (RD) theory and optimal transport geometry. In the framework, lecture content is modeled as a metric-measure space, capturing semantic and relational structure, while candidate KGs are aligned using Fused Gromov-Wasserstein (FGW) couplings to quantify semantic distortion. The rate term, expressed via the size of KG, reflects complexity and compactness. Refinement operators (add, merge, split, remove, rewire) minimize the rate-distortion Lagrangian, yielding compact, information-preserving KGs. Our prototype applied to data science lectures yields interpretable RD curves and shows that MCQs generated from refined KGs consistently surpass those from raw notes on fifteen quality criteria. This study establishes a principled foundation for information-theoretic KG optimization in personalized and AI-assisted education.

</details>


### [90] [Scene Graph-Guided Generative AI Framework for Synthesizing and Evaluating Industrial Hazard Scenarios](https://arxiv.org/abs/2511.13970)
*Sanjay Acharjee,Abir Khan Ratul,Diego Patino,Md Nazmus Sakib*

Main category: cs.AI

TL;DR: 本文提出了一种由场景图引导的生成式人工智能框架，用于合成基于历史职业安全与健康管理局（OSHA）事故报告的危险场景的逼真图像。我们还引入了一个视觉问答（VQA）框架来评估生成数据的真实性和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 训练视觉模型准确检测工作场所危害需要不安全情况的真实图像，而获取此类数据集非常困难，因为捕捉事故触发场景几乎不可能。

Method: 1. 使用 GPT-4o 分析 OSHA 叙述，提取结构化的危害推理。
2. 将推理转换为捕获空间和上下文关系的对象级场景图。
3. 场景图引导文本到图像扩散模型生成符合构图的危害场景。
4. 引入视觉问答（VQA）框架评估生成数据的真实感和语义保真度。

Result: 在四种最先进的生成模型中，提出的 VQA 图分数优于基于熵验证的 CLIP 和 BLIP 指标，证实其具有更高的判别敏感性。

Conclusion: 本文成功开发了一种通过场景图引导的生成式人工智能框架，能够合成逼真的危险场景图像，并提出了一种有效的 VQA 评估框架，为克服工作场所危害检测领域的数据获取难题提供了新的解决方案。

Abstract: Training vision models to detect workplace hazards accurately requires realistic images of unsafe conditions that could lead to accidents. However, acquiring such datasets is difficult because capturing accident-triggering scenarios as they occur is nearly impossible. To overcome this limitation, this study presents a novel scene graph-guided generative AI framework that synthesizes photorealistic images of hazardous scenarios grounded in historical Occupational Safety and Health Administration (OSHA) accident reports. OSHA narratives are analyzed using GPT-4o to extract structured hazard reasoning, which is converted into object-level scene graphs capturing spatial and contextual relationships essential for understanding risk. These graphs guide a text-to-image diffusion model to generate compositionally accurate hazard scenes. To evaluate the realism and semantic fidelity of the generated data, a visual question answering (VQA) framework is introduced. Across four state-of-the-art generative models, the proposed VQA Graph Score outperforms CLIP and BLIP metrics based on entropy-based validation, confirming its higher discriminative sensitivity.

</details>


### [91] [ALEX:A Light Editing-knowledge Extractor](https://arxiv.org/abs/2511.14018)
*Minghu Wang,Shuliang Zhao,Yuanyuan Zhao,Hongxia Xu*

Main category: cs.AI

TL;DR: ALEX是一个针对大型语言模型（LLMs）的轻量级知识编辑框架，通过分层记忆架构和推理查询合成模块，显著提升了多跳问题回答的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在处理动态演变信息时的知识静态性问题，特别是在处理复杂的多跳问题时面临的扩展性和检索效率挑战。

Method: ALEX框架采用分层记忆架构，将知识更新组织成语义簇，将检索复杂度从O(N)降低到O(K+N/C)。它还集成了推理查询合成（IQS）模块，用于弥合查询和事实之间的语义鸿沟，并包含一个动态证据裁决（DEA）引擎，执行高效的两阶段检索过程。

Result: 在MQUAKE基准测试中，ALEX显著提高了多跳答案的准确性（MultiHop-ACC）和推理路径的可靠性（HopWise-ACC）。同时，它将所需的搜索空间减少了80%以上。

Conclusion: ALEX为构建可扩展、高效和准确的知识编辑系统提供了一个有前景的途径。

Abstract: The static nature of knowledge within Large Language Models (LLMs) makes it difficult for them to adapt to evolving information, rendering knowledge editing a critical task. However, existing methods struggle with challenges of scalability and retrieval efficiency, particularly when handling complex, multi-hop questions that require multi-step reasoning. To address these challenges, this paper introduces ALEX (A Light Editing-knowledge Extractor), a lightweight knowledge editing framework. The core innovation of ALEX is its hierarchical memory architecture, which organizes knowledge updates (edits) into semantic clusters. This design fundamentally reduces retrieval complexity from a linear O(N) to a highly scalable O(K+N/C). Furthermore, the framework integrates an Inferential Query Synthesis (IQS) module to bridge the semantic gap between queries and facts , and a Dynamic Evidence Adjudication (DEA) engine that executes an efficient two-stage retrieval process. Experiments on the MQUAKE benchmark demonstrate that ALEX significantly improves both the accuracy of multi-hop answers (MultiHop-ACC) and the reliability of reasoning paths (HopWise-ACC). It also reduces the required search space by over 80% , presenting a promising path toward building scalable, efficient, and accurate knowledge editing systems.

</details>


### [92] [Syn-STARTS: Synthesized START Triage Scenario Generation Framework for Scalable LLM Evaluation](https://arxiv.org/abs/2511.14023)
*Chiharu Hagiwara,Naoki Nonaka,Yuhta Hashimoto,Ryu Uchimido,Jun Seita*

Main category: cs.AI

TL;DR: 该研究提出了Syn-STARTS框架，利用大型语言模型生成MCIs分诊案例，解决了真实世界数据稀缺的问题，并验证了其生成数据的质量和稳定性，为开发高性能AI模型提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 在处理大规模伤亡事件（MCIs）时，分诊是最大化幸存者存活率的关键决策过程。人工智能在这种情境下的决策优化作用日益受到关注，但其开发和性能评估需要充分且高质量的基准数据集。然而，MCIs不常发生，现场记录难以积累，导致难以收集用于研究的大规模真实世界数据。

Method: 开发Syn-STARTS框架，该框架使用大型语言模型（LLMs）来生成分诊案例。将Syn-STARTS生成的案例与通过人工整理训练材料得到的TRIAGE开放数据集进行比较和验证。评估LLM在标准分诊方法START定义的绿色、黄色、红色和黑色类别中数百个案例的准确性。

Result: Syn-STARTS生成的分诊案例在质量上与从训练材料中人工整理得到的TRIAGE开放数据集无法区分。在对数百个案例（每个类别）进行评估时，LLM的准确性表现出高度稳定性。

Conclusion: 合成数据在开发用于严重和危急医疗情况的高性能AI模型方面具有巨大潜力。Syn-STARTS框架有效解决了MCIs分诊数据稀缺的问题，为AI在医疗应急决策中的应用提供了可行方案。

Abstract: Triage is a critically important decision-making process in mass casualty incidents (MCIs) to maximize victim survival rates. While the role of AI in such situations is gaining attention for making optimal decisions within limited resources and time, its development and performance evaluation require benchmark datasets of sufficient quantity and quality. However, MCIs occur infrequently, and sufficient records are difficult to accumulate at the scene, making it challenging to collect large-scale realworld data for research use. Therefore, we developed Syn-STARTS, a framework that uses LLMs to generate triage cases, and verified its effectiveness. The results showed that the triage cases generated by Syn-STARTS were qualitatively indistinguishable from the TRIAGE open dataset generated by manual curation from training materials. Furthermore, when evaluating the LLM accuracy using hundreds of cases each from the green, yellow, red, and black categories defined by the standard triage method START, the results were found to be highly stable. This strongly indicates the possibility of synthetic data in developing high-performance AI models for severe and critical medical situations.

</details>


### [93] [Making Evidence Actionable in Adaptive Learning](https://arxiv.org/abs/2511.14052)
*Amirreza Mehrabi,Jason W. Morphew,Breejha Quezada,N. Sanjay Rebello*

Main category: cs.AI

TL;DR: 这篇论文介绍了一项研究，旨在通过教师管理的反馈循环，将概念层面的评估证据转化为精准的微干预措施，以解决自适应学习中诊断精确但干预薄弱的问题。


<details>
  <summary>Details</summary>
Motivation: 自适应学习在诊断方面表现精确，但在干预方面相对薄弱，常常导致帮助时机不当或不切实际。研究旨在设计一种机制，使得自适应学习能够提供更及时和更匹配的学习干预。

Method: 本研究的自适应学习算法包含三个主要安全保障，Adequacy用于确保学习差距的弥合，Attention作为时间和冗余的预算约束，Diversity用于防止单一资源的过拟合。研究将干预分配形式化为一个二元整数规划问题，并加入了覆盖率、时间、难度窗口（由能力估计和概念矩阵中的先决条件决定）以及通过多样性实现的抗冗余约束。研究采用了贪婪选择、基于梯度的松弛以及混合方法来处理不同丰富度和延迟要求的场景。

Result: 在模拟和一项针对1204名学生的入门物理学课程部署中，两种求解器都能在限定的观察时间内为几乎所有学生实现完整的技能覆盖。其中，基于梯度的方法相比贪婪算法，将冗余覆盖减少了约12个百分点，并协调了不同难度。而贪婪算法在资源稀缺的情况下，以较低的计算成本提供了可比较的充分性。此外，松弛变量能够定位缺失内容并支持有针对性的内容 Curations，从而维持了不同学生群体的学习充分性。

Conclusion: 这项研究提出了一个可 HINGI 和可审计的控制器，它能够弥合诊断与教学之间的鸿沟，并在课堂规模上实现公平且负荷感知的个性化教学。

Abstract: Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage, time, difficulty windows informed by ability estimates, prerequisites encoded by a concept matrix, and anti-redundancy enforced through diversity. Greedy selection serves low-richness and tight-latency regimes, gradient-based relaxation serves rich repositories, and a hybrid method transitions along a richness-latency frontier. In simulation and in an introductory physics deployment with one thousand two hundred four students, both solvers achieved full skill coverage for essentially all learners within bounded watch time. The gradient-based method reduced redundant coverage by approximately twelve percentage points relative to greedy and harmonized difficulty across slates, while greedy delivered comparable adequacy with lower computational cost in scarce settings. Slack variables localized missing content and supported targeted curation, sustaining sufficiency across subgroups. The result is a tractable and auditable controller that closes the diagnostic-pedagogical loop and delivers equitable, load-aware personalization at classroom scale.

</details>


### [94] [APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design](https://arxiv.org/abs/2511.14101)
*Xinpeng Chen,Xiaofeng Han,Kaihao Zhang,Guochao Ren,Yujie Wang,Wenhao Cao,Yang Zhou,Jianfeng Lu,Zhenbo Song*

Main category: cs.AI

TL;DR: APD-agents是一个由大型语言模型驱动的多智能体框架，用于移动应用程序的自动化页面设计，它将用户的描述转化为结构化数据，然后通过多个智能体协作生成粗粒度和细粒度的页面布局。


<details>
  <summary>Details</summary>
Motivation: 尽管许多设计软件可以帮助执行重复性任务，但它们需要广泛的培训才能有效使用。此外，跨应用页面的协作设计需要额外的时间来统一标准并确保样式一致。

Method: 我们提出了APD-agents，一个由大型语言模型（LLM）驱动的多智能体框架，用于移动应用程序的自动化页面设计。我们的框架包括OrchestratorAgent、SemanticParserAgent、PrimaryLayoutAgent、TemplateRetrievalAgent和RecursiveComponentAgent。这些智能体协同工作，将用户对页面的描述转化为结构化数据，生成初始粗粒度布局，检索相关模板以增强布局质量，并递归生成所有细粒度子元素。

Result: 在RICO数据集上的实验结果表明，APD-agents实现了最先进的性能。

Conclusion: APD-agents通过大型语言模型驱动的多智能体系统，实现了移动应用程序页面设计的自动化，有效解决了传统设计过程中耗时、培训成本高和协同设计不一致等问题。

Abstract: Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.

</details>


### [95] [Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation](https://arxiv.org/abs/2511.14131)
*Yu Zhong,Zihao Zhang,Rui Zhang,Lingdong Huang,Haihan Gao,Shuo Wang,Da Li,Ruijian Han,Jiaming Guo,Shaohui Peng,Di Huang,Yunji Chen*

Main category: cs.AI

TL;DR: 本文提出了一个名为R3的双过程思维框架，它将大型语言模型的泛化能力与VLN的特定领域知识相结合，以零样本的方式解决了传统大型语言模型在VLN任务中面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在VLN中具有潜力，但它们在理解真实世界空间相关性方面的不足导致任务完成性能与领域专家之间存在差距。此外，引入大型语言模型还会增加计算成本和推理延迟。

Method: R3框架包含三个核心模块：Runner（轻量级专家模型，负责常规导航）、Ruminator（基于多模态大型语言模型，采用思维链提示进行结构化推理）和Regulator（监控导航进度，并根据三个标准控制适当的思维模式，协调Runner和Ruminator）。

Result: 在REVERIE基准测试中，R3在SPL和RGSPL方面分别超过了现有最先进的方法3.28%和3.30%。

Conclusion: R3框架通过有效整合大型语言模型和VLN特定专业知识，显著提高了VLN任务的性能，尤其是在处理具有挑战性的任务时。

Abstract: Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.

</details>


### [96] [Do Large Language Models (LLMs) Understand Chronology?](https://arxiv.org/abs/2511.14214)
*Pattaraphon Kenny Wongchamcharoen,Paul Glasserman*

Main category: cs.AI

TL;DR: 该研究评估了大型语言模型（LLMs）在处理时间序列任务时的表现，发现其在维持全局时间线上存在困难，但明确的推理预算能显著提高性能，尤其是在GPT-5模型中，这对于LLMs在金融领域的实时应用至关重要。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在金融和经济领域的应用日益广泛，但其对时间顺序的理解能力是一个未经检验的关键假设，尤其是在处理基于提示的避免前瞻性偏差问题时。

Method: 研究设计了一系列复杂度递增的时间顺序任务，包括时间顺序排序、条件排序（先过滤后排序）和时间错位检测。评估了GPT-4.1、Claude-3.7 Sonnet（有无扩展思维）和GPT-5模型在不同推理努力设置下的表现。

Result: 模型在序列长度增加时，准确匹配率急剧下降，但排序相关性保持较高，表明模型能保持局部顺序但难以维持全局一致的时间线。条件排序中，大多数失败源于过滤而非排序步骤，但GPT-5和带有扩展思维的Claude-3.7 Sonnet表现显著优于普通模型。时间错位检测是LLMs最简单的任务，但性能会随着时间线或实体重叠的增加而下降。明确的推理预算有助于时间顺序排序，GPT-5在中高推理努力下能在所有长度和完美条件排序任务中实现完美排序，而低推理努力会随着列表变长而性能下降。

Conclusion: 当前大型语言模型在处理时间顺序任务时存在局限性，但明确的推理预算可以通过提高任务复杂度来显著提升模型的性能，GPT-5在相关任务中表现出卓越的能力。这些发现对于LLMs在金融领域的实时应用具有重要意义。

Abstract: Large language models (LLMs) are increasingly used in finance and economics, where prompt-based attempts against look-ahead bias implicitly assume that models understand chronology. We test this fundamental question with a series of chronological ordering tasks with increasing complexities over facts the model already knows from pre-training. Our tasks cover (1) chronological ordering, (2) conditional sorting (filter, then order), and (3) anachronism detection. We evaluate GPT-4.1, Claude-3.7 Sonnet, with and without Extended Thinking (ET), and GPT-5 across multiple reasoning-effort settings. Across models, Exact match rate drops sharply as sequences lengthen even while rank correlations stay high as LLMs largely preserve local order but struggle to maintain a single globally consistent timeline. In conditional sorting, most failures stem from the filtering step rather than the ordering step, but GPT-5 and Claude-3.7 Sonnet with Extended Thinking outshine normal models significantly. Lastly, anachronism detection is found to be the easiest task for the LLMs but performance still declines with increasingly overlapping timelines or entities. Overall, our main contribution is showing that allocating explicit reasoning budget helps with chronological ordering with GPT-5 at medium/high reasoning effort achieving flawless ordering at all lengths and perfect conditional sorting (both self-filtered and given-subset), whereas low/minimal effort degrades with longer lists, mirroring earlier models. Our findings delineate limits of current LLMs on chronological tasks, providing insights into task complexity, and demonstrate scenarios in which reasoning helps. These patterns are important for the real-time application of LLMs in finance. We release all code and evaluation templates to support full reproducibility.

</details>


### [97] [Listen Like a Teacher: Mitigating Whisper Hallucinations using Adaptive Layer Attention and Knowledge Distillation](https://arxiv.org/abs/2511.14219)
*Kumud Tripathi,Aditya Srinivas Menon,Aman Gaurav,Raj Prakash Gohil,Pankaj Wasnik*

Main category: cs.AI

TL;DR: 该论文提出了一种名为 Whisper 的自动语音识别模型，该模型通过对抗性训练和知识蒸馏来提高其在嘈杂环境下的性能。


<details>
  <summary>Details</summary>
Motivation: Whisper 模型在多语言和零样本设置中表现出色，但其在噪声声学条件下经常出现幻觉错误。以前的工作主要集中在音频预处理或转录的后处理上，以过滤掉错误内容。然而，对Whisper模型本身的修改在很大程度上尚未被探索。

Method: 本文提出了一个两阶段架构：第一阶段通过自适应层注意力（ALA）增强编码器鲁棒性；第二阶段使用多目标知识蒸馏（KD）框架进一步抑制幻觉。ALA通过层间相关性分析将编码器层分组，并融合这些块表示以共同利用低级和高级特征。KD框架在噪声音频上训练学生模型，以使其语义和注意力分布与处理干净输入的教师模型保持一致。

Result: 在嘈杂语音基准测试中，我们的方法显著减少了幻觉和词错误率，同时保持了在干净语音上的性能。

Conclusion: ALA和KD共同提供了一种原则性策略，以提高Whisper在真实世界嘈杂条件下的可靠性。

Abstract: The Whisper model, an open-source automatic speech recognition system, is widely adopted for its strong performance across multilingual and zero-shot settings. However, it frequently suffers from hallucination errors, especially under noisy acoustic conditions. Previous works to reduce hallucinations in Whisper-style ASR systems have primarily focused on audio preprocessing or post-processing of transcriptions to filter out erroneous content. However, modifications to the Whisper model itself remain largely unexplored to mitigate hallucinations directly. To address this challenge, we present a two-stage architecture that first enhances encoder robustness through Adaptive Layer Attention (ALA) and further suppresses hallucinations using a multi-objective knowledge distillation (KD) framework. In the first stage, ALA groups encoder layers into semantically coherent blocks via inter-layer correlation analysis. A learnable multi-head attention module then fuses these block representations, enabling the model to jointly exploit low- and high-level features for more robust encoding. In the second stage, our KD framework trains the student model on noisy audio to align its semantic and attention distributions with a teacher model processing clean inputs. Our experiments on noisy speech benchmarks show notable reductions in hallucinations and word error rates, while preserving performance on clean speech. Together, ALA and KD offer a principled strategy to improve Whisper's reliability under real-world noisy conditions.

</details>


### [98] [DevPiolt: Operation Recommendation for IoT Devices at Xiaomi Home](https://arxiv.org/abs/2511.14227)
*Yuxiang Wang,Siwen Wang,Haowei Han,Ao Wang,Boya Liu,Yong Zhao,Chengbo Wu,Bin Zhu,Bin Qin,Xiaokai Zhou,Xiao Yan,Jiawei Jiang,Bo Du*

Main category: cs.AI

TL;DR: DevPiolt，一个基于LLM的IoT设备操作推荐模型，通过持续预训练、多任务微调和直接偏好优化解决了现有模型的局限性，显著提高了推荐性能和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有推荐模型难以处理复杂的IoT设备操作逻辑、多样化的用户偏好且对次优推荐敏感，限制了其在IoT设备操作中的应用。

Method: DevPiolt首先通过持续预训练和多任务微调赋予LLM基本的IoT操作领域知识，然后利用直接偏好优化来与用户偏好对齐，最后设计了基于置信度的曝光控制机制以避免低质量推荐。

Result: DevPiolt在所有数据集上显著优于基线模型，平均提升69.5%。在小米之家App部署后，独立访客设备覆盖率增加21.6%，页面浏览接受率增加29.1%。

Conclusion: DevPiolt通过创新的LLM应用和优化策略，有效解决了IoT设备操作推荐的挑战，并在实际应用中取得了显著成效，提升了用户体验和业务价值。

Abstract: Operation recommendation for IoT devices refers to generating personalized device operations for users based on their context, such as historical operations, environment information, and device status. This task is crucial for enhancing user satisfaction and corporate profits. Existing recommendation models struggle with complex operation logic, diverse user preferences, and sensitive to suboptimal suggestions, limiting their applicability to IoT device operations. To address these issues, we propose DevPiolt, a LLM-based recommendation model for IoT device operations. Specifically, we first equip the LLM with fundamental domain knowledge of IoT operations via continual pre-training and multi-task fine-tuning. Then, we employ direct preference optimization to align the fine-tuned LLM with specific user preferences. Finally, we design a confidence-based exposure control mechanism to avoid negative user experiences from low-quality recommendations. Extensive experiments show that DevPiolt significantly outperforms baselines on all datasets, with an average improvement of 69.5% across all metrics. DevPiolt has been practically deployed in Xiaomi Home app for one quarter, providing daily operation recommendations to 255,000 users. Online experiment results indicate a 21.6% increase in unique visitor device coverage and a 29.1% increase in page view acceptance rates.

</details>


### [99] [Enhancing Regional Airbnb Trend Forecasting Using LLM-Based Embeddings of Accessibility and Human Mobility](https://arxiv.org/abs/2511.14248)
*Hongju Lee,Youngjun Park,Jisun An,Dongman Lee*

Main category: cs.AI

TL;DR: 这篇论文提出了一个新颖的时间序列预测框架，用于预测区域爱彼迎市场趋势，取得了显著更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 爱彼迎等短租平台的扩张扰乱了当地住房市场，导致租金上涨和住房负担能力问题。准确预测区域爱彼迎市场趋势可以为政策制定者和城市规划者提供关键见解，以减轻这些影响。

Method: 本研究提出了一个新颖的时间序列预测框架，用于预测区域爱彼迎市场的三个关键指标：收入、预订天数和预订数量。该模型使用滑动窗口方法预测未来1到3个月的趋势，通过将列表特征与城市可达性和人类出行等外部情境因素相结合来构建区域表示。该方法将结构化表格数据转换为大型语言模型的基于提示的输入，生成全面的区域嵌入。然后，这些嵌入被输入到先进的时间序列模型（RNN、LSTM、Transformer）中，以更好地捕捉复杂的时空动态。

Result: 在首尔的爱彼迎数据集上进行的实验表明，与传统的统计和机器学习模型等常规基线相比，我们的方法将平均RMSE和MAE降低了约48%。

Conclusion: 该框架不仅提高了预测准确性，而且为检测供应过剩区域和支持数据驱动的城市政策决策提供了实用见解。

Abstract: The expansion of short-term rental platforms, such as Airbnb, has significantly disrupted local housing markets, often leading to increased rental prices and housing affordability issues. Accurately forecasting regional Airbnb market trends can thus offer critical insights for policymakers and urban planners aiming to mitigate these impacts. This study proposes a novel time-series forecasting framework to predict three key Airbnb indicators -- Revenue, Reservation Days, and Number of Reservations -- at the regional level. Using a sliding-window approach, the model forecasts trends 1 to 3 months ahead. Unlike prior studies that focus on individual listings at fixed time points, our approach constructs regional representations by integrating listing features with external contextual factors such as urban accessibility and human mobility. We convert structured tabular data into prompt-based inputs for a Large Language Model (LLM), producing comprehensive regional embeddings. These embeddings are then fed into advanced time-series models (RNN, LSTM, Transformer) to better capture complex spatio-temporal dynamics. Experiments on Seoul's Airbnb dataset show that our method reduces both average RMSE and MAE by approximately 48% compared to conventional baselines, including traditional statistical and machine learning models. Our framework not only improves forecasting accuracy but also offers practical insights for detecting oversupplied regions and supporting data-driven urban policy decisions.

</details>


### [100] [PathMind: A Retrieve-Prioritize-Reason Framework for Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2511.14256)
*Yu Liu,Xixun Lin,Yanmin Shang,Yangxi Li,Shi Wang,Yanan Cao*

Main category: cs.AI

TL;DR: PathMind框架通过选择性地引导大型语言模型（LLMs）利用重要的推理路径，以提升知识图谱推理（KGR）的忠实性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLMs）的知识图谱推理（KGR）方法存在两个主要限制：1）现有方法不加区分地提取推理路径，未能评估它们的不同重要性，这可能引入误导LLMs的无关噪声；2）需要高检索需求和频繁的LLM调用来动态探索潜在的推理路径。

Method: PathMind遵循“检索-优先-推理”范式。首先，通过检索模块从知识图谱中检索查询子图。其次，引入路径优先级机制，利用语义感知的路径优先级函数识别重要的推理路径，该函数同时考虑累积成本和到达目标的估计未来成本。最后，PathMind通过双阶段训练策略生成准确且逻辑一致的响应，包括任务特定的指令微调和路径偏好对齐。

Result: PathMind在基准数据集上进行了广泛实验，结果表明它始终优于竞争基线，尤其是在输入token较少的复杂推理任务上，通过识别关键推理路径获得了显著提升。

Conclusion: PathMind框架通过其独特的“检索-优先-推理”范式和路径优先级机制，有效地解决了LLM基KGR方法的局限性，提高了推理的忠实性和可解释性。

Abstract: Knowledge graph reasoning (KGR) is the task of inferring new knowledge by performing logical deductions on knowledge graphs. Recently, large language models (LLMs) have demonstrated remarkable performance in complex reasoning tasks. Despite promising success, current LLM-based KGR methods still face two critical limitations. First, existing methods often extract reasoning paths indiscriminately, without assessing their different importance, which may introduce irrelevant noise that misleads LLMs. Second, while many methods leverage LLMs to dynamically explore potential reasoning paths, they require high retrieval demands and frequent LLM calls. To address these limitations, we propose PathMind, a novel framework designed to enhance faithful and interpretable reasoning by selectively guiding LLMs with important reasoning paths. Specifically, PathMind follows a "Retrieve-Prioritize-Reason" paradigm. First, it retrieves a query subgraph from KG through the retrieval module. Next, it introduces a path prioritization mechanism that identifies important reasoning paths using a semantic-aware path priority function, which simultaneously considers the accumulative cost and the estimated future cost for reaching the target. Finally, PathMind generates accurate and logically consistent responses via a dual-phase training strategy, including task-specific instruction tuning and path-wise preference alignment. Extensive experiments on benchmark datasets demonstrate that PathMind consistently outperforms competitive baselines, particularly on complex reasoning tasks with fewer input tokens, by identifying essential reasoning paths.

</details>


### [101] [When Words Change the Model: Sensitivity of LLMs for Constraint Programming Modelling](https://arxiv.org/abs/2511.14334)
*Alessio Pellegrino,Jacopo Mauro*

Main category: cs.AI

TL;DR: 本文分析了大语言模型在约束编程（CP）问题建模方面的能力，发现其对经典问题的表现可能源于数据污染，并且在上下文和语言变体下，模型的性能会急剧下降，表明其理解能力较浅。


<details>
  <summary>Details</summary>
Motivation: 优化和约束编程的长期目标是，通过自然语言描述问题，并自动获得可执行、高效的模型。大型语言模型似乎使这一愿景更近，在为经典基准自动生成模型方面表现出令人印象深刻的结果。然而，这种明显的成功可能源于数据污染而非真正的推理。

Method: 我们系统地复述和扰动了一组著名的CSPLib问题，以保留其结构，同时修改其上下文并引入误导性元素。然后，我们比较了三个代表性大型语言模型在原始和修改描述下生成的模型。

Result: 定性分析表明，虽然大型语言模型可以生成语法有效和语义合理模型，但它们的性能在上下文和语言变化下急剧下降，这揭示了其理解的肤浅性和对措辞的敏感性。

Conclusion: 鉴于大型语言模型在上下文和语言变化下性能的急剧下降，揭示了其理解的肤浅性和对措辞的敏感性，因此需要进一步研究来提高大型语言模型在真实世界约束编程问题建模中的鲁棒性和泛化能力。

Abstract: One of the long-standing goals in optimisation and constraint programming is to describe a problem in natural language and automatically obtain an executable, efficient model. Large language models appear to bring this vision closer, showing impressive results in automatically generating models for classical benchmarks. However, much of this apparent success may derive from data contamination rather than genuine reasoning: many standard CP problems are likely included in the training data of these models. To examine this hypothesis, we systematically rephrased and perturbed a set of well-known CSPLib problems to preserve their structure while modifying their context and introducing misleading elements. We then compared the models produced by three representative LLMs across original and modified descriptions. Our qualitative analysis shows that while LLMs can produce syntactically valid and semantically plausible models, their performance drops sharply under contextual and linguistic variation, revealing shallow understanding and sensitivity to wording.

</details>


### [102] [Operationalizing Pluralistic Values in Large Language Model Alignment Reveals Trade-offs in Safety, Inclusivity, and Model Behavior](https://arxiv.org/abs/2511.14476)
*Dalia Ali,Dora Zhao,Allison Koenecke,Orestis Papakyriakopoulos*

Main category: cs.AI

TL;DR: 该研究探讨了在大型语言模型（LLM）对齐过程中纳入多元价值观的影响，通过评估人群差异和设计参数，发现不同人群对LLM回复的评价存在显著差异，且技术设计选择对模型行为有重要影响。


<details>
  <summary>Details</summary>
Motivation: 目前LLM的训练在安全性与人类价值观对齐方面常常忽视人类社会多样性，因此本研究旨在探讨将多元价值观纳入LLM对齐过程如何影响其行为。

Method: 研究收集了来自美国和德国参与者（N = 1,095，27,375 次评分）的对齐数据，他们从五个维度对LLM的回复进行评分： Toxicity（毒性）、Emotional Awareness (EA)（情感意识）、Sensitivity（敏感性）、Stereotypical Bias（刻板印象偏见）和Helpfulness（有用性）。研究人员使用来自不同社会群体的偏好，并改变评分量表、分歧处理方法和优化技术，对多个大型语言模型和大型推理模型进行了微调。

Result: 研究结果显示，在评价LLM回复时存在系统性的人群差异：男性参与者对回复的“毒性”评分比女性低18%；保守派和黑人参与者对回复的“情感意识”评分分别比自由派和白人高27.9%和44%。根据特定群体偏好进行微调的模型表现出不同的行为。技术设计选择显示出显著影响：保留评估者分歧比多数投票能多减少约53%的“毒性”，5点量表比二元量表能多减少约22%；直接偏好优化（DPO）在多值优化方面始终优于群体相对策略优化（GRPO）。

Conclusion: 这项研究回答了一个关键问题：对齐应该如何平衡专家驱动和用户驱动的信号，以确保安全和公平的代表性。通过初步探索，研究强调了在LLM对齐中考虑社会多样性和优化技术选择的重要性。

Abstract: Although large language models (LLMs) are increasingly trained using human feedback for safety and alignment with human values, alignment decisions often overlook human social diversity. This study examines how incorporating pluralistic values affects LLM behavior by systematically evaluating demographic variation and design parameters in the alignment pipeline. We collected alignment data from US and German participants (N = 1,095, 27,375 ratings) who rated LLM responses across five dimensions: Toxicity, Emotional Awareness (EA), Sensitivity, Stereotypical Bias, and Helpfulness. We fine-tuned multiple Large Language Models and Large Reasoning Models using preferences from different social groups while varying rating scales, disagreement handling methods, and optimization techniques. The results revealed systematic demographic effects: male participants rated responses 18% less toxic than female participants; conservative and Black participants rated responses 27.9% and 44% more emotionally aware than liberal and White participants, respectively. Models fine-tuned on group-specific preferences exhibited distinct behaviors. Technical design choices showed strong effects: the preservation of rater disagreement achieved roughly 53% greater toxicity reduction than majority voting, and 5-point scales yielded about 22% more reduction than binary formats; and Direct Preference Optimization (DPO) consistently outperformed Group Relative Policy Optimization (GRPO) in multi-value optimization. These findings represent a preliminary step in answering a critical question: How should alignment balance expert-driven and user-driven signals to ensure both safety and fair representation?

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [103] [DNA Storage in the Short Molecule Regime](https://arxiv.org/abs/2511.14284)
*Ran Tamir,Nir Weinberger,Albert Guillén i Fàbregas*

Main category: cs.IT

TL;DR: 本文致力于DNA存储系统中的信息存储问题。


<details>
  <summary>Details</summary>
Motivation: Shomorony和Heckel（2022）提出了关于可靠存储信息比特数目的猜想，本文旨在完成该猜想的证明。

Method: 本文分析了一种随机编码方案，其中每个码字都是通过量化从概率单纯形中提取的随机生成的概率质量函数而获得的。通过分析最优最大似然解码器，本文推导出了一个可达界限。此外，本文还提出了第二种编码方案。

Result: 本文得出的可达界限与整个短分子范围内的最新逆界相符，完成了该猜想的证明。第二种编码方案在显著降低计算复杂度的同时实现了最优缩放。

Conclusion: 本文完成了Shomorony和Heckel（2022）提出的猜想的证明，并提出了一种新的低复杂度的编码方案，为DNA存储系统提供了理论和实践上的进步。

Abstract: We study the amount of reliable information that can be stored in a DNA-based storage system composed of short DNA molecules. In this regime, Shomorony and Heckel (2022) put forward a conjecture on the scaling of the number of information bits that can be reliably stored. In this paper, we complete the proof of this conjecture. We analyze a random-coding scheme in which each codeword is obtained by quantizing a randomly generated probability mass function drawn from the probability simplex. By analyzing the optimal maximum-likelihood decoder, we derive an achievability bound that matches a recently established converse bound across the entire short-molecule regime. We also propose a second coding scheme, which operates with significantly lower computational complexity but achieves the optimal scaling, except for a specific range of very short molecules.

</details>


### [104] [The Capacity of Collusion-Resilient Decentralized Secure Aggregation with Groupwise Keys](https://arxiv.org/abs/2511.14444)
*Zhou Li,Xiang Zhang,Yizhou Zhao,Haiqiang Chen,Jihao Fan,Giuseppe Caire*

Main category: cs.IT

TL;DR: 本文研究了信息论去中心化安全聚合（DSA）问题，考虑了群秘密密钥和抗合谋攻击。


<details>
  <summary>Details</summary>
Motivation: 在DSA中，K个用户通过无差错广播信道互连。每个用户都有一个私有输入，并旨在计算所有其他用户输入的总和，同时满足安全约束，即没有用户（即使与多达T个其他用户合谋）能够推断出除了恢复的总和之外的任何输入信息。为了确保安全，用户配备了秘密密钥来掩盖其输入。基于最近在高效的基于组的密钥生成协议方面的进展，我们考虑了对称的组密钥设置，其中G个用户的每个子集共享一个独立于所有其他组密钥的组密钥。

Method: 我们刻画了由每用户广播通信速率和组密钥速率的所有可实现对组成的最佳速率区域。

Result: DSA在G=1或G≥K-T时不可行。当2≤G<K-T时，为了安全地计算所需和的一个符号，每个用户必须广播至少一个符号，并且每个组密钥必须包含至少(K-T-2)/C(K-T-1, G)个独立符号。

Conclusion: 我们的结果建立了具有群密钥的DSA的基本限制，并为去中心化学习系统中通信和密钥高效的安全聚合提供了设计思路。

Abstract: This paper investigates the information-theoretic decentralized secure aggregation (DSA) problem under practical groupwise secret keys and collusion resilience. In DSA, $K$ users are interconnected through error-free broadcast channels. Each user holds a private input and aims to compute the sum of all other users' inputs, while satisfying the security constraint that no user, even when colluding with up to $T$ other users, can infer any information about the inputs beyond the recovered sum. To ensure security, users are equipped with secret keys to mask their inputs. Motivated by recent advances in efficient group-based key generation protocols, we consider the symmetric groupwise key setting, where every subset of $G$ users shares a group key that is independent of all other group keys. The problem is challenging because the recovery and security constraints must hold simultaneously for all users, and the structural constraints on the secret keys limit the flexibility of key correlations. We characterize the optimal rate region consisting of all achievable pairs of per-user broadcast communication rate and groupwise key rate. In particular, we show that DSA with groupwise keys is infeasible when $G=1$ or $G\ge K-T$. Otherwise, when $2\le G<K-T$, to securely compute one symbol of the desired sum, each user must broadcast at least one symbol, and each group key must contain at least $(K-T-2)/\binom{K-T-1}{G}$ independent symbols. Our results establish the fundamental limits of DSA with groupwise keys and provide design insights for communication- and key-efficient secure aggregation in decentralized learning systems.

</details>


### [105] [Monimial Matrix Analogue of Yoshida's theorem](https://arxiv.org/abs/2511.14480)
*Ananda Chakraborty*

Main category: cs.IT

TL;DR: 本文研究了有限域上线性码的权枚举子变体，并推广了平均完全联合权枚举子的概念，给出了其MacWilliams型恒等式，最后提出了该平均完全联合权枚举子的Yoshida定理的单项式模拟以及$g$重平均完全联合权枚举子的广义表示和单项式矩阵模拟的Yoshida定理。


<details>
  <summary>Details</summary>
Motivation: 为了推广有限域上线性码的权枚举子的概念，并建立其MacWilliams型恒等式和Yoshida定理的单项式模拟。

Method: 1. 推广了有限域上两个线性码的平均完全联合权枚举子的概念。2. 给出了其MacWilliams型恒等式。3. 建立了该平均完全联合权枚举子的Yoshida定理的单项式模拟。4. 提出了有限域上$g$重平均完全联合权枚举子的广义表示。5. 建立了$g$重平均完全联合权枚举子的Yoshida定理的单项式矩阵模拟。

Result: 推广了有限域上线性码的平均完全联合权枚举子，并得到了其MacWilliams型恒等式；建立了该枚举子的Yoshida定理的单项式模拟；提出了$g$重平均完全联合权枚举子的广义表示和Yoshida定理的单项式矩阵模拟。

Conclusion: 本文成功推广了有限域上线性码的权枚举子的相关理论，并建立了新的恒等式和定理，为进一步研究线性码的性质提供了新的工具和思路。

Abstract: In this paper, we study variants of weight enumerators of linear codes over $\mathbb{F}_q$. We generalize the concept of average complete joint weight enumerators of two linear codes over $\mathbb{F}_q$. We also give its MacWilliams type identities. Then we establish a monomial analogue of Yoshida's theorem for this average complete joint weight enumerators. Finally, we present the generalized representation for average of $g$-fold complete joint weight enumerators for $\mathbb{F}_q$-linear codes and establish a monomial matrix analogue of Yoshida's theorem for average $g$-fold complete joint weight enumerators.

</details>


### [106] [Compression with Privacy-Preserving Random Access](https://arxiv.org/abs/2511.14524)
*Venkat Chandar,Aslan Tchamkerten,Shashank Vatedka*

Main category: cs.IT

TL;DR: 本文提出了一种无损压缩i.i.d.二进制源序列的方法，其压缩率高于熵，且在对任何单个$X_i$进行解码时，不会泄露关于其他比特的信息。


<details>
  <summary>Details</summary>
Motivation: 在无损数据压缩中，安全性是一个重要的考虑因素，尤其是在处理敏感数据时。传统的无损压缩方法通常会泄露关于其他比特的信息，这可能会导致隐私泄露。因此，作者的动机是开发一种既能实现无损压缩，又能保护隐私的方法。

Method: 本文提出了一种新的无损压缩方法，该方法基于i.i.d.二进制源序列的特性。该方法旨在确保在解码单个比特时，不会泄露关于其他比特的信息。

Result: 实验结果表明，该方法可以在高于熵的任何速率下对i.i.d.二进制源序列进行无损压缩。更重要的是，该方法实现了隐私保护，即在对任何单个比特进行解码时，不会泄露关于其他比特的信息。

Conclusion: 本文提出了一种新颖的无损压缩方法，该方法不仅实现了高效的压缩，而且在解码过程中提供了强大的隐私保护。这项工作对于需要在保证数据安全性的同时进行无损压缩的应用具有重要意义。

Abstract: It is shown that an i.i.d. binary source sequence $X_1, \ldots, X_n$ can be losslessly compressed at any rate above entropy such that the individual decoding of any $X_i$ reveals \emph{no} information about the other bits $\{X_j : j \neq i\}$.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [107] [Knowledge vs. Experience: Asymptotic Limits of Impatience in Edge Tenants](https://arxiv.org/abs/2511.13763)
*Anthony Kiggundu,Bin Han,Hans D. Schotten*

Main category: stat.ML

TL;DR: 本文分析了封闭形式的马尔可夫残余逗留时间估计器和在线训练的执行者-评论家这两种信息反馈如何影响双M/M/1系统中的放弃和排队行为。


<details>
  <summary>Details</summary>
Motivation: 研究在双M/M/1系统中，两种信息反馈（马尔可夫估计器和在线训练的执行者-评论家）如何影响顾客放弃和排队行为。

Method: 本文采用分析方法，针对不等服务率和总时间耐心的情况，证明了总等待时间呈线性增长，放弃不可避免，并且当积压趋于无穷大时，成功排队的概率消失。此外，在温和的次线性误差条件下，两种信息模型产生相同的渐近限制。同时，通过实证验证了这些限制并量化了有限积压的差异。

Result: 研究发现，学习型和分析型反馈在实际系统规模下会产生不同的延迟、放弃率和瞬态排队行为，但最终会收敛到理论所暗示的相同渐近结果。

Conclusion: 研究结果揭示了信息价值何时重要（有限状态）何时不重要（渐近），这为低成本、排队感知系统的轻量级遥测和决策逻辑设计提供了依据。

Abstract: We study how two information feeds, a closed-form Markov estimator of residual sojourn and an online trained actor-critic, affect reneging and jockeying in a dual M/M/1 system. Analytically, for unequal service rates and total-time patience, we show that total wait grows linearly so abandonment is inevitable and the probability of a successful jockey vanishes as the backlog approaches towards infinity. Furthermore, under a mild sub-linear error condition both information models yield the same asymptotic limits (robustness). We empirically validate these limits and quantify finite backlog differences. Our findings show that learned and analytic feeds produce different delays, reneging rates and transient jockeying behavior at practical sizes, but converge to the same asymptotic outcome implied by our theory. The results characterize when value-of-information matters (finite regimes) and when it does not (asymptotics), informing lightweight telemetry and decision-logic design for low-cost, jockeying-aware systems.

</details>


### [108] [Uncertainty-Calibrated Prediction of Randomly-Timed Biomarker Trajectories with Conformal Bands](https://arxiv.org/abs/2511.13911)
*Vasiliki Tassopoulou,Charis Stamouli,Haochang Shou,George J. Pappas,Christos Davatzikos*

Main category: stat.ML

TL;DR: 该研究提出了一种适用于随机时间轨迹的共形预测方法，可以为生物标志物轨迹提供具有统计学保证的预测区间，并在阿尔茨海默病生物标志物预测中取得良好效果，提高了高风险受试者的识别能力。


<details>
  <summary>Details</summary>
Motivation: 尽管在从真实临床数据预测生物标志物轨迹方面取得了进展，但预测的不确定性带来了高风险（例如误诊），限制了其临床应用。为了在医疗保健中安全可靠地使用此类预测，本研究旨在开发一种不确定性校准的生物标志物轨迹预测方法。

Method: 本研究引入了一种共形方法，用于不确定性校准的生物标志物轨迹预测。该方法通过一种新颖的非一致性评分，将共形预测扩展到随机时间轨迹设置，从而产生预测区间，保证以用户预设的概率覆盖未知生物标志物轨迹。研究还开发了组条件共形区间，以解决人群异质性问题。

Result: 该方法在阿尔茨海默病的两种脑生物标志物预测中，其共形预测区间始终达到预期的覆盖范围，并且比基线预测区间更紧密。通过不确定性校准的风险评分，识别出的高风险受试者比标准风险评分多17.5%。

Conclusion: 本研究提出的共形预测方法能够为生物标志物轨迹提供不确定性校准的预测，有效解决了预测不确定性带来的临床应用风险。该方法在阿尔茨海默病风险评估中展现了临床实用价值，提高了高风险受试者的识别能力，凸显了不确定性校准在真实世界临床决策中的重要性。

Abstract: Despite recent progress in predicting biomarker trajectories from real clinical data, uncertainty in the predictions poses high-stakes risks (e.g., misdiagnosis) that limit their clinical deployment. To enable safe and reliable use of such predictions in healthcare, we introduce a conformal method for uncertainty-calibrated prediction of biomarker trajectories resulting from randomly-timed clinical visits of patients. Our approach extends conformal prediction to the setting of randomly-timed trajectories via a novel nonconformity score that produces prediction bands guaranteed to cover the unknown biomarker trajectories with a user-prescribed probability. We apply our method across a wide range of standard and state-of-the-art predictors for two well-established brain biomarkers of Alzheimer's disease, using neuroimaging data from real clinical studies. We observe that our conformal prediction bands consistently achieve the desired coverage, while also being tighter than baseline prediction bands. To further account for population heterogeneity, we develop group-conditional conformal bands and test their coverage guarantees across various demographic and clinically relevant subpopulations. Moreover, we demonstrate the clinical utility of our conformal bands in identifying subjects at high risk of progression to Alzheimer's disease. Specifically, we introduce an uncertainty-calibrated risk score that enables the identification of 17.5% more high-risk subjects compared to standard risk scores, highlighting the value of uncertainty calibration in real-world clinical decision making. Our code is available at github.com/vatass/ConformalBiomarkerTrajectories.

</details>


### [109] [Empirical Likelihood for Random Forests and Ensembles](https://arxiv.org/abs/2511.13934)
*Harold D. Chiang,Yukitoshi Matsushita,Taisuke Otsu*

Main category: stat.ML

TL;DR: 本文提出了一个用于随机森林和相关集成方法的经验似然（EL）框架，旨在量化其统计不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有集成方法在量化统计不确定性方面存在不足，本文旨在通过引入经验似然框架来解决这一问题。

Method: 通过利用集成预测中固有的不完全U统计量结构，构建了一个经验似然统计量。针对稀疏子采样导致的过度覆盖问题，提出了一种修正的经验似然方法，通过简单调整恢复了枢轴性。

Result: 理论证明和模拟结果表明，修正后的经验似然方法在覆盖准确性和实际可靠性方面优于现有推断方法。

Conclusion: 本文成功开发了一个计算效率高的经验似然框架，为随机森林等集成方法提供了准确的统计不确定性量化方法。

Abstract: We develop an empirical likelihood (EL) framework for random forests and related ensemble methods, providing a likelihood-based approach to quantify their statistical uncertainty. Exploiting the incomplete $U$-statistic structure inherent in ensemble predictions, we construct an EL statistic that is asymptotically chi-squared when subsampling induced by incompleteness is not overly sparse. Under sparser subsampling regimes, the EL statistic tends to over-cover due to loss of pivotality; we therefore propose a modified EL that restores pivotality through a simple adjustment. Our method retains key properties of EL while remaining computationally efficient. Theory for honest random forests and simulations demonstrate that modified EL achieves accurate coverage and practical reliability relative to existing inference methods.

</details>


### [110] [Splat Regression Models](https://arxiv.org/abs/2511.14042)
*Mara Daniels,Philippe Rigollet*

Main category: stat.ML

TL;DR: 本文介绍了一种名为“Splat回归模型”的高表达性函数逼近器，它将高斯泼溅法作为特例统一到一个理论框架中。


<details>
  <summary>Details</summary>
Motivation: 开发一种既具有高可解释性又具有高准确性的函数逼近器。

Method: Splat回归模型，它将异构和各向异性凸起函数的混合物作为输出，通过 Wasserstein-Fisher-Rao 梯度流进行优化。

Result: Splat模型能够局部调整每个splat的尺度和方向，实现了高解释性和高精度；同时，它将流行的高斯泼溅方法作为特例统一到统一的理论框架中。

Conclusion: Splat回归模型及其相关算法为解决涉及低维数据的各种近似、估计和逆问题提供了一种灵活且有前景的方法。

Abstract: We introduce a highly expressive class of function approximators called Splat Regression Models. Model outputs are mixtures of heterogeneous and anisotropic bump functions, termed splats, each weighted by an output vector. The power of splat modeling lies in its ability to locally adjust the scale and direction of each splat, achieving both high interpretability and accuracy. Fitting splat models reduces to optimization over the space of mixing measures, which can be implemented using Wasserstein-Fisher-Rao gradient flows. As a byproduct, we recover the popular Gaussian Splatting methodology as a special case, providing a unified theoretical framework for this state-of-the-art technique that clearly disambiguates the inverse problem, the model, and the optimization algorithm. Through numerical experiments, we demonstrate that the resulting models and algorithms constitute a flexible and promising approach for solving diverse approximation, estimation, and inverse problems involving low-dimensional data.

</details>


### [111] [SCOPE: Spectral Concentration by Distributionally Robust Joint Covariance-Precision Estimation](https://arxiv.org/abs/2511.14146)
*Renjie Chen,Viet Anh Nguyen,Huifu Xu*

Main category: stat.ML

TL;DR: 本文提出了一种分布鲁棒公式，用于同时估计随机向量的协方差矩阵和精度矩阵。


<details>
  <summary>Details</summary>
Motivation: 作者希望找到一种方法，可以同时估计随机向量的协方差矩阵和精度矩阵，并且该方法对于分布误差具有鲁棒性。

Method: 该模型通过最小化协方差估计量的Frobenius损失和精度矩阵估计量的Stein损失在所有来自以名义分布为中心的模糊集中的分布上的最坏情况加权和。模糊集的半径通过凸谱散度来衡量。

Result: 所提出的分布鲁棒估计模型可以简化为凸优化问题，从而产生准解析估计器。联合估计器是非线性收缩估计器。估计器的特征值非线性地收缩到一个正标量，该标量由损失项的权重系数决定。通过仔细调整系数，收缩纠正了经验协方差/精度矩阵估计器的谱偏差。

Conclusion: 本文提出的SCOPE方法可以有效地同时估计协方差矩阵和精度矩阵，并且具有良好的鲁棒性和收缩效果，优于现有的一些方法。

Abstract: We propose a distributionally robust formulation for simultaneously estimating the covariance matrix and the precision matrix of a random vector.The proposed model minimizes the worst-case weighted sum of the Frobenius loss of the covariance estimator and Stein's loss of the precision matrix estimator against all distributions from an ambiguity set centered at the nominal distribution. The radius of the ambiguity set is measured via convex spectral divergence. We demonstrate that the proposed distributionally robust estimation model can be reduced to a convex optimization problem, thereby yielding quasi-analytical estimators. The joint estimators are shown to be nonlinear shrinkage estimators. The eigenvalues of the estimators are shrunk nonlinearly towards a positive scalar, where the scalar is determined by the weight coefficient of the loss terms. By tuning the coefficient carefully, the shrinkage corrects the spectral bias of the empirical covariance/precision matrix estimator. By this property, we call the proposed joint estimator the Spectral concentrated COvariance and Precision matrix Estimator (SCOPE). We demonstrate that the shrinkage effect improves the condition number of the estimator. We provide a parameter-tuning scheme that adjusts the shrinkage target and intensity that is asymptotically optimal. Numerical experiments on synthetic and real data show that our shrinkage estimators perform competitively against state-of-the-art estimators in practical applications.

</details>


### [112] [Causal Discovery on Higher-Order Interactions](https://arxiv.org/abs/2511.14206)
*Alessio Zanga,Marco Scutari,Fabio Stella*

Main category: stat.ML

TL;DR: 本文提出了一种新的DAG聚合算法，该算法基于高阶结构，在数据稀疏和高维度环境下优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在数据稀疏时，现有的因果发现方法在聚合bootstrapped DAGs时，只考虑了DAGs中边的置信度，忽略了复杂的高阶边结构。

Method: 本文引入了一个新的基于高阶结构的理论框架，并提出了一个新的DAG聚合算法。

Result: 仿真研究表明，该方法在计算效率和有效性方面均优于现有技术，尤其是在样本量小和高维度设置下。

Conclusion: 本文提出了一种有效且计算高效的DAG聚合算法，该算法通过考虑高阶结构，提高了因果发现的性能，尤其适用于数据稀疏场景。

Abstract: Causal discovery combines data with knowledge provided by experts to learn the DAG representing the causal relationships between a given set of variables. When data are scarce, bagging is used to measure our confidence in an average DAG obtained by aggregating bootstrapped DAGs. However, the aggregation step has received little attention from the specialized literature: the average DAG is constructed using only the confidence in the individual edges of the bootstrapped DAGs, thus disregarding complex higher-order edge structures. In this paper, we introduce a novel theoretical framework based on higher-order structures and describe a new DAG aggregation algorithm. We perform a simulation study, discussing the advantages and limitations of the proposed approach. Our proposal is both computationally efficient and effective, outperforming state-of-the-art solutions, especially in low sample size regimes and under high dimensionality settings.

</details>


### [113] [Skewness-Robust Causal Discovery in Location-Scale Noise Models](https://arxiv.org/abs/2511.14441)
*Daniel Klippert,Alexander Marx*

Main category: stat.ML

TL;DR: 这篇论文介绍了一种名为SkewD的算法，用于在存在偏斜噪声分布的情况下进行双变量因果发现。


<details>
  <summary>Details</summary>
Motivation: 为了区分因果发现中的马尔可夫等价图，需要限制结构因果模型。在双变量模型中区分因和果，即区分X→Y和Y→X。位置尺度噪声模型（LSNMs）是一个灵活的模型类别，在大多数情况下是通用的和可识别的。然而，对于任意噪声项N，估计这些模型具有挑战性。

Method: 本文提出了一种名为SkewD的算法，这是一种基于似然的算法，用于在具有偏斜噪声分布的LSNM下进行双变量因果发现。SkewD将通常的正态分布框架扩展到偏斜正态设置，从而在对称和偏斜噪声下实现可靠的推断。对于参数估计，我们采用了启发式搜索和期望条件最大化算法的组合。

Result: SkewD在具有偏斜噪声的新合成数据集以及已建立的基准数据集上进行了评估。在我们的实验中，SkewD表现出强大的性能，并且与以前的工作相比，在高偏斜度下保持鲁棒性。

Conclusion: 当噪声N是偏斜随机变量时，现有方法的可靠性会降低。SkewD通过将通常的正态分布框架扩展到偏斜正态设置，从而在对称和偏斜噪声下实现可靠的推断，解决了这一限制。

Abstract: To distinguish Markov equivalent graphs in causal discovery, it is necessary to restrict the structural causal model. Crucially, we need to be able to distinguish cause $X$ from effect $Y$ in bivariate models, that is, distinguish the two graphs $X \to Y$ and $Y \to X$. Location-scale noise models (LSNMs), in which the effect $Y$ is modeled based on the cause $X$ as $Y = f(X) + g(X)N$, form a flexible class of models that is general and identifiable in most cases. Estimating these models for arbitrary noise terms $N$, however, is challenging. Therefore, practical estimators are typically restricted to symmetric distributions, such as the normal distribution. As we showcase in this paper, when $N$ is a skewed random variable, which is likely in real-world domains, the reliability of these approaches decreases. To approach this limitation, we propose SkewD, a likelihood-based algorithm for bivariate causal discovery under LSNMs with skewed noise distributions. SkewD extends the usual normal-distribution framework to the skew-normal setting, enabling reliable inference under symmetric and skewed noise. For parameter estimation, we employ a combination of a heuristic search and an expectation conditional maximization algorithm. We evaluate SkewD on novel synthetically generated datasets with skewed noise as well as established benchmark datasets. Throughout our experiments, SkewD exhibits a strong performance and, in comparison to prior work, remains robust under high skewness.

</details>
