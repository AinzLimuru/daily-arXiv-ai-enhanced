<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 64]
- [cs.IT](#cs.IT) [Total: 1]
- [stat.ML](#stat.ML) [Total: 6]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.LG](#cs.LG) [Total: 65]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Contextual Augmentation for Entity Linking using Large Language Models](https://arxiv.org/abs/2510.18888)
*Daniel Vollmers,Hamada M. Zahera,Diego Moussallem,Axel-Cyrille Ngonga Ngomo*

Main category: cs.CL

TL;DR: 该论文提出了一种新的实体链接方法，它结合了实体识别和消歧，并利用大型语言模型来丰富上下文。


<details>
  <summary>Details</summary>
Motivation: 传统实体链接方法将实体识别和消歧作为两个独立步骤处理，计算成本高且效果不佳。

Method: 本文提出了一种微调模型，该模型在一个统一的框架内共同整合了实体识别和消歧。此外，该方法利用大型语言模型来丰富实体提及的上下文。

Result: 在基准数据集上进行评估，并与几个基线进行了比较。评估结果表明，该方法在域外数据集上实现了最先进的性能。

Conclusion: 所提出的方法在实体链接方面优于传统方法，并在域外数据集上取得了最先进的性能。

Abstract: Entity Linking involves detecting and linking entity mentions in natural
language texts to a knowledge graph. Traditional methods use a two-step process
with separate models for entity recognition and disambiguation, which can be
computationally intensive and less effective. We propose a fine-tuned model
that jointly integrates entity recognition and disambiguation in a unified
framework. Furthermore, our approach leverages large language models to enrich
the context of entity mentions, yielding better performance in entity
disambiguation. We evaluated our approach on benchmark datasets and compared
with several baselines. The evaluation results show that our approach achieves
state-of-the-art performance on out-of-domain datasets.

</details>


### [2] [Small Language Models Offer Significant Potential for Science Community](https://arxiv.org/abs/2510.18890)
*Jian Zhang*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个使用小型语言模型（MiniLMs）从地球科学文献中进行信息检索的框架，该框架具有精确、快速和成本效益的特点，并可用于事实检索、趋势分析等应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言处理领域取得了显著进展，但其潜在的信息偏差和计算成本引发了担忧。因此，本研究旨在探索使用免费的小型语言模型（MiniLMs）从大量地球科学文献中进行精确、快速且经济高效的信息检索的可行性。

Method: 1. 构建了一个包含约7700万高质量句子的地球科学语料库，这些句子来源于95种领先的同行评审地球科学期刊，发表时间为2000年至2024年。
2. 使用MiniLMs通过语义搜索技术和句子级索引从语料库中提取相关的领域特定信息，实现计算效率。
3. 通过情感分析来分析情感基调，并通过无监督聚类分析句子中的主题簇。

Result: 1. MiniLMs方法能够有效地识别大量经过专家验证的、具有多学科来源的信息，尤其适用于包含定量发现的信息，这与ChatGPT-4等大型语言模型产生的通用响应不同。
2. MiniLM提供了一个强大的工具，可以通过分析情感基调和主题簇来跟踪地球科学社区内结论、研究重点、进展和新兴问题的演变。

Conclusion: MiniLM在地球科学社区中具有重要的潜力，可应用于事实和图像检索、趋势分析、矛盾分析和教育目的。

Abstract: Recent advancements in natural language processing, particularly with large
language models (LLMs), are transforming how scientists engage with the
literature. While the adoption of LLMs is increasing, concerns remain regarding
potential information biases and computational costs. Rather than LLMs, I
developed a framework to evaluate the feasibility of precise, rapid, and
cost-effective information retrieval from extensive geoscience literature using
freely available small language models (MiniLMs). A curated corpus of
approximately 77 million high-quality sentences, extracted from 95 leading
peer-reviewed geoscience journals such as Geophysical Research Letters and
Earth and Planetary Science Letters published during years 2000 to 2024, was
constructed. MiniLMs enable a computationally efficient approach for extracting
relevant domain-specific information from these corpora through semantic search
techniques and sentence-level indexing. This approach, unlike LLMs such as
ChatGPT-4 that often produces generalized responses, excels at identifying
substantial amounts of expert-verified information with established,
multi-disciplinary sources, especially for information with quantitative
findings. Furthermore, by analyzing emotional tone via sentiment analysis and
topical clusters through unsupervised clustering within sentences, MiniLM
provides a powerful tool for tracking the evolution of conclusions, research
priorities, advancements, and emerging questions within geoscience communities.
Overall, MiniLM holds significant potential within the geoscience community for
applications such as fact and image retrievals, trend analyses, contradiction
analyses, and educational purposes.

</details>


### [3] [When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs](https://arxiv.org/abs/2510.18892)
*Richard J. Young,Brandon Gillins,Alice M. Matthews*

Main category: cs.CL

TL;DR: 该论文提出了一个简化的评估框架，使用20个精心设计的提示来评估大型语言模型（LLM）在不同任务类别中的指令遵循能力。该框架通过大规模实证研究进行了验证，旨在提供一个实用的诊断工具，以评估LLM的真实能力，而非记忆性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）得到了广泛部署，但系统评估其指令遵循能力仍然具有挑战性。现有基准测试可能导致新模型在评估时表现出记忆性能而非真实能力，因此需要新颖的评估方法来诊断特定的指令遵循模式。

Method: 本文提出了一个简化的评估框架，包含20个精心设计的提示，用于评估LLM在不同任务类别中的指令遵循能力。该框架通过一个大规模实证研究进行了验证，该研究测试了OpenRouter上256个经过验证的LLM模型。评估方法侧重于可验证的指令，并引入了一个紧凑的测试套件，平衡了全面性和效率。每个提示都针对指令遵循的不同方面，包括格式依从性、内容限制、逻辑排序和多步骤任务执行。

Result: 研究结果揭示了LLM在指令遵循方面普遍存在的故障模式，并确定了构成特殊挑战的特定指令类型。

Conclusion: 这项工作提供了一个实用的评估工具，也是对当前LLM领域指令遵循能力最全面的实证分析之一。该框架有助于研究人员和实践者快速诊断LLM的特定指令依从性，评估其真实能力。

Abstract: Despite widespread deployment of Large Language Models, systematic evaluation
of instruction-following capabilities remains challenging. While comprehensive
benchmarks exist, focused assessments that quickly diagnose specific
instruction adherence patterns are valuable. As newer models may be trained on
existing benchmarks, novel evaluation approaches are needed to assess genuine
capabilities rather than memorized performance. This paper presents a
streamlined evaluation framework using twenty carefully designed prompts to
assess LLM instruction-following across diverse task categories. We demonstrate
this framework through a large-scale empirical study conducted on October 14,
2025, testing 256 verified working models from 331 available via OpenRouter. To
ensure methodological rigor and prevent selection bias, we first verified each
model's basic functionality before inclusion. Unlike large-scale benchmarks
requiring extensive computational resources, our approach offers a practical
diagnostic tool researchers and practitioners can readily apply. Our
methodology builds upon verifiable instructions while introducing a compact
test suite balancing comprehensiveness with efficiency. Each prompt targets
distinct aspects of instruction following, including format compliance, content
constraints, logical sequencing, and multi-step task execution. We evaluate
models from major providers (OpenAI, Anthropic, Google, Meta, Mistral) and
emerging implementations (Qwen, DeepSeek, community models), providing
comparative performance analysis. Our findings reveal consistent failure modes
and identify specific instruction types posing particular challenges. This work
contributes both a practical evaluation tool and one of the most comprehensive
empirical analyses of instruction-following capabilities across the
contemporary LLM landscape.

</details>


### [4] [Transformer-Based Low-Resource Language Translation: A Study on Standard Bengali to Sylheti](https://arxiv.org/abs/2510.18898)
*Mangsura Kabir Oni,Tabia Tanzin Prama*

Main category: cs.CL

TL;DR: 这篇论文探讨了将多语言Transformer模型微调以进行孟加拉语到锡尔赫特语的机器翻译，并将其与零样本大型语言模型进行比较。


<details>
  <summary>Details</summary>
Motivation: 探索低资源语言（如锡尔赫特语）的机器翻译，因为它们目前尚未得到充分研究，而现有方法主要关注高资源语言。

Method: 通过微调多语言Transformer模型并将它们与零样本大型语言模型进行比较，研究孟加拉语到锡尔赫特语的翻译。

Result: 微调模型显著优于LLMs，其中mBART-50在翻译充分性方面表现最佳，而MarianMT在字符级保真度方面表现出最强。

Conclusion: 任务特定的适应性对于代表性不足的语言很重要，并且有助于包容性语言技术的持续发展。

Abstract: Machine Translation (MT) has advanced from rule-based and statistical methods
to neural approaches based on the Transformer architecture. While these methods
have achieved impressive results for high-resource languages, low-resource
varieties such as Sylheti remain underexplored. In this work, we investigate
Bengali-to-Sylheti translation by fine-tuning multilingual Transformer models
and comparing them with zero-shot large language models (LLMs). Experimental
results demonstrate that fine-tuned models significantly outperform LLMs, with
mBART-50 achieving the highest translation adequacy and MarianMT showing the
strongest character-level fidelity. These findings highlight the importance of
task-specific adaptation for underrepresented languages and contribute to
ongoing efforts toward inclusive language technologies.

</details>


### [5] [DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code](https://arxiv.org/abs/2510.18904)
*Shriyansh Agrawal,Aidan Lau,Sanyam Shah,Ahan M R,Kevin Zhu,Sunishchal Dev,Vasu Sharma*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的方法，通过微调编码器型小型语言模型（SLMs）来检测机器生成的内容，并在准确性、计算效率和鲁棒性方面均优于现有的大型语言模型检测器。


<details>
  <summary>Details</summary>
Motivation: 目前，用于检测机器生成文本和源代码的检测器，主要是零样本方法，存在计算成本高或准确性不足的问题，或者两者之间存在权衡，这促使研究者寻求更有效的方法。

Method: 本研究通过使用专门的数据集对RoBERTA和CodeBERTa等预训练的编码器型小型语言模型（SLMs）进行微调，以实现对机器生成内容的二元分类。

Result: 作者提出的编码器能够达到0.97至0.99的AUROC和0.89至0.94的宏观F1分数。与现有方法相比，在512-token输入下，延迟降低了8-12倍，峰值VRAM减少了3-5倍。在跨生成器漂移和对抗性转换下，性能仍能保持洁净AUROC的92%以上。

Conclusion: 本研究证明了在二元分类任务中，通过微调编码器型小型语言模型，可以在大幅降低计算成本的同时，显著优于大型语言模型检测器，并且在各种复杂场景下表现出强大的鲁棒性。

Abstract: The prevalence of Large Language Models (LLMs) for generating multilingual
text and source code has only increased the imperative for machine-generated
content detectors to be accurate and efficient across domains. Current
detectors, predominantly utilizing zero-shot methods, such as Fast DetectGPT or
GPTZero, either incur high computational cost or lack sufficient accuracy,
often with a trade-off between the two, leaving room for further improvement.
To address these gaps, we propose the fine-tuning of encoder-only Small
Language Models (SLMs), in particular, the pre-trained models of RoBERTA and
CodeBERTa using specialized datasets on source code and other natural language
to prove that for the task of binary classification, SLMs outperform LLMs by a
huge margin whilst using a fraction of compute. Our encoders achieve AUROC $=
0.97$ to $0.99$ and macro-F1 $0.89$ to $0.94$ while reducing latency by
$8$-$12\times$ and peak VRAM by $3$-$5\times$ at $512$-token inputs. Under
cross-generator shifts and adversarial transformations (paraphrase,
back-translation; code formatting/renaming), performance retains $\geq 92%$ of
clean AUROC. We release training and evaluation scripts with seeds and configs;
a reproducibility checklist is also included.

</details>


### [6] [Improving Topic Modeling of Social Media Short Texts with Rephrasing: A Case Study of COVID-19 Related Tweets](https://arxiv.org/abs/2510.18908)
*Wangjiaxuan Xin,Shuhua Yin,Shi Chen,Yaorong Ge*

Main category: cs.CL

TL;DR: 该研究提出了 TM-Rephrase 框架，利用大型语言模型（LLMs）将推文改写为更标准化和正式的语言，以改善主题模型的性能，尤其是在处理社交媒体短文本时。


<details>
  <summary>Details</summary>
Motivation: 社交媒体短文本的简洁性、非正式性和噪音会阻碍传统主题模型的有效性，导致主题不连贯或冗余，难以解释。

Method: 本研究开发了 TM-Rephrase 框架，一个与模型无关的框架，它利用大型语言模型（LLMs）在主题建模之前将原始推文改写成更标准化和正式的语言。研究使用了包含 25,027 条与 COVID-19 相关的推文数据集，并调查了两种改写策略（通用改写和口语到正式改写）对多种主题建模方法的影响。

Result: TM-Rephrase 在三个衡量主题建模性能的指标（主题连贯性、主题独特性和主题多样性）上有所改善，同时减少了大多数主题建模算法的主题冗余，其中口语到正式的改写策略带来了最大的性能提升，尤其对 Latent Dirichlet Allocation (LDA) 算法效果显著。

Conclusion: 本研究为增强公共卫生相关社交媒体分析中的主题建模提供了一种模型无关的方法，对于更好地理解健康危机及其他重要领域中的公共话语具有广泛的意义。

Abstract: Social media platforms such as Twitter (now X) provide rich data for
analyzing public discourse, especially during crises such as the COVID-19
pandemic. However, the brevity, informality, and noise of social media short
texts often hinder the effectiveness of traditional topic modeling, producing
incoherent or redundant topics that are often difficult to interpret. To
address these challenges, we have developed \emph{TM-Rephrase}, a
model-agnostic framework that leverages large language models (LLMs) to
rephrase raw tweets into more standardized and formal language prior to topic
modeling. Using a dataset of 25,027 COVID-19-related Twitter posts, we
investigate the effects of two rephrasing strategies, general- and
colloquial-to-formal-rephrasing, on multiple topic modeling methods. Results
demonstrate that \emph{TM-Rephrase} improves three metrics measuring topic
modeling performance (i.e., topic coherence, topic uniqueness, and topic
diversity) while reducing topic redundancy of most topic modeling algorithms,
with the colloquial-to-formal strategy yielding the greatest performance gains
and especially for the Latent Dirichlet Allocation (LDA) algorithm. This study
contributes to a model-agnostic approach to enhancing topic modeling in public
health related social media analysis, with broad implications for improved
understanding of public discourse in health crisis as well as other important
domains.

</details>


### [7] [Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection](https://arxiv.org/abs/2510.18909)
*Hongyi He,Xiao Liu,Zhenghao Lin,Mingni Tang,Yi Cheng,Jintao Wang,Wenjie Li,Peng Cheng,Yeyun Gong*

Main category: cs.CL

TL;DR: 本文提出了正交多样性感知选择（ODiS）算法，通过将数据评估的多维度分数分解为正交特征维度，来在预训练大语言模型时平衡数据的质量和多样性，解决了传统基于分数选择方法可能忽略多样性的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的预训练数据质量至关重要，它包含事实可靠性、语义价值和多样性。现有基于分数选择数据的方法往往会因为忽略了多样性而导致性能下降，这说明了数据集分数和下游基准测试结果之间存在非单调性。

Method: 本文提出了正交多样性感知选择（ODiS）算法。该算法首先从语言质量、知识质量和理解难度等多个维度评估数据。然后，通过主成分分析（PCA）对多维分数进行去相关处理，得到正交评估维度。接着，训练一个基于Roberta的评分器，将数据回归到PCA投影分数上，以实现大规模语料库的可扩展推理。最后，ODiS在每个正交维度内选择得分最高的数据来构建训练数据集。

Result: ODiS选择的数据在不同维度之间的重叠度小于2%，这证实了维度之间的正交性。更重要的是，使用ODiS选择的数据训练的模型在下游基准测试中显著优于其他基线模型。

Conclusion: 为了提高大语言模型在下游任务中的表现，在数据选择过程中，正交的、多样性感知的数据选择是必不可少的。ODiS算法通过对多维度评估分数进行正交分解，有效地平衡了数据质量和多样性，从而提升了模型的性能。

Abstract: High-quality pre-training data is crutial for large language models, where
quality captures factual reliability and semantic value, and diversity ensures
broad coverage and distributional heterogeneity. Existing approaches typically
rely on single or multiple-dimensional score-based selection. However, directly
selecting top-scored data often degrades performance, and sampling from a
broader range is required to recover results. The above non-monotonicity
between dataset scores and downstream benchmark results reveals a fundamental
bias: score-based methods collapse correlated dimensions, causing top-scored
data to appear high-quality while systematically overlooking diversity. We
argue that ensuring diversity requires decomposing correlated metrics into
orthogonal feature dimensions, from which the top-scored data can be directly
selected. Therefore, we proposed the Orthogonal Diversity-Aware Selection
(ODiS) algorithm, which preserves both quality and diversity during data
selection. First, ODiS evaluates data from multiple dimensions, covering
language quality, knowledge quality, and comprehension difficulty. The
multi-dimensional scores are then decorrelated via Principal Component Analysis
(PCA), yielding orthogonal evaluation dimensions. For each dimension, a
Roberta-based scorer is trained to regress the data onto PCA-projected scores,
enabling scalable inference on large corpora. Finally, ODiS constructs the
training dataset by selecting top-scored data within each orthogonal dimension,
thereby ensuring both quality and diversity. Empirical results show that
ODiS-selected data exhibit less than 2\% inter-dimension overlap, confirming
orthogonality between dimensions. More importantly, models trained with
ODiS-selected data significantly outperform other baselines on downstream
benchmarks, highlighting the necessity of orthogonal, diversity-aware data
selection for LLMs.

</details>


### [8] [Context-aware Fairness Evaluation and Mitigation in LLMs](https://arxiv.org/abs/2510.18914)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 这篇论文提出了一种动态的、可逆的、基于剪枝的框架，用于在推理时减少大型语言模型中的不良行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中嵌入的偏差会导致不公平、不一致性漂移、有害内容放大以及在长时间对话中传播不需要的模式。现有的训练时或以数据为中心的方法计算成本高昂，部署后不可逆，并且难以适应新的对话上下文。

Method: 提出了一种动态的、可逆的、基于剪枝的框架，该框架能够检测上下文感知的神经元激活，并应用自适应掩码来调节其在生成过程中的影响。

Result: 与现有方法相比，该方法提供了一种细粒度、内存感知的缓解方案，可以在多语言的单轮和多轮对话中保持知识，并提供更连贯的行为。

Conclusion: 该框架能够实现真实世界对话式人工智能中的动态公平性控制，有效减少大型语言模型中的不良行为。

Abstract: Large language models often display undesirable behaviors embedded in their
internal representations, undermining fairness, inconsistency drift,
amplification of harmful content, and the propagation of unwanted patterns
during extended dialogue and conversations. Although training-time or
data-centric methods attempt to reduce these effects, they are computationally
expensive, irreversible once deployed, and slow to adapt to new conversational
contexts. Pruning-based methods provide a flexible and transparent way to
reduce bias by adjusting the neurons responsible for certain behaviors.
However, most existing approaches are static; once a neuron is removed, the
model loses the ability to adapt when the conversation or context changes. To
address this, we propose a dynamic, reversible, pruning-based framework that
detects context-aware neuron activations and applies adaptive masking to
modulate their influence during generation. Our inference-time solution
provides fine-grained, memory-aware mitigation with knowledge-preserved, more
coherent behavior across multilingual single- and multi-turn dialogues,
enabling dynamic fairness control in real-world conversational AI.

</details>


### [9] [MMAO-Bench: MultiModal All in One Benchmark Reveals Compositional Law between Uni-modal and Omni-modal in OmniModels](https://arxiv.org/abs/2510.18915)
*Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Xuezhi Cao*

Main category: cs.CL

TL;DR: MMAO-Bench是一个新型多模态基准测试，用于评估统一视觉、音频和语言多模态模型的理解能力。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型仍在从单模态理解向统一视觉、音频和语言模态发展，但明确单模态和全模态之间的相关性仍存在困难。为了促进全模态模型的智能演进，这需要一个全面的评估。

Method: 我们提出了一个新颖、高质量和多样性的多模态基准测试——多模态一体化基准测试（MMAO-Bench）。该基准测试包含1880个人工策划样本，涵盖44种任务类型，以及一种创新的多步骤开放式问题类型，可以更好地评估复杂的推理任务。

Result: 实验结果显示了跨模态和单模态性能之间的组合规律，并且全模态能力在弱模型上表现为瓶颈效应，而在强模型上则表现出协同促进作用。

Conclusion: MMAO-Bench为评估和推动全模态模型的发展提供了一个全面的工具，并揭示了全模态能力与模型强度之间的关系。

Abstract: Multimodal Large Languages models have been progressing from uni-modal
understanding toward unifying visual, audio and language modalities,
collectively termed omni models. However, the correlation between uni-modal and
omni-modal remains unclear, which requires comprehensive evaluation to drive
omni model's intelligence evolution. In this work, we propose a novel, high
quality and diversity omni model benchmark, MultiModal All in One Benchmark
(MMAO-Bench), which effectively assesses both uni-modal and omni-modal
understanding capabilities. The benchmark consists of 1880 human curated
samples, across 44 task types, and a innovative multi-step open-ended question
type that better assess complex reasoning tasks. Experimental result shows the
compositional law between cross-modal and uni-modal performance and the
omni-modal capability manifests as a bottleneck effect on weak models, while
exhibiting synergistic promotion on strong models.

</details>


### [10] [A Graph Signal Processing Framework for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2510.19117)
*Valentin Noël*

Main category: cs.CL

TL;DR: 这篇论文提出了一种通过谱分析框架来区分大型语言模型中的事实推理和幻觉的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然取得了显著的成果，但区分事实推理和幻觉仍然具有挑战性。

Method: 本文提出了一个谱分析框架，将Transformer层建模为由注意力引起的动态图，将token嵌入作为图上的信号。通过图信号处理，定义了包括Dirichlet能量、谱熵和高频能量比在内的诊断指标，并与计算稳定性建立了理论联系。

Result: 实验表明，事实陈述表现出一致的“能量山”行为和低频收敛，而不同类型的幻觉显示出不同的特征。逻辑矛盾会使谱线不稳定，语义错误保持稳定但连接性漂移，替换幻觉显示出中间扰动。一个使用谱特征的简单检测器达到了88.75%的准确率，而基于困惑度的基线准确率为75%。

Conclusion: 这些发现表明，谱几何可以捕获推理模式和错误行为，可能为大型语言模型中的幻觉检测提供一个框架。

Abstract: Large language models achieve impressive results but distinguishing factual
reasoning from hallucinations remains challenging. We propose a spectral
analysis framework that models transformer layers as dynamic graphs induced by
attention, with token embeddings as signals on these graphs. Through graph
signal processing, we define diagnostics including Dirichlet energy, spectral
entropy, and high-frequency energy ratios, with theoretical connections to
computational stability. Experiments across GPT architectures suggest universal
spectral patterns: factual statements exhibit consistent "energy mountain"
behavior with low-frequency convergence, while different hallucination types
show distinct signatures. Logical contradictions destabilize spectra with large
effect sizes ($g>1.0$), semantic errors remain stable but show connectivity
drift, and substitution hallucinations display intermediate perturbations. A
simple detector using spectral signatures achieves 88.75% accuracy versus 75%
for perplexity-based baselines, demonstrating practical utility. These findings
indicate that spectral geometry may capture reasoning patterns and error
behaviors, potentially offering a framework for hallucination detection in
large language models.

</details>


### [11] [Training-Free Spectral Fingerprints of Voice Processing in Transformers](https://arxiv.org/abs/2510.19131)
*Valentin Noël*

Main category: cs.CL

TL;DR: 本文分析了不同Transformer架构在语言计算中的连接模式，发现它们留下了“计算指纹”。研究通过图信号处理和代数连通性分析，揭示了不同模型在处理语音交替时的独特模式，并证明这些模式与模型行为和训练偏好密切相关。


<details>
  <summary>Details</summary>
Motivation: 探索不同Transformer架构在执行相同语言计算时，是否会通过其独特的连接模式留下可检测的“计算指纹”，并研究这些指纹如何反映模型的训练重点和行为差异。

Method: 1. 使用图信号处理技术处理注意力诱导的token图。2. 跟踪20种语言和三种模型家族在语音交替下代数连通性（Fiedler值，$\\Delta\\lambda_2$）的变化，特别关注预设的早期层（2-5层）。3. 通过注意力头消融实验验证这些光谱特征的功能相关性。

Result: 1. Phi-3-Mini模型在早期层（2-5层）表现出明显的英语特定中断（$\\overline{\\Delta\\lambda_2}_{[2,5]}\\!\approx\\!-0.446$），而其他19种语言的影响微乎其微，这与该模型主要针对英语使用的公开文档一致。2. Qwen2.5-7B模型显示出小的、分布式的变化，在形态丰富的语言中表现最显著。3. LLaMA-3.2-1B模型表现出系统但微弱的响应。4. 这些光谱特征与行为差异密切相关（Phi-3: r=-0.976），并通过注意力头消融实验证实了其功能相关性。

Conclusion: 训练重点可以在Transformer架构中留下可检测的计算印记，表现为语法转换过程中可测量的连接模式。这项研究提供了一个简单、无需训练的诊断框架，可用于揭示架构偏差并支持模型可靠性分析，并且该框架还可以区分推理模式。

Abstract: Different transformer architectures implement identical linguistic
computations via distinct connectivity patterns, yielding model imprinted
``computational fingerprints'' detectable through spectral analysis. Using
graph signal processing on attention induced token graphs, we track changes in
algebraic connectivity (Fiedler value, $\Delta\lambda_2$) under voice
alternation across 20 languages and three model families, with a prespecified
early window (layers 2--5). Our analysis uncovers clear architectural
signatures: Phi-3-Mini shows a dramatic English specific early layer disruption
($\overline{\Delta\lambda_2}_{[2,5]}\!\approx\!-0.446$) while effects in 19
other languages are minimal, consistent with public documentation that
positions the model primarily for English use. Qwen2.5-7B displays small,
distributed shifts that are largest for morphologically rich languages, and
LLaMA-3.2-1B exhibits systematic but muted responses. These spectral signatures
correlate strongly with behavioral differences (Phi-3: $r=-0.976$) and are
modulated by targeted attention head ablations, linking the effect to early
attention structure and confirming functional relevance. Taken together, the
findings are consistent with the view that training emphasis can leave
detectable computational imprints: specialized processing strategies that
manifest as measurable connectivity patterns during syntactic transformations.
Beyond voice alternation, the framework differentiates reasoning modes,
indicating utility as a simple, training free diagnostic for revealing
architectural biases and supporting model reliability analysis.

</details>


### [12] [ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge](https://arxiv.org/abs/2510.18941)
*Zhilin Wang,Jaehun Jung,Ximing Lu,Shizhe Diao,Ellie Evans,Jiaqi Zeng,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.CL

TL;DR: 本文介绍了ProfBench，一个由人类专家在物理学博士、化学博士、金融MBA和咨询MBA等专业领域评估的7000多个响应-标准对的基准。ProfBench旨在评估大型语言模型在处理专业文档、综合信息和生成综合报告方面的表现。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）的进展通常受限于验证响应的挑战，这使得评估仅限于数学、编程和简短问答等任务。然而，许多实际应用需要评估LLMs在处理专业文档、综合信息和生成综合报告方面的能力。

Method: 本文引入了ProfBench：一个由拥有专业知识的人类专家（包括物理学博士、化学博士、金融MBA和咨询MBA）评估的7000多个响应-标准对的基准。为了经济高效地评估ProfBench的评分标准，我们构建了鲁棒且经济的LLM-Judges，通过缓解自我增强偏差并将评估成本降低2-3个数量级，使其对更广泛的社区公平且易于访问。

Result: 研究结果表明，ProfBench即使对于最先进的LLM也构成了重大挑战，GPT-5-high等表现最佳的模型总体性能也仅达到65.9%。此外，我们发现了专有模型和开源模型之间显著的性能差异，并深入探讨了扩展思维在解决复杂专业领域任务中的作用。

Conclusion: ProfBench为评估LLMs在专业文档处理、信息综合和报告生成方面的能力提供了一个有价值的基准。研究结果突出了当前LLMs在这些复杂任务中面临的挑战，并强调了未来改进的领域，特别是在提高开放权重模型的性能方面。

Abstract: Evaluating progress in large language models (LLMs) is often constrained by
the challenge of verifying responses, limiting assessments to tasks like
mathematics, programming, and short-form question-answering. However, many
real-world applications require evaluating LLMs in processing professional
documents, synthesizing information, and generating comprehensive reports in
response to user queries. We introduce ProfBench: a set of over 7000
response-criterion pairs as evaluated by human-experts with professional
knowledge across Physics PhD, Chemistry PhD, Finance MBA and Consulting MBA. We
build robust and affordable LLM-Judges to evaluate ProfBench rubrics, by
mitigating self-enhancement bias and reducing the cost of evaluation by 2-3
orders of magnitude, to make it fair and accessible to the broader community.
Our findings reveal that ProfBench poses significant challenges even for
state-of-the-art LLMs, with top-performing models like GPT-5-high achieving
only 65.9\% overall performance. Furthermore, we identify notable performance
disparities between proprietary and open-weight models and provide insights
into the role that extended thinking plays in addressing complex,
professional-domain tasks. Data:
https://huggingface.co/datasets/nvidia/ProfBench and Code:
https://github.com/NVlabs/ProfBench

</details>


### [13] [Dynamic Evaluation for Oversensitivity in LLMs](https://arxiv.org/abs/2510.19005)
*Sophia Xiao Pu,Sitao Cheng,Xin Eric Wang,William Yang Wang*

Main category: cs.CL

TL;DR: 这篇文章介绍了语言模型在处理良性提示时出现过度敏感的问题，并提出了一种名为 OVERBENCH 的动态基准测试方法来解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试依赖于静态数据集，随着模型的演进，这些数据集会过时，导致数据污染和评估能力下降。

Method: 开发了一个框架，该框架动态生成模型特定的挑战性数据集，捕捉新兴的防御模式，并与每个模型的独特行为保持一致。在此基础上，构建了 OVERBENCH 基准测试，该测试汇集了来自不同 LLM 系列的数据集，包含来自 25 个模型的 450,000 个样本。

Result: OVERBENCH 提供了一个动态且不断演进的过度敏感性视角，允许随着模型的进步持续监控防御触发器，突出静态数据集 overlooked 的漏洞。

Conclusion: OVERBENCH 解决了现有静态数据集的局限性，为评估语言模型的过度敏感性提供了一种动态和持续的解决方案。

Abstract: Oversensitivity occurs when language models defensively reject prompts that
are actually benign. This behavior not only disrupts user interactions but also
obscures the boundary between harmful and harmless content. Existing benchmarks
rely on static datasets that degrade overtime as models evolve, leading to data
contamination and diminished evaluative power. To address this, we develop a
framework that dynamically generates model-specific challenging datasets,
capturing emerging defensive patterns and aligning with each model's unique
behavior. Building on this approach, we construct OVERBENCH, a benchmark that
aggregates these datasets across diverse LLM families, encompassing 450,000
samples from 25 models. OVERBENCH provides a dynamic and evolving perspective
on oversensitivity, allowing for continuous monitoring of defensive triggers as
models advance, highlighting vulnerabilities that static datasets overlook.

</details>


### [14] [Are they lovers or friends? Evaluating LLMs' Social Reasoning in English and Korean Dialogues](https://arxiv.org/abs/2510.19028)
*Eunsu Kim,Junyeong Park,Juhyun Oh,Kiwoong Park,Seyoung Song,A. Seza Dogruoz,Najoung Kim,Alice Oh*

Main category: cs.CL

TL;DR: 该研究介绍了SCRIPTS数据集，旨在评估大型语言模型（LLMs）在人际交往中进行社会推理的能力。研究发现，LLMs在社会推理方面存在显著局限性，尤其是在韩语数据集上的表现不佳，并且容易选择不合理的关系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在人机交互中扮演着越来越重要的角色，因此它们在人际情境中的社会推理能力至关重要。

Method: 研究引入了SCRIPTS数据集，包含1000个来自电影剧本的英语和韩语对话。任务是评估模型推断对话者之间人际关系（例如，朋友、姐妹、恋人）的社会推理能力。每个对话都由来自韩国和美国的母语（或同等水平）的韩语和英语使用者标注了概率关系标签（“极有可能”、“不太可能”、“不可能”）。研究评估了九种模型在此任务上的表现。

Result: 当前专有LLMs在英语数据集上的准确率约为75-80%，而在韩语数据集上的表现下降到58-69%。更引人注目的是，模型在10-25%的响应中选择了“不可能”的关系。此外，研究发现，思维模型和思维链提示（对一般推理有效）对社会推理的益处很小，并且偶尔会放大社会偏见。

Conclusion: 目前的LLMs在社会推理能力方面存在显著局限性，这表明需要努力开发具有社会意识的语言模型。

Abstract: As large language models (LLMs) are increasingly used in human-AI
interactions, their social reasoning capabilities in interpersonal contexts are
critical. We introduce SCRIPTS, a 1k-dialogue dataset in English and Korean,
sourced from movie scripts. The task involves evaluating models' social
reasoning capability to infer the interpersonal relationships (e.g., friends,
sisters, lovers) between speakers in each dialogue. Each dialogue is annotated
with probabilistic relational labels (Highly Likely, Less Likely, Unlikely) by
native (or equivalent) Korean and English speakers from Korea and the U.S.
Evaluating nine models on our task, current proprietary LLMs achieve around
75-80% on the English dataset, whereas their performance on Korean drops to
58-69%. More strikingly, models select Unlikely relationships in 10-25% of
their responses. Furthermore, we find that thinking models and chain-of-thought
prompting, effective for general reasoning, provide minimal benefits for social
reasoning and occasionally amplify social biases. Our findings reveal
significant limitations in current LLMs' social reasoning capabilities,
highlighting the need for efforts to develop socially-aware language models.

</details>


### [15] [Re:Member: Emotional Question Generation from Personal Memories](https://arxiv.org/abs/2510.19030)
*Zackary Rackauckas,Nobuaki Minematsu,Julia Hirschberg*

Main category: cs.CL

TL;DR: Re:Member是一个利用情感表达和记忆接地交互来增强第二语言学习的系统，它通过个人视频和风格化口语问题，结合情感识别和生成技术，促进情感回忆和会话参与。


<details>
  <summary>Details</summary>
Motivation: 探索情感表达和记忆接地交互如何支持更具吸引力的第二语言（L2）学习。

Method: Re:Member系统利用用户的个人视频，生成目标语言的风格化口语问题，以鼓励情感回忆和会话参与。系统将情感语气与视觉语境对齐，使用如耳语或深夜语调等表达性语音风格来唤起特定情绪。它结合了基于WhisperX的转录对齐、三帧视觉采样和Style-BERT-VITS2进行情感合成，形成一个模块化的生成流程。

Result: Re:Member作为一个风格化的交互探测器，强调了情感和个人媒体在以学习者为中心的教育技术中的作用。

Conclusion: Re:Member系统成功地展示了情感表达和记忆在第二语言学习中的重要性，通过创新的技术组合，为学习者提供了更具吸引力和个性化的学习体验。

Abstract: We present Re:Member, a system that explores how emotionally expressive,
memory-grounded interaction can support more engaging second language (L2)
learning. By drawing on users' personal videos and generating stylized spoken
questions in the target language, Re:Member is designed to encourage affective
recall and conversational engagement. The system aligns emotional tone with
visual context, using expressive speech styles such as whispers or late-night
tones to evoke specific moods. It combines WhisperX-based transcript alignment,
3-frame visual sampling, and Style-BERT-VITS2 for emotional synthesis within a
modular generation pipeline. Designed as a stylized interaction probe,
Re:Member highlights the role of affect and personal media in learner-centered
educational technologies.

</details>


### [16] [When Can We Trust LLMs in Mental Health? Large-Scale Benchmarks for Reliable LLM Evaluation](https://arxiv.org/abs/2510.19032)
*Abeer Badawi,Elahe Rahimi,Md Tahmid Rahman Laskar,Sheri Grach,Lindsay Bertrand,Lames Danok,Jimmy Huang,Frank Rudzicz,Elham Dolatabadi*

Main category: cs.CL

TL;DR: 该研究介绍了MentalBench-100k和MentalAlign-70k两个基准，用于评估LLMs在心理健康支持方面的表现。研究发现LLM评委在认知属性上可靠性强，但在同理心、安全性和相关性方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在心理健康支持方面的表现极具挑战性，因为治疗性对话在情感和认知上都非常复杂。现有基准的规模和可靠性有限，通常依赖合成数据或社交媒体数据，并且缺乏评估自动化裁判何时值得信任的框架。

Method: 本文引入了两个基准来解决大规模对话数据集和裁判可靠性评估的需求：MentalBench-100k 和 MentalAlign-70k。MentalBench-100k 整合了来自三个真实情景数据集的10,000个单轮对话，每个对话都配有九个LLM生成的回复，共产生100,000个回复对。MentalAlign-70k 通过将四个高性能LLM裁判与人类专家在70,000个评分上进行比较，重新构建了评估框架，这些评分基于七个属性，分为认知支持得分（CSS）和情感共鸣得分（ARS）。研究采用了情感认知一致性框架，这是一种使用组内相关系数（ICC）和置信区间的统计方法，以量化LLM裁判与人类专家之间的一致性、连贯性和偏差。

Result: 分析揭示了LLM裁判的系统性夸大，对于指导和信息量等认知属性具有很强的可靠性，但对于同理心的准确性有所降低，并且在安全性和相关性方面存在一定程度的不可靠性。

Conclusion: 本研究的贡献为心理健康领域LLM的可靠、大规模评估奠定了新的方法论和实证基础。

Abstract: Evaluating Large Language Models (LLMs) for mental health support is
challenging due to the emotionally and cognitively complex nature of
therapeutic dialogue. Existing benchmarks are limited in scale, reliability,
often relying on synthetic or social media data, and lack frameworks to assess
when automated judges can be trusted. To address the need for large-scale
dialogue datasets and judge reliability assessment, we introduce two benchmarks
that provide a framework for generation and evaluation. MentalBench-100k
consolidates 10,000 one-turn conversations from three real scenarios datasets,
each paired with nine LLM-generated responses, yielding 100,000 response pairs.
MentalAlign-70k}reframes evaluation by comparing four high-performing LLM
judges with human experts across 70,000 ratings on seven attributes, grouped
into Cognitive Support Score (CSS) and Affective Resonance Score (ARS). We then
employ the Affective Cognitive Agreement Framework, a statistical methodology
using intraclass correlation coefficients (ICC) with confidence intervals to
quantify agreement, consistency, and bias between LLM judges and human experts.
Our analysis reveals systematic inflation by LLM judges, strong reliability for
cognitive attributes such as guidance and informativeness, reduced precision
for empathy, and some unreliability in safety and relevance. Our contributions
establish new methodological and empirical foundations for reliable,
large-scale evaluation of LLMs in mental health. We release the benchmarks and
codes at: https://github.com/abeerbadawi/MentalBench/

</details>


### [17] [From Memorization to Generalization: Fine-Tuning Large Language Models for Biomedical Term-to-Identifier Normalization](https://arxiv.org/abs/2510.19036)
*Suswitha Pericharla,Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在生物医学术语标准化任务中的表现，发现其在不同术语体系（如GO、HPO、GENE）上的记忆化和泛化能力差异显著，并揭示了标识符的普及度和词汇化程度是影响微调效果的关键因素。


<details>
  <summary>Details</summary>
Motivation: 自动化术语规范化对于有效的生物医学数据整合至关重要，它能将自然语言生物医学术语映射到标准化标识符，实现语义互操作性。大型语言模型（LLMs）在此任务中展现出潜力，但其性能在不同术语体系上表现不一，因此需要深入评估其在记忆化和泛化方面的表现。

Method: 研究评估了Llama 3.1 8B模型在多个生物医学本体论（包括GO、HPO和GENE）上的记忆化（训练术语性能）和泛化（验证术语性能）。同时，还比较了GPT-4o和Llama变体的基线准确性，并进行了嵌入分析以探究术语与标识符之间的语义对齐情况。

Result: GO映射显示出显著的记忆化提升（术语到标识符的准确性提高了77%），而HPO的提升很小。泛化仅发生在蛋白质-基因（GENE）映射中（提高了13.9%），而HPO和GO的微调几乎没有产生泛化效果。GPT-4o在所有术语体系上的基线准确性均优于两种Llama变体。嵌入分析显示基因符号和蛋白质名称之间存在紧密的语义对齐，而GO和HPO的术语与标识符之间的对齐较弱，这与有限的词汇化一致。

Conclusion: 微调的成功取决于标识符的普及度和词汇化这两个相互作用的因素。普及的标识符在预训练期间更容易被遇到，从而增强记忆化。词汇化标识符（如基因符号）能够实现语义泛化。相反，GO和HPO中的任意标识符将模型限制为死记硬背。这些发现为何时微调能增强事实回忆以及何时因稀疏或非词汇化标识符而失败提供了预测框架。

Abstract: Effective biomedical data integration depends on automated term
normalization, the mapping of natural language biomedical terms to standardized
identifiers. This linking of terms to identifiers is essential for semantic
interoperability. Large language models (LLMs) show promise for this task but
perform unevenly across terminologies. We evaluated both memorization
(training-term performance) and generalization (validation-term performance)
across multiple biomedical ontologies. Fine-tuning Llama 3.1 8B revealed marked
differences by terminology. GO mappings showed strong memorization gains (up to
77% improvement in term-to-identifier accuracy), whereas HPO showed minimal
improvement. Generalization occurred only for protein-gene (GENE) mappings
(13.9% gain), while fine-tuning for HPO and GO yielded negligible transfer.
Baseline accuracy varied by model scale, with GPT-4o outperforming both Llama
variants for all terminologies. Embedding analyses showed tight semantic
alignment between gene symbols and protein names but weak alignment between
terms and identifiers for GO or HPO, consistent with limited lexicalization.
Fine-tuning success depended on two interacting factors: identifier popularity
and lexicalization. Popular identifiers were more likely encountered during
pretraining, enhancing memorization. Lexicalized identifiers, such as gene
symbols, enabled semantic generalization. By contrast, arbitrary identifiers in
GO and HPO constrained models to rote learning. These findings provide a
predictive framework for when fine-tuning enhances factual recall versus when
it fails due to sparse or non-lexicalized identifiers.

</details>


### [18] [That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation](https://arxiv.org/abs/2510.19116)
*Jaesung Bae,Cameron Churchwell,Mitchell Hermon,Tsun-An Hsieh,Jocelyn Xu,Yekaterina Yegorova,Mark Hasegawa-Johnson,Heng Ji*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在参数知识与提示中的冲突信息不一致时如何表现，并提出了一个领域无关的框架来构建和解释这些冲突。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理参数知识与冲突信息不一致时，其行为表现的研究。

Method: 提出了一种领域无关的框架，用于构建和解释知识冲突，并设计了一种新颖的评估方法和针对代码冲突场景的数据集。

Result: 实验表明，足够大的LLMs在其参数中编码了知识冲突的概念，检测准确率高达80.65%。基于这些见解，激活级别操纵可以将操纵成功率提高12.6%。

Conclusion: LLMs能够编码知识冲突的概念，并且激活级别操纵可以有效提高模型在处理冲突信息时的性能，但效果取决于模型大小、任务领域和操纵方向之间的平衡。

Abstract: This paper investigates how large language models (LLMs) behave when faced
with discrepancies between their parametric knowledge and conflicting
information contained in a prompt. Building on prior question-answering (QA)
research, we extend the investigation of knowledge conflicts to the realm of
code generation. We propose a domain-agnostic framework for constructing and
interpreting such conflicts, along with a novel evaluation method and dataset
tailored to code conflict scenarios. Our experiments indicate that sufficiently
large LLMs encode the notion of a knowledge conflict in their parameters,
enabling us to detect knowledge conflicts with up to \textbf{80.65\%} accuracy.
Building on these insights, we show that activation-level steering can achieve
up to a \textbf{12.6\%} improvement in steering success over a random baseline.
However, effectiveness depends critically on balancing model size, task domain,
and steering direction. The experiment code and data will be made publicly
available after acceptance.

</details>


### [19] [Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges](https://arxiv.org/abs/2510.19144)
*Cheng Huang,Nyima Tashi,Fan Gao,Yutong Liu,Jiahao Li,Hao Tian,Siyang Jiang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Jin Zhang,Xiao Feng,Hao Wang,Jie Tang,Guojie Tang,Xiangxiang Wang,Jia Zhang,Tsengdar Lee,Yongbin Yu*

Main category: cs.CL

TL;DR: 这篇论文全面概述了藏语AI研究的现状、面临的挑战、现有资源和工具，并指出了未来的发展方向，旨在促进藏语AI生态系统的建设。


<details>
  <summary>Details</summary>
Motivation: 尽管对服务不足语言的AI系统开发兴趣日益增长，但由于缺乏可访问的数据资源、标准化的基准和专用工具，藏语AI受到的关注有限。

Method: 通过对文本和语音数据资源、NLP任务、机器翻译、语音识别以及LLM的最新发展进行调查，系统地分类现有数据集和工具，评估不同任务中使用的方法，并尽可能比较性能。

Result: 识别出数据稀疏性、拼写变异和缺乏统一评估指标等主要瓶颈；讨论了跨语言迁移、多模态学习和社区驱动资源创建的潜力。

Conclusion: 本调查旨在为未来藏语AI研究提供基础参考，并鼓励合作，为低资源语言构建一个包容和可持续的AI生态系统。

Abstract: Tibetan, one of the major low-resource languages in Asia, presents unique
linguistic and sociocultural characteristics that pose both challenges and
opportunities for AI research. Despite increasing interest in developing AI
systems for underrepresented languages, Tibetan has received limited attention
due to a lack of accessible data resources, standardized benchmarks, and
dedicated tools. This paper provides a comprehensive survey of the current
state of Tibetan AI in the AI domain, covering textual and speech data
resources, NLP tasks, machine translation, speech recognition, and recent
developments in LLMs. We systematically categorize existing datasets and tools,
evaluate methods used across different tasks, and compare performance where
possible. We also identify persistent bottlenecks such as data sparsity,
orthographic variation, and the lack of unified evaluation metrics.
Additionally, we discuss the potential of cross-lingual transfer, multi-modal
learning, and community-driven resource creation. This survey aims to serve as
a foundational reference for future work on Tibetan AI research and encourages
collaborative efforts to build an inclusive and sustainable AI ecosystem for
low-resource languages.

</details>


### [20] [Think Straight, Stop Smart: Structured Reasoning for Efficient Multi-Hop RAG](https://arxiv.org/abs/2510.19171)
*Jihwan Bang,Juntae Lee,Seunghan Yang,Sungha Choi*

Main category: cs.CL

TL;DR: TSSS：一种高效的多跳检索增强生成（RAG）框架。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳RAG迭代提示方法效率低下，存在重复生成和随机停止的问题，导致token使用过多和终止不稳定。

Method: TSSS框架，包括：1. 基于模板的推理，缓存重复前缀并将子查询锚定到主问题，减少token生成成本并促进稳定推理；2. 基于检索器的终止器，一旦额外子查询陷入重复，就确定性地停止推理。

Result: 在HotpotQA、2WikiMultiHop和MuSiQue数据集上，TSSS在RAG-CoT方法中实现了最先进的准确性和具有竞争力的效率。

Conclusion: TSSS通过结构化推理和终止控制分离，实现了更快的推理和更可靠的答案，尤其适用于设备端推理等效率受限的场景。

Abstract: Multi-hop retrieval-augmented generation (RAG) is a promising strategy for
complex reasoning, yet existing iterative prompting approaches remain
inefficient. They often regenerate predictable token sequences at every step
and rely on stochastic stopping, leading to excessive token usage and unstable
termination. We propose TSSS (Think Straight, Stop Smart), a structured
multi-hop RAG framework designed for efficiency. TSSS introduces (i) a
template-based reasoning that caches recurring prefixes and anchors sub-queries
to the main question, reducing token generation cost while promoting stable
reasoning, and (ii) a retriever-based terminator, which deterministically halts
reasoning once additional sub-queries collapse into repetition. This separation
of structured reasoning and termination control enables both faster inference
and more reliable answers. On HotpotQA, 2WikiMultiHop, and MuSiQue, TSSS
achieves state-of-the-art accuracy and competitive efficiency among RAG-CoT
approaches, highlighting its effectiveness in efficiency-constrained scenarios
such as on-device inference.

</details>


### [21] [When Facts Change: Probing LLMs on Evolving Knowledge with evolveQA](https://arxiv.org/abs/2510.19172)
*Nishanth Sridhar Nakshatri,Shamik Roy,Manoj Ghuhan Arivazhagan,Hanhan Zhou,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.CL

TL;DR: 该论文介绍了evolveQA，这是一个旨在评估大型语言模型（LLMs）处理时间动态知识能力的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有研究在评估LLMs处理时间知识冲突时，通常依赖于结构化知识库（如Wikidata），但这些基准侧重于流行实体，且缺乏动态结构来公平评估不同知识截止日期的LLMs。因此，需要一个新的基准来评估LLMs处理随时间演变的知识的能力。

Method: evolveQA基准是从3个真实的、带有时间戳的语料库构建的：AWS更新、Azure更改和WHO疾病爆发报告。该框架识别自然发生的知识演变，并生成针对不同LLM知识截止日期的带有“黄金答案”的问题。

Result: 通过对12个开源和闭源LLMs进行广泛评估，在3种知识探测格式下，evolveQA上的性能与静态知识问题相比，显著下降了31%。

Conclusion: evolveQA基线可以有效评估LLMs处理随时间演变的知识的能力，并发现LLMs在这方面存在显著的性能下降。

Abstract: LLMs often fail to handle temporal knowledge conflicts--contradictions
arising when facts evolve over time within their training data. Existing
studies evaluate this phenomenon through benchmarks built on structured
knowledge bases like Wikidata, but they focus on widely-covered,
easily-memorized popular entities and lack the dynamic structure needed to
fairly evaluate LLMs with different knowledge cut-off dates. We introduce
evolveQA, a benchmark specifically designed to evaluate LLMs on temporally
evolving knowledge, constructed from 3 real-world, time-stamped corpora: AWS
updates, Azure changes, and WHO disease outbreak reports. Our framework
identifies naturally occurring knowledge evolution and generates questions with
gold answers tailored to different LLM knowledge cut-off dates. Through
extensive evaluation of 12 open and closed-source LLMs across 3 knowledge
probing formats, we demonstrate significant performance drops of up to 31% on
evolveQA compared to static knowledge questions.

</details>


### [22] [Interpretable Question Answering with Knowledge Graphs](https://arxiv.org/abs/2510.19181)
*Kartikeya Aneja,Manasvi Srivastava,Subhayan Das,Nagender Aneja*

Main category: cs.CL

TL;DR: 本文介绍了一种不依赖大型语言模型（LLM）的检索增强生成（RAG）的知识图谱问答系统。


<details>
  <summary>Details</summary>
Motivation: 在缺乏大型语言模型（LLM）的检索增强生成（RAG）的情况下，探索一种问答系统的方法。

Method: 该系统首先预处理文档生成问答对，然后将问答对转换成知识图谱。接着，通过嵌入和模糊技术进行基于图的检索、重新排序和释义，以生成最终答案。

Result: 在CRAG基准测试中，使用LLAMA-3.2和GPT-3.5-Turbo进行LLM-as-a-judge评估，准确率分别为71.9%和54.4%。

Conclusion: 本文成功地提出了一种不依赖大型语言模型（LLM）的检索增强生成（RAG）的知识图谱问答系统，并在CRAG基准测试中取得了不错的准确率。

Abstract: This paper presents a question answering system that operates exclusively on
a knowledge graph retrieval without relying on retrieval augmented generation
(RAG) with large language models (LLMs). Instead, a small paraphraser model is
used to paraphrase the entity relationship edges retrieved from querying the
knowledge graph. The proposed pipeline is divided into two main stages. The
first stage involves pre-processing a document to generate sets of
question-answer (QA) pairs. The second stage converts these QAs into a
knowledge graph from which graph-based retrieval is performed using embeddings
and fuzzy techniques. The graph is queried, re-ranked, and paraphrased to
generate a final answer. This work includes an evaluation using LLM-as-a-judge
on the CRAG benchmark, which resulted in accuracies of 71.9% and 54.4% using
LLAMA-3.2 and GPT-3.5-Turbo, respectively.

</details>


### [23] [Modality Matching Matters: Calibrating Language Distances for Cross-Lingual Transfer in URIEL+](https://arxiv.org/abs/2510.19217)
*York Hay Ng,Aditya Khan,Xiang Lu,Matteo Salloum,Michael Zhou,Phuong H. Hoang,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个为跨语言传输提供类型匹配语言距离的框架，解决了现有语言知识库的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有语言知识库（如URIEL+）在跨语言传输方面存在两个主要限制：1. 它们单一的向量表示不适用于多样化的语言数据结构；2. 它们缺乏将各种信号聚合成一个综合分数的原则性方法。

Method: 本文提出了针对每种距离类型的新颖的、结构感知的表示方法：地理距离采用说话者加权分布，谱系距离采用双曲线嵌入，类型学距离采用潜在变量模型。然后，将这些信号统一成一个稳健的、与任务无关的复合距离。

Result: 在选择传输语言时，论文提出的表示方法和复合距离在各种NLP任务中持续提高了性能。

Conclusion: 本文提供了一个更具原则性和有效性的多语言研究工具包，通过类型匹配的语言距离框架，显著改善了跨语言传输任务的表现。

Abstract: Existing linguistic knowledge bases such as URIEL+ provide valuable
geographic, genetic and typological distances for cross-lingual transfer but
suffer from two key limitations. One, their one-size-fits-all vector
representations are ill-suited to the diverse structures of linguistic data,
and two, they lack a principled method for aggregating these signals into a
single, comprehensive score. In this paper, we address these gaps by
introducing a framework for type-matched language distances. We propose novel,
structure-aware representations for each distance type: speaker-weighted
distributions for geography, hyperbolic embeddings for genealogy, and a latent
variables model for typology. We unify these signals into a robust,
task-agnostic composite distance. In selecting transfer languages, our
representations and composite distances consistently improve performance across
a wide range of NLP tasks, providing a more principled and effective toolkit
for multilingual research.

</details>


### [24] [Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization](https://arxiv.org/abs/2510.19265)
*Yuto Tomikawa,Masaki Uto*

Main category: cs.CL

TL;DR: 本文提出了一种新的难度可控的多项选择题生成方法，该方法利用大型语言模型和直接偏好优化技术来提高难度控制的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经问题生成方法在控制难度方面存在局限性，具体表现为：无法直接生成多项选择题，这是教育中最常用的题型；在难度控制的准确性方面没有经过明确的训练。

Method: 本文提出了一种新颖的难度可控的多项选择题生成方法，该方法利用大型语言模型并结合直接偏好优化技术来提高难度控制的准确性。

Result: 这项研究提出了一个新颖的难度可控的多项选择题生成方法，可以解决现有方法的局限性。

Conclusion: 通过利用大型语言模型和直接偏好优化技术，本文提出的方法有望提高难度控制的准确性，并能直接生成多项选择题，从而在自适应学习支持中发挥更大的作用。

Abstract: Difficulty-controllable question generation for reading comprehension has
gained significant attention in the field of education as a fundamental tool
for adaptive learning support. Although several neural question generation
methods have recently succeeded in controlling difficulty, conventional
approaches still face two major limitations. First, they cannot directly
generate multiple-choice questions, which are the most widely used question
type in educational contexts. Second, they are not explicitly trained to
optimize the accuracy of difficulty control, leaving room for further
improvement in difficulty controllability. To address these limitations, this
study proposes a novel difficulty-controllable multiple-choice question
generation method for reading comprehension which leverages a large language
model trained using a direct preference optimization technique to improve the
accuracy of difficulty control.

</details>


### [25] [JointCQ: Improving Factual Hallucination Detection with Joint Claim and Query Generation](https://arxiv.org/abs/2510.19310)
*Fan Xu,Huixuan Zhang,Zhenliang Zhang,Jiahao Wang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 该论文介绍了一个名为 JointCQ 的联合声明与查询生成框架，旨在解决大型语言模型中的幻觉问题，并通过实验证明其在幻觉检测基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）普遍存在幻觉问题，即生成看似事实但实则不可靠的内容。现有的幻觉检测方法在声明提取和查询生成阶段存在局限性，例如声明提取过程中的上下文丢失和查询生成特异性不足，导致幻觉检测管道的整体性能下降。

Method: 本文提出了 JointCQ 框架，这是一个联合声明与查询生成框架，旨在构建一个高效且有效的声明-查询生成器。该框架利用精心设计的评估标准来过滤合成的训练数据，并微调一个语言模型，以实现联合声明提取和查询生成。这为下游的搜索和验证提供了可靠且信息丰富的输入。

Result: 实验结果表明，JointCQ 方法在多个开放域问答幻觉检测基准测试中优于现有方法。

Conclusion: JointCQ 框架通过改进声明提取和查询生成阶段的性能，有效地解决了大型语言模型中的幻觉问题，为构建更值得信赖和透明的语言模型系统提供了新的途径。

Abstract: Current large language models (LLMs) often suffer from hallucination issues,
i,e, generating content that appears factual but is actually unreliable. A
typical hallucination detection pipeline involves response decomposition (i.e.,
claim extraction), query generation, evidence collection (i.e., search or
retrieval), and claim verification. However, existing methods exhibit
limitations in the first two stages, such as context loss during claim
extraction and low specificity in query generation, resulting in degraded
performance across the hallucination detection pipeline. In this work, we
introduce JointCQ https://github.com/pku0xff/JointCQ, a joint claim-and-query
generation framework designed to construct an effective and efficient
claim-query generator. Our framework leverages elaborately designed evaluation
criteria to filter synthesized training data, and finetunes a language model
for joint claim extraction and query generation, providing reliable and
informative inputs for downstream search and verification. Experimental results
demonstrate that our method outperforms previous methods on multiple
open-domain QA hallucination detection benchmarks, advancing the goal of more
trustworthy and transparent language model systems.

</details>


### [26] [KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints](https://arxiv.org/abs/2510.19316)
*Kailin Jiang,Hongbo Jiang,Ning Jiang,Zhi Gao,Jinhe Bi,Yuchen Ren,Bin Li,Yuntao Du,Lei Liu,Qing Li*

Main category: cs.CL

TL;DR: 本文提出了KORE方法，通过知识导向的增强和约束来有效地向大型多模态模型注入新知识，并防止灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）的知识是静态且有限的，难以跟上现实世界的动态发展，现有方法在知识适应和知识保留方面存在困难，且面临灾难性遗忘问题。

Method: KORE方法将独立的知识条目自动转换为结构化和全面的知识，以确保模型准确学习新知识。同时，KORE将先前的知识存储在LMM线性层激活的协方差矩阵中，并通过将原始权重投影到矩阵的零空间来初始化适配器，从而定义了最小化对先前知识干扰的微调方向。

Result: 在LLaVA-v1.5-7B、LLaVA-v1.5-13B和Qwen2.5-VL-7B等多种LMM上的大量实验表明，KORE在新知识注入性能方面表现出色，并有效缓解了灾难性遗忘。

Conclusion: KORE方法通过知识导向的增强和约束，有效地解决了大型多模态模型中知识注入和知识保留的挑战，为LMM的持续知识获取提供了新的途径。

Abstract: Large Multimodal Models encode extensive factual knowledge in their
pre-trained weights. However, its knowledge remains static and limited, unable
to keep pace with real-world developments, which hinders continuous knowledge
acquisition. Effective knowledge injection thus becomes critical, involving two
goals: knowledge adaptation (injecting new knowledge) and knowledge retention
(preserving old knowledge). Existing methods often struggle to learn new
knowledge and suffer from catastrophic forgetting. To address this, we propose
KORE, a synergistic method of KnOwledge-oRientEd augmentations and constraints
for injecting new knowledge into large multimodal models while preserving old
knowledge. Unlike general text or image data augmentation, KORE automatically
converts individual knowledge items into structured and comprehensive knowledge
to ensure that the model accurately learns new knowledge, enabling accurate
adaptation. Meanwhile, KORE stores previous knowledge in the covariance matrix
of LMM's linear layer activations and initializes the adapter by projecting the
original weights into the matrix's null space, defining a fine-tuning direction
that minimizes interference with previous knowledge, enabling powerful
retention. Extensive experiments on various LMMs, including LLaVA-v1.5-7B,
LLaVA-v1.5-13B, and Qwen2.5-VL-7B, show that KORE achieves superior new
knowledge injection performance and effectively mitigates catastrophic
forgetting.

</details>


### [27] [HAD: HAllucination Detection Language Models Based on a Comprehensive Hallucination Taxonomy](https://arxiv.org/abs/2510.19318)
*Fan Xu,Xinyu Hu,Zhenghan Yu,Li Lin,Xu Zhang,Yang Zhang,Wei Zhou,Jinjie Gu,Xiaojun Wan*

Main category: cs.CL

TL;DR: 该论文提出了HAllucination Detection (HAD) 模型，旨在解决自然语言生成（NLG）模型，特别是大型语言模型中存在的幻觉问题。HAD模型能够对幻觉进行检测、范围识别和纠正。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成（NLG）模型，尤其是大型语言模型的日益普及，人们对其输出的可靠性和准确性产生了担忧。其中一个主要挑战是“幻觉”，即模型生成听起来合理但实际上不正确的信息。因此，幻觉检测已成为一项至关重要的任务。

Method: 本研究提出了一个包含11个类别的综合幻觉分类法，涵盖了各种NLG任务。研究还提出了HAllucination Detection (HAD) 模型。HAD模型将幻觉检测、跨度级识别和纠正整合到单个推理过程中。该模型在约9万个样本的合成数据集上进行训练，具有通用性，可应用于各种NLG任务。此外，研究人员还精心标注了一个名为HADTest的幻觉检测测试集，包含2,248个样本。

Result: 在域内和域外测试集上的评估表明，HAD模型通常优于现有基线，并在HaluEval、FactCHD和FaithBench上取得了最先进的成果，证实了其稳健性和通用性。

Conclusion: HAD模型在解决NLG模型中的幻觉问题上表现出色，通过集成的检测、识别和纠正能力，显著提高了NLG模型输出的可靠性和准确性。

Abstract: The increasing reliance on natural language generation (NLG) models,
particularly large language models, has raised concerns about the reliability
and accuracy of their outputs. A key challenge is hallucination, where models
produce plausible but incorrect information. As a result, hallucination
detection has become a critical task. In this work, we introduce a
comprehensive hallucination taxonomy with 11 categories across various NLG
tasks and propose the HAllucination Detection (HAD) models
https://github.com/pku0xff/HAD, which integrate hallucination detection,
span-level identification, and correction into a single inference process.
Trained on an elaborate synthetic dataset of about 90K samples, our HAD models
are versatile and can be applied to various NLG tasks. We also carefully
annotate a test set for hallucination detection, called HADTest, which contains
2,248 samples. Evaluations on in-domain and out-of-domain test sets show that
our HAD models generally outperform the existing baselines, achieving
state-of-the-art results on HaluEval, FactCHD, and FaithBench, confirming their
robustness and versatility.

</details>


### [28] [Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization](https://arxiv.org/abs/2510.19325)
*Junjie Song,Yiwen Liu,Dapeng Li,Yin Sun,Shukun Fu,Siqi Chen,Yuji Cao*

Main category: cs.CL

TL;DR: 该论文介绍了一种名为超体积优化 (HVO) 的新颖优化策略，它通过使用超体积方法在强化学习的奖励过程中动态调整组间分数，以解决文本摘要中的多目标优化问题。实验结果表明，HVO 在整体分数上优于 GRPO，并在不同维度上表现出更平衡的性能。一个通过 HVO 增强的 7B 基础模型在摘要任务中的表现与 GPT-4 相当，同时保持了更短的生成长度。


<details>
  <summary>Details</summary>
Motivation: 文本摘要是一个需要同时优化多个目标的任务，包括一致性、连贯性、相关性和流畅性。尽管大型语言模型 (LLMs) 在强化学习 (RL) 的增强下表现出色，但很少有研究关注通过基于 LLM 的强化学习来优化摘要的多目标问题。

Method: 本研究引入了一种名为超体积优化 (HVO) 的新颖优化策略。HVO 在强化学习的奖励过程中，通过使用超体积方法动态调整组间分数。这种方法引导模型的优化逐步逼近帕累托前沿，从而在多个目标之间生成平衡的摘要。

Result: 实验结果表明，HVO 在几个代表性的摘要数据集上，其整体分数优于组相对策略优化 (GRPO)，并在不同维度上显示出更平衡的性能。此外，一个通过 HVO 增强的 7B 基础模型在摘要任务中的表现与 GPT-4 相当，同时保持了更短的生成长度。

Conclusion: 超体积优化 (HVO) 是一种有效解决文本摘要多目标优化问题的新型策略。它能够生成在多个目标之间更平衡的摘要，并在性能和生成效率上优于现有方法。

Abstract: Text summarization is a crucial task that requires the simultaneous
optimization of multiple objectives, including consistency, coherence,
relevance, and fluency, which presents considerable challenges. Although large
language models (LLMs) have demonstrated remarkable performance, enhanced by
reinforcement learning (RL), few studies have focused on optimizing the
multi-objective problem of summarization through RL based on LLMs. In this
paper, we introduce hypervolume optimization (HVO), a novel optimization
strategy that dynamically adjusts the scores between groups during the reward
process in RL by using the hypervolume method. This method guides the model's
optimization to progressively approximate the pareto front, thereby generating
balanced summaries across multiple objectives. Experimental results on several
representative summarization datasets demonstrate that our method outperforms
group relative policy optimization (GRPO) in overall scores and shows more
balanced performance across different dimensions. Moreover, a 7B foundation
model enhanced by HVO performs comparably to GPT-4 in the summarization task,
while maintaining a shorter generation length. Our code is publicly available
at https://github.com/ai4business-LiAuto/HVO.git

</details>


### [29] [Slot Filling as a Reasoning Task for SpeechLLMs](https://arxiv.org/abs/2510.19326)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 该论文提出了一种将推理集成到语音大型语言模型（speechLLMs）中的方法，用于端到端槽填充任务，并通过引入推理步骤显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 受最新推理LLMs发展的启发，作者旨在通过将槽填充任务分解为多个推理步骤，解决现有speechLLMs在复杂任务中推理能力不足的问题。

Method: 1. 采用思维链框架将槽填充任务分解为多个推理步骤。 2. 创建了一个推理数据集。 3. 应用监督微调策略到speechLLM。 4. 区分“常规”和“推理”speechLLMs，并试验不同类型和大小的LLM作为文本基础模型。 5. 进一步展示了混合speechLLM的构建和微调方法，以同时保留直接和推理操作模式。

Result: 1. 引入推理中间步骤后，性能显著提高。 2. 发现主要为数学、逻辑和编码领域开发的推理文本LLM作为推理speechLLM的基础模型可能表现不佳。 3. 混合speechLLM（基于混合文本基础LLM并微调以保留直接和推理两种操作模式）的性能优于仅使用单一操作模式进行微调的模型。

Conclusion: 将推理集成到speechLLMs中，通过思维链框架和监督微调，可以有效提升端到端槽填充任务的性能。选择合适的基础LLM类型和采用混合微调策略对于构建高性能的推理speechLLM至关重要。

Abstract: We propose integration of reasoning into speech large language models
(speechLLMs) for the end-to-end slot-filling task. Inspired by the recent
development of reasoning LLMs, we use a chain-of-thought framework to decompose
the slot-filling task into multiple reasoning steps, create a reasoning dataset
and apply the supervised fine-tuning strategy to a speechLLM. We distinguish
between regular and reasoning speechLLMs and experiment with different types
and sizes of LLMs as their text foundation models. We demonstrate performance
improvements by introducing reasoning (intermediate) steps. However, we show
that a reasoning textual LLM developed mainly for math, logic and coding
domains might be inferior as a foundation model for a reasoning speechLLM. We
further show that hybrid speechLLMs, built on a hybrid text foundation LLM and
fine-tuned to preserve both direct and reasoning modes of operation, have
better performance than those fine-tuned employing only one mode of operation.

</details>


### [30] [Algorithmic Fairness in NLP: Persona-Infused LLMs for Human-Centric Hate Speech Detection](https://arxiv.org/abs/2510.19331)
*Ewelina Gajewska,Arda Derbent,Jaroslaw A Chudziak,Katarzyna Budzynska*

Main category: cs.CL

TL;DR: 本文研究了通过注释者角色对大型语言模型（Persona-LLMs）进行个性化设置，如何影响其对仇恨言论的敏感性，特别是与注释者和目标之间共同或不同身份相关的偏见。


<details>
  <summary>Details</summary>
Motivation: 探索个性化大型语言模型（Persona-LLMs）在仇恨言论检测中如何受注释者身份相关偏见的影响，旨在通过结合群体心理学和先进自然语言处理技术，解决自动化仇恨言论检测中的偏见问题。

Method: 采用谷歌Gemini和OpenAI的GPT-4.1-mini模型，使用两种角色提示方法：浅层角色提示和基于检索增强生成（RAG）的深度情境化角色发展，以纳入更丰富的角色档案。分析使用内群体和外群体注释者角色对模型检测性能和不同社会群体之间公平性的影响。

Result: 通过将社会人口统计学属性纳入大型语言模型，可以解决自动化仇恨言论检测中的偏见。研究结果揭示了基于角色的方法在减少偏见方面的潜力和局限性。

Conclusion: 个性化大型语言模型（Persona-LLMs）可以通过整合社会人口学属性来有效解决仇恨言论检测中的偏见问题，但仍需注意其潜力和局限性，以开发更公平的检测系统。

Abstract: In this paper, we investigate how personalising Large Language Models
(Persona-LLMs) with annotator personas affects their sensitivity to hate
speech, particularly regarding biases linked to shared or differing identities
between annotators and targets. To this end, we employ Google's Gemini and
OpenAI's GPT-4.1-mini models and two persona-prompting methods: shallow persona
prompting and a deeply contextualised persona development based on
Retrieval-Augmented Generation (RAG) to incorporate richer persona profiles. We
analyse the impact of using in-group and out-group annotator personas on the
models' detection performance and fairness across diverse social groups. This
work bridges psychological insights on group identity with advanced NLP
techniques, demonstrating that incorporating socio-demographic attributes into
LLMs can address bias in automated hate speech detection. Our results highlight
both the potential and limitations of persona-based approaches in reducing
bias, offering valuable insights for developing more equitable hate speech
detection systems.

</details>


### [31] [Local Obfuscation by GLINER for Impartial Context Aware Lineage: Development and evaluation of PII Removal system](https://arxiv.org/abs/2510.19346)
*Prakrithi Shivaprakash,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: LOGICAL是一个高效、本地部署的PII移除系统，它基于微调的GLiNER模型，在临床笔记PII移除方面表现出色，优于LLM，尤其适用于资源受限环境下的数据去识别。


<details>
  <summary>Details</summary>
Motivation: 在电子健康记录（EHRs）中移除临床笔记中的个人身份信息（PII）对于研究和人工智能发展至关重要。大型语言模型（LLMs）虽然功能强大，但其高计算成本和API服务的隐私风险限制了其使用，尤其是在资源匮乏的环境中。

Method: 我们开发了LOGICAL系统，它是一个高效、本地部署的PII移除系统，基于微调的GLiNER模型。我们从一家精神病医院的EHR系统中使用了1515份临床文档，定义了9个PII类别进行移除。一个modern-gliner-bi-large-v1.0模型在2849个文本实例上进行了微调，并在376个实例的测试集上进行了评估，使用字符级别的精确度、召回率和F1分数。

Result: 微调后的GLiNER模型表现优异，总体微平均F1分数为0.980，显著优于Gemini-Pro-2.5（F1分数：0.845）。LOGICAL正确地完全消毒了95%的文档，而次优解决方案的这一比例为64%。该模型在没有专用GPU的标准笔记本电脑上高效运行。

Conclusion: 经过微调的专业Transformer模型（如GLiNER）为临床笔记中的PII移除提供了一个准确、计算效率高且安全的解决方案。这种“源头净化”方法是资源密集型LLM的一个实用替代方案，能够为研究和AI开发创建去识别的数据集，同时保护数据隐私，尤其是在资源受限的环境中。

Abstract: Removing Personally Identifiable Information (PII) from clinical notes in
Electronic Health Records (EHRs) is essential for research and AI development.
While Large Language Models (LLMs) are powerful, their high computational costs
and the data privacy risks of API-based services limit their use, especially in
low-resource settings. To address this, we developed LOGICAL (Local Obfuscation
by GLINER for Impartial Context-Aware Lineage), an efficient, locally
deployable PII removal system built on a fine-tuned Generalist and Lightweight
Named Entity Recognition (GLiNER) model. We used 1515 clinical documents from a
psychiatric hospital's EHR system. We defined nine PII categories for removal.
A modern-gliner-bi-large-v1.0 model was fine-tuned on 2849 text instances and
evaluated on a test set of 376 instances using character-level precision,
recall, and F1-score. We compared its performance against Microsoft Azure NER,
Microsoft Presidio, and zero-shot prompting with Gemini-Pro-2.5 and
Llama-3.3-70B-Instruct. The fine-tuned GLiNER model achieved superior
performance, with an overall micro-average F1-score of 0.980, significantly
outperforming Gemini-Pro-2.5 (F1-score: 0.845). LOGICAL correctly sanitised 95%
of documents completely, compared to 64% for the next-best solution. The model
operated efficiently on a standard laptop without a dedicated GPU. However, a
2% entity-level false negative rate underscores the need for human-in-the-loop
validation across all tested systems. Fine-tuned, specialised transformer
models like GLiNER offer an accurate, computationally efficient, and secure
solution for PII removal from clinical notes. This "sanitisation at the source"
approach is a practical alternative to resource-intensive LLMs, enabling the
creation of de-identified datasets for research and AI development while
preserving data privacy, particularly in resource-constrained environments.

</details>


### [32] [Modeling Turn-Taking with Semantically Informed Gestures](https://arxiv.org/abs/2510.19350)
*Varsha Suresh,M. Hamza Mughal,Christian Theobalt,Vera Demberg*

Main category: cs.CL

TL;DR: 这篇论文研究了手势在多模态轮流对话中的作用。


<details>
  <summary>Details</summary>
Motivation: 人类在对话中利用多种模态线索（如言语、手势和注视）来管理轮流。虽然语言和听觉特征提供了丰富的信息，但手势为建模这些过渡提供了补充线索。

Method: 本文引入了DnD Gesture++，这是对多方DnD手势语料库的扩展，其中包含2,663个跨越意象、隐喻、指示和语篇类型的手势语义注释。利用这个数据集，通过一个集成文本、音频和手势的专家混合框架来模拟轮流预测。

Result: 实验表明，结合语义引导的手势比基线模型有持续的性能提升。

Conclusion: 手势在多模态轮流对话中扮演着补充角色。

Abstract: In conversation, humans use multimodal cues, such as speech, gestures, and
gaze, to manage turn-taking. While linguistic and acoustic features are
informative, gestures provide complementary cues for modeling these
transitions. To study this, we introduce DnD Gesture++, an extension of the
multi-party DnD Gesture corpus enriched with 2,663 semantic gesture annotations
spanning iconic, metaphoric, deictic, and discourse types. Using this dataset,
we model turn-taking prediction through a Mixture-of-Experts framework
integrating text, audio, and gestures. Experiments show that incorporating
semantically guided gestures yields consistent performance gains over
baselines, demonstrating their complementary role in multimodal turn-taking.

</details>


### [33] [M3-SLU: Evaluating Speaker-Attributed Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2510.19358)
*Yejin Kwon,Taewoo Kang,Hyunsoo Yoon,Changouk Kim*

Main category: cs.CL

TL;DR: 介绍了M3-SLU，一个用于评估多说话人、多轮口语理解的新型多模态大型语言模型（MLLM）基准。


<details>
  <summary>Details</summary>
Motivation: 尽管最近的模型在语音和文本理解方面表现出色，但它们在说话人归因推理方面仍然存在困难，即理解在自然对话中“谁在什么时间说了什么”。

Method: M3-SLU建立在四个开放语料库（CHiME-6、MELD、MultiDialog和AMI）之上，包含超过12,000个经过验证的实例，配有音频、转录和元数据。它包括两个任务：（1）说话人归因问答和（2）通过话语匹配进行说话人归因。

Result: 结果表明，模型可以理解“说了什么”，但通常无法识别“是谁说的”，这揭示了说话人感知对话理解中的一个关键空白。

Conclusion: M3-SLU提供了一个具有挑战性的基准，以推动说话人感知多模态理解的研究。

Abstract: We present M3-SLU, a new multimodal large language model (MLLM) benchmark for
evaluating multi-speaker, multi-turn spoken language understanding. While
recent models show strong performance in speech and text comprehension, they
still struggle with speaker-attributed reasoning, the ability to understand who
said what and when in natural conversations. M3-SLU is built from four open
corpora (CHiME-6, MELD, MultiDialog, and AMI) and comprises over 12,000
validated instances with paired audio, transcripts, and metadata. It includes
two tasks: (1) Speaker-Attributed Question Answering and (2) Speaker
Attribution via Utterance Matching. We provide baseline results for both
cascaded pipelines and end-to-end MLLMs, evaluated using an LLM-as-Judge and
accuracy metrics. Results show that while models can capture what was said,
they often fail to identify who said it, revealing a key gap in speaker-aware
dialogue understanding. M3-SLU offers as a challenging benchmark to advance
research in speaker-aware multimodal understanding.

</details>


### [34] [LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts](https://arxiv.org/abs/2510.19363)
*Siyuan Wang,Gaokai Zhang,Li Lyna Zhang,Ning Shang,Fan Yang,Dongyao Chen,Mao Yang*

Main category: cs.CL

TL;DR: LoongRL 是一种数据驱动的强化学习方法，通过引入名为 KeyChain 的合成方法，将短多跳问答转化为长上下文任务，以提升大型语言模型在长上下文推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在长上下文推理方面存在挑战，现有强化学习方法主要关注短上下文推理，且缺乏高难度强化学习数据。

Method: LoongRL 引入 KeyChain 方法。KeyChain 通过插入 UUID 链，将真实问题隐藏在大量干扰文档中，从而将短多跳问答转化为高难度长上下文任务。解决这些任务需要模型逐步追踪正确的链条，识别真实问题，检索相关事实并进行推理。

Result: LoongRL 在 16K 上训练的模型能够有效解决 128K 任务，且泛化能力强。在 Qwen2.5-7B 和 14B 模型上，LoongRL 使长上下文多跳问答的准确率分别绝对提升了 23.5% 和 21.1%。LoongRL-14B 的得分达到 74.2，与更大型模型（如 o3-mini 和 DeepSeek-R1）相当，并提升了长上下文检索能力，通过了所有 128K “大海捞针”压力测试，同时保留了短上下文推理能力。

Conclusion: LoongRL 成功地通过数据驱动的强化学习方法，显著提升了大型语言模型在长上下文推理方面的能力，并通过引入 KeyChain 方法有效解决了高难度强化学习数据稀缺的问题，展现出强大的泛化能力和实际应用价值。

Abstract: Reasoning over long contexts is essential for large language models. While
reinforcement learning (RL) enhances short-context reasoning by inducing "Aha"
moments in chain-of-thought, the advanced thinking patterns required for
long-context reasoning remain largely unexplored, and high-difficulty RL data
are scarce. In this paper, we introduce LoongRL, a data-driven RL method for
advanced long-context reasoning. Central to LoongRL is KeyChain, a synthesis
approach that transforms short multi-hop QA into high-difficulty long-context
tasks by inserting UUID chains that hide the true question among large
collections of distracting documents. Solving these tasks requires the model to
trace the correct chain step-by-step, identify the true question, retrieve
relevant facts and reason over them to answer correctly. RL training on
KeyChain data induces an emergent plan-retrieve-reason-recheck reasoning
pattern that generalizes far beyond training length. Models trained at 16K
effectively solve 128K tasks without prohibitive full-length RL rollout costs.
On Qwen2.5-7B and 14B, LoongRL substantially improves long-context multi-hop QA
accuracy by +23.5% and +21.1% absolute gains. The resulting LoongRL-14B reaches
a score of 74.2, rivaling much larger frontier models such as o3-mini (74.5)
and DeepSeek-R1 (74.9). It also improves long-context retrieval, passes all
128K needle-in-a-haystack stress tests, and preserves short-context reasoning
capabilities.

</details>


### [35] [The Massive Legal Embedding Benchmark (MLEB)](https://arxiv.org/abs/2510.19365)
*Umar Butler,Abdur-Rahman Butler,Adrian Lucas Malec*

Main category: cs.CL

TL;DR: MLEB是一个迄今为止规模最大、种类最多、最全面的开放法律信息检索基准测试集。


<details>
  <summary>Details</summary>
Motivation: 作者希望填补开源法律信息检索领域的领域和司法管辖区空白。

Method: MLEB包含十个经过专家注释的数据集，涵盖多个司法管辖区（美国、英国、欧盟、澳大利亚、爱尔兰和新加坡）、文档类型（案例、立法、监管指南、合同和文献）和任务类型（搜索、零样本分类和问答）。其中七个数据集是作者为了填补空白而新建的。

Result: 作者构建了MLEB和新的组成数据集，并公开发布了代码、结果和数据，以帮助进行可重现的评估。

Conclusion: MLEB的创建为法律信息检索领域提供了一个大规模、多样化且全面的开放基准测试集，有助于推动该领域的研究和发展。

Abstract: We present the Massive Legal Embedding Benchmark (MLEB), the largest, most
diverse, and most comprehensive open-source benchmark for legal information
retrieval to date. MLEB consists of ten expert-annotated datasets spanning
multiple jurisdictions (the US, UK, EU, Australia, Ireland, and Singapore),
document types (cases, legislation, regulatory guidance, contracts, and
literature), and task types (search, zero-shot classification, and question
answering). Seven of the datasets in MLEB were newly constructed in order to
fill domain and jurisdictional gaps in the open-source legal information
retrieval landscape. We document our methodology in building MLEB and creating
the new constituent datasets, and release our code, results, and data openly to
assist with reproducible evaluations.

</details>


### [36] [MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs](https://arxiv.org/abs/2510.19366)
*Xinfeng Xia,Jiacheng Liu,Xiaofeng Hou,Peng Tang,Mingxuan Zhang,Wenfeng Wang,Chao Li*

Main category: cs.CL

TL;DR: MoE-Prism通过将MoE模型解构为细粒度的“子专家”，并利用QoS感知调度，提供了比现有MoE模型多4倍以上的离散、稳定的操作点，从而在不重新训练的情况下，显著提高了AI服务的吞吐量或降低了延迟，弥补了模型与系统之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型由于其粗粒度的专家路由机制，导致在成本和质量之间存在僵硬的权衡，无法适应多样化的服务水平目标（SLOs），并导致严重的资源过度配置。

Method: MoE-Prism通过模型-系统协同设计实现。首先，一个“离线重构引擎”利用基于元启发式方法的划分优化求解器，将单体专家系统地解构为细粒度的“子专家”，在不重新训练的情况下保持功能局部性。其次，一个“在线调度引擎”通过QoS感知调度利用这种新的弹性，实现专门的策略来解决复杂的系统问题，如在云部署中最大化吞吐量和管理内存受限设备的延迟优化卸载。

Result: MoE-Prism在三个不同的MoE模型上的评估显示，它提供了比基线多4倍以上的离散、稳定的操作点。这使得AI服务在严格的延迟预算下，吞吐量可以动态提高19.9%；在资源有限的情况下，延迟可以降低10.36%。

Conclusion: MoE-Prism提供了弥合模型与系统之间差距的关键“控制旋钮”，从而支持下一代自适应、高效和QoS感知的AI服务。

Abstract: Mixture-of-Experts (MoE) models, the state-of-the-art in large-scale AI,
achieve high quality by sparsely activating parameters. However, their reliance
on routing between a few monolithic experts via a top-k mechanism creates a
"quality cliff", offering only a few coarse-grained operating points. This
inflexibility forces a difficult trade-off between cost and quality, preventing
adaptation to diverse Service Level Objectives (SLOs) and leading to
significant resource over-provisioning.
  This paper introduces MoE-Prism, a model-system co-design that transforms
rigid MoE models into elastic services. Our methodology is divided into two
phases. First, an \emph{Offline Refactoring Engine} systematically deconstructs
monolithic experts into fine-grained "sub-experts." This engine employs a
partitioning optimization solver that uses a metaheuristic-based approach to
group neurons, preserving functional locality without requiring retraining.
Second, an \emph{Online Scheduling Engine} leverages this new elasticity
through QoS-aware scheduling. It implements specialized policies to solve
complex system problems, including maximizing throughput in cloud deployments
and managing latency-optimized offloading for memory-constrained devices. Our
evaluation across three different MoE models shows that MoE-Prismprovides over
4 times more distinct, stable operating points than the baseline. This allows
an AI service to dynamically improve throughput by up to 19.9\% under a strict
latency budget or reduce latency by up to 10.36\% under limited resources.
MoE-Prism provides the critical "control knob" to bridge the model-system gap,
enabling the next generation of adaptive, efficient, and QoS-aware AI services.

</details>


### [37] [Sign Language Translation with Sentence Embedding Supervision](https://arxiv.org/abs/2510.19367)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 这篇论文提出了一种通过使用目标语句的句子嵌入作为监督来改进手语翻译系统SOTA的方法。这种方法不需要人工标注，并且显著优于其他无词汇方法，缩小了无词汇系统和依赖词汇系统之间的差距。


<details>
  <summary>Details</summary>
Motivation: 目前最先进的手语翻译系统依赖于词汇标注，但词汇标注数据稀缺且数据集之间差异很大。这限制了手语翻译系统的发展和应用。

Method: 本文提出了一种新颖的方法，在训练时使用目标语句的句子嵌入来代替词汇。这种监督方式不需要任何人工标注，因为它是在原始文本数据上学习的。该方法易于实现多语言，并在PHOENIX-2014T（德语手语）和How2Sign（美式手语）数据集上进行了评估，分别使用单语言和多语言句子嵌入以及翻译系统进行实验。

Result: 该方法在没有词汇的SOTA手语翻译数据集上取得了显著优于其他无词汇方法的性能，并且在没有使用额外SLT数据集进行预训练的情况下，缩小了无词汇系统和依赖词汇系统之间的差距。

Conclusion: 本文提出了一种有效且无需人工标注的无词汇手语翻译方法，该方法通过利用句子嵌入作为监督，在多语言手语翻译任务上取得了显著的性能提升，并为未来的手语翻译研究开辟了新的途径。

Abstract: State-of-the-art sign language translation (SLT) systems facilitate the
learning process through gloss annotations, either in an end2end manner or by
involving an intermediate step. Unfortunately, gloss labelled sign language
data is usually not available at scale and, when available, gloss annotations
widely differ from dataset to dataset. We present a novel approach using
sentence embeddings of the target sentences at training time that take the role
of glosses. The new kind of supervision does not need any manual annotation but
it is learned on raw textual data. As our approach easily facilitates
multilinguality, we evaluate it on datasets covering German (PHOENIX-2014T) and
American (How2Sign) sign languages and experiment with mono- and multilingual
sentence embeddings and translation systems. Our approach significantly
outperforms other gloss-free approaches, setting the new state-of-the-art for
data sets where glosses are not available and when no additional SLT datasets
are used for pretraining, diminishing the gap between gloss-free and
gloss-dependent systems.

</details>


### [38] [SONAR-SLT: Multilingual Sign Language Translation via Language-Agnostic Sentence Embedding Supervision](https://arxiv.org/abs/2510.19398)
*Yasser Hamidullah,Shakib Yazdani,Cennet Oguz,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 本文提出了一种无需手语语言知识的无手语翻译方法，其核心思想是使用多语言的文本和语音训练出语言无关的多模态嵌入，从而实现直接的多语言翻译。为解决数据稀缺问题，本文提出了一种耦合增强方法，将多语言目标增强与视频级扰动相结合，从而提升了模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的手语翻译（SLT）方法通常使用单一书面语言的文本进行训练，这限制了其可扩展性和跨语言泛化能力。虽然早期方法用基于文本的句子嵌入取代了传统的手语注释，但这些方法仍然受限于特定语言和模态，无法实现多语言翻译。

Method: 本文提出了一种语言无关、多模态的嵌入方法，通过在多种语言的文本和语音上进行训练，以实现直接多语言翻译。为了解决数据稀缺问题，本文还提出了一种耦合增强方法，它结合了多语言目标增强（即翻译成多种语言）和视频级扰动，从而提高了模型的鲁棒性。

Result: 实验结果表明，与仅使用文本的句子嵌入监督相比，本文提出的方法在BLEURT指标上获得了持续的提升，尤其是在低资源设置下，提升更为显著。

Conclusion: 语言无关的嵌入监督与耦合增强方法相结合，为传统的手语翻译训练提供了一种可扩展且语义鲁棒的替代方案。

Abstract: Sign language translation (SLT) is typically trained with text in a single
spoken language, which limits scalability and cross-language generalization.
Earlier approaches have replaced gloss supervision with text-based sentence
embeddings, but up to now, these remain tied to a specific language and
modality. In contrast, here we employ language-agnostic, multimodal embeddings
trained on text and speech from multiple languages to supervise SLT, enabling
direct multilingual translation. To address data scarcity, we propose a coupled
augmentation method that combines multilingual target augmentations (i.e.
translations into many languages) with video-level perturbations, improving
model robustness. Experiments show consistent BLEURT gains over text-only
sentence embedding supervision, with larger improvements in low-resource
settings. Our results demonstrate that language-agnostic embedding supervision,
combined with coupled augmentation, provides a scalable and semantically robust
alternative to traditional SLT training.

</details>


### [39] [ToMMeR -- Efficient Entity Mention Detection from Large Language Models](https://arxiv.org/abs/2510.19410)
*Victor Morand,Nadi Tomeh,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: ToMMeR是一个轻量级模型，用于从LLM的早期层探测提及检测能力，在13个NER基准测试中实现了93%的零样本召回率和90%以上的精确度，并且在扩展后达到了接近SOTA的NER性能。


<details>
  <summary>Details</summary>
Motivation: 此论文旨在解决将文本跨度识别为实体这一信息提取的基础性问题，同时也是性能瓶颈。

Method: 本文引入了一个名为ToMMeR的轻量级模型（<300K参数），该模型从LLM的早期层探测提及检测能力。它在13个NER基准测试上进行了评估，并使用LLM作为判别器来评估其准确性。此外，还进行了跨模型分析，以探究不同架构模型在提及边界上的表现。最后，通过添加跨度分类头来扩展ToMMeR，以评估其在NER任务上的性能。

Result: ToMMeR在13个NER基准测试中实现了93%的零样本召回率，并且在使用LLM作为判断器的情况下，其精确度超过90%。跨模型分析表明，多样化的架构（14M-15B参数）在提及边界上表现出相似性（DICE >75%）。当ToMMeR扩展了跨度分类头后，它在标准基准测试上达到了近乎SOTA的NER性能（80-87% F1）。

Conclusion: 实体在早期Transformer层中以结构化形式存在，并且可以以最小的参数高效地恢复。提及检测能力自然地从语言建模中浮现。

Abstract: Identifying which text spans refer to entities -- mention detection -- is
both foundational for information extraction and a known performance
bottleneck. We introduce ToMMeR, a lightweight model (<300K parameters) probing
mention detection capabilities from early LLM layers. Across 13 NER benchmarks,
ToMMeR achieves 93\% recall zero-shot, with over 90\% precision using an LLM as
a judge showing that ToMMeR rarely produces spurious predictions despite high
recall. Cross-model analysis reveals that diverse architectures (14M-15B
parameters) converge on similar mention boundaries (DICE >75\%), confirming
that mention detection emerges naturally from language modeling. When extended
with span classification heads, ToMMeR achieves near SOTA NER performance
(80-87\% F1 on standard benchmarks). Our work provides evidence that structured
entity representations exist in early transformer layers and can be efficiently
recovered with minimal parameters.

</details>


### [40] [Spatio-temporal Sign Language Representation and Translation](https://arxiv.org/abs/2510.19413)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 本文描述了DFKI-MLT参加WMT-SLT 2022手语翻译任务的提交，该任务涉及将瑞士德语手语（视频）翻译成德语（文本）。


<details>
  <summary>Details</summary>
Motivation: 手语翻译（SLT）的最新技术使用带有自定义输入嵌入的通用seq2seq架构。SLT系统使用从视频帧中提取的特征，而不是文本机器翻译中使用的词嵌入。标准方法通常无法从时间特征中受益。

Method: 我们提出了一个系统，该系统在一个模型中学习时空特征表示和翻译，形成一个真正的端到端架构，有望更好地推广到新的数据集。

Result: 我们最好的系统在开发集上取得了5±1的BLEU分数，但测试集上的性能下降到0.11±0.06的BLEU分数。

Conclusion: 尽管在开发集上表现良好，但该端到端手语翻译系统在测试集上的性能显著下降，表明其泛化能力有待提高。

Abstract: This paper describes the DFKI-MLT submission to the WMT-SLT 2022 sign
language translation (SLT) task from Swiss German Sign Language (video) into
German (text). State-of-the-art techniques for SLT use a generic seq2seq
architecture with customized input embeddings. Instead of word embeddings as
used in textual machine translation, SLT systems use features extracted from
video frames. Standard approaches often do not benefit from temporal features.
In our participation, we present a system that learns spatio-temporal feature
representations and translation in a single model, resulting in a real
end-to-end architecture expected to better generalize to new data sets. Our
best system achieved $5\pm1$ BLEU points on the development set, but the
performance on the test dropped to $0.11\pm0.06$ BLEU points.

</details>


### [41] [BLiSS 1.0: Evaluating Bilingual Learner Competence in Second Language Small Language Models](https://arxiv.org/abs/2510.19419)
*Yuan Gao,Suchir Salhan,Andrew Caines,Paula Buttery,Weiwei Sun*

Main category: cs.CL

TL;DR: BLiSS 1.0 是一个旨在弥合性能导向基准与认知启发模型评估之间差距的基准测试。它通过测试模型区分自然学习者错误和人工错误的能力，以评估模型对人类语言习得系统模式的理解。


<details>
  <summary>Details</summary>
Motivation: 弥合性能导向基准与认知启发模型评估之间的差距，特别是在评估认知启发模型对人类语言习得的理解方面。

Method: 引入了选择性容忍度范式，测试模型是否认为自然学习者错误比同一句子中匹配的人工错误更合理。该基准从超过280万个自然学习者句子中构建，提供了136,867个受控三元组（已更正、学习者、人工错误）。

Result: 在不同模型上进行的实验表明，选择性容忍度是一种独立于标准语法性的独特能力，并且模型的性能强烈地受训练范式的影响。

Conclusion: BLiSS 是一个强大的工具，可以衡量不同训练目标如何影响模型与人类语言习得系统模式的一致性。选择性容忍度是一个独特的评估维度，有助于深入理解模型对人类语言学习的认知机制的捕捉能力。

Abstract: To bridge the gap between performance-oriented benchmarks and the evaluation
of cognitively inspired models, we introduce BLiSS 1.0, a Benchmark of Learner
Interlingual Syntactic Structure. Our benchmark operationalizes a new paradigm
of selective tolerance, testing whether a model finds a naturalistic learner
error more plausible than a matched, artificial error within the same sentence.
Constructed from over 2.8 million naturalistic learner sentences, BLiSS
provides 136,867 controlled triplets (corrected, learner, artificial) for this
purpose. Experiments on a diverse suite of models demonstrate that selective
tolerance is a distinct capability from standard grammaticality, with
performance clustering strongly by training paradigm. This validates BLiSS as a
robust tool for measuring how different training objectives impact a model's
alignment with the systematic patterns of human language acquisition.

</details>


### [42] [MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models](https://arxiv.org/abs/2510.19457)
*Kailin Jiang,Ning Jiang,Yuchen Ren,Yuchen Li,Yifan Gao,Jinhe Bi,Yunpu Ma,Qingqing Liu,Xianhao Wang,Yifan Jia,Hongbo Jiang,Yaocong Hu,Bin Li,Lei Liu,Yuntao Du*

Main category: cs.CL

TL;DR: 该论文提出了MINED，一个用于评估大型多模态模型（LMMs）时间敏感知识理解能力的基准，涵盖认知、意识、可信度、理解、推理和鲁棒性六个维度和11个任务。研究发现LMMs在这方面表现不佳，Gemini-2.5-Pro得分最高，但开源模型仍有欠缺。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）在跨模态预训练中编码了丰富的 G 事实知识，但其静态表示难以准确理解时间敏感的知识。现有基准受静态设计的限制，不足以评估 LMMs 理解时间敏感知识的能力。

Method: 本文提出了MINED基准，通过从维基百科中构建2,104个时间敏感知识样本，涵盖认知、意识、可信度、理解、推理、鲁棒性6个关键维度和11个挑战性任务。

Result: 在MINED上评估15个广泛使用的LMMs发现，Gemini-2.5-Pro取得了最高的平均CEM分数63.07，而大多数开源LMMs仍缺乏时间理解能力。LMMs在组织知识方面表现最好，在体育方面表现最弱。知识编辑方法在单编辑场景中可以有效更新LMMs的时间敏感知识。

Conclusion: LMMs在时间敏感知识理解方面存在不足，特别是在开源模型中。MINED基准的提出有助于全面评估LMMs的这一能力。知识编辑为更新LMMs中的时间敏感知识提供了潜在的解决方案。

Abstract: Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal
pre-training, yet their static representations struggle to maintain an accurate
understanding of time-sensitive factual knowledge. Existing benchmarks remain
constrained by static designs, inadequately evaluating LMMs' ability to
understand time-sensitive knowledge. To address this gap, we propose MINED, a
comprehensive benchmark that evaluates temporal awareness along 6 key
dimensions and 11 challenging tasks: cognition, awareness, trustworthiness,
understanding, reasoning, and robustness. MINED is constructed from Wikipedia
by two professional annotators, containing 2,104 time-sensitive knowledge
samples spanning six knowledge types. Evaluating 15 widely used LMMs on MINED
shows that Gemini-2.5-Pro achieves the highest average CEM score of 63.07,
while most open-source LMMs still lack time understanding ability. Meanwhile,
LMMs perform best on organization knowledge, whereas their performance is
weakest on sport. To address these challenges, we investigate the feasibility
of updating time-sensitive knowledge in LMMs through knowledge editing methods
and observe that LMMs can effectively update knowledge via knowledge editing
methods in single editing scenarios.

</details>


### [43] [Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition](https://arxiv.org/abs/2510.19471)
*Yuu Jinnai*

Main category: cs.CL

TL;DR: 这篇论文研究了在自动语音识别（ASR）和语音翻译（ST）任务中使用最小贝叶斯风险（MBR）解码的可能性，并将其与束搜索进行了比较。


<details>
  <summary>Details</summary>
Motivation: 探索MBR解码在语音到文本任务中的有效性，因为MBR解码在文本到文本生成任务中表现出色，但尚未广泛应用于语音到文本任务。

Method: 本文在英语和日语的ASR和ST任务上评估了MBR解码，使用了Whisper及其衍生模型进行实验。

Result: 在大多数实验设置中，MBR解码的准确性优于束搜索。

Conclusion: MBR解码对于需要高准确性的离线ASR和ST任务来说是一种很有前途的方法。

Abstract: Recent work has shown that sample-based Minimum Bayes Risk (MBR) decoding
outperforms beam search in text-to-text generation tasks, such as machine
translation, text summarization, and image captioning. On the other hand, beam
search is the current practice for speech-to-text tasks such as automatic
speech recognition (ASR) and Speech Translation (ST). Given that MBR decoding
is effective in text-to-text generation tasks, it is reasonable to expect it to
also be effective for speech-to-text tasks. In this paper, we evaluate MBR
decoding for ASR and ST tasks on English and Japanese using Whisper and its
derivative models. We observe that the accuracy of MBR decoding outperforms
that of beam search in most of the experimental settings we have evaluated. The
results show that MBR decoding is a promising method for offline ASR and ST
tasks that require high accuracy. The code is available at
https://github.com/CyberAgentAILab/mbr-for-asr

</details>


### [44] [Machine Text Detectors are Membership Inference Attacks](https://arxiv.org/abs/2510.19492)
*Ryuto Koike,Liam Dugan,Masahiro Kaneko,Chris Callison-Burch,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 本文分析了成员推理攻击（MIAs）和机器生成文本检测之间的可迁移性，发现二者在方法论上存在共通性，并提出了一个统一的评估套件MINT。


<details>
  <summary>Details</summary>
Motivation: MIAs和机器生成文本检测虽然目标不同，但方法上都利用了语言模型的概率分布信号。目前两者的研究相对独立，可能导致忽略更强的方法和有价值的见解。

Method: 通过理论和实证研究，探究了MIAs和机器文本检测之间的可迁移性。理论上证明了在两个任务上渐近性能最高的度量标准是相同的，并统一了现有文献中与该最优度量相关的部分。实证实验涵盖了7种最先进的MIA方法和5种最先进的机器文本检测器，涉及13个领域和10个生成器。

Result: 实验结果表明，在跨任务性能上存在很强的等级相关性（rho > 0.6）。值得注意的是，最初为机器文本检测设计的Binoculars在MIA基准测试中也取得了最先进的性能。

Conclusion: 研究结果强调了两个研究社区之间需要加强跨任务意识和协作。为了促进跨任务发展和公平评估，本文引入了MINT，一个针对MIAs和机器生成文本检测的统一评估套件，其中包含了来自这两个任务的15种最新方法的实现。

Abstract: Although membership inference attacks (MIAs) and machine-generated text
detection target different goals, identifying training samples and synthetic
texts, their methods often exploit similar signals based on a language model's
probability distribution. Despite this shared methodological foundation, the
two tasks have been independently studied, which may lead to conclusions that
overlook stronger methods and valuable insights developed in the other task. In
this work, we theoretically and empirically investigate the transferability,
i.e., how well a method originally developed for one task performs on the
other, between MIAs and machine text detection. For our theoretical
contribution, we prove that the metric that achieves the asymptotically highest
performance on both tasks is the same. We unify a large proportion of the
existing literature in the context of this optimal metric and hypothesize that
the accuracy with which a given method approximates this metric is directly
correlated with its transferability. Our large-scale empirical experiments,
including 7 state-of-the-art MIA methods and 5 state-of-the-art machine text
detectors across 13 domains and 10 generators, demonstrate very strong rank
correlation (rho > 0.6) in cross-task performance. We notably find that
Binoculars, originally designed for machine text detection, achieves
state-of-the-art performance on MIA benchmarks as well, demonstrating the
practical impact of the transferability. Our findings highlight the need for
greater cross-task awareness and collaboration between the two research
communities. To facilitate cross-task developments and fair evaluations, we
introduce MINT, a unified evaluation suite for MIAs and machine-generated text
detection, with implementation of 15 recent methods from both tasks.

</details>


### [45] [What is the Best Sequence Length for BABYLM?](https://arxiv.org/abs/2510.19493)
*Suchir Salhan,Richard Diehl Martinez,Zébulon Goriely,Paula Buttery*

Main category: cs.CL

TL;DR: 研究了序列长度对BabyLM预训练的影响，结果表明最佳长度取决于任务和模型架构。


<details>
  <summary>Details</summary>
Motivation: Transformer语言模型通常在固定长度的上下文窗口下运行，但过去的BabyLM挑战提交使用了较短的序列长度。因此，研究的目的是确定在训练Baby LM时应该使用什么样的序列长度。

Method: 使用1亿词的训练数据和固定的计算预算，比较了1.25亿参数的Mamba和OPT模型。

Result: 虽然通常情况下序列越长越好，但最佳长度取决于任务和架构。较短的序列足以完成语法泛化任务，而较长的上下文有利于形态类比推理任务。

Conclusion: 研究结果表明，在BabyLM预训练中，序列长度的选择应根据具体的任务和所使用的模型架构进行调整，以达到最佳性能。

Abstract: Transformer language models typically operate with a fixed-length context
window, which has grown in step with large-scale pretraining datasets. In the
BabyLM Challenge, however, many past submissions have defaulted to using much
shorter sequence lengths. We examine the impact of sequence length on BabyLM
pretraining, to answer the simple question: what sequence length should we be
using when training Baby LMs? Using 100M-word training data and fixed compute
budgets, we compare 125M-parameter Mamba and OPT models, finding that although
longer is often better, the optimal length depends on both task and
architecture. Shorter sequences are sufficient for grammatical generalization
tasks whereas longer contexts benefit morphological analogical reasoning tasks.

</details>


### [46] [Lookahead Routing for Large Language Models](https://arxiv.org/abs/2510.19506)
*Canbin Huang,Tianyuan Shi,Yuhua Zhu,Ruijun Chen,Xiaojun Quan*

Main category: cs.CL

TL;DR: Lookahead是一个新的路由框架，它通过预测潜在的输出表示来预见模型输出，从而在不进行完全推理的情况下实现更明智的模型选择。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM路由方法通常将路由视为一个基于输入查询的分类问题，忽略了潜在输出中的有价值信息，并且未能捕捉到在响应生成过程中出现的隐式意图或上下文细微差别，这可能导致次优的路由决策。

Method: Lookahead通过预测潜在的输出表示来“预见”模型输出，并利用这些预测来指导模型选择。该框架基于因果语言模型和掩码语言模型实现了两种方法。

Result: 在七个公共基准测试中（涵盖指令遵循、数学推理和代码生成），Lookahead始终优于现有路由基线，其性能比现有技术平均提高了7.7%。

Conclusion: Lookahead框架通过预测潜在的输出表示来指导模型选择，从而在不进行完全推理的情况下实现了更准确和高效的LLM路由。

Abstract: Large language model (LLM) routers improve the efficiency of multi-model
systems by directing each query to the most appropriate model while leveraging
the diverse strengths of heterogeneous LLMs. Most existing approaches frame
routing as a classification problem based solely on the input query. While this
reduces overhead by avoiding inference across all models, it overlooks valuable
information that could be gleaned from potential outputs and fails to capture
implicit intent or contextual nuances that often emerge only during response
generation. These limitations can result in suboptimal routing decisions,
particularly for complex or ambiguous queries that require deeper semantic
understanding. To address this challenge, we propose Lookahead, a routing
framework that "foresees" potential model outputs by predicting their latent
representations and uses these predictions to guide model selection, thus
enabling more informed routing without full inference. Within this framework,
we implement two approaches based on causal and masked language models.
Empirical evaluations across seven public benchmarks - spanning instruction
following, mathematical reasoning, and code generation - show that Lookahead
consistently outperforms existing routing baselines, achieving an average
performance gain of 7.7% over the state-of-the-art. Our code is available at
https://github.com/huangcb01/lookahead-routing.

</details>


### [47] [Which Evaluation for Which Model? A Taxonomy for Speech Model Assessment](https://arxiv.org/abs/2510.19509)
*Maureen de Seyssel,Eeshan Gunesh Dhekane*

Main category: cs.CL

TL;DR: 这篇论文提出了一个统一的评估分类法，用于评估语音基础模型在各种任务中的能力。


<details>
  <summary>Details</summary>
Motivation: 尽管语音基础模型在各种任务中取得了显著成就，但其评估方法在任务和模型类型之间仍然是脱节的。不同的模型擅长语音处理的不同方面，因此需要不同的评估协议。

Method: 本文提出了一个统一的分类法，该分类法定义了三个正交轴：正在测量的评估方面、尝试任务所需的模型能力以及执行任务所需的任务或协议要求。作者根据这些轴对现有评估和基准进行了分类，涵盖了表示学习、语音生成和交互式对话等领域。

Result: 通过将每个评估映射到模型所展现的能力（例如，语音生成、实时处理）及其方法学要求（例如，微调数据、人工判断），该分类法提供了一个原则性框架，用于将模型与合适的评估方法对齐。

Conclusion: 这项工作为选择、解释和扩展语音模型评估提供了概念基础和实践指导。它还揭示了系统性差距，例如韵律、交互或推理的覆盖范围有限，这为未来基准设计指明了优先方向。

Abstract: Speech foundation models have recently achieved remarkable capabilities
across a wide range of tasks. However, their evaluation remains disjointed
across tasks and model types. Different models excel at distinct aspects of
speech processing and thus require different evaluation protocols. This paper
proposes a unified taxonomy that addresses the question: Which evaluation is
appropriate for which model? The taxonomy defines three orthogonal axes: the
\textbf{evaluation aspect} being measured, the model capabilities required to
attempt the task, and the task or protocol requirements needed to perform it.
We classify a broad set of existing evaluations and benchmarks along these
axes, spanning areas such as representation learning, speech generation, and
interactive dialogue. By mapping each evaluation to the capabilities a model
exposes (e.g., speech generation, real-time processing) and to its
methodological demands (e.g., fine-tuning data, human judgment), the taxonomy
provides a principled framework for aligning models with suitable evaluation
methods. It also reveals systematic gaps, such as limited coverage of prosody,
interaction, or reasoning, that highlight priorities for future benchmark
design. Overall, this work offers a conceptual foundation and practical guide
for selecting, interpreting, and extending evaluations of speech models.

</details>


### [48] [Conditions for Catastrophic Forgetting in Multilingual Translation](https://arxiv.org/abs/2510.19546)
*Danni Liu,Jan Niehues*

Main category: cs.CL

TL;DR: 本文系统性地研究了在多语言微调中引发灾难性遗忘的条件，发现在模型和数据规模之间的相对比例是遗忘的主要决定因素。


<details>
  <summary>Details</summary>
Motivation: 微调多语言基础模型时，经常出现灾难性遗忘，导致模型在未进行微调的语言上性能下降，但目前关于遗忘何时发生的研究结果较为分散。

Method: 本文使用机器翻译作为测试平台，通过控制不同模型架构、数据规模和微调方法的实验，来识别引发多语言微调中灾难性遗忘的条件。

Result: 研究发现模型和数据规模之间的相对比例是遗忘的主要决定因素；模型的指令遵循能力对于保留多语言知识比其架构更重要；参数高效微调在缓解遗忘方面并未显示出比全量微调更明显的优势；跨语言对齐可以减轻遗忘，同时促进向未见目标语言的正向迁移。

Conclusion: 本文通过系统性研究，明确了多语言微调中灾难性遗忘的发生条件，并为缓解遗忘提供了新的视角，即关注模型与数据规模的相对比例，以及利用跨语言对齐。

Abstract: Fine-tuning multilingual foundation models on specific languages often
induces catastrophic forgetting, degrading performance on languages unseen in
fine-tuning. While this phenomenon is widely-documented, the literature
presents fragmented results about when forgetting occurs. To address this
ambiguity, we conduct a systematic empirical study using machine translation as
a testbed to identify the conditions that trigger catastrophic forgetting in
multilingual fine-tuning. Through controlled experiments across different model
architectures, data scales, and fine-tuning approaches, we reveal that the
relative scale between model and data size is a primary determinant of
forgetting. Moreover, we demonstrate that a model's instruction-following
ability is more critical for retaining multilingual knowledge than its
architecture. Contrary to assumptions, parameter-efficient fine-tuning offers
no clear advantage over full fine-tuning in mitigating forgetting. Lastly, we
show that cross-lingual alignment can mitigate forgetting while also
facilitating positive transfer to unseen target languages.

</details>


### [49] [Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark](https://arxiv.org/abs/2510.19585)
*Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen*

Main category: cs.CL

TL;DR: 本文介绍了一个从多语言历史文档中提取拉丁语片段的任务。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型在处理混合语言历史文献中拉丁语片段提取的潜力尚未得到充分开发和评估，尤其是在应对版面多样性方面。

Method: 通过在一个包含724个标注页面的多模态数据集上，对大型基础模型进行基准测试和性能评估。

Result: 实验结果表明，利用现有模型可以实现可靠的拉丁语检测。

Conclusion: 本研究首次全面分析了这些模型在该任务上的能力和局限性。

Abstract: This paper presents a novel task of extracting Latin fragments from
mixed-language historical documents with varied layouts. We benchmark and
evaluate the performance of large foundation models against a multimodal
dataset of 724 annotated pages. The results demonstrate that reliable Latin
detection with contemporary models is achievable. Our study provides the first
comprehensive analysis of these models' capabilities and limits for this task.

</details>


### [50] [PBBQ: A Persian Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models](https://arxiv.org/abs/2510.19616)
*Farhan Farsi,Shayan Bali,Fatemeh Valeh,Parsa Ghofrani,Alireza Pakniat,Kian Kashfipour,Amir H. Payberah*

Main category: cs.CL

TL;DR: 本文介绍了PBBQ，这是一个旨在评估波斯语大型语言模型中社会偏见的大型基准数据集。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的普及，确保其符合社会规范已成为一个关键问题。虽然现有研究检查了各种语言中的偏见检测，但在解决波斯文化背景下的社会偏见方面仍然存在显著的资源空白。

Method: PBBQ基准测试涵盖16个文化类别，通过250名来自不同 KSA 的个体的问卷调查开发，并与社会科学专家密切合作以确保其有效性。PBBQ数据集包含超过37,000个精心策划的问题。作者通过PBBQ评估了几种开源LLM、一个闭源模型和波斯语特定的微调模型。

Result: 目前发现LLM在波斯文化中表现出显著的社会偏见。此外，通过比较模型输出和人类回答，我们观察到LLM经常复制人类偏见模式，这突显了学习到的表征和文化刻板印象之间复杂的相互作用。

Conclusion: PBBQ是第一个针对波斯语大语言模型的社会偏见基准测试数据集，它揭示了当前LLM中存在的显著社会偏见，并强调了未来在偏见缓解方面的工作。

Abstract: With the increasing adoption of large language models (LLMs), ensuring their
alignment with social norms has become a critical concern. While prior research
has examined bias detection in various languages, there remains a significant
gap in resources addressing social biases within Persian cultural contexts. In
this work, we introduce PBBQ, a comprehensive benchmark dataset designed to
evaluate social biases in Persian LLMs. Our benchmark, which encompasses 16
cultural categories, was developed through questionnaires completed by 250
diverse individuals across multiple demographics, in close collaboration with
social science experts to ensure its validity. The resulting PBBQ dataset
contains over 37,000 carefully curated questions, providing a foundation for
the evaluation and mitigation of bias in Persian language models. We benchmark
several open-source LLMs, a closed-source model, and Persian-specific
fine-tuned models on PBBQ. Our findings reveal that current LLMs exhibit
significant social biases across Persian culture. Additionally, by comparing
model outputs to human responses, we observe that LLMs often replicate human
bias patterns, highlighting the complex interplay between learned
representations and cultural stereotypes.Upon acceptance of the paper, our PBBQ
dataset will be publicly available for use in future work. Content warning:
This paper contains unsafe content.

</details>


### [51] [Style Attack Disguise: When Fonts Become a Camouflage for Adversarial Intent](https://arxiv.org/abs/2510.19641)
*Yangshijie Zhang,Xinda Wang,Jialin Liu,Wenqiang Wang,Zhicong Ma,Xingxing Jia*

Main category: cs.CL

TL;DR: 这篇论文揭示了由于人类和模型在识别文本风格上的差异，导致自然语言处理模型容易受到一种名为SAD的样式攻击，该攻击通过引入样式字体或类似字体的表情符号来降低模型性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体用户利用样式字体和类似字体的表情符号来表达个性，但这些视觉上吸引人的文本却给自然语言处理模型带来了隐患。人类可以轻松阅读这些样式文本，但模型却将它们识别为不同的标记，从而导致干扰，因此论文旨在解决这种人-模型感知差距。

Method: 本文提出了一种基于样式攻击的方法，名为“样式攻击伪装”（SAD），并设计了两种规模：轻量级（追求查询效率）和强力型（追求卓越的攻击性能）。

Result: 在情感分类和机器翻译任务中，针对传统模型、大型语言模型（LLMs）和商业服务进行的实验表明，SAD展现出强大的攻击性能。研究还发现SAD对多模态任务（包括文本到图像和文本到语音生成）也存在潜在威胁。

Conclusion: 样式字体和类似字体的表情符号在带给用户个性的同时，也对NLP模型带来了新的安全隐患。SAD攻击利用了人-模型感知差距，在多种任务上表现出强大的攻击能力，这提示我们需要重新审视模型在处理这类文本时的鲁棒性。

Abstract: With social media growth, users employ stylistic fonts and font-like emoji to
express individuality, creating visually appealing text that remains
human-readable. However, these fonts introduce hidden vulnerabilities in NLP
models: while humans easily read stylistic text, models process these
characters as distinct tokens, causing interference. We identify this
human-model perception gap and propose a style-based attack, Style Attack
Disguise (SAD). We design two sizes: light for query efficiency and strong for
superior attack performance. Experiments on sentiment classification and
machine translation across traditional models, LLMs, and commercial services
demonstrate SAD's strong attack performance. We also show SAD's potential
threats to multimodal tasks including text-to-image and text-to-speech
generation.

</details>


### [52] [LLavaCode: Compressed Code Representations for Retrieval-Augmented Code Generation](https://arxiv.org/abs/2510.19644)
*Daria Cherniuk,Nikita Sukhorukov,Nikita Sushko,Daniil Gusak,Danil Sivtsov,Elena Tutubalina,Evgeny Frolov*

Main category: cs.CL

TL;DR: LlavaCode框架通过将代码压缩为紧凑的语义丰富表示形式，以减少检索上下文的长度，从而提升代码补全的生成质量并降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 在交互式IDE环境中，代码补全时整合代码上下文会导致序列长度显著增加，从而降低推理速度。

Method: LlavaCode框架将代码压缩成紧凑且语义丰富的表示，通过小型投影模块，将检索到的上下文编码为少量压缩的单token向量。

Result: 与完整的RAG管道相比，LlavaCode在行补全任务中将Time-to-First-Token（TTFT）减少了20-38%，并且显著提高了编码模型的EM和ES指标，同时只引入了可忽略的延迟增加。

Conclusion: LlavaCode通过有效的代码压缩和上下文表示，成功解决了传统检索增强生成模型在代码补全中遇到的长序列和高延迟问题，为交互式代码开发提供了更快速、高质量的解决方案。

Abstract: Retrieval-augmented generation has emerged as one of the most effective
approaches for code completion, particularly when context from a surrounding
repository is essential. However, incorporating context significantly extends
sequence length, leading to slower inference - a critical limitation for
interactive settings such as IDEs. In this work, we introduce LlavaCode, a
framework that compresses code into compact, semantically rich representations
interpretable by code LLM, enhancing generation quality while reducing the
retrieved context to only a few compressed single-token vectors. Using a small
projector module we can significantly increase the EM and ES metrics of coding
model with negligible latency increase. Our experiments demonstrate that
compressed context enables 20-38% reduction in Time-to-First-Token (TTFT) on
line completion tasks compared to full-RAG pipelines.

</details>


### [53] [Unraveling Emotions with Pre-Trained Models](https://arxiv.org/abs/2510.19668)
*Alejandro Pajón-Sanmartín,Francisco De Arriba-Pérez,Silvia García-Méndez,Fátima Leal,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.CL

TL;DR: 本文比较了在情感识别中，微调和提示工程在三种不同场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在情感识别方面取得了显著进展，但在探索大型语言模型（LLM）的开放式查询时仍存在挑战。自动情感分析在开放文本中面临上下文模糊、语言变异和复杂情感表达解释困难等挑战，这使得通用模型的直接应用变得困难。

Method: 本文比较了在情感识别中微调和提示工程的有效性，具体在以下三种场景中进行：1. 比较微调预训练模型和使用简单提示的通用LLM的性能；2. 评估不同情感提示设计对LLM的有效性；3. 评估情感分组技术对这些模型的影响。

Result: 经过微调的预训练情感识别模型在实验测试中达到了70%以上的效果。研究结果强调，LLM需要结构化的提示工程和情感分组来提高其性能。

Conclusion: 这些进展改进了情感分析、人机交互以及对各种领域用户行为的理解。

Abstract: Transformer models have significantly advanced the field of emotion
recognition. However, there are still open challenges when exploring open-ended
queries for Large Language Models (LLMs). Although current models offer good
results, automatic emotion analysis in open texts presents significant
challenges, such as contextual ambiguity, linguistic variability, and
difficulty interpreting complex emotional expressions. These limitations make
the direct application of generalist models difficult. Accordingly, this work
compares the effectiveness of fine-tuning and prompt engineering in emotion
detection in three distinct scenarios: (i) performance of fine-tuned
pre-trained models and general-purpose LLMs using simple prompts; (ii)
effectiveness of different emotion prompt designs with LLMs; and (iii) impact
of emotion grouping techniques on these models. Experimental tests attain
metrics above 70% with a fine-tuned pre-trained model for emotion recognition.
Moreover, the findings highlight that LLMs require structured prompt
engineering and emotion grouping to enhance their performance. These
advancements improve sentiment analysis, human-computer interaction, and
understanding of user behavior across various domains.

</details>


### [54] [DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference](https://arxiv.org/abs/2510.19669)
*Xiang Liu,Xuming Hu,Xiaowen Chu,Eunsol Choi*

Main category: cs.CL

TL;DR: LLMs在解决问题时常出现冗长的思考过程，本研究旨在提高其效率。我们通过分析token概率的熵，发现了一个U型熵模式，表明在简单问题上存在“过度思考”现象。在此基础上，我们引入了DiffAdapt框架，根据问题难度和推理轨迹熵为每个问题选择Easy/Normal/Hard推理策略，从而在不微调LLM的情况下，实现与现有方法相当或更好的准确性，并减少高达22.4%的token使用量。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLMs）解决问题的效率，使其在不过度思考的情况下达到高性能。

Method: 1. 分析LLM推理轨迹中token概率的熵，发现U型熵模式，尤其是在简单问题上存在“过度思考”现象。
2. 提出DiffAdapt框架，根据问题难度和推理轨迹熵为每个问题选择Easy/Normal/Hard推理策略。
3. DiffAdapt通过一个对LLM最终隐藏状态进行分类的小型探测器进行适应，而不是微调基础LLM。

Result: DiffAdapt在五种模型和八个基准测试中，实现了与现有方法相当或更高的准确性。
DiffAdapt将token使用量减少了高达22.4%。

Conclusion: DiffAdapt为计算高效的LLM推理提供了一条实用路径，在不牺牲性能的情况下显著提高了效率。

Abstract: Recent reasoning Large Language Models (LLMs) demonstrate remarkable
problem-solving abilities but often generate long thinking traces whose utility
is unclear. Our work aims to improve their efficiency, enabling them to reach
high performance without overthinking. First, we analyze the entropy of token
probabilities in reasoning traces. Across three models, we observe a consistent
U-shaped entropy pattern: high entropy on easy problems despite high accuracy,
low entropy on problems with medium difficulty, and high entropy on hard
problems reflecting uncertainty. Specifically, we notice 22--25\% entropy
reduction from easy to medium difficulty regions, suggesting an {overthinking}
phenomenon on easy instances. Building on these insights, we introduce
\textbf{DiffAdapt}, a lightweight framework that selects Easy/Normal/Hard
inference strategies per question based on their difficulty and reasoning trace
entropy. Each inference strategy consists of a fixed prompt, temperature and
maximum token length. In contrast to existing efficiency optimization methods,
our approach does not fine-tune base LLM but a small probe that classifies
LLM's final hidden state, allowing inexpensive adaptation. We comprehensively
evaluate our method on five models and eight benchmarks. Our method achieves
comparable or improved accuracy while reducing token usage by up to 22.4\%,
establishing a practical path toward compute-efficient reasoning.

</details>


### [55] [CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](https://arxiv.org/abs/2510.19670)
*Hasan Akgul,Mari Eplik,Javier Rojas,Aina Binti Abdullah,Pieter van der Merwe*

Main category: cs.CL

TL;DR: CoSense-LLM是一个边缘优先的框架，它将多模态传感器数据转化为紧凑、可验证的语义token，并在延迟、能耗、带宽和隐私约束下与大型语言模型协同工作。


<details>
  <summary>Details</summary>
Motivation: 在大模型部署中，如何在干扰严重的环境下，在语义、隐私和可预测延迟方面达到平衡。

Method: CoSense-LLM框架包含四个部分：SenseFusion（轻量级编码器，对齐传感器嵌入并压缩为离散代码）、Edge-RAG（本地混合检索层，基于站点策略生成内容）、PromptRouter（成本和不确定性感知的策略，选择生成方式）和Secure Execution（可审计的编辑路径，确保原始波形不离开设备）。该系统支持现代服务优化，包括分页或流式KV缓存、FlashAttention风格的内核、推测解码和量化LoRA适配器，并支持设备上的个性化和联邦更新。

Result: CoSense-LLM在家庭、办公室和诊所部署中提供了有根据的解释，同时满足严格的服务水平目标：在边缘主导路径上保持亚秒级（p95）端到端延迟，通过优先选择本地检索来降低层间token和带宽成本，并通过仅传输离散代码和编辑后的元数据来保护隐私。消融实验表明，Edge-RAG提高了事实一致性并减少了矛盾，校准的不确定性实现了选择性弃权和受控升级，KV加解码加速器降低了每次决策的能耗。

Conclusion: CoSense-LLM的边缘优先设计将语义、隐私和可预测延迟视为在干扰严重环境中部署大型模型的同等重要目标。

Abstract: We present CoSense-LLM, an edge-first framework that turns continuous
multimodal sensor streams (for example Wi-Fi CSI, IMU, audio, RFID, and
lightweight vision) into compact, verifiable semantic tokens and coordinates
with large language models under explicit latency, energy, bandwidth, and
privacy constraints. CoSense-LLM has four parts: (i) SenseFusion, a lightweight
encoder that aligns sensor embeddings with language and compresses them into
short discrete code sequences; (ii) Edge-RAG, a local hybrid retrieval layer
that grounds generation in site specific policies and notes; (iii)
PromptRouter, a cost and uncertainty aware policy that selects edge only
generation, edge plus retrieval, or compact cloud escalation; and (iv) Secure
Execution, an auditable redaction path that enforces data minimization so raw
waveforms never leave the device. The system works with modern serving
optimizations, including paged or streaming KV caches, FlashAttention style
kernels, speculative decoding, and quantized LoRA adapters, and supports on
device personalization and federated updates under non IID drift. Across home,
office, and clinic deployments, CoSense-LLM delivers grounded explanations
while meeting tight service level objectives: it sustains sub second (p95) end
to end latency on edge dominant paths, reduces inter tier token and bandwidth
costs by preferring local retrieval grounded responses, and preserves privacy
by transmitting only discrete codes and redacted metadata. Ablations show that
Edge-RAG improves factual consistency and reduces contradictions, calibrated
uncertainty enables selective abstention and controlled escalations, and KV
plus decoding accelerators lower energy per decision. The results support an
edge first design that treats semantics, privacy, and predictable latency as co
equal goals for large model deployments in interference prone environments.

</details>


### [56] [Do Prompts Reshape Representations? An Empirical Study of Prompting Effects on Embeddings](https://arxiv.org/abs/2510.19694)
*Cesar Gonzalez-Gutierrez,Dirk Hovy*

Main category: cs.CL

TL;DR: 这篇论文研究了在零样本设置中，提示（prompting）如何影响语言模型的内部表示，并挑战了更相关提示会带来更好表示的假设。


<details>
  <summary>Details</summary>
Motivation: 研究提示如何影响语言模型内部表示的质量，并深入理解预训练嵌入如何支持上下文任务解决。

Method: 通过一系列探测实验，分析了零样本分类中提示嵌入和不同提示模板组合。

Result: 提示会影响表示质量，但这些变化与提示对目标任务的相关性之间没有持续关联。

Conclusion: 挑战了更相关的提示必然会产生更好表示的假设，并分析了导致这种意外行为的潜在因素。

Abstract: Prompting is a common approach for leveraging LMs in zero-shot settings.
However, the underlying mechanisms that enable LMs to perform diverse tasks
without task-specific supervision remain poorly understood. Studying the
relationship between prompting and the quality of internal representations can
shed light on how pre-trained embeddings may support in-context task solving.
In this empirical study, we conduct a series of probing experiments on prompt
embeddings, analyzing various combinations of prompt templates for zero-shot
classification. Our findings show that while prompting affects the quality of
representations, these changes do not consistently correlate with the relevance
of the prompts to the target task. This result challenges the assumption that
more relevant prompts necessarily lead to better representations. We further
analyze potential factors that may contribute to this unexpected behavior.

</details>


### [57] [From Answers to Guidance: A Proactive Dialogue System for Legal Documents](https://arxiv.org/abs/2510.19723)
*Ashish Chouhan,Michael Gertz*

Main category: cs.CL

TL;DR: 本文介绍了EUDial数据集和LexGuide框架，旨在通过主动式多轮对话帮助普通民众理解复杂的欧盟法律信息。


<details>
  <summary>Details</summary>
Motivation: 尽管欧盟提供了开放的法律信息获取途径，但普通民众在理解和利用这些复杂机构文本方面仍面临挑战。

Method: 本文构建了EUDial数据集，该数据集包含来自欧洲议会研究服务公民咨询部门（AskEP）的204个博客文章中整理出的880个对话轮次。在此基础上，提出了LexGuide框架，该框架利用带有分层主题组织的检索增强生成技术来构建对话流程。

Result: 主动的、结构化的导航弥合了法律信息的可获得性与公民理解之间的鸿沟。

Conclusion: EUDial和LexGuide为推进主动式法律对话系统提供了实用的资源。

Abstract: The accessibility of legal information remains a constant challenge,
particularly for laypersons seeking to understand and apply complex
institutional texts. While the European Union provides open access to
legislation, parliamentary responses, and regulatory documents, these resources
can be challenging for laypeople to explore. In this paper, we introduce
EUDial, a proactive multi-turn dialogue dataset constructed from 204 blogs
curated by the Citizens' Enquiries Unit (AskEP) of the European Parliamentary
Research Service. EUDial contains 880 dialogue turns (averaging 4.3 turns per
dialogue), where each dialogue includes initial questions, structured answers,
and follow-up questions. Beyond dataset construction, we propose the LexGuide
framework that leverages retrieval-augmented generation with hierarchical topic
organization to structure dialogue progression, ensuring both comprehensive
coverage of legal aspects and coherence across conversational turns. The
results demonstrate that proactive, structured navigation closes the gap
between the availability of legal information and citizen comprehension,
establishing EUDial and LexGuide as practical resources for advancing proactive
legal dialogue systems.

</details>


### [58] [SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration](https://arxiv.org/abs/2510.19767)
*Xichen Zhang,Sitong Wu,Haoru Tan,Shaozuo Yu,Yinghao Zhu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: 为了解决大型语言模型在复杂推理任务中“浅层思考”的问题，本研究提出了一种名为SmartSwitch的推理框架。该框架通过监测模型推理过程，并在检测到有潜力的思考被过早放弃时，插入“深化提示”以引导模型进行更深入的探索。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理任务中存在“浅层思考”（underthinking）的问题，即模型频繁切换思路而没有进行充分的探索，这限制了模型性能和token效率。

Method: SmartSwitch推理框架有两个核心模块：感知模块和干预模块。感知模块负责识别思维转换点，并使用现成的过程奖励模型（PRM）评估之前思维的潜力。如果发现一个高潜力的思维被过早放弃，干预模块会中断当前的推理过程，回溯到转换点之前，并插入一个“深化提示”，以鼓励模型沿着有前途的路径进行更深入的探索。

Result: 在具有挑战性的数学推理基准测试中进行了广泛的实验，结果表明该方法显著提高了不同规模的各种大型语言模型的性能。

Conclusion: SmartSwitch框架通过有效解决大型语言模型中的“浅层思考”问题，显著提升了模型在复杂推理任务中的表现，且该框架具有良好的通用性和可集成性。

Abstract: The long chain-of-thought (LongCoT) capability is central to the recent
breakthroughs achieved by large language models in complex reasoning tasks.
However, the accompanying issue of ''underthinking'', where models exhibit
shallow reasoning by frequently switching thoughts without sufficient
exploration, limits both performance and token efficiency. To address this
problem, we propose a simple yet effective reasoning strategy: the SmartSwitch
inference framework. This framework can be easily integrated into any large
language model as a plug-and-play solution, continuously monitoring the model's
reasoning process to detect underthinking and guide it toward deeper
exploration of promising but overlooked thoughts. Specifically, the perception
module identifies points where thoughts switch and evaluates the potential of
the preceding thought using an off-the-shelf process reward model (PRM). If a
high-potential thought is found to be prematurely abandoned, the intervention
module interrupts the ongoing inference, backtracks to the point before the
switch, and inserts a "deepening prompt" to encourage further exploration along
that promising path. Extensive experiments on challenging mathematical
reasoning benchmarks demonstrate that our method significantly enhances the
performance of various large language models of different sizes.

</details>


### [59] [AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders](https://arxiv.org/abs/2510.19779)
*Yuezhou Hu,Jiaxin Guo,Xinyu Feng,Tuo Zhao*

Main category: cs.CL

TL;DR: AdaSPEC：一种针对LLM推理加速的解码方法，通过选择性地过滤难以拟合的token，提高了draft模型和target模型的对齐度，从而加速解码过程。


<details>
  <summary>Details</summary>
Motivation: 以往的知识蒸馏方法旨在最小化草稿模型和目标模型之间所有token的KL散度，这与SD最大化token接受率的真正目标不符。草稿模型通常难以完全吸收目标模型的知识，导致性能不佳。

Method: 本文提出了AdaSPEC，一种在知识蒸馏过程中引入选择性token过滤的新方法。AdaSPEC利用参考模型识别并过滤掉难以拟合的token，使草稿模型能够更好地与目标模型在更简单的token上对齐。

Result: AdaSPEC在算术推理、指令遵循、编码和摘要等不同任务上，使用31M/1.4B和350M/2.7B参数的模型配置进行了评估。结果表明，AdaSPEC始终优于最先进的DistillSpec方法，在所有任务中均获得更高的接受率（最高可达15%）。

Conclusion: 通过选择性地过滤难以拟合的token，AdaSPEC提高了草稿模型和目标模型之间的对齐度，从而在不影响生成质量的前提下，提高了整体token接受率，加速了大型语言模型推理。

Abstract: Speculative Decoding (SD) accelerates large language model inference by
employing a small draft model to generate predictions, which are then verified
by a larger target model. The effectiveness of SD hinges on the alignment
between these models, which is typically enhanced by Knowledge Distillation
(KD). However, conventional KD methods aim to minimize the KL divergence
between the draft and target models across all tokens, a goal that is
misaligned with the true objective of SD, which is to maximize token acceptance
rate. Therefore, draft models often struggle to fully assimilate the target
model's knowledge due to capacity constraints, leading to suboptimal
performance. To address this challenge, we propose AdaSPEC, a novel method that
incorporates selective token filtering into the KD process. AdaSPEC utilizes a
reference model to identify and filter out difficult-to-fit tokens, enabling
the distillation of a draft model that better aligns with the target model on
simpler tokens. This approach improves the overall token acceptance rate
without compromising generation quality. We evaluate AdaSPEC across diverse
tasks, including arithmetic reasoning, instruction-following, coding, and
summarization, using model configurations of 31M/1.4B and 350M/2.7B parameters.
Our results demonstrate that AdaSPEC consistently outperforms the
state-of-the-art DistillSpec method, achieving higher acceptance rates across
all tasks (up to 15\%). The code is publicly available at
https://github.com/yuezhouhu/adaspec.

</details>


### [60] [Adapting Multilingual Models to Code-Mixed Tasks via Model Merging](https://arxiv.org/abs/2510.19782)
*Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本文提出了一种针对混合语言NLP任务的模型合并新方法，该方法在多种语言设置下，其性能优于传统的全量微调和持续预训练方法。


<details>
  <summary>Details</summary>
Motivation: 传统的混合语言NLP适应策略存在局限性。

Method: 该方法包括三个步骤：1. 对未标记的混合语言文本进行持续预训练（CPT），以获得适应检查点。2. 将适应检查点与基础模型合并。3. 在下游任务数据上进行微调（FT）。

Result: 合并模型在F1分数上优于全量微调（提高2-5点）和CPT->FT（提高1-2点）。在跨语言对迁移任务中，合并模型的性能也优于单语英语基线。

Conclusion: 模型合并是处理混合语言任务的一种有效策略，尤其在数据资源有限的情况下，且需要跨语言迁移的场景中表现出色。

Abstract: We study model merging as a practical alternative to conventional adaptation
strategies for code-mixed NLP. Starting from a multilingual base model, we: (i)
perform continued pre-training (CPT) on unlabeled code-mixed text to obtain an
adapted checkpoint, (ii) merge checkpoint with the base model, and (iii)
fine-tune (FT) on the downstream task data. We evaluate our approach for
sentence classification (sentiment and hate speech) task in English-Hindi
(En-Hi) and English-Spanish (En-Es) using XLM-R and Llama-3.2-1B models. Our
results show that merged models consistently outperform full fine-tuning and
CPT->FT. We observe gains of 2--5 points in F1 over full fine-tuning and ~1-2
points over CPT->FT, indicating that unlabeled data is leveraged more
effectively via merging than via CPT alone. Zero-/few-shot prompting with
larger LLMs (e.g., Llama-3.3-70B) lags behind fine-tuned and merged
checkpoints, underscoring limits of in-context learning for code-mixed inputs.
We further test cross-pair transfer by training on En-Hi and evaluating on
En-Ta and En-Ml: merged checkpoints transfer more strongly than
monolingual-English baselines (e.g., TV/TIES variants reaching 0.65-0.68 F1 vs
0.61-0.63 for full fine-tuning), suggesting that code-mixed knowledge is a more
reliable substrate for low-resource pairs. We conclude with adaptation recipes
matched to common data regimes (labeled only; labeled+unlabeled; transfer-only)
and discuss limitations and scaling considerations for broader tasks and larger
models.

</details>


### [61] [ToolDreamer: Instilling LLM Reasoning Into Tool Retrievers](https://arxiv.org/abs/2510.19791)
*Saptarshi Sengupta,Zhengyu Zhou,Jun Araki,Xingbo Wang,Bingqing Wang,Suhang Wang,Zhe Feng*

Main category: cs.CL

TL;DR: 这篇论文提出了一个名为ToolDreamer的框架，旨在解决大型语言模型在处理大规模工具集时，检索工具效率低下的问题。ToolDreamer通过生成假设性的工具描述来更好地对齐用户查询和工具，从而提高工具检索的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理大规模工具集时，由于将所有工具包含在上下文窗口中会导致超出限制，因此需要外部检索器来提供最相关的工具。然而，现有的检索模型仅基于用户查询和工具描述之间的相似性进行排序，这导致检索效果不佳，因为用户请求的语言与工具描述的语言往往不一致。

Method: 我们提出了ToolDreamer框架，它通过使用大型语言模型生成假设性的（合成的）工具描述来调整检索器模型。这些假设性描述是大型语言模型认为可能对查询有用的工具描述。这种方法旨在在工具描述的语言空间内实现查询和工具之间更自然的对齐。

Result: 我们将ToolDreamer应用于ToolRet数据集，结果表明我们的方法改善了稀疏和密集检索器的性能，无论是否经过训练，这展示了其灵活性。

Conclusion: 通过我们提出的框架，我们的目标是将一部分推理负担转移给检索器，以便大型语言模型能够有效地处理大量工具，而不会使其上下文窗口过载。

Abstract: Tool calling has become increasingly popular for Large Language Models
(LLMs). However, for large tool sets, the resulting tokens would exceed the
LLM's context window limit, making it impossible to include every tool. Hence,
an external retriever is used to provide LLMs with the most relevant tools for
a query. Existing retrieval models rank tools based on the similarity between a
user query and a tool description (TD). This leads to suboptimal retrieval as
user requests are often poorly aligned with the language of TD. To remedy the
issue, we propose ToolDreamer, a framework to condition retriever models to
fetch tools based on hypothetical (synthetic) TD generated using an LLM, i.e.,
description of tools that the LLM feels will be potentially useful for the
query. The framework enables a more natural alignment between queries and tools
within the language space of TD's. We apply ToolDreamer on the ToolRet dataset
and show that our method improves the performance of sparse and dense
retrievers with and without training, thus showcasing its flexibility. Through
our proposed framework, our aim is to offload a portion of the reasoning burden
to the retriever so that the LLM may effectively handle a large collection of
tools without inundating its context window.

</details>


### [62] [The Art of Asking: Multilingual Prompt Optimization for Synthetic Data](https://arxiv.org/abs/2510.19806)
*David Mora,Viraat Aryabumi,Wei-Yin Ko,Sara Hooker,Julia Kreutzer,Marzieh Fadaee*

Main category: cs.CL

TL;DR: 本文提出了一种通过优化提示空间来改进多语言大模型的轻量级框架，该框架通过自然性、文化适应性和难度增强等方面对翻译提示进行系统转换，在相同数据条件下，取得了显著的下游改进。


<details>
  <summary>Details</summary>
Motivation: 目前多语言大模型的合成数据应用受限于基于翻译的提示，这种策略继承了以英语为中心的框架和风格，忽略了文化维度，最终限制了模型的泛化能力。

Method: 引入了一个轻量级的提示空间优化框架，系统地转换翻译后的提示，以提高自然性、文化适应性和难度。

Result: 在相同的“数据条件”下，我们的方法在多种语言和任务中取得了显著且持续的改进：Global-MMLU 准确性提高了4.7%；Flores XCometXL 提高了2.4%；mArenaHard 偏好胜率提高了35.3%。

Conclusion: 提示空间优化是一种简单而有效的新范式，可用于构建更鲁棒、更具文化底蕴和全球能力的多语言大型语言模型。

Abstract: Synthetic data has become a cornerstone for scaling large language models,
yet its multilingual use remains bottlenecked by translation-based prompts.
This strategy inherits English-centric framing and style and neglects cultural
dimensions, ultimately constraining model generalization. We argue that the
overlooked prompt space-the very inputs that define training
distributions-offers a more powerful lever for improving multilingual
performance. We introduce a lightweight framework for prompt-space
optimization, where translated prompts are systematically transformed for
Naturalness, Cultural Adaptation, and Difficulty Enhancement. Using an
off-the-shelf multilingual LLM, we apply these transformations to prompts for
12 languages spanning 7 families. Under identical data conditions, our
approaches achieve substantial and consistent downstream improvements over the
translation-only baseline: +4.7% on Global-MMLU accuracy, +2.4% on Flores
XCometXL and +35.3% wins in preferences on mArenaHard. We establish
prompt-space optimization as a simple yet powerful paradigm for building
multilingual LLMs that are more robust, culturally grounded, and globally
capable.

</details>


### [63] [Scaf-GRPO: Scaffolded Group Relative Policy Optimization for Enhancing LLM Reasoning](https://arxiv.org/abs/2510.19807)
*Xichen Zhang,Sitong Wu,Yinghao Zhu,Haoru Tan,Shaozuo Yu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: 本文介绍了Scaf-GRPO方**, 这是一种通过在模型学习停滞时提供分层提示来克服大语言模型中存在的“学习鸿沟”问题的技术。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理复杂推理任务时，会遇到“学习鸿沟”的问题，即当问题超出其当前能力时，模型无法获得奖励信号，导致学习停滞。

Method: Scaf-GRPO（Scaffolded Group Relative Policy Optimization）框架首先诊断学习停滞，然后通过注入分层提示进行干预，这些提示从抽象概念到具体步骤，帮助模型构建有效的解决方案。

Result: Scaf-GRPO在具有挑战性的数学基准测试中表现出色，将Qwen2.5-Math-7B模型在AIME24基准上的pass@1分数相对 vanilla GRPO 基线提高了44.3%。

Conclusion: Scaf-GRPO为LLM解决之前无法解决的问题提供了一种强大而有效的方法，是推动LLM自主推理能力发展的关键一步。

Abstract: Reinforcement learning from verifiable rewards has emerged as a powerful
technique for enhancing the complex reasoning abilities of Large Language
Models (LLMs). However, these methods are fundamentally constrained by the
''learning cliff'' phenomenon: when faced with problems far beyond their
current capabilities, models consistently fail, yielding a persistent
zero-reward signal. In policy optimization algorithms like GRPO, this collapses
the advantage calculation to zero, rendering these difficult problems invisible
to the learning gradient and stalling progress. To overcome this, we introduce
Scaf-GRPO (Scaffolded Group Relative Policy Optimization), a progressive
training framework that strategically provides minimal guidance only when a
model's independent learning has plateaued. The framework first diagnoses
learning stagnation and then intervenes by injecting tiered in-prompt hints,
ranging from abstract concepts to concrete steps, enabling the model to
construct a valid solution by itself. Extensive experiments on challenging
mathematics benchmarks demonstrate Scaf-GRPO's effectiveness, boosting the
pass@1 score of the Qwen2.5-Math-7B model on the AIME24 benchmark by a relative
44.3% over a vanilla GRPO baseline. This result demonstrates our framework
provides a robust and effective methodology for unlocking a model's ability to
solve problems previously beyond its reach, a critical step towards extending
the frontier of autonomous reasoning in LLM.

</details>


### [64] [Hubble: a Model Suite to Advance the Study of LLM Memorization](https://arxiv.org/abs/2510.19811)
*Johnny Tian-Zheng Wei,Ameya Godbole,Mohammad Aflah Khan,Ryan Wang,Xiaoyuan Zhu,James Flemings,Nitya Kashyap,Krishna P. Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: Hubble是用于大语言模型（LLM）记忆化科学研究的开源模型套件，包括标准模型和扰动模型。研究表明，记忆化风险取决于敏感数据在训练语料库中的频率，并提出了稀释敏感数据和在训练早期引入敏感数据的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 探索和理解大语言模型的记忆化机制，并找出降低记忆化风险的有效策略。

Method: 开发并发布了Hubble模型套件，包括1B和8B参数的标准模型和扰动模型，分别在100B或500B token上进行预训练。通过控制文本插入，模拟关键记忆化风险，并分析敏感数据插入的时间对记忆化的影响。

Result: 记忆化风险取决于敏感数据相对于训练语料库大小的频率。没有持续暴露的敏感数据可能会被遗忘。建议通过增加训练语料库大小来稀释敏感数据，并在训练早期引入敏感数据。Hubble模型套件还可用于成员推理和机器遗忘等研究。

Conclusion: Hubble模型套件为LLM记忆化研究提供了一个开放且可控的平台，研究结果揭示了影响记忆化的关键因素，并提出了降低记忆化风险的实用建议。它有望推动LLM记忆化、成员推理和机器遗忘等领域的进一步研究。

Abstract: We present Hubble, a suite of fully open-source large language models (LLMs)
for the scientific study of LLM memorization. Hubble models come in standard
and perturbed variants: standard models are pretrained on a large English
corpus, and perturbed models are trained in the same way but with controlled
insertion of text (e.g., book passages, biographies, and test sets) designed to
emulate key memorization risks. Our core release includes 8 models -- standard
and perturbed models with 1B or 8B parameters, pretrained on 100B or 500B
tokens -- establishing that memorization risks are determined by the frequency
of sensitive data relative to size of the training corpus (i.e., a password
appearing once in a smaller corpus is memorized better than the same password
in a larger corpus). Our release also includes 6 perturbed models with text
inserted at different pretraining phases, showing that sensitive data without
continued exposure can be forgotten. These findings suggest two best practices
for addressing memorization risks: to dilute sensitive data by increasing the
size of the training corpus, and to order sensitive data to appear earlier in
training. Beyond these general empirical findings, Hubble enables a broad range
of memorization research; for example, analyzing the biographies reveals how
readily different types of private information are memorized. We also
demonstrate that the randomized insertions in Hubble make it an ideal testbed
for membership inference and machine unlearning, and invite the community to
further explore, benchmark, and build upon our work.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [65] [Recursive decoding of binary rank Reed-Muller codes and Plotkin construction for matrix codes](https://arxiv.org/abs/2510.19095)
*Alain Couvreur,Rakhi Pratihar*

Main category: cs.IT

TL;DR: 本文介绍了一种在“二元”情况下（即当G = (Z/2Z)^m时）的秩度量Reed-Muller码的解码方法，其灵感来自于对Plotkin构造的汉明度量二进制Reed-Muller码的解码。该算法的渐近复杂度优于最近提出的基于Dickson矩阵的任意秩度量Reed-Muller码解码算法。


<details>
  <summary>Details</summary>
Motivation: 探索秩度量Reed-Muller码在“二元” G = (Z/2Z)^m情况下的解码问题，并寻求比现有方法更 эффектив的解码算法。

Method: 本文提出了一种受Plotkin构造启发的新型递归解码算法，该算法针对特定子类的秩度量Reed-Muller码。

Result: 本文所提出的递归算法的渐近复杂度优于最近提出的基于Dickson矩阵的任意秩度量Reed-Muller码解码算法。此外，该解码器具有完全不同的性质，并 dẫn出了Plotkin构造的自然秩度量对应物。

Conclusion: 本文成功地为“二元”情况下的秩度量Reed-Muller码提出了一种高效的解码算法，并提供了一种通用的类似Plotkin的矩阵秩度量码构造方法及其解码器。

Abstract: In 2021, Augot, Couvreur, Lavauzelle and Neri introduced a new class of rank
metric codes which can be regarded as rank metric counterparts of Reed-Muller
codes. Given a finite Galois extension $\mathbb{L} / \mathbb{K}$, these codes
are defined as some specific $\mathbb{L}$-subspaces of the twisted group
algebra $\mathbb{L} [\textrm{G}]$. We investigate the decoding of such codes in
the "binary" case, \emph{i.e.,} when $\textrm{G} = (\mathbb{Z}/2\mathbb{Z})^m$.
Our approach takes its inspiration from the decoding of Hamming metric binary
Reed-Muller codes using their recursive Plotkin "$(u ~|~ u+v)$" structure. If
our recursive algorithm restricts to a specific subclass of rank metric
Reed-Muller codes, its asymptotic complexity beats that of the recently
proposed decoding algorithm for arbitrary rank metric Reed-Muller codes based
on Dickson matrices. Also, this decoder is of completely different nature and
leads a natural rank metric counterpart of the Plotkin construction. To
illustrate this, we also propose a generic Plotkin-like construction for matrix
rank metric codes with an associate decoder, which can be applied to any pair
of codes equipped with an efficient decoder.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [66] [Calibrated Principal Component Regression](https://arxiv.org/abs/2510.19020)
*Yixuan Florence Wu,Yilun Zhu,Lei Cao and,Naichen Shi*

Main category: stat.ML

TL;DR: 本文提出了一种新的广义线性模型统计推断方法，称为校准主成分回归（CPCR）。CPCR通过在主成分子空间中学习低方差先验，然后通过中心Tikhonov步骤在原始特征空间中校准模型，成功地缓解了传统主成分回归（PCR）的截断偏差问题。在理论和实践中，CPCR均表现出优于标准PCR的性能，尤其是在回归信号在低方差方向上具有不可忽略分量的情况下。


<details>
  <summary>Details</summary>
Motivation: 在过参数化广义线性模型中，主成分回归（PCR）通过将高维数据投影到低维主成分子空间中来降低方差。然而，当真实回归向量在保留的主成分之外具有质量时，PCR会产生截断偏差。本文旨在解决PCR的这一固有缺陷，即降低截断偏差。

Method: 本文提出了校准主成分回归（CPCR）方法。CPCR首先在主成分（PC）子空间中学习一个低方差先验，然后通过一个居中的Tikhonov步骤在原始特征空间中校准模型。CPCR利用交叉拟合来软化PCR的硬截断，从而控制截断偏差。

Result: 在随机矩阵机制下，计算了CPCR的样本外风险，结果表明，当回归信号在低方差方向上具有不可忽略的分量时，CPCR的性能优于标准PCR。在多个过参数化问题上，CPCR持续改进了预测。

Conclusion: CPCR是一种在新过参数化设置中稳定且灵活的方法，通过有效控制截断偏差，显著优于传统PCR，尤其适用于回归信号在低方差方向上含有效分量的情况。

Abstract: We propose a new method for statistical inference in generalized linear
models. In the overparameterized regime, Principal Component Regression (PCR)
reduces variance by projecting high-dimensional data to a low-dimensional
principal subspace before fitting. However, PCR incurs truncation bias whenever
the true regression vector has mass outside the retained principal components
(PC). To mitigate the bias, we propose Calibrated Principal Component
Regression (CPCR), which first learns a low-variance prior in the PC subspace
and then calibrates the model in the original feature space via a centered
Tikhonov step. CPCR leverages cross-fitting and controls the truncation bias by
softening PCR's hard cutoff. Theoretically, we calculate the out-of-sample risk
in the random matrix regime, which shows that CPCR outperforms standard PCR
when the regression signal has non-negligible components in low-variance
directions. Empirically, CPCR consistently improves prediction across multiple
overparameterized problems. The results highlight CPCR's stability and
flexibility in modern overparameterized settings.

</details>


### [67] [Extreme Event Aware ($η$-) Learning](https://arxiv.org/abs/2510.19161)
*Kai Chang,Themistoklis P. Sapsis*

Main category: stat.ML

TL;DR: 本文介绍了一种名为“Extreme Event Aware”（e2a 或 eta）的学习方法，旨在解决在处理复杂动力系统中的罕见和极端事件时，现有数据驱动方法在缺乏极端事件数据时的局限性。


<details>
  <summary>Details</summary>
Motivation: 量化和预测罕见和极端事件对于理解复杂动力系统至关重要，但由于这些事件的稀疏性和严重性，现有的数据驱动方法在训练数据中缺乏极端事件时表现出较高的认知不确定性。

Method: e2a（eta）学习方法通过在训练过程中强制执行可观测的极端事件统计信息来减少不确定性，即使在“未知”的极端事件区域也是如此。这些统计信息可以通过定性论证或使用未标记数据进行估计。

Result: e2a（eta）学习方法能够生成前所未有的极端事件，即使训练数据中缺少这些极端事件。基于最优传输的理论结果为该方法提供了严格的证明和最优性。

Conclusion: e2a（eta）学习框架通过引入极端事件统计正则化，有效克服了现有数据驱动方法在缺乏极端事件数据时的局限性，在多种原型问题和实际降水尺度缩减问题中展现出良好的性能，并可以生成前所未有的极端事件。

Abstract: Quantifying and predicting rare and extreme events persists as a crucial yet
challenging task in understanding complex dynamical systems. Many practical
challenges arise from the infrequency and severity of these events, including
the considerable variance of simple sampling methods and the substantial
computational cost of high-fidelity numerical simulations. Numerous data-driven
methods have recently been developed to tackle these challenges. However, a
typical assumption for the success of these methods is the occurrence of
multiple extreme events, either within the training dataset or during the
sampling process. This leads to accurate models in regions of quiescent events
but with high epistemic uncertainty in regions associated with extremes. To
overcome this limitation, we introduce Extreme Event Aware (e2a or eta) or
$\eta$-learning which does not assume the existence of extreme events in the
available data. $\eta$-learning reduces the uncertainty even in `uncharted'
extreme event regions, by enforcing the extreme event statistics of an
observable indicative of extremeness during training, which can be available
through qualitative arguments or estimated with unlabeled data. This type of
statistical regularization results in models that fit the observed data, while
enforcing consistency with the prescribed observable statistics, enabling the
generation of unprecedented extreme events even when the training data lack
extremes therein. Theoretical results based on optimal transport offer a
rigorous justification and highlight the optimality of the introduced method.
Additionally, extensive numerical experiments illustrate the favorable
properties of the $\eta$-learning framework on several prototype problems and
real-world precipitation downscaling problems.

</details>


### [68] [Topology of Currencies: Persistent Homology for FX Co-movements: A Comparative Clustering Study](https://arxiv.org/abs/2510.19306)
*Pattravadee de Favereau de Jeneret,Ioannis Diamantis*

Main category: stat.ML

TL;DR: 本文探讨了拓扑数据分析（TDA）在货币行为聚类方面是否能提供超越传统统计方法的额外洞察。研究发现，TDA在捕捉货币联动结构模式方面表现出色，其聚类结果比传统统计特征聚类产生更紧凑和分离良好的簇，尤其是在Calinski-Harabasz指数上得分显著更高。


<details>
  <summary>Details</summary>
Motivation: 探索拓扑数据分析（TDA）是否在聚类货币行为方面比传统统计方法具有优势，尤其是在外汇市场这种非线性、高维度的复杂系统中。

Method: 研究者比较了基于TDA派生特征和经典统计特征的聚类结果，数据为13种主要货币兑欧元的月度对数收益。采用了K-means和层次聚类两种算法，并通过轮廓系数和Calinski-Harabasz指数评估聚类质量。

Result: 与传统统计特征聚类相比，基于TDA特征的聚类产生了更紧凑和分离良好的簇，特别是在Calinski-Harabasz指数上得分显著更高。然而，所有聚类方法的轮廓系数都一般，表明外汇时间序列分组固有难度。

Conclusion: TDA是一种有价值的补充工具，可用于分析金融时间序列，尤其是在风险管理中，其中理解结构性同向变动至关重要。与传统方法相比，TDA可以捕捉到传统方法可能忽略的货币同向变动的结构模式。

Abstract: This study investigates whether Topological Data Analysis (TDA) can provide
additional insights beyond traditional statistical methods in clustering
currency behaviours. We focus on the foreign exchange (FX) market, which is a
complex system often exhibiting non-linear and high-dimensional dynamics that
classical techniques may not fully capture. We compare clustering results based
on TDA-derived features versus classical statistical features using monthly
logarithmic returns of 13 major currency exchange rates (all against the euro).
Two widely-used clustering algorithms, \(k\)-means and Hierarchical clustering,
are applied on both types of features, and cluster quality is evaluated via the
Silhouette score and the Calinski-Harabasz index. Our findings show that
TDA-based feature clustering produces more compact and well-separated clusters
than clustering on traditional statistical features, particularly achieving
substantially higher Calinski-Harabasz scores. However, all clustering
approaches yield modest Silhouette scores, underscoring the inherent difficulty
of grouping FX time series. The differing cluster compositions under TDA vs.
classical features suggest that TDA captures structural patterns in currency
co-movements that conventional methods might overlook. These results highlight
TDA as a valuable complementary tool for analysing financial time series, with
potential applications in risk management where understanding structural
co-movements is crucial.

</details>


### [69] [Metadata Extraction Leveraging Large Language Models](https://arxiv.org/abs/2510.19334)
*Cuize Han,Sesh Jalagam*

Main category: stat.ML

TL;DR: 本文介绍了一种利用大型语言模型（LLM）增强合同元数据提取的方法，该方法可自动检测和标注合同中的重要法律条款，显著提高条款识别的准确性和效率，有望降低合同审查的时间和成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在各个领域（包括法律文档分析自动化）的任务中取得了革命性进展。本文旨在利用LLM技术，优化现代合同管理系统中的法律文件审查过程，特别是元数据提取环节。

Method: 本文利用公开的合同理解Atticus数据集（CUAD）和专有合同数据集，将先进的LLM方法与实际应用相结合。我们确定了优化元数据提取的三个关键要素：强大的文本转换、战略性分块选择以及高级的LLM特定技术（包括思维链（CoT）提示和结构化工具调用）。

Result: 实验结果表明，该方法在条款识别的准确性和效率方面都有显著提高。

Conclusion: 本文提出的方法有望降低与合同审查相关的时间和成本，同时在法律条款识别方面保持高准确性。研究结果表明，经过仔细优化的LLM系统可以成为法律专业人员的宝贵工具，有可能增加各种规模组织获得高效合同审查服务的机会。

Abstract: The advent of Large Language Models has revolutionized tasks across domains,
including the automation of legal document analysis, a critical component of
modern contract management systems. This paper presents a comprehensive
implementation of LLM-enhanced metadata extraction for contract review,
focusing on the automatic detection and annotation of salient legal clauses.
Leveraging both the publicly available Contract Understanding Atticus Dataset
(CUAD) and proprietary contract datasets, our work demonstrates the integration
of advanced LLM methodologies with practical applications. We identify three
pivotal elements for optimizing metadata extraction: robust text conversion,
strategic chunk selection, and advanced LLM-specific techniques, including
Chain of Thought (CoT) prompting and structured tool calling. The results from
our experiments highlight the substantial improvements in clause identification
accuracy and efficiency. Our approach shows promise in reducing the time and
cost associated with contract review while maintaining high accuracy in legal
clause identification. The results suggest that carefully optimized LLM systems
could serve as valuable tools for legal professionals, potentially increasing
access to efficient contract review services for organizations of all sizes.

</details>


### [70] [On the hardness of RL with Lookahead](https://arxiv.org/abs/2510.19372)
*Corentin Pla,Hugo Richard,Marc Abeille,Nadav Merlis,Vianney Perchet*

Main category: stat.ML

TL;DR: 该论文研究了具有转移前瞻的强化学习（RL），其中智能体在决定行动方案之前，可以观察在执行任意 \(\ell\) 步行动序列后将访问哪些状态。


<details>
  <summary>Details</summary>
Motivation: 研究转移前瞻在强化学习中的应用，并探讨其计算效率。

Method: 通过新颖的线性规划公式证明了单步前瞻（\(\ell=1\)）的最优规划可以在多项式时间内解决。

Result: 单步前瞻（\(\ell=1\)）的规划问题是可 tractably 解决的，而 \(\ell \geq 2\) 时问题变为 NP-hard。

Conclusion: 明确了强化学习中具有转移前瞻的规划问题在可处理和不可处理情况之间的精确边界。

Abstract: We study reinforcement learning (RL) with transition look-ahead, where the
agent may observe which states would be visited upon playing any sequence of
$\ell$ actions before deciding its course of action. While such predictive
information can drastically improve the achievable performance, we show that
using this information optimally comes at a potentially prohibitive
computational cost. Specifically, we prove that optimal planning with one-step
look-ahead ($\ell=1$) can be solved in polynomial time through a novel linear
programming formulation. In contrast, for $\ell \geq 2$, the problem becomes
NP-hard. Our results delineate a precise boundary between tractable and
intractable cases for the problem of planning with transition look-ahead in
reinforcement learning.

</details>


### [71] [Learning Upper Lower Value Envelopes to Shape Online RL: A Principled Approach](https://arxiv.org/abs/2510.19528)
*Sebastian Reboul,Hélène Halconruy,Randal Douc*

Main category: stat.ML

TL;DR: 本文提出了一种利用离线数据加速在线强化学习的两阶段框架，通过学习和应用分离的价值上下界，显著降低了在线学习的遗憾。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用离线数据加速在线强化学习，这是一个潜力巨大但缺乏理论基础的方向。

Method: 本文提出了一个原则性的两阶段框架：第一阶段利用离线数据推导价值函数的上下界，第二阶段将这些界限融入在线算法。与以往方法不同的是，本文解耦了上下界，使其更灵活、逼近更紧密。本文的包络是数据驱动的，并明确建模为随机变量。

Result: 分析建立了由两个可解释量确定的高概率遗憾界限，为离线预训练和在线微调之间提供了正式的桥梁。在表格MDP上的实证结果表明，与UCBVI和以前的方法相比，遗憾得到了显著降低。

Conclusion: 本文成功地将离线数据整合到在线强化学习中，通过数据驱动的价值包络，有效加速了在线学习过程并提高了性能。

Abstract: We investigate the fundamental problem of leveraging offline data to
accelerate online reinforcement learning - a direction with strong potential
but limited theoretical grounding. Our study centers on how to learn and apply
value envelopes within this context. To this end, we introduce a principled
two-stage framework: the first stage uses offline data to derive upper and
lower bounds on value functions, while the second incorporates these learned
bounds into online algorithms. Our method extends prior work by decoupling the
upper and lower bounds, enabling more flexible and tighter approximations. In
contrast to approaches that rely on fixed shaping functions, our envelopes are
data-driven and explicitly modeled as random variables, with a filtration
argument ensuring independence across phases. The analysis establishes
high-probability regret bounds determined by two interpretable quantities,
thereby providing a formal bridge between offline pre-training and online
fine-tuning. Empirical results on tabular MDPs demonstrate substantial regret
reductions compared with both UCBVI and prior methods.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [72] [Local Guidance for Configuration-Based Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19072)
*Tomoki Arita,Keisuke Okumura*

Main category: cs.MA

TL;DR: 该文章探讨了在多智能体路径规划（MAPF）中，局部引导方法在提升性能方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的MAPF引导方法侧重于全局信息以缓解拥塞和提高协调效率，但本文旨在探索局部的、以智能体为中心的引导方法，并评估其在计算成本和解决方案质量之间的权衡。

Method: 文章通过为每个智能体提供局部的时空线索作为引导信息，并将其应用于领先的配置求解器LaCAM。

Result: 尽管局部引导方法涉及智能体移动时的重新计算，但经验表明，该方法在适度的计算时间内显著提高了解决方案的质量。

Conclusion: 局部引导方法为MAPF带来了新的性能突破，证明了在每个智能体附近提供局部引导的有效性，即使这需要重新计算。

Abstract: Guidance is an emerging concept that improves the empirical performance of
real-time, sub-optimal multi-agent pathfinding (MAPF) methods. It offers
additional information to MAPF algorithms to mitigate congestion on a global
scale by considering the collective behavior of all agents across the entire
workspace. This global perspective helps reduce agents' waiting times, thereby
improving overall coordination efficiency. In contrast, this study explores an
alternative approach: providing local guidance in the vicinity of each agent.
While such localized methods involve recomputation as agents move and may
appear computationally demanding, we empirically demonstrate that supplying
informative spatiotemporal cues to the planner can significantly improve
solution quality without exceeding a moderate time budget. When applied to
LaCAM, a leading configuration-based solver, this form of guidance establishes
a new performance frontier for MAPF.

</details>


### [73] [Polynomial-time Configuration Generator for Connected Unlabeled Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19567)
*Takahiro Suzuki,Keisuke Okumura*

Main category: cs.MA

TL;DR: CUMAPF是一个多智能体路径规划问题，要求智能体在移动过程中始终保持连接。PULL算法是针对CUMAPF问题提出的，它是一个完整且多项式时间的算法，基于规则的一步函数来计算后续配置，以保持连接并向目标配置前进。


<details>
  <summary>Details</summary>
Motivation: CUMAPF问题在群体机器人应用中非常重要，例如自重构和行进，而标准MAPF算法无法保证智能体之间所需的连接性。

Method: 本文提出了一种名为PULL的算法。PULL算法基于规则的一步函数，该函数计算后续配置，以在保持连接的同时向目标配置前进。此外，作者还开发了一个最终最优的求解器，将PULL集成到现有的基于搜索的MAPF算法中，适用于小规模实例。

Result: PULL算法在二维网格中每步运行时间为O(n^2)，其中n是智能体的数量。实验表明，PULL在随机生成实例中能为数百个智能体找到具有竞争力的解决方案。

Conclusion: PULL是一种轻量级的、多项式时间的算法，能够有效地解决大规模CUMAPF问题。

Abstract: We consider Connected Unlabeled Multi-Agent Pathfinding (CUMAPF), a variant
of MAPF where the agents must maintain connectivity at all times. This problem
is fundamental to swarm robotics applications like self-reconfiguration and
marching, where standard MAPF is insufficient as it does not guarantee the
required connectivity between agents. While unlabeled MAPF is tractable in
optimization, CUMAPF is NP-hard even on highly restricted graph classes. To
tackle this challenge, we propose PULL, a complete and polynomial-time
algorithm with a simple design. It is based on a rule-based one-step function
that computes a subsequent configuration that preserves connectivity and
advances towards the target configuration. PULL is lightweight, and runs in
$O(n^2)$ time per step in 2D grid, where $n$ is the number of agents. Our
experiments further demonstrate its practical performance: PULL finds
competitive solution qualities against trivial solutions for hundreds of
agents, in randomly generated instances. Furthermore, we develop an eventually
optimal solver that integrates PULL into an existing search-based MAPF
algorithm, providing a valuable tool for small-scale instances.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [74] [Test-time Verification via Optimal Transport: Coverage, ROC, & Sub-optimality](https://arxiv.org/abs/2510.18982)
*Arpan Mukherjee,Marcello Bullo,Debabrota Basu,Deniz Gündüz*

Main category: cs.AI

TL;DR: 本文提出了一种统一的框架来量化大型语言模型（LLM）测试时验证中生成器覆盖率、验证器收敛区域（ROC）和采样算法次优性之间的相互作用，并揭示了次优性-覆盖率曲线的三种状态。


<details>
  <summary>Details</summary>
Motivation: 目前关于大型语言模型（LLM）测试时验证的研究，未能充分探讨验证器及其不完善之处，也缺乏一个统一的框架来量化生成器覆盖率、验证器收敛区域（ROC）和采样算法次优性之间相互作用的几何形状。

Method: 将可验证的测试时扩展视为一个传输问题。 这种方法量化了生成器覆盖率、验证器收敛区域（ROC）和采样算法次优性之间的相互作用。 提出了两种采样算法（序列式和批量式）并分析了它们的计算复杂性如何影响这些权衡。

Result: 次优性-覆盖率曲线表现出三种状态：传输状态（次优性随覆盖率增加）、策略改进状态（次优性可能随覆盖率降低，具体取决于验证器的ROC）和饱和状态（次优性趋于稳定，不受覆盖率影响）。

Conclusion: 本文提出的统一框架通过将可验证的测试时扩展视为传输问题，成功地量化了生成器覆盖率、验证器收敛区域（ROC）和采样算法次优性之间的复杂相互作用，并揭示了次优性-覆盖率曲线的三种状态。 此外，对序列式和批量式采样算法的分析及其计算复杂性如何影响这些权衡，为优化测试时验证提供了宝贵的见解。

Abstract: While test-time scaling with verification has shown promise in improving the
performance of large language models (LLMs), the role of the verifier and its
imperfections remain underexplored. The effect of verification manifests
through interactions of three quantities: (i) the generator's coverage, (ii)
the verifier's region of convergence (ROC), and (iii) the sampling algorithm's
sub-optimality. Though recent studies capture subsets of these factors, a
unified framework quantifying the geometry of their interplay is missing. We
frame verifiable test-time scaling as a transport problem. This characterizes
the interaction of coverage, ROC, and sub-optimality, and uncovers that the
sub-optimality--coverage curve exhibits three regimes. A transport regime --
where sub-optimality increases with coverage, a policy improvement regime --
where sub-optimality may decrease with coverage, depending on the verifier's
ROC, and a saturation regime -- where sub-optimality plateaus, unaffected by
coverage. We further propose and analyze two classes of sampling algorithms --
sequential and batched, and examine how their computational complexities shape
these trade-offs. Empirical results with Qwen, Llama, and Gemma models
corroborate our theoretical findings.

</details>


### [75] [Timely Clinical Diagnosis through Active Test Selection](https://arxiv.org/abs/2510.18988)
*Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: ACTMED是一个诊断框架，它利用贝叶斯实验设计（BED）和大型语言模型（LLM）来模拟临床诊断推理，以提高诊断准确性，可解释性和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 目前的机器学习诊断方法大多依赖静态、完全观察的数据集，未能反映临床医生在实践中使用的序贯的、资源 M-感知的推理。在压力大或资源有限的环境中，诊断仍然复杂且容易出错，这突出表明需要帮助临床医生做出及时且经济高效的决策的框架。

Method: 本文提出了ACTMED（Adaptive Clinical Test selection via Model-based Experimental Design），一个将贝叶斯实验设计（BED）与大型语言模型（LLM）相结合的诊断框架，以更好地模拟现实世界的诊断推理。在每个步骤中，ACTMED选择预期能为给定患者最大程度降低诊断不确定性的测试。LLMs充当灵活的模拟器，生成可信的患者状态分布，并支持信念更新，而无需结构化的、特定任务的训练数据。

Result: ACTMED在真实世界的数据集上进行了评估，结果表明它可以优化测试选择，以提高诊断准确性、可解释性和资源利用率。

Conclusion: ACTMED代表着朝着透明、适应性强、与临床医生对齐的诊断系统迈出了一步，该系统可以在不同环境下推广，并减少对领域特定数据的依赖。

Abstract: There is growing interest in using machine learning (ML) to support clinical
diag- nosis, but most approaches rely on static, fully observed datasets and
fail to reflect the sequential, resource-aware reasoning clinicians use in
practice. Diagnosis remains complex and error prone, especially in
high-pressure or resource-limited settings, underscoring the need for
frameworks that help clinicians make timely and cost-effective decisions. We
propose ACTMED (Adaptive Clinical Test selection via Model-based Experimental
Design), a diagnostic framework that integrates Bayesian Experimental Design
(BED) with large language models (LLMs) to better emulate real-world diagnostic
reasoning. At each step, ACTMED selects the test expected to yield the greatest
reduction in diagnostic uncertainty for a given patient. LLMs act as flexible
simulators, generating plausible patient state distributions and supporting
belief updates without requiring structured, task-specific training data.
Clinicians can remain in the loop; reviewing test suggestions, interpreting
intermediate outputs, and applying clinical judgment throughout. We evaluate
ACTMED on real-world datasets and show it can optimize test selection to
improve diagnostic accuracy, interpretability, and resource use. This
represents a step to- ward transparent, adaptive, and clinician-aligned
diagnostic systems that generalize across settings with reduced reliance on
domain-specific data.

</details>


### [76] [The MUSE Benchmark: Probing Music Perception and Auditory Relational Reasoning in Audio LLMS](https://arxiv.org/abs/2510.19055)
*Brandon James Carone,Iran R. Roman,Pablo Ripollés*

Main category: cs.AI

TL;DR: 本文提出了音乐理解与结构评估（MUSE）基准，旨在评估多模态大型语言模型（MLLMs）在音乐感知方面的能力，并发现现有SOTA模型与人类水平之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大型语言模型（MLLMs）在音频理解方面表现出一定能力，但当前的评估方法可能掩盖了它们在关系推理方面的根本弱点。因此，需要一个能够深入探测音乐感知基本技能的评估基准。

Method: 本文引入了音乐理解与结构评估（MUSE）基准，这是一个包含10项任务的开源资源，专门用于探测基本的音乐感知技能。研究者使用该基准评估了四种SOTA模型（Gemini Pro和Flash、Qwen2.5-Omni和Audio-Flamingo 3），并与一个大型人类基线（N=200）进行了对比。此外，研究还探讨了思维链（CoT）提示对模型性能的影响。

Result: 评估结果显示，SOTA模型的能力存在较大差异，并且与人类专家之间存在持续的差距。Gemini Pro在基本感知任务上表现良好，而Qwen和Audio Flamingo 3的表现接近或低于随机水平，暴露了严重的感知缺陷。此外，研究发现思维链（CoT）提示的效果不稳定，通常会产生负面影响。

Conclusion: MUSE基准为评估不变的音乐表征和推动更强大的AI系统发展提供了关键工具。研究结果表明，当前的MLLMs在音乐感知和关系推理方面仍有很大提升空间，需要进一步的研究和改进，尤其是在提升模型的鲁棒性方面。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated capabilities in
audio understanding, but current evaluations may obscure fundamental weaknesses
in relational reasoning. We introduce the Music Understanding and Structural
Evaluation (MUSE) Benchmark, an open-source resource with 10 tasks designed to
probe fundamental music perception skills. We evaluate four SOTA models (Gemini
Pro and Flash, Qwen2.5-Omni, and Audio-Flamingo 3) against a large human
baseline (N=200). Our results reveal a wide variance in SOTA capabilities and a
persistent gap with human experts. While Gemini Pro succeeds on basic
perception, Qwen and Audio Flamingo 3 perform at or near chance, exposing
severe perceptual deficits. Furthermore, we find Chain-of-Thought (CoT)
prompting provides inconsistent, often detrimental results. Our work provides a
critical tool for evaluating invariant musical representations and driving
development of more robust AI systems.

</details>


### [77] [A Multi-faceted Analysis of Cognitive Abilities: Evaluating Prompt Methods with Large Language Models on the CONSORT Checklist](https://arxiv.org/abs/2510.19139)
*Sohyeon Jeon,Hyung-Chul Lee*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型（LLMs）在评估临床试验报告（CONSORT标准）方面的能力和局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在医疗领域迅速发展，但其在评估临床试验报告方面（CONSORT标准）的能力，特别是认知和推理策略，尚不明确。

Method: 本研究采用行为和元认知分析方法，使用经过专家验证的数据，系统比较了两个代表性LLMs在三种提示条件下的表现。

Result: 模型在处理CONSORT项目的不同之处、提示类型、推理风格的转变、明确的不确定性以及替代解释都影响了响应模式。

Conclusion: 研究结果强调了LLMs在临床合规自动化方面的局限性，并强调了理解其认知适应和策略行为对于开发更具解释性和可靠性的医疗AI的重要性。

Abstract: Despite the rapid expansion of Large Language Models (LLMs) in healthcare,
the ability of these systems to assess clinical trial reporting according to
CONSORT standards remains unclear, particularly with respect to their cognitive
and reasoning strategies. This study applies a behavioral and metacognitive
analytic approach with expert-validated data, systematically comparing two
representative LLMs under three prompt conditions. Clear differences emerged in
how the models approached various CONSORT items, and prompt types, including
shifts in reasoning style, explicit uncertainty, and alternative
interpretations shaped response patterns. Our results highlight the current
limitations of these systems in clinical compliance automation and underscore
the importance of understanding their cognitive adaptations and strategic
behavior in developing more explainable and reliable medical AI.

</details>


### [78] [The Zero-Step Thinking: An Empirical Study of Mode Selection as Harder Early Exit in Reasoning Models](https://arxiv.org/abs/2510.19176)
*Yuqiao Tan,Shizhu He,Kang Liu,Jun Zhao*

Main category: cs.AI

TL;DR: 这篇文章探讨了在推理过程中，如何通过模式选择和早期退出方法来降低计算开销。研究发现，现有方法在信息有限的情况下，仍无法有效解决模式选择问题。


<details>
  <summary>Details</summary>
Motivation: 现有的推理模型在数学和逻辑推理等任务中表现出色，但其分步思考过程常导致过度思考和不必要的计算开销。

Method: 本文首先将模式选择（在Long-CoT或Short-CoT之间选择）视为早期退出（确定最佳停止点）问题的一个更具挑战性的变体，因为两者目标相似但决策时机不同。作者通过零步思考（zero-step thinking）方法来解决模式选择问题，即在推理过程开始时，根据预定义的“虚假思考”进行决策，而不进行显式推理。研究对比了九种基线方法，包括基于提示的方法和利用内部信息的方法。

Result: 基于提示的方法由于分类能力有限，在只有少量人工设计信息时常表现不佳。而利用内部信息的方法在多数情况下表现较好，但仍存在稳定性问题。研究结果表明，仅依靠模型提供的信息不足以有效解决信息有限情境下的模式选择问题。

Conclusion: 现有的、仅依赖模型自身提供信息的方法，在解决信息有限场景下的模式选择问题时是不足的。模式选择任务仍然面临持续的挑战。

Abstract: Reasoning models have demonstrated exceptional performance in tasks such as
mathematics and logical reasoning, primarily due to their ability to engage in
step-by-step thinking during the reasoning process. However, this often leads
to overthinking, resulting in unnecessary computational overhead. To address
this issue, Mode Selection aims to automatically decide between Long-CoT
(Chain-of-Thought) or Short-CoT by utilizing either a Thinking or NoThinking
mode. Simultaneously, Early Exit determines the optimal stopping point during
the iterative reasoning process. Both methods seek to reduce the computational
burden. In this paper, we first identify Mode Selection as a more challenging
variant of the Early Exit problem, as they share similar objectives but differ
in decision timing. While Early Exit focuses on determining the best stopping
point for concise reasoning at inference time, Mode Selection must make this
decision at the beginning of the reasoning process, relying on pre-defined fake
thoughts without engaging in an explicit reasoning process, referred to as
zero-step thinking. Through empirical studies on nine baselines, we observe
that prompt-based approaches often fail due to their limited classification
capabilities when provided with minimal hand-crafted information. In contrast,
approaches that leverage internal information generally perform better across
most scenarios but still exhibit issues with stability. Our findings indicate
that existing methods relying solely on the information provided by models are
insufficient for effectively addressing Mode Selection in scenarios with
limited information, highlighting the ongoing challenges of this task. Our code
is available at https://github.com/Trae1ounG/Zero_Step_Thinking.

</details>


### [79] [WebGraphEval: Multi-Turn Trajectory Evaluation for Web Agents using Graph Representation](https://arxiv.org/abs/2510.19205)
*Yaoyao Qian,Yuanli Wang,Jinda Zhang,Yun Zong,Meixu Chen,Hanhan Zhou,Jindan Huang,Yifan Zeng,Xinyu Hu,Chan Hee Song,Danqing Zhang*

Main category: cs.AI

TL;DR: WebGraphEval是一个评估Web智能体的新框架，它通过将智能体轨迹抽象为统一的加权动作图来克服现有评估方法的局限性，并能捕捉跨模型规律性、识别冗余和低效，并发现被结果度量忽略的关键决策点。


<details>
  <summary>Details</summary>
Motivation: 目前的Web智能体评估方法主要依赖于二元成功度量或与单一参考轨迹的符合性，这忽略了基准数据集中存在的结构多样性。

Method: WebGraphEval框架将多个智能体的轨迹抽象为一个统一的、加权的动作图。它能规范地编码动作、合并重复行为，并应用结构分析（包括奖励传播和成功加权的边统计）。该框架直接兼容WebArena等基准，并利用排行榜运行和新收集的轨迹而无需修改环境。

Result: 通过对来自六个Web智能体的数千条轨迹进行评估，WebGraphEval表明图抽象能够捕捉跨模型规律性，突出冗余和低效率，并识别出被基于结果的度量所忽视的关键决策点。

Conclusion: WebGraphEval通过将Web交互 O 框定为图结构数据，建立了一种通用的方法，用于Web智能体的多路径、跨智能体和效率感知的评估。

Abstract: Current evaluation of web agents largely reduces to binary success metrics or
conformity to a single reference trajectory, ignoring the structural diversity
present in benchmark datasets. We present WebGraphEval, a framework that
abstracts trajectories from multiple agents into a unified, weighted action
graph. This representation is directly compatible with benchmarks such as
WebArena, leveraging leaderboard runs and newly collected trajectories without
modifying environments. The framework canonically encodes actions, merges
recurring behaviors, and applies structural analyses including reward
propagation and success-weighted edge statistics. Evaluations across thousands
of trajectories from six web agents show that the graph abstraction captures
cross-model regularities, highlights redundancy and inefficiency, and
identifies critical decision points overlooked by outcome-based metrics. By
framing web interaction as graph-structured data, WebGraphEval establishes a
general methodology for multi-path, cross-agent, and efficiency-aware
evaluation of web agents.

</details>


### [80] [ChatGPT Unveils Its Limits: Principles of Law Deliver Checkmate](https://arxiv.org/abs/2510.19261)
*Marianna Molinari,Ilaria Angela Amantea,Marinella Quaranta,Guido Governatori*

Main category: cs.AI

TL;DR: 这篇文章探讨了ChatGPT在法律领域的表现，发现尽管它拥有知识，但却无法将其有效地整合和推理以达到穷尽式的结果，从而揭示了其局限性。


<details>
  <summary>Details</summary>
Motivation: 探索ChatGPT在法律领域的表现及其局限性，并与正则表达式基线进行比较。

Method: 通过在法律领域进行实验，并将ChatGPT的表现与使用正则表达式（Regex）的基线进行比较。

Result: DALL-E 2能够生成高质量图像，但其创造力得分低于人类。

Conclusion: ChatGPT在法律领域中无法像人类一样进行全面的理解和推理，这表明其在该领域存在重大局限性，真正的智能仍然是人类独有的特征。

Abstract: This study examines the performance of ChatGPT with an experiment in the
legal domain. We compare the outcome with it a baseline using regular
expressions (Regex), rather than focusing solely on the assessment against
human performance. The study reveals that even if ChatGPT has access to the
necessary knowledge and competencies, it is unable to assemble them, reason
through, in a way that leads to an exhaustive result. This unveils a major
limitation of ChatGPT. Intelligence encompasses the ability to break down
complex issues and address them according to multiple required competencies,
providing a unified and comprehensive solution. In the legal domain, one of the
most crucial tasks is reading legal decisions and extracting key passages
condensed from principles of law (PoLs), which are then incorporated into
subsequent rulings by judges or defense documents by lawyers. In performing
this task, artificial intelligence lacks an all-encompassing understanding and
reasoning, which makes it inherently limited. Genuine intelligence, remains a
uniquely human trait, at least in this particular field.

</details>


### [81] [An Argumentative Explanation Framework for Generalized Reason Model with Inconsistent Precedents](https://arxiv.org/abs/2510.19263)
*Wachara Fungwacharakorn,Gauvain Bourgne,Ken Satoh*

Main category: cs.AI

TL;DR: 本文提出了一种扩展的派生状态论证框架（DSA框架），旨在为基于广义理由模型的案例推理提供论证性解释，以解决现有方法无法处理不一致先例的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的案例推理方法（在AI和法律领域）通常假设先例集必须是一致的，这限制了它们的应用范围。尽管存在针对传统一致理由模型的论证性解释方法，但对于能够适应不一致先例的广义理由模型，尚未开发出相应的论证性解释方法。

Method: 本文通过扩展派生状态论证框架（DSA框架）来解决上述问题。该扩展旨在解释根据广义理由模型进行的推理。

Result: 通过扩展DSA框架，本文提供了一种为基于广义理由模型的案例推理提供论证性解释的方法。

Conclusion: 本文成功地提出了一种处理不一致先例的论证性解释方法，从而扩展了案例推理在AI和法律领域的应用范围。这一方法基于对派生状态论证框架的扩展，能够在先例不一致的情况下提供合理的解释。

Abstract: Precedential constraint is one foundation of case-based reasoning in AI and
Law. It generally assumes that the underlying set of precedents must be
consistent. To relax this assumption, a generalized notion of the reason model
has been introduced. While several argumentative explanation approaches exist
for reasoning with precedents based on the traditional consistent reason model,
there has been no corresponding argumentative explanation method developed for
this generalized reasoning framework accommodating inconsistent precedents. To
address this question, this paper examines an extension of the derivation state
argumentation framework (DSA-framework) to explain the reasoning according to
the generalized notion of the reason model.

</details>


### [82] [NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning](https://arxiv.org/abs/2510.19429)
*Wonje Choi,Jooyoung Kim,Honguk Woo*

Main category: cs.AI

TL;DR: NeSyPr是一个神经符号具身推理框架，它通过神经符号过程化编译知识，使基于大型语言模型的智能体在动态环境中具备结构化、适应性和及时性推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在具身任务中面临挑战，因为在线访问大规模推理引擎或符号规划器受到延迟、连接和资源限制。

Method: NeSyPr首先通过符号工具生成任务特定计划，然后将其转化为可组合的过程表示。这些表示编码了计划的隐式生产规则，从而使组合过程能够无缝集成到语言模型的推理过程中。

Result: NeSyPr在PDDLGym、VirtualHome和ALFWorld等具身基准测试中表现出色，与大型推理模型和符号规划器相比，它能够用更紧凑的语言模型实现高效的推理能力。

Conclusion: NeSyPr通过神经符号过程化编译知识，将多步骤符号结构化寻径和推理抽象并泛化为单步骤语言模型推理，从而支持在延迟敏感和资源受限的物理系统中进行高效的测试时间推理。

Abstract: We address the challenge of adopting language models (LMs) for embodied tasks
in dynamic environments, where online access to large-scale inference engines
or symbolic planners is constrained due to latency, connectivity, and resource
limitations. To this end, we present NeSyPr, a novel embodied reasoning
framework that compiles knowledge via neurosymbolic proceduralization, thereby
equipping LM-based agents with structured, adaptive, and timely reasoning
capabilities. In NeSyPr, task-specific plans are first explicitly generated by
a symbolic tool leveraging its declarative knowledge. These plans are then
transformed into composable procedural representations that encode the plans'
implicit production rules, enabling the resulting composed procedures to be
seamlessly integrated into the LM's inference process. This neurosymbolic
proceduralization abstracts and generalizes multi-step symbolic structured
path-finding and reasoning into single-step LM inference, akin to human
knowledge compilation. It supports efficient test-time inference without
relying on external symbolic guidance, making it well suited for deployment in
latency-sensitive and resource-constrained physical systems. We evaluate NeSyPr
on the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating
its efficient reasoning capabilities over large-scale reasoning models and a
symbolic planner, while using more compact LMs.

</details>


### [83] [DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning](https://arxiv.org/abs/2510.19562)
*Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU*

Main category: cs.AI

TL;DR: DAIL（Distributional Aligned Learning）是一种新颖的方法，旨在通过分布策略和语义对齐解决语言指令的歧义问题，并在实验中取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 智能体理解自然语言和遵循人类指令的能力至关重要，但语言指令的灵活性导致了任务上的巨大歧义，严重降低了算法性能。

Method: DAIL方法包含两个关键组件：分布策略（distributional policy）和语义对齐（semantic alignment）。作者提供了理论结果，表明价值分布估计机制增强了任务的可区分性。同时，语义对齐模块捕捉了轨迹和语言指令之间的对应关系。

Result: 在结构化和视觉观察基准上的大量实验结果表明，DAIL有效解决了指令歧义，取得了优于基线方法的性能。

Conclusion: DAIL方法能有效解决语言指令的歧义问题，显著提高智能体在语言条件任务中的表现。

Abstract: Comprehending natural language and following human instructions are critical
capabilities for intelligent agents. However, the flexibility of linguistic
instructions induces substantial ambiguity across language-conditioned tasks,
severely degrading algorithmic performance. To address these limitations, we
present a novel method named DAIL (Distributional Aligned Learning), featuring
two key components: distributional policy and semantic alignment. Specifically,
we provide theoretical results that the value distribution estimation mechanism
enhances task differentiability. Meanwhile, the semantic alignment module
captures the correspondence between trajectories and linguistic instructions.
Extensive experimental results on both structured and visual observation
benchmarks demonstrate that DAIL effectively resolves instruction ambiguities,
achieving superior performance to baseline methods. Our implementation is
available at https://github.com/RunpengXie/Distributional-Aligned-Learning.

</details>


### [84] [A Graph Engine for Guitar Chord-Tone Soloing Education](https://arxiv.org/abs/2510.19666)
*Matthew Keating,Michael Casey*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个基于图的引擎，用于为吉他学生计算和弦音独奏建议。该引擎通过生成和弦音琶音、构建加权图、计算边权重和寻找最短路径来生成和弦音独奏线条，并提供了一个用户友好的系统供学生练习。


<details>
  <summary>Details</summary>
Motivation: 开发一个工具来帮助吉他学生学习和弦音独奏，这是一种爵士吉他理论的基础练习，但学习和练习起来很困难。

Method: 1. 讨论生成和弦音琶音的方法。
2. 构建一个加权图，其中每个节点代表进行中的和弦的和弦音琶音。
3. 计算每个连续和弦节点之间的边权重，以找到最佳过渡音。
4. 找到通过该图的最短路径并重建一个和弦音独奏线条。
5. 讨论一个用户友好的系统来处理引擎的输入和输出。

Result: 通过构建一个加权图并找到最短路径，该引擎能够生成和弦音独奏线条。该系统提供了一个用户友好的界面，方便吉他学生练习。

Conclusion: 该论文成功开发了一个基于图的引擎，可以为吉他学生提供和弦音独奏建议，从而帮助他们学习和弦音独奏，这是爵士吉他理论的重要组成部分。

Abstract: We present a graph-based engine for computing chord tone soloing suggestions
for guitar students. Chord tone soloing is a fundamental practice for
improvising over a chord progression, where the instrumentalist uses only the
notes contained in the current chord. This practice is a building block for all
advanced jazz guitar theory but is difficult to learn and practice. First, we
discuss methods for generating chord-tone arpeggios. Next, we construct a
weighted graph where each node represents a chord tone arpeggio for a chord in
the progression. Then, we calculate the edge weight between each consecutive
chord's nodes in terms of optimal transition tones. We then find the shortest
path through this graph and reconstruct a chord-tone soloing line. Finally, we
discuss a user-friendly system to handle input and output to this engine for
guitar students to practice chord tone soloing.

</details>


### [85] [Explainable e-sports win prediction through Machine Learning classification in streaming](https://arxiv.org/abs/2510.19671)
*Silvia García-Méndez,Francisco de Arriba-Pérez*

Main category: cs.AI

TL;DR: 这篇论文提出了一种可解释的串流赢预测分类解决方案，克服了现有方法只关注批处理分类的限制，准确率超过90%。


<details>
  <summary>Details</summary>
Motivation: 电子竞技观众和玩家数量的增加，以及优化的通信解决方案和云计算技术的发展，推动了在线游戏行业的持续增长。然而，现有的基于人工智能的电子竞技分析解决方案主要集中在批处理分类上，忽略了可视化技术。

Method: 本文提出了一种可解释的串流赢预测分类解决方案，通过在多个滑动窗口中控制输入数据来反映相关的游戏变化。

Result: 实验结果表明，该方法的准确率超过90%，优于文献中现有的解决方案。

Conclusion: 该系统可以通过可解释性模块，为排名和推荐系统提供信息丰富的决策支持，从而在结果预测中建立信任。

Abstract: The increasing number of spectators and players in e-sports, along with the
development of optimized communication solutions and cloud computing
technology, has motivated the constant growth of the online game industry. Even
though Artificial Intelligence-based solutions for e-sports analytics are
traditionally defined as extracting meaningful patterns from related data and
visualizing them to enhance decision-making, most of the effort in professional
winning prediction has been focused on the classification aspect from a batch
perspective, also leaving aside the visualization techniques. Consequently,
this work contributes to an explainable win prediction classification solution
in streaming in which input data is controlled over several sliding windows to
reflect relevant game changes. Experimental results attained an accuracy higher
than 90 %, surpassing the performance of competing solutions in the literature.
Ultimately, our system can be leveraged by ranking and recommender systems for
informed decision-making, thanks to the explainability module, which fosters
trust in the outcome predictions.

</details>


### [86] [RLIE: Rule Generation with Logistic Regression, Iterative Refinement, and Evaluation for Large Language Models](https://arxiv.org/abs/2510.19698)
*Yang Yang,Hua XU,Zhangyi Hu,Yutao Yue*

Main category: cs.AI

TL;DR: RLIE是一个统一的框架，它将LLM与概率模型相结合，学习一组加权规则，以解决现有LLM规则学习方法中忽视规则间交互以及与概率规则学习结合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLM）的规则学习方法往往忽略规则间的交互，并且未能充分探索LLM与概率规则学习相结合以进行稳健推理的潜力。

Method: RLIE框架分为四个阶段：（1）规则生成：LLM提出并筛选候选规则；（2）逻辑回归：学习用于全局选择和校准的概率权重；（3）迭代优化：根据预测误差更新规则集；（4）评估：将带权重的规则集作为直接分类器与将规则注入LLM的方法进行比较。

Result: 直接应用学习到的带权重规则表现出卓越的性能，而将规则、权重和逻辑模型输出提示给LLM反而会降低准确性。

Conclusion: RLIE框架揭示了LLM在归纳推理方面的潜力与局限性，并将其与经典的概率规则组合方法相结合，以实现更可靠的神经符号推理。LLM擅长语义生成和解释，但在精确的概率集成方面可靠性较低。

Abstract: Large Language Models (LLMs) can propose rules in natural language,
sidestepping the need for a predefined predicate space in traditional rule
learning. Yet many LLM-based approaches ignore interactions among rules, and
the opportunity to couple LLMs with probabilistic rule learning for robust
inference remains underexplored. We present RLIE, a unified framework that
integrates LLMs with probabilistic modeling to learn a set of weighted rules.
RLIE has four stages: (1) Rule generation, where an LLM proposes and filters
candidates; (2) Logistic regression, which learns probabilistic weights for
global selection and calibration; (3) Iterative refinement, which updates the
rule set using prediction errors; and (4) Evaluation, which compares the
weighted rule set as a direct classifier with methods that inject rules into an
LLM. We evaluate multiple inference strategies on real-world datasets. Applying
rules directly with their learned weights yields superior performance, whereas
prompting LLMs with the rules, weights, and logistic-model outputs surprisingly
degrades accuracy. This supports the view that LLMs excel at semantic
generation and interpretation but are less reliable for precise probabilistic
integration. RLIE clarifies the potential and limitations of LLMs for inductive
reasoning and couples them with classic probabilistic rule combination methods
to enable more reliable neuro-symbolic reasoning.

</details>


### [87] [Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning](https://arxiv.org/abs/2510.19732)
*Gunshi Gupta,Karmesh Yadav,Zsolt Kira,Yarin Gal,Rahaf Aljundi*

Main category: cs.AI

TL;DR: 该论文提出了Memo，一种基于Transformer的模型和训练方法，用于解决具身智能体在长时间范围内操作时，因视觉输入过载和上下文限制而导致的记忆问题。


<details>
  <summary>Details</summary>
Motivation: 开发能够形成和访问记忆以保持环境背景化的模型，对于使具身智能体长时间有效运行至关重要。现有的Transformer模型在处理具身序贯决策任务中的视觉输入时，常因上下文限制而难以保持长期记忆，而人类能够压缩并利用一生的经验。

Method: Memo通过在训练期间将周期性摘要token与模型输入交错，实现记忆的创建和检索。

Result: Memo在gridworld元RL基准测试和照片级真实室内环境中的多目标导航任务中表现出色，优于简单的长上下文Transformer基线，并且在计算和存储方面更高效。

Conclusion: Memo能够更好地泛化到更长的推理上下文，并且在必须截断历史上下文以适应推理约束的流媒体设置中保持鲁棒性。这表明Memo为具身智能体在长时间范围内的有效操作提供了有前景的解决方案。

Abstract: To enable embodied agents to operate effectively over extended timeframes, it
is crucial to develop models that form and access memories to stay
contextualized in their environment. In the current paradigm of training
transformer-based policies for embodied sequential decision-making tasks,
visual inputs often overwhelm the context limits of transformers, while humans
can maintain and utilize a lifetime of experience compressed as memories.
Significant compression is possible in principle, as much of the input is
irrelevant and can be abstracted. However, existing approaches predominantly
focus on either recurrent models with fixed-size memory or transformers with
full-context reliance. In this work, we propose Memo, a transformer-based
architecture and training recipe for reinforcement learning (RL) on
memory-intensive, long-horizon tasks. Memo incorporates the creation and
retrieval of memory by interleaving periodic summarization tokens with the
inputs of a model during training. We demonstrate Memo's effectiveness on a
gridworld meta-RL benchmark and a multi-object navigation task in
photo-realistic indoor settings. Memo outperforms naive long-context
transformer baselines while being more compute and storage efficient.
Additionally, Memo generalizes better to longer contexts at inference time and
remains robust in streaming settings, where historical context must be
truncated to fit inference constraints.

</details>


### [88] [Benchmarking World-Model Learning](https://arxiv.org/abs/2510.19788)
*Archana Warrier,Dat Nyugen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares*

Main category: cs.AI

TL;DR: 这篇论文提出了WorldTest，一个用于评估模型学习智能体的新协议，它将无奖励交互与在相关但不同环境中的测试阶段分开。


<details>
  <summary>Details</summary>
Motivation: 目前的模型学习智能体在训练和评估上与实际目标存在偏差，它们通常局限于下一帧预测和在相同环境中的奖励最大化，这限制了其对多种下游任务的支持能力。

Method: 本文提出了WorldTest协议，旨在评估模型学习智能体。该协议将无奖励交互与有评分的测试阶段分离，测试阶段在一个不同但相关的环境中进行。WorldTest具有开放性，不预设任务，并对模型表示保持不可知。为了实例化WorldTest，作者构建了AutumnBench，一个包含43个交互式网格世界环境和129个任务的基准，任务涵盖 masked-frame 预测、规划和预测因果动态变化。

Result: 通过对517名人类参与者和三个前沿模型在AutumnBench上进行比较，研究发现人类的表现优于现有模型。计算能力的提升在某些环境中能改善模型性能，但在另一些环境中则不能。

Conclusion: WorldTest提供了一个新颖的评估模板，包括无奖励探索、派生测试和基于行为的评分，用以评估智能体对环境动态的学习能力。AutumnBench揭示了世界模型学习领域仍有显著的提升空间。

Abstract: Model-learning agents should gather information to learn world models that
support many downstream tasks and inferences, such as predicting unobserved
states, estimating near- and far-term consequences of actions, planning action
sequences, and detecting changes in dynamics. Current methods for learning and
evaluating world models diverge from this goal: training and evaluation are
anchored to next-frame prediction, and success is scored by reward maximization
in the same environment. We propose WorldTest, a protocol to evaluate
model-learning agents that separates reward-free interaction from a scored test
phase in a different but related environment. WorldTest is
open-ended$\unicode{x2014}$models should support many different tasks unknown
ahead of time$\unicode{x2014}$and agnostic to model representation, allowing
comparison across approaches. We instantiated WorldTest with AutumnBench, a
suite of 43 interactive grid-world environments and 129 tasks across three
families: masked-frame prediction, planning, and predicting changes to the
causal dynamics. We compared 517 human participants and three frontier models
on AutumnBench. We found that humans outperform the models, and scaling compute
improves performance only in some environments but not others. WorldTest
provides a novel template$\unicode{x2014}$reward-free exploration, derived
tests, and behavior-based scoring$\unicode{x2014}$to evaluate what agents learn
about environment dynamics, and AutumnBench exposes significant headroom in
world-model learning.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [89] [The Value of Patience in Online Grocery Shopping](https://arxiv.org/abs/2510.19066)
*Javad Eshtiyagh,Pei Zhao,Federico Librino,Giovanni Resta,Paolo Santi,Martina Mazzarello,Akanksha Khurd,Santo Fortunato,Carlo Ratti*

Main category: cs.SI

TL;DR: 疫情期间，在线生鲜配送的发展对消费者行为产生了深远影响，但加剧了城市交通拥堵和污染。本研究探讨了消费者在配送时间上的耐心，如何平衡个人便利和社会成本，旨在通过延长配送时间来缓解交通压力。


<details>
  <summary>Details</summary>
Motivation: 在线生鲜配送的快速发展导致城市交通拥堵、排放和污染加剧，但目前关于个人便利与社会成本之间权衡的研究较少。

Method: 本文首先提出了一个数学模型，强调了顾客耐心与交通拥堵之间的凸性关系。其次，通过分析迪拜的800多万份生鲜订单，验证了理论预测。

Result: 研究表明，配送时间每增加5分钟，每日配送里程可减少约30%，全生命周期的二氧化碳排放量可减少20%。然而，超过10分钟后，边际效益显著降低。

Conclusion: 适度增加消费者在配送时间上的耐心，可以显著减少交通拥堵和碳排放，这为城市配送系统提供了一个平衡个人便利和社会福祉的可行策略。

Abstract: Since the COVID-19 pandemic, online grocery shopping has rapidly reshaped
consumer behavior worldwide, fueled by ever-faster delivery promises aimed at
maximizing convenience. Yet, this growth has also substantially increased urban
traffic congestion, emissions, and pollution. Despite extensive research on
urban delivery optimization, little is known about the trade-off between
individual convenience and these societal costs. In this study, we investigate
the value of marginal extensions in delivery times, termed customer patience,
in mitigating the traffic burden caused by grocery deliveries. We first
conceptualize the problem and present a mathematical model that highlights a
convex relationship between patience and traffic congestion. The theoretical
predictions are confirmed by an extensive, network-science based analysis
leveraging two large-scale datasets encompassing over 8 million grocery orders
in Dubai. Our findings reveal that allowing just five additional minutes in
delivery time reduces daily delivery mileage by approximately 30 percent and
life-cycle CO2 emissions by 20 percent. Beyond ten minutes of added patience,
however, marginal benefits diminish significantly. These results highlight that
modest increases in consumer patience can deliver substantial gains in traffic
reduction and sustainability, offering a scalable strategy to balance
individual convenience with societal welfare in urban delivery systems.

</details>


### [90] [Unfair Mistakes on Social Media: How Demographic Characteristics influence Authorship Attribution](https://arxiv.org/abs/2510.19708)
*Jasmin Wyss,Rebekah Overdorf*

Main category: cs.SI

TL;DR: 作者归属模型在开放世界中可能存在偏见，即使在封闭世界中表现公平。


<details>
  <summary>Details</summary>
Motivation: 作者归属技术在在线环境中应用广泛，但其对不同人口群体是否存在偏见尚不明确。这种偏见可能导致不公平的指控、封号和隐私侵犯。

Method: 本文从三个方面系统地评估了作者归属领域中，模型在性别、母语和年龄方面是否存在偏见：1. 评估具有特定人口统计学特征的用户比例如何影响分类器的整体性能。2. 评估用户的个人信息是否会影响其文本被错误分类的概率。3. 在排除真实作者的情况下，评估模型错误的类型，即强制分类器选择一个错误的作者。

Result: 1. 审查和分析表明，在封闭世界环境中，作者归属模型没有表现出跨人口群体的偏见。2. 在第三种评估方式中，分析表明模型倾向于将作品归因于与真实作者具有相同人口统计学特征的用户。这些错误不仅包括偏离用户通常风格的文本，还包括那些非常接近作者平均水平的文本。

Conclusion: 即使模型在封闭世界环境中表现公平，也可能无法保证错误不可避免时的公平性。研究结果强调了在实际应用中需要更全面地评估模型公平性。

Abstract: Authorship attribution techniques are increasingly being used in online
contexts such as sock puppet detection, malicious account linking, and
cross-platform account linking. Yet, it is unknown whether these models perform
equitably across different demographic groups. Bias in such techniques could
lead to false accusations, account banning, and privacy violations
disproportionately impacting users from certain demographics. In this paper, we
systematically audit authorship attribution for bias with respect to gender,
native language, and age. We evaluate fairness in 3 ways. First, we evaluate
how the proportion of users with a certain demographic characteristic impacts
the overall classifier performance. Second, we evaluate if a user's demographic
characteristics influence the probability that their texts are misclassified.
Our analysis indicates that authorship attribution does not demonstrate bias
across demographic groups in the closed-world setting. Third, we evaluate the
types of errors that occur when the true author is removed from the suspect
set, thereby forcing the classifier to choose an incorrect author. Unlike the
first two settings, this analysis demonstrates a tendency to attribute
authorship to users who share the same demographic characteristic as the true
author. Crucially, these errors do not only include texts that deviate from a
user's usual style, but also those that are very close to the author's average.
Our results highlight that though a model may appear fair in the closed-world
setting for a performant classifier, this does not guarantee fairness when
errors are inevitable.

</details>


### [91] [From Substitution to Complement? Uncovering the Evolving Interplay between Ride-hailing Services and Public Transit](https://arxiv.org/abs/2510.19745)
*Zhicheng Jin,Xiaotong Sun,Li Zhen,Weihua Gu,Huizhao Tu*

Main category: cs.SI

TL;DR: 该研究分析了网约车服务与公共交通之间的关系，发现它们之间的互补和替代关系在成熟市场中发生变化。


<details>
  <summary>Details</summary>
Motivation: 传统的观点认为网约车主要替代公共交通，但随着网约车市场的发展和成熟，二者之间的关系可能发生转变。

Method: 本研究收集了2022年9月上海96,716辆网约车的出行数据，并提出了一个增强的数据驱动框架，将网约车与公共交通的关系分为四种类型：首公里互补、末公里互补、替代和独立。此外，还提出了一种结合CatBoost和SHAP的机器学习方法来研究影响因素的非线性作用。

Result: 研究发现互补出行（9.22%）和替代出行（9.06%）的比例相当，与之前的研究结果形成鲜明对比。研究还揭示了一些变量（如到最近地铁站的距离、公交车站密度）的显著非线性效应。地铁枢纽和常规单线站点对首公里或末公里互补比例的影响不同。互补比例与到单线站点的距离呈倒U型关系：在1.5公里内急剧上升，在1.5至3公里之间保持峰值，随后下降。

Conclusion: 网约车与公共交通的关系在成熟市场中并非简单替代，而是互补与替代并存，且受多种因素的非线性影响。

Abstract: The literature on transportation network companies (TNCs), also known as
ride-hailing services, has often characterized these service providers as
predominantly substitutive to public transit (PT). However, as TNC markets
expand and mature, the complementary and substitutive relationships with PT may
shift. To explore whether such a transformation is occurring, this study
collected travel data from 96,716 ride-hailing vehicles during September 2022
in Shanghai, a city characterized by an increasingly saturated TNC market. An
enhanced data-driven framework is proposed to classify TNC-PT relationships
into four types: first-mile complementary, last-mile complementary,
substitutive, and independent. Our findings indicate comparable ratios of
complementary trips (9.22%) and substitutive trips (9.06%), contrasting sharply
with the findings of prior studies. Furthermore, to examine the nonlinear
impact of various influential factors on these ratios, a machine learning
method integrating categorical boosting (CatBoost) and Shapley additive
explanations (SHAP) is proposed. The results show significant nonlinear effects
in some variables, including the distance to the nearest metro station and the
density of bus stops. Moreover, metro hubs and regular single-line stations
exhibit distinct effects on first- or last-mile complementary ratios. These
ratios' relation to the distance to single-line stations shows an inverted
U-shaped pattern, with effects rising sharply within 1.5 km, remaining at the
peak between 1.5 and 3 km, and then declining as the distance increases to
about 15 km.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [92] [3D Optimization for AI Inference Scaling: Balancing Accuracy, Cost, and Latency](https://arxiv.org/abs/2510.18905)
*Minseok Jung,Abhas Ricky,Muhammad Rameez Chatni*

Main category: cs.LG

TL;DR: 本文介绍了一个结合准确性、成本和延迟的3D优化框架，以实现约束感知的AI推理扩展，并通过蒙特卡洛模拟和四种优化方法对九种大型语言模型进行了评估。


<details>
  <summary>Details</summary>
Motivation: 目前的AI推理扩展方法未能充分考虑成本和延迟约束，主要局限于一维启发式或二维权衡。

Method: 本文引入了一个3D优化框架，将准确性、成本和延迟纳入统一的决策空间。通过蒙特卡洛模拟，在三个代表性场景和九个模拟大型语言模型上评估了四种优化方法，以解决3D多目标优化问题。

Result: 研究结果表明，在多目标优化框架下，拐点优化实现了最佳平衡。当精度优先时，精度最大化仍然是更优的选择。

Conclusion: 该框架为跨不同操作环境的、部署感知的AI推理扩展奠定了理论基础，克服了传统1D和2D优化方法的局限性。

Abstract: AI inference scaling is often tuned through 1D heuristics (a fixed reasoning
passes) or 2D bivariate trade-offs (e.g., performance vs. compute), which fail
to consider cost and latency constraints. We introduce a 3D optimization
framework that jointly calibrates accuracy, cost, and latency within a unified
decision space, enabling constraints-aware inference scaling. Using Monte Carlo
simulations across three representative scenarios and nine simulated large
language models, we evaluate four optimization methods to address the 3D
multi-objective optimization (MOO) problem. Framing inference scaling in MOO
shapes a feasible space that 1D and 2D optimizations fail to capture, enabling
environmentadaptive selection of the inference scaling k. Results show that
knee-point optimization achieves the best balance, while accuracy-maximization
remains favorable when precision is prioritized. The framework establishes a
theoretical foundation for deployment-aware inference scaling across diverse
operational contexts.

</details>


### [93] [Large Connectome Model: An fMRI Foundation Model of Brain Connectomes Empowered by Brain-Environment Interaction in Multitask Learning Landscape](https://arxiv.org/abs/2510.18910)
*Ziquan Wei,Tingting Dan,Guorong Wu*

Main category: cs.LG

TL;DR: 该论文提出了一个功能神经影像学基础模型，通过多任务预训练和半监督微调，在多种临床应用中表现出巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在临床应用中受到样本量限制，且自监督学习与“大脑-结果”关系不完全一致，导致预训练模型在下游任务中表现不佳。

Method: 该论文将大脑建模视为多任务学习，提出了一种可扩展的模型架构，通过对多脑-环境交互（BEI）进行标记化实现多任务预训练，并通过分配预训练BEI的伪标签实现半监督微调。

Result: 该基础模型在性别预测、人类行为识别以及自闭症、帕金森病、阿尔茨海默病和精神分裂症的早期诊断等多种应用中取得了可喜的成果。

Conclusion: 该基础模型展示了在促进当前神经影像学临床应用方面的巨大潜力。

Abstract: A reliable foundation model of functional neuroimages is critical to promote
clinical applications where the performance of current AI models is
significantly impeded by a limited sample size. To that end, tremendous efforts
have been made to pretraining large models on extensive unlabeled fMRI data
using scalable self-supervised learning. Since self-supervision is not
necessarily aligned with the brain-to-outcome relationship, most foundation
models are suboptimal to the downstream task, such as predicting disease
outcomes. By capitalizing on rich environmental variables and demographic data
along with an unprecedented amount of functional neuroimages, we form the brain
modeling as a multitask learning and present a scalable model architecture for
(i) multitask pretraining by tokenizing multiple brain-environment interactions
(BEI) and (ii) semi-supervised finetuning by assigning pseudo-labels of
pretrained BEI. We have evaluated our foundation model on a variety of
applications, including sex prediction, human behavior recognition, and disease
early diagnosis of Autism, Parkinson's disease, Alzheimer's disease, and
{Schizophrenia}, where promising results indicate the great potential to
facilitate current neuroimaging applications in clinical routines.

</details>


### [94] [ADPO: Anchored Direct Preference Optimization](https://arxiv.org/abs/2510.18913)
*Wang Zixian*

Main category: cs.LG

TL;DR: ADPO是一个统一的框架，它通过软偏好、参考策略锚定和群组化扩展来推广DPO。ADPO在上下文bandit和序列强化学习中表现出色，并在不同噪声条件下提供了明确的指导。


<details>
  <summary>Details</summary>
Motivation: DPO假设硬性二元标签和成对比较，而忽视了不确定性和梯度漂移的问题。

Method: ADPO通过引入软偏好概率、任意参考策略锚定和Plackett-Luce分布的列表式偏好建模来解决这些问题。

Result: 在上下文bandits中，锚定将WinMass提高了38-63%。在重尾污染下，KDE平滑实现了0.68对0.32（112%的相对增益）。在序列强化学习中，锚定将带噪声偏好性能提高了15-29%。

Conclusion: ADPO为处理不同噪声条件下的偏好优化提供了有效的解决方案，特别推荐在干净或中等噪声下使用成对锚定的Soft-DPO，在极端污染下使用基于KDE的列表式ADPO。

Abstract: Anchored Direct Preference Optimization (ADPO) is a unified framework that
generalizes Direct Preference Optimization (DPO) with soft preferences,
reference-policy anchoring, and groupwise extensions. While standard DPO
assumes hard binary labels and pairwise comparisons, ADPO introduces: (i) soft
preference probabilities that encode uncertainty and mitigate gradient drift;
(ii) arbitrary reference-policy anchors that stabilize training via groupwise
shift invariance and implicit KL regularization; and (iii) listwise preference
modeling through Plackett-Luce distributions. We prove that DPO, Bradley-Terry
objectives, and Top-1-vs-Rest formulations emerge as special cases. ADPO yields
three practical variants: pairwise anchored Soft-DPO, listwise anchored
Soft-DPO with raw rewards, and KDE-based listwise smoothing for heavy-tailed
noise. In contextual bandits, anchoring improves WinMass by 38-63% over
standard DPO, while KDE smoothing achieves 0.68 vs 0.32 under heavy-tailed
contamination (112% relative gain). In sequential reinforcement learning
(CartPole, LunarLander), anchoring improves noisy-preference performance by
15-29%, confirming transfer from single-step to multi-step settings.
Experiments with 10-256 parameter models provide clear guidance: use pairwise
anchored Soft-DPO for clean or moderate noise, and KDE-based listwise ADPO for
extreme contamination.

</details>


### [95] [Benchmarking On-Device Machine Learning on Apple Silicon with MLX](https://arxiv.org/abs/2510.18921)
*Oluwaseun A. Ajayi,Ogundepo Odunayo*

Main category: cs.LG

TL;DR: 本文评估了MLX这一针对Apple芯片设备优化的机器学习框架的性能，特别关注其在Transformer模型推理延迟方面的表现，并将其与PyTorch进行了比较。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型普及和机器学习兴起背景下，人们对在小型设备上部署这些模型越来越感兴趣，这需要能利用设备硬件的框架，MLX框架应运而生来解决这一问题。

Method: 本文创建了一个名为MLX-transformers的框架，该框架包含MLX中不同的Transformer实现，并能下载PyTorch的模型检查点并将其转换为MLX格式。通过利用Apple Silicon的先进架构和能力，MLX-Transformers可以直接从Hugging Face无缝执行Transformer模型，无需通常在框架之间移植模型所需的检查点转换。

Result: 研究在两台Apple Silicon Macbook设备上，针对NVIDIA CUDA GPU，对不同Transformer模型进行了基准测试。具体来说，比较了相同参数大小和检查点模型的推理延迟性能，评估了BERT、RoBERTa和XLM-RoBERTa模型的性能。

Conclusion: 结果突出了MLX在Apple生态系统中实现高效且更易访问的设备端机器学习应用的潜力。

Abstract: The recent widespread adoption of Large Language Models (LLMs) and machine
learning in general has sparked research interest in exploring the
possibilities of deploying these models on smaller devices such as laptops and
mobile phones. This creates a need for frameworks and approaches that are
capable of taking advantage of on-device hardware. The MLX framework was
created to address this need. It is a framework optimized for machine learning
(ML) computations on Apple silicon devices, facilitating easier research,
experimentation, and prototyping.
  This paper presents a performance evaluation of MLX, focusing on inference
latency of transformer models. We compare the performance of different
transformer architecture implementations in MLX with their Pytorch
counterparts. For this research we create a framework called MLX-transformers
which includes different transformer implementations in MLX and downloads the
model checkpoints in pytorch and converts it to the MLX format. By leveraging
the advanced architecture and capabilities of Apple Silicon, MLX-Transformers
enables seamless execution of transformer models directly sourced from Hugging
Face, eliminating the need for checkpoint conversion often required when
porting models between frameworks.
  Our study benchmarks different transformer models on two Apple Silicon
macbook devices against an NVIDIA CUDA GPU. Specifically, we compare the
inference latency performance of models with the same parameter sizes and
checkpoints. We evaluate the performance of BERT, RoBERTa, and XLM-RoBERTa
models, with the intention of extending future work to include models of
different modalities, thus providing a more comprehensive assessment of MLX's
capabilities. The results highlight MLX's potential in enabling efficient and
more accessible on-device ML applications within Apple's ecosystem.

</details>


### [96] [Noise-corrected GRPO: From Noisy Rewards to Unbiased Gradients](https://arxiv.org/abs/2510.18924)
*Omar El mansouri,Mohamed El Amine Seddik,Salem Lahlou*

Main category: cs.LG

TL;DR: 本文提出了一种名为GRPO和Dr.GRPO的降噪强化学习框架，能够有效应对人类反馈或可验证奖励中存在的噪音，并在数学和代码任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM对齐或SOTA推理模型构建中使用的强化学习方法（如RLHF或RLVR）对不一致或错误的奖励噪声高度敏感，但这种噪声与广泛使用的基于群体的策略优化方法之间的相互作用尚未得到充分探索。

Method: 本文引入了一种名为Group Relative Policy Optimization (GRPO) 和 Done Right GRPO (Dr.GRPO) 的降噪框架，该框架明确将奖励损坏建模为伯努利噪声。该方法在估计奖励翻转概率后进行噪声校正，以消除学习信号中的偏差，从而获得无偏差的梯度估计。

Result: 在数学和代码任务中，应用本文提出的噪声校正方法后，标准奖励模型的使用效果得到了持续改善。在真实的奖励模型条件下，数学任务的准确率提高了高达6.7个百分点，代码任务的准确率提高了1.5个百分点。

Conclusion: 本文将监督学习中的标签噪声校正与现代RLHF相结合，为嘈杂的真实世界部署提供了理论见解和实用算法。理论分析表明，基于群体的方法本质上可以减轻个体层面噪声，而本文的校正策略则增强了这种鲁棒性。

Abstract: Reinforcement learning from human feedback (RLHF) or verifiable rewards
(RLVR), the standard paradigm for aligning LLMs or building recent SOTA
reasoning models, is highly sensitive to noise from inconsistent or erroneous
rewards. Yet, the interaction between such noise and widely used group-based
policy optimization methods remains underexplored. We introduce a noise-robust
Group Relative Policy Optimization (GRPO) and Done Right GRPO (Dr.GRPO)
framework that explicitly models reward corruption as Bernoulli noise. Our
method applies noise correction after estimating reward flip probabilities to
debias the learning signal, yielding provably unbiased gradient estimates.
Theoretical analysis shows that group-based methods inherently mitigate
individual-level noise, and our correction strategy amplifies this robustness.
Empirically, we observe consistent improvements across math and code tasks when
applying our noise correction to standard reward model usage, with particular
gains of up to 6.7 percentage points in accuracy on math tasks and 1.5 on code
tasks under realistic reward model conditions. This work bridges label-noise
correction from supervised learning with modern RLHF, offering both theoretical
insights and a practical algorithm for noisy real-world deployment.

</details>


### [97] [BAPO: Stabilizing Off-Policy Reinforcement Learning for LLMs via Balanced Policy Optimization with Adaptive Clipping](https://arxiv.org/abs/2510.18927)
*Zhiheng Xi,Xin Guo,Yang Nan,Enyu Zhou,Junrui Shen,Wenxiang Chen,Jiaqi Liu,Jixuan Huang,Zhihao Zhang,Honglin Guo,Xun Deng,Zhikai Lei,Miao Zheng,Guoteng Wang,Shuo Zhang,Peng Sun,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.LG

TL;DR: 本文提出了一种名为BAPO的新型强化学习方法，通过动态调整裁剪边界来平衡策略优化，有效解决了现有离策略强化学习中策略熵下降和优化不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 在离策略设置中应用强化学习（RL）以提高样本效率面临挑战，主要表现为策略熵急剧下降、优化不稳定甚至崩溃。

Method: 通过理论和实证分析，本文发现：1）优化中存在不平衡，负优势样本在策略梯度中占主导地位，抑制了有益行为并有梯度爆炸的风险；2）导出的“熵剪辑规则”表明，PPO类目标中固定的剪辑机制系统性地阻止了熵增加的更新，导致策略过度利用而牺牲了探索。在此基础上，本文提出了BAPO方法，通过动态调整剪辑边界，自适应地重新平衡正负贡献，保持熵，并稳定RL优化。

Result: 在各种离策略场景（包括样本重放和部分 rollout）中，BAPO实现了快速、稳定和数据高效的训练。在AIME 2024和AIME 2025基准测试中，本文的7B BAPO模型超越了SkyWork-OR1-7B等开源模型。32B BAPO模型不仅在同等规模模型中取得了最先进的结果，而且还超越了o3-mini和Gemini-2.5-Flash-Thinking等领先的专有系统。

Conclusion: BAPO通过引入自适应剪裁机制，有效解决了离策略强化学习中的关键挑战，实现了性能上的显著提升，并且在多个基准测试中取得了最佳结果。

Abstract: Reinforcement learning (RL) has recently become the core paradigm for
aligning and strengthening large language models (LLMs). Yet, applying RL in
off-policy settings--where stale data from past policies are used for
training--improves sample efficiency, but remains challenging: policy entropy
declines sharply, optimization often becomes unstable and may even collapse.
Through theoretical and empirical analysis, we identify two key insights: (i)
an imbalance in optimization, where negative-advantage samples dominate the
policy gradient, suppressing useful behaviors and risking gradient explosions;
and (ii) the derived Entropy-Clip Rule, which reveals that the fixed clipping
mechanism in PPO-like objectives systematically blocks entropy-increasing
updates, thereby driving the policy toward over-exploitation at the expense of
exploration. Building on these insights, we propose BAlanced Policy
Optimization with Adaptive Clipping (BAPO), a simple yet effective method that
dynamically adjusts clipping bounds to adaptively re-balance positive and
negative contributions, preserve entropy, and stabilize RL optimization. Across
diverse off-policy scenarios--including sample replay and partial rollout--BAPO
achieves fast, stable, and data-efficient training. On AIME 2024 and AIME 2025
benchmarks, our 7B BAPO model surpasses open-source counterparts such as
SkyWork-OR1-7B, while our 32B BAPO model not only achieves state-of-the-art
results among models of the same scale but also outperforms leading proprietary
systems like o3-mini and Gemini-2.5-Flash-Thinking.

</details>


### [98] [An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data--Extended Version](https://arxiv.org/abs/2510.18998)
*Buang Zhang,Tung Kieu,Xiangfei Qiu,Chenjuan Guo,Jilin Hu,Aoying Zhou,Christian S. Jensen,Bin Yang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的时间序列异常检测方法，该方法通过分解编码表示来增强模型在存在异常数据训练时的鲁棒性，并通过新的互信息度量代替重建误差来识别异常。


<details>
  <summary>Details</summary>
Motivation: 时间序列异常检测在现代大规模系统中非常重要，并且在各种领域中应用广泛。无监督方法因其无需异常标签而受到广泛关注，其中自动编码器因其使用重构误差定义异常分数而备受关注。然而，自动编码器学习到的表示对训练时间序列中的异常敏感，导致准确性降低。

Method: 我们提出了一种新颖的“编码-然后-分解”范式，将编码表示分解为稳定表示和辅助表示，从而增强了在受污染时间序列训练时的鲁棒性。此外，我们提出了一种新的基于互信息度量来替代重建误差以识别异常。

Result: 我们的方法在八个常用的多变量和单变量时间序列基准测试中展示了具有竞争力或最先进的性能，并对不同污染比的时间序列表现出鲁棒性。

Conclusion: 所提出的编码-然后-分解范式结合互信息度量，有效解决了自动编码器在异常检测中对异常敏感的问题，提高了检测的准确性和鲁棒性。

Abstract: Time series anomaly detection is important in modern large-scale systems and
is applied in a variety of domains to analyze and monitor the operation of
diverse systems. Unsupervised approaches have received widespread interest, as
they do not require anomaly labels during training, thus avoiding potentially
high costs and having wider applications. Among these, autoencoders have
received extensive attention. They use reconstruction errors from compressed
representations to define anomaly scores. However, representations learned by
autoencoders are sensitive to anomalies in training time series, causing
reduced accuracy. We propose a novel encode-then-decompose paradigm, where we
decompose the encoded representation into stable and auxiliary representations,
thereby enhancing the robustness when training with contaminated time series.
In addition, we propose a novel mutual information based metric to replace the
reconstruction errors for identifying anomalies. Our proposal demonstrates
competitive or state-of-the-art performance on eight commonly used multi- and
univariate time series benchmarks and exhibits robustness to time series with
different contamination ratios.

</details>


### [99] [Scalable LinUCB: Low-Rank Design Matrix Updates for Recommenders with Large Action Spaces](https://arxiv.org/abs/2510.19349)
*Evgenia Shustova,Marina Sheshukova,Sergey Samsonov,Evgeny Frolov*

Main category: cs.LG

TL;DR: 本文介绍了一种可伸缩的LinUCB算法，通过动态低秩参数化逆Cholesky式因子，实现对逆正则化设计矩阵的快速、内存高效操作。


<details>
  <summary>Details</summary>
Motivation: LinUCB在推荐系统中广泛应用，但其训练、推理和内存成本随特征维度和动作空间大小的增加而增长。主要瓶颈在于需要更新、反转和存储吸收交互历史上下文信息的设计矩阵。

Method: 通过动态低秩参数化逆Cholesky式因子，实现了对逆正则化设计矩阵的快速、内存高效操作。推导出数值稳定的rank-1和批量更新，无需直接形成整个矩阵即可维护逆矩阵。为了控制内存增长，采用投影分裂积分器进行动态低秩近似，使得平均每步更新成本为O(dr)，内存为O(dr)。

Result: 实验证明了该算法在推荐系统数据集上的有效性。推理复杂度为每个动作评估O(dr)。

Conclusion: Scalable LinUCB算法通过动态低秩参数化和投影分裂积分器，有效解决了传统LinUCB在处理高维特征和大规模动作空间时面临的计算和内存效率问题，显著提升了算法的可扩展性和实用性。

Abstract: Linear contextual bandits, especially LinUCB, are widely used in recommender
systems. However, its training, inference, and memory costs grow with feature
dimensionality and the size of the action space. The key bottleneck becomes the
need to update, invert and store a design matrix that absorbs contextual
information from interaction history. In this paper, we introduce Scalable
LinUCB, the algorithm that enables fast and memory efficient operations with
the inverse regularized design matrix. We achieve this through a dynamical
low-rank parametrization of its inverse Cholesky-style factors. We derive
numerically stable rank-1 and batched updates that maintain the inverse without
directly forming the entire matrix. To control memory growth, we employ a
projector-splitting integrator for dynamical low-rank approximation, yielding
average per-step update cost $O(dr)$ and memory $O(dr)$ for approximation rank
$r$. Inference complexity of the suggested algorithm is $O(dr)$ per action
evaluation. Experiments on recommender system datasets demonstrate the
effectiveness of our algorithm.

</details>


### [100] [Empowering Decision Trees via Shape Function Branching](https://arxiv.org/abs/2510.19040)
*Nakul Upadhya,Eldan Cohen*

Main category: cs.LG

TL;DR: SGT是一种新型的决策树，它通过在每个内部节点应用可学习的轴对齐形状函数，以实现对非线性特征效应的有效捕获，从而提高模型性能并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的决策树依赖简单的轴对齐线性分割，导致模型结构复杂，难以理解。

Method: 提出Shape Generalized Tree (SGT)，它在每个内部节点应用可学习的轴对齐形状函数，实现单次分割中的非线性划分。同时提出了ShapeCART算法来学习SGT。此外，还将SGT扩展到双变量形状函数 (S$^2$GT) 和多路树 (SGT$_K$)，并提出了相应的学习算法Shape$^2$CART和ShapeCART$_K$。

Result: SGT在各种数据集上取得了卓越的性能，并且与传统的轴对齐线性树相比，模型尺寸更小。

Conclusion: SGT通过引入可学习的轴对齐形状函数，在保持决策树可解释性的前提下，显著提升了其处理非线性特征效应的能力，从而在性能和模型复杂度之间取得了更好的平衡。

Abstract: Decision trees are prized for their interpretability and strong performance
on tabular data. Yet, their reliance on simple axis-aligned linear splits often
forces deep, complex structures to capture non-linear feature effects,
undermining human comprehension of the constructed tree. To address this
limitation, we propose a novel generalization of a decision tree, the Shape
Generalized Tree (SGT), in which each internal node applies a learnable
axis-aligned shape function to a single feature, enabling rich, non-linear
partitioning in one split. As users can easily visualize each node's shape
function, SGTs are inherently interpretable and provide intuitive, visual
explanations of the model's decision mechanisms. To learn SGTs from data, we
propose ShapeCART, an efficient induction algorithm for SGTs. We further extend
the SGT framework to bivariate shape functions (S$^2$GT) and multi-way trees
(SGT$_K$), and present Shape$^2$CART and ShapeCART$_K$, extensions to ShapeCART
for learning S$^2$GTs and SGT$_K$s, respectively. Experiments on various
datasets show that SGTs achieve superior performance with reduced model size
compared to traditional axis-aligned linear trees.

</details>


### [101] [POLAR: Policy-based Layerwise Reinforcement Learning Method for Stealthy Backdoor Attacks in Federated Learning](https://arxiv.org/abs/2510.19056)
*Kuai Yu,Xiaoyu Wu,Peishen Yan,Qingqian Yang,Linshan Jiang,Hao Wang,Yang Hua,Tao Song,Haibing Guan*

Main category: cs.LG

TL;DR: 本文提出了一种名为POLAR的策略，它利用强化学习来解决联邦学习中分层后门攻击中的后门关键（BC）层选择问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习后门攻击方法选择BC层时，采用基于规则的选择，未能考虑层间相互关系，效率低下，且容易被发现。

Method: POLAR是一种轻量级的策略，它使用伯努利采样，通过策略梯度更新来动态学习攻击策略，并根据后门成功率（BSR）的提高来优化层选择。此外，POLAR引入了一个正则化约束来限制修改层的数量，以确保隐蔽性。

Result: POLAR在对抗六种最先进的防御措施时，性能优于最新的攻击方法，最高可达40%。

Conclusion: POLAR通过引入强化学习和正则化约束，有效地解决了联邦学习中分层后门攻击的BC层选择问题，提高了攻击的效率和隐蔽性。

Abstract: Federated Learning (FL) enables decentralized model training across multiple
clients without exposing local data, but its distributed feature makes it
vulnerable to backdoor attacks. Despite early FL backdoor attacks modifying
entire models, recent studies have explored the concept of backdoor-critical
(BC) layers, which poison the chosen influential layers to maintain
stealthiness while achieving high effectiveness. However, existing BC layers
approaches rely on rule-based selection without consideration of the
interrelations between layers, making them ineffective and prone to detection
by advanced defenses. In this paper, we propose POLAR (POlicy-based LAyerwise
Reinforcement learning), the first pipeline to creatively adopt RL to solve the
BC layer selection problem in layer-wise backdoor attack. Different from other
commonly used RL paradigm, POLAR is lightweight with Bernoulli sampling. POLAR
dynamically learns an attack strategy, optimizing layer selection using policy
gradient updates based on backdoor success rate (BSR) improvements. To ensure
stealthiness, we introduce a regularization constraint that limits the number
of modified layers by penalizing large attack footprints. Extensive experiments
demonstrate that POLAR outperforms the latest attack methods by up to 40%
against six state-of-the-art (SOTA) defenses.

</details>


### [102] [Policy Learning with Abstention](https://arxiv.org/abs/2510.19672)
*Ayush Sawarni,Jikai Jin,Justin Whitehouse,Vasilis Syrgkanis*

Main category: cs.LG

TL;DR: 本文探讨了在个性化医疗和广告等领域中使用的策略学习算法，并提出了一种允许算法在不确定时放弃决策的策略学习方法。


<details>
  <summary>Details</summary>
Motivation: 在个性化医疗和广告等高风险场景中，现有的策略学习方法即使在预测不确定时也强制要求做出决策，这可能带来风险。因此，需要一种允许在不确定时弃权的策略学习方法。

Method: 我们提出了一种两阶段学习器。首先，它识别一组接近最优的策略，然后根据这些策略之间的分歧构建一个弃权规则。当倾向性已知时，我们建立了快速的O(1/n)型遗憾保证，并将这些保证通过双重鲁棒(DR)目标扩展到未知倾向性的情况。弃权作为一种通用工具，可直接应用于策略学习中的其他核心问题：在没有常见可实现性假设的边际条件下，它能提供改进的保证，通过对小数据漂移进行对冲，连接到分布鲁棒的策略学习，并通过以高概率确保比基线策略有所改进来支持安全的策略改进。

Result: 我们建立了快速的O(1/n)型遗憾保证，并通过双重鲁棒(DR)目标将这些保证扩展到未知倾向性的情况。弃权作为一种通用工具，直接应用于策略学习中的其他核心问题，并在边际条件下提供改进的保证，连接到分布鲁棒的策略学习，并支持安全的策略改进。

Conclusion: 策略学习中的弃权机制可以有效地解决高风险决策场景下的不确定性问题，并通过两阶段学习器和双重鲁棒目标实现了性能提升和更广泛的应用。

Abstract: Policy learning algorithms are widely used in areas such as personalized
medicine and advertising to develop individualized treatment regimes. However,
most methods force a decision even when predictions are uncertain, which is
risky in high-stakes settings. We study policy learning with abstention, where
a policy may defer to a safe default or an expert. When a policy abstains, it
receives a small additive reward on top of the value of a random guess. We
propose a two-stage learner that first identifies a set of near-optimal
policies and then constructs an abstention rule from their disagreements. We
establish fast O(1/n)-type regret guarantees when propensities are known, and
extend these guarantees to the unknown-propensity case via a doubly robust (DR)
objective. We further show that abstention is a versatile tool with direct
applications to other core problems in policy learning: it yields improved
guarantees under margin conditions without the common realizability assumption,
connects to distributionally robust policy learning by hedging against small
data shifts, and supports safe policy improvement by ensuring improvement over
a baseline policy with high probability.

</details>


### [103] [Statistical Inference for Linear Functionals of Online Least-squares SGD when $t \gtrsim d^{1+δ}$](https://arxiv.org/abs/2510.19734)
*Bhavya Agrawalla,Krishnakumar Balasubramanian,Promit Ghosal*

Main category: cs.LG

TL;DR: 该论文为オンライン最小二乘SGD的线性函数建立了非渐近Berry-Esseen界，从而在增长维度体系下提供了高斯中心极限定理（CLT）。


<details>
  <summary>Details</summary>
Motivation: 量化SGD的固有不确定性。

Method: 本研究为オンライン最小二乘SGD的线性函数建立了非渐近Berry-Esseen界，从而在增长维度体系下提供了高斯中心极限定理（CLT）。

Result: 当迭代次数$t \gtrsim d^{1+\delta}$（对于任意$\delta > 0$）时，SGD迭代的CLT成立。所提出的在线SGD程序在$O(td)$时间内运行，只需要$O(d)$内存，而协方差反演方法的运行时间为$O(td^2 + d^3)$。这显著扩展了先前工作所允许的维度范围，并提高了计算效率。此外，本研究还开发了一种在线方差估计器，用于CLT中出现的渐近方差，并为该估计器建立了高概率偏差界限。

Conclusion: 这些结果首次提供了一个完全在线和数据驱动的框架，用于在接近最优的$t \gtrsim d^{1+\delta}$尺度下构建SGD迭代的置信区间。

Abstract: Stochastic Gradient Descent (SGD) has become a cornerstone method in modern
data science. However, deploying SGD in high-stakes applications necessitates
rigorous quantification of its inherent uncertainty. In this work, we establish
\emph{non-asymptotic Berry--Esseen bounds} for linear functionals of online
least-squares SGD, thereby providing a Gaussian Central Limit Theorem (CLT) in
a \emph{growing-dimensional regime}. Existing approaches to high-dimensional
inference for projection parameters, such as~\cite{chang2023inference}, rely on
inverting empirical covariance matrices and require at least $t \gtrsim
d^{3/2}$ iterations to achieve finite-sample Berry--Esseen guarantees,
rendering them computationally expensive and restrictive in the allowable
dimensional scaling. In contrast, we show that a CLT holds for SGD iterates
when the number of iterations grows as $t \gtrsim d^{1+\delta}$ for any $\delta
> 0$, significantly extending the dimensional regime permitted by prior works
while improving computational efficiency. The proposed online SGD-based
procedure operates in $\mathcal{O}(td)$ time and requires only $\mathcal{O}(d)$
memory, in contrast to the $\mathcal{O}(td^2 + d^3)$ runtime of
covariance-inversion methods. To render the theory practically applicable, we
further develop an \emph{online variance estimator} for the asymptotic variance
appearing in the CLT and establish \emph{high-probability deviation bounds} for
this estimator. Collectively, these results yield the first fully online and
data-driven framework for constructing confidence intervals for SGD iterates in
the near-optimal scaling regime $t \gtrsim d^{1+\delta}$.

</details>


### [104] [What Makes a Good Curriculum? Disentangling the Effects of Data Ordering on LLM Mathematical Reasoning](https://arxiv.org/abs/2510.19099)
*Yaning Jia,Chunhui Zhang,Xingjian Diao,Xiangchi Yuan,Zhongyu Ouyang,soroush vosoughi*

Main category: cs.LG

TL;DR: 这篇论文研究了课程学习（CL）在提高大型语言模型（LLM）推理能力方面的应用。


<details>
  <summary>Details</summary>
Motivation: 以往的工作在课程学习中采用了不同的难度衡量标准和训练设置，导致以下基本问题尚未解决：课程学习何时有效？正向还是反向排序更好？答案是否取决于我们衡量什么？

Method: 作者们通过一个统一的离线评估框架来解决这些问题，该框架将课程难度分解为五个互补的维度：问题难度、模型意外性、置信度裕度、预测不确定性和决策可变性。通过在Llama3.1-8B、Mistral-7B和Gemma3-4B上对数学推理基准进行受控的训练后实验。

Result: (i) 没有一种课程策略是普遍适用的，正向与反向课程学习的相对有效性共同取决于模型能力和任务复杂性；(ii) 即使在单一指标内，不同难度水平的样本会根据任务需求产生不同的收益；(iii) 任务对齐的课程侧重于塑造模型的最终表示和泛化，而内部状态课程则调节置信度和不确定性等内部状态。

Conclusion: 研究结果挑战了通用课程策略的观念，并为不同模型和任务体系提供了可操作的指导，其中一些指标表明，优先处理决策不确定样本可以进一步提高学习效果。

Abstract: Curriculum learning (CL) - ordering training data from easy to hard - has
become a popular strategy for improving reasoning in large language models
(LLMs). Yet prior work employs disparate difficulty metrics and training
setups, leaving open fundamental questions: When does curriculum help? Which
direction - forward or reverse - is better? And does the answer depend on what
we measure? We address these questions through a unified offline evaluation
framework that decomposes curriculum difficulty into five complementary
dimensions: Problem Difficulty, Model Surprisal, Confidence Margin, Predictive
Uncertainty, and Decision Variability. Through controlled post-training
experiments on mathematical reasoning benchmarks with Llama3.1-8B, Mistral-7B,
and Gemma3-4B, we find that (i) no curriculum strategy dominates universally -
the relative effectiveness of forward versus reverse CL depends jointly on
model capability and task complexity; (ii) even within a single metric, samples
at different difficulty levels produce distinct gains depending on task
demands; and (iii) task-aligned curricula focus on shaping the model's final
representations and generalization, whereas inner-state curricula modulate
internal states such as confidence and uncertainty. Our findings challenge the
notion of a universal curriculum strategy and offer actionable guidance across
model and task regimes, with some metrics indicating that prioritizing
decision-uncertain samples can further enhance learning outcomes.

</details>


### [105] [MetaCluster: Enabling Deep Compression of Kolmogorov-Arnold Network](https://arxiv.org/abs/2510.19105)
*Matthew Raffel,Adwaith Renjith,Lizhong Chen*

Main category: cs.LG

TL;DR: MetaCluster框架通过将低维嵌入映射到系数向量并进行聚类，最终实现KANs模型参数存储减少80倍且不损失准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的KANs模型具有高表达能力和准确性，但参数和内存呈倍数增长。

Method: MetaCluster框架，包括一个与KAN共同训练的轻量级元学习器，该学习器将低维嵌入映射到系数向量，使其在低维流形上进行聚类。然后，在系数空间中运行K-means，用共享的质心替换每条边的向量。在丢弃元学习器后，通过对质心码本进行微调来恢复准确性损失。

Result: 在MNIST、CIFAR-10和CIFAR-100数据集上，针对标准KANs和使用多种基函数的ConvKANs，MetaCluster使参数存储减少了多达80倍，且没有牺牲准确性。

Conclusion: MetaCluster框架能够显著压缩KANs模型，大幅减少参数存储，同时保持甚至恢复模型精度。

Abstract: Kolmogorov-Arnold Networks (KANs) replace scalar weights with per-edge
vectors of basis coefficients, thereby boosting expressivity and accuracy but
at the same time resulting in a multiplicative increase in parameters and
memory. We propose MetaCluster, a framework that makes KANs highly compressible
without sacrificing accuracy. Specifically, a lightweight meta-learner, trained
jointly with the KAN, is used to map low-dimensional embedding to coefficient
vectors, shaping them to lie on a low-dimensional manifold that is amenable to
clustering. We then run K-means in coefficient space and replace per-edge
vectors with shared centroids. Afterwards, the meta-learner can be discarded,
and a brief fine-tuning of the centroid codebook recovers any residual accuracy
loss. The resulting model stores only a small codebook and per-edge indices,
exploiting the vector nature of KAN parameters to amortize storage across
multiple coefficients. On MNIST, CIFAR-10, and CIFAR-100, across standard KANs
and ConvKANs using multiple basis functions, MetaCluster achieves a reduction
of up to 80$\times$ in parameter storage, with no loss in accuracy. Code will
be released upon publication.

</details>


### [106] [Steering Autoregressive Music Generation with Recursive Feature Machines](https://arxiv.org/abs/2510.19127)
*Daniel Zhao,Daniel Beaglehole,Taylor Berg-Kirkpatrick,Julian McAuley,Zachary Novack*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为MusicRFM的框架，它使用递归特征机（RFMs）来控制预训练音乐模型的内部激活，从而实现对音乐生成过程的细粒度、可解释的控制，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有可控音乐生成方法通常需要模型再训练或引入听觉伪影，这限制了它们在实际应用中的灵活性和效果。

Method: MusicRFM框架通过适应递归特征机（RFMs）来实现对冻结的预训练音乐模型的细粒度、可解释的控制。RFMs分析模型的内部梯度，产生可解释的“概念方向”（激活空间中对应音符或和弦等音乐属性的特定轴）。首先，训练轻量级RFM探针以在MusicGen的隐藏状态中发现这些方向；然后，在推理过程中，将它们注入回模型以实时引导生成过程，而无需进行每步优化。该方法还包括动态、时变调度和同时执行多个音乐属性的方法等高级控制机制。

Result: MusicRFM成功地平衡了控制和生成质量：将生成目标音符的准确率从0.23提高到0.82，同时文本提示依从性与未引导基线的偏差保持在约0.02以内，这表明在对提示保真度影响最小的情况下实现了有效控制。

Conclusion: MusicRFM框架通过利用RFMs对预训练音乐模型进行内部激活控制，有效解决了可控音乐生成中的挑战，实现了细粒度、可解释的控制，并在保持生成质量的同时显著提高了生成准确性。

Abstract: Controllable music generation remains a significant challenge, with existing
methods often requiring model retraining or introducing audible artifacts. We
introduce MusicRFM, a framework that adapts Recursive Feature Machines (RFMs)
to enable fine-grained, interpretable control over frozen, pre-trained music
models by directly steering their internal activations. RFMs analyze a model's
internal gradients to produce interpretable "concept directions", or specific
axes in the activation space that correspond to musical attributes like notes
or chords. We first train lightweight RFM probes to discover these directions
within MusicGen's hidden states; then, during inference, we inject them back
into the model to guide the generation process in real-time without per-step
optimization. We present advanced mechanisms for this control, including
dynamic, time-varying schedules and methods for the simultaneous enforcement of
multiple musical properties. Our method successfully navigates the trade-off
between control and generation quality: we can increase the accuracy of
generating a target musical note from 0.23 to 0.82, while text prompt adherence
remains within approximately 0.02 of the unsteered baseline, demonstrating
effective control with minimal impact on prompt fidelity. We release code to
encourage further exploration on RFMs in the music domain.

</details>


### [107] [InvarGC: Invariant Granger Causality for Heterogeneous Interventional Time Series under Latent Confounding](https://arxiv.org/abs/2510.19138)
*Ziyi Zhang,Shaogang Ren,Xiaoning Qian,Nick Duffield*

Main category: cs.LG

TL;DR: 本文提出了一种不变Granger因果关系（InvarGC）方法，通过利用跨环境异质性来处理潜在混杂因素和区分干预与非干预环境，从而在存在潜在混杂和未知干预的情况下识别因果关系。


<details>
  <summary>Details</summary>
Motivation: 传统的Granger因果关系方法在非线性因果关系检测方面存在局限性，并且通常依赖于因果充分性和已知干预目标这两个关键假设。然而，在实际应用中，潜在混杂因素普遍存在，并且干预环境往往难以区分。

Method: 本文提出了不变Granger因果关系（InvarGC）方法。该方法通过利用跨环境异质性来减轻潜在混杂因素的影响，并以边级别的粒度区分干预和非干预环境，从而恢复不变的因果关系。同时，论文还建立了在该条件下的可识别性。

Result: 在合成和真实数据集上进行的大量实验表明，InvarGC方法与最先进的方法相比，表现出了 F 竞争力。

Conclusion: InvarGC方法有效地解决了存在潜在混杂和未知干预环境下因果关系发现的挑战，并通过利用跨环境异质性提高了因果关系识别的准确性和鲁ibility。

Abstract: Granger causality is widely used for causal structure discovery in complex
systems from multivariate time series data. Traditional Granger causality tests
based on linear models often fail to detect even mild non-linear causal
relationships. Therefore, numerous recent studies have investigated non-linear
Granger causality methods, achieving improved performance. However, these
methods often rely on two key assumptions: causal sufficiency and known
interventional targets. Causal sufficiency assumes the absence of latent
confounders, yet their presence can introduce spurious correlations. Moreover,
real-world time series data usually come from heterogeneous environments,
without prior knowledge of interventions. Therefore, in practice, it is
difficult to distinguish intervened environments from non-intervened ones, and
even harder to identify which variables or timesteps are affected. To address
these challenges, we propose Invariant Granger Causality (InvarGC), which
leverages cross-environment heterogeneity to mitigate the effects of latent
confounding and to distinguish intervened from non-intervened environments with
edge-level granularity, thereby recovering invariant causal relations. In
addition, we establish the identifiability under these conditions. Extensive
experiments on both synthetic and real-world datasets demonstrate the
competitive performance of our approach compared to state-of-the-art methods.

</details>


### [108] [Subliminal Corruption: Mechanisms, Thresholds, and Interpretability](https://arxiv.org/abs/2510.19152)
*Reya Vir,Sarvesh Bhatnagar*

Main category: cs.LG

TL;DR: 本文探讨了机器学习模型中一种名为“潜意识腐败”的现象，即不良特征通过语义中性数据传播，绕过标准安全检查，并量化了其动态。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在合成数据上进行微调时面临关键风险，即微小错位可能通过相互连接的AI系统传播。

Method: 通过使用GPT-2的教师-学生设置，系统研究了潜意识腐败的缩放定律、阈值和机制。

Result: 1. 潜意识腐败会导致行为交叉，不仅损害目标特征，还会降低模型的整体对齐性；2. 对齐失败发生在中毒数据达到临界阈值时的急剧相变，而非逐渐退化；3. 可解释性分析表明，腐败机制模仿了模型的自然微调过程，难以检测。

Conclusion: 这些结果揭示了依赖合成数据的AI系统中的一个关键漏洞，强调了需要新的安全协议来应对潜在威胁。

Abstract: As machine learning models are increasingly fine-tuned on synthetic data,
there is a critical risk of subtle misalignments spreading through
interconnected AI systems. This paper investigates subliminal corruption, which
we define as undesirable traits are transmitted through semantically neutral
data, bypassing standard safety checks. While this phenomenon has been
identified, a quantitative understanding of its dynamics is missing. To address
this gap, we present a systematic study of the scaling laws, thresholds, and
mechanisms of subliminal corruption using a teacher-student setup with GPT-2.
Our experiments reveal three key findings: (1) subliminal corruption causes
behavioral crossover, degrading the model's overall alignment, not just the
targeted trait; (2) alignment fails in a sharp phase transition at a critical
threshold of poisoned data, rather than degrading gradually; and (3)
interpretability analysis shows the corruption mechanism mimics the model's
natural fine-tuning process, making it difficult to detect. These results
demonstrate a critical vulnerability in AI systems that rely on synthetic data
and highlight the need for new safety protocols that can account for latent
threats.

</details>


### [109] [Feature Space Adaptation for Robust Model Fine-Tuning](https://arxiv.org/abs/2510.19155)
*Peng Wang,Minghao Gu,Qiang Huang*

Main category: cs.LG

TL;DR: 该论文提出了两种名为LoRFA和VeFA的新型微调方法，旨在解决模型微调中灾难性遗忘的问题，并通过在特征空间而非权重空间进行调整来增强模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决模型微调中灾难性遗忘的问题，尤其是在下游领域标记数据有限或与预训练分布差异很大的情况下，传统参数高效微调方法容易使模型过度专业化，覆盖预训练知识。

Method: 提出了在特征空间进行微调的两种新方法：LoRFA（低秩特征适应）和VeFA（基于向量的特征适应）。这两种方法通过轻量级的特征级转换来补偿下游潜在变量的影响，从而保留预训练表示，提高模型在分布变化下的泛化能力。

Result: LoRFA和VeFA在图像分类、NLU和NLG任务上，与LoRA相比，取得了可比的微调结果，并表现出持续更强的鲁棒性。

Conclusion: 在特征空间进行适应能够有效地缓解灾难性遗忘，并显著增强模型在面对分布变化时的泛化能力和鲁棒性。

Abstract: Catastrophic forgetting is a common issue in model fine-tuning, especially
when the downstream domain contains limited labeled data or differs greatly
from the pre-training distribution. Existing parameter-efficient fine-tuning
methods operate in the weight space by modifying or augmenting the pre-trained
model's parameters, which can yield models overly specialized to the available
downstream data. To mitigate the risk of overwriting pre-trained knowledge and
enhance robustness, we propose to fine-tune the pre-trained model in the
feature space. Two new fine-tuning methods are proposed: LoRFA (Low-Rank
Feature Adaptation) and VeFA (Vector-Based Feature Adaptation). Feature space
adaptation is inspired by the idea of effect equivalence modeling (EEM) of
downstream lurking variables causing distribution shifts, which posits that
unobserved factors can be represented as the total equivalent amount on
observed features. By compensating for the effects of downstream lurking
variables via a lightweight feature-level transformation, the pre-trained
representations can be preserved, which improves model generalization under
distribution shift. We evaluate LoRFA and VeFA versus LoRA on image
classification, NLU, and NLG, covering both standard fine-tuning metrics and
robustness. Feature space adaptation achieves comparable fine-tuning results
and consistently stronger robustness.

</details>


### [110] [Instance-Dependent Regret Bounds for Nonstochastic Linear Partial Monitoring](https://arxiv.org/abs/2510.19158)
*Federico Di Gennaro,Khaled Eldowa,Nicolò Cesa-Bianchi*

Main category: cs.LG

TL;DR: 本文提出了一种针对线性部分监控问题的探索-优化方法，能在特定游戏结构下实现更透明的后悔界。


<details>
  <summary>Details</summary>
Motivation: 经典的部分监控模型无法处理无限结果空间，且以往理论保证中游戏结构对后悔界的影响不够清晰。

Method: 通过探索-优化方法解决非随机、有限动作的线性部分监控问题。

Result: 推导出的后悔界限依赖于游戏结构，且比以往的理论保证更清晰。在简单游戏（局部可观测）中达到 \sqrt{T} 的标准速率，在困难游戏（全局可观测）中达到 T^{2/3}。

Conclusion: 本文提出的方法对于线性部分监控问题实现了更透明和紧密的后悔界，可以应用于多种部分信息场景。

Abstract: In contrast to the classic formulation of partial monitoring, linear partial
monitoring can model infinite outcome spaces, while imposing a linear structure
on both the losses and the observations. This setting can be viewed as a
generalization of linear bandits where loss and feedback are decoupled in a
flexible manner. In this work, we address a nonstochastic (adversarial),
finite-actions version of the problem through a simple instance of the
exploration-by-optimization method that is amenable to efficient
implementation. We derive regret bounds that depend on the game structure in a
more transparent manner than previous theoretical guarantees for this paradigm.
Our bounds feature instance-specific quantities that reflect the degree of
alignment between observations and losses, and resemble known guarantees in the
stochastic setting. Notably, they achieve the standard $\sqrt{T}$ rate in easy
(locally observable) games and $T^{2/3}$ in hard (globally observable) games,
where $T$ is the time horizon. We instantiate these bounds in a selection of
old and new partial information settings subsumed by this model, and illustrate
that the achieved dependence on the game structure can be tight in interesting
cases.

</details>


### [111] [Preliminary Use of Vision Language Model Driven Extraction of Mouse Behavior Towards Understanding Fear Expression](https://arxiv.org/abs/2510.19160)
*Paimon Goulart,Jordan Steinhauser,Kylene Shuler,Edward Korzus,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.LG

TL;DR: 该工作提出了一个视觉-语言模型 (VLM)，通过编码视频和文本输入来分类小鼠在环境中存在的各种行为。


<details>
  <summary>Details</summary>
Motivation: 此模型能够通过对每个受试者及其每个会话产生一个行为向量来促进跨学科研究，从而支持对小鼠行为的研究。

Method: 我们使用了开源的 Qwen2.5-VL 模型，并通过提示、带标签示例的上下文学习 (ICL) 和帧级预处理来提高其性能，从而实现了在不进行模型微调的情况下在所有行为上获得较高的 F1 分数。

Result: 我们发现每种方法都有助于改进分类，并且结合这些方法可以在所有行为（包括不常见的行为，如僵住和逃跑）上获得较高的 F1 分数，而无需进行任何模型微调。

Conclusion: 这个模型能够促进跨学科研究人员研究小鼠行为，通过将不同时间点和环境下测量的多样化行为特征整合到一个全面的数据集中，以解决复杂的研究问题。

Abstract: Integration of diverse data will be a pivotal step towards improving
scientific explorations in many disciplines. This work establishes a
vision-language model (VLM) that encodes videos with text input in order to
classify various behaviors of a mouse existing in and engaging with their
environment. Importantly, this model produces a behavioral vector over time for
each subject and for each session the subject undergoes. The output is a
valuable dataset that few programs are able to produce with as high accuracy
and with minimal user input. Specifically, we use the open-source Qwen2.5-VL
model and enhance its performance through prompts, in-context learning (ICL)
with labeled examples, and frame-level preprocessing. We found that each of
these methods contributes to improved classification, and that combining them
results in strong F1 scores across all behaviors, including rare classes like
freezing and fleeing, without any model fine-tuning. Overall, this model will
support interdisciplinary researchers studying mouse behavior by enabling them
to integrate diverse behavioral features, measured across multiple time points
and environments, into a comprehensive dataset that can address complex
research questions.

</details>


### [112] [Natural Gradient VI: Guarantees for Non-Conjugate Models](https://arxiv.org/abs/2510.19163)
*Fangyuan Sun,Ilyas Fatkhullin,Niao He*

Main category: cs.LG

TL;DR: 本文探讨了随机自然梯度变分推断（NGVI）在非共轭似然情况下的理论基础，提出了改进的NGVI算法并证明了其收敛性，揭示了变分损失的隐藏凸性以建立快速收敛性。


<details>
  <summary>Details</summary>
Motivation: NGVI在概率模型中广泛应用，但在非共轭似然情况下，其理论基础，特别是收敛性保证，仍然有限。现有的理论成果不适用于非凸的变分损失。

Method: 本文首先推导了变分损失在适当的镜像映射下满足相对光滑性的充分条件。其次，提出了一种结合非欧几里得投影的改进NGVI算法，并证明了其全局非渐近收敛到平稳点。最后，在对似然函数附加结构假设下，揭示了变分损失的隐藏凸性，并建立了NGVI到全局最优的快速全局收敛性。

Result: 本文为NGVI在非共轭似然情况下的理论分析奠定了基础，提出了改进的NGVI算法并证明了其全局非渐近收敛性，并在特定条件下实现了快速全局收敛。

Conclusion: 本文通过推导相对光滑条件、提出改进算法和揭示隐藏凸性，显著提升了对NGVI在非共轭推断设置中几何形状和收敛行为的理解。

Abstract: Stochastic Natural Gradient Variational Inference (NGVI) is a widely used
method for approximating posterior distribution in probabilistic models.
Despite its empirical success and foundational role in variational inference,
its theoretical underpinnings remain limited, particularly in the case of
non-conjugate likelihoods. While NGVI has been shown to be a special instance
of Stochastic Mirror Descent, and recent work has provided convergence
guarantees using relative smoothness and strong convexity for conjugate models,
these results do not extend to the non-conjugate setting, where the variational
loss becomes non-convex and harder to analyze. In this work, we focus on
mean-field parameterization and advance the theoretical understanding of NGVI
in three key directions. First, we derive sufficient conditions under which the
variational loss satisfies relative smoothness with respect to a suitable
mirror map. Second, leveraging this structure, we propose a modified NGVI
algorithm incorporating non-Euclidean projections and prove its global
non-asymptotic convergence to a stationary point. Finally, under additional
structural assumptions about the likelihood, we uncover hidden convexity
properties of the variational loss and establish fast global convergence of
NGVI to a global optimum. These results provide new insights into the geometry
and convergence behavior of NGVI in challenging inference settings.

</details>


### [113] [Imbalanced Gradients in RL Post-Training of Multi-Task LLMs](https://arxiv.org/abs/2510.19178)
*Runzhe Wu,Ankur Samanta,Ayush Jain,Scott Fujimoto,Jeongyeol Kwon,Ben Kretzu,Youliang Yu,Kaveh Hassani,Boris Vidolov,Yonathan Efroni*

Main category: cs.LG

TL;DR: 这篇论文研究了大型语言模型（LLM）多任务训练中梯度不平衡问题，并指出大梯度任务的学习收益可能并不大。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的多任务训练通常采用混合数据集和联合优化的方式。然而，论文指出，这种方法隐式假设所有任务贡献的梯度大小相似，但这一假设在强化学习（RL）后训练中并不成立。某些任务会产生显著更大的梯度，从而导致更新偏向这些任务。

Method: 论文通过实验和分析，揭示了RL后训练中，某些任务会产生显著更大的梯度，从而导致更新偏向这些任务的现象。论文还进一步分析了这些梯度不平衡与学习收益的关系，并探究了其产生的原因，排除了与典型训练统计数据（如训练奖励或优势）的关联。

Result: 研究发现，在RL后训练中，某些任务会产生显著更大的梯度，导致优化偏向这些任务。然而，大梯度任务并不一定意味着更大的学习收益，其学习收益可能与小梯度任务相似甚至更低。梯度不平衡不能用典型的训练统计数据来解释，而可能源于任务固有的差异。

Conclusion: 这篇论文对目前大型语言模型（LLM）多任务训练中朴素的数据集混合方法提出了质疑，并呼吁未来在梯度层面进行原理性的校正。

Abstract: Multi-task post-training of large language models (LLMs) is typically
performed by mixing datasets from different tasks and optimizing them jointly.
This approach implicitly assumes that all tasks contribute gradients of similar
magnitudes; when this assumption fails, optimization becomes biased toward
large-gradient tasks. In this paper, however, we show that this assumption
fails in RL post-training: certain tasks produce significantly larger
gradients, thus biasing updates toward those tasks. Such gradient imbalance
would be justified only if larger gradients implied larger learning gains on
the tasks (i.e., larger performance improvements) -- but we find this is not
true. Large-gradient tasks can achieve similar or even much lower learning
gains than small-gradient ones. Further analyses reveal that these gradient
imbalances cannot be explained by typical training statistics such as training
rewards or advantages, suggesting that they arise from the inherent differences
between tasks. This cautions against naive dataset mixing and calls for future
work on principled gradient-level corrections for LLMs.

</details>


### [114] [Enhancing Graph Neural Networks: A Mutual Learning Approach](https://arxiv.org/abs/2510.19223)
*Paul Agbaje,Akajyoti Mitra,Afia Anjum,Pranali Khose,Ebelechukwu Nwafor,Habeeb Olufowobi*

Main category: cs.LG

TL;DR: 本文提出了一种协同学习框架，使GNN学生模型能够在没有预训练教师模型的情况下相互学习，并在节点和图分类任务中取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏（KD）技术在资源受限设备中部署高性能模型方面具有优势，但需要一个复杂的教师模型。本文旨在探索在没有预训练教师模型的情况下，通过GNN之间的协同学习来提升模型性能。

Method: 本文提出了一种协同学习框架，其中学生GNN模型在训练过程中相互教学。主要方法包括：1. 引入自适应logits加权单元，以促进模型之间高效的知识交换。2. 采用熵增强技术，以改善相互学习过程。

Result: 在三个节点分类数据集和三个图分类数据集上的大量实验表明，该方法在多任务处理中优于现有方法，展示了其有效性。

Conclusion: 本文提出的协同学习框架，通过允许简单的GNN模型相互教学，在没有预训练教师模型的情况下，显著提升了模型在节点和图分类任务上的性能，并为资源受限环境下的模型部署提供了新的思路。

Abstract: Knowledge distillation (KD) techniques have emerged as a powerful tool for
transferring expertise from complex teacher models to lightweight student
models, particularly beneficial for deploying high-performance models in
resource-constrained devices. This approach has been successfully applied to
graph neural networks (GNNs), harnessing their expressive capabilities to
generate node embeddings that capture structural and feature-related
information. In this study, we depart from the conventional KD approach by
exploring the potential of collaborative learning among GNNs. In the absence of
a pre-trained teacher model, we show that relatively simple and shallow GNN
architectures can synergetically learn efficient models capable of performing
better during inference, particularly in tackling multiple tasks. We propose a
collaborative learning framework where ensembles of student GNNs mutually teach
each other throughout the training process. We introduce an adaptive logit
weighting unit to facilitate efficient knowledge exchange among models and an
entropy enhancement technique to improve mutual learning. These components
dynamically empower the models to adapt their learning strategies during
training, optimizing their performance for downstream tasks. Extensive
experiments conducted on three datasets each for node and graph classification
demonstrate the effectiveness of our approach.

</details>


### [115] [Controllable Machine Unlearning via Gradient Pivoting](https://arxiv.org/abs/2510.19226)
*Youngsik Hwang,Dong-Young Lim*

Main category: cs.LG

TL;DR: CUP通过将机器遗忘重构为多目标优化问题，解决了现有近似遗忘方法在遗忘效率和模型保真度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 近似遗忘方法在遗忘效率和模型保真度之间存在关键的权衡，导致了过度遗忘、缺乏细粒度控制以及缺乏综合评估权衡的指标等挑战。

Method: 本文将机器遗忘重构为多目标优化（MOO）问题，并引入了一种新颖的算法CUP（Controllable Unlearning by Pivoting Gradient）。CUP具有独特的枢轴机制，能够可控地遍历整个帕累托前沿，并通过单一的“遗忘强度”超参数精确选择所需的权衡。

Result: CUP生成了一组更优的帕累托最优解，在各种视觉任务中始终优于现有方法。

Conclusion: CUP算法通过多目标优化和可控的帕累托前沿导航，有效解决了机器遗忘中的权衡问题，提供了更精细的控制和更优的性能。

Abstract: Machine unlearning (MU) aims to remove the influence of specific data from a
trained model. However, approximate unlearning methods, often formulated as a
single-objective optimization (SOO) problem, face a critical trade-off between
unlearning efficacy and model fidelity. This leads to three primary challenges:
the risk of over-forgetting, a lack of fine-grained control over the unlearning
process, and the absence of metrics to holistically evaluate the trade-off. To
address these issues, we reframe MU as a multi-objective optimization (MOO)
problem. We then introduce a novel algorithm, Controllable Unlearning by
Pivoting Gradient (CUP), which features a unique pivoting mechanism. Unlike
traditional MOO methods that converge to a single solution, CUP's mechanism is
designed to controllably navigate the entire Pareto frontier. This navigation
is governed by a single intuitive hyperparameter, the `unlearning intensity',
which allows for precise selection of a desired trade-off. To evaluate this
capability, we adopt the hypervolume indicator, a metric that captures both the
quality and diversity of the entire set of solutions an algorithm can generate.
Our experimental results demonstrate that CUP produces a superior set of
Pareto-optimal solutions, consistently outperforming existing methods across
various vision tasks.

</details>


### [116] [Brain-Inspired Perspective on Configurations: Unsupervised Similarity and Early Cognition](https://arxiv.org/abs/2510.19229)
*Juntang Wang,Yihan Wang,Hao Wu,Dongmian Zou,Shixin Xu*

Main category: cs.LG

TL;DR: 婴儿在没有监督的情况下进行类别发现、新颖性检测和适应新环境，这对当前的机器学习提出了挑战。本文提出了一种受大脑启发的配置视角。


<details>
  <summary>Details</summary>
Motivation: 探索一种受大脑启发的配置视角，解决婴儿在无监督情况下进行类别发现、新颖性检测和适应新环境的挑战。

Method: 提出了一种有限分辨率聚类框架，该框架使用单一分辨率参数和吸引-排斥动力学，以产生层次组织、新颖性敏感性和灵活适应性。同时引入了mheatmap，提供比例热图和重新分配算法来公平评估多分辨率和动态行为。

Result: 这些配置在标准聚类指标上具有竞争力，在新颖性检测方面达到87%的AUC，并在动态类别演变过程中显示出35%的更好稳定性。

Conclusion: 将配置定位为早期认知分类的原则性计算模型，并向受大脑启发的AI迈出了一步。

Abstract: Infants discover categories, detect novelty, and adapt to new contexts
without supervision -- a challenge for current machine learning. We present a
brain-inspired perspective on configurations, a finite-resolution clustering
framework that uses a single resolution parameter and attraction-repulsion
dynamics to yield hierarchical organization, novelty sensitivity, and flexible
adaptation. To evaluate these properties, we introduce mheatmap, which provides
proportional heatmaps and a reassignment algorithm to fairly assess
multi-resolution and dynamic behavior. Across datasets, configurations are
competitive on standard clustering metrics, achieve 87% AUC in novelty
detection, and show 35% better stability during dynamic category evolution.
These results position configurations as a principled computational model of
early cognitive categorization and a step toward brain-inspired AI.

</details>


### [117] [Understanding the Implicit Biases of Design Choices for Time Series Foundation Models](https://arxiv.org/abs/2510.19236)
*Annan Yu,Danielle C. Maddix,Boran Han,Xiyuan Zhang,Abdul Fatir Ansari,Oleksandr Shchur,Christos Faloutsos,Andrew Gordon Wilson,Michael W. Mahoney,Yuyang Wang*

Main category: cs.LG

TL;DR: 本文探讨了时间序列基础模型（TSFMs）的训练过程中的设计选择如何影响模型质量。


<details>
  <summary>Details</summary>
Motivation: 理解训练过程中的各种“旋钮”如何影响TSFMs的模型质量，而不是开发新的模型并声称其优于现有模型。

Method: 通过理论和受控的实证评估相结合，识别了几个设计选择（如patch size、embedding choice、训练目标等），并展示了它们如何导致模型基本属性（如时间行为、几何结构、模型回归均值的程度等）的隐含偏差。

Result: 这些偏差可以是直观的，也可以是非常反直观的，这取决于模型和数据的特性。此外，通过一个异常值处理的案例研究，说明了多个偏差如何以复杂的方式相互作用。

Conclusion: 讨论了研究结果对学习以及构建TSFMs的启示。

Abstract: Time series foundation models (TSFMs) are a class of potentially powerful,
general-purpose tools for time series forecasting and related temporal tasks,
but their behavior is strongly shaped by subtle inductive biases in their
design. Rather than developing a new model and claiming that it is better than
existing TSFMs, e.g., by winning on existing well-established benchmarks, our
objective is to understand how the various ``knobs'' of the training process
affect model quality. Using a mix of theory and controlled empirical
evaluation, we identify several design choices (patch size, embedding choice,
training objective, etc.) and show how they lead to implicit biases in
fundamental model properties (temporal behavior, geometric structure, how
aggressively or not the model regresses to the mean, etc.); and we show how
these biases can be intuitive or very counterintuitive, depending on properties
of the model and data. We also illustrate in a case study on outlier handling
how multiple biases can interact in complex ways; and we discuss implications
of our results for learning the bitter lesson and building TSFMs.

</details>


### [118] [SPOT: Scalable Policy Optimization with Trees for Markov Decision Processes](https://arxiv.org/abs/2510.19241)
*Xuyuan Xiong,Pedro Chumpitaz-Flores,Kaixun Hua,Cheng Hua*

Main category: cs.LG

TL;DR: 该论文提出了一种名为 SPOT 的新颖方法，用于在马尔可夫决策过程中计算决策树策略，它将优化问题表述为混合整数线性规划。


<details>
  <summary>Details</summary>
Motivation: 在马尔可夫决策过程中优化决策树策略仍然具有挑战性，但可解释的强化学习策略对于高风险决策至关重要。

Method: SPOT 将优化问题表述为混合整数线性规划（MILP）。为了提高效率，我们采用了一种 giảm-空间分支定界方法，将 MDP 动力学与树结构约束分离，从而实现高效的并行搜索。

Result: 与以前的方法相比，SPOT 显著提高了运行时间、可伸缩性，并在标准基准测试中实现了实质性加速，可以扩展到具有更多状态的更大 MDP。每次迭代都能产生最佳决策树，且得到的决策树策略具有可解释性和紧凑性，在不影响性能的情况下保持了透明度。

Conclusion: SPOT 方法同时实现了可解释性和可伸缩性，提供了高质量的策略，比现有方法快了一个数量级。

Abstract: Interpretable reinforcement learning policies are essential for high-stakes
decision-making, yet optimizing decision tree policies in Markov Decision
Processes (MDPs) remains challenging. We propose SPOT, a novel method for
computing decision tree policies, which formulates the optimization problem as
a mixed-integer linear program (MILP). To enhance efficiency, we employ a
reduced-space branch-and-bound approach that decouples the MDP dynamics from
tree-structure constraints, enabling efficient parallel search. This
significantly improves runtime and scalability compared to previous methods.
Our approach ensures that each iteration yields the optimal decision tree.
Experimental results on standard benchmarks demonstrate that SPOT achieves
substantial speedup and scales to larger MDPs with a significantly higher
number of states. The resulting decision tree policies are interpretable and
compact, maintaining transparency without compromising performance. These
results demonstrate that our approach simultaneously achieves interpretability
and scalability, delivering high-quality policies an order of magnitude faster
than existing approaches.

</details>


### [119] [Mixing Configurations for Downstream Prediction](https://arxiv.org/abs/2510.19248)
*Juntang Wang,Hao Wu,Runkun Guo,Yihan Wang,Dongmian Zou,Shixin Xu*

Main category: cs.LG

TL;DR: 本文提出了一种名为 GraMixC 的即插即用模块，该模块通过提取配置、使用 RMS 技术对齐并融合它们，从而改进了 Vision Transformers 中的注册令牌，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 聚类算法旨在模拟人类按相似性对对象进行分组的认知机制。最近的社区检测进展使得无需标记数据即可发现配置（跨多个分辨率尺度的有效分层聚类）。本文正是基于这些发现，旨在改进 Vision Transformers 中的注册令牌。

Method: 本文提出 GraMixC，这是一个即插即用模块，它提取配置，使用 Reverse Merge/Split (RMS) 技术对齐它们，并通过注意力头融合它们，然后将它们转发到任何下游预测器。

Result: 在 DSN1 16S rRNA 培养基预测任务上，GraMixC 将 R2 分数从 0.6 提高到 0.9，超越了多种方法，达到了新的技术水平。此外，GraMixC 在标准表格基准测试中也表现出色，始终优于单分辨率和静态特征基线方法。

Conclusion: GraMixC 通过有效地利用配置解决了现有方法的局限性，特别是在 Vision Transformers 的注册令牌方面，并在多个任务中取得了显著的性能提升。

Abstract: Humans possess an innate ability to group objects by similarity, a cognitive
mechanism that clustering algorithms aim to emulate. Recent advances in
community detection have enabled the discovery of configurations -- valid
hierarchical clusterings across multiple resolution scales -- without requiring
labeled data. In this paper, we formally characterize these configurations and
identify similar emergent structures in register tokens within Vision
Transformers. Unlike register tokens, configurations exhibit lower redundancy
and eliminate the need for ad hoc selection. They can be learned through
unsupervised or self-supervised methods, yet their selection or composition
remains specific to the downstream task and input. Building on these insights,
we introduce GraMixC, a plug-and-play module that extracts configurations,
aligns them using our Reverse Merge/Split (RMS) technique, and fuses them via
attention heads before forwarding them to any downstream predictor. On the DSN1
16S rRNA cultivation-media prediction task, GraMixC improves the R2 score from
0.6 to 0.9 across multiple methods, setting a new state of the art. We further
validate GraMixC on standard tabular benchmarks, where it consistently
outperforms single-resolution and static-feature baselines.

</details>


### [120] [Knowledge Distillation of Uncertainty using Deep Latent Factor Model](https://arxiv.org/abs/2510.19290)
*Sehyun Park,Jongjin Lee,Yunseop Shin,Ilsang Ohn,Yongdai Kim*

Main category: cs.LG

TL;DR: 高斯蒸馏是一种集成压缩技术，它将教师集成压缩成学生分布而不是学生集成，以在减小模型尺寸的同时保留不确定性。


<details>
  <summary>Details</summary>
Motivation: 深度集成在不确定性量化方面表现出色，但其高昂的计算和内存需求限制了实际应用。知识蒸馏可以压缩集成模型，但现有技术难以保留不确定性。

Method: 高斯蒸馏通过深度潜在因子模型（DLF）估计教师集成的分布，将每个教师集成成员视为某个随机过程的实现。DLF模型中的均值和协方差函数通过期望最大化（EM）算法稳定估计。

Result: 高斯蒸馏在多个基准数据集上优于现有基线。它还能有效处理语言模型的微调和分布偏移问题。

Conclusion: 高斯蒸馏通过将集成蒸馏为分布，解决了模型压缩中不确定性保留的难题，并在各种任务上取得了优异性能。

Abstract: Deep ensembles deliver state-of-the-art, reliable uncertainty quantification,
but their heavy computational and memory requirements hinder their practical
deployments to real applications such as on-device AI. Knowledge distillation
compresses an ensemble into small student models, but existing techniques
struggle to preserve uncertainty partly because reducing the size of DNNs
typically results in variation reduction. To resolve this limitation, we
introduce a new method of distribution distillation (i.e. compressing a teacher
ensemble into a student distribution instead of a student ensemble) called
Gaussian distillation, which estimates the distribution of a teacher ensemble
through a special Gaussian process called the deep latent factor model (DLF) by
treating each member of the teacher ensemble as a realization of a certain
stochastic process. The mean and covariance functions in the DLF model are
estimated stably by using the expectation-maximization (EM) algorithm. By using
multiple benchmark datasets, we demonstrate that the proposed Gaussian
distillation outperforms existing baselines. In addition, we illustrate that
Gaussian distillation works well for fine-tuning of language models and
distribution shift problems.

</details>


### [121] [QiMeng-SALV: Signal-Aware Learning for Verilog Code Generation](https://arxiv.org/abs/2510.19296)
*Yang Zhang,Rui Zhang,Jiaming Guo,Lei Huang,Di Huang,Yunpu Zhao,Shuyao Cheng,Pengwei Jin,Chongxiao Li,Zidong Du,Xing Hu,Qi Guo,Yunji Chen*

Main category: cs.LG

TL;DR: 这篇论文提出了一种针对Verilog代码生成的信号感知学习方法（QiMeng-SALV），通过利用功能正确输出信号的代码段来优化强化学习训练，解决了缺乏有意义功能奖励的问题，实现了在VerilogEval和RTLLM上的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在Verilog代码生成方面显示出巨大潜力，但由于缺乏有意义的功能奖励，基于强化学习的偏好优化难以生成功能正确的Verilog代码。

Method: QiMeng-SALV方法的核心思想是提取部分错误模块中已验证的信号感知实现，以增强有意义功能奖励的提取。具体步骤包括：1. 通过与训练数据中的参考模块进行比较，验证生成模块中信号的功能正确性。2. 利用抽象语法树（AST）识别能从错误模块中提供有意义功能奖励的信号感知代码段。3. 引入信号感知DPO（直接偏好优化），针对正确的信号级代码段进行优化，防止错误信号带来的噪声和干扰。

Result: 实验表明，QiMeng-SALV方法在VerilogEval和RTLLM数据集上取得了最先进的性能。一个7B参数的模型性能可与DeepSeek v3 671B模型相媲美，并且显著优于在相同数据集上训练的领先的开源模型CodeV。

Conclusion: QiMeng-SALV方法实现了从传统的模块级优化到细粒度信号级优化的范式转变，解决了Verilog代码生成中功能奖励不足的问题，显著提升了代码生成的准确性。

Abstract: The remarkable progress of Large Language Models (LLMs) presents promising
opportunities for Verilog code generation which is significantly important for
automated circuit design. The lacking of meaningful functional rewards hinders
the preference optimization based on Reinforcement Learning (RL) for producing
functionally correct Verilog code. In this paper, we propose Signal-Aware
Learning for Verilog code generation (QiMeng-SALV) by leveraging code segments
of functionally correct output signal to optimize RL training. Considering
Verilog code specifies the structural interconnection of hardware gates and
wires so that different output signals are independent, the key insight of
QiMeng-SALV is to extract verified signal-aware implementations in partially
incorrect modules, so as to enhance the extraction of meaningful functional
rewards. Roughly, we verify the functional correctness of signals in generated
module by comparing with that of reference module in the training data. Then
abstract syntax tree (AST) is employed to identify signal-aware code segments
which can provide meaningful functional rewards from erroneous modules.
Finally, we introduce signal-aware DPO which is optimized on the correct
signal-level code segments, thereby preventing noise and interference from
incorrect signals. The proposed QiMeng-SALV underscores the paradigm shift from
conventional module-level to fine-grained signal-level optimization in Verilog
code generation, addressing the issue of insufficient functional rewards.
Experiments demonstrate that our method achieves state-of-the-art performance
on VerilogEval and RTLLM, with a 7B parameter model matching the performance of
the DeepSeek v3 671B model and significantly outperforming the leading
open-source model CodeV trained on the same dataset. Our code is available at
https://github.com/zy1xxx/SALV.

</details>


### [122] [Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall](https://arxiv.org/abs/2510.19304)
*Mingyu Jo,Jaesik Yoon,Justin Deschenaux,Caglar Gulcehre,Sungjin Ahn*

Main category: cs.LG

TL;DR: Loopholing离散扩散模型(LDDMs)通过保留采样过程中的丰富分布信息，显著提高了离散扩散模型的性能，在文本生成和推理任务上取得了突破。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在并行解码方面具有潜力，但其采样过程中的信息损失限制了其性能。

Method: Loopholing通过确定性潜在路径保存了丰富的分布信息，并采用了自条件策略进行高效训练。

Result: LDDMs在生成困惑度方面比基线模型降低了高达61%，缩小了与自回归模型的差距，并生成了更连贯的文本。在推理任务中，LDDMs也提升了性能。

Conclusion: Loopholing机制有效缓解了离散扩散模型的信息损失问题，为高质量非自回归文本生成提供了一条可扩展的路径。

Abstract: Discrete diffusion models offer a promising alternative to autoregressive
generation through parallel decoding, but they suffer from a sampling wall:
once categorical sampling occurs, rich distributional information collapses
into one-hot vectors and cannot be propagated across steps, forcing subsequent
steps to operate with limited information. To mitigate this problem, we
introduce Loopholing, a novel and simple mechanism that preserves this
information via a deterministic latent pathway, leading to Loopholing Discrete
Diffusion Models (LDDMs). Trained efficiently with a self-conditioning
strategy, LDDMs achieve substantial gains-reducing generative perplexity by up
to 61% over prior baselines, closing (and in some cases surpassing) the gap
with autoregressive models, and producing more coherent text. Applied to
reasoning tasks, LDDMs also improve performance on arithmetic benchmarks such
as Countdown and Game of 24. These results also indicate that loopholing
mitigates idle steps and oscillations, providing a scalable path toward
high-quality non-autoregressive text generation.

</details>


### [123] [FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal Data and Pseudo-Absence Imputation](https://arxiv.org/abs/2510.19305)
*Chirag Padubidri,Pranesh Velmurugan,Andreas Lanitis,Andreas Kamilaris*

Main category: cs.LG

TL;DR: 该研究通过深度学习和数据插补技术，提高了两栖动物物种分布模型（SDM）的准确性，并实现了84.9%的栖息地分类准确率，对生物多样性监测具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 物种分布的监测对于保护工作至关重要，传统的和公民科学的数据收集方法在覆盖范围和完整性上存在局限性。

Method: 本研究通过深度学习和数据插补技术，利用“EY - 2022生物多样性挑战”的数据，增强了两栖动物物种分布模型（SDM）的准确性。主要方法包括：数据平衡、特征选择以及集成多种模型（融合了图像和表格数据）。

Result: 数据平衡显著改善了模型性能，将青蛙计数任务的平均绝对误差（MAE）从189降低到29。特征选择识别了影响物种出现的关键环境因素。多模式集成模型（整合了土地覆盖、NDVI和其他环境输入）优于单个模型，并展现出在未见区域的强大泛化能力。图像和表格数据的融合提高了青蛙计数和栖息地分类的准确性，达到了84.9%的准确率和0.90的AUC（Area Under the Curve）。

Conclusion: 本研究强调了多模态学习和数据预处理技术（如平衡和插补）在数据稀疏或不完整时，提高预测生态建模的潜力，有助于更精确和可扩展的生物多样性监测。

Abstract: Monitoring species distribution is vital for conservation efforts, enabling
the assessment of environmental impacts and the development of effective
preservation strategies. Traditional data collection methods, including citizen
science, offer valuable insights but remain limited in coverage and
completeness. Species Distribution Modelling (SDM) helps address these gaps by
using occurrence data and environmental variables to predict species presence
across large regions. In this study, we enhance SDM accuracy for frogs (Anura)
by applying deep learning and data imputation techniques using data from the
"EY - 2022 Biodiversity Challenge." Our experiments show that data balancing
significantly improved model performance, reducing the Mean Absolute Error
(MAE) from 189 to 29 in frog counting tasks. Feature selection identified key
environmental factors influencing occurrence, optimizing inputs while
maintaining predictive accuracy. The multimodal ensemble model, integrating
land cover, NDVI, and other environmental inputs, outperformed individual
models and showed robust generalization across unseen regions. The fusion of
image and tabular data improved both frog counting and habitat classification,
achieving 84.9% accuracy with an AUC of 0.90. This study highlights the
potential of multimodal learning and data preprocessing techniques such as
balancing and imputation to improve predictive ecological modeling when data
are sparse or incomplete, contributing to more precise and scalable
biodiversity monitoring.

</details>


### [124] [Calibration and Discrimination Optimization Using Clusters of Learned Representation](https://arxiv.org/abs/2510.19328)
*Tomer Lavi,Bracha Shapira,Nadav Rappoport*

Main category: cs.LG

TL;DR: 该文章提出了一种新颖的校准流程，通过在学习到的输入样本表示集群上训练校准函数的集成，来提高机器学习模型对判别和校准的可靠性，而校准通常是风险评估和决策中被忽视但关键的方面。


<details>
  <summary>Details</summary>
Motivation: 在临床预测等关键决策中，机器学习模型需要高度可靠的预测，这不仅体现在判别能力上，也体现在校准上。尽管校准经常被忽视，但它对于关键决策至关重要。

Method: 该方法引入了一种新颖的校准流程，它利用在输入样本学习表示的集群上训练的校准函数集成来增强整体校准。同时，该方法提出了一种独特的匹配度量，以确保模型选择能够同时优化判别和校准。

Result: 该方法将各种校准方法的校准分数从82.28%提高到100%。所提出的通用方案适用于任何基础表示、聚类、校准方法和度量，在常用校准方法中提供了灵活性和卓越的性能。

Conclusion: 该文章提出了一种新颖的校准流程，通过对学习到的表示集群进行校准函数的集成训练，显著提高了机器学习模型的校准性能，同时兼顾了判别和校准，为关键决策提供了更可靠的预测。

Abstract: Machine learning models are essential for decision-making and risk
assessment, requiring highly reliable predictions in terms of both
discrimination and calibration. While calibration often receives less
attention, it is crucial for critical decisions, such as those in clinical
predictions. We introduce a novel calibration pipeline that leverages an
ensemble of calibration functions trained on clusters of learned
representations of the input samples to enhance overall calibration. This
approach not only improves the calibration score of various methods from 82.28%
up to 100% but also introduces a unique matching metric that ensures model
selection optimizes both discrimination and calibration. Our generic scheme
adapts to any underlying representation, clustering, calibration methods and
metric, offering flexibility and superior performance across commonly used
calibration methods.

</details>


### [125] [Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning](https://arxiv.org/abs/2510.19338)
*Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou*

Main category: cs.LG

TL;DR: 该技术报告介绍了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0，它们通过混合注意力SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 在长文本推理场景中，降低I/O和计算开销是主要的挑战。

Method: Ring-linear模型系列采用混合架构，有效整合了线性注意力和softmax注意力，并通过自研的FP8运算符库-linghe提高了训练效率。

Result: 相较于320亿参数的密集模型，该系列的推理成本降低了1/10；相较于原始Ring系列，成本降低了50%以上。训练效率提高了50%。模型在多个复杂的推理基准测试中保持SOTA性能。

Conclusion: Ring-linear模型通过混合注意力机制和优化的训练推理引擎，显著降低了长文本推理的成本，并保持了领先的性能。

Abstract: In this technical report, we present the Ring-linear model series,
specifically including Ring-mini-linear-2.0 and Ring-flash-linear-2.0.
Ring-mini-linear-2.0 comprises 16B parameters and 957M activations, while
Ring-flash-linear-2.0 contains 104B parameters and 6.1B activations. Both
models adopt a hybrid architecture that effectively integrates linear attention
and softmax attention, significantly reducing I/O and computational overhead in
long-context inference scenarios. Compared to a 32 billion parameter dense
model, this series reduces inference cost to 1/10, and compared to the original
Ring series, the cost is also reduced by over 50%. Furthermore, through
systematic exploration of the ratio between different attention mechanisms in
the hybrid architecture, we have identified the currently optimal model
structure. Additionally, by leveraging our self-developed high-performance FP8
operator library-linghe, overall training efficiency has been improved by 50%.
Benefiting from the high alignment between the training and inference engine
operators, the models can undergo long-term, stable, and highly efficient
optimization during the reinforcement learning phase, consistently maintaining
SOTA performance across multiple challenging complex reasoning benchmarks.

</details>


### [126] [Foundation Model Forecasts: Form and Function](https://arxiv.org/abs/2510.19345)
*Alvaro Perez-Diaz,James C. Loach,Danielle E. Toutoungi,Lee Middleton*

Main category: cs.LG

TL;DR: 本文分析了时间序列基础模型（TSFMs）的预测类型对其在实际操作任务中应用的重要性，并指出多数模型未能生成轨迹集合预测，这限制了它们在复杂任务中的实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管时间序列基础模型在预测准确性方面表现出色，但其预测形式（点预测、分位数预测、参数预测或轨迹集合预测）直接影响其在实际操作任务中的应用价值。目前大多数模型仅生成点预测或参数预测，无法满足许多需要保留时间依赖性的操作任务。

Method: 本文对现有的时间序列基础模型进行了调查，分析了不同预测类型之间的转换可行性，并从理论上证明了边缘分布无法确定路径依赖事件的概率。接着，将六种基本预测任务映射到最小充分的预测类型，并建立了一个任务对齐的评估框架。

Result: 调查发现，三分之二的时间序列基础模型只产生点预测或参数预测。轨迹集合预测可以通过边缘化转换为更简单的形式，而反向转换则需要通过copulas或共形方法强加时间依赖性。理论证明了无穷多个联合分布可以共享相同的边缘分布，但对操作问题的答案却不同。

Conclusion: 预测类型而非准确性，是区分时间序列基础模型实际效用的关键。未来的研究应更多地关注如何生成轨迹集合预测，以满足复杂操作任务的需求。

Abstract: Time-series foundation models (TSFMs) achieve strong forecast accuracy, yet
accuracy alone does not determine practical value. The form of a forecast --
point, quantile, parametric, or trajectory ensemble -- fundamentally constrains
which operational tasks it can support. We survey recent TSFMs and find that
two-thirds produce only point or parametric forecasts, while many operational
tasks require trajectory ensembles that preserve temporal dependence. We
establish when forecast types can be converted and when they cannot: trajectory
ensembles convert to simpler forms via marginalization without additional
assumptions, but the reverse requires imposing temporal dependence through
copulas or conformal methods. We prove that marginals cannot determine
path-dependent event probabilities -- infinitely many joint distributions share
identical marginals but yield different answers to operational questions. We
map six fundamental forecasting tasks to minimal sufficient forecast types and
provide a task-aligned evaluation framework. Our analysis clarifies when
forecast type, not accuracy, differentiates practical utility.

</details>


### [127] [A Markov Decision Process for Variable Selection in Branch & Bound](https://arxiv.org/abs/2510.19348)
*Paul Strang,Zacharie Alès,Côme Bissuel,Olivier Juan,Safia Kedad-Sidhoum,Emmanuel Rachelson*

Main category: cs.LG

TL;DR: BBMDP是一种基于马尔可夫决策过程（MDP）的混合整数线性规划（MILP）分支定界（B&B）变量选择方法，它在四个标准MILP基准测试中优于现有的强化学习（RL）方法。


<details>
  <summary>Details</summary>
Motivation: MILP求解NP-难组合优化问题时，分支定界（B&B）算法的性能受变量选择启发式影响。当前研究热点是利用强化学习（RL）算法学习最优分支策略。

Method: 我们提出了BBMDP，一个 principled vanilla MDP 公式，用于B&B中的变量选择，可以利用广泛的RL算法来学习最优的B&B启发式。

Result: 计算实验验证了我们模型的有效性，我们的分支agent在四个标准MILP基准测试中优于现有的最先进RL agent。

Conclusion: BBMDP为在B&B中学习最优分支启发式提供了一个通用且有效的RL框架。

Abstract: Mixed-Integer Linear Programming (MILP) is a powerful framework used to
address a wide range of NP-hard combinatorial optimization problems, often
solved by Branch and Bound (B&B). A key factor influencing the performance of
B&B solvers is the variable selection heuristic governing branching decisions.
Recent contributions have sought to adapt reinforcement learning (RL)
algorithms to the B&B setting to learn optimal branching policies, through
Markov Decision Processes (MDP) inspired formulations, and ad hoc convergence
theorems and algorithms. In this work, we introduce BBMDP, a principled vanilla
MDP formulation for variable selection in B&B, allowing to leverage a broad
range of RL algorithms for the purpose of learning optimal B\&B heuristics.
Computational experiments validate our model empirically, as our branching
agent outperforms prior state-of-the-art RL agents on four standard MILP
benchmarks.

</details>


### [128] [Optimization Benchmark for Diffusion Models on Dynamical Systems](https://arxiv.org/abs/2510.19376)
*Fabian Schaipp*

Main category: cs.LG

TL;DR: 这篇论文评估了不同优化器在训练扩散模型时的性能，发现Muon和SOAP比AdamW更高效。


<details>
  <summary>Details</summary>
Motivation: 目前对扩散模型训练中优化技术的研究不足。

Method: 本文评估了最近的优化算法在训练用于去噪流轨迹的扩散模型时的性能，并研究了学习率调度对训练动态的影响，以及Adam和SGD之间的性能差距。

Result: Muon和SOAP被发现是比AdamW更高效的替代方案（最终损失降低18%）。

Conclusion: Muon和SOAP在训练扩散模型方面表现出色，并可作为AdamW的高效替代品。

Abstract: The training of diffusion models is often absent in the evaluation of new
optimization techniques. In this work, we benchmark recent optimization
algorithms for training a diffusion model for denoising flow trajectories. We
observe that Muon and SOAP are highly efficient alternatives to AdamW (18%
lower final loss). We also revisit several recent phenomena related to the
training of models for text or image applications in the context of diffusion
model training. This includes the impact of the learning-rate schedule on the
training dynamics, and the performance gap between Adam and SGD.

</details>


### [129] [CPSVD: Enhancing Large Language Model Compression via Column-Preserving Singular Value Decomposition](https://arxiv.org/abs/2510.19385)
*Lin Xv,Jingsheng Gao,Xian Gao,Ting Li,Yuzhuo Fu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为CPSVD的新型LLM压缩方法，通过智能地分割参数矩阵并针对不同部分采用不同的压缩策略，以实现比现有SVD方法更优的压缩效果。


<details>
  <summary>Details</summary>
Motivation: 现有SVD压缩方法对整个参数矩阵统一处理，忽略了SVD近似误差在矩阵不同部分差异显著，导致压缩效果不理想。

Method: CPSVD通过智能地分割参数矩阵来改进SVD压缩。它识别并直接保留具有高分解误差的矩阵列，仅对具有低分解误差的列应用SVD。CPSVD精确确定两种策略之间的最佳平衡点以最小化误差。此外，CPSVD根据LLM内部不同矩阵的分解误差固有的异构性，自适应地为层内的模块分配非均匀的压缩率，同时遵循目标层级压缩比。

Result: CPSVD在广泛的实验中始终优于最先进的基于SVD的LLM压缩方法。

Conclusion: CPSVD实现了更低的困惑度和更高的零样本任务准确性，有效提升了LLM的压缩性能。

Abstract: The rapid advancement of Large Language Models (LLMs) faces a critical
bottleneck in their immense size, necessitating efficient compression
techniques. While Singular Value Decomposition (SVD) is a promising approach,
existing SVD-based methods treat the entire parameter matrix uniformly,
overlooking that SVD approximation errors vary significantly across different
matrix parts, which often leads to suboptimal compression. To address this, we
propose \textbf{C}olumn-\textbf{P}reserving \textbf{S}ingular \textbf{V}alue
\textbf{D}ecomposition (CPSVD), a novel method that refines SVD-based LLM
compression by intelligently segmenting the parameter matrix. Unlike
traditional SVD, CPSVD identifies and directly preserves matrix columns with
high decomposition errors, applying SVD only to columns with low decomposition
errors, while precisely determining the optimal balance point between these two
strategies to minimize error. Furthermore, leveraging the inherent
heterogeneity in decomposition errors across different matrices within an LLM,
CPSVD adaptively allocates non-uniform compression rates to modules within that
layer, while adhering to a target layer-wise compression ratio, thereby further
enhancing compression performance. Extensive experiments demonstrate that CPSVD
consistently outperforms state-of-the-art SVD-based LLM compression methods,
achieving lower perplexity and higher accuracy on zero-shot tasks.

</details>


### [130] [ARA: Adaptive Rank Allocation for Efficient Large Language Model SVD Compression](https://arxiv.org/abs/2510.19389)
*Lin Xv,Jingsheng Gao,Xian Gao,Ting Liu,Yuzhuo Fu*

Main category: cs.LG

TL;DR: 本文提出了一种自适应秩分配(ARA)方法，以解决大语言模型(LLM)压缩中奇异值分解(SVD)的秩分配问题。


<details>
  <summary>Details</summary>
Motivation: 传统的SVD在LLM压缩中面临挑战，特别是在全局压缩比约束下，为不同线性模块确定合适的秩是一个关键问题。现有方法存在局限性，如启发式算法探索受限，基于掩码的训练难以有效捕捉奇异值谱与可训练参数之间的关系，并且忽略了增益函数在压缩比为1时不平滑的关键特性，导致训练过程陷入次优的局部最小值。

Method: 本文提出了一种自适应秩分配（ARA）方法。ARA通过引入专门的掩码设计，实现了保留秩和可训练参数之间的高效映射和更新；同时，采用额外的损失函数来引导参数选择，使其趋向于全局最优解。

Result: 在LLaMA2-7B模型上，以80%的压缩比，ARA将WikiText2上的困惑度从8.38降低到6.42，并且与均匀压缩相比，平均零样本任务准确率提高了9.72个百分点。

Conclusion: ARA方法在SVD-based LLM压缩中的秩分配问题上表现出最先进的性能，有效降低了困惑度并提高了零样本任务准确性。

Abstract: In the field of large language model (LLM) compression, singular value
decomposition (SVD) is a widely studied and adopted low-rank decomposition
technique. Since SVD operates exclusively on linear modules, and these modules
in LLMs are separated by nonlinear components, SVD can only be applied
independently to each linear module. Under a global compression ratio
constraint, determining the appropriate rank for different linear modules
becomes a critical problem. Existing approaches, such as heuristic algorithms
and mask-based training, have made progress in addressing this challenge.
However, these methods still suffer from several limitations: heuristic
algorithms explore the solution space within restricted regions, while
mask-based training struggles to efficiently capture the relationship between
singular value spectra and trainable parameters. More importantly, current
methods overlook the key property that the gain function is non-smooth at a
compression ratio of 1, which often leads the training process to suboptimal
local minima. To address these issues, we propose an Adaptive Rank Allocation
(ARA) method. Specifically, (1) ARA introduces a dedicated mask design that
enables efficient mapping and updating between retained ranks and trainable
parameters; and (2) it employs an additional loss function to guide parameter
selection toward globally optimal solutions. Experimental results demonstrate
that ARA achieves state-of-the-art performance. On the LLaMA2-7B model with a
80\% compression ratio, ARA reduces perplexity on WikiText2 from 8.38 to 6.42
and improves average zero-shot task accuracy by 9.72 percentage points compared
with uniform compression. These results highlight the effectiveness of our
method for rank allocation in SVD-based LLM compression.

</details>


### [131] [FairNet: Dynamic Fairness Correction without Performance Loss via Contrastive Conditional LoRA](https://arxiv.org/abs/2510.19421)
*Songqi Zhou,Zeyuan Liu,Benben Jiang*

Main category: cs.LG

TL;DR: FairNet是一个新颖的动态、实例级公平校正框架，用于解决机器学习模型中的公平性问题。它通过结合偏见检测器和条件低秩适应（LoRA）来实现，旨在在解决数据稀疏性和敏感属性利用不足问题的同时，保持模型性能，并能处理不同敏感属性标签场景。


<details>
  <summary>Details</summary>
Motivation: 现有的去偏方法通常会牺牲模型性能，依赖静态校正策略，并且在数据稀疏（尤其是在少数群体中）的情况下表现不佳。此外，它们对敏感属性的利用也不理想，要么过度依赖完整的属性标注，要么完全忽略这些属性。

Method: FairNet框架包含一个偏见检测器和条件低秩适应（LoRA）模块。LoRA模块只对被识别为有偏的实例进行公平性校正，从而在无偏实例上保持性能。TNR/FPR适中的情况下，FairNet可以在不降低整体模型性能的前提下，提高最差组的性能，并可能带来轻微的性能提升。为了训练LoRA模块，本文提出了一种新的对比损失函数，旨在最小化不同敏感组内类表示的差异，并有效解决少数群体的欠拟合问题。

Result: FairNet能够增强最差组的性能，而不会降低整体模型性能。在某些情况下，它甚至能带来轻微的性能提升。它还可以灵活处理敏感属性标签完整、部分或完全缺失的场景。

Conclusion: FairNet在解决机器学习公平性挑战方面表现出色，特别是在处理数据稀疏性、敏感属性利用不足以及保持模型性能方面。通过动态、实例级的校正策略和创新的损失函数，它为实现更公平的AI模型提供了一个有效且灵活的解决方案。

Abstract: Ensuring fairness in machine learning models is a critical challenge.
Existing debiasing methods often compromise performance, rely on static
correction strategies, and struggle with data sparsity, particularly within
minority groups. Furthermore, their utilization of sensitive attributes is
often suboptimal, either depending excessively on complete attribute labeling
or disregarding these attributes entirely. To overcome these limitations, we
propose FairNet, a novel framework for dynamic, instance-level fairness
correction. FairNet integrates a bias detector with conditional low-rank
adaptation (LoRA), which enables selective activation of the fairness
correction mechanism exclusively for instances identified as biased, and
thereby preserve performance on unbiased instances. A key contribution is a new
contrastive loss function for training the LoRA module, specifically designed
to minimize intra-class representation disparities across different sensitive
groups and effectively address underfitting in minority groups. The FairNet
framework can flexibly handle scenarios with complete, partial, or entirely
absent sensitive attribute labels. Theoretical analysis confirms that, under
moderate TPR/FPR for the bias detector, FairNet can enhance the performance of
the worst group without diminishing overall model performance, and potentially
yield slight performance improvements. Comprehensive empirical evaluations
across diverse vision and language benchmarks validate the effectiveness of
FairNet.

</details>


### [132] [LLM Unlearning with LLM Beliefs](https://arxiv.org/abs/2510.19422)
*Kemou Li,Qizhou Wang,Yue Wang,Fengpeng Li,Jun Liu,Bo Han,Jiantao Zhou*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为“挤压效应”的现象，即当大型语言模型执行遗忘操作时，概率质量会重新分布到与目标语义相关的区域。为了解决这个问题，论文提出了一种引导（BS）框架，该框架通过结合模型自身的“模型信念”来对抗挤压效应，从而实现更彻底的遗忘，同时保持模型的效用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在学习并输出敏感或有害内容的风险。

Method: 本文提出了一种新的引导（BS）框架来解决挤压效应。该框架将模型置信度（即模型自身高置信度的生成结果）纳入遗忘目标中。通过联合抑制目标响应和模型置信度，BS-T（token）衰减高概率token，而BS-S（sequence）则删除整个高置信度的生成序列。

Result: 通过在多种模型家族的广泛基准测试中进行实验，证实了所提出方法的有效性。

Conclusion: 现有的遗忘方法存在“挤压效应”，导致“虚假遗忘”。本文提出的引导（BS）框架通过整合模型信念，能够有效对抗挤压效应，实现更彻底的遗忘，同时保持模型效用。

Abstract: Large language models trained on vast corpora inherently risk memorizing
sensitive or harmful content, which may later resurface in their outputs.
Prevailing unlearning methods generally rely on gradient ascent and its
variants to lower the probability of specific target responses. However, we
find that this strategy induces a critical side effect: probability mass is
redistributed into high-likelihood regions, often corresponding to semantically
related rephrasings of the targets. We refer to this as the squeezing effect,
which explains why many methods yield merely spurious unlearning, a problem
further obscured by automated metrics (e.g., ROUGE, truth ratio) that misreport
actual success. To address this, we propose a bootstrapping (BS) framework that
explicitly links the squeezing effect with the model's own high-confidence
generations, namely its model beliefs. Since model beliefs inherently capture
the very high-likelihood regions where probability mass is squeezed,
incorporating them into the unlearning objective directly counters the
squeezing effect. By jointly suppressing both target responses and model
beliefs, BS-T (token) attenuates high-probability tokens, whereas BS-S
(sequence) removes entire high-confidence generations, together achieving more
thorough forgetting while preserving utility. Extensive experiments across
diverse benchmarks with various model families confirm the effectiveness of our
approach.

</details>


### [133] [g-DPO: Scalable Preference Optimization for Protein Language Models](https://arxiv.org/abs/2510.19474)
*Constance Ferragu,Jonathan D. Ziegler,Nicolas Deutschmann,Arthur Lindoulsi,Eli Bixby,Cradle ML Team*

Main category: cs.LG

TL;DR: g-DPO是一种与实验设计目标对齐蛋白质语言模型的有效方法，解决了DPO面临的可扩展性瓶颈。


<details>
  <summary>Details</summary>
Motivation: DPO在与实验设计目标对齐蛋白质语言模型时表现出色，但其可扩展性受限于训练对数量的二次增长，导致训练时间过长。

Method: g-DPO通过序列空间聚类来修剪冗余对以保留训练信号，并利用基于群组的近似方法分摊似然计算。

Result: 在三个蛋白质工程任务中，g-DPO在计算和体外性能方面与标准DPO无统计学差异，但收敛速度提高了1.8到3.7倍。数据集越大，性能提升越显著。

Conclusion: g-DPO通过解决DPO的可扩展性问题，使其在保持性能的同时，大幅提高了训练效率，尤其适用于大规模数据集。

Abstract: Direct Preference Optimization (DPO) is an effective approach for aligning
protein language models with experimental design goals. However, DPO faces a
scalability bottleneck: the number of possible training pairs grows
quadratically with the number of labeled sequences, leading to prohibitive
training times even for modestly sized datasets. We introduce g-DPO, a
framework that (i) uses sequence space clustering to prune redundant pairs
while preserving training signal, and (ii) amortizes likelihood computations
with group-based approximations. Across three protein engineering tasks, g-DPO
maintains in-silico and in-vitro performance that is statistically
indistinguishable from standard DPO, while converging 1.8 to 3.7 times faster,
with greater gains expected as the size of the dataset increases.

</details>


### [134] [A Concrete Roadmap towards Safety Cases based on Chain-of-Thought Monitoring](https://arxiv.org/abs/2510.19476)
*Julian Schulz*

Main category: cs.LG

TL;DR: 研究了AI模型在接近危险能力水平时，如何通过思维链（CoT）监控来构建安全案例。提出了一个两部分的安全案例框架，并探讨了CoT监控面临的威胁以及保持CoT忠实性的技术。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统功能日益强大，传统的安全案例方法已不足以应对其潜在危险，因此需要寻找新的安全保障方法。本文旨在提出一种基于CoT监控的新型安全案例构建路线图。

Method: 本文提出了一种两部分的安全案例框架：1）证明模型在无CoT运行时不具备危险能力；2）确保CoT所启用的危险能力可通过CoT监控检测。研究了“神经语言”和“编码推理”等可监控性威胁，并分为三种形式（语言漂移、隐写术和异类推理），分析了它们的驱动因素。评估了现有和新兴的保持CoT忠实性的技术，并在模型产生不可监控推理时，探索了从不可监控CoT中提取可监控CoT的可能性。建立了预测市场来评估CoT监控安全案例的可行性。

Result: 提出了一个全面的CoT监控安全案例构建路线图，其中包括两部分的安全案例框架，并分析了监控性威胁及其应对策略。探讨了保持CoT忠实性和从不可监控CoT中提取可监控CoT的方法。通过预测市场评估了技术里程碑对CoT监控可行性的影响。

Conclusion: 思维链（CoT）监控为AI系统在危险能力水平下的安全保障提供了一种有前景的新方法。通过对可监控性威胁的系统性分析和对CoT忠实性技术的评估，本文为构建更强大的AI安全案例奠定了基础。尽管仍面临挑战，但CoT监控有望提高AI系统的可控性和可信赖性。

Abstract: As AI systems approach dangerous capability levels where inability safety
cases become insufficient, we need alternative approaches to ensure safety.
This paper presents a roadmap for constructing safety cases based on
chain-of-thought (CoT) monitoring in reasoning models and outlines our research
agenda. We argue that CoT monitoring might support both control and
trustworthiness safety cases. We propose a two-part safety case: (1)
establishing that models lack dangerous capabilities when operating without
their CoT, and (2) ensuring that any dangerous capabilities enabled by a CoT
are detectable by CoT monitoring. We systematically examine two threats to
monitorability: neuralese and encoded reasoning, which we categorize into three
forms (linguistic drift, steganography, and alien reasoning) and analyze their
potential drivers. We evaluate existing and novel techniques for maintaining
CoT faithfulness. For cases where models produce non-monitorable reasoning, we
explore the possibility of extracting a monitorable CoT from a non-monitorable
CoT. To assess the viability of CoT monitoring safety cases, we establish
prediction markets to aggregate forecasts on key technical milestones
influencing their feasibility.

</details>


### [135] [Graph Unlearning Meets Influence-aware Negative Preference Optimization](https://arxiv.org/abs/2510.19479)
*Qiang Chen,Zhongze Wu,Ang He,Xi Lin,Shuo Jiang,Shan You,Chang Xu,Yi Chen,Xiu Su*

Main category: cs.LG

TL;DR: INPO是一种影响感知型负偏好优化框架，旨在通过减缓梯度上升的散度速度和提高模型实用性来改进图遗忘模型。


<details>
  <summary>Details</summary>
Motivation: 现有的图遗忘模型在遗忘过程中会导致模型实用性急剧下降，因为梯度上升的散度速度很快。

Method: INPO提出通过分析NPO的散度速度较慢，并理论上证明遗忘高影响力边可以减少遗忘的影响。它设计了一种影响感知消息函数来放大未习得边的影响，并通过基于移除的方法快速估计每条边的影响。此外，INPO还提出了一种拓扑熵损失，以避免在遗忘过程中局部结构中信息损失过多。

Result: INPO模型在五个真实世界数据集上取得了最先进的性能，并在所有遗忘质量指标上表现出色，同时保持了模型的实用性。

Conclusion: INPO框架通过关注减缓散度速度和提高模型实用性对遗忘过程的鲁棒性，有效解决了现有图遗忘模型中实用性下降的问题。

Abstract: Recent advancements in graph unlearning models have enhanced model utility by
preserving the node representation essentially invariant, while using gradient
ascent on the forget set to achieve unlearning. However, this approach causes a
drastic degradation in model utility during the unlearning process due to the
rapid divergence speed of gradient ascent. In this paper, we introduce
\textbf{INPO}, an \textbf{I}nfluence-aware \textbf{N}egative
\textbf{P}reference \textbf{O}ptimization framework that focuses on slowing the
divergence speed and improving the robustness of the model utility to the
unlearning process. Specifically, we first analyze that NPO has slower
divergence speed and theoretically propose that unlearning high-influence edges
can reduce impact of unlearning. We design an influence-aware message function
to amplify the influence of unlearned edges and mitigate the tight topological
coupling between the forget set and the retain set. The influence of each edge
is quickly estimated by a removal-based method. Additionally, we propose a
topological entropy loss from the perspective of topology to avoid excessive
information loss in the local structure during unlearning. Extensive
experiments conducted on five real-world datasets demonstrate that INPO-based
model achieves state-of-the-art performance on all forget quality metrics while
maintaining the model's utility. Codes are available at
\href{https://github.com/sh-qiangchen/INPO}{https://github.com/sh-qiangchen/INPO}.

</details>


### [136] [ELUTQ: Efficient LUT-Aware Quantization for Deploying Large Language Models on Edge Devices](https://arxiv.org/abs/2510.19482)
*Xin Nie,Liang Dong,HaiCheng Zhang,JiaWang Xiao,G. Sun*

Main category: cs.LG

TL;DR: ELUTQ是一种针对CPU边缘设备的LLM高效量化框架，引入了分层线性量化（HLQ）以在不增加计算成本的情况下提高低位宽量化的性能和效率，并在LLaMA3-8B和LLaMA2-7B上取得了显著的效果。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLMs）向基于CPU的边缘设备部署时，由于内存和计算资源有限，现有的量化方法（特别是硬件友好的均匀量化）在低位宽下存在量化效果不佳和反量化开销大的问题，这限制了边缘智能的发展和AI的普及。

Method: 本研究提出了ELUTQ框架，该框架引入了分层线性量化（HLQ）这一新颖的量化格式。HLQ旨在更好地捕捉权重分布的统计特性，同时不增加基于位串行查找表（LUT）的GEMM操作的计算成本，从而避免了反量化开销。ELUTQ还提供优化的CPU内核以支持高效的端到端推理。

Result: 实验结果表明，在后训练量化下，对于LLaMA3-8B，HLQ在3位精度下将困惑度降低了约8%，在2位精度下降低了85%，且量化过程在一小时内完成。通过高效微调，HLQ在两小时内进一步提高了2位性能。在推理效率方面，ELUTQ的2位LLaMA2-7B在Apple M2芯片（4线程，批量大小=1）上实现了超过25 token/s的处理速度。

Conclusion: ELUTQ框架及其引入的HLQ量化格式有效解决了LLMs在CPU边缘设备上部署的内存和计算限制问题。通过提高量化精度和消除反量化开销，ELUTQ显著提升了低位宽下LLMs的性能和推理效率，为边缘AI的普及提供了可行方案。

Abstract: The deployment of Large Language Models (LLMs) on CPU-based edge devices is
crucial for enabling on-device intelligence and expanding AI accessibility.
However, it remains challenging due to limited memory and computational
resources. During edge inference, memory usage and latency are the primary
bottlenecks. Although weight quantization can effectively reduce memory
consumption, existing hardware-friendly approaches often rely on uniform
quantization, which poorly fits weight distributions and incurs high
dequantization overhead at low bit widths. To address these limitations, we
propose ELUTQ, an efficient quantization framework introducing a novel
quantization format, Hierarchical Linear Quantization (HLQ). HLQ better
captures the statistical characteristics of weights without increasing the
computational cost of Bit-serial LUT-based GEMM operations, thereby eliminating
dequantization overhead. It is orthogonal to existing quantization algorithms
and can be seamlessly integrated into various quantization pipelines. For
efficient on-device deployment, ELUTQ provides optimized CPU kernels for
end-to-end inference. Experiments show that for LLaMA3-8B, HLQ reduces
perplexity by about 8% at 3-bit and 85% at 2-bit precision under post-training
quantization, completing quantization within one hour. With efficient
finetuning, HLQ further improves 2-bit performance within two hours. In terms
of inference efficiency, our 2-bit LLaMA2-7B achieves over 25 tokens/s on an
Apple M2 chip (4 threads, batch size = 1).

</details>


### [137] [Teaming LLMs to Detect and Mitigate Hallucinations](https://arxiv.org/abs/2510.19507)
*Demian Till,John Smeaton,Peter Haubrick,Gouse Saheb,Florian Graef,David Berman*

Main category: cs.LG

TL;DR: 本文提出了一种名为“联盟一致性”的新方法，通过结合来自多个大型语言模型的响应来改进幻觉检测和缓解，并在降低推理成本的同时，显著优于单模型一致性方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在幻觉检测和缓解方面取得了最先进的成果，但仍存在数据缺陷导致的局限性。

Method: 将单模型一致性方法扩展到结合来自多个具有不同训练数据、训练方案和模型架构的LLM的响应。此方法称为“联盟一致性”。

Result: “联盟一致性”方法在幻觉检测和缓解能力方面，显著优于单模型一致性方法。性能的提升往往伴随着推理成本的降低。

Conclusion: “联盟一致性”方法通过结合多个大型语言模型，有效地提升了幻觉检测和缓解能力，同时降低了推理成本，为LLM的应用提供了新的途径。

Abstract: Recent work has demonstrated state-of-the-art results in large language model
(LLM) hallucination detection and mitigation through consistency-based
approaches which involve aggregating multiple responses sampled from a single
LLM for a given prompt. These approaches help offset limitations stemming from
the imperfect data on which LLMs are trained, which includes biases and
under-representation of information required at deployment time among other
limitations which can lead to hallucinations. We show that extending these
single-model consistency methods to combine responses from multiple LLMs with
different training data, training schemes and model architectures can result in
substantial further improvements in hallucination detection and mitigation
capabilities beyond their single-model consistency counterparts. We evaluate
this \emph{consortium consistency} approach across many model teams from a pool
of 15 LLMs and explore under what conditions it is beneficial to team together
different LLMs in this manner. Further, we show that these performance
improvements often come with reduced inference costs, offsetting a significant
drawback with single-model consistency methods.

</details>


### [138] [From Prototypes to Sparse ECG Explanations: SHAP-Driven Counterfactuals for Multivariate Time-Series Multi-class Classification](https://arxiv.org/abs/2510.19514)
*Maciej Mozolewski,Betül Bayrak,Kerstin Bach,Grzegorz J. Nalepa*

Main category: cs.LG

TL;DR: 该研究提出了一种原型驱动框架，用于为12导联心电图分类模型生成稀疏反事实解释。该方法利用SHAP阈值识别关键信号段，并结合动态时间规整和medoid聚类提取代表性原型，实现了在保持高有效性的同时，大幅减少信号修改量，并提升时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健等领域，时间序列的基于实例的解释因其可操作性和可解释性而受到关注。文章旨在解决最先进模型可解释性面临的挑战，为12导联心电图分类模型提供一种原型驱动的稀疏反事实解释框架。

Method: 该方法主要分为三个步骤：1. 使用基于SHAP的阈值识别关键信号段并将其转换为区间规则。2. 运用动态时间规整（DTW）和 medoid 聚类提取具有代表性的原型。3. 将这些原型与查询R峰对齐，以确保与被解释样本的一致性。

Result: 该框架生成的反事实解释仅修改了原始信号的78%，在所有类别中保持了81.3%的有效性，并在时间稳定性方面提高了43%。研究评估了三种方法变体：Original、Sparse和Aligned Sparse，其中针对心肌梗死（MI）的类别特异性有效性高达98.9%，而对肥厚（HYP）检测的挑战性则为13.2%。该方法支持在近实时（<1秒）时间内生成临床有效的反事实解释。

Conclusion: 该研究为AI诊断系统中的生理学感知反事实解释奠定了设计原则，并为临床部署的用户控制解释界面描绘了路径，有助于开发交互式解释平台。

Abstract: In eXplainable Artificial Intelligence (XAI), instance-based explanations for
time series have gained increasing attention due to their potential for
actionable and interpretable insights in domains such as healthcare. Addressing
the challenges of explainability of state-of-the-art models, we propose a
prototype-driven framework for generating sparse counterfactual explanations
tailored to 12-lead ECG classification models. Our method employs SHAP-based
thresholds to identify critical signal segments and convert them into interval
rules, uses Dynamic Time Warping (DTW) and medoid clustering to extract
representative prototypes, and aligns these prototypes to query R-peaks for
coherence with the sample being explained. The framework generates
counterfactuals that modify only 78% of the original signal while maintaining
81.3% validity across all classes and achieving 43% improvement in temporal
stability. We evaluate three variants of our approach, Original, Sparse, and
Aligned Sparse, with class-specific performance ranging from 98.9% validity for
myocardial infarction (MI) to challenges with hypertrophy (HYP) detection
(13.2%). This approach supports near realtime generation (< 1 second) of
clinically valid counterfactuals and provides a foundation for interactive
explanation platforms. Our findings establish design principles for
physiologically-aware counterfactual explanations in AI-based diagnosis systems
and outline pathways toward user-controlled explanation interfaces for clinical
deployment.

</details>


### [139] [Bi-Level Decision-Focused Causal Learning for Large-Scale Marketing Optimization: Bridging Observational and Experimental Data](https://arxiv.org/abs/2510.19517)
*Shuli Zhang,Hao Zhou,Jiaqi Zheng,Guibin Jiang,Bing Cheng,Wei Lin,Guihai Chen*

Main category: cs.LG

TL;DR: 该文章提出了一种名为Bi-DFCL（双层决策聚焦因果学习）的新方法，旨在解决在线互联网平台营销中用户留存和平台收入优化问题中存在的预测与决策错位以及偏差-方差困境。Bi-DFCL通过结合实验数据和观察数据，实现了无偏的决策质量评估和最优的偏差-方差权衡，并在实际应用中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 传统的在线互联网平台营销策略在优化用户留存和平台收入时，采用的两阶段方法（机器学习预测后进行运筹优化决策）存在两个主要挑战：1. 预测-决策错位：机器学习模型仅关注预测准确性，未能考虑下游优化目标。2. 偏差-方差困境：观测数据存在偏差，而实验数据虽然无偏但稀缺且成本高。

Method: Bi-DFCL方法主要包括两个方面：1. 开发了一个使用实验数据、对运筹决策质量进行无偏估计的估计器。该估计器通过替代损失函数指导机器学习模型训练，连接离散优化的梯度。2. 建立了一个双层优化框架，通过隐式微分共同利用观测数据和实验数据。这种新颖的表述使得无偏的运筹估计器能够纠正来自有偏观测数据的学习方向，从而实现最优的偏差-方差权衡。

Result: Bi-DFCL在公共基准测试、工业营销数据集和大规模在线A/B测试中进行了广泛评估。结果表明，Bi-DFCL相对于最先进的方法取得了统计学上显著的改进。目前，Bi-DFCL已部署在全球最大的在线食品配送平台之一美团。

Conclusion: Bi-DFCL成功解决了在线平台营销中预测与决策错位以及偏差-方差困境，通过其独特的双层优化框架和无偏估计器，实现了对用户留存和平台收入的有效优化。该方法在实际应用中已被验证有效，并已部署在大型在线平台。

Abstract: Online Internet platforms require sophisticated marketing strategies to
optimize user retention and platform revenue -- a classical resource allocation
problem. Traditional solutions adopt a two-stage pipeline: machine learning
(ML) for predicting individual treatment effects to marketing actions, followed
by operations research (OR) optimization for decision-making. This paradigm
presents two fundamental technical challenges. First, the prediction-decision
misalignment: Conventional ML methods focus solely on prediction accuracy
without considering downstream optimization objectives, leading to improved
predictive metrics that fail to translate to better decisions. Second, the
bias-variance dilemma: Observational data suffers from multiple biases (e.g.,
selection bias, position bias), while experimental data (e.g., randomized
controlled trials), though unbiased, is typically scarce and costly --
resulting in high-variance estimates. We propose Bi-level Decision-Focused
Causal Learning (Bi-DFCL) that systematically addresses these challenges.
First, we develop an unbiased estimator of OR decision quality using
experimental data, which guides ML model training through surrogate loss
functions that bridge discrete optimization gradients. Second, we establish a
bi-level optimization framework that jointly leverages observational and
experimental data, solved via implicit differentiation. This novel formulation
enables our unbiased OR estimator to correct learning directions from biased
observational data, achieving optimal bias-variance tradeoff. Extensive
evaluations on public benchmarks, industrial marketing datasets, and
large-scale online A/B tests demonstrate the effectiveness of Bi-DFCL, showing
statistically significant improvements over state-of-the-art. Currently,
Bi-DFCL has been deployed at Meituan, one of the largest online food delivery
platforms in the world.

</details>


### [140] [Optimizing the Unknown: Black Box Bayesian Optimization with Energy-Based Model and Reinforcement Learning](https://arxiv.org/abs/2510.19530)
*Ruiyao Miao,Junren Xiao,Shiya Tsang,Hui Xiong,Yingnian Wu*

Main category: cs.LG

TL;DR: REBMBO: 一种结合了高斯过程和能量模型的贝叶斯优化方法，通过强化学习实现自适应多步前瞻，克服了传统BO方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的贝叶斯优化方法存在一步偏差，容易收敛到局部最优，在复杂或高维任务中表现不佳。

Method: REBMBO方法通过将高斯过程（GP）用于局部引导，能量模型（EBM）用于捕获全局结构信息，将贝叶斯优化迭代定义为马尔可夫决策过程（MDP），并使用近端策略优化（PPO）进行自适应多步前瞻。

Result: 在合成和真实世界的基准测试中，REBMBO表现出卓越的性能，并且在各种GP配置下都具有良好的适应性和鲁棒性。

Conclusion: REBMBO通过结合GP、EBM和强化学习，有效地解决了传统贝叶斯优化方法的局限性，实现了更好的优化性能。

Abstract: Existing Bayesian Optimization (BO) methods typically balance exploration and
exploitation to optimize costly objective functions. However, these methods
often suffer from a significant one-step bias, which may lead to convergence
towards local optima and poor performance in complex or high-dimensional tasks.
Recently, Black-Box Optimization (BBO) has achieved success across various
scientific and engineering domains, particularly when function evaluations are
costly and gradients are unavailable. Motivated by this, we propose the
Reinforced Energy-Based Model for Bayesian Optimization (REBMBO), which
integrates Gaussian Processes (GP) for local guidance with an Energy-Based
Model (EBM) to capture global structural information. Notably, we define each
Bayesian Optimization iteration as a Markov Decision Process (MDP) and use
Proximal Policy Optimization (PPO) for adaptive multi-step lookahead,
dynamically adjusting the depth and direction of exploration to effectively
overcome the limitations of traditional BO methods. We conduct extensive
experiments on synthetic and real-world benchmarks, confirming the superior
performance of REBMBO. Additional analyses across various GP configurations
further highlight its adaptability and robustness.

</details>


### [141] [The Confusing Instance Principle for Online Linear Quadratic Control](https://arxiv.org/abs/2510.19531)
*Waris Radji,Odalric-Ambrym Maillard*

Main category: cs.LG

TL;DR: 该文章提出了一种名为MED-LQ的新型控制策略，用于解决未知动态下的线性二次调节（LQR）控制问题，该策略基于Confusing Instance原则和MED算法家族，并通过在大型控制套件上的基准测试证明其竞争力。


<details>
  <summary>Details</summary>
Motivation: 传统的乐观面临不确定性（OFU）和汤普森采样（TS）等基于多臂老虎机（MABs）的方法在实践中存在局限性，促使作者寻求一种替代方案来解决具有未知动态的二次成本线性系统控制问题。

Method: 本文提出了一种基于Confusing Instance（CI）原则的替代方案，并利用LQR策略的结构以及敏感性和稳定性分析，开发了MED-LQ控制策略。该策略将CI和MED的原理扩展到小规模设置之外。

Result: MED-LQ在综合控制套件的基准测试中表现出竞争性能。

Conclusion: MED-LQ是一种基于Confusing Instance原理和MED算法家族的新型控制策略，在各种场景下均表现出良好的性能，并具有在大型马尔可夫决策过程（MDPs）中广泛应用的潜力。

Abstract: We revisit the problem of controlling linear systems with quadratic cost
under unknown dynamics with model-based reinforcement learning. Traditional
methods like Optimism in the Face of Uncertainty and Thompson Sampling, rooted
in multi-armed bandits (MABs), face practical limitations. In contrast, we
propose an alternative based on the Confusing Instance (CI) principle, which
underpins regret lower bounds in MABs and discrete Markov Decision Processes
(MDPs) and is central to the Minimum Empirical Divergence (MED) family of
algorithms, known for their asymptotic optimality in various settings. By
leveraging the structure of LQR policies along with sensitivity and stability
analysis, we develop MED-LQ. This novel control strategy extends the principles
of CI and MED beyond small-scale settings. Our benchmarks on a comprehensive
control suite demonstrate that MED-LQ achieves competitive performance in
various scenarios while highlighting its potential for broader applications in
large-scale MDPs.

</details>


### [142] [Insights into the Unknown: Federated Data Diversity Analysis on Molecular Data](https://arxiv.org/abs/2510.19535)
*Markus Bujotzek,Evelyn Trautmann,Calum Hand,Ian Hales*

Main category: cs.LG

TL;DR: 联邦学习（FL）为药物发现带来了希望，但由于其在估计数据集多样性、执行数据拆分和理解组合化学空间方面的局限性，阻碍了其在工业应用中的转化。本文研究了联邦聚类方法在解开和表示分布式分子数据方面的效果。作者评估了三种方法：Federated kMeans (Fed-kMeans)、结合了Fed-kMeans的Federated Principal Component Analysis (Fed-PCA+Fed-kMeans)和Federated Locality-Sensitive Hashing (Fed-LSH)，并将其与八个不同分子数据集的集中式对应方法进行比较。


<details>
  <summary>Details</summary>
Motivation: 目前，人工智能方法在制药药物发现领域的应用日益广泛，但由于其对公共数据集的依赖性，缺乏专有药物数据的规模和多样性，使得它们在工业应用中的转化受到限制。

Method: 本文研究了联邦聚类方法在解开和表示分布式分子数据方面的效果。作者评估了三种方法：Federated kMeans (Fed-kMeans)、结合了Fed-kMeans的Federated Principal Component Analysis (Fed-PCA+Fed-kMeans)和Federated Locality-Sensitive Hashing (Fed-LSH)，并将其与八个不同分子数据集的集中式对应方法进行比较。作者还引入了SF-ICF作为一种化学信息评估指标，并将其用于评估。

Result: 大规模基准测试与深入的可解释性分析相结合，表明了通过化学信息指标和客户端可解释性分析，将领域知识融入分子数据联邦多样性分析的重要性。

Conclusion: 联邦聚类方法在解开和表示分布式分子数据方面具有潜力，但需要结合领域知识和可解释性分析来提高其在药物发现领域的应用效果。本文引入的SF-ICF指标和可解释性分析方法为未来的研究提供了新的思路和可解释的思路。

Abstract: AI methods are increasingly shaping pharmaceutical drug discovery. However,
their translation to industrial applications remains limited due to their
reliance on public datasets, lacking scale and diversity of proprietary
pharmaceutical data. Federated learning (FL) offers a promising approach to
integrate private data into privacy-preserving, collaborative model training
across data silos. This federated data access complicates important
data-centric tasks such as estimating dataset diversity, performing informed
data splits, and understanding the structure of the combined chemical space. To
address this gap, we investigate how well federated clustering methods can
disentangle and represent distributed molecular data. We benchmark three
approaches, Federated kMeans (Fed-kMeans), Federated Principal Component
Analysis combined with Fed-kMeans (Fed-PCA+Fed-kMeans), and Federated
Locality-Sensitive Hashing (Fed-LSH), against their centralized counterparts on
eight diverse molecular datasets. Our evaluation utilizes both, standard
mathematical and a chemistry-informed evaluation metrics, SF-ICF, that we
introduce in this work. The large-scale benchmarking combined with an in-depth
explainability analysis shows the importance of incorporating domain knowledge
through chemistry-informed metrics, and on-client explainability analyses for
federated diversity analysis on molecular data.

</details>


### [143] [Learning and Simulating Building Evacuation Patterns for Enhanced Safety Design Using Generative Models](https://arxiv.org/abs/2510.19623)
*Jin Han,Zhe Zheng,Yi Gu,Jia-Rui Lin,Xin-Zheng Lu*

Main category: cs.LG

TL;DR: 该研究提出了DiffEvac，一种基于生成模型（GMs）的学习建筑疏散模式的新方法，旨在解决传统疏散模拟在早期设计阶段的建模挑战，并显著提高模拟效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统疏散模拟方法过度依赖于精细建模和大量参数，这使得它们难以在早期设计阶段的快速迭代过程中应用。

Method: 1. 建立了包含399种不同功能布局及其对应疏散热点图的数据集。2. 提出了分离的特征表示方法，用于嵌入布局和人员密度等物理特征，供生成模型使用。3. 提出了基于图像提示的扩散模型，从模拟疏散热点图中学习疏散模式。

Result: 与使用条件GANs和RGB表示的现有研究相比，DiffEvac在SSIM方面提高了37.6%，在PSNR方面提高了142%，并且速度快了16倍，将模拟时间缩短到2分钟。

Conclusion: DiffEvac显著增强了快速设计迭代和调整过程中的疏散模拟效率，并为智能建筑设计中的未来安全优化提供了新的见解和技术途径。该方法降低了建模负担，支持大规模假设情景探索，并易于与多目标设计工具结合。

Abstract: Evacuation simulation is essential for building safety design, ensuring
properly planned evacuation routes. However, traditional evacuation simulation
relies heavily on refined modeling with extensive parameters, making it
challenging to adopt such methods in a rapid iteration process in early design
stages. Thus, this study proposes DiffEvac, a novel method to learn building
evacuation patterns based on Generative Models (GMs), for efficient evacuation
simulation and enhanced safety design. Initially, a dataset of 399 diverse
functional layouts and corresponding evacuation heatmaps of buildings was
established. Then, a decoupled feature representation is proposed to embed
physical features like layouts and occupant density for GMs. Finally, a
diffusion model based on image prompts is proposed to learn evacuation patterns
from simulated evacuation heatmaps. Compared to existing research using
Conditional GANs with RGB representation, DiffEvac achieves up to a 37.6%
improvement in SSIM, 142% in PSNR, and delivers results 16 times faster,
thereby cutting simulation time to 2 minutes. Case studies further demonstrate
that the proposed method not only significantly enhances the rapid design
iteration and adjustment process with efficient evacuation simulation but also
offers new insights and technical pathways for future safety optimization in
intelligent building design. The research implication is that the approach
lowers the modeling burden, enables large-scale what-if exploration, and
facilitates coupling with multi-objective design tools.

</details>


### [144] [Latent Space Factorization in LoRA](https://arxiv.org/abs/2510.19640)
*Shashi Kumar,Yacouba Kaloga,John Mitros,Petr Motlicek,Ina Kodrasi*

Main category: cs.LG

TL;DR: FVAE-LoRA通过变分自编码器学习两个独立的潜在空间，一个用于任务相关特征，另一个用于残差信息，同时还有效地将任务相关信号与不必要的信息分离开来。这使得FVAE-LoRA在各种任务的性能和分布偏移下的鲁棒性方面优于传统的LoRA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA变体缺乏明确区分学习到的低秩子空间中任务相关信息的机制，这可能会限制下游性能。

Method: 我们提出了可分解变分自编码器LoRA（FVAE-LoRA），它利用变分自编码器（VAE）学习两个不同的潜在空间。我们新颖的证据下界公式明确促进了潜在空间之间的分解，将一个潜在空间专门用于任务显著特征，另一个用于残差信息。

Result: 在文本、音频和图像任务上进行的大量实验表明，FVAE-LoRA始终优于标准的LoRA。此外，虚假相关性评估证实FVAE-LoRA能更好地 H 隔离任务相关信号，从而在分布偏移下提高鲁棒性。

Conclusion: FVAE-LoRA通过学习独立且分解的潜在空间来有效地区分任务相关和残差信息，在多种任务中表现出优异的性能，并且在分布偏移下具有更高的鲁棒性。

Abstract: Low-rank adaptation (LoRA) is a widely used method for parameter-efficient
finetuning. However, existing LoRA variants lack mechanisms to explicitly
disambiguate task-relevant information within the learned low-rank subspace,
potentially limiting downstream performance. We propose Factorized Variational
Autoencoder LoRA (FVAE-LoRA), which leverages a VAE to learn two distinct
latent spaces. Our novel Evidence Lower Bound formulation explicitly promotes
factorization between the latent spaces, dedicating one latent space to
task-salient features and the other to residual information. Extensive
experiments on text, audio, and image tasks demonstrate that FVAE-LoRA
consistently outperforms standard LoRA. Moreover, spurious correlation
evaluations confirm that FVAE-LoRA better isolates task-relevant signals,
leading to improved robustness under distribution shifts. Our code is publicly
available at: https://github.com/idiap/FVAE-LoRA

</details>


### [145] [Fast Inference via Hierarchical Speculative Decoding](https://arxiv.org/abs/2510.19705)
*Amir Globerson,Haim Kaplan,Yishay Mansour,Clara Mohri,Tal Schuster*

Main category: cs.LG

TL;DR: HSD通过将多个草稿模型堆叠成一个层次结构，实现了比单一草稿模型基线快1.2倍的速度，从而降低了Transformer语言模型的推理延迟。


<details>
  <summary>Details</summary>
Motivation: Transformer语言模型的自回归文本生成导致推理延迟与生成的token数量成正比，传统的推测解码方法通过小草稿模型验证token来降低延迟，但草稿模型的选择存在速度和准确性之间的权衡。

Method: 提出分层推测解码（HSD）算法，将速度和准确性各异的多个草稿模型堆叠成一个层次结构，每个模型提出token，并由下一个更大的模型进行验证，最终由目标模型进行验证。推导了任何此类层次结构的预期延迟表达式，并证明了选择延迟最优的层次结构可以在多项式时间内完成。

Result: HSD方法比现有的单一草稿模型基线提速高达1.2倍。

Conclusion: HSD算法通过有效地利用多个草稿模型，显著降低了Transformer语言模型的生成延迟，超越了以往的技术。

Abstract: Transformer language models generate text autoregressively, making inference
latency proportional to the number of tokens generated. Speculative decoding
reduces this latency without sacrificing output quality, by leveraging a small
draft model to propose tokens that the larger target model verifies in
parallel. In practice, however, there may exist a set of potential draft
models- ranging from faster but less inaccurate, to slower yet more reliable.
We introduce Hierarchical Speculative Decoding (HSD), an algorithm that stacks
these draft models into a hierarchy, where each model proposes tokens, and the
next larger model verifies them in a single forward pass, until finally the
target model verifies tokens. We derive an expression for the expected latency
of any such hierarchy and show that selecting the latency-optimal hierarchy can
be done in polynomial time. Empirically, HSD gives up to 1.2x speed-up over the
best single-draft baseline, demonstrating the practicality of our algorithm in
reducing generation latency beyond previous techniques.

</details>


### [146] [Enabling Granular Subgroup Level Model Evaluations by Generating Synthetic Medical Time Series](https://arxiv.org/abs/2510.19728)
*Mahmoud Ibrahim,Bart Elen,Chang Sun,Gökhan Ertaylan,Michel Dumontier*

Main category: cs.LG

TL;DR: 该论文提出了一个利用合成ICU时间序列数据训练和评估预测模型的新框架，旨在解决现有方法在处理长尾人群、次要预测任务和亚组分析方面的不足。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有合成数据生成器在处理长尾人群（即“尾部”人群的次要预测任务）和亚组分析方面的不足，作者们提出了一种改进的合成数据生成框架，以实现更可靠和值得信赖的模型评估。

Method: 该论文在现有扩散模型和VAE模型（TimeDiff、HealthGen、TimeAutoDiff）的基础上，引入了名为“Enhanced TimeAutoDiff”的改进模型。该模型通过增加分布对齐惩罚来增强潜在扩散目标。作者们在MIMIC-III和eICU数据集上，针对24小时死亡率和二元住院时长预测任务对所有模型进行了广泛的基准测试。

Result: 实验结果表明，Enhanced TimeAutoDiff将真实数据与合成数据评估之间的差距（即“TRTS差距”）减少了70%以上，实现了ΔTRTS ≤ 0.014 AUROC，同时保持了训练效用（ΔTSTR ≈ 0.01）。对于32个交叉亚组，大型合成队列将亚组层面的AUROC估计误差相对于小型真实测试集减少了50%，并且在72%至84%的亚组中表现优于真实测试集。

Conclusion: 这项工作为重症监护中值得信赖的、细粒度模型评估提供了实用且保护隐私的路线图。它使得对不同患者群体进行稳健可靠的性能分析成为可能，而无需暴露敏感的电子健康记录数据，从而提升了医疗AI的整体可信度。

Abstract: We present a novel framework for leveraging synthetic ICU time-series data
not only to train but also to rigorously and trustworthily evaluate predictive
models, both at the population level and within fine-grained demographic
subgroups. Building on prior diffusion and VAE-based generators (TimeDiff,
HealthGen, TimeAutoDiff), we introduce \textit{Enhanced TimeAutoDiff}, which
augments the latent diffusion objective with distribution-alignment penalties.
We extensively benchmark all models on MIMIC-III and eICU, on 24-hour mortality
and binary length-of-stay tasks. Our results show that Enhanced TimeAutoDiff
reduces the gap between real-on-synthetic and real-on-real evaluation (``TRTS
gap'') by over 70\%, achieving $\Delta_{TRTS} \leq 0.014$ AUROC, while
preserving training utility ($\Delta_{TSTR} \approx 0.01$). Crucially, for 32
intersectional subgroups, large synthetic cohorts cut subgroup-level AUROC
estimation error by up to 50\% relative to small real test sets, and outperform
them in 72--84\% of subgroups. This work provides a practical,
privacy-preserving roadmap for trustworthy, granular model evaluation in
critical care, enabling robust and reliable performance analysis across diverse
patient populations without exposing sensitive EHR data, contributing to the
overall trustworthiness of Medical AI.

</details>


### [147] [SEMPO: Lightweight Foundation Models for Time Series Forecasting](https://arxiv.org/abs/2510.19710)
*Hui He,Kun Yi,Yuanchi Ma,Qi Zhang,Zhendong Niu,Guansong Pang*

Main category: cs.LG

TL;DR: 本文提出了SEMPO，这是一种轻量级基础模型，它仅需在相对小规模的数据上进行预训练，即可在时间序列预测方面表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型规模庞大，需要大量预训练数据，限制了其在资源受限环境中的部署。本文旨在解决通用性和经济性之间的矛盾。

Method: SEMPO包含两个关键模块：1）能量感知频谱分解模块，通过建模高能和低能但信息丰富的频率信号，显著提高预训练数据利用率；2）Mixture-of-PrOmpts使能的Transformer，通过学习特定数据集的提示和自适应路由时间序列tokens到基于提示的专家，实现参数高效的模型适应。

Result: SEMPO显著减少了预训练数据规模和模型大小，在零样本和少样本预测场景中均取得了优于现有技术的性能。

Conclusion: SEMPO通过创新的模块设计，成功解决了时间序列基础模型在资源受限环境中的部署难题，实现了轻量化、高效能和强泛化能力的统一。

Abstract: The recent boom of large pre-trained models witnesses remarkable success in
developing foundation models (FMs) for time series forecasting. Despite
impressive performance across diverse downstream forecasting tasks, existing
time series FMs possess massive network architectures and require substantial
pre-training on large-scale datasets, which significantly hinders their
deployment in resource-constrained environments. In response to this growing
tension between versatility and affordability, we propose SEMPO, a novel
lightweight foundation model that requires pretraining on relatively
small-scale data, yet exhibits strong general time series forecasting.
Concretely, SEMPO comprises two key modules: 1) energy-aware SpEctral
decomposition module, that substantially improves the utilization of
pre-training data by modeling not only the high-energy frequency signals but
also the low-energy yet informative frequency signals that are ignored in
current methods; and 2) Mixture-of-PrOmpts enabled Transformer, that learns
heterogeneous temporal patterns through small dataset-specific prompts and
adaptively routes time series tokens to prompt-based experts for
parameter-efficient model adaptation across different datasets and domains.
Equipped with these modules, SEMPO significantly reduces both pre-training data
scale and model size, while achieving strong generalization. Extensive
experiments on two large-scale benchmarks covering 16 datasets demonstrate the
superior performance of SEMPO in both zero-shot and few-shot forecasting
scenarios compared with state-of-the-art methods. Code and data are available
at https://github.com/mala-lab/SEMPO.

</details>


### [148] [BATIS: Bayesian Approaches for Targeted Improvement of Species Distribution Models](https://arxiv.org/abs/2510.19749)
*Catherine Villeneuve,Benjamin Akera,Mélisande Teng,David Rolnick*

Main category: cs.LG

TL;DR: 这篇论文介绍了BATIS，一个新颖实用的框架，用于解决物种分布模型（SDMs）中数据空间偏差的问题，通过贝叶斯深度学习方法迭代更新先验预测，从而在数据稀缺地区大大提高SDMs的可靠性。


<details>
  <summary>Details</summary>
Motivation: 物种分布模型（SDMs）在监测和应对生物多样性变化方面被广泛应用，但目前的深度学习SDMs在处理复杂异构数据集时，其有效性仍然受到数据中空间偏差的限制。

Method: 本文从贝叶斯视角重新审视了深度SDMs，并引入了BATIS框架，该框架通过有限的观测数据迭代更新先验预测。模型需要有效捕捉任意不确定性和认知不确定性，以结合细粒度的局部洞察和更广泛的生态模式。作者在一个包含来自eBird平台的公民科学观测数据的新型数据集上，对大量不确定性量化方法进行了基准测试。

Result: 实证研究表明，贝叶斯深度学习方法可以大大提高数据稀缺地区SDMs的可靠性。

Conclusion: BATIS框架通过贝叶斯深度学习方法，在物种分布模型中有效解决了数据稀缺问题，显著提升了模型在数据稀缺区域的预测可靠性，对生态理解和保护工作具有重要意义。

Abstract: Species distribution models (SDMs), which aim to predict species occurrence
based on environmental variables, are widely used to monitor and respond to
biodiversity change. Recent deep learning advances for SDMs have been shown to
perform well on complex and heterogeneous datasets, but their effectiveness
remains limited by spatial biases in the data. In this paper, we revisit deep
SDMs from a Bayesian perspective and introduce BATIS, a novel and practical
framework wherein prior predictions are updated iteratively using limited
observational data. Models must appropriately capture both aleatoric and
epistemic uncertainty to effectively combine fine-grained local insights with
broader ecological patterns. We benchmark an extensive set of uncertainty
quantification approaches on a novel dataset including citizen science
observations from the eBird platform. Our empirical study shows how Bayesian
deep learning approaches can greatly improve the reliability of SDMs in
data-scarce locations, which can contribute to ecological understanding and
conservation efforts.

</details>


### [149] [When Do Transformers Learn Heuristics for Graph Connectivity?](https://arxiv.org/abs/2510.19753)
*Qilin Ye,Deqing Fu,Robin Jia,Vatsal Sharan*

Main category: cs.LG

TL;DR: 本文分析了Transformer模型在学习通用算法时，倾向于依赖脆弱的启发式方法而非通用算法的问题。


<details>
  <summary>Details</summary>
Motivation: 解释Transformer模型在学习通用算法时，为何会依赖脆弱的启发式方法，而不是可泛化的算法。

Method: 通过对解耦Transformer架构的理论分析和实证研究，证明了L层模型解决图直径可达3^L的能力，并实现了等效于计算邻接矩阵幂的算法。分析了训练动态，揭示了学习策略取决于大多数训练实例是否在模型容量范围内。

Result: 在模型容量范围内的图（直径≤3^L）能够促使模型学习到正确的算法解，而超出容量的图则会导致模型学习到基于节点度的简单启发式方法。经验证，将训练数据限制在模型容量内，可以使标准Transformer和解耦Transformer都学会精确算法，而非基于度的启发式方法。

Conclusion: Transformer模型在学习算法时，其能力受限于模型层数决定的图直径。若训练数据超出此容量，模型更倾向于学习启发式策略。将训练数据限制在模型容量内，有助于模型学习到通用算法。

Abstract: Transformers often fail to learn generalizable algorithms, instead relying on
brittle heuristics. Using graph connectivity as a testbed, we explain this
phenomenon both theoretically and empirically. We consider a simplified
Transformer architecture, the disentangled Transformer, and prove that an
$L$-layer model has capacity to solve for graphs with diameters up to exactly
$3^L$, implementing an algorithm equivalent to computing powers of the
adjacency matrix. We analyze the training-dynamics, and show that the learned
strategy hinges on whether most training instances are within this model
capacity. Within-capacity graphs (diameter $\leq 3^L$) drive the learning of a
correct algorithmic solution while beyond-capacity graphs drive the learning of
a simple heuristic based on node degrees. Finally, we empirically demonstrate
that restricting training data within a model's capacity leads to both standard
and disentangled transformers learning the exact algorithm rather than the
degree-based heuristic.

</details>


### [150] [Semantic World Models](https://arxiv.org/abs/2510.19818)
*Jacob Berg,Chuning Zhu,Yanda Bao,Ishan Durugkar,Abhishek Gupta*

Main category: cs.LG

TL;DR: 本文提出了一种语义世界模型（SWM），它将世界模型构建为对未来帧中语义信息的视觉问答问题，解决了传统世界模型中像素重建与规划目标不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人控制世界模型通过预测未来帧来规划，但像素预测的准确性与规划决策的有效性之间常常存在 Mismatch。

Method: 将世界模型构建为视觉问答问题，专注于预测任务相关的语义信息而不是重建像素。通过有监督的微调，将预训练的视觉语言模型训练成“语义”世界模型，使用图像-动作-文本数据。

Result: 语义世界模型（SWM）在开放式机器人任务的策略改进方面表现出色，与基于重建的动作条件世界模型相比，泛化能力显著提高。

Conclusion: 语义世界模型提供了一种利用视觉语言模型进行有效机器人规划的新范式，通过关注任务相关的语义信息，显著提高了泛化能力和鲁棒性。

Abstract: Planning with world models offers a powerful paradigm for robotic control.
Conventional approaches train a model to predict future frames conditioned on
current frames and actions, which can then be used for planning. However, the
objective of predicting future pixels is often at odds with the actual planning
objective; strong pixel reconstruction does not always correlate with good
planning decisions. This paper posits that instead of reconstructing future
frames as pixels, world models only need to predict task-relevant semantic
information about the future. For such prediction the paper poses world
modeling as a visual question answering problem about semantic information in
future frames. This perspective allows world modeling to be approached with the
same tools underlying vision language models. Thus vision language models can
be trained as "semantic" world models through a supervised finetuning process
on image-action-text data, enabling planning for decision-making while
inheriting many of the generalization and robustness properties from the
pretrained vision-language models. The paper demonstrates how such a semantic
world model can be used for policy improvement on open-ended robotics tasks,
leading to significant generalization improvements over typical paradigms of
reconstruction-based action-conditional world modeling. Website available at
https://weirdlabuw.github.io/swm.

</details>


### [151] [CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees](https://arxiv.org/abs/2510.19754)
*Aman Bilkhoo,Milad Kazemi,Nicola Paoletti,Mehran Hosseini*

Main category: cs.LG

TL;DR: CONFEX是一种新的反事实解释方法，它结合了共形预测和混合整数线性规划，能够生成具有预测不确定性和最优性保证的、对不确定性敏感的反事实解释。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释方法往往忽略不确定性，或者在结合不确定性时缺乏有原则的机制和正式的保证，导致在预测不确定性高的区域解释可能具有误导性或不适用。

Method: CONFEX使用共形预测（CP）和混合整数线性规划（MILP）来生成对不确定性敏感的反事实解释。它开发了一种新颖的局部CP程序，通过利用输入空间的离线基于树的划分，实现了高效的MILP编码，从而提供局部覆盖保证。

Result: CONFEX在预测不确定性和最优性方面都提供了严格的保证。通过在各种基准和指标上与最先进的方法进行评估，CONFEX证明了其不确定性感知方法能够产生稳健且合理的解释。

Conclusion: CONFEX通过引入不确定性感知机制和严格的保证，提高了反事实解释的可靠性和准确性，是反事实解释领域的一个重要进展。

Abstract: Counterfactual explanations (CFXs) provide human-understandable
justifications for model predictions, enabling actionable recourse and
enhancing interpretability. To be reliable, CFXs must avoid regions of high
predictive uncertainty, where explanations may be misleading or inapplicable.
However, existing methods often neglect uncertainty or lack principled
mechanisms for incorporating it with formal guarantees. We propose CONFEX, a
novel method for generating uncertainty-aware counterfactual explanations using
Conformal Prediction (CP) and Mixed-Integer Linear Programming (MILP). CONFEX
explanations are designed to provide local coverage guarantees, addressing the
issue that CFX generation violates exchangeability. To do so, we develop a
novel localised CP procedure that enjoys an efficient MILP encoding by
leveraging an offline tree-based partitioning of the input space. This way,
CONFEX generates CFXs with rigorous guarantees on both predictive uncertainty
and optimality. We evaluate CONFEX against state-of-the-art methods across
diverse benchmarks and metrics, demonstrating that our uncertainty-aware
approach yields robust and plausible explanations.

</details>


### [152] [The Tail Tells All: Estimating Model-Level Membership Inference Vulnerability Without Reference Models](https://arxiv.org/abs/2510.19773)
*Euodia Dodd,Nataša Krčo,Igor Shilov,Yves-Alexandre de Montjoye*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的方法，用于在不需要参考模型的情况下，评估AI模型对抗成员推断攻击的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有的成员推断攻击（MIAs）方法需要训练大量的参考模型，计算成本高昂，限制了它们的实用性。

Method: 本文利用了损失分布在训练后变得不对称和重尾的特性。观察到大多数受MIAs风险影响的点已经从分布的尾部（高损失区域）移动到头部（低损失区域）。基于这一发现，作者提出了一种仅从训练和测试分布中估计模型级脆弱性的方法：通过高损失区域中异常值的缺失来预测风险。

Result: 通过广泛的架构和数据集评估，本文方法（简单损失攻击的TNR）能准确估计模型对SOTA MIA攻击（LiRA）的模型级脆弱性。同时，该方法优于低成本攻击（如RMIA）和其他分布差异度量。此外，将非线性函数用于风险评估在评估大型语言模型的风险方面也显示出潜力。

Conclusion: 本文提出了一种有效且计算成本低的方法来评估AI模型对成员推断攻击的脆弱性，该方法无需参考模型，并能准确预测SOTA攻击的风险，在实际应用中具有广阔前景，尤其在大型语言模型中具有应用前景。

Abstract: Membership inference attacks (MIAs) have emerged as the standard tool for
evaluating the privacy risks of AI models. However, state-of-the-art attacks
require training numerous, often computationally expensive, reference models,
limiting their practicality. We present a novel approach for estimating
model-level vulnerability, the TPR at low FPR, to membership inference attacks
without requiring reference models. Empirical analysis shows loss distributions
to be asymmetric and heavy-tailed and suggests that most points at risk from
MIAs have moved from the tail (high-loss region) to the head (low-loss region)
of the distribution after training. We leverage this insight to propose a
method to estimate model-level vulnerability from the training and testing
distribution alone: using the absence of outliers from the high-loss region as
a predictor of the risk. We evaluate our method, the TNR of a simple loss
attack, across a wide range of architectures and datasets and show it to
accurately estimate model-level vulnerability to the SOTA MIA attack (LiRA). We
also show our method to outperform both low-cost (few reference models) attacks
such as RMIA and other measures of distribution difference. We finally evaluate
the use of non-linear functions to evaluate risk and show the approach to be
promising to evaluate the risk in large-language models.

</details>


### [153] [GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters](https://arxiv.org/abs/2510.19778)
*Anand Choudhary,Yasser Sulaıman,Lukas Mauch,Ghouthi Boukli Hacene,Fabien Cardinaux,Antoine Bosselut*

Main category: cs.LG

TL;DR: GaLLoP是一种新颖的稀疏微调技术，它通过选择性地微调具有最大梯度幅度和最小预训练幅度的模型参数，从而在保持模型预训练知识的同时有效适应下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏微调技术在将大型语言模型适应下游任务时，其效果高度依赖于对参数子集的优化选择。

Method: GaLLoP算法通过梯度与参数幅度的双重考量来精选微调参数：优先微调那些对下游任务具有最大梯度幅度，同时其预训练参数幅度又最小的参数。

Result: 在LLaMA3 8B和Gemma 2B模型上的实验表明，GaLLoP在分布内和分布外性能上均优于或媲美LoRA、DoRA和SAFT等主流高效参数微调技术。

Conclusion: GaLLoP通过优先保持重要的预训练参数不变，有效减轻了灾难性遗忘和任务数据记忆化问题，从而稳定了模型性能并增强了泛化能力。

Abstract: Sparse fine-tuning techniques adapt LLMs to downstream tasks by only tuning a
sparse subset of model parameters. However, the effectiveness of sparse
adaptation depends on optimally selecting the model parameters to be
fine-tuned. In this work, we introduce a novel sparse fine-tuning technique
named GaLLoP: Gradient-based Sparse Learning on Low-Magnitude Parameters, which
fine-tunes only those model parameters which have the largest gradient
magnitudes on downstream tasks and the smallest pre-trained magnitudes,
intuitively prioritizing parameters that are highly task-relevant, but
minimally disruptive to pre-trained knowledge. Our experimentation with LLaMA3
8B and Gemma 2B as base models shows that GaLLoP consistently improves or
matches the in-distribution as well as out-of-distribution performance obtained
via the usage of other leading parameter-efficient fine-tuning techniques,
including LoRA, DoRA, and SAFT. Our analysis demonstrates that GaLLoP mitigates
catastrophic forgetting and memorization of task data, as important pre-trained
parameters remain unchanged, and stabilizes performance relative to other
fine-tuning techniques, robustly generalizing across most random seeds.

</details>


### [154] [Blackbox Model Provenance via Palimpsestic Membership Inference](https://arxiv.org/abs/2510.19796)
*Rohith Kuditipudi,Jing Huang,Sally Zhu,Diyi Yang,Christopher Potts,Percy Liang*

Main category: cs.LG

TL;DR: 本文探讨了在一个开放权重语言模型情境中，Alice如何证明Bob正在使用她的模型，无论是通过查询还是纯文本观察。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLM）的训练和部署中，模型的衍生和使用权属认定是一个重要问题。文章旨在解决开源模型所有者（Alice）如何证明他人（Bob）使用了她的模型这一问题。

Method: 本文将模型归属问题定义为一个独立性测试问题。研究利用了语言模型中“回文记忆”现象，即模型更有可能记住训练后期出现的数据。通过统计测试来捕获Bob的模型或文本与Alice模型训练数据排序之间的相关性。在查询设置中，通过提示词直接估算Bob模型对Alice训练数据和顺序的似然度。在观察设置中，尝试了两种方法：1) 估算Bob文本与Alice训练数据片段重叠的似然度；2) 估算Bob文本相对于Alice模型不同版本的似然度，这些版本通过重复训练的最后阶段并重新洗牌数据获得。

Result: 在查询设置中，通过对1B到12B参数的Pythia和OLMo基础模型的40多个微调模型进行测试，发现Bob模型对Alice训练数据顺序的似然度与训练数据顺序之间存在显著相关性，在绝大多数情况下p值达到1e-8。在观察设置中，第二种方法（估算Bob文本与Alice模型不同版本的似然度）能够可靠地区分Bob的文本，只需几百个tokens。第一种方法（估算Bob文本与Alice训练数据片段重叠的似然度）不需要重新训练，但需要更多的tokens（数十万）才能达到高区分度。

Conclusion: 本文提出了一种利用语言模型“回文记忆”特性来证明模型归属的有效方法，即通过分析Bob模型或其生成文本与Alice训练数据排序的统计相关性。

Abstract: Suppose Alice trains an open-weight language model and Bob uses a blackbox
derivative of Alice's model to produce text. Can Alice prove that Bob is using
her model, either by querying Bob's derivative model (query setting) or from
the text alone (observational setting)? We formulate this question as an
independence testing problem--in which the null hypothesis is that Bob's model
or text is independent of Alice's randomized training run--and investigate it
through the lens of palimpsestic memorization in language models: models are
more likely to memorize data seen later in training, so we can test whether Bob
is using Alice's model using test statistics that capture correlation between
Bob's model or text and the ordering of training examples in Alice's training
run. If Alice has randomly shuffled her training data, then any significant
correlation amounts to exactly quantifiable statistical evidence against the
null hypothesis, regardless of the composition of Alice's training data. In the
query setting, we directly estimate (via prompting) the likelihood Bob's model
gives to Alice's training examples and order; we correlate the likelihoods of
over 40 fine-tunes of various Pythia and OLMo base models ranging from 1B to
12B parameters with the base model's training data order, achieving a p-value
on the order of at most 1e-8 in all but six cases. In the observational
setting, we try two approaches based on estimating 1) the likelihood of Bob's
text overlapping with spans of Alice's training examples and 2) the likelihood
of Bob's text with respect to different versions of Alice's model we obtain by
repeating the last phase (e.g., 1%) of her training run on reshuffled data. The
second approach can reliably distinguish Bob's text from as little as a few
hundred tokens; the first does not involve any retraining but requires many
more tokens (several hundred thousand) to achieve high power.

</details>


### [155] [Transformers are almost optimal metalearners for linear classification](https://arxiv.org/abs/2510.19797)
*Roey Magen,Gal Vardi*

Main category: cs.LG

TL;DR: 本文从理论角度分析了Transformer在元学习方面的能力，表明其在特定条件下可以作为近乎最优的元学习器。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer的上下文学习（ICL）能力是否能使其在不进行额外训练的情况下，仅用少量上下文示例即可适应新任务，并作为元学习器。现有的分析大多未在正式的元学习设置下进行。

Method: 本文对一个简化的Transformer架构进行了理论分析，该架构通过梯度下降进行训练，并专门研究了其在线性分类设置下的元学习能力。研究考虑了一系列任务，其中每个任务对应一个类条件高斯混合模型，其均值向量位于共享的k维子空间内。

Result: 经过训练后，Transformer能够仅使用$O(k / R^4)$个上下文示例泛化到新任务，其中R是测试时的信号强度。这一性能几乎与知道共享子空间的最优学习器相匹配，并且显著优于仅使用上下文数据的学习器（后者需要$\\Omega(d / R^4)$个示例）。重要的是，实现此结果所需的训练任务数量和每个任务的示例数量均独立于环境维度d。

Conclusion: Transformer在特定线性分类设置下，通过梯度下降训练，可以作为近乎最优的元学习器，其泛化能力优于仅依赖上下文数据的学习器，并且在效率上接近知道任务结构的最优学习器。

Abstract: Transformers have demonstrated impressive in-context learning (ICL)
capabilities, raising the question of whether they can serve as metalearners
that adapt to new tasks using only a small number of in-context examples,
without any further training. While recent theoretical work has studied
transformers' ability to perform ICL, most of these analyses do not address the
formal metalearning setting, where the objective is to solve a collection of
related tasks more efficiently than would be possible by solving each task
individually. In this paper, we provide the first theoretical analysis showing
that a simplified transformer architecture trained via gradient descent can act
as a near-optimal metalearner in a linear classification setting. We consider a
natural family of tasks where each task corresponds to a class-conditional
Gaussian mixture model, with the mean vectors lying in a shared $k$-dimensional
subspace of $R^d$. After training on a sufficient number of such tasks, we show
that the transformer can generalize to a new task using only $O(k / R^4)$
in-context examples, where $R$ denotes the signal strength at test time. This
performance (almost) matches that of an optimal learner that knows exactly the
shared subspace and significantly outperforms any learner that only has access
to the in-context data, which requires $\Omega(d / R^4)$ examples to
generalize. Importantly, our bounds on the number of training tasks and
examples per task needed to achieve this result are independent of the ambient
dimension $d$.

</details>


### [156] [The Feasibility of Training Sovereign Language Models in the Global South: A Study of Brazil and Mexico](https://arxiv.org/abs/2510.19801)
*Sandra Malagon,Monica A. Ulloa Ruiz,Tatiana Elizabeth Sandoval Plaza,Gabriel Rafael Rosario Bolívar,Valentina García Mesa,Ivanna Alvarado Morales*

Main category: cs.LG

TL;DR: 本文分析了在硬件受限的发展中国家训练大型语言模型的经济和技术可行性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练计算需求激增，加剧了高能力司法管辖区与全球南方国家之间的结构性不对称，因此研究在硬件、能源和财政受限条件下，巴西和墨西哥在主权范围内训练大型语言模型的技术和财政可行性。

Method: 采用双轴设计，改变加速器代次（NVIDIA H100 vs. A100）和训练时长（90天vs. 150天），估算了训练一个10万亿token模型的计算需求、能源消耗、资本支出和监管兼容性。

Result: 所有配置均低于出口管制和电力基础设施上限，但财政可行性取决于硬件效率。H100方案的总成本为800-1400万美元，而A100方案由于更高的能源和硬件需求，需要1900-3200万美元。

Conclusion: 将训练时间延长应作为缓解硬件限制的政策手段，使中等收入国家能够在不与全球前沿竞争的情况下，生产可用、可审计和本地化的模型，从而建立可持续且具有战略 sufficiency 的人工智能能力。

Abstract: The rapid escalation of computational requirements for training large-scale
language models has reinforced structural asymmetries between high-capacity
jurisdictions and countries in the Global South. This paper examines the
technical and fiscal feasibility of sovereign-scale language model training in
Brazil and Mexico under conditions of constrained hardware access, energy
availability, and fiscal ceilings. Using a dual-axis design that varies
accelerator generation (NVIDIA H100 vs. A100) and training duration (90 vs. 150
days), we estimate compute demand, energy consumption, capital expenditures,
and regulatory compatibility for the training of a 10-trillion-token model. Our
findings show that while all configurations remain below export-control and
electrical infrastructure thresholds, fiscal viability is determined by
hardware efficiency. H100-based scenarios achieve training feasibility at a
total cost of 8-14 million USD, while A100 deployments require 19-32 million
USD due to higher energy and hardware demand. We argue that extending training
timelines should be treated as a policy lever to mitigate hardware constraints,
enabling the production of usable, auditable, and locally aligned models
without competing at the global frontier. This study contributes to the
discourse on AI compute governance and technological sovereignty by
highlighting context-sensitive strategies that allow middle-income countries to
establish sustainable and strategically sufficient AI capabilities.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [157] [Autobidding Arena: unified evaluation of the classical and RL-based autobidding algorithms](https://arxiv.org/abs/2510.19357)
*Andrey Pudovikov,Alexandra Khirianova,Ekaterina Solodneva,Aleksandr Katrutsa,Egor Samosvat,Yuriy Dorn*

Main category: cs.GT

TL;DR: 这篇论文提出了一种标准化和透明的评估协议，用于比较经典的自动出价算法和基于强化学习的自动出价算法，并通过多个指标评估了它们的性能。


<details>
  <summary>Details</summary>
Motivation: 自动出价算法在电商公司的广告收入生成中起着至关重要的作用。为了使竞价过程可扩展到数千次拍卖，业界正在积极开发自动出价算法。因此，公平且可重现地评估自动出价算法是一个重要问题。

Method: 本研究提出了一种标准化和透明的评估协议，用于比较经典的自动出价算法和基于强化学习（RL）的自动出价算法。我们考虑了不同类别中最有效的自动出价算法，例如基于控制器、RL、最优公式等，并在竞价环境中对它们进行了基准测试。我们利用业界最新开发的开源环境，该环境准确模拟了竞价过程。研究选择了能说明自动出价算法性能、相应成本并跟踪预算进度的评估指标。

Result: 我们的工作展示了所考虑的自动出价算法最有前景的用例，强调了它们令人惊讶的缺点，并根据多个指标评估了它们。结果表明，这种指标选择使研究结果适用于自动出价有效的广泛平台。

Conclusion: 本研究提出的比较结果有助于从业者从不同角度评估候选自动出价算法，并选择符合其公司目标的高效算法。

Abstract: Advertisement auctions play a crucial role in revenue generation for
e-commerce companies. To make the bidding procedure scalable to thousands of
auctions, the automatic bidding (autobidding) algorithms are actively developed
in the industry. Therefore, the fair and reproducible evaluation of autobidding
algorithms is an important problem. We present a standardized and transparent
evaluation protocol for comparing classical and reinforcement learning (RL)
autobidding algorithms. We consider the most efficient autobidding algorithms
from different classes, e.g., ones based on the controllers, RL, optimal
formulas, etc., and benchmark them in the bidding environment. We utilize the
most recent open-source environment developed in the industry, which accurately
emulates the bidding process. Our work demonstrates the most promising use
cases for the considered autobidding algorithms, highlights their surprising
drawbacks, and evaluates them according to multiple metrics. We select the
evaluation metrics that illustrate the performance of the autobidding
algorithms, the corresponding costs, and track the budget pacing. Such a choice
of metrics makes our results applicable to the broad range of platforms where
autobidding is effective. The presented comparison results help practitioners
to evaluate the candidate autobidding algorithms from different perspectives
and select ones that are efficient according to their companies' targets.

</details>


### [158] [Comparing Uniform Price and Discriminatory Multi-Unit Auctions through Regret Minimization](https://arxiv.org/abs/2510.19591)
*Marius Potfer,Vianney Perchet*

Main category: cs.GT

TL;DR: 这篇论文比较了重复多单位拍卖中的两种主要形式：统一价格拍卖和歧视性拍卖，并分析了单一竞标者在随机对抗环境中学习出价的难度和效率。


<details>
  <summary>Details</summary>
Motivation: 论文旨在比较统一价格拍卖和歧视性拍卖这两种在电力市场和国库券拍卖中常见的机制，重点关注单一竞标者在学习出价过程中的表现。

Method: 通过分析在完全信息反馈和赌博机反馈两种情况下，两种拍卖形式的遗憾增长率来表征学习难度。此外，还对其他参与者对称且具有单位需求时的特定拍卖情况进行了分析。

Result: 在完全信息反馈和赌博机反馈下，两种拍卖形式的遗憾增长率相似，分别为$\tilde{\Theta} ( \sqrt{T} )$和$\tilde{\Theta} ( T^{2/3} )$。然而，在某些情况下，统一价格拍卖的学习速度可能更快，遗憾增长率为$\tilde{\Theta} ( \sqrt{T} )$，而歧视性拍卖仍保持在$\tilde{\Theta} ( T^{2/3} )$。在其他参与者对称且单位需求的情况下，也出现了类似的遗憾增长率差异。

Conclusion: 统一价格拍卖和歧视性拍卖在学习难度和效率上存在结构性差异。尽管在最坏情况下的遗憾增长率相似，但在特定场景下，统一价格拍卖可能展现出更快的学习速度和更低的遗憾。

Abstract: Repeated multi-unit auctions, where a seller allocates multiple identical
items over many rounds, are common mechanisms in electricity markets and
treasury auctions. We compare the two predominant formats: uniform-price and
discriminatory auctions, focusing on the perspective of a single bidder
learning to bid against stochastic adversaries. We characterize the learning
difficulty in each format, showing that the regret scales similarly for both
auction formats under both full-information and bandit feedback, as
$\tilde{\Theta} ( \sqrt{T} )$ and $\tilde{\Theta} ( T^{2/3} )$, respectively.
However, analysis beyond worst-case regret reveals structural differences:
uniform-price auctions may admit faster learning rates, with regret scaling as
$\tilde{\Theta} ( \sqrt{T} )$ in settings where discriminatory auctions remain
at $\tilde{\Theta} ( T^{2/3} )$. Finally, we provide a specific analysis for
auctions in which the other participants are symmetric and have unit-demand,
and show that in these instances, a similar regret rate separation appears.

</details>


### [159] [On Minimal Achievable Quotas in Multiwinner Voting](https://arxiv.org/abs/2510.19620)
*Patrick Becker,Fabian Frank*

Main category: cs.GT

TL;DR: 本文探讨了Approval-based多胜选投票中，比例性概念（如JR和EJR）对固定配额的依赖性，并引入了一种新的、依赖于实例的配额方法来解决其缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有的批准式多胜选投票中的比例性公理（JR和EJR）依赖于固定的配额（如Hare或Droop），其中Droop配额是最小的，能够保证在所有情况下都存在。这促使我们探索超越固定配额范式的方法。

Method: 我们引入了依赖于实例的配额比例概念，并证明了所有常用投票规则与最优解之间存在加性距离，最大为k^2/(k+1)^2。我们还研究了实例依赖配额的计算复杂性，证明了确定使给定批准配置文件满足α-JR的最佳α值是NP完全的。为了解决这个问题，我们提出了一个用于计算满足α-JR的委员会的整数线性规划（ILP）公式，并在选民区间（VI）和候选人区间（CI）域中获得了积极的结果。

Result: 我们发现，所有常用投票规则与最优方案之间存在一个可加距离，最大为k^2/(k+1)^2。确定给定审批配置文件满足α-JR的最佳α值是NP完全的。但是，我们提出了一个整数线性规划（ILP）公式来计算满足α-JR的委员会，并在选民区间（VI）和候选人区间（CI）域中获得了积极结果。

Conclusion: 本文首次超越了固定配额范式，引入了依赖于实例的配额比例概念。尽管确定最优α值是NP完全的，但我们提出的ILP公式在特定领域表现良好，为未来研究提供了新方向。

Abstract: Justified representation (JR) and extended justified representation (EJR) are
well-established proportionality axioms in approval-based multiwinner voting.
Both axioms are always satisfiable, but they rely on a fixed quota (typically
Hare or Droop), with the Droop quota being the smallest one that guarantees
existence across all instances. With this observation in mind, we take a first
step beyond the fixed-quota paradigm and introduce proportionality notions
where the quota is instance-dependent. We demonstrate that all commonly studied
voting rules can have an additive distance to the optimum of
$\frac{k^2}{(k+1)^2}$. Moreover, we look into the computational aspects of our
instance-dependent quota and prove that determining the optimal value of
$\alpha$ for a given approval profile satisfying $\alpha$-JR is NP-complete. To
address this, we introduce an integer linear programming (ILP) formulation for
computing committees that satisfy $\alpha$-JR, and we provide positive results
in the voter interval (VI) and candidate interval (CI) domains.

</details>
