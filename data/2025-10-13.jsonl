{"id": "2510.07888", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2510.07888", "abs": "https://arxiv.org/abs/2510.07888", "authors": ["Xinren Zhang", "Sixi Cheng", "Zixin Zhong", "Jiadong Yu"], "title": "Network Topology and Information Efficiency of Multi-Agent Systems: Study based on MARL", "comment": null, "summary": "Multi-agent systems (MAS) solve complex problems through coordinated\nautonomous entities with individual decision-making capabilities. While\nMulti-Agent Reinforcement Learning (MARL) enables these agents to learn\nintelligent strategies, it faces challenges of non-stationarity and partial\nobservability. Communications among agents offer a solution, but questions\nremain about its optimal structure and evaluation. This paper explores two\nunderexamined aspects: communication topology and information efficiency. We\ndemonstrate that directed and sequential topologies improve performance while\nreducing communication overhead across both homogeneous and heterogeneous\ntasks. Additionally, we introduce two metrics -- Information Entropy Efficiency\nIndex (IEI) and Specialization Efficiency Index (SEI) -- to evaluate message\ncompactness and role differentiation. Incorporating these metrics into training\nobjectives improves success rates and convergence speed. Our findings highlight\nthat designing adaptive communication topologies with information-efficient\nmessaging is essential for effective coordination in complex MAS."}
{"id": "2510.07597", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.07597", "abs": "https://arxiv.org/abs/2510.07597", "authors": ["Nicolas Resch", "S. Venkitesh"], "title": "List Recoverable Codes: The Good, the Bad, and the Unknown (hopefully not Ugly)", "comment": null, "summary": "List recovery is a fundamental task for error-correcting codes, vastly\ngeneralizing unique decoding from worst-case errors and list decoding. Briefly,\none is given ''soft information'' in the form of input lists S_1,...,S_n of\nbounded size, and one argues that there are not too many codewords that agree a\nlot with this soft information. This general problem appears in many guises,\nboth within coding theory and in theoretical computer science more broadly.\n  In this article we survey recent results on list recovery codes, introducing\nboth the ''good'' (i.e., possibility results, showing that codes with certain\nlist recoverability exist), the ''bad'' (impossibility results), and the\n''unknown''. We additionally demonstrate that, while list recoverable codes\nwere initially introduced as a component in list decoding concatenated codes,\nthey have since found myriad applications to and connections with other topics\nin theoretical computer science."}
{"id": "2510.07722", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.07722", "abs": "https://arxiv.org/abs/2510.07722", "authors": ["Russell K. Standish"], "title": "Is star complexity a proxy for information based complexity of graphs?", "comment": "Accepted for Complex Networks 2025", "summary": "Information-based complexity (IBC) is a well-defined complexity measure of\nany object given a description in a language and a classifier that identifies\nthose descriptions with the object. Of course, the exact numerical value will\nvary according to the descriptive language and classifier, but under certain\nuniversality conditions (eg the classifier identifies programs of a universal\nTurning machine that halt and output the same value), asymptotically, the\ncomplexity measure is independent of the classifier up to a constant of O(1).\nThe hypothesis being investigated in this work that any practical IBC measure\nwill similarly be asymptotically equivalent to any other practical IBC measure.\nStandish presented an IBC measure for graphs ${\\cal C}$ that encoded graphs by\ntheir links, and identifies graphs as those that are automorphic to each other.\nAn interesting alternate graph measure is {\\em star complexity}, which is\ndefined as the number of union and intersection operations of basic stars that\ncan generate the original graph. Whilst not an IBC itself, it can be related to\nan IBC (called ${\\cal C}^*$) that is strongly correlated with star complexity.\nIn this paper, 10 and 22 vertex graphs are constructed up to a star complexity\nof 8, and the ${\\cal C}^*$ compared emprically with ${\\cal C}$. Finally, an\neasily computable upper bound of star complexity is found to be strongly\nrelated to ${\\cal C}$."}
{"id": "2510.07821", "categories": ["cs.SI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.07821", "abs": "https://arxiv.org/abs/2510.07821", "authors": ["Raisa M. Simoes", "Timoteo Kelly", "Eduardo J. Simoes", "Praveen Rao"], "title": "From Keywords to Clusters: AI-Driven Analysis of YouTube Comments to Reveal Election Issue Salience in 2024", "comment": null, "summary": "This paper aims to explore two competing data science methodologies to\nattempt answering the question, \"Which issues contributed most to voters'\nchoice in the 2024 presidential election?\" The methodologies involve novel\nempirical evidence driven by artificial intelligence (AI) techniques. By using\ntwo distinct methods based on natural language processing and clustering\nanalysis to mine over eight thousand user comments on election-related YouTube\nvideos from one right leaning journal, Wall Street Journal, and one left\nleaning journal, New York Times, during pre-election week, we quantify the\nfrequency of selected issue areas among user comments to infer which issues\nwere most salient to potential voters in the seven days preceding the November\n5th election. Empirically, we primarily demonstrate that immigration and\ndemocracy were the most frequently and consistently invoked issues in user\ncomments on the analyzed YouTube videos, followed by the issue of identity\npolitics, while inflation was significantly less frequently referenced. These\nresults corroborate certain findings of post-election surveys but also refute\nthe supposed importance of inflation as an election issue. This indicates that\nvariations on opinion mining, with their analysis of raw user data online, can\nbe more revealing than polling and surveys for analyzing election outcomes."}
{"id": "2510.07430", "categories": ["cs.GT"], "pdf": "https://arxiv.org/pdf/2510.07430", "abs": "https://arxiv.org/abs/2510.07430", "authors": ["Yang Jiao", "Guanpu Chen", "Yiguang Hong"], "title": "BG-FlipIn: A Bayesian game framework for FlipIt-insider models in advanced persistent threats", "comment": null, "summary": "In this paper, we study advanced persistent threats (APT) with an insider who\nhas different preferences. To address the uncertainty of the insider's\npreference, we propose the BG-FlipIn: a Bayesian game framework for\nFlipIt-insider models with an investigation on malicious, inadvertent, or\ncorrupt insiders. We calculate the closed-form Bayesian Nash Equilibrium\nexpression and further obtain three edge cases with deterministic insiders\ncorresponding to their Nash Equilibrium expressions. On this basis, we further\ndiscover several phenomena in APT related to the defender's move rate and cost,\nas well as the insider's preferences. We then provide decision-making guidance\nfor the defender, given different parametric conditions. Two applications\nvalidate that our BG-FlipIn framework enables the defender to make decisions\nconsistently, avoiding detecting the insider's concrete preference or adjusting\nits strategy frequently."}
{"id": "2510.08071", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.08071", "abs": "https://arxiv.org/abs/2510.08071", "authors": ["Rashid Iqbal", "Dimitrios Bozanis", "Dimitrios Tyrovolas", "Christos K. Liaskos", "Muhammad Ali Imran", "George K. Karagiannidis", "Hanaa Abumarshoud"], "title": "Integrated Localization, Mapping, and Communication through VCSEL-Based Light-emitting RIS (LeRIS)", "comment": null, "summary": "This paper presents a light-emitting reconfigurable intelligent surface\n(LeRIS) architecture that integrates vertical cavity surface emitting lasers\n(VCSELs) to jointly support user localization, obstacle-aware mapping, and\nmillimeter-wave (mmWave) communication in programmable wireless environments\n(PWEs). Unlike prior light-emitting diode (LED)-based LeRIS designs with\ndiffuse emission or LiDAR-assisted schemes requiring bulky sensing modules, the\nproposed VCSEL-based approach exploits narrow Gaussian beams and multimode\ndiversity to enable compact, low-power, and analytically tractable integration.\nWe derive closed-form expressions to jointly recover user position and\norientation from received signal strength using only five VCSELs, and reduce\nthis requirement to three under specific geometric conditions by leveraging\ndual-mode operation. In parallel, we introduce a VCSEL-based mapping method\nthat uses reflected signal time-of-arrival measurements to detect obstructions\nand guide blockage-resilient RIS beam routing. Simulation results demonstrate\nmillimeter-level localization accuracy, robust obstacle detection, high\nspectral efficiency, and substantial gains in minimum user rate. These findings\nestablish VCSEL-based LeRIS as a scalable and practically integrable enabler\nfor resilient 6G wireless systems with multi-functional PWEs."}
{"id": "2510.08012", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.08012", "abs": "https://arxiv.org/abs/2510.08012", "authors": ["Jinze Wang", "Lu Zhang", "Yiyang Cui", "Zhishu Shen", "Xingjun Ma", "Jiong Jin", "Tiehua Zhang"], "title": "Do We Really Need SFT? Prompt-as-Policy over Knowledge Graphs for Cold-start Next POI Recommendation", "comment": null, "summary": "Next point-of-interest (POI) recommendation is crucial for smart urban\nservices such as tourism, dining, and transportation, yet most approaches\nstruggle under cold-start conditions where user-POI interactions are sparse.\nRecent efforts leveraging large language models (LLMs) address this challenge\nthrough either supervised fine-tuning (SFT) or in-context learning (ICL).\nHowever, SFT demands costly annotations and fails to generalize to inactive\nusers, while static prompts in ICL cannot adapt to diverse user contexts. To\novercome these limitations, we propose Prompt-as-Policy over knowledge graphs,\na reinforcement-guided prompting framework that learns to construct prompts\ndynamically through contextual bandit optimization. Our method treats prompt\nconstruction as a learnable policy that adaptively determines (i) which\nrelational evidences to include, (ii) the number of evidence per candidate, and\n(iii) their organization and ordering within prompts. More specifically, we\nconstruct a knowledge graph (KG) to discover candidates and mine relational\npaths, which are transformed into evidence cards that summarize rationales for\neach candidate POI. The frozen LLM then acts as a reasoning engine, generating\nrecommendations from the KG-discovered candidate set based on the\npolicy-optimized prompts. Experiments on three real-world datasets demonstrate\nthat Prompt-as-Policy consistently outperforms state-of-the-art baselines,\nachieving average 7.7\\% relative improvements in Acc@1 for inactive users,\nwhile maintaining competitive performance on active users, without requiring\nmodel fine-tuning."}
{"id": "2510.07572", "categories": ["cs.GT", "cs.IT", "math.IT", "math.PR", "60D05, 68Q87", "G.3; I.2.4"], "pdf": "https://arxiv.org/pdf/2510.07572", "abs": "https://arxiv.org/abs/2510.07572", "authors": ["Jesse D Wei", "Guo Wei"], "title": "Deterministic algorithms for inhomogeneous Bernoulli trials: Shapley value of network devices", "comment": "27 pages", "summary": "Suppose that $n$ computer devices are to be connected to a network via\ninhomogeneous Bernoulli trials. The Shapley value of a device quantifies how\nmuch the network's value increases due to the participation of that device.\nCharacteristic functions of such games are naturally taken as the belief\nfunction (containment function) and Choquet capacity (hitting probability) of a\nrandom set (random network of devices).\n  Traditionally, the Shapley value is either calculated as the expected\nmarginal contribution over all possible coalitions (subnetworks), which results\nin exponential computational complexity, or approximated by the Monte Carlo\nsampling technique, where the performance is highly dependent on the stochastic\nsampling process.\n  The purpose of this study is to design deterministic algorithms for games\nformulated via inhomogeneous Bernoulli trials that approximate the Shapley\nvalue in linear or quadratic time, with rigorous error analysis (Sections 3 and\n4). Additionally, we provide a review of relevant literature on existing\ncalculation methods in Remark 3.1 and Appendix I.\n  A further goal is to supplement Shapley's original proof by deriving the\nShapley value formula using a rigorous approach based on definite integrals and\ncombinatorial analysis. This method explicitly highlights the roles of the\nBinomial Theorem and the Beta function in the proof, addressing a gap in\nShapley's work (Appendix II)."}
{"id": "2510.08117", "categories": ["cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.08117", "abs": "https://arxiv.org/abs/2510.08117", "authors": ["Frédéric Zheng", "Yassir Jedra", "Alexandre Proutiere"], "title": "Near-optimal Rank Adaptive Inference of High Dimensional Matrices", "comment": null, "summary": "We address the problem of estimating a high-dimensional matrix from linear\nmeasurements, with a focus on designing optimal rank-adaptive algorithms. These\nalgorithms infer the matrix by estimating its singular values and the\ncorresponding singular vectors up to an effective rank, adaptively determined\nbased on the data. We establish instance-specific lower bounds for the sample\ncomplexity of such algorithms, uncovering fundamental trade-offs in selecting\nthe effective rank: balancing the precision of estimating a subset of singular\nvalues against the approximation cost incurred for the remaining ones. Our\nanalysis identifies how the optimal effective rank depends on the matrix being\nestimated, the sample size, and the noise level. We propose an algorithm that\ncombines a Least-Squares estimator with a universal singular value thresholding\nprocedure. We provide finite-sample error bounds for this algorithm and\ndemonstrate that its performance nearly matches the derived fundamental limits.\nOur results rely on an enhanced analysis of matrix denoising methods based on\nsingular value thresholding. We validate our findings with applications to\nmultivariate regression and linear dynamical system identification."}
{"id": "2510.08190", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.08190", "abs": "https://arxiv.org/abs/2510.08190", "authors": ["Abdou Majeed Alidou", "Júlia Baligács", "Jan Hązła"], "title": "Geometric opinion exchange polarizes in every dimension", "comment": null, "summary": "A recent line of work studies models of opinion exchange where agent opinions\nabout $d$ topics are tracked simultaneously. The opinions are represented as\nvectors on the unit $(d-1)$-sphere, and the update rule is based on the overall\ncorrelation between the relevant vectors. The update rule reflects the\nassumption of biased assimilation, i.e., a pair of opinions is brought closer\ntogether if their correlation is positive and further apart if the correlation\nis negative.\n  This model seems to induce the polarization of opinions into two antipodal\ngroups. This is in contrast to many other known models which tend to achieve\nconsensus. The polarization property has been recently proved for $d=2$, but\nthe general case of $d \\ge 3$ remained open. In this work, we settle the\ngeneral case, using a more detailed understanding of the model dynamics and\ntools from the theory of random processes."}
{"id": "2510.08453", "categories": ["cs.GT", "91A44, 91A20, 28E05"], "pdf": "https://arxiv.org/pdf/2510.08453", "abs": "https://arxiv.org/abs/2510.08453", "authors": ["Kiri Sakahara", "Takashi Sato"], "title": "Extending Games beyond the Finite Horizon", "comment": "34 pages, 11 figures", "summary": "This paper argues that the finite horizon paradox, where game theory\ncontradicts intuition, stems from the limitations of standard number systems in\nmodelling the cognitive perception of infinity. To address this issue, we\npropose a new framework based on Alternative Set Theory (AST). This framework\nrepresents different cognitive perspectives on a long history of events using\ndistinct topologies. These topologies define an indiscernibility equivalence\nthat formally treats huge, indistinguishable quantities as equivalent. This\noffers criterion-dependent resolutions to long-standing paradoxes, such as\nSelten's chain store paradox and Rosenthal's centipede game. Our framework\nreveals new intuitive subgame perfect equilibria, the characteristics of which\ndepend on the chosen temporal perspective and payoff evaluation. Ultimately, by\ngrounding its mathematical foundation in different modes of human cognition,\nour work expands the explanatory power of game theory for long-horizon\nscenarios."}
{"id": "2510.08364", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.08364", "abs": "https://arxiv.org/abs/2510.08364", "authors": ["Han Wu", "Hamdi Joudeh"], "title": "Exponential Error Bounds for Information Bottleneck Source Coding Problems", "comment": null, "summary": "We study the information bottleneck (IB) source coding problem, also known as\nremote lossy source coding under logarithmic loss. Based on a rate-limited\ndescription of noisy observations, the receiver produces a soft estimate for\nthe remote source, i.e., a probability distribution, evaluated under the\nlogarithmic loss. We focus on the excess distortion probability of IB source\ncoding and investigate how fast it converges to 0 or 1, depending on whether\nthe rate is above or below the rate-distortion function. The latter case is\nalso known as the exponential strong converse. We establish both the exact\nerror exponent and the exact strong converse exponent for IB source coding by\nderiving matching upper and lower exponential bounds. The obtained exponents\ninvolve optimizations over auxiliary random variables. The matching converse\nbounds are derived through non-trivial extensions of existing sphere packing\nand single-letterization techniques, which we adapt to incorporate auxiliary\nrandom variables.\n  In the second part of this paper, we establish a code-level connection\nbetween IB source coding and source coding with a helper, also known as the\nWyner-Ahlswede-K\\\"orner (WAK) problem. We show that every code for the WAK\nproblem is a code for IB source coding. This requires noticing that IB source\ncoding, under the excess distortion criterion, is equivalent to source coding\nwith a helper available at both the transmitter and the receiver; the latter in\nturn relates to the WAK problem. Through this connection, we re-derive the best\nknown sphere packing exponent of the WAK problem, and provide it with an\noperational interpretation."}
{"id": "2510.08481", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.08481", "abs": "https://arxiv.org/abs/2510.08481", "authors": ["Yifei Xu", "Jiaying Wu", "Herun Wan", "Yang Li", "Zhen Hou", "Min-Yen Kan"], "title": "Forecasting the Buzz: Enriching Hashtag Popularity Prediction with LLM Reasoning", "comment": "Accepted to CIKM 2025", "summary": "Hashtag trends ignite campaigns, shift public opinion, and steer millions of\ndollars in advertising spend, yet forecasting which tag goes viral is elusive.\nClassical regressors digest surface features but ignore context, while large\nlanguage models (LLMs) excel at contextual reasoning but misestimate numbers.\nWe present BuzzProphet, a reasoning-augmented hashtag popularity prediction\nframework that (1) instructs an LLM to articulate a hashtag's topical virality,\naudience reach, and timing advantage; (2) utilizes these popularity-oriented\nrationales to enrich the input features; and (3) regresses on these inputs. To\nfacilitate evaluation, we release HashView, a 7,532-hashtag benchmark curated\nfrom social media. Across diverse regressor-LLM combinations, BuzzProphet\nreduces RMSE by up to 2.8% and boosts correlation by 30% over baselines, while\nproducing human-readable rationales. Results demonstrate that using LLMs as\ncontext reasoners rather than numeric predictors injects domain insight into\ntabular models, yielding an interpretable and deployable solution for social\nmedia trend forecasting."}
{"id": "2510.08487", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.08487", "abs": "https://arxiv.org/abs/2510.08487", "authors": ["Mohammadreza Bakhshizadeh Mohajer", "Alex Dytso", "Daniela Tuninetti", "Luca Barletta"], "title": "A Rate-Distortion Bound for ISAC", "comment": "35 pages, 3 figures, submitted to JSAIT", "summary": "This paper addresses the fundamental performance limits of Integrated Sensing\nand Communication (ISAC) systems by introducing a novel converse bound based on\nrate-distortion theory. This rate-distortion bound (RDB) overcomes the\nrestrictive regularity conditions of classical estimation theory, such as the\nBayesian Cram\\'er-Rao Bound (BCRB). The proposed framework is broadly\napplicable, holding for arbitrary parameter distributions and distortion\nmeasures, including mean-squared error and probability of error. The bound is\nproved to be tight in the high sensing noise regime and can be strictly tighter\nthan the BCRB in the low sensing noise regime. The RDB's utility is\ndemonstrated on two challenging scenarios: Nakagami fading channel estimation,\nwhere it provides a valid bound even when the BCRB is inapplicable, and a\nbinary occupancy detection task, showcasing its versatility for discrete\nsensing problems. This work provides a powerful and general tool for\ncharacterizing the ultimate performance tradeoffs in ISAC systems."}
{"id": "2510.07572", "categories": ["cs.GT", "cs.IT", "math.IT", "math.PR", "60D05, 68Q87", "G.3; I.2.4"], "pdf": "https://arxiv.org/pdf/2510.07572", "abs": "https://arxiv.org/abs/2510.07572", "authors": ["Jesse D Wei", "Guo Wei"], "title": "Deterministic algorithms for inhomogeneous Bernoulli trials: Shapley value of network devices", "comment": "27 pages", "summary": "Suppose that $n$ computer devices are to be connected to a network via\ninhomogeneous Bernoulli trials. The Shapley value of a device quantifies how\nmuch the network's value increases due to the participation of that device.\nCharacteristic functions of such games are naturally taken as the belief\nfunction (containment function) and Choquet capacity (hitting probability) of a\nrandom set (random network of devices).\n  Traditionally, the Shapley value is either calculated as the expected\nmarginal contribution over all possible coalitions (subnetworks), which results\nin exponential computational complexity, or approximated by the Monte Carlo\nsampling technique, where the performance is highly dependent on the stochastic\nsampling process.\n  The purpose of this study is to design deterministic algorithms for games\nformulated via inhomogeneous Bernoulli trials that approximate the Shapley\nvalue in linear or quadratic time, with rigorous error analysis (Sections 3 and\n4). Additionally, we provide a review of relevant literature on existing\ncalculation methods in Remark 3.1 and Appendix I.\n  A further goal is to supplement Shapley's original proof by deriving the\nShapley value formula using a rigorous approach based on definite integrals and\ncombinatorial analysis. This method explicitly highlights the roles of the\nBinomial Theorem and the Beta function in the proof, addressing a gap in\nShapley's work (Appendix II)."}
