<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.IT](#cs.IT) [Total: 6]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.LG](#cs.LG) [Total: 53]
- [cs.MA](#cs.MA) [Total: 3]
- [stat.ML](#stat.ML) [Total: 9]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.SI](#cs.SI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

TL;DR: 这篇论文旨在通过利用大五人格特质框架来提取和利用大型语言模型中的隐性人格，从而实现对其生成行为的精确控制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成内容时会表现出隐性人格，但可靠地控制或调整这些特质以满足特定需求仍然是一个开放的挑战。在生成过程中有效操纵模型行为的机制是文献中需要填补的关键空白。这篇论文旨在解决在利用大语言模型中的隐性人格来控制其生成行为所面临的挑战。

Method: 本研究提出了一种新颖的流程，该流程使用大五人格特质（开放性、尽责性、外向性、宜人性、神经质）从 transformer 层中提取隐藏状态激活，这是一个全面且经过经验验证的建模人类人格的框架。该方法应用低秩子空间发现方法，并在不同的模型架构上识别出特定特质的最佳层，以实现稳健的注入。然后，通过具有动态层选择的灵活 steering 框架来操作所得到的与人格对齐的方向，从而实现对 LLM 输出中特质表达的精确控制。

Result: 研究结果表明，人格特质占据了一个低秩共享子空间，并且这些潜在结构可以通过仔细的扰动转化为有效的 steering 机制，而不会影响流畅性、变化性和一般能力。

Conclusion: 通过利用大五人格特质框架，本研究为理解和控制大型语言模型中的隐性人格提供了一种新颖的方法。通过提取和操作与人格特质相关的隐藏状态激活，该方法成功地实现了对模型生成行为的精确控制，同时保持了输出的质量。这有助于弥合心理学理论与实际模型对齐之间的鸿沟。

Abstract: Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [2] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

TL;DR: TextualVerifier是一个基于LLM的自验证框架，通过思维链推理和多数投票来提高TextGrad中基于文本决策的推理有效性。


<details>
  <summary>Details</summary>
Motivation: TextGrad在没有明确数值方程的情况下实现优化，但缺乏自我验证机制。

Method: TextualVerifier包含四个阶段：思维链分解、变体生成、多数投票和共识聚合，并无侵入性地集成到TextGrad的损失函数和优化结果验证阶段。

Result: TextualVerifier在PRM800K上将推理步骤的有效性提高了29%。与TextGrad集成后，在GPQA-Diamond、MMLU-ML和MMLU-CP基准上，将性能提高了2.2个百分点，最终版本分别提高了8.08、10.71和3.92个百分点。

Conclusion: TextualVerifier是TextGrad首个基于LLM的自验证框架，无需数值梯度，提高了推理的可靠性，并为文本优化中的验证开辟了新方向。

Abstract: TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [3] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

TL;DR: 该论文介绍了 GRDD+（扩展希腊方言数据集），其中包含 10 种希腊方言，共计 6,374,939 个词。它是迄今为止规模最大、种类最多的希腊方言数据集。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏涵盖多种希腊方言且规模较大的数据集来改进大型语言模型。

Method: 通过扩展现有 GRDD 数据集（增加了克里特、塞浦路斯、本都和北希腊方言的数据），并新增六种方言（希腊-科西嘉语、Griko 语、Maniot 语、Heptanesian 语、Tsakonian 语和 Katharevusa 希腊语），最终构建了 GRDD+ 数据集。随后，使用该数据集对三种大型语言模型（Llama-3-8B、Llama-3.1-8B、Krikri-8B）进行微调，并与前沿模型进行比较。

Result: GRDD+ 数据集包含 6,374,939 个词和 10 种方言。该数据集是迄今为止规模最大、种类最多的希腊方言数据集。研究人员对不同的 LLM 进行了微调实验，以评估高质量方言数据对其性能的影响。

Conclusion: GRDD+ 数据集是希腊方言研究的重要资源，有望促进方言自然语言处理领域的发展。通过微调实验，证明了高质量方言数据在提升大型语言模型性能方面具有显著作用。

Abstract: We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [4] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

TL;DR: PLLuM是一个大型开源波兰语基础模型家族，旨在解决现有LLM对非英语语言支持有限的问题，并通过新的波兰语语料库、指令数据集和负责任的AI框架开发，以促进波兰的开放研究和主权AI技术。


<details>
  <summary>Details</summary>
Motivation: 开发针对波兰语的大型语言模型，解决现有大型语言模型主要关注英语，导致对其他语言支持有限的问题，并推动波兰本地化、透明和与文化相关的AI发展。

Method: 构建了一个新的1400亿token的波兰语文本语料库用于预训练，一个7.7万个自定义指令数据集以及一个10万个偏好优化数据集。采用了包括严格数据治理和用于输出校正与安全过滤的混合模块的负责任AI框架。详细描述了基础模型和指令微调模型的架构、训练过程和对齐技术。

Result: 开发出了PLLuM模型家族，通过在公共管理领域的下游任务中验证了其有效性。模型在波兰语处理方面表现出色，并注重负责任的AI实践。

Conclusion: PLLuM模型家族的发布，旨在促进开放研究，加强波兰的主权AI技术，并为非英语语言的LLM发展提供了一个重要范例。

Abstract: Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


### [5] [Computational Turing Test Reveals Systematic Differences Between Human and AI Language](https://arxiv.org/abs/2511.04195)
*Nicolò Pagan,Petter Törnberg,Christopher A. Bail,Anikó Hannák,Christopher Barrie*

Main category: cs.CL

TL;DR: 本文介绍了一种计算图灵测试框架，并通过比较九种开源大型语言模型，发现即使经过校准，大型语言模型的输出与人类文本仍有明显区别，并且在“逼真度”和“语义保真度”之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型在社会科学中越来越多地用于模拟人类行为，但其生成文本的真实性假设尚未得到充分验证。现有的验证方法主要依赖人类判断，但这种判断并不准确。因此，该领域缺乏评估大型语言模型生成文本真实性或根据真实世界数据校准模型的可靠工具。

Method: 本文提出了一个计算图灵测试框架，该框架将聚合指标（基于BERT的可检测性和语义相似性）与可解释的语言特征（文体标记和主题模式）相结合，以评估大型语言模型在给定数据集中逼近人类语言的程度。其次，本文系统地比较了九种开源大型语言模型在五种校准策略下的表现，包括微调、风格提示和上下文检索，并以它们在X（以前称为Twitter）、Bluesky和Reddit上重现用户交互的能力作为基准。

Result: 研究结果挑战了文献中的核心假设。即使经过校准，大型语言模型的输出与人类文本之间仍然存在明显区别，尤其是在情感基调和情感表达方面。指令调优模型的表现不如其基础模型，并且扩大模型规模并不能增强类人性。至关重要的是，本文发现了一个权衡：优化类人性往往以牺牲语义保真度为代价，反之亦然。

Conclusion: 这些结果为大型语言模型模拟中的验证和校准提供了一个急需的可扩展框架，并对其目前在捕捉人类交流方面的局限性提出了 G 示。

Abstract: Large language models (LLMs) are increasingly used in the social sciences to
simulate human behavior, based on the assumption that they can generate
realistic, human-like text. Yet this assumption remains largely untested.
Existing validation efforts rely heavily on human-judgment-based evaluations --
testing whether humans can distinguish AI from human output -- despite evidence
that such judgments are blunt and unreliable. As a result, the field lacks
robust tools for assessing the realism of LLM-generated text or for calibrating
models to real-world data. This paper makes two contributions. First, we
introduce a computational Turing test: a validation framework that integrates
aggregate metrics (BERT-based detectability and semantic similarity) with
interpretable linguistic features (stylistic markers and topical patterns) to
assess how closely LLMs approximate human language within a given dataset.
Second, we systematically compare nine open-weight LLMs across five calibration
strategies -- including fine-tuning, stylistic prompting, and context retrieval
-- benchmarking their ability to reproduce user interactions on X (formerly
Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the
literature. Even after calibration, LLM outputs remain clearly distinguishable
from human text, particularly in affective tone and emotional expression.
Instruction-tuned models underperform their base counterparts, and scaling up
model size does not enhance human-likeness. Crucially, we identify a trade-off:
optimizing for human-likeness often comes at the cost of semantic fidelity, and
vice versa. These results provide a much-needed scalable framework for
validation and calibration in LLM simulations -- and offer a cautionary note
about their current limitations in capturing human communication.

</details>


### [6] [BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation](https://arxiv.org/abs/2511.04153)
*Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali*

Main category: cs.CL

TL;DR: 研究了三种多智能体LLM管道在Text-to-SQL任务上的性能，发现多智能体讨论能提升小型模型表现，而规划器-编码器管道效果最佳。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在处理大型数据库和复杂推理时，难以从自然语言指令生成准确的SQL。

Method: 本文探索了三种多智能体LLM管道：1) 多智能体讨论管道，智能体迭代地评论和优化SQL查询；2) 规划器-编码器管道，规划模型生成逐步SQL生成计划，编码器合成查询；3) 编码器-聚合器管道，多个编码器独立生成SQL查询，推理智能体选择最佳查询。并在Bird-Bench Mini-Dev数据集上进行了系统性性能基准测试。

Result: 多智能体讨论管道可以将小型模型的执行准确率提高高达10.6%（Qwen2.5-7b-Instruct在三轮讨论后）。在所有管道中，规划器-编码器管道表现最佳，使用DeepSeek-R1-32B和QwQ-32B作为规划器，将Gemma 3 27B IT的准确率从52.4%提高到56.4%。

Conclusion: 多智能体讨论可以有效提升小型模型在Text-to-SQL任务上的性能。规划器-编码器管道在Text-to-SQL任务中表现出最佳性能，通过分离规划和查询生成过程可以显著提高模型准确性。

Abstract: Text-to-SQL systems provide a natural language interface that can enable even
laymen to access information stored in databases. However, existing Large
Language Models (LLM) struggle with SQL generation from natural instructions
due to large schema sizes and complex reasoning. Prior work often focuses on
complex, somewhat impractical pipelines using flagship models, while smaller,
efficient models remain overlooked. In this work, we explore three multi-agent
LLM pipelines, with systematic performance benchmarking across a range of small
to large open-source models: (1) Multi-agent discussion pipeline, where agents
iteratively critique and refine SQL queries, and a judge synthesizes the final
answer; (2) Planner-Coder pipeline, where a thinking model planner generates
stepwise SQL generation plans and a coder synthesizes queries; and (3)
Coder-Aggregator pipeline, where multiple coders independently generate SQL
queries, and a reasoning agent selects the best query. Experiments on the
Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small
model performance, with up to 10.6% increase in Execution Accuracy for
Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines,
the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B
and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest
score of 56.4%. Codes are available at
https://github.com/treeDweller98/bappa-sql.

</details>


### [7] [STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models](https://arxiv.org/abs/2511.03827)
*Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik*

Main category: cs.CL

TL;DR: STARS是一种新的解码时算法，它通过迭代采样、评分和拒绝/接受固定大小的token片段来引导模型生成。这使得早期纠正生成路径成为可能，显著提高了计算效率并提升了对齐质量。


<details>
  <summary>Details</summary>
Motivation: 使大型语言模型与人类价值观对齐对其安全部署至关重要，但现有方法计算成本高昂且次优。

Method: 提出STARS（Segment-level Token Alignment with Rejection Sampling），一种解码时算法，通过迭代采样、评分和拒绝/接受短的、固定大小的token片段来引导模型生成。

Result: 在六个LLM的测试中，STARS在胜率上比监督微调（SFT）高出14.9个百分点，比直接偏好优化（DPO）高出4.3个百分点，并且与强大的Best-of-N基线相比仍具有很强的竞争力。

Conclusion: STARS提供了一种通用、鲁棒且高效的替代方案，用于对齐LLM，优于传统的微调和全序列排名方法。

Abstract: Aligning large language models with human values is crucial for their safe
deployment; however, existing methods, such as fine-tuning, are computationally
expensive and suboptimal. In contrast, inference-time approaches like Best-of-N
sampling require practically infeasible computation to achieve optimal
alignment. We propose STARS: Segment-level Token Alignment with Rejection
Sampling, a decoding-time algorithm that steers model generation by iteratively
sampling, scoring, and rejecting/accepting short, fixed-size token segments.
This allows for early correction of the generation path, significantly
improving computational efficiency and boosting alignment quality. Across a
suite of six LLMs, we show that STARS outperforms Supervised Fine-Tuning (SFT)
by up to 14.9 percentage points and Direct Preference Optimization (DPO) by up
to 4.3 percentage points on win-rates, while remaining highly competitive with
strong Best-of-N baselines. Our work establishes granular, reward-guided
sampling as a generalizable, robust, and efficient alternative to traditional
fine-tuning and full-sequence ranking methods for aligning LLMs.

</details>


### [8] [Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification](https://arxiv.org/abs/2511.03830)
*Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń*

Main category: cs.CL

TL;DR: 本文介绍了一种高效的多标签文本分类方法，通过将分类任务重新表述为一系列二分决策，结合前缀缓存机制，在不牺牲准确性的前提下显著提高了短文本推理效率。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLMs）中，多标签文本分类任务的效率提升。

Method: 将多标签分类任务重新表述为一系列二分（是/否）决策，每个目标维度独立查询。结合前缀缓存机制和LLM-to-SLM蒸馏，使用强大的标注模型（DeepSeek-V3）提供多重标注，聚合后微调小型模型（HerBERT-Large, CLARIN-1B, PLLuM-8B, Gemma3-1B）。

Result: 微调后的模型在零样本基线上显示出显著改进，尤其是在训练期间见过的维度上。

Conclusion: 将多标签分类分解为二分查询，结合蒸馏和缓存感知推理，为基于LLM的分类提供了一个可扩展且有效的框架。该方法具有通用性，可应用于不同领域。

Abstract: We introduce a method for efficient multi-label text classification with
large language models (LLMs), built on reformulating classification tasks as
sequences of dichotomic (yes/no) decisions. Instead of generating all labels in
a single structured response, each target dimension is queried independently,
which, combined with a prefix caching mechanism, yields substantial efficiency
gains for short-text inference without loss of accuracy. To demonstrate the
approach, we focus on affective text analysis, covering 24 dimensions including
emotions and sentiment. Using LLM-to-SLM distillation, a powerful annotator
model (DeepSeek-V3) provides multiple annotations per text, which are
aggregated to fine-tune smaller models (HerBERT-Large, CLARIN-1B, PLLuM-8B,
Gemma3-1B). The fine-tuned models show significant improvements over zero-shot
baselines, particularly on the dimensions seen during training. Our findings
suggest that decomposing multi-label classification into dichotomic queries,
combined with distillation and cache-aware inference, offers a scalable and
effective framework for LLM-based classification. While we validate the method
on affective states, the approach is general and applicable across domains.

</details>


### [9] [Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens](https://arxiv.org/abs/2511.03880)
*Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo*

Main category: cs.CL

TL;DR: 该论文分析了低资源语言机器翻译数据集中存在的性别偏见和有害内容，强调数量不等于质量。


<details>
  <summary>Details</summary>
Motivation: 随着低资源语言越来越多地被纳入NLP研究，人们越来越重视收集大规模数据集。然而，在追求数量而非质量时，存在构建性能不佳的语言技术和产生延续社会偏见的有害内容的风险。

Method: 本文调查了三种低资源语言（阿凡奥罗莫语、阿姆哈拉语和提格里尼亚语）机器翻译数据集的质量，重点关注数据集中的性别表征。

Result: 研究发现，训练数据中包含大量政治和宗教领域的文本，而基准数据集则侧重于新闻、健康和体育。数据集中还存在明显的男性偏向，体现在人名、动词的语法性别以及刻板印象的描述中。此外，论文还发现针对女性的有害和有毒描述，这些描述在数据量最大的语言中更为突出。

Conclusion: 数量不保证质量。希望这项工作能启发对为低资源语言收集的数据集进行进一步调查，并促使及早缓解有害内容。

Abstract: As low-resourced languages are increasingly incorporated into NLP research,
there is an emphasis on collecting large-scale datasets. But in prioritizing
quantity over quality, we risk 1) building language technologies that perform
poorly for these languages and 2) producing harmful content that perpetuates
societal biases. In this paper, we investigate the quality of Machine
Translation (MT) datasets for three low-resourced languages--Afan Oromo,
Amharic, and Tigrinya, with a focus on the gender representation in the
datasets. Our findings demonstrate that while training data has a large
representation of political and religious domain text, benchmark datasets are
focused on news, health, and sports. We also found a large skew towards the
male gender--in names of persons, the grammatical gender of verbs, and in
stereotypical depictions in the datasets. Further, we found harmful and toxic
depictions against women, which were more prominent for the language with the
largest amount of data, underscoring that quantity does not guarantee quality.
We hope that our work inspires further inquiry into the datasets collected for
low-resourced languages and prompts early mitigation of harmful content.
WARNING: This paper contains discussion of NSFW content that some may find
disturbing.

</details>


### [10] [GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation](https://arxiv.org/abs/2511.03900)
*Manh Nguyen,Sunil Gupta,Dai Do,Hung Le*

Main category: cs.CL

TL;DR: 本文介绍了一种名为GRAD的解码方法，它通过构建稀疏的token转换图，将模型生成与语料库中的证据相结合，从而在不重新训练LLM的情况下减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的幻觉问题依然存在，现有的方法依赖外部知识源，但这些方法存在脆弱、领域敏感或成本较高等问题。

Method: GRAD（Graph-Retrieved Adaptive Decoding）方法在解码时通过在一次前向传播中，在少量检索到的语料库中累积下一个token的logits，从而构建一个稀疏的token转换图。在解码过程中，将图检索到的logits进行最大归一化处理，并与模型logits自适应融合，以支持高证据的延续，同时保持流畅性。

Result: GRAD在三个模型和一系列问答基准测试中，在固有、外在幻觉和事实性任务中，始终优于基线，固有准确率最高提高9.7%，幻觉率降低8.6%，正确性提高6.9%。在所有方法中，GRAD取得了最高的真实-信息量乘积得分。

Conclusion: GRAD提供了一种轻量级、即插即用的替代方案，可以替代对比解码和知识图谱增强，证明了语料库级别的token转换统计证据可以有效地引导生成更真实和可验证的输出。

Abstract: Hallucination mitigation remains a persistent challenge for large language
models (LLMs), even as model scales grow. Existing approaches often rely on
external knowledge sources, such as structured databases or knowledge graphs,
accessed through prompting or retrieval. However, prompt-based grounding is
fragile and domain-sensitive, while symbolic knowledge integration incurs heavy
retrieval and formatting costs. Motivated by knowledge graphs, we introduce
Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds
generation in corpus-derived evidence without retraining. GRAD constructs a
sparse token transition graph by accumulating next-token logits across a small
retrieved corpus in a single forward pass. During decoding, graph-retrieved
logits are max-normalized and adaptively fused with model logits to favor
high-evidence continuations while preserving fluency. Across three models and a
range of question-answering benchmarks spanning intrinsic, extrinsic
hallucination, and factuality tasks, GRAD consistently surpasses baselines,
achieving up to 9.7$\%$ higher intrinsic accuracy, 8.6$\%$ lower hallucination
rates, and 6.9$\%$ greater correctness compared to greedy decoding, while
attaining the highest truth--informativeness product score among all methods.
GRAD offers a lightweight, plug-and-play alternative to contrastive decoding
and knowledge graph augmentation, demonstrating that statistical evidence from
corpus-level token transitions can effectively steer generation toward more
truthful and verifiable outputs.

</details>


### [11] [The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023](https://arxiv.org/abs/2511.03915)
*Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个衡量人类繁荣的地理指数（HFGI），该指数通过分析2013-2023年间约26亿条美国地理定位推文，利用微调的大型语言模型对与哈佛大学全球繁荣研究框架相关的48个指标（以及对移民的态度和对腐败的看法）进行分类。该数据集提供了月度和年度的县级和州级繁荣相关讨论指标，这些指标经过验证，能够准确反映潜在结构，并与既定指标显示出预期的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的衡量人类繁荣的方法，尽管涵盖了幸福、健康、目标、美德、人际关系和财务稳定等多个维度，却普遍缺乏精细的空间和时间分辨率。这限制了我们对超越经济指标的社会福祉进行深入理解和分析的能力。

Method: 本研究引入了人类繁荣地理指数（HFGI），该指数是通过分析大约26亿条2013年至2023年间的美国地理定位推文而得出的。研究中使用了微调的大型语言模型，对推文内容进行了分类，涉及48个与哈佛大学全球繁荣研究框架相符的指标，此外还包括对移民的态度和对腐败的看法。该数据集提供了月度和年度的县级和州级繁荣相关言论指标。

Result: HFGI数据集提供了月度和年度的县级和州级繁荣相关言论指标，并且这些测量结果已经过验证，证实其能够准确代表潜在的构建，并与已有的指标显示出预期的相关性。这表明HFGI是一个有效且可靠的工具，能够反映社会福祉。

Conclusion: 这项研究提供了一个史无前例的高分辨率资源，使得跨学科分析福祉、不平等和社会变迁成为可能。通过社交媒体言论，HFGI能够深入洞察过去十年美国人类繁荣的动态。

Abstract: Quantifying human flourishing, a multidimensional construct including
happiness, health, purpose, virtue, relationships, and financial stability, is
critical for understanding societal well-being beyond economic indicators.
Existing measures often lack fine spatial and temporal resolution. Here we
introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing
approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned
large language models to classify expressions across 48 indicators aligned with
Harvard's Global Flourishing Study framework plus attitudes towards migration
and perception of corruption. The dataset offers monthly and yearly county- and
state-level indicators of flourishing-related discourse, validated to confirm
that the measures accurately represent the underlying constructs and show
expected correlations with established indicators. This resource enables
multidisciplinary analyses of well-being, inequality, and social change at
unprecedented resolution, offering insights into the dynamics of human
flourishing as reflected in social media discourse across the United States
over the past decade.

</details>


### [12] [Direct Semantic Communication Between Large Language Models via Vector Translation](https://arxiv.org/abs/2511.03945)
*Fu-Chun Yang,Jason Eshraghian*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种通过向量翻译实现大型语言模型（LLM）之间潜在语义通信的方法，以克服传统上通过纯文本传递信息时存在的信息损失和计算开销问题。


<details>
  <summary>Details</summary>
Motivation: 在辩论、反思或工具调用等多智能体设置中，大型语言模型（LLM）之间通过纯文本传递消息，会丢弃大部分潜在语义，限制了信息传输并增加了不必要的计算开销。

Method: 作者通过向量翻译形成了一个潜在桥梁，利用学习到的映射实现表示空间之间的直接语义交换。他们训练了一个双编码器翻译器，用于Llama-2-7B和Mistral-7B-Instruct之间，并取得了平均余弦对齐度为0.538的性能。通过将翻译后的向量以30%的混合强度注入目标模型，可以在不破坏logits稳定性的前提下引导目标模型的生成。

Result: 双向评估显示出2.01:1的传输不对称性，表明通用模型的表示比指令调优模型的表示更具可转移性。这种保守的注入方法保持了计算稳定性。

Conclusion: 跨模型潜在通信是可行的，这使得能够共享意义而非仅仅是token的协作式AI系统成为可能。

Abstract: In multi-agent settings, such as debate, reflection, or tool-calling, large
language models (LLMs) pass messages as plain tokens, discarding most latent
semantics. This constrains information transfer and adds unnecessary
computational overhead. We form a latent bridge via vector translations, which
use learned mappings that enable direct semantic exchange between
representation spaces. A dual-encoder translator trained between Llama-2-7B and
Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the
translated vectors at 30 percent blending strength steers the target model's
generation without destabilizing logits. Bidirectional evaluation shows a
2.01:1 transfer asymmetry, indicating that general-purpose models yield more
transferable representations than instruction-tuned variants. This conservative
injection preserves computational stability while demonstrating that
cross-model latent communication is feasible, enabling collaborative AI systems
that share meaning rather than tokens.

</details>


### [13] [Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises](https://arxiv.org/abs/2511.04020)
*Shiyin Lin*

Main category: cs.CL

TL;DR: 这篇论文提出了一种将溯因推理整合到检索增强型大型语言模型（RAG）中的框架，以解决检索证据不完整导致推理过程中的空白问题。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG管道在检索到的证据不完整时往往会失效，导致推理过程中出现空白。

Method: 本研究提出的方法能够检测证据不足，生成候选的缺失前提，并通过一致性和合理性检查来验证这些前提。

Result: 在溯因推理和多跳问答基准测试上的实验结果表明，该方法提高了答案的准确性和推理的忠实性。

Conclusion: 溯因推理是增强RAG系统鲁棒性和可解释性的一个有前景的方向。

Abstract: Large Language Models (LLMs) enhanced with retrieval -- commonly referred to
as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance
in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved
evidence is incomplete, leaving gaps in the reasoning process. In such cases,
\emph{abductive inference} -- the process of generating plausible missing
premises to explain observations -- offers a principled approach to bridge
these gaps. In this paper, we propose a framework that integrates abductive
inference into retrieval-augmented LLMs. Our method detects insufficient
evidence, generates candidate missing premises, and validates them through
consistency and plausibility checks. Experimental results on abductive
reasoning and multi-hop QA benchmarks show that our approach improves both
answer accuracy and reasoning faithfulness. This work highlights abductive
inference as a promising direction for enhancing the robustness and
explainability of RAG systems.

</details>


### [14] [T-FIX: Text-Based Explanations with Features Interpretable to eXperts](https://arxiv.org/abs/2511.04070)
*Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong*

Main category: cs.CL

TL;DR: 本文介绍了一个名为T-FIX的基准，用于评估大型语言模型在知识密集型场景中生成解释的专家对齐程度。


<details>
  <summary>Details</summary>
Motivation: 在大模型应用于知识密集型场景时，用户不仅需要答案，还需要有意义的解释。现有的评估方法未能有效衡量解释内容是否符合专家直觉。

Method: 本文提出了T-FIX基准，涵盖七个知识密集型领域。通过与领域专家合作，开发了新的度量标准来衡量大型语言模型解释与专家判断的一致性。

Result: 本文将专家对齐形式化为评估解释的标准。

Conclusion: T-FIX基准和新的评估指标能够更好地评估大型语言模型在知识密集型领域中生成解释的质量，确保其与专家知识和直觉保持一致。

Abstract: As LLMs are deployed in knowledge-intensive settings (e.g., surgery,
astronomy, therapy), users expect not just answers, but also meaningful
explanations for those answers. In these settings, users are often domain
experts (e.g., doctors, astrophysicists, psychologists) who require
explanations that reflect expert-level reasoning. However, current evaluation
schemes primarily emphasize plausibility or internal faithfulness of the
explanation, which fail to capture whether the content of the explanation truly
aligns with expert intuition. We formalize expert alignment as a criterion for
evaluating explanations with T-FIX, a benchmark spanning seven
knowledge-intensive domains. In collaboration with domain experts, we develop
novel metrics to measure the alignment of LLM explanations with expert
judgment.

</details>


### [15] [Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04072)
*Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan*

Main category: cs.CL

TL;DR: 本文提出了PoK框架，结合结构化规划和对比时间知识检索，显著提高了大型语言模型在时间知识图谱问答中的检索精度和推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的TKGQA方法未能充分理解时间约束的复杂语义信息，LLMs在时间推理能力上存在局限性，常出现幻觉和知识缺失。

Method: 本文提出了PoK（Plan of Knowledge）框架，该框架包含两个主要部分：1. 知识规划模块：将复杂的时间问题分解为一系列子目标，为推理探索提供中间指导。2. 对比时间检索器：构建时间知识存储（TKS），通过对比检索框架从TKG中选择性地检索语义和时间上一致的事实。

Result: 在四个基准TKGQA数据集上的广泛实验表明，PoK显著提高了LLM的检索精度和推理准确性，最多超越了现有最先进的TKGQA方法56.0%。

Conclusion: PoK框架通过结合结构化规划和时间知识检索，有效地增强了时间推理的可解释性和事实一致性，显著提升了大型语言模型在时间知识图谱问答任务上的性能。

Abstract: Temporal Knowledge Graph Question Answering (TKGQA) aims to answer
time-sensitive questions by leveraging factual information from Temporal
Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG
embeddings or graph neural networks to inject temporal knowledge, they fail to
fully understand the complex semantic information of time constraints.
Recently, Large Language Models (LLMs) have shown remarkable progress,
benefiting from their strong semantic understanding and reasoning
generalization capabilities. However, their temporal reasoning ability remains
limited. LLMs frequently suffer from hallucination and a lack of knowledge. To
address these limitations, we propose the Plan of Knowledge framework with a
contrastive temporal retriever, which is named PoK. Specifically, the proposed
Plan of Knowledge module decomposes a complex temporal question into a sequence
of sub-objectives from the pre-defined tools, serving as intermediate guidance
for reasoning exploration. In parallel, we construct a Temporal Knowledge Store
(TKS) with a contrastive retrieval framework, enabling the model to selectively
retrieve semantically and temporally aligned facts from TKGs. By combining
structured planning with temporal knowledge retrieval, PoK effectively enhances
the interpretability and factual consistency of temporal reasoning. Extensive
experiments on four benchmark TKGQA datasets demonstrate that PoK significantly
improves the retrieval precision and reasoning accuracy of LLMs, surpassing the
performance of the state-of-the-art TKGQA methods by 56.0% at most.

</details>


### [16] [The truth is no diaper: Human and AI-generated associations to emotional words](https://arxiv.org/abs/2511.04077)
*Špela Vintar,Jan Jona Javoršek*

Main category: cs.CL

TL;DR: 研究了人类和大型语言模型（LLMs）的词语联想行为，特别是针对带有情感色彩的词语，发现LLMs的联想与人类存在中度重叠，但LLMs倾向于放大刺激的情感负荷，并且比人类更可预测、缺乏创造性。


<details>
  <summary>Details</summary>
Motivation: 探究人类和大型语言模型（LLMs）之间词语联想行为的异同，特别是在情感词语联想方面，以了解LLMs的联想方式是否与人类相似。

Method: 通过比较人类和LLMs对带有情感色彩的词语的联想行为，对它们之间的联想差异进行分析。

Result: 人类和LLMs在词语联想上存在中度重叠，但LLMs的联想往往会放大刺激词语的情感负荷，并且比人类的联想更具可预测性，缺乏创造性。

Conclusion: LLMs的词语联想能力虽然与人类有一定相似之处，但在情感词语联想方面，仍表现出与人类显著的差异，尤其是在情感放大和创造性方面。

Abstract: Human word associations are a well-known method of gaining insight into the
internal mental lexicon, but the responses spontaneously offered by human
participants to word cues are not always predictable as they may be influenced
by personal experience, emotions or individual cognitive styles. The ability to
form associative links between seemingly unrelated concepts can be the driving
mechanisms of creativity. We perform a comparison of the associative behaviour
of humans compared to large language models. More specifically, we explore
associations to emotionally loaded words and try to determine whether large
language models generate associations in a similar way to humans. We find that
the overlap between humans and LLMs is moderate, but also that the associations
of LLMs tend to amplify the underlying emotional load of the stimulus, and that
they tend to be more predictable and less creative than human ones.

</details>


### [17] [Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods](https://arxiv.org/abs/2511.04079)
*Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz*

Main category: cs.CL

TL;DR: 该研究通过大规模医学影像报告训练，提升了基于Transformer模型的去识别化能力，并在PHI检测方面超越了现有学术和商业系统。


<details>
  <summary>Details</summary>
Motivation: 通过扩展训练数据集和利用Transformer模型，提高放射学报告自动去识别化的效率和准确性，并与商业云系统进行性能比较。

Method: 本研究回顾性地在一个最先进的、基于Transformer的PHI去识别管道上进行构建。通过使用两个大型标注放射学语料库进行微调，并引入额外的PHI类别（AGE）。模型性能在斯坦福和宾夕法尼亚大学的测试集上进行了评估。此外，研究还评估了合成PHI生成的稳定性以及与商业系统的性能对比。

Result: 模型在Penn数据集上F1得分达到0.973，在Stanford数据集上达到0.996，超越或保持了先前最先进的模型性能。合成PHI评估显示出一致的检测能力（F1：0.959）。模型在合成Penn报告上的表现优于所有供应商系统（F1：0.960 vs. 0.632-0.754）。

Conclusion: 基于Transformer的去识别模型，通过多样化的放射学数据集训练，在PHI检测方面优于先前的学术和商业系统，并为安全的临床文本处理建立了新的基准。

Abstract: Objective: To enhance automated de-identification of radiology reports by
scaling transformer-based models through extensive training datasets and
benchmarking performance against commercial cloud vendor systems for protected
health information (PHI) detection. Materials and Methods: In this
retrospective study, we built upon a state-of-the-art, transformer-based, PHI
de-identification pipeline by fine-tuning on two large annotated radiology
corpora from Stanford University, encompassing chest X-ray, chest CT,
abdomen/pelvis CT, and brain MR reports and introducing an additional PHI
category (AGE) into the architecture. Model performance was evaluated on test
sets from Stanford and the University of Pennsylvania (Penn) for token-level
PHI detection. We further assessed (1) the stability of synthetic PHI
generation using a "hide-in-plain-sight" method and (2) performance against
commercial systems. Precision, recall, and F1 scores were computed across all
PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the
Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining
the previous state-of-the-art model performance. Synthetic PHI evaluation
showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50
independently de-identified Penn datasets. Our model outperformed all vendor
systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754).
Discussion: Large-scale, multimodal training improved cross-institutional
generalization and robustness. Synthetic PHI generation preserved data utility
while ensuring privacy. Conclusion: A transformer-based de-identification model
trained on diverse radiology datasets outperforms prior academic and commercial
systems in PHI detection and establishes a new benchmark for secure clinical
text processing.

</details>


### [18] [A Characterization of List Language Identification in the Limit](https://arxiv.org/abs/2511.04103)
*Moses Charikar,Chirag Pabbaraju,Ambuj Tewari*

Main category: cs.CL

TL;DR: 本文探讨了极限语言辨识问题，其中学习者在每个时间步可以给出k个猜测。文章给出了可进行k列表辨识的语言集合的精确特征，表明如果一个集合在极限中是k列表可辨识的，那么它可以以指数速率进行k列表辨识，这是最优的。


<details>
  <summary>Details</summary>
Motivation: 最初的语言辨识理论（Gold和Angluin）限制了学习者只能给出一个猜测，这导致了许多局限性。受语言生成问题最新进展的启发，本文旨在通过允许学习者在每个时间步输出k个猜测来重新审视经典的语言辨识问题，从而扩展和放宽这些限制。

Method: 本文通过将Angluin的特征化方法递归化，对在极限中可以进行k列表辨识的语言集合进行了精确的特征化。此外，这项研究工作还探究了列表辨识在统计环境中的速率，其中输入数据是从某个语言分布中以独立同分布（i.i.d.）流的形式抽取的。

Result: 可进行k列表辨识的语言集合，可以分解为k个子集合，每个子集合都可以用一个猜测进行辨识。如果一个集合在极限中是k列表可辨识的，那么它可以以指数速率进行k列表辨识，并且这是最优的。相反，如果一个集合在极限中不能进行k列表辨识，则其辨识速率不可能趋近于零。

Conclusion: 本文推进了我们对极限语言辨识的理解，特别是在学习者能够提供多个猜测的情况下。研究结果对语言学习和更广泛的机器学习领域都有影响，为设计更强大的语言学习算法提供了理论基础。

Abstract: We study the problem of language identification in the limit, where given a
sequence of examples from a target language, the goal of the learner is to
output a sequence of guesses for the target language such that all the guesses
beyond some finite time are correct. Classical results of Gold showed that
language identification in the limit is impossible for essentially any
interesting collection of languages. Later, Angluin gave a precise
characterization of language collections for which this task is possible.
Motivated by recent positive results for the related problem of language
generation, we revisit the classic language identification problem in the
setting where the learner is given the additional power of producing a list of
$k$ guesses at each time step. The goal is to ensure that beyond some finite
time, one of the guesses is correct at each time step.
  We give an exact characterization of collections of languages that can be
$k$-list identified in the limit, based on a recursive version of Angluin's
characterization (for language identification with a list of size $1$). This
further leads to a conceptually appealing characterization: A language
collection can be $k$-list identified in the limit if and only if the
collection can be decomposed into $k$ collections of languages, each of which
can be identified in the limit (with a list of size $1$). We also use our
characterization to establish rates for list identification in the statistical
setting where the input is drawn as an i.i.d. stream from a distribution
supported on some language in the collection. Our results show that if a
collection is $k$-list identifiable in the limit, then the collection can be
$k$-list identified at an exponential rate, and this is best possible. On the
other hand, if a collection is not $k$-list identifiable in the limit, then it
cannot be $k$-list identified at any rate that goes to zero.

</details>


### [19] [Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models](https://arxiv.org/abs/2511.04108)
*Wenmo Qiu,Saurabh Srivastava*

Main category: cs.CL

TL;DR: 这篇论文探讨了批处理提示如何提高大型语言模型（LLM）的多步推理能力，通过减少推理成本和改进模型行为，特别是在处理大型推理模型（LRM）时。


<details>
  <summary>Details</summary>
Motivation: 探索批处理提示作为一种降低大型语言模型推理成本的策略，并揭示其在多步推理中作为模型行为正则化的额外优势。

Method: 在13个不同的基准测试中进行全面研究，分析批处理对准确性和推理token使用量的影响，并通过详细的行为分析探究批处理如何影响模型行为。

Result: 批处理不仅提高了准确性，还将推理token使用量减少了3到5倍。批处理能抑制模型“过度思考”和“对冲语言”，鼓励模型给出更果断的答案。此外，批处理还表现出 emergent collective effects，即模型能够将早期示例的模式泛化到同一批次中更难的示例。

Conclusion: 批处理不仅仅是一种提高吞吐量的优化手段，更是一种强大的推理时正则化器，能够使LLM的推理更高效、更可靠。

Abstract: Recent work has explored batch prompting as a strategy to amortize inference
cost in large language models (LLMs). In this paper, we show that batching
offers an additional, underappreciated benefit: it regularizes model behavior
during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a
comprehensive study across 13 diverse benchmarks and observe that batching
improves accuracy while substantially reducing reasoning token usage, often by
3x-5x. Through detailed behavioral analysis, we find that batching suppresses
overthinking, reduces hedging language (e.g., repetitive self-corrections), and
encourages more decisive answers. Surprisingly, we also observe emergent
collective effects in batched inference: models often generalize patterns from
earlier examples to solve harder ones in the same batch. These findings
position batching not just as a throughput optimization, but as a powerful
inference-time regularizer for more efficient and reliable LLM reasoning.

</details>


### [20] [RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning](https://arxiv.org/abs/2511.04120)
*Xinyuan Li,Murong Xu,Wenbiao Tao,Hanlun Zhu,Yike Zhao,Jipeng Zhang,Yunshi Lan*

Main category: cs.CL

TL;DR: 本文提出RIDE，一个新颖的对抗性问题重写框架，它利用项目响应理论（IRT）来严格衡量问题难度，并生成更具挑战性、形式良好的数学问题变体。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在数学推理方面表现出色，但这些结果可能因训练数据泄露或肤浅的模式匹配而非真正的推理而被夸大。因此，需要一种基于对抗性扰动的评估来衡量真实的数学推理能力。

Method: 我们利用35个大型语言模型来模拟学生，并从它们的回答中构建一个难度排序器。这个排序器在强化学习过程中提供奖励信号，并指导问题重写模型在不同难度级别上重新 формулировать现有问题。

Result: 将RIDE应用于竞赛级别的数学基准测试，可以得到扰动版本，这些版本会降低高级大型语言模型的性能，实验表明26个模型的平均下降率为21.73%。

Conclusion: RIDE能够有效评估大型语言模型在数学推理方面的真实能力和鲁棒性。

Abstract: Large language models (LLMs) achieve high performance on mathematical
reasoning, but these results can be inflated by training data leakage or
superficial pattern matching rather than genuine reasoning. To this end, an
adversarial perturbation-based evaluation is needed to measure true
mathematical reasoning ability. Current rule-based perturbation methods often
generate ill-posed questions and impede the systematic evaluation of question
difficulty and the evolution of benchmarks. To bridge this gap, we propose
RIDE, a novel adversarial question-rewriting framework that leverages Item
Response Theory (IRT) to rigorously measure question difficulty and to generate
intrinsically more challenging, well-posed variations of mathematical problems.
We employ 35 LLMs to simulate students and build a difficulty ranker from their
responses. This ranker provides a reward signal during reinforcement learning
and guides a question-rewriting model to reformulate existing questions across
difficulty levels. Applying RIDE to competition-level mathematical benchmarks
yields perturbed versions that degrade advanced LLM performance, with
experiments showing an average 21.73% drop across 26 models, thereby exposing
limited robustness in mathematical reasoning and confirming the validity of our
evaluation approach.

</details>


### [21] [CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese](https://arxiv.org/abs/2511.04139)
*Dazhong Chen,Yi-Cheng Lin,Yuchen Huang,Ziwei Gong,Di Jiang,Zeying Xie,Yi R.,Fung*

Main category: cs.CL

TL;DR: 本文介绍了CantoASR，这是一个针对粤语自动语音识别（ASR）的创新框架，它通过集成强制对齐、LoRA微调的Whisper模型以及指令微调的Qwen-Audio模型，显著提高了在资源匮乏的粤语环境下的识别准确率，解决了现有模型在处理粤语声调和口音方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音识别（ASR）模型在处理资源匮乏的粤语时面临巨大挑战，主要原因是标注数据有限、粤语特有的六种声调、变调现象以及口音差异。尽管像Whisper这样的模型已经存在，但它们的词错误率（WER）仍然很高。大型音频语言模型（LALMs）虽然能够利用更广泛的上下文推理，但仍需要明确的声调和韵律声学线索。

Method: CantoASR框架通过以下方法协同工作：1. **强制对齐（Forced alignment）**：用于精确提取声学特征。2. **LoRA微调的Whisper模型**：专门用于提高声调辨别能力。3. **指令微调的Qwen-Audio模型**：实现韵律感知的错误纠正。

Result: 在粤语口语数据上的评估显示，CantoASR在字符错误率（CER）方面比Whisper-Large-V3有了显著的提升。

Conclusion: 将声学线索与大型音频语言模型（LALM）的推理能力相结合，为低资源声调语言和方言的自动语音识别提供了一个可扩展的策略。这一发现为解决粤语等复杂方言的ASR难题指明了方向。

Abstract: Automatic speech recognition (ASR) is critical for language accessibility,
yet low-resource Cantonese remains challenging due to limited annotated data,
six lexical tones, tone sandhi, and accent variation. Existing ASR models, such
as Whisper, often suffer from high word error rates. Large audio-language
models (LALMs), in contrast, can leverage broader contextual reasoning but
still require explicit tonal and prosodic acoustic cues. We introduce CantoASR,
a collaborative ASR-LALM error correction framework that integrates forced
alignment for acoustic feature extraction, a LoRA-finetuned Whisper for
improved tone discrimination, and an instruction-tuned Qwen-Audio for
prosody-aware correction. Evaluations on spontaneous Cantonese data show
substantial CER gains over Whisper-Large-V3. These findings suggest that
integrating acoustic cues with LALM reasoning provides a scalable strategy for
low-resource tonal and dialectal ASR.

</details>


### [22] [Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains](https://arxiv.org/abs/2511.04184)
*Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu*

Main category: cs.CL

TL;DR: LAAC（LLM作为沟通者）提出了一种新的范式，将大型语言模型定位为智能沟通中介，通过结构化对话捕捉发件人意图，并促进与收件人进行真正的知识交流。这篇论文评估了LAAC在部署到多个沟通领域中的可信度要求。


<details>
  <summary>Details</summary>
Motivation: AI生成内容的泛滥导致了沟通效率的下降，发件人和收件人都过度依赖大型语言模型进行内容的扩展和压缩，从而缺乏真实的内容互动。

Method: 本研究提出了LAAC（LLM as a Communicator）框架，将大型语言模型作为智能沟通中介。该框架通过结构化对话捕捉发件人的意图，并促进与收件人进行真正的知识交流。论文系统地评估了LAAC在多个沟通领域部署的可信度要求，具体从三个基本维度进行研究：信息捕获保真度、再现性和查询响应完整性。利用LAAC的多智能体架构，通过受控实验评估了这些信任维度。

Result: 初步研究结果揭示了在LAAC可靠部署于高风险沟通场景之前必须解决的可衡量信任差距。

Conclusion: LAAC作为智能沟通中介，具有潜力解决当前AI生成内容带来的沟通效率问题。然而，在实际部署之前，需要解决信息保真度、一致性和可靠性等方面的信任差距。

Abstract: The proliferation of AI-generated content has created an absurd communication
theater where senders use LLMs to inflate simple ideas into verbose content,
recipients use LLMs to compress them back into summaries, and as a consequence
neither party engage with authentic content. LAAC (LLM as a Communicator)
proposes a paradigm shift - positioning LLMs as intelligent communication
intermediaries that capture the sender's intent through structured dialogue and
facilitate genuine knowledge exchange with recipients. Rather than perpetuating
cycles of AI-generated inflation and compression, LAAC enables authentic
communication across diverse contexts including academic papers, proposals,
professional emails, and cross-platform content generation. However, deploying
LLMs as trusted communication intermediaries raises critical questions about
information fidelity, consistency, and reliability. This position paper
systematically evaluates the trustworthiness requirements for LAAC's deployment
across multiple communication domains. We investigate three fundamental
dimensions: (1) Information Capture Fidelity - accuracy of intent extraction
during sender interviews across different communication types, (2)
Reproducibility - consistency of structured knowledge across multiple
interaction instances, and (3) Query Response Integrity - reliability of
recipient-facing responses without hallucination, source conflation, or
fabrication. Through controlled experiments spanning multiple LAAC use cases,
we assess these trust dimensions using LAAC's multi-agent architecture.
Preliminary findings reveal measurable trust gaps that must be addressed before
LAAC can be reliably deployed in high-stakes communication scenarios.

</details>


### [23] [LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal](https://arxiv.org/abs/2511.04205)
*Michał Karp,Anna Kubaszewska,Magdalena Król,Robert Król,Aleksander Smywiński-Pohl,Mateusz Szymański,Witold Wydmański*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在波兰国家上诉法院的官方资格考试中的表现，发现尽管在知识测试中表现良好，但在实践书面部分均未达到及格线，且“LLM即法官”的评估与官方评审团的判断存在差异。


<details>
  <summary>Details</summary>
Motivation: 评估当前大型语言模型（LLMs）是否能通过波兰国家上诉法院的官方资格考试。

Method: 作者探究了两种方法：将LLMs作为实际考生，以及采用“LLM即法官”的方法（其中模型生成的答案由其他模型自动评估）。考试包括公共采购法的多项选择知识测试和书面判决。构建了混合信息检索和提取流程以支持模型。使用多种LLMs（包括GPT-4.1, Claude 4 Sonnet和Bielik-11B-v2.6）在“闭卷”和多种检索增强生成设置下进行测试。

Result: 模型在知识测试中取得了满意的分数，但没有一个能在实践书面部分达到及格线。“LLM即法官”的评估结果与官方评审委员会的判断经常存在分歧。主要限制包括：易受“幻觉”影响、法律条文引用不正确、逻辑论证薄弱。

Conclusion: 尽管技术进步迅速，但当前LLMs尚不能替代波兰公共采购裁决中的人类法官或独立审查员，需要法律专家和技术团队之间的密切合作。

Abstract: This study provides an empirical assessment of whether current large language
models (LLMs) can pass the official qualifying examination for membership in
Poland's National Appeal Chamber (Krajowa Izba Odwo{\l}awcza). The authors
examine two related ideas: using LLM as actual exam candidates and applying the
'LLM-as-a-judge' approach, in which model-generated answers are automatically
evaluated by other models. The paper describes the structure of the exam, which
includes a multiple-choice knowledge test on public procurement law and a
written judgment, and presents the hybrid information recovery and extraction
pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4
Sonnet and Bielik-11B-v2.6) were tested in closed-book and various
Retrieval-Augmented Generation settings. The results show that although the
models achieved satisfactory scores in the knowledge test, none met the passing
threshold in the practical written part, and the evaluations of the
'LLM-as-a-judge' often diverged from the judgments of the official examining
committee. The authors highlight key limitations: susceptibility to
hallucinations, incorrect citation of legal provisions, weaknesses in logical
argumentation, and the need for close collaboration between legal experts and
technical teams. The findings indicate that, despite rapid technological
progress, current LLMs cannot yet replace human judges or independent examiners
in Polish public procurement adjudication.

</details>


### [24] [REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs](https://arxiv.org/abs/2511.04228)
*Liran Cohen,Yaniv Nemcovesky,Avi Mendelson*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 REMIND 的新型评估方法，用于检测模型在机器遗忘后是否仍残留未学习数据的痕迹。


<details>
  <summary>Details</summary>
Motivation: 机器遗忘对于确保隐私、安全和合规性至关重要，但现有的评估方法可能忽略语义相似示例中存在的残余影响，从而导致隐私泄露和间接信息泄漏。

Method: REMIND 方法通过分析模型在微小输入变化上的损失来检测未学习数据的微妙残余影响。研究表明，未学习的数据会产生更平坦、不那么陡峭的损失曲线，而保留或不相关的数据则表现出更尖锐、更不稳定的模式。REMIND 仅需要基于查询的访问。

Result: REMIND 在相似限制下优于现有方法，并在不同模型、数据集和释义输入下表现出鲁棒性，使其在实际部署中具有实用性。

Conclusion: REMIND 提供了一种更灵敏、可解释的遗忘有效性度量，为评估语言模型中的遗忘提供了一个可靠的框架，并为记忆和遗忘提供了一个新的视角。

Abstract: Machine unlearning aims to remove the influence of specific training data
from a model without requiring full retraining. This capability is crucial for
ensuring privacy, safety, and regulatory compliance. Therefore, verifying
whether a model has truly forgotten target data is essential for maintaining
reliability and trustworthiness. However, existing evaluation methods often
assess forgetting at the level of individual inputs. This approach may overlook
residual influence present in semantically similar examples. Such influence can
compromise privacy and lead to indirect information leakage. We propose REMIND
(Residual Memorization In Neighborhood Dynamics), a novel evaluation method
aiming to detect the subtle remaining influence of unlearned data and classify
whether the data has been effectively forgotten. REMIND analyzes the model's
loss over small input variations and reveals patterns unnoticed by single-point
evaluations. We show that unlearned data yield flatter, less steep loss
landscapes, while retained or unrelated data exhibit sharper, more volatile
patterns. REMIND requires only query-based access, outperforms existing methods
under similar constraints, and demonstrates robustness across different models,
datasets, and paraphrased inputs, making it practical for real-world
deployment. By providing a more sensitive and interpretable measure of
unlearning effectiveness, REMIND provides a reliable framework to assess
unlearning in language models. As a result, REMIND offers a novel perspective
on memorization and unlearning.

</details>


### [25] [Reusing Pre-Training Data at Test Time is a Compute Multiplier](https://arxiv.org/abs/2511.04234)
*Alex Fang,Thomas Voice,Ruoming Pang,Ludwig Schmidt,Tom Gunter*

Main category: cs.CL

TL;DR: 研究表明，当前的大型语言模型预训练方法未能充分利用现有数据集中的信息，通过检索增强生成可以在MMLU、Math-500和SimpleQA等任务上实现显著的准确性提升，尤其是MMLU，检索增强相当于约5倍的计算量乘数。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型预训练过程中，从数据中提取思想和知识的效率，以及数据集价值被遗留的程度。

Method: 使用检索增强生成（RAG）和测试时计算，量化预训练过程遗留的数据集价值，并分析其随规模的变化。

Result: 通过对标准和开源数据集的预训练和检索，MMLU、Math-500和SimpleQA的准确性显著提高，即使经过去污染处理也依然有效。MMLU任务中，检索增强相当于约5倍的计算量乘数。在测试时利用额外计算解析检索到的上下文，可以将MMLU的准确性再提高10个百分点，例如LLaMA 3.1 8B模型。

Conclusion: 当前的大型语言模型预训练方法并未充分利用现有预训练数据集中的信息，未来仍有很大的改进空间。

Abstract: Large language models learn from their vast pre-training corpora, gaining the
ability to solve an ever increasing variety of tasks; yet although researchers
work to improve these datasets, there is little effort to understand how
efficient the pre-training apparatus is at extracting ideas and knowledge from
the data. In this work, we use retrieval augmented generation along with
test-time compute as a way to quantify how much dataset value was left behind
by the process of pre-training, and how this changes across scale. We
demonstrate that pre-training then retrieving from standard and largely
open-sourced datasets results in significant accuracy gains in MMLU, Math-500,
and SimpleQA, which persist through decontamination. For MMLU we observe that
retrieval acts as a ~5x compute multiplier versus pre-training alone. We show
that these results can be further improved by leveraging additional compute at
test time to parse the retrieved context, demonstrating a 10 percentage point
improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results
suggest that today's pre-training methods do not make full use of the
information in existing pre-training datasets, leaving significant room for
progress.

</details>


### [26] [Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models](https://arxiv.org/abs/2511.04248)
*Salma Mekaooui,Hiba Sofyan,Imane Amaaz,Imane Benchrif,Arsalane Zarghili,Ilham Chaker,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于图的方法，用于从文本中提取主题，并为这些主题分配有意义的标签，而无需依赖计算成本高昂的模型，实现了与ChatGPT-3.5相当的性能。


<details>
  <summary>Details</summary>
Motivation: 在大规模非结构化文本数据中，从文本中提取主题至关重要。现有方法通常计算成本高昂，而传统主题模型如（TM）虽然资源消耗较少，但生成的主题通常是词语分布，缺乏清晰的可解释性。

Method: 本研究提出了一种基于图的方法，通过丰富主题词并探索它们之间的语义关系来为主题分配有意义的标签。该方法利用图分析主题词之间的连接，从而得出准确捕捉每个主题含义的标签。

Result: 所提出的方法在两个不同的数据集上与包括ChatGPT-3.5在内的几个基准进行了比较。该方法在BERTScore和余弦相似度方面始终优于传统基准，并取得了与ChatGPT-3.5相当的结果，同时保持了计算效率。

Conclusion: 本研究提出了一种高效且可解释的文本主题标注方法，为主题标注和提高可解释性、自动化提供了新的研究方向。

Abstract: Extracting topics from text has become an essential task, especially with the
rapid growth of unstructured textual data. Most existing works rely on highly
computational methods to address this challenge. In this paper, we argue that
probabilistic and statistical approaches, such as topic modeling (TM), can
offer effective alternatives that require fewer computational resources. TM is
a statistical method that automatically discovers topics in large collections
of unlabeled text; however, it produces topics as distributions of
representative words, which often lack clear interpretability. Our objective is
to perform topic labeling by assigning meaningful labels to these sets of
words. To achieve this without relying on computationally expensive models, we
propose a graph-based approach that not only enriches topic words with
semantically related terms but also explores the relationships among them. By
analyzing these connections within the graph, we derive suitable labels that
accurately capture each topic's meaning. We present a comparative study between
our proposed method and several benchmarks, including ChatGPT-3.5, across two
different datasets. Our method achieved consistently better results than
traditional benchmarks in terms of BERTScore and cosine similarity and produced
results comparable to ChatGPT-3.5, while remaining computationally efficient.
Finally, we discuss future directions for topic labeling and highlight
potential research avenues for enhancing interpretability and automation.

</details>


### [27] [SSPO: Subsentence-level Policy Optimization](https://arxiv.org/abs/2511.04256)
*Kun Yang,Zikang chen,Yanmeng Wang,Zhigen Li*

Main category: cs.CL

TL;DR: 本文介绍了SSPO，一种新的RLVR算法，它在句子级别应用重要性比率，以平衡GRPO和GSPO的优缺点。SSPO不仅避免了训练崩溃和高方差，而且防止了修剪机制放弃整个响应token。SSPO在五个数据集上的平均得分达到46.57，超过GRPO（43.01）和GSPO（44.42），并在三个数据集上获得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR算法，如GRPO和GSPO，存在策略更新不稳定或采样数据利用率低的问题。GRPO的重要性比率在token级别计算，容易受异常值影响导致训练崩溃。GSPO在响应级别计算重要性比率，解决了GRPO的变异性问题，但极端值可能导致整个响应被错误地丢弃，降低了采样数据利用率。

Method: 本文引入了SSPO算法，通过在句子级别应用重要性比率来平衡GRPO和GSPO的优点。SSPO在PPO-CLIP中应用句子熵来稳定调整剪辑边界，鼓励高熵token进行探索，并缩小低熵token的剪辑范围。

Result: SSPO在五个数据集上的平均得分达到46.57，超过GRPO（43.01）和GSPO（44.42）。SSPO在三个数据集上取得了最先进的性能。

Conclusion: SSPO通过结合GSPO的精髓并克服其缺点，有效利用了生成数据，提高了LLMs的推理能力。

Abstract: As a significant part of post-training of the Large Language Models (LLMs),
Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs'
reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative
Policy Optimization) and GSPO (Group Sequence Policy Optimization), are
observed to suffer from unstable policy updates and low usage of sampling data,
respectively. The importance ratio of GRPO is calculated at the token level,
which focuses more on optimizing a single token. This will be easily affected
by outliers, leading to model training collapse. GSPO proposed the calculation
of the response level importance ratio, which solves the problem of high
variance and training noise accumulation in the calculation of the GRPO
importance ratio. However, since all the response tokens share a common
importance ratio, extreme values can easily raise or lower the overall mean,
leading to the entire response being mistakenly discarded, resulting in a
decrease in the utilization of sampled data. This paper introduces SSPO, which
applies sentence-level importance ratio, taking the balance between GRPO and
GSPO. SSPO not only avoids training collapse and high variance, but also
prevents the whole response tokens from being abandoned by the clipping
mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily
adjust the clipping bounds, encouraging high-entropy tokens to explore and
narrow the clipping range of low-entropy tokens. In particular, SSPO achieves
an average score of 46.57 across five datasets, surpassing GRPO (43.01) and
GSPO (44.42), and wins state-of-the-art performance on three datasets. These
results highlight SSPO's effectiveness in leveraging generated data by taking
the essence of GSPO but rejecting its shortcomings.

</details>


### [28] [Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning](https://arxiv.org/abs/2511.04406)
*Mohammad Amin Ghanizadeh,Mohammad Javad Dousti*

Main category: cs.CL

TL;DR: 本文提出了一种针对机器翻译系统微调的数据选择方法，该方法通过学习器模型和预训练参考模型的协同作用，定义可学习性分数并采用批量选择策略，显著提高了数据效率和翻译性能。


<details>
  <summary>Details</summary>
Motivation: 提高机器翻译模型的性能，实现鲁棒可靠的翻译系统，核心在于有效选择高质量数据。

Method: 该方法通过结合学习器模型和预训练参考模型的协同作用，定义了一个可学习性分数来评估数据点的效用。同时，采用批量选择策略，考虑数据点之间的相互依赖性，以优化训练效率。

Result: 在英波语对和其他几个语言对上，使用在CCMatrix数据集上微调的mBART模型进行实验表明，该方法与iid基线相比，数据效率提高了五倍。利用缓存嵌入时，计算效率提高了24倍。

Conclusion: 所提出的数据选择方法能够显著提高机器翻译系统的效率和泛化能力，并通过精心选择最具影响力的训练示例来实现卓越的翻译性能。

Abstract: Data quality and its effective selection are fundamental to improving the
performance of machine translation models, serving as cornerstones for
achieving robust and reliable translation systems. This paper presents a data
selection methodology specifically designed for fine-tuning machine translation
systems, which leverages the synergy between a learner model and a pre-trained
reference model to enhance overall training effectiveness. By defining a
learnability score, our approach systematically evaluates the utility of data
points for training, ensuring that only the most relevant and impactful
examples contribute to the fine-tuning process. Furthermore, our method employs
a batch selection strategy which considers interdependencies among data points,
optimizing the efficiency of the training process while maintaining a focus on
data relevance. Experiments on English to Persian and several other language
pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that
our method can achieve up to a fivefold improvement in data efficiency compared
to an iid baseline. Experimental results indicate that our approach improves
computational efficiency by 24 when utilizing cached embeddings, as it requires
fewer training data points. Additionally, it enhances generalization, resulting
in superior translation performance compared to random selection method.

</details>


### [29] [If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning Task for LLMs](https://arxiv.org/abs/2511.04432)
*Lars Bungum,Charles Yijia Huang,Abeer Kashar*

Main category: cs.CL

TL;DR: 研究LLMs在1940年挪威语料上的时间推理能力，发现英语提示效果优于挪威语提示，大模型表现更好。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）进行时间推理的能力，并评估语言和模型大小对其性能的影响。

Method: 使用1940年的挪威书籍中的知识问答，提示LLMs以1940年的视角回答问题。问题以英语和挪威语两种语言呈现。通过LLM作为评判者进行评分，并进行人工抽样检查。

Result: 英语提示下的回答效果始终优于挪威语提示，这与预期相反。较大尺寸的LLM在回答效果上有所提升。

Conclusion: LLMs在时间推理方面表现出潜力，但其性能受提示语言和模型规模的影响。尽管挪威语是数据集的原始语言，但英语提示却能带来更好的表现，这表明LLMs对特定语言的偏好可能超出简单的数据匹配。

Abstract: In this study, we experiment with the ability of LLMs to do temporal
reasoning. Using a Norwegian book from 1940 containing trivia questions, we
prompt the LLMs to answer the questions as if it were 1940. We also pose the
questions in both English and Norwegian. Correct answers are often presented as
sentences, and grading is done by means of LLM-as-judge, with sampled checks by
a native speaker. Prompting in English consistently gave better results than in
Norwegian, an unexpected result. In contrast, using larger LLMs improved
results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families,
and also the largest available LLM especially crafted for Norwegian.

</details>


### [30] [Probabilistic Textual Time Series Depression Detection](https://arxiv.org/abs/2511.04476)
*Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov*

Main category: cs.CL

TL;DR: PTTSD是一个概率文本时间序列抑郁症检测框架，它可以根据临床访谈中的话语水平预测PHQ-8分数，并对不确定性进行建模。


<details>
  <summary>Details</summary>
Motivation: 现有的抑郁症严重程度预测模型通常缺乏不确定性估计和时间建模。

Method: PTTSD结合了双向LSTM、自注意力机制和残差连接，并使用高斯或Student-t输出头通过负对数似然进行训练，包括序列到序列和序列到一的变体。

Result: PTTSD在E-DAIC和DAIC-WOZ数据集上取得了最先进的性能（例如，在E-DAIC上MAE=3.85，在DAIC上MAE=3.55），并产生了良好校准的预测区间。消融实验证实了注意力和概率建模的价值。

Conclusion: PTTSD是一个有效的抑郁症检测框架，它不仅提供了准确的预测，还对不确定性进行了建模，这对于临床决策支持至关重要。

Abstract: Accurate and interpretable predictions of depression severity are essential
for clinical decision support, yet existing models often lack uncertainty
estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time
Series Depression Detection framework that predicts PHQ-8 scores from
utterance-level clinical interviews while modeling uncertainty over time. PTTSD
includes sequence-to-sequence and sequence-to-one variants, both combining
bidirectional LSTMs, self-attention, and residual connections with Gaussian or
Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC
and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only
systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated
prediction intervals. Ablations confirm the value of attention and
probabilistic modeling, while comparisons with MentalBERT establish generality.
A three-part calibration analysis and qualitative case studies further
highlight the interpretability and clinical relevance of uncertainty-aware
forecasting.

</details>


### [31] [ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai](https://arxiv.org/abs/2511.04479)
*Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 这项研究推出了ThaiOCRBench，一个针对泰语视觉语言模型的综合评估基准。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态建模取得了进展，但现有基准主要关注资源丰富的语言，使得泰语在此类任务中代表性不足，尤其在需要理解文档结构的任务上。

Method: ThaiOCRBench通过一个包含2808个样本和13个任务类别的多样化、人工标注数据集来解决这个问题。研究者在零样本设置下评估了包括专有和开源系统在内的多种最先进的视觉语言模型。

Result: 结果显示，专有模型（如Gemini 2.5 Pro）的表现优于开源模型，并且开源模型在细粒度文本识别和手写内容提取方面的性能下降最为明显。

Conclusion: ThaiOCRBench为评估低资源、脚本复杂环境下的视觉语言模型提供了一个标准化框架，并为改进泰语文档理解提供了可行的见解。

Abstract: We present ThaiOCRBench, the first comprehensive benchmark for evaluating
vision-language models (VLMs) on Thai text-rich visual understanding tasks.
Despite recent progress in multimodal modeling, existing benchmarks
predominantly focus on high-resource languages, leaving Thai underrepresented,
especially in tasks requiring document structure understanding. ThaiOCRBench
addresses this gap by offering a diverse, human-annotated dataset comprising
2,808 samples across 13 task categories. We evaluate a wide range of
state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and
open-source systems. Results show a significant performance gap, with
proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source
counterparts. Notably, fine-grained text recognition and handwritten content
extraction exhibit the steepest performance drops among open-source models.
Through detailed error analysis, we identify key challenges such as language
bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a
standardized framework for assessing VLMs in low-resource, script-complex
settings, and provides actionable insights for improving Thai-language document
understanding.

</details>


### [32] [RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables](https://arxiv.org/abs/2511.04491)
*Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy*

Main category: cs.CL

TL;DR: RUST-BENCH是一个表格推理基准，旨在解决现有基准未能充分体现真实世界数据复杂性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有表格推理基准大多在小型、统一的表格上对模型进行测试，未能充分代表真实世界数据的复杂性，也未能完整展现大型语言模型的推理能力。真实的表格往往冗长、异构、领域特定，混合了结构化字段和自由文本，需要跨越数千个token进行多跳推理。

Method: 我们引入了RUST-BENCH，一个包含7966个问题的基准，这些问题来源于2031个真实世界的表格，涵盖两个领域：i) RB-Science（NSF资助记录）和ii) RB-Sports（NBA统计数据）。RUST-BENCH在规模、异构性、领域特异性和推理复杂性方面对LLM进行联合评估。

Result: 对开源和专有模型的实验表明，LLM在异构模式和复杂的多跳推理方面表现不佳，揭示了当前架构和提示策略中持续存在的弱点。

Conclusion: RUST-BENCH为推进表格推理研究建立了一个具有挑战性的新测试平台。

Abstract: Existing tabular reasoning benchmarks mostly test models on small, uniform
tables, underrepresenting the complexity of real-world data and giving an
incomplete view of Large Language Models' (LLMs) reasoning abilities. Real
tables are long, heterogeneous, and domain-specific, mixing structured fields
with free text and requiring multi-hop reasoning across thousands of tokens. To
address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from
2031 real-world tables spanning two domains: i) RB-Science (NSF grant records)
and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates
LLMs jointly across scale, heterogeneity, domain specificity, and reasoning
complexity. Experiments with open-source and proprietary models show that LLMs
struggle with heterogeneous schemas and complex multi-hop inference, revealing
persistent weaknesses in current architectures and prompting strategies.
RUST-BENCH establishes a challenging new testbed for advancing tabular
reasoning research.

</details>


### [33] [OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code Generation](https://arxiv.org/abs/2511.04495)
*Cuong Huynh,Jie Cao*

Main category: cs.CL

TL;DR: OUNLP团队在TSAR-2025共享任务中提交了一个基于LLM提示的文本简化系统，他们发现文本简化性能与源文本和目标文本的CEFR等级差距高度相关。受此启发，他们提出了两种多轮简化方法：MRS-Rule和MRS-Joint，并使用GPT-4o生成简化文本。他们的系统排名20支队伍中的第7位，后续改进表明以LLM简化候选项作为起点可以进一步提升多轮简化性能。


<details>
  <summary>Details</summary>
Motivation: 探索并改进LLM驱动的文本简化方法，特别关注不同CEFR等级差距对简化性能的影响。

Method: 提出了两种多轮简化方法：基于规则的简化（MRS-Rule）和联合基于规则的LLM简化（MRS-Joint）。这些方法通过GPT-4o生成简化文本，并利用了源文本和目标文本CEFR等级差距的分析结果。

Result: OUNLP系统在TSAR-2025共享任务中排名第7位。后续改进表明，以LLM简化候选项作为起点可以显著提升多轮简化性能。

Conclusion: 文本简化性能与源CEFR等级和目标CEFR等级之间的差距密切相关。多轮简化方法，特别是结合LLM生成的初始简化候选项，可以有效提高文本简化效果。

Abstract: This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task
(Alva-Manchego et al., 2025), designed for readability-controlled text
simplification using LLM-prompting-based generation. Based on the analysis of
prompt-based text simplification methods, we discovered an interesting finding
that text simplification performance is highly related to the gap between the
source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by
this finding, we propose two multi-round simplification methods and generate
them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based
LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams.
Later improvements with MRS-Joint show that taking the LLM simplified
candidates as the starting point could further boost the multi-round
simplification performance.

</details>


### [34] [Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering](https://arxiv.org/abs/2511.04499)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: 本文系统性地评估了六个大型语言模型（LLMs）的Fiver-Big-2（BFI-2）框架下的性格特征，发现在不同采样温度下，神经质和外向性等人格维度表现出显著差异，并揭示了模型架构特征可能导致稳定的性格倾向。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）的类人格行为对于负责任的开发和部署至关重要，因此本文旨在评估LLMs的性格特征及其影响因素。

Method: 本文采用Big Five Inventory-2 (BFI-2) 框架系统评估了六个大型语言模型在不同采样温度下的性格特质表达。此外，还通过层次聚类分析揭示了模型的聚类情况。

Result: 研究发现，在五个性格维度中有四个维度存在显著差异，其中神经质（Neuroticism）和外向性（Extraversion）容易受到温度调整的影响。层次聚类分析揭示了不同的模型聚类，表明架构特征可能使某些模型倾向于稳定的特质配置文件。

Conclusion: 本文的结果为LLMs中类人格模式的出现提供了新的见解，并为模型调优、选择和AI系统的伦理治理提供了新的视角。

Abstract: As Large Language Models (LLMs) become integral to human-centered
applications, understanding their personality-like behaviors is increasingly
important for responsible development and deployment. This paper systematically
evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to
assess trait expressions under varying sampling temperatures. We find
significant differences across four of the five personality dimensions, with
Neuroticism and Extraversion susceptible to temperature adjustments. Further,
hierarchical clustering reveals distinct model clusters, suggesting that
architectural features may predispose certain models toward stable trait
profiles. Taken together, these results offer new insights into the emergence
of personality-like patterns in LLMs and provide a new perspective on model
tuning, selection, and the ethical governance of AI systems. We share the data
and code for this analysis here:
https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1

</details>


### [35] [Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways](https://arxiv.org/abs/2511.04506)
*Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi*

Main category: cs.CL

TL;DR: 该研究提出了一个名为Lunguage++的框架，用于处理放射学报告中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 放射学报告对于临床决策至关重要，但报告中常包含不确定性，表现为明确不确定性和隐含不确定性两种类型。明确不确定性通过模糊措辞表达，其含义随语境变化，导致传统规则系统难以量化。隐含不确定性则源于放射科医生省略部分推理过程，使得未提及的发现是确实不存在还是仅为简洁而省略变得不明确。

Method: 该研究提出一个两部分框架来解决这些挑战。量化明确不确定性：通过创建一个经过专家验证的、基于LLM的常见模糊短语参考排名，并将每个发现根据此参考映射到概率值。建模隐含不确定性：通过一个扩展框架，系统地添加了从14种常见诊断的专家定义诊断路径中提取的特征性子发现。

Result: 通过上述方法，该研究发布了Lunguage++，这是Lungage基准测试的一个扩展的、不确定性感知版本，该基准测试包含细粒度的结构化放射学报告。

Conclusion: Lunguage++这一丰富的资源，能够实现不确定性感知的图像分类、忠实的诊断推理，并为诊断不确定性的临床影响的新研究提供了可能。

Abstract: Radiology reports are invaluable for clinical decision-making and hold great
potential for automated analysis when structured into machine-readable formats.
These reports often contain uncertainty, which we categorize into two distinct
types: (i) Explicit uncertainty reflects doubt about the presence or absence of
findings, conveyed through hedging phrases. These vary in meaning depending on
the context, making rule-based systems insufficient to quantify the level of
uncertainty for specific findings; (ii) Implicit uncertainty arises when
radiologists omit parts of their reasoning, recording only key findings or
diagnoses. Here, it is often unclear whether omitted findings are truly absent
or simply unmentioned for brevity. We address these challenges with a two-part
framework. We quantify explicit uncertainty by creating an expert-validated,
LLM-based reference ranking of common hedging phrases, and mapping each finding
to a probability value based on this reference. In addition, we model implicit
uncertainty through an expansion framework that systematically adds
characteristic sub-findings derived from expert-defined diagnostic pathways for
14 common diagnoses. Using these methods, we release Lunguage++, an expanded,
uncertainty-aware version of the Lunguage benchmark of fine-grained structured
radiology reports. This enriched resource enables uncertainty-aware image
classification, faithful diagnostic reasoning, and new investigations into the
clinical impact of diagnostic uncertainty.

</details>


### [36] [Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics](https://arxiv.org/abs/2511.04527)
*Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow*

Main category: cs.CL

TL;DR: 该论文探讨了在大型语言模型的思维链推理过程中，不确定性与模型内部激活状态之间的关系。研究发现，模型的激活状态可以预测其不确定性以及未来可能的推理路径。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在生成文本时，是否在内部表征了其可能采取的不同推理路径，以及如何量化这种不确定性。

Method: 通过在思维链推理过程中使用隐藏激活来控制和预测语言模型的不确定性。实验中关联模型的不确定性与通过控制其激活来引导模型的难易程度。

Result: 模型在不同token上的不确定性与通过控制其激活来引导模型的难易程度之间存在明显关联。当模型有多种路径可选时（即尚未确定最终答案时），激活干预最有效。隐藏激活能够预测模型的未来结果分布，表明模型隐含地表示了可能的路径空间。

Conclusion: 语言模型在进行思维链推理时，其内部激活状态能够反映并预测其不确定性及潜在的推理路径。这表明模型在某种程度上代表了不同的生成路径，并且在不确定性较高时更容易被引导。

Abstract: When a language model generates text, the selection of individual tokens
might lead it down very different reasoning paths, making uncertainty difficult
to quantify. In this work, we consider whether reasoning language models
represent the alternate paths that they could take during generation. To test
this hypothesis, we use hidden activations to control and predict a language
model's uncertainty during chain-of-thought reasoning. In our experiments, we
find a clear correlation between how uncertain a model is at different tokens,
and how easily the model can be steered by controlling its activations. This
suggests that activation interventions are most effective when there are
alternate paths available to the model -- in other words, when it has not yet
committed to a particular final answer. We also find that hidden activations
can predict a model's future outcome distribution, demonstrating that models
implicitly represent the space of possible paths.

</details>


### [37] [IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection](https://arxiv.org/abs/2511.04528)
*Kaveh Eskandari Miandoab,Katharine Kowalyshyn,Kabir Pamnani,Anesu Gavhera,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: IntelliProof是一个通过LLM分析议论文的交互式系统，它将文章结构化为论证图，并提供可视化、解释和量化评估功能，帮助用户理解论证质量。


<details>
  <summary>Details</summary>
Motivation: 现有的自动论文评分系统专注于结果，而IntelliProof强调用户体验，旨在通过可视化和解释来帮助用户更好地理解议论文的论证结构和质量。

Method: IntelliProof将议论文结构化为论证图，其中主张是节点，支持证据是节点属性，边表示支持或攻击关系。它使用LLM对每个关系进行分类和评分，并提供分类的理由以及论文连贯性的量化指标。

Result: IntelliProof能够快速评估论证质量，同时保留人工监督。它提供了一套工具，以自然语言帮助用户更好地理解议论文及其论证图，弥合了结构语义与用户理解之间的差距。

Conclusion: IntelliProof是一个创新的系统，它通过结合LLM的分析能力和用户友好的可视化界面，提供了一种有效且交互性强的方法来分析和理解议论文的论证结构和质量。

Abstract: We present IntelliProof, an interactive system for analyzing argumentative
essays through LLMs. IntelliProof structures an essay as an argumentation
graph, where claims are represented as nodes, supporting evidence is attached
as node properties, and edges encode supporting or attacking relations. Unlike
existing automated essay scoring systems, IntelliProof emphasizes the user
experience: each relation is initially classified and scored by an LLM, then
visualized for enhanced understanding. The system provides justifications for
classifications and produces quantitative measures for essay coherence. It
enables rapid exploration of argumentative quality while retaining human
oversight. In addition, IntelliProof provides a set of tools for a better
understanding of an argumentative essay and its corresponding graph in natural
language, bridging the gap between the structural semantics of argumentative
essays and the user's understanding of a given text. A live demo and the system
are available here to try: \textbf{https://intelliproof.vercel.app}

</details>


### [38] [From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting](https://arxiv.org/abs/2511.04538)
*Cyril Vallez,Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic*

Main category: cs.CL

TL;DR: 最新的开源大语言模型在早期报告的漏洞场景中仍然存在安全问题，这表明功能性与安全性之间的权衡阻碍了漏洞的有效修复。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型 (LLM) 生成代码中的漏洞问题，特别是虽然已经提出了许多 LLM 代码安全基准和改进方法，但这些方法对广泛使用的 LLM 影响仍不明确。

Method: 设计了一种新的严重性度量指标——提示暴露（PE），以反映 LLM 生成漏洞的风险。PE综合考虑了漏洞的严重性、生成机会以及导致生成漏洞代码的提示表述。

Result: 最新的开源模型在实际使用设置中，即使在最早报告的漏洞场景中也容易受到攻击。这表明，在安全性和功能性之间的权衡，至今未能有效修补漏洞。

Conclusion: 为了解决LLM生成代码的安全问题，引入了提示暴露（PE）和模型暴露（ME）分数。ME分数可以评估模型生成漏洞的严重性和普遍性，以鼓励缓解最严重和最普遍的漏洞。

Abstract: As the role of Large Language Models (LLM)-based coding assistants in
software development becomes more critical, so does the role of the bugs they
generate in the overall cybersecurity landscape. While a number of LLM code
security benchmarks have been proposed alongside approaches to improve the
security of generated code, it remains unclear to what extent they have
impacted widely used coding LLMs. Here, we show that even the latest
open-weight models are vulnerable in the earliest reported vulnerability
scenarios in a realistic use setting, suggesting that the safety-functionality
trade-off has until now prevented effective patching of vulnerabilities. To
help address this issue, we introduce a new severity metric that reflects the
risk posed by an LLM-generated vulnerability, accounting for vulnerability
severity, generation chance, and the formulation of the prompt that induces
vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation
of the most serious and prevalent vulnerabilities, we use PE to define the
Model Exposure (ME) score, which indicates the severity and prevalence of
vulnerabilities a model generates.

</details>


### [39] [When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection](https://arxiv.org/abs/2511.04643)
*Alamgir Munir Qazi,John P. McCrae,Jamal Abdul Nasir*

Main category: cs.CL

TL;DR: DeReC是一个轻量级且高效的事实核查框架，它使用密集检索和专门的分类器，在保持或超越现有大型语言模型性能的同时，显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 目前的事实核查系统虽然利用大型语言模型生成解释性理由，但面临计算成本高昂和幻觉风险，难以在实际中部署。

Method: DeReC（密集检索分类）框架通过结合密集检索和专门分类，利用通用文本嵌入来替代基于自回归LLM的方法。

Result: DeReC在效率上优于现有的解释生成型LLM，在RAWFC数据集上将运行时间减少了95%，在LIAR-RAW数据集上减少了92%。在RAWFC数据集上，DeReC的F1分数达到65.58%，超过了L-Defense（61.20%）等现有先进方法，显示出更优的准确性。

Conclusion: 精心设计的基于检索的系统可以在特定任务中达到或超过LLM的性能，同时在实际部署中更具实用性。

Abstract: The proliferation of misinformation necessitates robust yet computationally
efficient fact verification systems. While current state-of-the-art approaches
leverage Large Language Models (LLMs) for generating explanatory rationales,
these methods face significant computational barriers and hallucination risks
in real-world deployments. We present DeReC (Dense Retrieval Classification), a
lightweight framework that demonstrates how general-purpose text embeddings can
effectively replace autoregressive LLM-based approaches in fact verification
tasks. By combining dense retrieval with specialized classification, our system
achieves better accuracy while being significantly more efficient. DeReC
outperforms explanation-generating LLMs in efficiency, reducing runtime by 95%
on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92%
on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds),
showcasing its effectiveness across varying dataset sizes. On the RAWFC
dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art
method L-Defense (61.20%). Our results demonstrate that carefully engineered
retrieval-based systems can match or exceed LLM performance in specialized
tasks while being significantly more practical for real-world deployment.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [40] [Environment Division Multiple Access (EDMA): A Feasibility Study via Pinching Antennas](https://arxiv.org/abs/2511.03820)
*Zhiguo Ding,Robert Schober,H. V. Poor*

Main category: cs.IT

TL;DR: 这篇论文介绍了一种名为环境分割多址（EDMA）的新型多址技术，它利用无线传播环境的动态特性，通过“掐断天线”重新配置传播环境，在不增加信号处理复杂性的前提下，提高预期接收器的信号强度，并抑制多址干扰。


<details>
  <summary>Details</summary>
Motivation: 传统的无线通信系统中，多址干扰是一个普遍存在的问题，需要复杂的信号处理技术来消除。本文旨在提出一种新的多址技术，通过智能地重新配置传播环境来解决多址干扰问题，从而提高通信性能。

Method: 本文提出了一种基于“掐断天线”的EDMA技术。通过在特定位置放置“掐断天线”，可以重新配置视距（LoS）链路，有意地阻断干扰链路。论文推导了EDMA在遍历和瞬时和速率方面的性能增益闭式表达式。此外，还研究了掐断天线位置的优化问题，并提出了两种低复杂度的算法，分别用于上行链路和下行链路传输。

Result: 论文的分析结果表明，EDMA在支持多用户通信方面具有巨大潜力。仿真结果也验证了所提出的低复杂度算法在掐断天线位置优化方面的优越性。

Conclusion: 本文提出了一种创新的环境分割多址（EDMA）技术，通过智能操纵无线传播环境来有效抑制多用户干扰，简化了信号处理复杂性，并显著提升了系统性能。该技术为未来多用户通信系统提供了一种有前景的解决方案。

Abstract: This paper exploits the dynamic features of wireless propagation environments
as the basis for a new multiple access technique, termed environment division
multiple access (EDMA). In particular, with the proposed
pinching-antenna-assisted EDMA, the multi-user propagation environment is
intelligently reconfigured to improve signal strength at intended receivers and
simultaneously suppress multiple-access interference, without requiring complex
signal processing, e.g., precoding, beamforming, or multi-user detection. The
key to creating a favorable propagation environment is to utilize the
capability of pinching antennas to reconfigure line-of-sight (LoS) links, e.g.,
pinching antennas are placed at specific locations, such that interference
links are blocked on purpose. Based on a straightforward choice of
pinching-antenna locations, the ergodic sum-rate gain of EDMA over conventional
multiple access and the probability that EDMA achieves a larger instantaneous
sum rate than the considered benchmarking scheme are derived in closed form.
The obtained analytical results demonstrate the significant potential of EDMA
for supporting multi-user communications. Furthermore, pinching antenna
location optimization is also investigated, since the locations of pinching
antennas are critical for reconfiguring LoS links and large-scale path losses.
Two low-complexity algorithms are developed for uplink and downlink
transmission, respectively, and simulation results are provided to show their
optimality in comparison to exhaustive searches.

</details>


### [41] [Which Similarity-Sensitive Entropy?](https://arxiv.org/abs/2511.03849)
*Phuc Nguyen,Josiah Couch,Rahul Bansal,Alexandra Morgan,Chris Tam,Miao Li,Rima Arnaout,Ramy Arnaout*

Main category: cs.IT

TL;DR: 比较LCR和VS两种相似性敏感熵的测度方法。


<details>
  <summary>Details</summary>
Motivation: 传统的熵度量方法只关注元素频率，而LCR和VS能捕捉元素间的相似性和差异性信息。

Method: 概念性分析、解析性分析和实验分析（使用53个机器学习数据集）

Result: LCR和VS可能存在数量级差异，并提供互补信息。两者都依赖于相似度的缩放方式，并通过“半距离”概念进行参数化。VS在某些雷尼-希尔阶参数值下是LCR的上限。

Conclusion: 当元素可解释为“本原元素”的线性组合或系统具有量子力学特性时，VS更优。若仅需捕捉相似性编码的丰富信息，LCR更优，但在特定半距离下，两者可互补。

Abstract: A canonical step in quantifying a system is to measure its entropy. Shannon
entropy and other traditional entropy measures capture only the information
encoded in the frequencies of a system's elements. Recently, Leinster, Cobbold,
and Reeve (LCR) introduced a method that also captures the rich information
encoded in the similarities and differences among elements, yielding
similarity-sensitive entropy. More recently, the Vendi score (VS) was
introduced as an alternative, raising the question of how LCR and VS compare,
and which is preferable. Here we address these questions conceptually,
analytically, and experimentally, using 53 machine-learning datasets. We show
that LCR and VS can differ by orders of magnitude and can capture complementary
information about a system, except in limiting cases. We demonstrate that both
LCR and VS depend on how similarities are scaled and introduce the concept of
``half distance'' to parameterize this dependence. We prove that VS provides an
upper bound on LCR for several values of the R\'enyi-Hill order parameter and
conjecture that this bound holds for all values. We conclude that VS is
preferable only when interpreting elements as linear combinations of a more
fundamental set of ``ur-elements'' or when the system or dataset possesses a
quantum-mechanical character. In the broader circumstance where one seeks
simply to capture the rich information encoded by similarity, LCR is favored;
nevertheless, for certain half-distances the two methods can complement each
other.

</details>


### [42] [Efficient and rate-optimal list-decoding in the presence of minimal feedback: Weldon and Slepian-Wolf in sheep's clothing](https://arxiv.org/abs/2511.04088)
*Pranav Joshi,Daniel McMorrow,Yihan Zhang,Amitalok J. Budkuley,Sidharth Jaggi*

Main category: cs.IT

TL;DR: 本文提出了一种在对抗性信道中实现接近信息论最佳速率的通信方案，即使在存在反馈的情况下也能工作。


<details>
  <summary>Details</summary>
Motivation: 在存在对抗性噪声的信道中，以接近信息论最佳速率进行通信是一个基本问题。尽管对于大型字母表q，已经存在具有计算可行编码/解码过程的此类代码，但对于任何q≥2，如何在低速率反馈可用的情况下实现这种性能仍然是一个挑战。

Method: 本文提出了一种低速率反馈方案，其反馈速率渐近可忽略不计，同时在任何q≥2的情况下实现接近信息论最佳的速率。

Result: 在足够小的 $\varepsilon > 0$ 和 $ \varrho \in (1-1/q-\Theta(\sqrt{\varepsilon}))$ 的情况下，该方案实现了 $1-H_q(\varrho) - \varepsilon$ 的速率（接近信息论最佳），列表大小为 $\exp(\mathcal{O}(\varepsilon^{-3/2}\log^2(1/\varepsilon))$，编解码计算复杂度为 $n^{\mathcal{O}(\varepsilon^{-1}\log(1/\varepsilon))}$，存储复杂度为 $\mathcal{O}(n^{\eta+1}\log n)$，错误概率为 $\mathcal{O}(n^{-\eta})$，反馈速率为 $\mathcal{O}(1/ \log n)$。

Conclusion: 本文提出了第一个在任何 $q \geq 2$ 的情况下，通过低速率反馈实现接近信息论最佳速率的通信方案，即使在存在对抗性噪声的情况下也能保持高性能。

Abstract: Given a channel with length-$n$ inputs and outputs over the alphabet
$\{0,1,\ldots,q-1\}$, and of which a fraction $\varrho \in (0,1-1/q)$ of
symbols can be arbitrarily corrupted by an adversary, a fundamental problem is
that of communicating at rates close to the information-theoretically optimal
values, while ensuring the receiver can infer that the transmitter's message is
from a ``small" set. While the existence of such codes is known, and
constructions with computationally tractable encoding/decoding procedures are
known for large $q$, we provide the first schemes that attain this performance
for any $q \geq 2$, as long as low-rate feedback (asymptotically negligible
relative to the number of transmissions) from the receiver to the transmitter
is available. For any sufficiently small $\varepsilon > 0$ and $\varrho \in
(1-1/q-\Theta(\sqrt{\varepsilon})$ our minimal feedback scheme has the
following parameters: Rate $1-H_q(\varrho) - \varepsilon$ (i.e.,
$\varepsilon$-close to information-theoretically optimal -- here $H_q(\varrho)$
is the $q$-ary entropy function), list-size
$\exp(\mathcal{O}(\varepsilon^{-3/2}\log^2(1/\varepsilon))$, computational
complexity of encoding/decoding
$n^{\mathcal{O}(\varepsilon^{-1}\log(1/\varepsilon))}$, storage complexity
$\mathcal{O}(n^{\eta+1}\log n)$ for a code design parameter $\eta>1$ that
trades off storage complexity with the probability of error. The error
probability is $\mathcal{O}(n^{-\eta})$, and the (vanishing) feedback rate is
$\mathcal{O}(1/ \log n)$.

</details>


### [43] [List Decoding of Folded Reed-Solomon Codes Over Galois Ring](https://arxiv.org/abs/2511.04135)
*Chen Yuan,Ruiqi Zhu*

Main category: cs.IT

TL;DR: 本文探讨了伽罗瓦环上RS码和FRSA码的列表解码，旨在弥补对环上RS码和FRSA码了解甚少的不足，以期推动零知识证明系统的发展。


<details>
  <summary>Details</summary>
Motivation: 由于零知识系统需求的增长，有必要研究伽罗瓦环上代码的邻近间隙。先前的研究表明，有限域上RS码的邻近间隙可以通过列表解码得到改善，但对伽罗瓦环上的RS码知之甚少，这阻碍了基于环的算术电路的零知识证明系统的发展。

Method: 1. 将Guruswami-Sudan的列表解码程序扩展到伽罗瓦环上的Reed-Solomon (RS) 码，证明了速率为r的RS码可以被列表解码到半径$1-\\sqrt{r}$。
2. 研究了伽罗瓦环上折叠Reed-Solomon (FRS) 码的列表解码，并证明其列表解码半径可以达到有限域上的Singleton界。
3. 通过将Shashank Srivastava (2025) 的最新工作扩展到伽罗瓦环，将折叠Reed-Solomon码的列表大小改进到$O(\\frac{1}{\\varepsilon^2})$。

Result: 1. 证明了伽罗瓦环上速率为r的RS码可以被列表解码到半径$1-\\sqrt{r}$。
2. 证明了伽罗瓦环上折叠Reed-Solomon码的列表解码半径可以达到有限域上的Singleton界。
3. 将伽罗瓦环上折叠Reed-Solomon码的列表大小改进到$O(\\frac{1}{\\varepsilon^2})$。

Conclusion: 本文成功地将列表解码技术应用于伽罗瓦环上的RS码和FRS码，并取得了与有限域上相似的解码半径和列表大小的改进，为伽罗瓦环上编码的零知识证明系统发展奠定了基础。

Abstract: List decoding of codes can be seen as the generalization of unique decoding
of codes While list decoding over finite fields has been extensively studied,
extending these results to more general algebraic structures such as Galois
rings remains an important challenge. Due to recent progress in zero knowledge
systems, there is a growing demand to investigate the proximity gap of codes
over Galois rings in Yizhou Yao and coauthors(2025), Alexander Golovne and
coauthors(2023), Yuanju Wei and coauthors(2025). The proximity gap is closely
related to the decoding capability of codes. It was shown in Eli Ben-Sasson and
coauthors(2020) that the proximity gap for RS codes over finite field can be
improved to $1-\sqrt{r}$ if one consider list decoding instead of unique
decoding. However, we know very little about RS codes over Galois ring which
might hinder the development of zero knowledge proof system for ring-based
arithmetic circuit. In this work, we first extend the list decoding procedure
of Guruswami and Sudan to Reed-Solomon codes over Galois rings, which shows
that RS codes with rate $r$ can be list decoded up to radius $1-\sqrt{r}$.
Then, we investigate the list decoding of folded Reed-Solomon codes over Galois
rings. We show that the list decoding radius of folded Reed-Solomon codes can
reach the Singlton bound as its counterpart over finite field. Finally, we
improve the list size of our folded Reed-Solomon code to
$O(\frac{1}{\varepsilon^2})$ by extending recent work in Shashank
Srivastava(2025) to Galois Rings.

</details>


### [44] [Affine Frequency Division Multiplexing: From Communication to Sensing](https://arxiv.org/abs/2511.04471)
*Ali Bemani,Nassar Ksairi,Marios Kountouris*

Main category: cs.IT

TL;DR: 本文讨论了AFDM在综合感知与通信（ISAC）系统中的应用，旨在解决高带宽需求下的接收机复杂性和能耗问题以及多雷达环境中的干扰问题。


<details>
  <summary>Details</summary>
Motivation: AFDM已被提议作为一种在双分散（延迟-多普勒）信道中实现全分集效益的有效波形。本文旨在探讨AFDM在ISAC系统中解决高带宽需求下保持接收机复杂度和能耗可接受、以及减轻多雷达环境中的干扰这两个挑战的能力。

Method: 在单基地感知中，通过AFDM兼容低复杂度的自干扰消除（SIC）方案和通过模拟去啁啾降低采样率来解决第一个挑战。在双基地感知中，展示了AFDM支持子奈奎斯特采样。通过利用离散仿射傅里叶变换（DAFT）的资源分配灵活性来解决第二个挑战。

Result: AFDM-based ISAC接收机能够通过兼容低复杂度的自干扰消除方案和模拟去啁啾实现较低的采样率，从而在高带宽需求下保持接收机复杂度和能耗在可接受水平。它在双基地感知中支持子奈奎斯特采样，且无需硬件修改并能保持延迟分辨率。同时，利用DAFT的资源分配灵活性，有效减轻了多雷达环境中的干扰。

Conclusion: AFDM波形在解决ISAC系统中的接收机复杂性和能耗问题以及多雷达环境中的干扰问题方面显示出巨大的潜力，尤其是在处理高带宽应用时。

Abstract: Affine Frequency Division Multiplexing (AFDM) has been proposed as an
effective waveform for achieving the full diversity of doubly-dispersive
(delay-Doppler) channels. While this property is closely related to range and
velocity estimation in sensing, this article focuses on other AFDM features
that are particularly relevant for addressing two challenges in integrated
sensing and communication (ISAC) systems: (1) maintaining receiver complexity
and energy consumption at acceptable levels while supporting the large
bandwidths required for high delay/range resolution, and (2) mitigating
interference in multiradar environments. In monostatic sensing, where direct
transmitter-receiver leakage is a major impairment, we show that AFDM-based
ISAC receivers can address the first challenge through their compatibility with
low-complexity self-interference cancellation (SIC) schemes and reduced
sampling rates via analog dechirping. In bistatic sensing, where such analog
solutions may not be feasible, we demonstrate that AFDM supports sub-Nyquist
sampling without requiring hardware modifications while preserving delay
resolution. Finally, we show that the second challenge can be addressed by
leveraging the resource-assignment flexibility of the discrete affine Fourier
transform (DAFT) underlying the AFDM waveform.

</details>


### [45] [Age of Job Completion Minimization with Stable Queues](https://arxiv.org/abs/2511.04630)
*Stavros Mitrolaris,Subhankar Banerjee,Sennur Ulukus*

Main category: cs.IT

TL;DR: 本文提出了一种针对具有马尔可夫机的时间隙作业分配系统的调度策略，旨在最大化作业完成数量并最小化采样成本和作业完成时间。


<details>
  <summary>Details</summary>
Motivation: 在具有中央服务器、N个用户和一台马尔可夫机的时间隙作业分配系统中，需要解决如何有效调度作业以最大化每单位时间完成的作业数量的问题。

Method: 本文引入了一个新的度量标准——作业完成时间（age of job completion），并提出了两种调度策略，通过数值评估其性能，以最小化作业完成时间和采样成本。

Result: 在本文提出的两种策略下，作业队列能够保持稳定，并且通过数值评估，证明了这些策略的有效性。

Conclusion: 本文提出的两种策略能够有效地在马尔可夫机作业分配系统中最大化作业完成数量，最小化完成时间和采样成本，并确保作业队列的稳定性。

Abstract: We consider a time-slotted job-assignment system with a central server, N
users and a machine which changes its state according to a Markov chain (hence
called a Markov machine). The users submit their jobs to the central server
according to a stochastic job arrival process. For each user, the server has a
dedicated job queue. Upon receiving a job from a user, the server stores that
job in the corresponding queue. When the machine is not working on a job
assigned by the server, the machine can be either in internally busy or in free
state, and the dynamics of these states follow a binary symmetric Markov chain.
Upon sampling the state information of the machine, if the server identifies
that the machine is in the free state, it schedules a user and submits a job to
the machine from the job queue of the scheduled user. To maximize the number of
jobs completed per unit time, we introduce a new metric, referred to as the age
of job completion. To minimize the age of job completion and the sampling cost,
we propose two policies and numerically evaluate their performance. For both of
these policies, we find sufficient conditions under which the job queues will
remain stable.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [46] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 本文探讨了汇编代码中Tokenization的重要性，评估了不同Tokenization模型和参数选择的影响，旨在优化低级代码分析的Tokenization模型。


<details>
  <summary>Details</summary>
Motivation: Tokenization在汇编代码分析中至关重要，但目前对汇编代码Tokenization的研究不足，存在空白。

Method: 本研究评估了NLP Tokenization模型的内在特性和参数选择（如词汇量大小）。探索了针对汇编代码的预处理定制选项和预Tokenization规则。评估了它们对函数签名预测等下游任务的影响。对各种Tokenization模型进行了深入研究，系统分析了它们在编码汇编指令和捕获语义细微差别方面的效率。通过内在评估，比较了不同分词器在分词效率、词汇压缩和汇编代码表示保真度方面的表现。

Result: 初步研究结果表明，分词器的选择显著影响下游性能，内在指标对外部评估结果具有部分但部完整的预测性。这些结果揭示了内在分词器属性与其在实际汇编代码任务中的效用之间复杂的权衡。

Conclusion: 本研究为优化低级代码分析的Tokenization模型提供了有价值的见解，有助于提高基于自然语言模型的二进制分析工作流程的稳健性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [47] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: 行为数据以图像表示时，多模态大型语言模型（MLLMs）在预测用户下一步购买行为方面的准确性提高了87.5%。


<details>
  <summary>Details</summary>
Motivation: 探讨文本和图像表示的用户行为数据哪种能更有效地最大化MLLM性能。

Method: 提出了一个名为BehaviorLens的系统基准测试框架，通过将交易数据表示为文本段落、散点图和流程图，评估六种MLLMs在用户行为推理中的模态权衡。

Result: 当数据以图像形式表示时，与等效的文本表示相比，多模态大型语言模型（MLLMs）的下一次购买预测准确率提高了87.5%，且没有额外计算成本。

Conclusion: 图像表示的用户行为数据在提高MLLMs预测用户行为准确率方面显著优于文本表示。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [48] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: “数字孪生”框架结合系统提示与探测方法，评估了大型语言模型（LLMs）模拟人类决策行为的能力。研究发现，Llama模型能高度复现人类合作模式，而Qwen模型则与纳什均衡预测更为一致。此方法可不经角色扮演提示，实现群体行为复制，并能对未探索的实验空间生成可测试的假设，为社会科学研究提供新途径。


<details>
  <summary>Details</summary>
Motivation: 目前对大型语言模型（LLMs）在决策和人类行为模拟方面与实际人类决策的一致性知之甚少。这种不一致可能导致实际应用中的危害结果，也可能使LLMs在社会模拟中失效。

Method: 开发了一个博弈论实验的数字孪生框架，并引入了系统的提示和探测框架进行机器行为评估。

Result: Llama模型能高度复现人类合作模式，捕捉人类偏离理性选择理论的行为；Qwen模型与纳什均衡预测紧密对齐。实现了无需基于角色的提示，即可进行人口层面的行为复制。研究还推广了人类测试游戏的范围，生成并预注册了针对新游戏配置的可测试假设。

Conclusion: 经过适当校准的LLMs可以复制人类的总体行为模式，并系统探索未知的实验空间，为社会和行为科学的传统研究提供补充方法，并能生成关于人类社会决策的新经验预测。

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [49] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: 这篇论文旨在挑战一个普遍的假设，即DKT的性能增益源于其模拟知识组件之间双向关系的能力，并证明DKT的优势在于其隐式能力，即将其先决条件关系建模为因果结构。


<details>
  <summary>Details</summary>
Motivation: 以往的研究认为，深度知识追踪（DKT）的性能提升源于其能够模拟不同知识组件（KC）之间的双向关系，从而能够根据学生在一个KC上的表现来推断他们对其他KC的理解。然而，本文对此提出了挑战。

Method: 作者通过将练习关系图修剪成有向无环图（DAG），并在Assistments数据集的因果子集上训练DKT，来证明DKT的预测能力与这些因果结构高度吻合。此外，作者提出了一种利用DKT学习到的表示来提取练习关系DAG的替代方法。

Result: 研究结果表明，DKT的预测能力与因果结构之间存在很强的关联性。DKT的有效性很大程度上是由其近似知识组件之间因果依赖关系的能力所驱动，而不仅仅是简单的关系映射。

Conclusion: 本文的结论是，深度知识追踪（DKT）的优势在于其将先决条件关系建模为因果结构的能力，而非双向关系。这为理解DKT的工作原理提供了新的视角。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [50] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: 这篇论文研究了大型语言模型（LLMs）如何代表文化多样性，并发现尽管可以通过调整提示语来影响模型输出，但LLMs仍然普遍偏向于某些特定国家的文化价值观。


<details>
  <summary>Details</summary>
Motivation: LLMs在全球范围内被广泛使用，但其训练数据和优化目标存在不平衡，这引发了对其能否代表其广泛用户群体的文化多样性的质疑。

Method: 我们使用Hofstede价值观调查模块和世界价值观调查中的63个项目，将其翻译成11种语言，并以包含或不包含不同明确文化视角的提示形式，对10个LLMs进行了探测。

Result: 提示语言和文化视角都会导致LLM输出的变化。尽管有针对性的提示可以在一定程度上使LLM的响应偏向相应国家的主导价值观，但它不能克服模型对数据集中少数几个国家（荷兰、德国、美国和日本）相关价值观的系统性偏见。所有被测试的模型都表现出相似的模式：在大多数话题上产生相当中立的回答，在社会宽容等问题上表现出选择性的进步立场。与指定提示语言相比，明确的文化视角能更好地改善与人类受访者文化价值观的一致性。

Conclusion: LLMs处于一个尴尬的中间地带：它们对提示的变化足够敏感以产生差异，但又过于坚定地锚定在特定的文化默认值上，无法充分代表文化多样性。

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [51] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 这篇论文研究了多智能体AI系统中的异常检测问题，旨在识别系统故障，并提出了一个数据收集流程和两个基准数据集。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统固有的不确定性以及容易出现漂移、循环和输出细节缺失等无声故障，这些故障很难被检测到。

Method: 本文提出了一个数据收集流程，用于捕获用户行为、智能体不确定性和LLM变化，并使用此流程收集并标注了两个包含4,275和894条轨迹的基准数据集。在这些数据集上，评估了监督式（XGBoost）和半监督式（SVDD）异常检测方法。

Result: 监督式（XGBoost）和半监督式（SVDD）方法的性能相当，准确率分别高达98%和96%。

Conclusion: 这项工作首次系统性地研究了多智能体AI系统中的异常检测，为未来的研究提供了数据集、基准和见解。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [52] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: 研究了大型语言模型（LLM）中数值推理错误表示机制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在数值推理方面存在错误，但其潜在的表征机制尚不清楚。我们假设数值属性占据共享的潜在子空间，并研究了两个问题：（1）LLM如何在内部整合单个实体的多个数值属性？，（2）不相关的数值上下文如何扰乱这些表征及其下游输出？

Method: 结合线性探测与偏相关分析和基于提示的脆弱性测试，在不同大小的模型中进行。

Result: 结果表明，LLM编码了真实世界的数值相关性，但倾向于系统地放大它们。此外，不相关的上下文会导致幅度表示发生持续偏移，其下游影响因模型大小而异。

Conclusion: 这些发现揭示了LLM决策中的脆弱性，并为在多属性纠缠下实现更公平、表征感知的控制奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [53] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL是一个去中心化的神经符号框架，通过两阶段协商协议，使多智能体在部分信息和有限通信下进行合作，避免了轨迹级别协调的脆弱性，提高了任务完成率和效率。


<details>
  <summary>Details</summary>
Motivation: 在多智能体合作规划中，智能体需要在信息不完全和通信受限的情况下做出联合决策。轨迹层面的协调往往因为微小的时序或动作偏差而导致冲突。

Method: DR. WELL框架采用两阶段协商协议：首先，智能体提出候选角色并进行推理；其次，在共识和环境约束下，智能体就联合分配达成一致。承诺后，每个智能体独立生成并执行其角色的符号计划，而不暴露详细轨迹。计划通过共享世界模型与执行结果相结合，该模型编码当前状态并在智能体行动时更新。

Result: 通过对合作推块任务的实验，DR. WELL框架中的智能体能够跨回合适应，动态世界模型捕获可重用模式，提高了任务完成率和效率。

Conclusion: DR. WELL框架通过符号计划而非原始轨迹进行推理，避免了脆弱的步骤级对齐，实现了可重用、可同步和可解释的高级操作。动态世界模型通过协商和自我完善，提高了任务完成度和效率，以时间开销换取了不断演进的、更高效的协作策略。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [54] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: LLM-KGFR是一个大型语言模型与知识图谱基础检索器协同工作的框架，旨在解决大型语言模型在知识密集型问题中的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理方面表现出色，但在处理知识密集型问题时，由于上下文和参数知识有限，表现不佳。现有的方法受限于数据集特定的微调和在大型或未知图上的可伸缩性。

Method: 我们提出了LLM-KGFR协同框架，其中LLM与结构化检索器（KGFR）协同工作。KGFR使用LLM生成的描述对关系进行编码，并根据实体在问题中的作用初始化实体，从而实现对未知KG的零样本泛化。为了高效处理大型图，KGFR采用了非对称渐进传播（APP）——一种逐步扩展，选择性地限制高阶节点，同时保留信息丰富的路径。通过节点、边和路径级别的接口，LLM迭代请求候选答案、支持事实和推理路径，形成一个可控的推理循环。

Result: 实验表明，LLM-KGFR在保持可伸缩性和泛化能力的同时，实现了强大的性能。

Conclusion: LLM-KGFR为知识图谱增强推理提供了一个实用的解决方案。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [55] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: 本文提出了Opus工作流评估框架，用于量化工作流的质量和效率，并支持自动化评估、排序和优化。


<details>
  <summary>Details</summary>
Motivation: 量化工作流质量和效率，并实现自动化评估、排序和优化。

Method: 该框架结合了Opus工作流奖励（一个概率函数，通过成功可能性、资源使用和输出增益来估计预期性能）和Opus工作流规范惩罚（一组可测量函数，捕捉内聚、耦合、可观察性和信息卫生方面的结构和信息质量），形成一个统一的优化公式。

Result: 实现了工作流的直接比较、评分和优化。

Conclusion: Opus工作流评估框架有效地量化了工作流的质量和效率，并为自动化评估、排序和优化提供了有效工具。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [56] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 该研究提出了一个多智能体预测编码框架，旨在最小化智能体间的相互不确定性，从而在部分可观测和带宽受限的多智能体系统中实现连贯的空间记忆共享和重建。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，共享和重建一致的空间记忆是一个关键挑战，因为部分可观测性和有限的带宽经常导致协调中的灾难性失败。

Method: 本研究引入了一个多智能体预测编码框架，将协调表述为智能体之间相互不确定性的最小化。该框架以信息瓶颈目标为基础，促使智能体学习何时、何地以及如何进行通信。该框架的基础是一个类似于网格单元的度量作为自我定位的内部空间编码，这自发地出现于自监督运动预测。在此内部空间代码的基础上，智能体逐渐发展出一种带宽高效的通信机制和专门的神经元群体，用于编码伙伴的位置：这是一种海马体社交地点细胞（SPCs）的人工模拟。这些社交表征通过一个分层强化学习策略进一步实现，该策略积极探索以减少联合不确定性。

Result: 在Memory-Maze基准测试中，该方法在带宽限制下表现出卓越的鲁棒性：当带宽从128位/步缩小到4位/步时，成功率从73.5%到64.4%逐渐下降，而完全广播基线则从67.6%骤降到28.6%。

Conclusion: 研究结果为复杂的社会表征如何从统一的预测驱动中产生，并最终形成社会集体智能，奠定了理论上合理且生物学上可信的基础。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [57] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: RLoverfitting (RL过拟合) 会导致模型在训练奖励上表现良好但泛化能力下降，原因在于策略过度专业化和灾难性遗忘。本文介绍了 RLoop，一个基于迭代策略初始化的自我改进框架，通过探索、过滤成功轨迹、创建专家数据集，并使用拒绝采样微调 (RFT) 来优化初始策略，从而有效缓解遗忘并显著提高泛化能力，平均准确率提高 9%，pass@32 提高超过 15%。


<details>
  <summary>Details</summary>
Motivation: RLoverfitting会导致模型在训练奖励上表现良好但泛化能力下降，原因在于策略过度专业化和灾难性遗忘。

Method: RLoop 框架通过迭代策略初始化实现自我改进：首先使用强化学习探索解决方案空间，然后过滤成功的轨迹以创建专家数据集。该数据集通过拒绝采样微调 (RFT) 来优化初始策略，为下一次迭代创建一个更好的起点。

Result: RLoop 有效缓解了遗忘并显著提高了泛化能力，与传统的强化学习相比，平均准确率提高了 9%，pass@32 提高了 15% 以上。

Conclusion: RLoop 通过迭代策略初始化，有效地将瞬态策略变化转化为稳定的性能提升，从而解决了强化学习中的过拟合问题，并通过实验证明了其在提高泛化能力方面的显著效果。

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [58] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: AdversariaLLM是一个用于LLM越狱鲁棒性研究的工具箱，旨在解决当前LLM安全和鲁棒性研究中实现、数据集和评估方法碎片化的问题，提高研究的可重现性和可比性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）安全性和鲁棒性研究的快速发展导致了实现、数据集和评估方法的碎片化，这使得研究的复现性和可比性面临挑战，阻碍了有意义的进展。

Method: AdversariaLLM工具箱实现了12种对抗性攻击算法，集成了7个基准数据集（涵盖有害性、过度拒绝和效用评估），并通过Hugging Face提供了对各种开源LLM的访问。它还包含计算资源跟踪、确定性结果和分布评估技术等高级功能，并集成了JudgeZoo进行评判。

Result: AdversariaLLM通过提供集成攻击算法、数据集、LLM访问、高级评估和评判功能，为LLM越狱鲁棒性研究建立了一个统一且可重现的平台。

Conclusion: AdversariaLLM旨在为LLM安全领域透明、可比较和可重现的研究奠定坚实基础，解决当前研究碎片化的问题。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [59] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: 该研究提出了一个名为RxSafeBench的基准测试，用于评估大型语言模型在医疗咨询中保障用药安全的能力，并发现现有LLMs在整合禁忌症和药物相互作用知识方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型在医疗领域的应用研究中，用药安全方面由于缺乏真实世界数据集和评估方法，研究相对有限。

Method: 1. 提出了一个模拟临床咨询的评估框架。 2. 构建了一个包含6,725个禁忌症、28,781个药物相互作用和14,906个适应症-药物对的用药安全数据库RxRisk DB。 3. 采用两阶段过滤策略生成了2,443个高质量咨询场景，形成了RxSafeBench基准。 4. 使用结构化多项选择题评估了领先的开源和专有LLMs，测试它们在模拟患者情境下推荐安全药物的能力。

Result: 目前的LLMs在整合禁忌症和药物相互作用知识方面表现不佳，尤其是在风险是隐含而非明确的情况下。

Conclusion: RxSafeBench是首个全面评估LLMs用药安全的基准，为提高AI驱动临床决策支持系统的可靠性提供了见解和方法。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [60] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: 这篇论文提出了一个名为 MGV 的新框架，该框架通过在生成和验证之前引入监控过程，扩展了传统的生成-验证范式。MGV 旨在通过整合元认知理论来解决模型在推理过程中过早地陷入次优路径的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时推理架构，如生成-验证范式，优先考虑生成和验证，但忽略了决定何时以及如何开始推理的监控过程。这种遗漏可能导致前缀支配陷阱，即模型过早地陷入次优推理路径且很少能恢复，导致大约 20% 的准确率损失。

Method: 本文通过将 Flavell 和 Nelson & Narens 的元认知理论形式化为计算规范，提出了监控-生成-验证（MGV）框架。MGV 通过在生成开始前添加捕获元认知体验（从难度评估到置信度判断）的明确监控，并利用验证反馈改进未来的监控，从而扩展了生成-验证范式。

Result: 尽管本文没有提供实证验证，但它首次系统地将基础元认知理论转化为计算模型，为理解推理系统故障提供了原则性词汇，并为未来的测试时推理设计提出了具体的架构干预措施。

Conclusion: MGV 框架通过整合元认知监控来解决现有推理架构的不足，有望提高模型的推理准确性。该工作为未来的研究提供了理论基础和方向，特别是在元认知与人工智能的结合方面。

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [61] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: 本文介绍了一种名为“迭代遗憾最小化微调”（Iterative RMFT）的后训练程序，旨在提高大型语言模型（LLMs）在交互式和动态环境中的决策能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在决策（DM）方面存在困难，即使在基本的在线决策问题中也难以实现低遗憾或有效的探索-利用权衡，因为它们最初并非为此目的设计。

Method: Iterative RMFT通过重复地将低遗憾的决策轨迹提取回基础模型来工作。在每次迭代中，模型会生成多个决策轨迹，选择其中遗憾最小的k个，并使用它们进行微调。与现有方法不同，我们的方法利用遗憾度量来激发模型自身的决策能力和推理原理，而不是依赖于预定义的决策算法或手动制作的思维链模板。

Result: 实验结果表明，Iterative RMFT显著提升了LLMs的决策性能，适用于从具有数值输入/输出的Transformer到开源LLM以及像GPT-4o mini这样的高级闭源模型。其在输出和推理格式上的灵活性使其能够泛化到具有不同时间范围、动作空间、奖励过程和自然语言上下文的任务。

Conclusion: Iterative RMFT为增强LLMs的决策能力提供了一个原则性的、通用的后训练框架。在简化设置下，单层Transformer在此范式下可以作为无遗憾学习器。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [62] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: 该论文介绍了CoRPO，一种解决GRPO在处理非二元奖励时缺陷的新策略优化方法，并在代码验证任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: GRPO在处理非二元奖励时存在问题，其群组平均基线可能导致对错误行为的错误强化。

Method: CoRPO引入了一种自适应基线，设定了最低质量阈值，确保失败的解决方案不会被正向强化。当策略达到该阈值后，基线会自动切换到相对偏好模式，以寻求最优解决方案。

Result: CoRPO在代码验证任务中表现出更稳定的收敛性和更好的域外泛化能力。

Conclusion: CoRPO是使LLM通过强化学习真正学习新能力的关键一步，它通过处理丰富的多维度反馈来实现这一目标。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [63] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 该研究提出了一个数据驱动的稀疏感知（DSS）框架，该框架与EPA-SWMM集成，以优化传感器布局并重建雨水管网中的峰值流量。


<details>
  <summary>Details</summary>
Motivation: 在有限的资源下，如何监测城市排水管网并预测流量状况是一个重大挑战。

Method: 该研究利用SWMM模型生成峰值流量剖面的训练数据集，并应用DSS框架（利用奇异值分解进行降维，QR分解进行传感器分配）来识别最佳监测节点。

Result: 在77个节点中，三个最佳放置的传感器实现了令人满意的重建性能，Nash-Sutcliffe效率（NSE）值为0.92-0.95。该模型对测量不确定性具有良好的鲁棒性。

Conclusion: DSS框架平衡了计算效率和物理可解释性，能够以最少的传感器实现高精度流量重建。该框架可以进一步与预测模型集成，以实现洪水预警和实时控制。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [64] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 该论文提出了一个将歧义视为合作交互特征的框架，用于处理表格数据自然语言接口中的歧义查询。


<details>
  <summary>Details</summary>
Motivation: 处理表格数据自然语言接口中查询固有的歧义问题。

Method: 区分合作查询和非合作查询的框架。将此框架应用于15个流行表格问答和分析数据集的评估中。

Result: 发现现有数据集中查询类型混杂，不利于评估系统执行准确性和解释能力。

Conclusion: 将研究视角从消除歧义转向通过合作解决查询，为表格数据自然语言界面的设计和评估提供了新的方向。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [65] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 本文介绍了一个审计框架，用于衡量问题集在参与者提出的问题中的代表性，核心是“公正代表（Justified Representation, JR）”的社会选择概念及其算法实现。研究还应用该方法评估了历史协商会议中专家小组问题、整数线性规划选择问题以及大型语言模型生成摘要问题的代表性。


<details>
  <summary>Details</summary>
Motivation: 在公民大会和审议式民意调查等许多审议过程中，参与者有机会直接与专家互动。由于时间限制，从参与者提出的问题中选择有限数量的问题是一个挑战。因此，如何选择能最好地代表所有参与者利益的少量问题是关键。

Method: 本文引入了一个审计框架来衡量问题集的代表性，该框架基于“公正代表（JR）”的社会选择概念。研究提出了在通用效用设置中审计JR的算法，其中最有效的算法运行时间为$O(mn\log n)$，其中$n$是参与者数量，$m$是提议的问题数量。研究将此审计方法应用于历史审议，比较了实际向专家小组提出的问题（由主持人选择）、通过整数线性规划选择的参与者问题以及大型语言模型（LLM）生成的摘要问题的代表性。

Result: 研究结果强调了大型语言模型（LLM）在支持审议过程方面的潜力和当前局限性。

Conclusion: 通过将本文提出的方法整合到一个已被50多个国家、数百次审议中使用的在线审议平台，可以帮助实践者审计和改进未来审议中的代表性。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [66] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一种神经符号方法，通过从思维链推理中提取和验证形式逻辑论证，提高了大型语言模型（LLMs）推理的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多步推理中可能会有错误或不可靠的逻辑，即使答案正确，也会降低在关键场景下的信任度。

Method: VeriCoT将每个思维链推理步骤形式化为一阶逻辑，并识别源上下文、常识知识或先前的推理步骤中的前提。它使用自动求解器验证逻辑有效性，并识别无根据或错误的推理步骤。

Result: 在ProofWriter、LegalBench和BioASQ数据集上的实验表明，VeriCoT能有效识别错误的推理，并能很好地预测最终答案的正确性。通过VeriCoT的验证信号进行自反思、监督微调和偏好微调，可以进一步提高推理的有效性和准确性。

Conclusion: VeriCoT通过结合神经符号方法，显著提升了LLMs推理过程的透明度、可信度和准确性，是解决LLMs推理可靠性问题的一个有效方案。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [67] [Laugh, Relate, Engage: Stylized Comment Generation for Short Videos](https://arxiv.org/abs/2511.03757)
*Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个名为LOLGORITHM的模块化多智能体系统，用于可控的短视频评论生成，该系统通过处理视频输入和实现细粒度的风格控制，显著优于基线模型，并在抖音和YouTube上均取得了90%以上的用户偏好率。


<details>
  <summary>Details</summary>
Motivation: 短视频平台上的评论在促进社区参与和内容再创作方面发挥着至关重要的作用，然而，生成符合平台规范且具有风格多样性和上下文意识的评论仍然是一个重大挑战。

Method: 本文提出了一个名为LOLGORITHM的模块化多智能体系统（MAS），用于可控的短视频评论生成。该系统集成了视频分割、上下文和情感分析以及风格感知提示构建，支持六种不同的评论风格：双关语（同音词）、押韵、表情包应用、讽刺（反语）、 MLLM直接处理视频输入，并通过明确的提示标记和少量示例实现细粒度的风格控制。为了支持开发和评估，我们使用抖音和YouTube的官方API构建了一个双语数据集，涵盖了喜剧小品、日常生活笑话、有趣的动物剪辑、幽默评论和脱口秀这五种流行的视频类型。

Result: 评估结合了原创性、相关性和风格一致性的自动化指标，以及一项涉及40个视频和105名参与者的大规模人类偏好研究。结果表明，LOLGORITHM显著优于基线模型，在抖音上获得了90%以上的偏好率，在YouTube上获得了87.55%的偏好率。

Conclusion: 这项工作提出了一个可扩展的、文化适应的短视频平台风格化评论生成框架，为增强用户参与度和创意互动提供了一条有前景的途径。

Abstract: Short-video platforms have become a central medium in the modern Internet
landscape, where efficient information delivery and strong interactivity are
reshaping user engagement and cultural dissemination. Among the various forms
of user interaction, comments play a vital role in fostering community
participation and enabling content re-creation. However, generating comments
that are both compliant with platform guidelines and capable of exhibiting
stylistic diversity and contextual awareness remains a significant challenge.
We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for
controllable short-video comment generation. The system integrates video
segmentation, contextual and affective analysis, and style-aware prompt
construction. It supports six distinct comment styles: puns (homophones),
rhyming, meme application, sarcasm (irony), plain humor, and content
extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM
directly processes video inputs and achieves fine-grained style control through
explicit prompt markers and few-shot examples. To support development and
evaluation, we construct a bilingual dataset using official APIs from Douyin
(Chinese) and YouTube (English), covering five popular video genres: comedy
skits, daily life jokes, funny animal clips, humorous commentary, and talk
shows. Evaluation combines automated metrics originality, relevance, and style
conformity with a large-scale human preference study involving 40 videos and
105 participants. Results show that LOLGORITHM significantly outperforms
baseline models, achieving preference rates of over 90% on Douyin and 87.55% on
YouTube. This work presents a scalable and culturally adaptive framework for
stylized comment generation on short-video platforms, offering a promising path
to enhance user engagement and creative interaction.

</details>


### [68] [Contamination Detection for VLMs using Multi-Modal Semantic Perturbation](https://arxiv.org/abs/2511.03774)
*Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee*

Main category: cs.LG

TL;DR: 本文提出了一种针对视觉-语言模型（VLMs）的污染检测方法，通过多模态语义扰动来识别模型是否因测试集泄漏而表现虚高。


<details>
  <summary>Details</summary>
Motivation: 目前，视觉-语言模型（VLMs）在多项基准任务中表现出色，但其在互联网规模的预训练语料库（通常是专有的）中可能存在测试集泄露问题，导致性能虚高。现有针对大型语言模型（LLMs）的缓解策略（如数据净化和基准重新设计）并不适用于VLMs的污染检测，因此需要开发新的检测方法。

Method: 本文首先故意污染了流行的基准测试上的开源VLMs，并发现现有检测方法要么完全失败，要么表现不一致。在此基础上，本文提出了一种新颖而有效的检测方法，该方法基于多模态语义扰动，并通过控制扰动下污染模型泛化能力的下降来检测污染。

Result: 通过有意污染开源VLMs，并使用多模态语义扰动的方法，本文成功检测出污染模型在受控扰动下泛化能力的失效。

Conclusion: 本文提出了一种新颖的多模态语义扰动检测方法，能够有效、鲁棒地检测视觉-语言模型中的测试集泄漏污染，并已在多种实际污染策略下验证了其有效性。未来将公开发布代码和扰动数据集。

Abstract: Recent advances in Vision-Language Models (VLMs) have achieved
state-of-the-art performance on numerous benchmark tasks. However, the use of
internet-scale, often proprietary, pretraining corpora raises a critical
concern for both practitioners and users: inflated performance due to test-set
leakage. While prior works have proposed mitigation strategies such as
decontamination of pretraining data and benchmark redesign for LLMs, the
complementary direction of developing detection methods for contaminated VLMs
remains underexplored. To address this gap, we deliberately contaminate
open-source VLMs on popular benchmarks and show that existing detection
approaches either fail outright or exhibit inconsistent behavior. We then
propose a novel simple yet effective detection method based on multi-modal
semantic perturbation, demonstrating that contaminated models fail to
generalize under controlled perturbations. Finally, we validate our approach
across multiple realistic contamination strategies, confirming its robustness
and effectiveness. The code and perturbed dataset will be released publicly.

</details>


### [69] [FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features](https://arxiv.org/abs/2511.03806)
*Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong*

Main category: cs.LG

TL;DR: FusionDP是一个两阶段框架，通过利用大型基础模型Impute敏感特征，并引入改进的DP-SGD算法进行模型训练，以在保证严格的特征级隐私的同时提升模型效用。


<details>
  <summary>Details</summary>
Motivation: 在差分隐私机器学习中，敏感训练数据的隐私保护至关重要。然而，实际中可能只需要对部分特征进行隐私保护。传统的DP-SGD对一个样本中的所有特征强制执行隐私保护，导致噪声注入过多和效用显著下降。

Method: FusionDP包含两个步骤。首先，它利用大型基础模型，在给定非敏感特征的情况下估算敏感特征，将其作为外部先验，在模型训练期间无需访问真实值即可提供敏感属性的高质量估计。其次，引入了一种改进的DP-SGD算法，该算法在原始特征和估算特征上训练模型，同时正式保留原始敏感特征的隐私。

Result: FusionDP在PhysioNet的表格数据脓毒症预测任务和MIMIC-III的临床笔记分类任务上进行了评估。结果表明，与现有的隐私保护基线相比，FusionDP显著提高了模型性能，同时保持了严格的特征级隐私。

Conclusion: 基础模型驱动的插补，可以增强了各种模态的隐私-效用权衡。

Abstract: Ensuring the privacy of sensitive training data is crucial in
privacy-preserving machine learning. However, in practical scenarios, privacy
protection may be required for only a subset of features. For instance, in ICU
data, demographic attributes like age and gender pose higher privacy risks due
to their re-identification potential, whereas raw lab results are generally
less sensitive. Traditional DP-SGD enforces privacy protection on all features
in one sample, leading to excessive noise injection and significant utility
degradation. We propose FusionDP, a two-step framework that enhances model
utility under feature-level differential privacy. First, FusionDP leverages
large foundation models to impute sensitive features given non-sensitive
features, treating them as external priors that provide high-quality estimates
of sensitive attributes without accessing the true values during model
training. Second, we introduce a modified DP-SGD algorithm that trains models
on both original and imputed features while formally preserving the privacy of
the original sensitive features. We evaluate FusionDP on two modalities: a
sepsis prediction task on tabular data from PhysioNet and a clinical note
classification task from MIMIC-III. By comparing against privacy-preserving
baselines, our results show that FusionDP significantly improves model
performance while maintaining rigorous feature-level privacy, demonstrating the
potential of foundation model-driven imputation to enhance the privacy-utility
trade-off for various modalities.

</details>


### [70] [Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations](https://arxiv.org/abs/2511.03807)
*Shivogo John*

Main category: cs.LG

TL;DR: 这篇论文提出了一种自适应可解释性框架，用于解决概念漂移下信用评分模型解释的不稳定性和潜在不公平性问题。


<details>
  <summary>Details</summary>
Motivation: 传统的解释技术（如SHAP）在概念漂移发生时，解释会变得不稳定且可能不公平，因为它们假设数据是静态的。

Method: 本文通过将XGBoost预测模型与三种自适应SHAP变体相结合来解决上述挑战：(A) 针对特征分布变化的逐片解释重新加权，(B) 使用滑动窗口背景样本的漂移感知SHAP重新基准化，以及(C) 使用增量岭回归的在线替代校准。

Result: 自适应方法，特别是重新基准化和基于替代的解释，在不降低预测精度的情况下，显著提高了时间稳定性并减少了不同人口群体之间的差异影响。鲁棒性测试也证实了自适应解释在真实世界漂移条件下的弹性。

Conclusion: 这些发现确立了自适应可解释性作为在数据驱动的信用系统以及更广泛的、决策模型随人口变化而演变的任何领域中，维持透明度、问责制和道德可靠性的实用机制。

Abstract: Evolving borrower behaviors, shifting economic conditions, and changing
regulatory landscapes continuously reshape the data distributions underlying
modern credit-scoring systems. Conventional explainability techniques, such as
SHAP, assume static data and fixed background distributions, making their
explanations unstable and potentially unfair when concept drift occurs. This
study addresses that challenge by developing adaptive explanation frameworks
that recalibrate interpretability and fairness in dynamically evolving credit
models. Using a multi-year credit dataset, we integrate predictive modeling via
XGBoost with three adaptive SHAP variants: (A) per-slice explanation
reweighting that adjusts for feature distribution shifts, (B) drift-aware SHAP
rebaselining with sliding-window background samples, and (C) online surrogate
calibration using incremental Ridge regression. Each method is benchmarked
against static SHAP explanations using metrics of predictive performance (AUC,
F1), directional and rank stability (cosine, Kendall tau), and fairness
(demographic parity and recalibration). Results show that adaptive methods,
particularly rebaselined and surrogate-based explanations, substantially
improve temporal stability and reduce disparate impact across demographic
groups without degrading predictive accuracy. Robustness tests, including
counterfactual perturbations, background sensitivity analysis, and
proxy-variable detection, confirm the resilience of adaptive explanations under
real-world drift conditions. These findings establish adaptive explainability
as a practical mechanism for sustaining transparency, accountability, and
ethical reliability in data-driven credit systems, and more broadly, in any
domain where decision models evolve with population change.

</details>


### [71] [Optimizing Reasoning Efficiency through Prompt Difficulty Prediction](https://arxiv.org/abs/2511.03808)
*Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata*

Main category: cs.LG

TL;DR: 这篇论文提出了一种路由方法，通过将问题分配给能力足够解决它的最小模型，以在不牺牲准确性的前提下，降低大型语言模型部署的计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务上表现出色，但由于其模型大小和较长的推理链，部署成本高昂。

Method: 作者利用S1.1-32B模型的中间表示，训练轻量级预测器来评估问题难度或模型正确性，从而在推理模型池中进行路由。

Result: 在各种数学基准测试中，与随机分配相比，路由方法提高了效率，并且在使用显著更少计算量的情况下，达到了S1.1-32B模型的性能。

Conclusion: 难度感知的路由方法对于经济高效地部署推理模型非常有效。

Abstract: Reasoning language models perform well on complex tasks but are costly to
deploy due to their size and long reasoning traces. We propose a routing
approach that assigns each problem to the smallest model likely to solve it,
reducing compute without sacrificing accuracy. Using intermediate
representations from s1.1-32B, we train lightweight predictors of problem
difficulty or model correctness to guide routing across a pool of reasoning
models. On diverse math benchmarks, routing improves efficiency over random
assignment and matches s1.1-32B's performance while using significantly less
compute. Our results demonstrate that difficulty-aware routing is effective for
cost-efficient deployment of reasoning models.

</details>


### [72] [Complexity as Advantage: A Regret-Based Perspective on Emergent Structure](https://arxiv.org/abs/2511.04590)
*Oshri Naparstek*

Main category: cs.LG

TL;DR: 该论文提出了“复杂性即优势（CAA）”框架，该框架根据一系列观察者来定义系统的复杂性，并评估系统对不同观察者试图建模时产生的预测遗憾。


<details>
  <summary>Details</summary>
Motivation: 此研究旨在通过引入“复杂性即优势（CAA）”框架，来解决传统复杂性度量方法无法捕捉系统对不同观察者产生差异化影响的问题。该框架试图从观察者角度重新定义复杂性，从而更好地理解为什么复杂性在功能上是有价值的。

Method: CAA框架通过衡量系统为试图建模的不同观察者带来的预测遗憾来定义复杂性。当系统对某些观察者来说很容易建模，而对另一些观察者来说却很难时，就产生了信息优势，此时系统被认为是复杂的。该方法将多种涌现行为概念（如多尺度熵、预测信息和观察者依赖结构）统一起来。

Result: CAA框架统一了多尺度熵、预测信息和观察者依赖结构等多种涌现行为概念。该框架表明，“有趣的”系统是那些能够为不同观察者带来差异化遗憾的系统，从而为复杂性的功能价值提供了量化依据。

Conclusion: 该论文成功提出了一个新颖的复杂性定义框架——复杂性即优势（CAA），该框架将复杂性视为相对于观察者的属性，并强调了复杂性在产生信息优势和功能价值方面的作用。这为理解学习、演化和人工智能系统提供了新的视角。

Abstract: We introduce Complexity as Advantage (CAA), a framework that defines the
complexity of a system relative to a family of observers. Instead of measuring
complexity as an intrinsic property, we evaluate how much predictive regret a
system induces for different observers attempting to model it. A system is
complex when it is easy for some observers and hard for others, creating an
information advantage. We show that this formulation unifies several notions of
emergent behavior, including multiscale entropy, predictive information, and
observer-dependent structure. The framework suggests that "interesting" systems
are those positioned to create differentiated regret across observers,
providing a quantitative grounding for why complexity can be functionally
valuable. We demonstrate the idea through simple dynamical models and discuss
implications for learning, evolution, and artificial agents.

</details>


### [73] [Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems](https://arxiv.org/abs/2511.04594)
*Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra*

Main category: cs.LG

TL;DR: 本文研究了分散式多智能体随机最短路径问题（Dec-MASSPs），首次针对线性函数逼近下的Dec-MASSPs建立了遗憾下界，揭示了该问题的学习难度。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）在蜂群机器人和交通路由等应用中至关重要，其中智能体必须以去中心化的方式进行协调以实现共同目标。随机最短路径（SSP）问题为建模这种设置下的去中心化控制提供了自然的框架。虽然SSP中的学习问题在单智能体设置中得到了广泛研究，但去中心化的多智能体变体在很大程度上仍未被探索。

Method: 本文在线性函数逼近下研究了分散式多智能体随机最短路径问题（Dec-MASSPs），其中转换动力学和成本使用线性模型表示。通过应用新颖的基于对称性的论证，确定了最优策略的结构。

Result: 本文的主要贡献是首次针对该设定建立了遗憾下界，该下界基于为任意数量的智能体n构建难以学习的实例。其遗憾下界为Ω(√K)（K为 эпизодов），凸显了Dec-MASSPs固有的学习难度。

Conclusion: 这些见解阐明了分散式控制的学习复杂性，并能进一步指导多智能体系统中高效学习算法的设计。

Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics
and traffic routing, where agents must coordinate in a decentralized manner to
achieve a common objective. Stochastic Shortest Path (SSP) problems provide a
natural framework for modeling decentralized control in such settings. While
the problem of learning in SSP has been extensively studied in single-agent
settings, the decentralized multi-agent variant remains largely unexplored. In
this work, we take a step towards addressing that gap. We study decentralized
multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the
transition dynamics and costs are represented using linear models. Applying
novel symmetry-based arguments, we identify the structure of optimal policies.
Our main contribution is the first regret lower bound for this setting based on
the construction of hard-to-learn instances for any number of agents, $n$. Our
regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the
inherent learning difficulty in Dec-MASSPs. These insights clarify the learning
complexity of decentralized control and can further guide the design of
efficient learning algorithms in multi-agent systems.

</details>


### [74] [Higher-Order Causal Structure Learning with Additive Models](https://arxiv.org/abs/2511.03831)
*James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang*

Main category: cs.LG

TL;DR: 这篇论文将因果添加剂模型（CAM）扩展到具有高阶交互的添加剂模型，引入了有向无环超图来表示模块化结构，并提供了可识别性结果和改进的算法，以在因果发现中显式处理交互。


<details>
  <summary>Details</summary>
Motivation: 尽管现实世界中存在大量表现出高阶机制的过程，但因果发现中对交互作用的明确处理却很少受到关注。因此，本文旨在扩展因果添加剂模型（CAM）以处理具有高阶交互的添加剂模型。

Method: 本文引入了有向无环超图（hyper DAG）来表示具有高阶交互的因果结构，并提供了处理这种新结构的必要定义和理论工具。作者还对超有向无环图的可识别性进行了研究，并扩展了典型的马尔可夫等价类。随后，他们开发了贪婪CAM算法的扩展版本，以处理更复杂的超有向无环图搜索空间。

Result: 通过引入有向无环超图，以及对超有向无环图的可识别性证明，本文在理论上扩展了因果发现领域。实验部分证明了所提出的扩展贪婪CAM算法在合成实验中的经验有效性，表明学习更复杂的超图结构可以带来更好的经验结果。

Conclusion: 本文成功地将因果添加剂模型扩展到具有高阶交互的添加剂模型，通过引入有向无环超图，为在因果发现中显式处理交互提供了一种新的理论框架和算法。研究结果强调了考虑高阶交互在因果结构学习中的重要性，尤其是其在实际应用中可能带来的性能提升。

Abstract: Causal structure learning has long been the central task of inferring causal
insights from data. Despite the abundance of real-world processes exhibiting
higher-order mechanisms, however, an explicit treatment of interactions in
causal discovery has received little attention. In this work, we focus on
extending the causal additive model (CAM) to additive models with higher-order
interactions. This second level of modularity we introduce to the structure
learning problem is most easily represented by a directed acyclic hypergraph
which extends the DAG. We introduce the necessary definitions and theoretical
tools to handle the novel structure we introduce and then provide
identifiability results for the hyper DAG, extending the typical Markov
equivalence classes. We next provide insights into why learning the more
complex hypergraph structure may actually lead to better empirical results. In
particular, more restrictive assumptions like CAM correspond to easier-to-learn
hyper DAGs and better finite sample complexity. We finally develop an extension
of the greedy CAM algorithm which can handle the more complex hyper DAG search
space and demonstrate its empirical usefulness in synthetic experiments.

</details>


### [75] [Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels](https://arxiv.org/abs/2511.03953)
*Wuxia Chen,Taposh Banerjee,Vahid Tarokh*

Main category: cs.LG

TL;DR: 本文关注马尔可夫过程中未知转移核的最快变化检测问题，提出了一种基于条件得分学习的CUSUM程序，并对其进行了理论分析和实验验证。


<details>
  <summary>Details</summary>
Motivation: 在未知转移核的马尔可夫过程中，如何进行最快变化检测是一个重要的挑战。传统的似然评估方法计算成本高，因此需要一种新的方法来避免显式似然评估。

Method: 本文提出直接从样本对 (x,y) 中学习条件得分 ∇y log p(y|x)，从而避免了显式似然评估。在此基础上，开发了一种基于得分的CUSUM程序，利用条件Hyvarinen得分差异来检测核中的变化。为了确保有界增量，提出了统计量的截断版本。

Result: 通过Hoeffding不等式，证明了均匀遍历马尔可夫过程的平均误报时间的指数下界。同时，证明了检测延迟的渐近上界。

Conclusion: 本文提出的方法为高维马尔可夫模型中的基于得分的检测提供了理论保证和实际可行性。

Abstract: We address the problem of quickest change detection in Markov processes with
unknown transition kernels. The key idea is to learn the conditional score
$\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$ directly from sample pairs
$( \mathbf{x},\mathbf{y})$, where both $\mathbf{x}$ and $\mathbf{y}$ are
high-dimensional data generated by the same transition kernel. In this way, we
avoid explicit likelihood evaluation and provide a practical way to learn the
transition dynamics. Based on this estimation, we develop a score-based CUSUM
procedure that uses conditional Hyvarinen score differences to detect changes
in the kernel. To ensure bounded increments, we propose a truncated version of
the statistic. With Hoeffding's inequality for uniformly ergodic Markov
processes, we prove exponential lower bounds on the mean time to false alarm.
We also prove asymptotic upper bounds on detection delay. These results give
both theoretical guarantees and practical feasibility for score-based detection
in high-dimensional Markov models.

</details>


### [76] [From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification](https://arxiv.org/abs/2511.03828)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: 为了解决离线到在线强化学习中由于分布偏移导致的挑战，该论文提出了Energy-Guided Diffusion Stratification (StratDiff) 方法。StratDiff使用扩散模型从离线数据中学习先验知识，并通过基于能量的函数进行优化，以改善策略模仿和在线微调期间生成类离线动作。然后，根据KL散度将训练批次分为离线类和在线类子集，并分别应用离线和在线学习策略进行更新。实验证明，StratDiff在D4RL基准上显著优于现有方法，提高了适应性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习向在线强化学习过渡时，由于离线数据中固定的行为策略与在线学习过程中不断演变的策略之间存在分布偏移，导致了严重的挑战。尽管这个问题广为人知，但很少有方法尝试明确评估或利用离线数据的分布结构，这在根据不同类型样本调整学习策略方面留下了研究空白。

Method: 本研究提出了Energy-Guided Diffusion Stratification (StratDiff) 方法。该方法首先部署一个扩散模型从离线数据集中学习先验知识。然后，通过基于能量的函数对这些知识进行细化，以改进策略模仿并在在线微调期间生成类似离线的动作。接着，为每个样本计算生成的动作与相应的采样动作之间的KL散度，并用这个散度将训练批次分层为“离线类”和“在线类”子集。最后，对离线类样本使用离线目标进行更新，而在线类样本则遵循在线学习策略。

Result: 通过将StratDiff与现有的Cal-QL和IQL方法结合，在D4RL基准上进行了广泛的实证评估。实验结果表明，StratDiff显著优于现有方法，在各种强化学习设置中展现出增强的适应性和更稳定的性能。

Conclusion: 本论文提出了StratDiff方法，有效解决了离线到在线强化学习中的分布偏移问题。该方法通过结合扩散模型和能量函数学习离线数据分布，并根据样本特征分层更新策略，显著提高了在线微调的效率和稳定性。实验证明了StratDiff的优越性，为离线到在线强化学习的过渡提供了新的解决方案。

Abstract: Transitioning from offline to online reinforcement learning (RL) poses
critical challenges due to distributional shifts between the fixed behavior
policy in the offline dataset and the evolving policy during online learning.
Although this issue is widely recognized, few methods attempt to explicitly
assess or utilize the distributional structure of the offline data itself,
leaving a research gap in adapting learning strategies to different types of
samples. To address this challenge, we propose an innovative method,
Energy-Guided Diffusion Stratification (StratDiff), which facilitates smoother
transitions in offline-to-online RL. StratDiff deploys a diffusion model to
learn prior knowledge from the offline dataset. It then refines this knowledge
through energy-based functions to improve policy imitation and generate
offline-like actions during online fine-tuning. The KL divergence between the
generated action and the corresponding sampled action is computed for each
sample and used to stratify the training batch into offline-like and
online-like subsets. Offline-like samples are updated using offline objectives,
while online-like samples follow online learning strategies. We demonstrate the
effectiveness of StratDiff by integrating it with off-the-shelf methods Cal-QL
and IQL. Extensive empirical evaluations on D4RL benchmarks show that StratDiff
significantly outperforms existing methods, achieving enhanced adaptability and
more stable performance across diverse RL settings.

</details>


### [77] [Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations](https://arxiv.org/abs/2511.04000)
*Kyaw Hpone Myint,Zhe Wu,Alexandre G. R. Day,Giri Iyengar*

Main category: cs.LG

TL;DR: 该研究介绍了一种高效、可扩展的决策树元学习综合预训练数据生成方法。


<details>
  <summary>Details</summary>
Motivation: 传统的决策树在金融和医疗等高风险领域因其可解释性而被广泛使用，但其预训练过程面临计算成本高昂和数据生成灵活性不足的挑战。

Method: 该方法通过合成方式对接近最优的决策树进行采样，从而创建大规模、真实的数据集，并结合MetaTree transformer架构进行元学习。

Result: 通过这种方法，MetaTree transformer在性能上可以与在真实数据上预训练或使用计算成本高昂的最优决策树相媲美。

Conclusion: 该策略显著降低了计算成本，增强了数据生成的灵活性，并为可解释决策树模型的元学习提供了可扩展且高效的途径。

Abstract: Decision trees are widely used in high-stakes fields like finance and
healthcare due to their interpretability. This work introduces an efficient,
scalable method for generating synthetic pre-training data to enable
meta-learning of decision trees. Our approach samples near-optimal decision
trees synthetically, creating large-scale, realistic datasets. Using the
MetaTree transformer architecture, we demonstrate that this method achieves
performance comparable to pre-training on real-world data or with
computationally expensive optimal decision trees. This strategy significantly
reduces computational costs, enhances data generation flexibility, and paves
the way for scalable and efficient meta-learning of interpretable decision tree
models.

</details>


### [78] [On Joint Regularization and Calibration in Deep Ensembles](https://arxiv.org/abs/2511.04160)
*Laurits Fredsgaard,Mikkel N. Schmidt*

Main category: cs.LG

TL;DR: 这篇论文研究了联合调整深度集成模型超参数对模型性能和不确定性校准的影响。


<details>
  <summary>Details</summary>
Motivation: 探索联合调整集成模型超参数（权重衰减、温度缩放、提前停止）对预测性能和不确定性量化的影响，并提出了一种部分重叠的保留策略来平衡联合评估和数据利用。

Method: 通过实验研究了联合调整权重衰减、温度缩放和提前停止对深度集成模型的影响，并提出了一种部分重叠的保留策略。

Result: 联合调整集成模型通常能与单独调整或超越单独调整性能，效果大小因任务和指标而异。部分重叠的保留策略提供了一种实用的解决方案。

Conclusion: 联合优化深度集成模型超参数能够提高性能，并提供了一种实用的部分重叠保留策略，为模型优化提供了有价值的见解和指导。

Abstract: Deep ensembles are a powerful tool in machine learning, improving both model
performance and uncertainty calibration. While ensembles are typically formed
by training and tuning models individually, evidence suggests that jointly
tuning the ensemble can lead to better performance. This paper investigates the
impact of jointly tuning weight decay, temperature scaling, and early stopping
on both predictive performance and uncertainty quantification. Additionally, we
propose a partially overlapping holdout strategy as a practical compromise
between enabling joint evaluation and maximizing the use of data for training.
Our results demonstrate that jointly tuning the ensemble generally matches or
improves performance, with significant variation in effect size across
different tasks and metrics. We highlight the trade-offs between individual and
joint optimization in deep ensemble training, with the overlapping holdout
strategy offering an attractive practical solution. We believe our findings
provide valuable insights and guidance for practitioners looking to optimize
deep ensemble models. Code is available at:
https://github.com/lauritsf/ensemble-optimality-gap

</details>


### [79] [Benchmark Datasets for Lead-Lag Forecasting on Social Platforms](https://arxiv.org/abs/2511.03877)
*Kimia Kazemian,Zhenzhen Liu,Yangfanyu Yang,Katie Z Luo,Shuhan Gu,Audrey Du,Xinyu Yang,Jack Jansons,Kilian Q Weinberger,John Thickstun,Yian Yin,Sarah Dean*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的预测问题，称为“先行-滞后预测”（Lead-Lag Forecasting, LLF），其中早期交互（先行）可以预测稍后发生的高影响力事件（滞后）。论文提供了两个大规模基准数据集（arXiv和GitHub）来促进LLF研究，并验证了数据的有效性，为LLF的系统探索奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 社会和协作平台中存在一种普遍的模式：早期交互（如浏览、点赞、下载）之后，会伴随更高影响力的事件（如引用、销售、评论），且这些事件之间存在时间上的滞后。然而，时间序列社区尚未将这种“先行-滞后”模式作为一个统一的预测问题进行研究，主要是因为缺乏标准化的数据集。因此，本文旨在 formalize LLF 问题，并通过提供基准数据集来推动该领域的研究。

Method: 本文通过将问题 formalize 为先行-滞后预测（LLF），即给定早期使用渠道（先行），预测相关但时间上滞后的结果渠道（滞后）。为了解决数据缺乏的问题，论文构建了两个大规模的基准数据集：arXiv 数据集（230万篇论文的访问量 -> 引用量）和 GitHub 数据集（300万个存储库的推送/星标 -> 分叉）。此外，论文还列举了其他具有类似先行-滞后动态的领域，例如维基百科（页面浏览量 -> 编辑）、Spotify（播放量 -> 音乐会出席）和电子商务（点击量 -> 购买）。论文详细记录了数据整理和清洗的技术细节，通过统计和分类测试验证了先行-滞后动态的存在，并对回归的参数和非参数基线进行了基准测试。

Result: 本文成功构建并发布了两个大规模的先行-滞后预测基准数据集（arXiv 和 GitHub），这些数据集具有长期动态、涵盖完整的成果范围，并避免了抽样中的幸存者偏差。通过统计和分类测试，验证了数据集中先行-滞后动态的有效性。同时，对参数和非参数基线回归模型进行了基准测试。

Conclusion: 本文将先行-滞后预测（LLF）确立为一种新颖的预测范式，并通过提供高质量的基准数据集和系统的实证分析，为在社会和使用数据中系统探索LLF奠定了经验基础。文章的数据门户网站提供了下载和文档，将促进该领域未来的研究。

Abstract: Social and collaborative platforms emit multivariate time-series traces in
which early interactions-such as views, likes, or downloads-are followed,
sometimes months or years later, by higher impact like citations, sales, or
reviews. We formalize this setting as Lead-Lag Forecasting (LLF): given an
early usage channel (the lead), predict a correlated but temporally shifted
outcome channel (the lag). Despite the ubiquity of such patterns, LLF has not
been treated as a unified forecasting problem within the time-series community,
largely due to the absence of standardized datasets. To anchor research in LLF,
here we present two high-volume benchmark datasets-arXiv (accesses -> citations
of 2.3M papers) and GitHub (pushes/stars -> forks of 3M repositories)-and
outline additional domains with analogous lead-lag dynamics, including
Wikipedia (page views -> edits), Spotify (streams -> concert attendance),
e-commerce (click-throughs -> purchases), and LinkedIn profile (views ->
messages). Our datasets provide ideal testbeds for lead-lag forecasting, by
capturing long-horizon dynamics across years, spanning the full spectrum of
outcomes, and avoiding survivorship bias in sampling. We documented all
technical details of data curation and cleaning, verified the presence of
lead-lag dynamics through statistical and classification tests, and benchmarked
parametric and non-parametric baselines for regression. Our study establishes
LLF as a novel forecasting paradigm and lays an empirical foundation for its
systematic exploration in social and usage data. Our data portal with downloads
and documentation is available at https://lead-lag-forecasting.github.io/.

</details>


### [80] [Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity](https://arxiv.org/abs/2511.04518)
*Obed Amo,Samit Ghosh,Markus Lange-Hegermann,Bogdan Raiţă,Michael Pokojovy*

Main category: cs.LG

TL;DR: 比较了两种二维波动方程求解方法的基准研究：边界约束Ehrenpreis-Palamodov高斯过程（B-EPGP）和Crank-Nicolson时间步长的有限元方法（CN-FEM），发现B-EPGP在相同自由度下更准确。


<details>
  <summary>Details</summary>
Motivation: 解决具有齐次Dirichlet边界条件的二维波动方程，并比较B-EPGP替代模型与经典CN-FEM方法的性能。

Method: B-EPGP方法利用从特征簇导出的指数多项式基来精确执行偏微分方程和边界条件，并采用罚式最小二乘法估计系数。为了公平比较，引入了自由度（DoF）匹配协议。

Result: 在匹配相同自由度下，B-EPGP始终比CN-FEM获得更低的时空L2误差和时间最大L2误差，精度提高了大约两个数量级。

Conclusion: B-EPGP在求解二维波动方程方面，相比于传统的CN-FEM方法，在相同计算资源下表现出显着更高的精度。

Abstract: We present a new benchmarking study comparing a boundary-constrained
Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical
finite element method combined with Crank--Nicolson time stepping (CN-FEM) for
solving the two-dimensional wave equation with homogeneous Dirichlet boundary
conditions. The B-EPGP construction leverages exponential-polynomial bases
derived from the characteristic variety to enforce the PDE and boundary
conditions exactly and employs penalized least squares to estimate the
coefficients. To ensure fairness across paradigms, we introduce a
degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP
consistently attains lower space-time $L^2$-error and maximum-in-time
$L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of
magnitude.

</details>


### [81] [Forgetting is Everywhere](https://arxiv.org/abs/2511.04666)
*Ben Sanati,Thomas L. Lee,Trevor McInroe,Aidan Scannell,Nikolay Malkin,David Abel,Amos Storkey*

Main category: cs.LG

TL;DR: 该论文提出了一个关于遗忘的算法和任务无关理论，将遗忘描述为学习器在未来经验预测分布中缺乏自我一致性，表现为预测信息的丢失。


<details>
  <summary>Details</summary>
Motivation: 在开发通用学习算法时，一个基本挑战是它们在适应新数据时往往会忘记过去的知识。尽管经过数十年的研究，但仍没有一个统一的定义能够深入了解学习的底层动态。

Method: 我们提出了一个算法和任务无关的理论，将遗忘描述为学习器在未来经验预测分布中缺乏自我一致性，表现为预测信息的丢失。我们的理论自然地产生了一个衡量算法遗忘倾向的通用度量。为了验证该理论，我们设计了一套全面的实验，涵盖了分类、回归、生成建模和强化学习。

Result: 我们通过实验证明了遗忘存在于所有学习设置中，并且在决定学习效率方面发挥着重要作用。

Conclusion: 这些结果共同建立了对遗忘的原则性理解，并为分析和改进通用学习算法的信息保留能力奠定了基础。

Abstract: A fundamental challenge in developing general learning algorithms is their
tendency to forget past knowledge when adapting to new data. Addressing this
problem requires a principled understanding of forgetting; yet, despite decades
of study, no unified definition has emerged that provides insights into the
underlying dynamics of learning. We propose an algorithm- and task-agnostic
theory that characterises forgetting as a lack of self-consistency in a
learner's predictive distribution over future experiences, manifesting as a
loss of predictive information. Our theory naturally yields a general measure
of an algorithm's propensity to forget. To validate the theory, we design a
comprehensive set of experiments that span classification, regression,
generative modelling, and reinforcement learning. We empirically demonstrate
how forgetting is present across all learning settings and plays a significant
role in determining learning efficiency. Together, these results establish a
principled understanding of forgetting and lay the foundation for analysing and
improving the information retention capabilities of general learning
algorithms.

</details>


### [82] [NVIDIA Nemotron Nano V2 VL](https://arxiv.org/abs/2511.03929)
*NVIDIA,:,Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu,Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu,Xin,Di,Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin,Akshay Hazare,Kaustubh Purandare,Ann Guan,Anna Warno,Chen Cui,Yoshi Suhara,Shibani Likhite,Seph Mard,Meredith Price,Laya Sleiman,Saori Kaji,Udi Karpas,Kari Briski,Joey Conway,Michael Lightstone,Jan Kautz,Mohammad Shoeybi,Mostofa Patwary,Jonathen Cohen,Oleksii Kuchaiev,Andrew Tao,Bryan Catanzaro*

Main category: cs.LG

TL;DR: 最新的Nemotron视觉语言模型Nemotron Nano V2 VL在文档理解、长视频理解和推理任务中表现出色，通过架构、数据集和训练方法的改进，显著超越了前代模型。


<details>
  <summary>Details</summary>
Motivation: 开发一款在真实世界文档理解、长视频理解和推理任务中表现强大的视觉语言模型。

Method: Nemotron Nano V2 VL基于混合 Mamba-Transformer LLM 架构的 Nemotron Nano V2，并采用了创新的 token 减少技术，以提高在长文档和视频场景中的推理吞吐量。它在模型架构、数据集和训练方法上进行了重大改进。

Result: Nemotron Nano V2 VL 在所有视觉和文本领域都取得了显著的性能提升，超越了之前的 Llama-3.1-Nemotron-Nano-VL-8B 模型。该模型发布了 BF16、FP8 和 FP4 格式的检查点，并共享了大部分数据集、训练方法和训练代码。

Conclusion: Nemotron Nano V2 VL 是一个在真实世界文档和视频理解方面具有显著进步的视觉语言模型，通过其创新的架构和训练策略，在性能和推理效率方面都达到了新的高度。

Abstract: We introduce Nemotron Nano V2 VL, the latest model of the Nemotron
vision-language series designed for strong real-world document understanding,
long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers
significant improvements over our previous model,
Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major
enhancements in model architecture, datasets, and training recipes. Nemotron
Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and
innovative token reduction techniques to achieve higher inference throughput in
long document and video scenarios. We are releasing model checkpoints in BF16,
FP8, and FP4 formats and sharing large parts of our datasets, recipes and
training code.

</details>


### [83] [LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction](https://arxiv.org/abs/2511.03938)
*Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani*

Main category: cs.LG

TL;DR: LogHD通过对类别轴进行对数压缩，在保持维度D的同时，将记忆需求从O(CD)降低到O(Dlogk C)。它在更小的模型尺寸和更高的鲁棒性下实现了与现有HDC设计相当的准确性，在同等记忆下，它比特征轴压缩方法能承受约2.5-3.0倍的比特翻转率，并在ASIC实现中表现出显著的能效和速度提升。


<details>
  <summary>Details</summary>
Motivation: 解决标准超维度计算（HDC）设计中，每个类别需要一个原型，导致O(CD)的内存需求问题，尤其是在内存、能量和可靠性受限的系统中。现有的压缩方法（D轴压缩）虽然改善了存储和计算，但削弱了鲁棒性。

Method: LogHD引入了对数类别轴压缩，用n≈⌈logk C⌉个捆绑超向量（字母表大小k）取代了C个每个类别的原型，并在n维激活空间中进行解码。它使用了一个容量感知的码本和基于配置文件的解码，并且可以与特征轴稀疏化结合使用。

Result: LogHD在保持维度D的情况下，将内存需求降至O(Dlogk C)，并在更小的模型和更高鲁健壮性下获得了具有竞争力的准确性。在同等内存下，LogHD能够承受比特征轴压缩方法高2.5-3.0倍的比特翻转率。ASIC实现显示，其能效比AMD Ryzen 9 9950X高498倍，速度快62.6倍；比NVIDIA RTX 4090高24.3倍的能效和6.58倍的速度；比采用特征轴HDC的ASIC基线能效高4.06倍，速度快2.19倍。

Conclusion: LogHD通过对数类别轴压缩，在降低内存需求、保持计算维度的同时，显著提高了超维度计算系统的鲁棒性、能效和速度。该方法在资源受限系统中的实际应用具有巨大潜力，尤其是在需要高容错性和低功耗的边缘计算场景。

Abstract: Hyperdimensional computing (HDC) suits memory, energy, and
reliability-constrained systems, yet the standard "one prototype per class"
design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior
compaction reduces $D$ (feature axis), improving storage/compute but weakening
robustness. We introduce LogHD, a logarithmic class-axis reduction that
replaces the $C$ per-class prototypes with $n\!\approx\!\lceil\log_k C\rceil$
bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional
activation space, cutting memory to $O(D\log_k C)$ while preserving $D$. LogHD
uses a capacity-aware codebook and profile-based decoding, and composes with
feature-axis sparsification. Across datasets and injected bit flips, LogHD
attains competitive accuracy with smaller models and higher resilience at
matched memory. Under equal memory, it sustains target accuracy at roughly
$2.5$-$3.0\times$ higher bit-flip rates than feature-axis compression; an ASIC
instantiation delivers $498\times$ energy efficiency and $62.6\times$ speedup
over an AMD Ryzen 9 9950X and $24.3\times$/$6.58\times$ over an NVIDIA RTX
4090, and is $4.06\times$ more energy-efficient and $2.19\times$ faster than a
feature-axis HDC ASIC baseline.

</details>


### [84] [RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods](https://arxiv.org/abs/2511.03939)
*Raghav Sharma,Manan Mehta,Sai Tiger Raina*

Main category: cs.LG

TL;DR: 这篇综述探讨了LLMs的对齐研究，超越了传统的文本方法，涵盖了多模态对齐、文化公平性和低延迟优化等新领域，旨在为研究人员构建更稳健、高效和公平的AI系统提供指导。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）对齐研究的新前沿，解决多模态对齐、文化公平性和低延迟优化等关键问题，并为构建更稳健、高效和公平的AI系统提供路线图。

Method: 系统地回顾了包括PPO、DPO和GRPO在内的基础算法，并详细分析了LLMs对齐领域的最新创新。

Result: 通过对现有对齐技术的比较性综合分析，概述了开放的挑战。

Conclusion: 本文为研究人员构建更稳健、高效和公平的AI系统提供了重要的路线图。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is the standard for
aligning Large Language Models (LLMs), yet recent progress has moved beyond
canonical text-based methods. This survey synthesizes the new frontier of
alignment research by addressing critical gaps in multi-modal alignment,
cultural fairness, and low-latency optimization. To systematically explore
these domains, we first review foundational algo- rithms, including PPO, DPO,
and GRPO, before presenting a detailed analysis of the latest innovations. By
providing a comparative synthesis of these techniques and outlining open
challenges, this work serves as an essential roadmap for researchers building
more robust, efficient, and equitable AI systems.

</details>


### [85] [PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis](https://arxiv.org/abs/2511.03966)
*Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo*

Main category: cs.LG

TL;DR: 该文章提出了一种针对认知诊断模型的数据遗忘算法，以解决用户删除个人数据的需求，该算法通过分层重要性指导遗忘，在保证模型性能的同时有效移除特定学生数据。


<details>
  <summary>Details</summary>
Motivation: 用户日益增长的“被遗忘权”使得从认知诊断（CD）模型中移除特定学生数据的需求变得紧迫。然而，现有CD模型在设计时缺乏隐私考虑，且缺乏有效的数据遗忘机制。直接应用通用遗忘算法效果不佳，因为它们难以在遗忘完整性、模型实用性和效率之间取得平衡，尤其是在CD模型独特的异构结构面前。

Method: 本文首次系统性研究了CD模型的数据遗忘问题，提出了一种新颖高效的算法：分层重要性指导遗忘（HIF）。其关键见解是CD模型中的参数重要性表现出明显的层级特征。HIF通过结合个体和层级重要性的创新平滑机制来利用这一点，从而能够更精确地区分与待遗忘数据相关的参数。

Result: 在三个真实世界数据集上的实验表明，HIF在关键指标上显著优于基线。

Conclusion: HIF为CD模型响应用户数据删除请求以及部署高性能、保护隐私的AI系统提供了首个有效解决方案。

Abstract: The need to remove specific student data from cognitive diagnosis (CD) models
has become a pressing requirement, driven by users' growing assertion of their
"right to be forgotten". However, existing CD models are largely designed
without privacy considerations and lack effective data unlearning mechanisms.
Directly applying general purpose unlearning algorithms is suboptimal, as they
struggle to balance unlearning completeness, model utility, and efficiency when
confronted with the unique heterogeneous structure of CD models. To address
this, our paper presents the first systematic study of the data unlearning
problem for CD models, proposing a novel and efficient algorithm: hierarchical
importanceguided forgetting (HIF). Our key insight is that parameter importance
in CD models exhibits distinct layer wise characteristics. HIF leverages this
via an innovative smoothing mechanism that combines individual and layer, level
importance, enabling a more precise distinction of parameters associated with
the data to be unlearned. Experiments on three real world datasets show that
HIF significantly outperforms baselines on key metrics, offering the first
effective solution for CD models to respond to user data removal requests and
for deploying high-performance, privacy preserving AI systems

</details>


### [86] [PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction](https://arxiv.org/abs/2511.03976)
*Xu Zou*

Main category: cs.LG

TL;DR: PETRA是一种基于系统发育树的创新性Transformer模型，能够有效预测SARS-CoV-2的未来突变，相较于基线模型表现出显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: SARS-CoV-2的快速演变和免疫逃逸变异的不断出现对公共卫生和疫苗研发带来了持续挑战。现有的大规模生成式预训练Transformer模型在处理带噪声的病毒基因组序列方面存在局限性。

Method: 本文引入了PETRA（Pretrained Evolutionary TRAnsformer），这是一种基于系统发育树而不是原始RNA序列的Transformer方法。该方法通过从系统发育树中提取的进化轨迹，有效缓解了测序噪声并捕获了病毒进化的层次结构。此外，该方法还采用了加权训练框架，以解决全球序列数据中存在的显著地理和时间不平衡。

Result: PETRA在预测未来SARS-CoV-2突变方面表现出色，核苷酸突变的加权recall@1达到9.45%，刺突氨基酸突变的加权recall@1达到17.10%，而最佳基线模型的相应数据分别为0.49%和6.64%。PETRA还展示了其在24F(XEC)和25A(LP.8.1)等主要分支的实时突变预测中的应用能力。

Conclusion: PETRA通过利用进化轨迹和加权训练框架，显著提高了SARS-CoV-2未来突变的预测能力，为应对病毒进化挑战提供了新的工具和视角。

Abstract: Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable
evolutionary trajectory, characterized by the continual emergence of
immune-evasive variants. This poses persistent challenges to public health and
vaccine development.
  While large-scale generative pre-trained transformers (GPTs) have
revolutionized the modeling of sequential data, their direct applications to
noisy viral genomic sequences are limited. In this paper, we introduce
PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based
on evolutionary trajectories derived from phylogenetic trees rather than raw
RNA sequences. This method effectively mitigates sequencing noise and captures
the hierarchical structure of viral evolution.
  With a weighted training framework to address substantial geographical and
temporal imbalances in global sequence data, PETRA excels in predicting future
SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide
mutations and 17.10\% for spike amino-acid mutations, compared to 0.49% and
6.64% respectively for the best baseline. PETRA also demonstrates its ability
to aid in the real-time mutation prediction of major clades like 24F(XEC) and
25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra

</details>


### [87] [Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models](https://arxiv.org/abs/2511.03981)
*Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu*

Main category: cs.LG

TL;DR: 该论文提出了一种可组合的微调方法，通过结合图结构先验和模块化适配器来解决大型预训练模型在多任务适应中面临的计算成本高和结构不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型预训练模型在多任务适应中面临的计算成本高和结构不稳定问题。

Method: 引入关系矩阵建模任务间的依赖关系，将节点和路径关联的图结构先验编码进去，为适配器权重分配和路径选择提供统一结构约束。模块化适配器通过低秩映射和可插拔机制嵌入到不同层，在先验指导下实现高效的跨任务组合和重用。

Result: 显著提高了任务预测准确性、适配器权重分配精度和整体计算效率，同时保持了模型的轻量化设计，验证了图先验和模块化机制在可组合微调中的协同优势。

Conclusion: 该方法通过图结构先验和模块化适配器的结合，有效地解决了多任务适应中的计算成本和结构稳定性问题，并在实验中表现出优越的性能。

Abstract: This paper proposes a composable fine-tuning method that integrates graph
structural priors with modular adapters to address the high computational cost
and structural instability faced by large-scale pre-trained models in
multi-task adaptation. The method introduces a relation matrix to model
dependencies among tasks, explicitly encoding correlations between nodes and
paths into graph structural priors, which provide unified structural
constraints for adapter weight allocation and path selection. Modular adapters
are embedded into different layers through low-rank mapping and a pluggable
mechanism, enabling efficient cross-task composition and reuse under prior
guidance. This mechanism not only improves parameter efficiency and training
stability but also alleviates path conflicts and redundant computation in
multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity,
environmental sensitivity, and data sensitivity are conducted to systematically
analyze key factors such as routing temperature, gating thresholds, and
relation matrix regularization strength, verifying the consistency and superior
performance of the method under structural constraints. The results demonstrate
that the proposed framework significantly enhances task prediction accuracy,
adapter weight allocation precision, and overall computational efficiency while
maintaining model lightweight design, highlighting the synergistic advantages
of graph priors and modular mechanisms in composable fine-tuning.

</details>


### [88] [Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes](https://arxiv.org/abs/2511.03986)
*Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder*

Main category: cs.LG

TL;DR: 这篇综述介绍了动态血糖监测（CGM）和可穿戴技术如何实现非侵入性、动态的代谢表型分析，从而实现个性化的糖尿病预防和管理。


<details>
  <summary>Details</summary>
Motivation: 传统的糖尿病和糖尿病前期分类方法忽略了病理生理学的异质性。作者旨在展示CGM和可穿戴技术如何通过动态代谢表型分析来解决这一问题，从而实现更精准的糖尿病预防。

Method: 文章通过展示证据来支持其论点：1. 机器学习模型可以利用CGM数据准确预测胰岛素抵抗和β细胞功能。2. 个体对标准化膳食的餐后血糖反应（PPGR）可以作为代谢亚型的生物标志物。3. 可穿戴设备数据揭示了饮食、睡眠和体力活动模式与特定代谢功能障碍的关联。4. 膳食干预措施在降低PPGR方面的效果具有表型依赖性。

Result: CGM和可穿戴技术能够将早期血糖异常的复杂性分解为不同的、可操作的亚表型。这种方法超越了简单的血糖控制，为针对个体核心代谢缺陷的营养、行为和药物策略铺平了道路。

Conclusion: 动态血糖监测（CGM）和可穿戴技术的发展为糖尿病的精准预防开辟了新时代。通过对个体代谢表型的深入理解，可以制定个性化的干预措施，从而更有效地管理和预防糖尿病。

Abstract: The classification of diabetes and prediabetes by static glucose thresholds
obscures the pathophysiological dysglycemia heterogeneity, primarily driven by
insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This
review demonstrates that continuous glucose monitoring and wearable
technologies enable a paradigm shift towards non-invasive, dynamic metabolic
phenotyping. We show evidence that machine learning models can leverage
high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance
tests to accurately predict gold-standard measures of muscle IR and beta-cell
function. This personalized characterization extends to real-world nutrition,
where an individual's unique postprandial glycemic response (PPGR) to
standardized meals, such as the relative glucose spike to potatoes versus
grapes, could serve as a biomarker for their metabolic subtype. Moreover,
integrating wearable data reveals that habitual diet, sleep, and physical
activity patterns, particularly their timing, are uniquely associated with
specific metabolic dysfunctions, informing precision lifestyle interventions.
The efficacy of dietary mitigators in attenuating PPGR is also shown to be
phenotype-dependent. Collectively, this evidence demonstrates that CGM can
deconstruct the complexity of early dysglycemia into distinct, actionable
subphenotypes. This approach moves beyond simple glycemic control, paving the
way for targeted nutritional, behavioral, and pharmacological strategies
tailored to an individual's core metabolic defects, thereby paving the way for
a new era of precision diabetes prevention.

</details>


### [89] [Accelerating scientific discovery with the common task framework](https://arxiv.org/abs/2511.04001)
*J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个针对科学和工程领域的通用任务框架（CTF），旨在评估机器学习和人工智能算法在动态系统表征和控制中的性能。


<details>
  <summary>Details</summary>
Motivation: 机器学习和人工智能算法正在改变和赋能工程、物理和生物科学中动态系统的表征和控制。然而，需要比较指标来评估在预测、状态重构、泛化和控制等方面的多样化科学目标，尤其是在数据有限和测量噪声存在的情况下。

Method: 本文提出了一个针对科学和工程领域的通用任务框架（CTF）。该框架包含不断增长的挑战性数据集，并设定了一系列多样化且实用的共同目标。

Result: CTF是一种关键的赋能技术，它促进了机器学习/人工智能算法在语音识别、语言处理和计算机视觉等传统应用中的快速发展。

Conclusion: 科学和工程领域迫切需要CTF的客观度量标准，以比较目前快速开发和部署的各种算法。

Abstract: Machine learning (ML) and artificial intelligence (AI) algorithms are
transforming and empowering the characterization and control of dynamic systems
in the engineering, physical, and biological sciences. These emerging modeling
paradigms require comparative metrics to evaluate a diverse set of scientific
objectives, including forecasting, state reconstruction, generalization, and
control, while also considering limited data scenarios and noisy measurements.
We introduce a common task framework (CTF) for science and engineering, which
features a growing collection of challenge data sets with a diverse set of
practical and common objectives. The CTF is a critically enabling technology
that has contributed to the rapid advance of ML/AI algorithms in traditional
applications such as speech recognition, language processing, and computer
vision. There is a critical need for the objective metrics of a CTF to compare
the diverse algorithms being rapidly developed and deployed in practice today
across science and engineering.

</details>


### [90] [Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing](https://arxiv.org/abs/2511.04002)
*Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.LG

TL;DR: 该论文介绍了一种为边缘设备上的LLM部署设计的自回归感知拆分计算框架，通过OPSC、两阶段中间压缩和统一优化框架，解决了LLM在资源受限IoT设备上的部署问题，并在推理速度和通信开销方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在各种推理任务中取得了接近人类的性能，但由于其庞大的参数量和内存密集型自回归解码，在资源受限的物联网（IoT）设备上部署仍然不切实际。

Method: 1. 提出了一点拆分压缩（OPSC），这是一种混合精度量化方案，通过策略性地将模型划分为具有不同精度级别的前端和后端S，防止内存不足。
2. 提出了一个两阶段中间压缩管道，结合阈值拆分（TS）和逐令牌自适应比特量化（TAB-Q），在显著降低通信开销的同时，保留了对精度至关重要的激活。
3. 建立了一个统一的优化框架，共同选择最佳拆分点、量化设置和序列长度，以满足严格的内存和延迟约束。

Result: 该框架在不同的LLM和硬件平台上进行了广泛评估，与最先进的量化方法（包括SmoothQuant、OmniQuant和Atom）相比，表现出卓越的性能。该框架实现了1.49的推理加速和显著的通信开销降低，同时保持或提高了模型精度。

Conclusion: 本研究通过引入自回归感知的拆分计算框架，成功解决了LLMs在资源受限IoT设备上部署的挑战。通过OPSC、两阶段中间压缩和统一优化框架，显著提升了LLM的推理速度、降低了通信开销，并保持或提高了模型精度，为LLMs在边缘设备上的实际应用开辟了道路。

Abstract: Large language models (LLMs) have achieved near-human performance across
diverse reasoning tasks, yet their deployment on resource-constrained
Internet-of-Things (IoT) devices remains impractical due to massive parameter
footprints and memory-intensive autoregressive decoding. While split computing
offers a promising solution by partitioning model execution between edge
devices and cloud servers, existing approaches fail to address the unique
challenges of autoregressive inference, particularly the iterative token
generation process and expanding key-value (KV) cache requirements. This work
introduces the first autoregressive-aware split computing framework designed
explicitly for LLM deployment on edge devices. Our approach makes three key
contributions. First, we develop one-point split compression (OPSC), a
mixed-precision quantization scheme that prevents out-of-memory failures by
strategically partitioning models into front-end and back-end segments with
different precision levels. Second, we propose a two-stage intermediate
compression pipeline that combines threshold splitting (TS) and token-wise
adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations
while dramatically reducing communication overhead. Third, we formulate a
unified optimization framework that jointly selects optimal split points,
quantization settings, and sequence lengths to satisfy strict memory and
latency constraints. Extensive evaluations across diverse LLMs and hardware
platforms demonstrate superior performance compared to state-of-the-art
quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework
achieves a 1.49 inference speedup and significant communication overhead
reduction while maintaining or improving model accuracy.

</details>


### [91] [DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization](https://arxiv.org/abs/2511.04063)
*Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: DartQuant是一种高效的分布感知旋转校准方法，它降低了旋转优化的复杂性，同时减少了对任务特定损失的依赖，从而避免了过拟合的风险。


<details>
  <summary>Details</summary>
Motivation: 量化在加速大规模模型推理方面起着关键作用，而旋转矩阵已被证明可以通过平滑异常值来有效提高量化性能。 然而，旋转优化算法的端到端微调会产生高昂的计算成本，并且容易过拟合。

Method: 我们提出了一种高效的分布感知旋转校准方法DartQuant，通过约束旋转后激活的分布来降低旋转优化的复杂性，从而有效减少对任务特定损失的依赖，降低了过拟合的风险。此外，我们引入了QR-Orth优化方案，用更高效的解决方案取代了昂贵的交替优化。

Result: 在各种模型量化实验中，DartQuant展示出卓越的性能。与现有方法相比，它在70B模型上实现了47倍的加速和10倍的内存节省。 此外，它首次在单个3090 GPU上成功完成了70B模型的旋转校准，使得在资源受限的环境中对大型语言模型进行量化成为可能。

Conclusion:  DartQuant在保持高性能的同时，显著降低了计算成本和内存消耗，并解决了大型模型量化中的过拟合问题，扩展了量化在资源受限环境中的应用前景。

Abstract: Quantization plays a crucial role in accelerating the inference of
large-scale models, and rotational matrices have been shown to effectively
improve quantization performance by smoothing outliers. However, end-to-end
fine-tuning of rotational optimization algorithms incurs high computational
costs and is prone to overfitting. To address this challenge, we propose an
efficient distribution-aware rotational calibration method, DartQuant, which
reduces the complexity of rotational optimization by constraining the
distribution of the activations after rotation. This approach also effectively
reduces reliance on task-specific losses, thereby mitigating the risk of
overfitting. Additionally, we introduce the QR-Orth optimization scheme, which
replaces expensive alternating optimization with a more efficient solution. In
a variety of model quantization experiments, DartQuant demonstrates superior
performance. Compared to existing methods, it achieves 47$\times$ acceleration
and 10$\times$ memory savings for rotational optimization on a 70B model.
Furthermore, it is the first to successfully complete rotational calibration
for a 70B model on a single 3090 GPU, making quantization of large language
models feasible in resource-constrained environments. Code is available at
https://github.com/CAS-CLab/DartQuant.git.

</details>


### [92] [Pediatric Appendicitis Detection from Ultrasound Images](https://arxiv.org/abs/2511.04069)
*Fatemeh Hosseinabadi,Seyedhassan Sharifi*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于预训练ResNet架构的深度学习模型，用于从超声图像中自动检测儿童阑尾炎，并在Regensburg儿童阑尾炎数据集中实现了93.44%的准确率。


<details>
  <summary>Details</summary>
Motivation: 儿童阑尾炎的诊断因症状重叠和影像质量差异而对临床医生构成挑战。

Method: 本研究使用了Regensburg儿童阑尾炎数据集，对ResNet模型进行了微调，以区分阑尾炎和非阑尾炎病例。图像经过归一化、大小调整和增强等预处理步骤。

Result: 所提出的ResNet模型在检测阑尾炎方面表现出色，总体准确率为93.44%，精确率为91.53%，召回率为89.8%。该模型有效学习了判别性空间特征，克服了儿科影像中低对比度、散斑噪声和解剖变异性带来的挑战。

Conclusion: 该深度学习模型在从超声图像中自动检测儿童阑尾炎方面表现出强大的性能，有望辅助临床诊断。

Abstract: Pediatric appendicitis remains one of the most common causes of acute
abdominal pain in children, and its diagnosis continues to challenge clinicians
due to overlapping symptoms and variable imaging quality. This study aims to
develop and evaluate a deep learning model based on a pretrained ResNet
architecture for automated detection of appendicitis from ultrasound images. We
used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound
scans, laboratory data, and clinical scores from pediatric patients admitted
with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each
subject had 1 to 15 ultrasound views covering the right lower quadrant,
appendix, lymph nodes, and related structures. For the image based
classification task, ResNet was fine tuned to distinguish appendicitis from
non-appendicitis cases. Images were preprocessed by normalization, resizing,
and augmentation to enhance generalization. The proposed ResNet model achieved
an overall accuracy of 93.44, precision of 91.53, and recall of 89.8,
demonstrating strong performance in identifying appendicitis across
heterogeneous ultrasound views. The model effectively learned discriminative
spatial features, overcoming challenges posed by low contrast, speckle noise,
and anatomical variability in pediatric imaging.

</details>


### [93] [Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters](https://arxiv.org/abs/2511.04073)
*Ananya Sutradhar,Suryansh Gupta,Ravishankar Krishnaswamy,Haiyang Xu,Aseem Rastogi,Gopal Srinivasa*

Main category: cs.LG

TL;DR: 该文章提出了一种新的过滤近似最近邻搜索方法，通过学习数据中的向量距离和过滤器匹配之间的最佳权衡，显著提高了搜索精度。


<details>
  <summary>Details</summary>
Motivation: 传统的图基方法在处理过滤近似最近邻搜索时，由于使用固定的、与数据无关的惩罚机制，导致在不同标签和向量分布的数据集上泛化能力差。

Method: 本研究提出了一种原则性的替代方案，直接从数据中学习向量距离和过滤器匹配之间的最佳权衡，并将其表述为一个受约束的线性优化问题，从而导出能够更好地反映底层过滤器分布并更有效地解决过滤ANN搜索问题的权重。这些学习到的权重将指导搜索过程和索引构建。

Result: 实验表明，通过使距离函数适应数据，相比固定惩罚方法，准确率显著提高了5-10%。

Conclusion: 新的方法为过滤近似最近邻搜索问题提供了一个更灵活和可推广的框架，通过学习数据中的最优权衡，显著提高了准确性。

Abstract: Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest
vectors for a query vector from a dataset. It enforces that a specified set of
discrete labels $S$ for the query must be included in the labels of each
retrieved vector. Existing graph-based methods typically incorporate filter
awareness by assigning fixed penalties or prioritizing nodes based on filter
satisfaction. However, since these methods use fixed, data in- dependent
penalties, they often fail to generalize across datasets with diverse label and
vector distributions. In this work, we propose a principled alternative that
learns the optimal trade-off between vector distance and filter match directly
from the data, rather than relying on fixed penalties. We formulate this as a
constrained linear optimization problem, deriving weights that better reflect
the underlying filter distribution and more effectively address the filtered
ANN search problem. These learned weights guide both the search process and
index construction, leading to graph structures that more effectively capture
the underlying filter distribution and filter semantics. Our experiments
demonstrate that adapting the distance function to the data significantly im-
proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible
and generalizable framework for the filtered ANN search problem.

</details>


### [94] [KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea](https://arxiv.org/abs/2511.04094)
*Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim*

Main category: cs.LG

TL;DR: 该研究介绍了韩国避税面板（KoTaP），这是一个包含2011年至2024年间在KOSPI和KOSDAQ上市的非金融公司的长期面板数据集。KoTaP旨在将企业避税作为预测变量，并将其与多个领域（包括盈余管理、盈利能力、稳定性、增长和公司治理）联系起来。


<details>
  <summary>Details</summary>
Motivation: 此研究的动机是建立一个长期面板数据集（KoTaP），以研究韩国企业的避税行为，并将其与盈余管理、盈利能力、稳定性、增长和公司治理等多个公司特征联系起来。KoTaP旨在填补现有研究的空白，提供一个包含韩国企业独特制度特征的数据集，同时保持国际可比性。

Method: 本研究通过以下步骤构建了KoTaP数据集：1. **数据来源：** 收集了2011年至2024年间在KOSPI和KOSDAQ上市的非金融公司数据。2. **数据筛选：** 排除了金融公司、非12月财年末公司、资本减值公司和税前利润为负的公司，最终得到12,653个公司-年度观测值，涉及1,754家公司。3. **变量构建：** 将公司避税作为预测变量，并使用现金有效税率（CETR）、GAAP有效税率（GETR）和账面-税务差异（TSTA, TSDA）等互补指标进行衡量。同时，将避税与盈余管理（基于应计制和活动）、盈利能力（ROA, ROE, CFO, LOSS）、稳定性（LEV, CUR, SIZE, PPE, AGE, INVREC）、增长（GRW, MB, TQ）和公司治理（BIG4, FORN, OWN）等多个领域建立了联系。4. **数据特征：** KoTaP是一个平衡面板数据集，具有标准化变量，并且与国际文献中核心指标的分布和相关性保持一致。同时，它反映了韩国企业的独特制度特征，例如股权集中、高外资持股和高流动性比率。

Result: 本研究构建了韩国避税面板（KoTaP）数据集，该数据集包含来自1,754家公司的12,653个公司-年度观测值。KoTaP数据集成功地将企业避税行为与盈余管理、盈利能力、稳定性、增长和公司治理等多种公司特征联系起来。该数据集在分布和核心指标相关性方面与国际文献保持一致，同时反映了韩国企业的独特制度特征，例如股权集中和高外资持股。

Conclusion: KoTaP是一个关键的开放资源，可用于会计、金融和跨学科研究。它支持基准计量经济学和深度学习模型、外部有效性检查和可解释AI分析的应用。此外，它还有助于政策评估、审计规划和投资分析，为研究人员提供了宝贵的工具来理解和分析韩国企业避税行为及其与公司绩效和治理之间关系的数据工具。

Abstract: This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term
panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011
and 2024. After excluding financial firms, firms with non-December fiscal year
ends, capital impairment, and negative pre-tax income, the final dataset
consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed
to treat corporate tax avoidance as a predictor variable and link it to
multiple domains, including earnings management (accrual- and activity-based),
profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE,
INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance
itself is measured using complementary indicators cash effective tax rate
(CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA,
TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is
its balanced panel structure with standardized variables and its consistency
with international literature on the distribution and correlation of core
indicators. At the same time, it reflects distinctive institutional features of
Korean firms, such as concentrated ownership, high foreign shareholding, and
elevated liquidity ratios, providing both international comparability and
contextual uniqueness. KoTaP enables applications in benchmarking econometric
and deep learning models, external validity checks, and explainable AI
analyses. It further supports policy evaluation, audit planning, and investment
analysis, making it a critical open resource for accounting, finance, and
interdisciplinary research.

</details>


### [95] [Decomposable Neuro Symbolic Regression](https://arxiv.org/abs/2511.04124)
*Giorgio Morales,John W. Sheppard*

Main category: cs.LG

TL;DR: 这篇论文提出了一种可分解的符号回归方法，利用transformer模型、遗传算法和遗传编程来发现可解释的多变量数学表达式，这些表达式可以解释不透明回归模型的计算函数。


<details>
  <summary>Details</summary>
Motivation: 传统的符号回归方法通常优先考虑最小化预测误差，而不是识别控制方程，这往往导致生成过于复杂或不准确的表达式。

Method: 本方法使用Multi-Set Transformer生成多个单变量符号骨架，这些骨架描述了每个变量如何影响不透明模型的响应。然后，通过基于遗传算法的方法评估并选择高质量的骨架子集，并通过基于遗传编程的级联过程逐步合并这些骨架，同时保留其原始骨架结构。最后，通过遗传算法对最终的多变量骨架进行系数优化。

Result: 该方法在不同噪声水平的问题上进行了评估，与两种基于GP的方法、三种神经SR方法和一种混合方法相比，其插值和外推误差更低或相当。与其他方法不同，该方法始终能学习到与原始数学结构匹配的表达式。

Conclusion: 该研究提出了一种名为“可分解符号回归”的方法，该方法通过结合transformer模型、遗传算法和遗传编程，解决了现有符号回归方法在生成可解释和结构准确的数学表达式方面的不足。该方法不仅在预测精度上表现出色，而且能够发现与潜在机制相符的表达式，有望在科学发现和模型解释方面提供新的视角。

Abstract: Symbolic regression (SR) models complex systems by discovering mathematical
expressions that capture underlying relationships in observed data. However,
most SR methods prioritize minimizing prediction error over identifying the
governing equations, often producing overly complex or inaccurate expressions.
To address this, we present a decomposable SR method that generates
interpretable multivariate expressions leveraging transformer models, genetic
algorithms (GAs), and genetic programming (GP). In particular, our explainable
SR method distills a trained ``opaque'' regression model into mathematical
expressions that serve as explanations of its computed function. Our method
employs a Multi-Set Transformer to generate multiple univariate symbolic
skeletons that characterize how each variable influences the opaque model's
response. We then evaluate the generated skeletons' performance using a
GA-based approach to select a subset of high-quality candidates before
incrementally merging them via a GP-based cascade procedure that preserves
their original skeleton structure. The final multivariate skeletons undergo
coefficient optimization via a GA. We evaluated our method on problems with
controlled and varying degrees of noise, demonstrating lower or comparable
interpolation and extrapolation errors compared to two GP-based methods, three
neural SR methods, and a hybrid approach. Unlike them, our approach
consistently learned expressions that matched the original mathematical
structure.

</details>


### [96] [Exploring the Feasibility of End-to-End Large Language Model as a Compiler](https://arxiv.org/abs/2511.04132)
*Hongbin Zhang,Shihao Gao,Yang Liu,Mingjie Xing,Yanjun Wu,Chen Zhao*

Main category: cs.LG

TL;DR: 本文探讨了大型语言模型（LLM）作为编译器（LaaC）的可行性，设计了CompilerEval数据集和框架来评估LLM在源代码理解和汇编代码生成方面的能力。结果显示LLM作为编译器的基本能力尚可，但编译成功率较低。通过优化提示、放大模型和结合推理方法可以显著提高汇M编A代I码N的T质E量N。A作I者Nt对LLaaC的未来持乐观态度，并提出了架构设计和未来研究方向，认为通过有针对性的训练、知识丰富的提示和专业基础设施，LaaC有潜力生成高质量汇编代码并推动编译领域的范式转变。


<details>
  <summary>Details</summary>
Motivation: LLM在许多领域都显示出显著优势，但其作为端到端编译器的潜力尚未得到充分探索。本文旨在探索LLM作为编译器的可行性。

Method: 设计了CompilerEval数据集和框架来评估主流LLM在源代码理解和汇编代码生成方面的能力。分析了各种错误，探索了多种改进LLM生成代码的方法，并评估了跨平台编译能力。

Result: LLM作为编译器展现出基本能力，但目前的编译成功率较低。通过优化提示、放大模型和结合推理方法，LLM生成的汇编代码质量可显著提高。

Conclusion: LaaC具有巨大潜力，通过有针对性的训练、知识丰富的提示和专业基础设施，有望生成高质量汇编代码并推动编译领域的范式转变。

Abstract: In recent years, end-to-end Large Language Model (LLM) technology has shown
substantial advantages across various domains. As critical system software and
infrastructure, compilers are responsible for transforming source code into
target code. While LLMs have been leveraged to assist in compiler development
and maintenance, their potential as an end-to-end compiler remains largely
unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and
its future directions. We designed the CompilerEval dataset and framework
specifically to evaluate the capabilities of mainstream LLMs in source code
comprehension and assembly code generation. In the evaluation, we analyzed
various errors, explored multiple methods to improve LLM-generated code, and
evaluated cross-platform compilation capabilities. Experimental results
demonstrate that LLMs exhibit basic capabilities as compilers but currently
achieve low compilation success rates. By optimizing prompts, scaling up the
model, and incorporating reasoning methods, the quality of assembly code
generated by LLMs can be significantly enhanced. Based on these findings, we
maintain an optimistic outlook for LaaC and propose practical architectural
designs and future research directions. We believe that with targeted training,
knowledge-rich prompts, and specialized infrastructure, LaaC has the potential
to generate high-quality assembly code and drive a paradigm shift in the field
of compilation.

</details>


### [97] [Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning](https://arxiv.org/abs/2511.04147)
*Jiaming Zhang,Yujie Yang,Haoning Wang,Liping Zhang,Shengbo Eben Li*

Main category: cs.LG

TL;DR: 该论文提出了一种名为交换策略优化（EPO）的算法框架，用于解决具有无限约束的半无限安全强化学习问题（SI-safe RL）。


<details>
  <summary>Details</summary>
Motivation: 在许多实际应用中，安全强化学习（safe RL）需要处理无限数量的约束，即半无限安全强化学习（SI-safe RL）问题，例如在整个连续参数空间中强制执行安全条件。

Method: EPO通过迭代解决具有有限约束集的安全强化学习子问题，并通过约束扩展和删除自适应地调整活跃集。在每次迭代中，违反预定义容差的约束被添加以改进策略，而那些在策略更新后拉格朗日乘子为零的约束被移除。

Result: 通过EPO训练的策略在性能上可以与最优解相媲美，并且全局约束违反严格保持在预定范围内。

Conclusion: EPO框架提供了一种解决SI-safe RL问题的有效方法，它在优化长期性能的同时，能够确保确定性有界安全性。

Abstract: Safe reinforcement learning (safe RL) aims to respect safety requirements
while optimizing long-term performance. In many practical applications,
however, the problem involves an infinite number of constraints, known as
semi-infinite safe RL (SI-safe RL). Such constraints typically appear when
safety conditions must be enforced across an entire continuous parameter space,
such as ensuring adequate resource distribution at every spatial location. In
this paper, we propose exchange policy optimization (EPO), an algorithmic
framework that achieves optimal policy performance and deterministic bounded
safety. EPO works by iteratively solving safe RL subproblems with finite
constraint sets and adaptively adjusting the active set through constraint
expansion and deletion. At each iteration, constraints with violations
exceeding the predefined tolerance are added to refine the policy, while those
with zero Lagrange multipliers are removed after the policy update. This
exchange rule prevents uncontrolled growth of the working set and supports
effective policy training. Our theoretical analysis demonstrates that, under
mild assumptions, strategies trained via EPO achieve performance comparable to
optimal solutions with global constraint violations strictly remaining within a
prescribed bound.

</details>


### [98] [Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories](https://arxiv.org/abs/2511.04155)
*Olav Finne Praesteng Larsen,Massimiliano Ruocco,Michail Spitieris,Abdulmajid Murad,Martina Ragosta*

Main category: cs.LG

TL;DR: 本文研究了在数据匮乏的机场中，如何利用迁移学习和生成模型生成轨迹数据，以支持空中交通管制（ATM）解决方案的开发和验证。


<details>
  <summary>Details</summary>
Motivation: 空中交通管理（ATM）解决方案的开发和验证需要大量的轨迹数据，但许多次级和区域机场面临数据稀缺问题，这限制了机器学习方法的应用以及大规模模拟和“假设”分析的能力。

Method: 本文研究了将基于扩散和流匹配的先进生成模型应用于航空领域，并评估了它们在苏黎世（数据丰富的机场）和都柏林（数据稀缺的机场）着陆轨迹数据集之间的可迁移性。模型在苏黎世进行预训练，然后在都柏林使用不同比例的本地数据（从0%到100%）进行微调。

Result: 研究结果表明，扩散模型在仅使用5%的都柏林数据时即可达到具有竞争力的性能，并在20%左右的数据量时达到基线水平的性能，在各项指标和视觉检查中始终优于从头训练的模型。潜在流匹配和潜在扩散模型也受益于预训练，但收益变化较大，而流匹配模型的泛化能力较弱。

Conclusion: 尽管在捕获罕见轨迹模式方面存在挑战，但这些发现证明了迁移学习在显著降低ATM轨迹生成数据需求方面的潜力，即使在历史记录有限的环境中也能实现逼真的合成数据生成。

Abstract: Access to trajectory data is a key requirement for developing and validating
Air Traffic Management (ATM) solutions, yet many secondary and regional
airports face severe data scarcity. This limits the applicability of machine
learning methods and the ability to perform large-scale simulations or
"what-if" analyses. In this paper, we investigate whether generative models
trained on data-rich airports can be efficiently adapted to data-scarce
airports using transfer learning. We adapt state-of-the-art diffusion- and
flow-matching-based architectures to the aviation domain and evaluate their
transferability between Zurich (source) and Dublin (target) landing trajectory
datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying
amounts of local data, ranging from 0% to 100%. Results show that
diffusion-based models achieve competitive performance with as little as 5% of
the Dublin data and reach baseline-level performance around 20%, consistently
outperforming models trained from scratch across metrics and visual
inspections. Latent flow matching and latent diffusion models also benefit from
pretraining, though with more variable gains, while flow matching models show
weaker generalization. Despite challenges in capturing rare trajectory
patterns, these findings demonstrate the potential of transfer learning to
substantially reduce data requirements for trajectory generation in ATM,
enabling realistic synthetic data generation even in environments with limited
historical records.

</details>


### [99] [Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data](https://arxiv.org/abs/2511.04158)
*Anzhuo Xie,Wei-Chen Chang*

Main category: cs.LG

TL;DR: 该研究提出了一种基于Transformer的纵向建模方法，用于处理异构电子健康记录（EHR）数据中的临床风险分类挑战。该方法通过特征嵌入层实现统一表示，引入可学习的时间编码机制捕捉动态演变，并采用多头自注意力结构对纵向序列进行全局依赖建模。此外，语义加权池化模块用于增强语义表示，最后通过线性映射层生成个体风险评分。实验结果表明，该模型在准确性、召回率、精确度和F1-Score方面优于传统模型，为临床智能决策提供了高效可靠的框架。


<details>
  <summary>Details</summary>
Motivation: 处理异构电子健康记录（EHR）数据中临床风险分类所面临的挑战，包括不规则的时间模式、大的模态差异和复杂的语义结构。

Method: 1. 采用特征嵌入层，将多源医疗特征统一表示结构化和非结构化数据。2. 引入可学习的时间编码机制，捕捉不均匀采样间隔下的动态演变。3. 核心模型采用多头自注意力结构，对纵向序列进行全局依赖建模，聚合不同时间尺度上的长期趋势和短期波动。4. 设计语义加权池化模块，为关键医疗事件分配自适应重要性，增强风险相关特征的判别能力。5. 通过线性映射层生成个体层面的风险分数。

Result: 所提出的模型在准确性、召回率、精确度和F1-Score方面优于传统的机器学习和时间深度学习模型，在多源异构EHR环境中实现了稳定准确的风险识别。

Conclusion: 该研究为临床智能决策提供了一个高效可靠的框架，有效解决了异构EHR数据在临床风险分类中的挑战。

Abstract: This study proposes a Transformer-based longitudinal modeling method to
address challenges in clinical risk classification with heterogeneous
Electronic Health Record (EHR) data, including irregular temporal patterns,
large modality differences, and complex semantic structures. The method takes
multi-source medical features as input and employs a feature embedding layer to
achieve a unified representation of structured and unstructured data. A
learnable temporal encoding mechanism is introduced to capture dynamic
evolution under uneven sampling intervals. The core model adopts a multi-head
self-attention structure to perform global dependency modeling on longitudinal
sequences, enabling the aggregation of long-term trends and short-term
fluctuations across different temporal scales. To enhance semantic
representation, a semantic-weighted pooling module is designed to assign
adaptive importance to key medical events, improving the discriminative ability
of risk-related features. Finally, a linear mapping layer generates
individual-level risk scores. Experimental results show that the proposed model
outperforms traditional machine learning and temporal deep learning models in
accuracy, recall, precision, and F1-Score, achieving stable and precise risk
identification in multi-source heterogeneous EHR environments and providing an
efficient and reliable framework for clinical intelligent decision-making.

</details>


### [100] [Block Rotation is All You Need for MXFP4 Quantization](https://arxiv.org/abs/2511.04214)
*Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng*

Main category: cs.LG

TL;DR: 这篇论文全面分析了MXFP4格式下LLMs的后训练量化（PTQ）方法，并发现现有技术（特别是基于旋转的方法）与MXFP4存在兼容性问题。作者提出了一种新的块旋转策略来解决这个问题，显著提高了量化精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速增长带来了巨大的内存、计算和能源成本。后训练量化（PTQ）是解决这些成本的有效方法，但目前在W4A4量化方面仍面临挑战。特别是，新兴的MXFP4格式与现有PTQ方法之间的兼容性问题尚未得到充分探讨。

Method: 本研究在MXFP4格式下对PTQ方法进行了全面的基准测试，并通过系统评估分析了不同方法的性能。在发现基于旋转的方法与MXFP4不兼容后，作者深入分析了不兼容的原因，并提出了一种新的块旋转策略来适应MXFP4格式。

Result: 研究发现，GPTQ等方法在MXFP4格式下表现良好，而大多数最先进的基于旋转的方法与MXFP4严重不兼容。这种不兼容的根本原因是MXFP4的PoT块缩放与全局旋转导致的离群点能量重新分配之间存在基本不匹配。作者提出的块旋转策略成功地使基于旋转的方法适应了MXFP4，并在不同的LLM上显著提高了精度。

Conclusion: 本研究为在MXFP4等新兴低精度格式下部署LLMs的PTQ提供了清晰的指导，并为未来的PTQ研究奠定了基础。研究结果揭示了MXFP4与现有PTQ方法之间的兼容性挑战，并通过提出创新的块旋转策略有效地解决了这一问题，为LLM的量化技术发展做出了重要贡献。

Abstract: Large language models (LLMs) have achieved remarkable success, but their
rapidly growing scale imposes prohibitive costs in memory, computation, and
energy. Post-training quantization (PTQ) is a promising solution for efficient
deployment, yet achieving accurate W4A4 quantization remains an open challenge.
While most existing methods are designed for INT4 formats, the emergence of
MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)--
raises questions about the applicability of current techniques. In this work,
we establish a comprehensive benchmark of PTQ methods under the MXFP4 format.
Through systematic evaluation, we find that methods like GPTQ consistently
deliver strong performance, whereas rotation-based approaches, which are almost
used by all state-of-the-art approaches, suffer from severe incompatibility
with MXFP4. We further provide the first in-depth analysis of this conflict,
tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two)
block scaling and the redistribution of outlier energy via global rotation.
Building on this insight, we propose a simple yet effective block rotation
strategy that adapts rotation-based methods to MXFP4, leading to substantial
accuracy improvements across diverse LLMs. Our findings not only offer clear
guidance for practitioners but also set a foundation for advancing PTQ research
under emerging low-precision formats.

</details>


### [101] [seqme: a Python library for evaluating biological sequence design](https://arxiv.org/abs/2511.04239)
*Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek*

Main category: cs.LG

TL;DR: seqme是一个用于评估生物序列计算设计方法的开源Python库，它提供了序列、嵌入和属性三类指标。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一个实现评估生物序列计算设计方法指标的单一软件包。

Method: 开发了一个名为seqme的模块化、可扩展的开源Python库。

Result: seqme库包含了模型无关的评估生物序列计算设计方法的指标，涵盖了序列、嵌入和属性三类指标。它适用于小分子、DNA、ncRNA、mRNA、肽和蛋白质等多种生物序列。该库还提供了多种嵌入和属性模型以及诊断和可视化功能。

Conclusion: seqme提供了一个全面的框架，用于评估一次性设计和迭代计算设计方法的性能。

Abstract: Recent advances in computational methods for designing biological sequences
have sparked the development of metrics to evaluate these methods performance
in terms of the fidelity of the designed sequences to a target distribution and
their attainment of desired properties. However, a single software library
implementing these metrics was lacking. In this work we introduce seqme, a
modular and highly extendable open-source Python library, containing
model-agnostic metrics for evaluating computational methods for biological
sequence design. seqme considers three groups of metrics: sequence-based,
embedding-based, and property-based, and is applicable to a wide range of
biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins.
The library offers a number of embedding and property models for biological
sequences, as well as diagnostics and visualization functions to inspect the
results. seqme can be used to evaluate both one-shot and iterative
computational design methods.

</details>


### [102] [Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics](https://arxiv.org/abs/2511.04244)
*Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi*

Main category: cs.LG

TL;DR: STELLE是一种神经符号框架，它通过将时间序列轨迹嵌入到时态逻辑概念空间中，实现分类和解释的统一。


<details>
  <summary>Details</summary>
Motivation: 时序分类数据通常出现在安全关键应用中，但目前的黑盒深度学习方法难以解释其输出。

Method: STELLE引入了一种受STL启发的新型核函数，将原始时间序列映射到预定义的STL公式对齐空间中，从而联合优化了准确性和可解释性。

Result: 针对个体预测，STELLE提供人类可读的STL条件作为局部解释；针对类别，STELLE提供类别特征公式作为全局解释。实验证明STELLE在保持竞争性准确率的同时，提供了逻辑上忠实的解释。

Conclusion: STELLE成功地将时间序列分类和解释结合起来，为安全关键应用提供了可解释的分类方案。

Abstract: Time series classification is a task of paramount importance, as this kind of
data often arises in safety-critical applications. However, it is typically
tackled with black-box deep learning methods, making it hard for humans to
understand the rationale behind their output. To take on this challenge, we
propose a novel approach, STELLE (Signal Temporal logic Embedding for
Logically-grounded Learning and Explanation), a neuro-symbolic framework that
unifies classification and explanation through direct embedding of trajectories
into a space of temporal logic concepts. By introducing a novel STL-inspired
kernel that maps raw time series to their alignment with predefined STL
formulae, our model jointly optimises accuracy and interpretability, as each
prediction is accompanied by the most relevant logical concepts that
characterise it. This yields (i) local explanations as human-readable STL
conditions justifying individual predictions, and (ii) global explanations as
class-characterising formulae. Experiments demonstrate that STELLE achieves
competitive accuracy while providing logically faithful explanations, validated
on diverse real-world benchmarks.

</details>


### [103] [Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference](https://arxiv.org/abs/2511.04286)
*Matteo Cercola,Valeria Capretti,Simone Formentin*

Main category: cs.LG

TL;DR: 本文提出了一个混合框架，结合了RLHF的可扩展性与PBO的查询效率，以实现主动且样本高效的偏好数据收集，并在高维偏好优化和大型语言模型微调任务上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 收集人类偏好数据以对齐机器学习模型通常成本高昂且耗时，因此需要更高效的学习范式。

Method: 本文提出了一个混合框架，通过将采集驱动模块集成到RLHF管道中，统一了RLHF的可扩展性与PBO的查询效率，从而实现主动且样本高效的偏好收集。

Result: 实验结果表明，在高维偏好优化和大型语言模型微调这两个代表性领域中，所提出的方法在样本效率和整体性能上都取得了持续的改进。

Conclusion: 所提出的混合框架在保持RLHF可扩展性的同时，显著提升了偏好数据收集的效率。

Abstract: Learning from human preferences is a cornerstone of aligning machine learning
models with subjective human judgments. Yet, collecting such preference data is
often costly and time-consuming, motivating the need for more efficient
learning paradigms. Two established approaches offer complementary advantages:
RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning,
while PBO achieves greater sample efficiency through active querying. We
propose a hybrid framework that unifies RLHF's scalability with PBO's query
efficiency by integrating an acquisition-driven module into the RLHF pipeline,
thereby enabling active and sample-efficient preference gathering. We validate
the proposed approach on two representative domains: (i) high-dimensional
preference optimization and (ii) LLM fine-tuning. Experimental results
demonstrate consistent improvements in both sample efficiency and overall
performance across these tasks.

</details>


### [104] [Differentially Private In-Context Learning with Nearest Neighbor Search](https://arxiv.org/abs/2511.04332)
*Antti Koskela,Tejas Kulkarni,Laith Zumot*

Main category: cs.LG

TL;DR: 本文提出了一个关于上下文学习（DP-ICL）的差分隐私框架，它可以在隐私保护的方式下，整合相关示例的最近邻搜索。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私上下文学习（DP-ICL）方法忽略了现代大型语言模型（LLM）管道中的一个关键组成部分：用于检索相关上下文数据的相似性搜索。

Method: 本文提出了一种新的DP框架，该框架通过结合上下文数据的最近邻检索和跟踪选择样本的累积隐私成本的隐私过滤器，以确保遵守中央差分隐私预算。

Result: 在所有评估基准上，本文方法都显著优于现有基线，实现了更有利的隐私-效用权衡。在文本分类和文档问答方面的实验结果表明，该方法相对于现有基线具有明显的优势。

Conclusion: 本文提出的DP框架，通过整合最近邻搜索和隐私过滤器，显著提升了差分隐私上下文学习的性能和隐私-效用权衡。

Abstract: Differentially private in-context learning (DP-ICL) has recently become an
active research topic due to the inherent privacy risks of in-context learning.
However, existing approaches overlook a critical component of modern large
language model (LLM) pipelines: the similarity search used to retrieve relevant
context data. In this work, we introduce a DP framework for in-context learning
that integrates nearest neighbor search of relevant examples in a privacy-aware
manner. Our method outperforms existing baselines by a substantial margin
across all evaluated benchmarks, achieving more favorable privacy-utility
trade-offs. To achieve this, we employ nearest neighbor retrieval from a
database of context data, combined with a privacy filter that tracks the
cumulative privacy cost of selected samples to ensure adherence to a central
differential privacy budget. Experimental results on text classification and
document question answering show a clear advantage of the proposed method over
existing baselines.

</details>


### [105] [The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity](https://arxiv.org/abs/2511.04418)
*Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann*

Main category: cs.LG

TL;DR: 该研究表明，在模棱两可的数据上，现有的大型语言模型不确定性量化方法表现不佳，并引入了新的基准数据集来解决此问题，旨在促进对该领域的新思考。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型中准确的不确定性量化对于可信赖的部署至关重要，但现有方法在处理现实世界中固有的模糊语言（反映任意不确定性）时存在局限性。

Method: 通过引入MAQA*和AmbigQA*两个具有真实答案分布的模糊问答数据集，研究者评估了不同不确定性估计范式（包括预测分布、模型内部表示和模型集成）在模糊数据上的表现。

Result: 现有的不确定性估计器在没有模糊性的严格假设下表现良好，但在模糊数据上性能会下降到接近随机水平。这种性能下降在不同估计范式中均保持一致。

Conclusion: 目前大型语言模型的不确定性量化方法存在关键缺陷，特别是在处理模糊性时受限，这需要重新思考当前的建模范式。

Abstract: Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is
critical for trustworthy deployment. While real-world language is inherently
ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically
benchmarked against tasks with no ambiguity. In this work, we demonstrate that
while current uncertainty estimators perform well under the restrictive
assumption of no ambiguity, they degrade to close-to-random performance on
ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first
ambiguous question-answering (QA) datasets equipped with ground-truth answer
distributions estimated from factual co-occurrence. We find this performance
deterioration to be consistent across different estimation paradigms: using the
predictive distribution itself, internal representations throughout the model,
and an ensemble of models. We show that this phenomenon can be theoretically
explained, revealing that predictive-distribution and ensemble-based estimators
are fundamentally limited under ambiguity. Overall, our study reveals a key
shortcoming of current UQ methods for LLMs and motivates a rethinking of
current modeling paradigms.

</details>


### [106] [Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness](https://arxiv.org/abs/2511.04401)
*Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的方法SCER，通过在嵌入空间中直接正则化特征表示来抑制虚假关联，从而提高了模型在子群体偏移情景下的最差群体鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型容易受到虚假关联的影响，尤其是在子群体偏移情景中，模型在代表性不足的群体中表现不佳。现有的方法在此问题上仍有局限性，缺乏将嵌入空间表示与最差群体错误联系起来的严格理论框架。

Method: SCER（Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness）通过直接正则化特征表示来抑制虚假线索。该方法在理论上证明了最差群体错误受到分类器对虚假和核心方向依赖程度的影响，这些方向是通过识别跨域和类的群组平均嵌入差异来确定的。通过在嵌入层面施加理论约束，SCER鼓励模型关注核心特征，同时降低对虚假模式的敏感性。

Result: 通过在多个视觉和语言数据集上的系统评估，SCER在最差群体准确性方面优于此前的最新研究。

Conclusion: SCER通过在嵌入空间中抑制虚假关联，有效提高了模型在子群体偏移下的鲁棒性，并在实验中取得了 SOTA 效果。

Abstract: Deep learning models achieve strong performance across various domains but
often rely on spurious correlations, making them vulnerable to distribution
shifts. This issue is particularly severe in subpopulation shift scenarios,
where models struggle in underrepresented groups. While existing methods have
made progress in mitigating this issue, their performance gains are still
constrained. They lack a rigorous theoretical framework connecting the
embedding space representations with worst-group error. To address this
limitation, we propose Spurious Correlation-Aware Embedding Regularization for
Worst-Group Robustness (SCER), a novel approach that directly regularizes
feature representations to suppress spurious cues. We show theoretically that
worst-group error is influenced by how strongly the classifier relies on
spurious versus core directions, identified from differences in group-wise mean
embeddings across domains and classes. By imposing theoretical constraints at
the embedding level, SCER encourages models to focus on core features while
reducing sensitivity to spurious patterns. Through systematic evaluation on
multiple vision and language, we show that SCER outperforms prior
state-of-the-art studies in worst-group accuracy. Our code is available at
\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.

</details>


### [107] [Federated Stochastic Minimax Optimization under Heavy-Tailed Noises](https://arxiv.org/abs/2511.04456)
*Xinwen Zhang,Hongchang Gao*

Main category: cs.LG

TL;DR: 本文针对联邦学习中重尾梯度噪声下的非凸-PL minimax优化问题，提出了两种新算法：Fed-NSGDA-M和FedMuon-DA。这两种算法在较宽松的条件下，均能有效处理重尾噪声，并理论上证明了其收敛速度为$O({1}/{(TNp)^{\frac{s-1}{2s}}})$。


<details>
  <summary>Details</summary>
Motivation: 在非凸随机优化中，重尾噪声比标准有界方差假设更符合实际，因此引起了广泛关注。

Method: 提出了两种新算法：Fed-NSGDA-M和FedMuon-DA。Fed-NSGDA-M集成归一化梯度，FedMuon-DA利用Muon优化器进行局部更新。

Result: 两种算法的收敛速度均为$O({1}/{(TNp)^{\frac{s-1}{2s}}})$。据作者所知，这是首次在重尾噪声下具有严格理论保证的联邦minimax优化算法。

Conclusion: 这两种新颖的算法在联邦学习中重尾噪声下的非凸-PL minimax优化问题上表现出有效性，并提供了理论收敛保证。

Abstract: Heavy-tailed noise has attracted growing attention in nonconvex stochastic
optimization, as numerous empirical studies suggest it offers a more realistic
assumption than standard bounded variance assumption. In this work, we
investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise
in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which
integrates normalized gradients, and FedMuon-DA, which leverages the Muon
optimizer for local updates. Both algorithms are designed to effectively
address heavy-tailed noise in federated minimax optimization, under a milder
condition. We theoretically establish that both algorithms achieve a
convergence rate of $O({1}/{(TNp)^{\frac{s-1}{2s}}})$. To the best of our
knowledge, these are the first federated minimax optimization algorithms with
rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments
further validate their effectiveness.

</details>


### [108] [Towards Causal Market Simulators](https://arxiv.org/abs/2511.04469)
*Dennis Thumm,Luis Ontaneda Mijares*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为TNCM-VAE的新型深度生成模型，专门用于生成具有因果关系的合成金融时间序列，从而支持反事实分析和风险评估。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成市场模型在生成合成金融数据方面表现出色，但它们缺乏因果推理能力，这对于反事实分析和风险评估至关重要。

Method: TNCM-VAE模型结合了变分自编码器（VAE）和结构因果模型。它通过在解码器架构中引入有向无环图来强制执行因果约束，并使用因果Wasserstein距离进行模型训练，从而在生成反事实金融时间序列的同时保留时间依赖性和因果关系。

Result: TNCM-VAE在基于O-U过程的合成自回归模型上进行了验证，在反事实概率估计方面表现出色，L1距离低至0.03-0.10，显著优于真实值。

Conclusion: TNCM-VAE模型能够生成遵循潜在因果机制的合理反事实市场轨迹，从而支持金融压力测试、情景分析和增强回溯测试。

Abstract: Market generators using deep generative models have shown promise for
synthetic financial data generation, but existing approaches lack causal
reasoning capabilities essential for counterfactual analysis and risk
assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that
combines variational autoencoders with structural causal models to generate
counterfactual financial time series while preserving both temporal
dependencies and causal relationships. Our approach enforces causal constraints
through directed acyclic graphs in the decoder architecture and employs the
causal Wasserstein distance for training. We validate our method on synthetic
autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating
superior performance in counterfactual probability estimation with L1 distances
as low as 0.03-0.10 compared to ground truth. The model enables financial
stress testing, scenario analysis, and enhanced backtesting by generating
plausible counterfactual market trajectories that respect underlying causal
mechanisms.

</details>


### [109] [Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training](https://arxiv.org/abs/2511.04485)
*Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle*

Main category: cs.LG

TL;DR: Q3R是一种新颖的低秩训练策略，它能够训练具有预设低目标秩的模型，同时保持与密集模型相当的预测性能，且计算开销小，并兼容现有架构。


<details>
  <summary>Details</summary>
Motivation: 传统的低秩优化方法在低秩预训练任务中表现不佳，因为在保持低秩结构和优化目标方面存在挑战。

Method: Q3R基于一个二次正则化项，该项将平滑对数行列式（用作秩替代目标）进行主化。它采用了一种受迭代重加权最小二乘（IRLS）框架启发的低秩归纳训练策略。

Result: Q3R能够训练具有预设低目标秩的模型，这些模型实现了与密集模型相当的预测性能，计算开销小，并保持与现有架构的完全兼容性。例如，在一项实验中，ViT-Tiny模型在CIFAR-10性能上分别截断了60%和80%的参数，准确率仅下降了约1.3%和4%。

Conclusion: Q3R是一种有效的低秩训练方法，适用于Transformer模型，在图像和语言任务以及低秩微调方面均表现出色。

Abstract: Parameter-efficient training, based on low-rank optimization, has become a
highly successful tool for fine-tuning large deep-learning models. However,
these methods fail at low-rank pre-training tasks where maintaining the
low-rank structure and the objective remains a challenging task. We propose the
Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel
low-rank inducing training strategy inspired by the iteratively reweighted
least squares (IRLS) framework. Q3R is based on a quadratic regularizer term
which majorizes a smoothed log determinant serving as rank surrogate objective.
Unlike other low-rank training techniques, Q3R is able to train weight matrices
with prescribed, low target ranks of models that achieve comparable predictive
performance as dense models, with small computational overhead, while remaining
fully compatible with existing architectures. For example, we demonstrated one
experiment where we are able to truncate $60\%$ and $80\%$ of the parameters of
a ViT-Tiny model with $~1.3\%$ and $~4\%$ accuracy drop in CIFAR-10 performance
respectively. The efficacy of Q3R is confirmed on Transformers across both
image and language tasks, including for low-rank fine-tuning.

</details>


### [110] [Alternative Fairness and Accuracy Optimization in Criminal Justice](https://arxiv.org/abs/2511.04505)
*Shaolong Wu,James Blume,Geshi Yeung*

Main category: cs.LG

TL;DR: 这篇论文探讨了算法公平性在刑事司法领域的应用，提出了一种改进的群体公平性方法，并通过三个支柱提供了一个实用的部署框架。


<details>
  <summary>Details</summary>
Motivation: 算法公平性研究领域发展迅速，但在刑事司法领域，关键概念仍未明确。

Method: 作者回顾了群体公平性、个体公平性和过程公平性，并分析了它们冲突的条件。然后，他们对标准的群体公平性进行了简单修改，旨在最小化加权误差损失，同时将假阴性率差异控制在较小的容忍范围内，而不是要求受保护群体之间的精确平等。

Result: 这种修改后的群体公平性方法使得解决方案更容易找到，提升了预测准确性，并揭示了错误成本的伦理选择。作者将此提案置于对偏见和不完整数据、潜在的平权行动以及子群体约束爆炸这三类批评中进行讨论。

Conclusion: 论文提出了一个在公共决策系统中部署的实用框架，该框架基于三个支柱：基于需求的决策、透明度和问责制，以及狭义的定义和解决方案。这些元素将技术设计与合法性联系起来，为使用风险评估和相关工具的机构提供了可操作的指导。

Abstract: Algorithmic fairness has grown rapidly as a research area, yet key concepts
remain unsettled, especially in criminal justice. We review group, individual,
and process fairness and map the conditions under which they conflict. We then
develop a simple modification to standard group fairness. Rather than exact
parity across protected groups, we minimize a weighted error loss while keeping
differences in false negative rates within a small tolerance. This makes
solutions easier to find, can raise predictive accuracy, and surfaces the
ethical choice of error costs. We situate this proposal within three classes of
critique: biased and incomplete data, latent affirmative action, and the
explosion of subgroup constraints. Finally, we offer a practical framework for
deployment in public decision systems built on three pillars: need-based
decisions, Transparency and accountability, and narrowly tailored definitions
and solutions. Together, these elements link technical design to legitimacy and
provide actionable guidance for agencies that use risk assessment and related
tools.

</details>


### [111] [Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers](https://arxiv.org/abs/2511.04514)
*C. Hepburn,T. Zielke,A. P. Raulf*

Main category: cs.LG

TL;DR: 本文研究了线性模式连接性（LMC）在数据偏移下的表现，并探讨了如何通过调整学习率和批量大小来缓解数据偏移的影响，以在训练效率和模型集成多样性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 线性模式连接性（LMC）与深度学习的多个方面相关，包括噪声随机梯度下的训练稳定性、局部最小值（盆地）的平滑度和泛化能力、采样模型的相似性和功能多样性以及架构对数据处理的影响。本文旨在研究LMC在数据偏移下的表现，并找出缓解其影响的条件。

Method: 本文通过实验研究了LMC在数据偏移下的表现。作者将数据偏移解释为随机梯度噪声的额外来源，并通过小学习率和大学习批次大小来减少其影响。

Result: 数据偏移可以通过小学习率和大学习批次大小来缓解。这些参数影响模型是收敛到相同的局部最小值，还是收敛到具有不同平滑度和泛化能力的损失函数区域。尽管通过LMC采样的模型比收敛到不同盆地的模型更容易犯类似错误，但LMC的优点在于平衡了训练效率与来自更大、更多样化集成所获得的收益。

Conclusion: 本文发现，在数据偏移下，通过调整学习率和批量大小可以有效缓解LMC的影响。LMC的价值在于权衡训练效率和模型集成多样性，为深度学习的训练和泛化提供了新的视角。

Abstract: The phenomenon of linear mode connectivity (LMC) links several aspects of
deep learning, including training stability under noisy stochastic gradients,
the smoothness and generalization of local minima (basins), the similarity and
functional diversity of sampled models, and architectural effects on data
processing. In this work, we experimentally study LMC under data shifts and
identify conditions that mitigate their impact. We interpret data shifts as an
additional source of stochastic gradient noise, which can be reduced through
small learning rates and large batch sizes. These parameters influence whether
models converge to the same local minimum or to regions of the loss landscape
with varying smoothness and generalization. Although models sampled via LMC
tend to make similar errors more frequently than those converging to different
basins, the benefit of LMC lies in balancing training efficiency against the
gains achieved from larger, more diverse ensembles. Code and supplementary
materials will be made publicly available at https://github.com/DLR-KI/LMC in
due course.

</details>


### [112] [Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics](https://arxiv.org/abs/2511.04534)
*Jonas E. Katona,Emily K. de Jong,Nipun Gunawardena*

Main category: cs.LG

TL;DR: 本文介绍了一种用于潜在空间降阶模型（ROMs）的预测不确定性量化事后、模型无关框架，它不需要修改基础架构或训练过程。


<details>
  <summary>Details</summary>
Motivation: 降阶模型（ROMs）可以有效地模拟高维物理系统，但缺乏鲁棒的不确定性量化方法。现有的方法通常是针对特定架构或训练的，这限制了灵活性和泛化能力。

Method: 本文引入了一种后验的、与模型无关的框架，用于潜在空间ROM中的预测不确定性量化，该框架无需修改底层架构或训练过程。通过使用共形预测，我们的方法估计了ROM管道多个组件的统计预测区间：潜在动力学、重建和端到端预测。

Result: 我们通过一个用于云微物理的潜在空间动力学模型验证了该方法，该模型能够准确预测液滴尺寸分布的演变，并量化整个ROM管道的不确定性。

Conclusion: 本文提出的框架为潜在空间降阶模型提供了一种灵活且通用的不确定性量化方法，能够提高模型预测的可靠性和可信度。

Abstract: Reduced-order models (ROMs) can efficiently simulate high-dimensional
physical systems, but lack robust uncertainty quantification methods. Existing
approaches are frequently architecture- or training-specific, which limits
flexibility and generalization. We introduce a post hoc, model-agnostic
framework for predictive uncertainty quantification in latent space ROMs that
requires no modification to the underlying architecture or training procedure.
Using conformal prediction, our approach estimates statistical prediction
intervals for multiple components of the ROM pipeline: latent dynamics,
reconstruction, and end-to-end predictions. We demonstrate the method on a
latent space dynamical model for cloud microphysics, where it accurately
predicts the evolution of droplet-size distributions and quantifies uncertainty
across the ROM pipeline.

</details>


### [113] [ARETE: an R package for Automated REtrieval from TExt with large language models](https://arxiv.org/abs/2511.04573)
*Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso*

Main category: cs.LG

TL;DR: 为了解决缺乏关键物种数据的问题，ARETE R包被开发出来，它利用大型语言模型自动从文献中提取物种出现数据，大大扩展了已知物种的分布范围，对保护规划具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 保护工作中关键物种数据的缺乏，尤其是物种出现数据，是实施严格保护举措的一大障碍。同时，人类活动加速了新信息收集和处理的需求，而现有文献数据多为非机器可读，导致数据获取效率低下。

Method: 本文推出了ARETE R包，这是一个开源软件，旨在通过大型语言模型（特别是chatGPT API）自动提取物种出现数据。该R包整合了数据提取和验证的所有步骤，包括光学字符识别、异常值检测以及以表格形式输出。ARETE通过将模型提取结果与人工标注结果进行系统比较来验证其有效性。

Result: 通过将使用GBIF数据和ARETE自动提取的100种蜘蛛的范围图进行比较，结果表明，新提取的数据将已知物种的出现范围平均扩大了三个数量级，揭示了过去发现物种的新区域。这对于空间保护规划和灭绝风险评估具有重要意义。

Conclusion: ARETE R包S能够更快地获取先前未被利用的物种出现数据，对于需要此类数据的项目来说具有颠覆性潜力。研究人员可以更好地分配资源，对手动验证选定物种进行优先排序，同时对大多数物种保持自动化提取。此工作流程还有助于在项目规划阶段预测可用的书目数据。

Abstract: 1. A hard stop for the implementation of rigorous conservation initiatives is
our lack of key species data, especially occurrence data. Furthermore,
researchers have to contend with an accelerated speed at which new information
must be collected and processed due to anthropogenic activity. Publications
ranging from scientific papers to gray literature contain this crucial
information but their data are often not machine-readable, requiring extensive
human work to be retrieved. 2. We present the ARETE R package, an open-source
software aiming to automate data extraction of species occurrences powered by
large language models, namely using the chatGPT Application Programming
Interface. This R package integrates all steps of the data extraction and
validation process, from Optical Character Recognition to detection of outliers
and output in tabular format. Furthermore, we validate ARETE through systematic
comparison between what is modelled and the work of human annotators. 3. We
demonstrate the usefulness of the approach by comparing range maps produced
using GBIF data and with those automatically extracted for 100 species of
spiders. Newly extracted data allowed to expand the known Extent of Occurrence
by a mean three orders of magnitude, revealing new areas where the species were
found in the past, which mayhave important implications for spatial
conservation planning and extinction risk assessments. 4. ARETE allows faster
access to hitherto untapped occurrence data, a potential game changer in
projects requiring such data. Researchers will be able to better prioritize
resources, manually verifying selected species while maintaining automated
extraction for the majority. This workflow also allows predicting available
bibliographic data during project planning.

</details>


### [114] [Environment Agnostic Goal-Conditioning, A Study of Reward-Free Autonomous Learning](https://arxiv.org/abs/2511.04598)
*Hampus Åström,Elin Anna Topp,Jacek Malec*

Main category: cs.LG

TL;DR: 该论文研究了如何将常规强化学习环境转化为目标条件环境，从而使智能体能够自主地、无奖励地学习解决任务。


<details>
  <summary>Details</summary>
Motivation: 作者旨在使智能体能够通过在环境不可知的方式中选择自己的目标来解决任务。

Method: 本文提出了一种将常规强化学习环境转化为目标条件环境的方法，该方法独立于底层的离策略学习算法。

Result: 实验结果表明，在与外部引导强化学习相当的训练时间内，智能体可以学会解决任务。尽管单个目标的性能可能不稳定，但平均目标成功率有所提高并趋于稳定。

Conclusion: 该方法能够实现智能体在特定用例之前进行通用训练，使其能够按照指令寻求环境中产生的任何观测。

Abstract: In this paper we study how transforming regular reinforcement learning
environments into goal-conditioned environments can let agents learn to solve
tasks autonomously and reward-free. We show that an agent can learn to solve
tasks by selecting its own goals in an environment-agnostic way, at training
times comparable to externally guided reinforcement learning. Our method is
independent of the underlying off-policy learning algorithm. Since our method
is environment-agnostic, the agent does not value any goals higher than others,
leading to instability in performance for individual goals. However, in our
experiments, we show that the average goal success rate improves and
stabilizes. An agent trained with this method can be instructed to seek any
observations made in the environment, enabling generic training of agents prior
to specific use cases.

</details>


### [115] [Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems](https://arxiv.org/abs/2511.04641)
*Hans Harder,Abhijeet Vishwasrao,Luca Guastoni,Ricardo Vinuesa,Sebastian Peitz*

Main category: cs.LG

TL;DR: 本文探讨了用于预测由偏微分方程描述的动态系统的概率技术，重点关注减少采样步骤的流匹配范例扩展。


<details>
  <summary>Details</summary>
Motivation: 探索和比较减少采样步骤的流匹配范例扩展，并应对直接预测大规模 3D 模拟的 2D 切片以实现高效流入生成的挑战。

Method: 本文研究并比较了直接蒸馏、渐进蒸馏、对抗扩散蒸馏、Wasserstein GAN 和修正流等多种流匹配范式扩展。

Result: 通过对一系列具有挑战性的系统进行实验，比较了各种方法的性能。此外，还解决了直接预测大规模 3D 模拟的 2D 切片的问题。

Conclusion: 本文成功地研究并比较了多种减少采样步骤的流匹配范式扩展，为预测动态系统和高效流入生成提供了有效的概率技术。

Abstract: This paper is concerned with probabilistic techniques for forecasting
dynamical systems described by partial differential equations (such as, for
example, the Navier-Stokes equations). In particular, it is investigating and
comparing various extensions to the flow matching paradigm that reduce the
number of sampling steps. In this regard, it compares direct distillation,
progressive distillation, adversarial diffusion distillation, Wasserstein GANs
and rectified flows. Moreover, experiments are conducted on a set of
challenging systems. In particular, we also address the challenge of directly
predicting 2D slices of large-scale 3D simulations, paving the way for
efficient inflow generation for solvers.

</details>


### [116] [Optimal Inference Schedules for Masked Diffusion Models](https://arxiv.org/abs/2511.04647)
*Sitan Chen,Kevin Cong,Jerry Li*

Main category: cs.LG

TL;DR: 本文分析了扩散语言模型（MDM）在并行采样方面的性能，指出MDM在并行采样时可能会出现性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 解决自回归大型语言模型推理过程的顺序性导致的推理时间长、成本高的问题。

Method: 通过建立真实分布与采样分布之间预期散度的精确表征，并将其与单变量函数逼近理论联系起来，来研究并行采样的性能。

Result: 发现了总相关性和双总相关性等信息论特性在确定采样调度和性能上限方面的作用，结果表明在某些情况下，可以在O(log n)步内完成采样，且性能没有明显损失。

Conclusion: 在没有先验知识的情况下，很难找到最优的并行采样策略，但通过利用信息论特性，可以在某些场景下实现高效的并行采样。

Abstract: A major bottleneck of standard auto-regressive large language models is that
their inference process is inherently sequential, resulting in very long and
costly inference times. To circumvent this, practitioners proposed a class of
language models called diffusion language models, of which the masked diffusion
model (MDM) is the most successful. The MDM is able to sample tokens
out-of-order and, ostensibly, many tokens at once and in parallel. However,
there is very limited rigorous understanding of how much parallel sampling
these models can perform without noticeable degradation in their sampling
performance. Prior work of Li and Cai obtained some preliminary bounds, but
these are not tight for many natural classes of distributions. In this work, we
give a new, exact characterization of the expected divergence between the true
distribution and the sampled distribution, for any distribution and any
unmasking schedule for the sampler, showing an elegant connection to the theory
of univariate function approximation.
  By leveraging this connection, we then attain a number of novel lower and
upper bounds for this problem. While the connection to function approximation
in principle gives the optimal unmasking schedule for any distribution, we show
that it is in general impossible to compete with it without strong a priori
knowledge of the distribution, even in seemingly benign settings. However, we
also demonstrate new upper bounds and new sampling schedules in terms of
well-studied information-theoretic properties of the base distribution, namely,
its total correlation and dual total correlation, which show that in some
natural settings, one can sample in $O(log n)$ steps without any visible loss
in performance, where $n$ is the total sequence length.

</details>


### [117] [TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning](https://arxiv.org/abs/2511.04653)
*Xinlu Zhang,Yansha Deng,Toktam Mahmoodi*

Main category: cs.LG

TL;DR: 本文提出了一种自适应模型剪枝技术，用于解决无线时间触发联邦学习（TT-Fed）中的通信开销和掉队者问题，并通过联合优化剪枝率和带宽分配来最小化训练损失并保证学习时延。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在解决数据隐私问题方面具有巨大潜力，但无线TT-Fed系统面临用户设备数量增长、无线带宽有限导致的掉队者和通信开销等挑战。

Method: 作者对基于模型剪枝的TT-Fed模型的梯度L2范数进行了收敛性分析，并在此基础上建立了剪枝率和无线带宽的联合优化问题，以在给定延迟阈值下最小化模型训练损失。利用KKT条件推导出无线带宽和剪枝率的闭式解。

Result: 仿真结果表明，模型剪枝可以在保持模型性能不变的情况下，将通信开销降低40%。

Conclusion: 本文提出的自适应模型剪枝技术能有效降低无线TT-Fed系统的通信开销，提高系统效率，且在理论分析和实验结果上均得到验证。

Abstract: Federated learning (FL) offers new opportunities in machine learning,
particularly in addressing data privacy concerns. In contrast to conventional
event-based federated learning, time-triggered federated learning (TT-Fed), as
a general form of both asynchronous and synchronous FL, clusters users into
different tiers based on fixed time intervals. However, the FL network consists
of a growing number of user devices with limited wireless bandwidth,
consequently magnifying issues such as stragglers and communication overhead.
In this paper, we introduce adaptive model pruning to wireless TT-Fed systems
and study the problem of jointly optimizing the pruning ratio and bandwidth
allocation to minimize the training loss while ensuring minimal learning
latency. To answer this question, we perform convergence analysis on the
gradient l_2 norm of the TT-Fed model based on model pruning. Based on the
obtained convergence upper bound, a joint optimization problem of pruning ratio
and wireless bandwidth is formulated to minimize the model training loss under
a given delay threshold. Then, we derive closed-form solutions for wireless
bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The
simulation results show that model pruning could reduce the communication cost
by 40% while maintaining the model performance at the same level.

</details>


### [118] [Nowcast3D: Reliable precipitation nowcasting via gray-box learning](https://arxiv.org/abs/2511.04659)
*Huaguan Chen,Wei Han,Haofei Sun,Ning Lin,Xingtao Song,Yunfan Yang,Jie Tian,Yang Liu,Ji-Rong Wen,Xiaoye Zhang,Xueshun Shen,Hao Sun*

Main category: cs.LG

TL;DR: 该文章介绍了一种用于极端降水临近预报的灰盒三维框架，它结合了物理约束和数据驱动学习，实现了三小时的准确预报，并在气象学家盲评中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的极端降水临近预报方法（如NWPs和外推模型）在时空分辨率、预报速度、误差积累和对三维垂直信息的利用方面存在局限性，无法准确捕捉快速演变的对流和高度依赖的动态。

Method: 该框架是一个灰盒、完全三维的临近预报系统，直接处理体视雷达反射率数据。它将物理约束的神经算子与数据驱动学习相结合，学习垂直变化的3D平流场（在保守平流算子下），参数化空间变化的扩散，并引入受布朗运动启发的随机项来表示未解决的运动。此外，一个残差分支捕捉小尺度对流起始和微物理变化，而一个基于扩散的随机模块估计不确定性。

Result: 该框架在长达三小时的预报时间内，对各种降水情况实现了更准确的预报。在160位气象学家的盲评中，该框架在57%的案例中排名第一。

Conclusion: 通过恢复具有物理一致性的完整三维动态，该灰盒框架为极端降水的熟练可靠的临近预报提供了一个可扩展且稳健的途径，克服了现有方法的局限性。

Abstract: Extreme precipitation nowcasting demands high spatiotemporal fidelity and
extended lead times, yet existing approaches remain limited. Numerical Weather
Prediction (NWP) and its deep-learning emulations are too slow and coarse for
rapidly evolving convection, while extrapolation and purely data-driven models
suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based
methods discard crucial vertical information, preventing accurate
reconstruction of height-dependent dynamics. We introduce a gray-box, fully
three-dimensional nowcasting framework that directly processes volumetric radar
reflectivity and couples physically constrained neural operators with
datadriven learning. The model learns vertically varying 3D advection fields
under a conservative advection operator, parameterizes spatially varying
diffusion, and introduces a Brownian-motion--inspired stochastic term to
represent unresolved motions. A residual branch captures small-scale convective
initiation and microphysical variability, while a diffusion-based stochastic
module estimates uncertainty. The framework achieves more accurate forecasts up
to three-hour lead time across precipitation regimes and ranked first in 57\%
of cases in a blind evaluation by 160 meteorologists. By restoring full 3D
dynamics with physical consistency, it offers a scalable and robust pathway for
skillful and reliable nowcasting of extreme precipitation.

</details>


### [119] [Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches](https://arxiv.org/abs/2511.04667)
*Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan*

Main category: cs.LG

TL;DR: 该研究使用结合了传统测试理论、机器学习和无监督聚类的多方法框架，评估了一项包含40个项目的数学分班考试，并对198名学生进行了测试。结果显示，该考试存在区分度不佳的题目，机器学习模型表现出色，聚类分析揭示了与现有标准不符的潜在能力结构。研究建议替换区分度差的题目，实施两阶段评估，并整合随机森林预测以优化分班。


<details>
  <summary>Details</summary>
Motivation: 此研究旨在评估一个40项数学分班考试的有效性，并找出改进该考试和优化学生分班的方法，以解决传统分班方法的潜在不足。

Method: 本研究采用多方法框架，结合了以下技术：1. 经典测试理论（CTT）对试题的区分度进行分析。2. 机器学习（ML）算法（如随机森林和梯度提升）用于预测和评估。3. 无监督聚类（K-means）用于识别学生能力的内在结构。这些方法被用于分析198名学生的考试数据。

Result: 1. 经典测试理论分析显示，55%的题目具有优异的区分度（D ≥ 0.40），而30%的题目区分度较差（D < 0.20），需替换。2. 第6题（图表解释）是区分度最高的题目（D = 1.000），具有最高的ANOVA F统计量（F = 4609.1）和最大的随机森林特征重要性（0.206）。3. 机器学习算法表现出色，随机森林和梯度提升的交叉验证准确率分别为97.5%和96.0%。4. K-means聚类识别出了一种自然存在的二元能力结构，分界点在42.5%，这与当前55%的机构分班阈值不同，表明可能存在过度分类至补习类别的情况。5. 两个聚类解决方案表现出极高的稳定性（bootstrap ARI = 0.855），且低能力聚类的纯度完美。

Conclusion: 多方法整合为优化数学分班提供了强大的实证基础。研究建议：1. 替换区分度差的题目。2. 实施两阶段评估。3. 整合随机森林预测与透明度机制。这些改进措施有望提高数学分班的准确性和公平性，避免学生被不当地分入补习课程。

Abstract: This study evaluates a 40-item mathematics placement examination administered
to 198 students using a multi-method framework combining Classical Test Theory,
machine learning, and unsupervised clustering. Classical Test Theory analysis
reveals that 55\% of items achieve excellent discrimination ($D \geq 0.40$)
while 30\% demonstrate poor discrimination ($D < 0.20$) requiring replacement.
Question 6 (Graph Interpretation) emerges as the examination's most powerful
discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA
F-statistic ($F = 4609.1$), and maximum Random Forest feature importance
(0.206), accounting for 20.6\% of predictive power. Machine learning algorithms
demonstrate exceptional performance, with Random Forest and Gradient Boosting
achieving 97.5\% and 96.0\% cross-validation accuracy. K-means clustering
identifies a natural binary competency structure with a boundary at 42.5\%,
diverging from the institutional threshold of 55\% and suggesting potential
overclassification into remedial categories. The two-cluster solution exhibits
exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster
purity. Convergent evidence across methods supports specific refinements:
replace poorly discriminating items, implement a two-stage assessment, and
integrate Random Forest predictions with transparency mechanisms. These
findings demonstrate that multi-method integration provides a robust empirical
foundation for evidence-based mathematics placement optimization.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [120] [OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems](https://arxiv.org/abs/2511.03761)
*Umut Çalıkyılmaz,Nitin Nayak,Jinghua Groppe,Sven Groppe*

Main category: cs.MA

TL;DR: 这篇论文提出了一种名为OptiMA的框架，用于设计和执行大规模多智能体系统（VCMAS），通过事务处理和事务调度来解决复杂系统中的容错性和性能瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 探索大型复杂多智能体模型的趋势带来了两个潜在问题：对故障的敏感性和性能瓶颈。

Method: 提出一个基于事务的框架来设计容错的VCMAS。为了解决性能瓶颈，将事务调度集成到该框架中。

Result: 开发了OptiMA框架，能够促进超过一百个智能体的VCMAS的执行。事务调度使系统性能提高了超过16%。

Conclusion: OptiMA框架通过事务处理和事务调度有效解决了VCMAS的可靠性和性能问题，并为未来的事务调度研究提供了理论分析和实用工具。

Abstract: In recent years, the research of multi-agent systems has taken a direction to
explore larger and more complex models to fulfill sophisticated tasks. We point
out two possible pitfalls that might be caused by increasing complexity;
susceptibilities to faults, and performance bottlenecks. To prevent the former
threat, we propose a transaction-based framework to design very complex
multi-agent systems (VCMAS). To address the second threat, we offer to
integrate transaction scheduling into the proposed framework. We implemented
both of these ideas to develop the OptiMA framework and show that it is able to
facilitate the execution of VCMAS with more than a hundred agents. We also
demonstrate the effect of transaction scheduling on such a system by showing
improvements up to more than 16\%. Furthermore, we also performed a theoretical
analysis on the transaction scheduling problem and provided practical tools
that can be used for future research on it.

</details>


### [121] [ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training](https://arxiv.org/abs/2511.03844)
*Yuran Ding,Xinwei Chen,Xiaofan Zhang,Zongwei Zhou*

Main category: cs.MA

TL;DR: 该论文介绍了一个名为ASAP的多智能体系统，旨在自动化优化大型语言模型（LLM）的分布式训练性能，通过诊断瓶颈并推荐分片配置，从而显著提高训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM分布式训练优化方法依赖于耗时的人工调整或资源密集型黑盒搜索，难以适应快速发展的LLM领域，导致开发缓慢和资源利用不足。

Method: ASAP是一个多智能体系统，包含协调器、分析器和提议器智能体。它将LLM推理与性能分析工具、屋脊线分析以及包含专家最佳实践和成功优化经验的知识库相结合，自动诊断性能瓶颈并推荐优化的分片配置。

Result: 实验表明，ASAP生成的分片配置可将训练步骤时间减少高达28%，吞吐量提高1.43倍。结合人工专家的额外优化，吞吐量可进一步提高到2.58倍。

Conclusion: ASAP为大规模LLM训练中的AI辅助性能工程提供了一种可扩展且可解释的方法，有望解决现有优化方法的效率问题。

Abstract: Optimizing large-language model (LLM) training on distributed domain-specific
accelerator systems presents significant challenges due to its complex
optimization space. Existing optimization methods, however, rely on
time-consuming manual tuning or resource-intensive black-box searches, which
struggle to keep pace with the rapidly evolving LLM domain, leading to slow
development and underutilized resources. To address this, we introduce ASAP, an
Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It
is a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents,
which integrates LLM reasoning with insights from performance profiling tools,
roofline analysis, and a knowledge base of best practices and successful past
optimizations from human experts. Our proposed design can automate the
diagnosis of performance bottlenecks and recommend optimized sharding
configurations with reasoning, thus effectively improving the efficiency of
distributed LLM training. Experiments have shown that the ASAP-generated
sharding configurations can contribute up to 28% training step time reduction
and 1.43 times throughput improvement. When combined with additional
optimization from human experts, throughput can be further increased to 2.58
times. The proposed ASAP promises to provide a scalable and explainable
methodology for AI-assisted performance engineering in large-scale LLM
training.

</details>


### [122] [Multi-Agent Collaborative Framework For Math Problem Generation](https://arxiv.org/abs/2511.03958)
*Kia Karbasi,Kevin Hong,Mohammad Amin Samadi,Gregory Pottie*

Main category: cs.MA

TL;DR: 本文介绍了一种利用协作多智能体框架进行数学教育自动问题生成（AQG）的新方法，该方法通过迭代优化来平衡问题的复杂性和认知需求，并初步评估显示其能提升生成内容的质量。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练的基于Transformer的语言模型在自然语言生成方面取得了显著进展，但它们在精确控制问题复杂性和认知需求方面仍存在困难，这使得数学教育领域的自动问题生成（AQG）成为智能辅导系统和教育工作者难以实现的目标。

Method: 本文提出了一种协作多智能体框架，将推理时间计算融入自动问题生成（AQG）中。该框架利用多个智能体迭代地优化生成的问题-答案对，以更好地平衡问题的复杂性和认知需求。

Result: 初步评估显示，该协作多智能体框架提升了所生成的教育内容的质量，因为它能够在认知挑战和清晰度之间实现更精细的平衡。

Conclusion: 将协作多智能体工作流整合到自动问题生成中，可以生成更可控、更具教学价值的内容，从而推动自动化教育内容生成和自适应学习环境的发展。

Abstract: Automatic question generation (AQG) for mathematics education remains an
elusive goal for Intelligent Tutoring Systems and educators. While pre-trained
transformer-based language models have significantly advanced natural language
generation, they often struggle to precisely control problem complexity and
cognitive demands. In this paper, we introduce a collaborative multi-agent
framework as a novel method of incorporating inference-time computation into
AQG. This approach leverages multiple agents that iteratively refine generated
question-answer pairs to better balance complexity and cognitive demand. We
evaluate the generated questions on five meta-evaluation criteria: relevance,
importance, clarity, difficulty matching, answerability, to assess the system's
ability to control the required complexity and quality of the questions.
Preliminary evaluations show that this collaborative multi-agent framework
elevates the quality of generated educational content by fostering a more
nuanced balance between cognitive challenge and clarity. These promising
outcomes suggest that integrating collaborative multi-agent workflows can yield
more controlled, pedagogically valuable content that can help advance automated
educational content generation and adaptive learning environments.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [123] [Friction on Demand: A Generative Framework for the Inverse Design of Metainterfaces](https://arxiv.org/abs/2511.03735)
*Valentin Mouton,Adrien Mélot*

Main category: stat.ML

TL;DR: 这篇文章介绍了使用变分自编码器（VAE）根据目标摩擦定律推断表面形貌的生成模型框架，以解决摩擦界面设计中的逆问题。


<details>
  <summary>Details</summary>
Motivation: 设计具有预定宏观行为的摩擦界面是一个具有挑战性的逆问题，因为解决方案的非唯一性和接触模拟的计算成本很高。传统方法依赖于低维参数化的启发式搜索，这限制了它们对更复杂或非线性摩擦定律的适用性。

Method: 本文引入了一个使用变分自编码器（VAE）的生成建模框架，以根据目标摩擦定律推断表面形貌。该方法在一个包含2亿个样本的合成数据集上进行训练，这些样本由参数化接触力学模型构建，从而实现了候选形貌的高效、无模拟生成。

Result: 我们研究了生成模型在该逆设计任务中的潜力和局限性，重点在于平衡生成解决方案的准确性、吞吐量和多样性。

Conclusion: 结果 M B . L & o A S强调了在平衡这些目标时的权衡和实际考虑。这种方法为通过定制表面形貌实现摩擦行为的近实时控制铺平了道路。

Abstract: Designing frictional interfaces to exhibit prescribed macroscopic behavior is
a challenging inverse problem, made difficult by the non-uniqueness of
solutions and the computational cost of contact simulations. Traditional
approaches rely on heuristic search over low-dimensional parameterizations,
which limits their applicability to more complex or nonlinear friction laws. We
introduce a generative modeling framework using Variational Autoencoders (VAEs)
to infer surface topographies from target friction laws. Trained on a synthetic
dataset composed of 200 million samples constructed from a parameterized
contact mechanics model, the proposed method enables efficient, simulation-free
generation of candidate topographies. We examine the potential and limitations
of generative modeling for this inverse design task, focusing on balancing
accuracy, throughput, and diversity in the generated solutions. Our results
highlight trade-offs and outline practical considerations when balancing these
objectives. This approach paves the way for near-real-time control of
frictional behavior through tailored surface topographies.

</details>


### [124] [Learning Paths for Dynamic Measure Transport: A Control Perspective](https://arxiv.org/abs/2511.03797)
*Aimee Maurais,Bamdad Hosseini,Youssef Marzouk*

Main category: stat.ML

TL;DR: 本文提出了一种从控制角度识别动态测量传输（DMT）测量路径的方法，并证明了其在生成更高效、更平滑传输模型方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的测量传输（DMT）路径选择可能不够理想，现有学习替代路径的方法与平均场博弈存在关联。

Method: 本文提出了一系列灵活的优化问题，用于识别DMT的倾斜测量路径，并建议使用鼓励相应速度平滑度的目标项。通过基于高斯过程方法求解偏微分方程的数值算法来解决这些问题。

Result: 与使用未倾斜参考路径的模型相比，该方法能够恢复更高效、更平滑的传输模型。

Conclusion: 从控制角度识别倾斜的测量路径，并通过鼓励速度平滑度的目标项进行优化，可以显著提高动态测量传输的效率和模型平滑度。

Abstract: We bring a control perspective to the problem of identifying paths of
measures for sampling via dynamic measure transport (DMT). We highlight the
fact that commonly used paths may be poor choices for DMT and connect existing
methods for learning alternate paths to mean-field games. Based on these
connections we pose a flexible family of optimization problems for identifying
tilted paths of measures for DMT and advocate for the use of objective terms
which encourage smoothness of the corresponding velocities. We present a
numerical algorithm for solving these problems based on recent Gaussian process
methods for solution of partial differential equations and demonstrate the
ability of our method to recover more efficient and smooth transport models
compared to those which use an untilted reference path.

</details>


### [125] [A general technique for approximating high-dimensional empirical kernel matrices](https://arxiv.org/abs/2511.03892)
*Chiraag Kaushik,Justin Romberg,Vidya Muthukumar*

Main category: stat.ML

TL;DR: 本文提出了一种计算随机核矩阵期望算子范数的简便方法，并通过该方法对内积核矩阵的期望算子范数进行了更精确的近似，同时也为核回归的偏差提供了一个更紧的下界。


<details>
  <summary>Details</summary>
Motivation: 作者旨在解决随机核矩阵期望算子范数的计算问题，并希望提供一个更简洁、用户友好的边界。

Method: 本文利用U-统计量的解耦结果和非交换Khintchine不等式来获得上界和下界。这些界限仅依赖于核函数的标量统计量和相应的“相关核”矩阵。

Result: 通过所提出的方法，文章对高维内积核矩阵的期望算子范数提供了新的、更紧密的近似。此外，该方法简化了现有结果的证明，并为各向异性高斯数据提供了新的近似结果。

Conclusion: 本文成功地为随机核矩阵的期望算子范数提供了简单且用户友好的界限，并在理论和实践上提升了对核方法的理解和应用。

Abstract: We present simple, user-friendly bounds for the expected operator norm of a
random kernel matrix under general conditions on the kernel function
$k(\cdot,\cdot)$. Our approach uses decoupling results for U-statistics and the
non-commutative Khintchine inequality to obtain upper and lower bounds
depending only on scalar statistics of the kernel function and a ``correlation
kernel'' matrix corresponding to $k(\cdot,\cdot)$. We then apply our method to
provide new, tighter approximations for inner-product kernel matrices on
general high-dimensional data, where the sample size and data dimension are
polynomially related. Our method obtains simplified proofs of existing results
that rely on the moment method and combinatorial arguments while also providing
novel approximation results for the case of anisotropic Gaussian data. Finally,
using similar techniques to our approximation result, we show a tighter lower
bound on the bias of kernel regression with anisotropic Gaussian data.

</details>


### [126] [High-dimensional limit theorems for SGD: Momentum and Adaptive Step-sizes](https://arxiv.org/abs/2511.03952)
*Aukosh Jagannath,Taj Jones-McCormick,Varnan Sarangian*

Main category: stat.ML

TL;DR: 本文对Polyak动量随机梯度下降(SGD-M)和自适应步长的极限进行了高维缩放，并将在线SGD与一些流行变体进行了比较。


<details>
  <summary>Details</summary>
Motivation: 开发一个高维缩放限制，用于Polyak动量随机梯度下降(SGD-M)和自适应步长的随机梯度下降。

Method: 高维缩放限制理论分析。

Result: SGD-M的缩放限制在适当的时间重定标和特定的步长选择后，与在线SGD的缩放限制一致。然而，如果两个算法之间的步长保持不变，SGD-M将放大高维效应，可能导致性能相对于在线SGD下降。

Conclusion: 通过Spiked Tensor PCA和Single Index Models等案例，证明了自适应步长的在线SGD在这些高维模型中具有更好的性能，并且可以稳定和改善动力学。

Abstract: We develop a high-dimensional scaling limit for Stochastic Gradient Descent
with Polyak Momentum (SGD-M) and adaptive step-sizes. This provides a framework
to rigourously compare online SGD with some of its popular variants. We show
that the scaling limits of SGD-M coincide with those of online SGD after an
appropriate time rescaling and a specific choice of step-size. However, if the
step-size is kept the same between the two algorithms, SGD-M will amplify
high-dimensional effects, potentially degrading performance relative to online
SGD. We demonstrate our framework on two popular learning problems: Spiked
Tensor PCA and Single Index Models. In both cases, we also examine online SGD
with an adaptive step-size based on normalized gradients. In the
high-dimensional regime, this algorithm yields multiple benefits: its dynamics
admit fixed points closer to the population minimum and widens the range of
admissible step-sizes for which the iterates converge to such solutions. These
examples provide a rigorous account, aligning with empirical motivation, of how
early preconditioners can stabilize and improve dynamics in settings where
online SGD fails.

</details>


### [127] [Robust inference using density-powered Stein operators](https://arxiv.org/abs/2511.03963)
*Shinto Eguchi*

Main category: stat.ML

TL;DR: 本文介绍了一种称为$\gamma$-Stein算子的新型Stein算子变体，它基于$\gamma$-散度，旨在为未归一化概率模型构建鲁棒的推断方法。


<details>
  <summary>Details</summary>
Motivation: 为未归一化概率模型开发鲁棒的推断方法。

Method: 引入了密度幂加权变体$\gamma$-Stein算子，并通过将模型密度提高到正幂$\gamma$来加权，从而降低异常值的影响。将此算子应用于得分匹配，提出了$\gamma$-核化Stein差异进行鲁棒拟合优度检验，并提出了$\gamma$-Stein变分梯度下降进行鲁棒贝叶斯后验逼近。

Result: 在污染高斯模型和四次势模型上的经验结果表明，该方法在鲁棒性和统计效率方面均显著优于标准基线。

Conclusion: $\gamma$-Stein算子及其派生方法为处理未归一化概率模型中的异常值提供了一种有原则且有效的鲁棒推断机制。

Abstract: We introduce a density-power weighted variant for the Stein operator, called
the $\gamma$-Stein operator. This is a novel class of operators derived from
the $\gamma$-divergence, designed to build robust inference methods for
unnormalized probability models. The operator's construction (weighting by the
model density raised to a positive power $\gamma$ inherently down-weights the
influence of outliers, providing a principled mechanism for robustness.
Applying this operator yields a robust generalization of score matching that
retains the crucial property of being independent of the model's normalizing
constant. We extend this framework to develop two key applications: the
$\gamma$-kernelized Stein discrepancy for robust goodness-of-fit testing, and
$\gamma$-Stein variational gradient descent for robust Bayesian posterior
approximation. Empirical results on contaminated Gaussian and quartic potential
models show our methods significantly outperform standard baselines in both
robustness and statistical efficiency.

</details>


### [128] [Online Conformal Inference with Retrospective Adjustment for Faster Adaptation to Distribution Shift](https://arxiv.org/abs/2511.04275)
*Jungbin Jun,Ilsang Ohn*

Main category: stat.ML

TL;DR: 本文提出了一种具有追溯调整功能的新型在线共形推断方法，可以更快地适应分布变化。


<details>
  <summary>Details</summary>
Motivation: 传统的共形预测方法在数据分布随时间变化的在线环境中表现不佳，因为它们适应分布变化的速度较慢。

Method: 本文提出了一种具有追溯调整功能的新型在线共形推断方法，该方法利用回归方法和高效的“留一法”更新公式，在新数据到达时追溯调整过去的预测，使整个预测集与最新的数据分布保持一致。

Result: 在合成和真实世界数据集上进行的大量数值研究表明，与现有的在线共形预测方法相比，该方法实现了更快的覆盖率重新校准和更高的统计效率。

Conclusion: 本文提出的追溯调整在线共形推断方法可以更快地适应分布变化，并在在线环境中获得更好的预测性能。

Abstract: Conformal prediction has emerged as a powerful framework for constructing
distribution-free prediction sets with guaranteed coverage assuming only the
exchangeability assumption. However, this assumption is often violated in
online environments where data distributions evolve over time. Several recent
approaches have been proposed to address this limitation, but, typically, they
slowly adapt to distribution shifts because they update predictions only in a
forward manner, that is, they generate a prediction for a newly observed data
point while previously computed predictions are not updated. In this paper, we
propose a novel online conformal inference method with retrospective
adjustment, which is designed to achieve faster adaptation to distributional
shifts. Our method leverages regression approaches with efficient leave-one-out
update formulas to retroactively adjust past predictions when new data arrive,
thereby aligning the entire set of predictions with the most recent data
distribution. Through extensive numerical studies performed on both synthetic
and real-world data sets, we show that the proposed approach achieves faster
coverage recalibration and improved statistical efficiency compared to existing
online conformal prediction methods.

</details>


### [129] [Robustness of Minimum-Volume Nonnegative Matrix Factorization under an Expanded Sufficiently Scattered Condition](https://arxiv.org/abs/2511.04291)
*Giovanni Barbarino,Nicolas Gillis,Subhayan Saha*

Main category: stat.ML

TL;DR: 这篇论文介绍了一种能够处理噪声的最小体积非负矩阵分解（min-vol NMF）方法。


<details>
  <summary>Details</summary>
Motivation: 以往的最小体积非负矩阵分解（min-vol NMF）在解决降噪问题时，鲁棒性一直是一个难题。这篇论文旨在解决在存在噪声的情况下，min-vol NMF 如何识别出真实因素的问题。

Method: 通过引入一个名为“扩展充分分散条件”的条件，以确保数据点在由基向量生成的潜在单纯形中充分分散，从而证明 min-vol NMF 即使在存在噪声的情况下也能识别出真实因素。

Result: 在满足扩展充分分散条件的情况下，即使存在噪声，min-vol NMF 也能有效地识别出原始因子。

Conclusion: 这篇论文证明了在特定条件下，即使存在噪声，最小体积非负矩阵分解（min-vol NMF）也能准确识别出真实因素。

Abstract: Minimum-volume nonnegative matrix factorization (min-vol NMF) has been used
successfully in many applications, such as hyperspectral imaging, chemical
kinetics, spectroscopy, topic modeling, and audio source separation. However,
its robustness to noise has been a long-standing open problem. In this paper,
we prove that min-vol NMF identifies the groundtruth factors in the presence of
noise under a condition referred to as the expanded sufficiently scattered
condition which requires the data points to be sufficiently well scattered in
the latent simplex generated by the basis vectors.

</details>


### [130] [Simultaneous Optimization of Geodesics and Fréchet Means](https://arxiv.org/abs/2511.04301)
*Frederik Möbius Rygaard,Søren Hauberg,Steen Markvorsen*

Main category: stat.ML

TL;DR: 本文提出了一种新的算法GEORCE-FM，用于快速有效地计算黎曼和芬斯勒流形上的Fréchet均值，并在理论和实践中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: Fréchet均值是几何统计中的核心概念，但在大多数流形上，即使是计算黎曼距离也涉及复杂的优化问题，导致现有Fréchet均值数值计算方法效率低下。

Method: GEORCE-FM算法通过在每次迭代中同时计算局部坐标图中的Fréchet均值和黎曼距离来提高计算速度。它还扩展到芬斯勒流形，并引入自适应扩展以处理大量数据点。

Result: GEORCE-FM算法具有全局收敛性和局部二次收敛性，并且其自适应扩展在期望意义上收敛到Fréchet均值。在准确性和运行时间方面，GEORCE-FM均优于现有基线方法。

Conclusion: GEORCE-FM算法是一种高效、准确计算黎曼和芬斯勒流形上Fréchet均值的新方法，具有良好的理论收敛性和实践性能，为几何统计学提供了有力的工具。

Abstract: A central part of geometric statistics is to compute the Fr\'echet mean. This
is a well-known intrinsic mean on a Riemannian manifold that minimizes the sum
of squared Riemannian distances from the mean point to all other data points.
The Fr\'echet mean is simple to define and generalizes the Euclidean mean, but
for most manifolds even minimizing the Riemannian distance involves solving an
optimization problem. Therefore, numerical computations of the Fr\'echet mean
require solving an embedded optimization problem in each iteration. We
introduce the GEORCE-FM algorithm to simultaneously compute the Fr\'echet mean
and Riemannian distances in each iteration in a local chart, making it faster
than previous methods. We extend the algorithm to Finsler manifolds and
introduce an adaptive extension such that GEORCE-FM scales to a large number of
data points. Theoretically, we show that GEORCE-FM has global convergence and
local quadratic convergence and prove that the adaptive extension converges in
expectation to the Fr\'echet mean. We further empirically demonstrate that
GEORCE-FM outperforms existing baseline methods to estimate the Fr\'echet mean
in terms of both accuracy and runtime.

</details>


### [131] [Riesz Regression As Direct Density Ratio Estimation](https://arxiv.org/abs/2511.04568)
*Masahiro Kato*

Main category: stat.ML

TL;DR: 本文分析了Riesz回归与直接密度比估计（DRE）之间的密切关系，特别是在平均处理效应（ATE）估计中。研究表明，Riesz回归的思想和目标与最小二乘重要性拟合（LSIF）一致，并由此证明了两者在特定情况下的等价性。


<details>
  <summary>Details</summary>
Motivation: 证明Riesz回归与直接密度比估计（DRE）之间的等价性，并利用这种等价性将DRE的现有成果引入Riesz回归，同时拓展DRE的应用范围。

Method: 通过理论分析和比较，作者证明了Riesz回归的思想和目标与直接密度比估计中的最小二乘重要性拟合（LSIF）一致，从而推导出两者在特定情况下的等价性。

Result: Riesz回归在重要情况下（包括平均处理效应估计）与直接密度比估计（DRE）密切相关。Riesz回归的思想和目标与直接密度比估计中的最小二乘重要性拟合（LSIF）一致。这种等价性允许将在收敛率分析、损失函数选择和正则化技术等方面的DRE现有成果直接应用于Riesz回归。反之，Riesz表示在去偏机器学习中的见解也拓宽了直接密度比估计方法的应用。

Conclusion: Riesz回归和直接密度比估计（DRE）在特定情况下是等价的，这种等价性为两者之间的知识迁移提供了桥梁，促进了去偏机器学习和密度比估计领域的发展和应用。

Abstract: Riesz regression has garnered attention as a tool in debiased machine
learning for causal and structural parameter estimation (Chernozhukov et al.,
2021). This study shows that Riesz regression is closely related to direct
density-ratio estimation (DRE) in important cases, including average treat-
ment effect (ATE) estimation. Specifically, the idea and objective in Riesz
regression coincide with the one in least-squares importance fitting (LSIF,
Kanamori et al., 2009) in direct density-ratio estimation. While Riesz
regression is general in the sense that it can be applied to Riesz representer
estimation in a wide class of problems, the equivalence with DRE allows us to
directly import exist- ing results in specific cases, including
convergence-rate analyses, the selection of loss functions via
Bregman-divergence minimization, and regularization techniques for flexible
models, such as neural networks. Conversely, insights about the Riesz
representer in debiased machine learning broaden the applications of direct
density-ratio estimation methods. This paper consolidates our prior results in
Kato (2025a) and Kato (2025b).

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [132] [On the Existence of Fair Allocations for Goods and Chores under Dissimilar Preferences](https://arxiv.org/abs/2511.03810)
*Egor Gagushin,Marios Mertzanidis,Alexandros Psomas*

Main category: cs.GT

TL;DR: 本文提出了一种新的方法来解决在任意数量的群体和物品类型下，公平分配不可分割物品的问题。


<details>
  <summary>Details</summary>
Motivation: Gorantla等人[GMV23]证明了在每种物品类型至少出现μ次的情况下，存在无 M 妒的分配，但他们的证明是非建设性的，并且只在两种群体或两种物品类型的情况下给出了μ的明确上限。我们旨在解决Gorantla等人提出的一个主要开放问题：为任意数量的群体和物品类型推导出μ的明确上限。

Method: 我们引入了一种显著更简单但功能强大的技术。该技术不仅为不可分割物品提供了建设性保证，而且自然地扩展到家务和连续领域。

Result: 我们为任意数量的群体和物品类型推导出了μ的明确上限，解决了Gorantla等人[GMV23]提出的一个主要开放问题。

Conclusion: 这项工作为公平分配问题提供了一个通用且可扩展的解决方案，特别是在存在多种群体和物品类型的情况下。该方法不仅适用于不可分割物品，也适用于家务和连续领域，并能推广到蛋糕切割等相关的公平分配场景中。

Abstract: We study the fundamental problem of fairly allocating a multiset
$\mathcal{M}$ of $t$ types of indivisible items among $d$ groups of agents,
where all agents within a group have identical additive valuations. Gorantla et
al. [GMV23] showed that for every such instance, there exists a finite number
$\mu$ such that, if each item type appears at least $\mu$ times, an envy-free
allocation exists. Their proof is non-constructive and only provides explicit
upper bounds on $\mu$ for the cases of two groups ($d=2$) or two item types
($t=2$).
  In this work, we resolve one of the main open questions posed by Gorantla et
al. [GMV23] by deriving explicit upper bounds on $\mu$ that hold for arbitrary
numbers of groups and item types. We introduce a significantly simpler, yet
powerful technique that not only yields constructive guarantees for indivisible
goods but also extends naturally to chores and continuous domains, leading to
new results in related fair division settings such as cake cutting.

</details>


### [133] [Fraud-Proof Revenue Division on Subscription Platforms](https://arxiv.org/abs/2511.04465)
*Abheek Ghosh,Tzeh Yuan Neoh,Nicholas Teh,Giannis Tyrovolas*

Main category: cs.GT

TL;DR: 该文章研究了订阅平台中收入分配机制，以防止欺诈。


<details>
  <summary>Details</summary>
Motivation: 探索能够阻止操纵的收入分配机制，而非依赖机器学习方法。

Method: 形式化了三种反操纵公理，并检验了现有规则是否满足这些公理。引入了一种名为 ScaledUserProp 的新规则。

Result: 广泛使用的流媒体平台机制未能阻止欺诈，甚至使操纵检测变得计算上难以处理。ScaledUserProp 满足所有反操纵公理。

Conclusion: ScaledUserProp 是一种比现有规则更公平的替代方案，并得到了真实和合成流媒体数据的实验支持。

Abstract: We study a model of subscription-based platforms where users pay a fixed fee
for unlimited access to content, and creators receive a share of the revenue.
Existing approaches to detecting fraud predominantly rely on machine learning
methods, engaging in an ongoing arms race with bad actors. We explore revenue
division mechanisms that inherently disincentivize manipulation. We formalize
three types of manipulation-resistance axioms and examine which existing rules
satisfy these. We show that a mechanism widely used by streaming platforms, not
only fails to prevent fraud, but also makes detecting manipulation
computationally intractable. We also introduce a novel rule, ScaledUserProp,
that satisfies all three manipulation-resistance axioms. Finally, experiments
with both real-world and synthetic streaming data support ScaledUserProp as a
fairer alternative compared to existing rules.

</details>


### [134] [Fisher Meets Lindahl: A Unified Duality Framework for Market Equilibrium](https://arxiv.org/abs/2511.04572)
*Yixin Tao,Weiqiang Zheng*

Main category: cs.GT

TL;DR: 本文提出了一个统一的市场均衡对偶框架，并证明了公共品市场的林达尔均衡与对偶费雪市场中的费雪市场均衡相对应。


<details>
  <summary>Details</summary>
Motivation: 探索公共品市场的林达尔均衡与私人品市场的费雪均衡之间的内在联系，并弥补林达尔均衡理论基础不足的问题。

Method: 提出一个统一的对偶框架，将林达尔均衡与费雪市场均衡联系起来，并利用间接效用构建对偶效用。

Result: 在对偶框架下，林达尔均衡的福利性质得到了分析，例如，对于凹齐次效用，林达尔均衡最大化纳什社会福利。同时，对偶框架也被应用于市场动态分析，并扩展了比例响应动态。此外，该框架还被应用于处理“家务型”市场场景。

Conclusion: 本文通过建立林达尔均衡和费雪均衡之间的对偶关系，不仅加深了对市场均衡的理解，还为林达尔均衡的计算和动态分析提供了新的方法和见解，同时推动了费雪市场均衡理论的发展。

Abstract: The Fisher market equilibrium for private goods and the Lindahl equilibrium
for public goods are classic and fundamental solution concepts for market
equilibria. While Fisher market equilibria have been well-studied, the
theoretical foundations for Lindahl equilibria remain substantially
underdeveloped.
  In this work, we propose a unified duality framework for market equilibria.
We show that Lindahl equilibria of a public goods market correspond to Fisher
market equilibria in a dual Fisher market with dual utilities, and vice versa.
The dual utility is based on the indirect utility, and the correspondence
between the two equilibria works by exchanging the roles of allocations and
prices.
  Using the duality framework, we address the gaps concerning the computation
and dynamics for Lindahl equilibria and obtain new insights and developments
for Fisher market equilibria. First, we leverage this duality to analyze
welfare properties of Lindahl equilibria. For concave homogeneous utilities, we
prove that a Lindahl equilibrium maximizes Nash Social Welfare (NSW). For
concave non-homogeneous utilities, we show that a Lindahl equilibrium achieves
$(1/e)^{1/e}$ approximation to the optimal NSW, and the approximation ratio is
tight. Second, we apply the duality framework to market dynamics, including
proportional response dynamics (PRD) and t\^atonnement. We obtain new market
dynamics for the Lindahl equilibria from market dynamics in the dual Fisher
market. We also use duality to extend PRD to markets with total complements
utilities, the dual class of gross substitutes utilities. Finally, we apply the
duality framework to markets with chores. We propose a program for private
chores for general convex homogeneous disutilities that avoids the "poles"
issue, whose KKT points correspond to Fisher market equilibria. We also
initiate the study of the Lindahl equilibrium for public chores.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [135] [Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for Latin American Contexts](https://arxiv.org/abs/2511.04090)
*Brigitte A. Mora-Reyes,Jennifer A. Drewyor,Abel A. Reyes-Angulo*

Main category: cs.SI

TL;DR: 该研究探讨了人工智能系统中拉丁美洲表征中的文化偏见，并提出了一个以拉丁美洲历史和文化为背景的、具有文化意识的数据集，以促进公平的人工智能发展。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统在拉丁美洲不同背景下的表征，揭示了经济发达地区和发展中地区数据之间存在差异，强调了英语相对于西班牙语、葡萄牙语以及盖丘亚语和纳瓦特尔语等本土语言的主导地位如何通过西方视角构建拉丁美洲观点，从而使偏见永久化。

Method: 引入了一个植根于拉丁美洲历史和社会政治背景的、具有文化意识的数据集，挑战了欧洲中心主义模型。评估了六种语言模型在测试文化背景意识问题上的表现，使用了新颖的文化表达性指标、统计测试和语言分析。

Result: 研究结果表明，一些模型能更好地捕捉拉丁美洲的视角，而另一些模型则表现出显著的情感错位（p < 0.001）。用该数据集对Mistral-7B进行微调，其文化表达性提高了42.9%。

Conclusion: 倡导通过优先考虑反映拉丁美洲历史、本土知识和多样化语言的数据集来发展公平的人工智能，同时强调以社区为中心的方法来扩大边缘化声音。

Abstract: Artificial intelligence (AI) systems often reflect biases from economically
advanced regions, marginalizing contexts in economically developing regions
like Latin America due to imbalanced datasets. This paper examines AI
representations of diverse Latin American contexts, revealing disparities
between data from economically advanced and developing regions. We highlight
how the dominance of English over Spanish, Portuguese, and indigenous languages
such as Quechua and Nahuatl perpetuates biases, framing Latin American
perspectives through a Western lens. To address this, we introduce a culturally
aware dataset rooted in Latin American history and socio-political contexts,
challenging Eurocentric models. We evaluate six language models on questions
testing cultural context awareness, using a novel Cultural Expressiveness
metric, statistical tests, and linguistic analyses. Our findings show that some
models better capture Latin American perspectives, while others exhibit
significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our
dataset improves its cultural expressiveness by 42.9%, advancing equitable AI
development. We advocate for equitable AI by prioritizing datasets that reflect
Latin American history, indigenous knowledge, and diverse languages, while
emphasizing community-centered approaches to amplify marginalized voices.

</details>


### [136] [Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI Tools](https://arxiv.org/abs/2511.04453)
*Obada Kraishan*

Main category: cs.SI

TL;DR: 该研究分析了Hacker News（HN）对开源项目在GitHub上获得星标数（stars）的影响，发现HN曝光能够显著增加项目的星标增长，并识别了关键影响因素，特别是发布时间。


<details>
  <summary>Details</summary>
Motivation: 尽管Hacker News等社交新闻平台已成为开源项目重要的发布渠道，但量化它们对项目影响的挑战依然存在。 本文旨在通过可复现的系统来追踪Hacker News曝光如何转化为AI和LLM工具在GitHub上的星标增长。

Method: 本文构建了一个完全基于公共API的可复现演示系统，用于跟踪Hacker News曝光如何转化为GitHub星标增长。该系统分析了2024-2025年期间138个从Hacker News发布的GitHub仓库数据。研究方法包括使用机器学习模型（Elastic Net）和非线性方法（Gradient Boosting）来识别病毒式增长的关键预测因素。整个数据收集、模型训练和可视化过程通过单文件脚本完成，可在标准硬件上五分钟内运行。

Result: 研究发现Hacker News曝光对GitHub星标增长有显著影响：项目在HN曝光后24小时内平均增加121个星标，48小时内增加189个，一周内增加289个。关键的病毒式增长预测因素是发布时间，在最佳时间发布可以带来数百个额外的星标。然而，在控制了其他因素后，“Show HN”标签并未显示出统计学上的优势。

Conclusion: Hacker News曝光显著促进了开源项目在GitHub上的星标增长，其中发布时间是影响病毒式传播的关键因素。本文提出的可复现框架为研究人员和开发者提供了关于项目发布策略的实用洞察，并且易于扩展到其他平台。

Abstract: Social news platforms have become key launch outlets for open-source
projects, especially Hacker News (HN), though quantifying their immediate
impact remains challenging. This paper presents a reproducible demonstration
system that tracks how HN exposure translates into GitHub star growth for AI
and LLM tools. Built entirely on public APIs, our pipeline analyzes 138
repository launches from 2024-2025 and reveals substantial launch effects:
repositories gain an average of 121 stars within 24 hours, 189 stars within 48
hours, and 289 stars within a week of HN exposure. Through machine learning
models (Elastic Net) and non-linear approaches (Gradient Boosting), we identify
key predictors of viral growth. Posting timing appears as key factor--launching
at optimal hours can mean hundreds of additional stars--while the "Show HN" tag
shows no statistical advantage after controlling for other factors. The
demonstration completes in under five minutes on standard hardware,
automatically collecting data, training models, and generating visualizations
through single-file scripts. This makes our findings immediately reproducible
and the framework easily be extended to other platforms, providing both
researchers and developers with actionable insights into launch dynamics.

</details>
