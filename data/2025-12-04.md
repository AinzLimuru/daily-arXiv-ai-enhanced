<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.LG](#cs.LG) [Total: 72]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.IT](#cs.IT) [Total: 6]
- [stat.ML](#stat.ML) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Entropy-Based Measurement of Value Drift and Alignment Work in Large Language Models](https://arxiv.org/abs/2512.03047)
*Samih Fadli*

Main category: cs.CL

TL;DR: 该论文提出了一种利用道德熵评估和监控大型语言模型（LLM）安全性的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的安全性评估通常基于静态基准，但实际问题如价值漂移、越狱攻击和对齐性退化是动态的。

Method: 将道德熵概念应用于LLM，并定义了一个五类行为分类法。训练了一个分类器，用于从模型转录中估计道德熵S(t)。测量了四种前沿模型的基础版本和指令调优版本的道德熵动态。

Result: 基础模型显示出持续的熵增长，而经过调优的模型抑制了漂移，并使道德熵降低了约80%。根据这些轨迹，估计了一个有效的对齐工作率gamma_eff。

Conclusion: 将S(t)和gamma_eff嵌入到一个监控流程中，当熵漂移超过稳定性阈值时会发出警报，从而实现在运行时对价值漂移进行监督。

Abstract: Large language model safety is usually assessed with static benchmarks, but key failures are dynamic: value drift under distribution shift, jailbreak attacks, and slow degradation of alignment in deployment. Building on a recent Second Law of Intelligence that treats ethical entropy as a state variable which tends to increase unless countered by alignment work, we make this framework operational for large language models. We define a five-way behavioral taxonomy, train a classifier to estimate ethical entropy S(t) from model transcripts, and measure entropy dynamics for base and instruction-tuned variants of four frontier models across stress tests. Base models show sustained entropy growth, while tuned variants suppress drift and reduce ethical entropy by roughly eighty percent. From these trajectories we estimate an effective alignment work rate gamma_eff and embed S(t) and gamma_eff in a monitoring pipeline that raises alerts when entropy drift exceeds a stability threshold, enabling run-time oversight of value drift.

</details>


### [2] [Watermarks for Embeddings-as-a-Service Large Language Models](https://arxiv.org/abs/2512.03079)
*Anudeex Shetty*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）的嵌入即服务（EaaS）中的水印技术，揭示了现有水印易受文本释义攻击的漏洞，并提出了一种新的水印技术WET（使用线性变换的水印EaaS）来抵抗此类攻击。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言理解和生成方面表现出色，企业开始提供嵌入即服务（EaaS）。然而，EaaS容易受到模仿攻击，攻击者可以在不访问模型内部工作原理的情况下克隆服务模型。为了保护EaaS提供商的知识产权，研究人员提出了在文本嵌入中添加水印来检查模型所有权。

Method: 本文首先通过实验证明，攻击者在模仿攻击中通过释义输入文本可以有效移除现有EaaS水印。随后，本文提出了一种名为WET的新型水印技术，该技术通过对嵌入进行线性变换来实现水印，并通过反向变换和比较恢复嵌入与原始嵌入之间的相似性来验证水印。

Result: 研究表明，现有EaaS水印在大多数情况下可以通过文本释义有效绕过，这揭示了当前EaaS水印技术的一个新漏洞。作为 M 措施，WET 技术被证明能够抵抗释义攻击，并具有近乎完美的 A 验性。

Conclusion: 本文揭示了现有EaaS水印在模仿攻击中易受文本释义攻击的漏洞，并提出了一种基于线性变换的新型水印技术WET，该技术能有效抵抗此类攻击，保护EaaS提供商的知识产权。

Abstract: Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. Based on these LLMs, businesses have started to provide Embeddings-as-a-Service (EaaS), offering feature extraction capabilities (in the form of text embeddings) that benefit downstream natural language processing tasks. However, prior research has demonstrated that EaaS is vulnerable to imitation attacks, where an attacker clones the service's model in a black-box manner without access to the model's internal workings. In response, watermarks have been added to the text embeddings to protect the intellectual property of EaaS providers by allowing them to check for model ownership. This thesis focuses on defending against imitation attacks by investigating EaaS watermarks. To achieve this goal, we unveil novel attacks and propose and validate new watermarking techniques.
  Firstly, we show that existing EaaS watermarks can be removed through paraphrasing the input text when attackers clone the model during imitation attacks. Our study illustrates that paraphrasing can effectively bypass current state-of-the-art EaaS watermarks across various attack setups (including different paraphrasing techniques and models) and datasets in most instances. This demonstrates a new vulnerability in recent EaaS watermarking techniques.
  Subsequently, as a countermeasure, we propose a novel watermarking technique, WET (Watermarking EaaS with Linear Transformation), which employs linear transformation of the embeddings. Watermark verification is conducted by applying a reverse transformation and comparing the similarity between recovered and original embeddings. We demonstrate its robustness against paraphrasing attacks with near-perfect verifiability. We conduct detailed ablation studies to assess the significance of each component and hyperparameter in WET.

</details>


### [3] [Alleviating Choice Supportive Bias in LLM with Reasoning Dependency Generation](https://arxiv.org/abs/2512.03082)
*Nan Zhuang,Wenshuo Wang,Lekai Qian,Yuxiao Wang,Boyu Cao,Qi Liu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的去偏方法，称为推理依赖生成（RDG），旨在解决大型语言模型（LLM）中的选择支持偏见（CSB）。


<details>
  <summary>Details</summary>
Motivation: 现有去偏方法主要针对人口学和社会偏见，而针对LLM认知偏见的方法仍未被充分探索。为了解决AI辅助决策中LLM评估时系统性偏爱其所选选项，从而损害客观性的问题。

Method: 本文提出推理依赖生成（RDG）框架，通过生成无偏见的推理数据，然后对LLM进行微调。RDG自动构建平衡的推理QA对，明确（不）建模选项、证据和理由之间的依赖关系。该方法能够跨领域生成大规模QA对数据集，并结合了上下文依赖数据和依赖解耦数据。

Result: 通过RDG生成的数据进行微调，LLMs在基于记忆的实验中表现出81.5%的改进，在基于评估的实验中表现出94.3%的改进。同时，在标准BBQ基准测试中保持了相似的性能。

Conclusion: 这项工作开创了一种解决LLMs中认知偏见的方法，有助于开发更可靠的AI辅助决策支持系统。

Abstract: Recent studies have demonstrated that some Large Language Models exhibit choice-supportive bias (CSB) when performing evaluations, systematically favoring their chosen options and potentially compromising the objectivity of AI-assisted decision making. While existing debiasing approaches primarily target demographic and social biases, methods for addressing cognitive biases in LLMs remain largely unexplored. In this work, we present the first solution to address CSB through Reasoning Dependency Generation (RDG), a novel framework for generating unbiased reasoning data to mitigate choice-supportive bias through fine-tuning. RDG automatically constructs balanced reasoning QA pairs, explicitly (un)modeling the dependencies between choices, evidences, and justifications. Our approach is able to generate a large-scale dataset of QA pairs across domains, incorporating Contextual Dependency Data and Dependency Decouple Data. Experiments show that LLMs fine-tuned on RDG-generated data demonstrate a 81.5% improvement in memory-based experiments and 94.3% improvement in the evaluation-based experiment, while maintaining similar performance on standard BBQ benchmarks. This work pioneers an approach for addressing cognitive biases in LLMs and contributes to the development of more reliable AI-assisted decision support systems.

</details>


### [4] [Enhancing Job Matching: Occupation, Skill and Qualification Linking with the ESCO and EQF taxonomies](https://arxiv.org/abs/2512.03195)
*Stylianos Saroglou,Konstantinos Diamantaras,Francesco Preta,Marina Delianidi,Apostolos Benisis,Christian Johannes Meyer*

Main category: cs.CL

TL;DR: 该研究探讨了语言模型在改善劳动力市场信息分类方面的潜力，通过将职位空缺文本与欧洲两大框架（ESCO和EQF）进行关联。


<details>
  <summary>Details</summary>
Motivation: 利用语言模型改进劳动力市场信息分类，解决职位空缺文本与欧洲技能、资质和职业分类法（ESCO）和欧洲资格框架（EQF）之间的映射问题。

Method: 本文研究并比较了句子链接（Sentence Linking）和实体链接（Entity Linking）两种主流方法。同时发布了一个开源工具，包含了这两种方法。此外，引入了两个专门用于评估职位空缺文本中职业和资格表示的带标注数据集，并探讨了如何利用生成式大型语言模型来完成这项任务。

Result: 研究结果推进了职位实体提取的最新技术，并为分析数字化经济中的工作、技能和劳动力市场叙事提供了计算基础设施。

Conclusion: 语言模型在连接职位空缺文本与劳动力市场分类框架方面具有巨大潜力，通过结合句子链接和实体链接方法，并利用生成式大型语言模型，能够有效提升劳动力市场信息的分类效率和准确性。

Abstract: This study investigates the potential of language models to improve the classification of labor market information by linking job vacancy texts to two major European frameworks: the European Skills, Competences, Qualifications and Occupations (ESCO) taxonomy and the European Qualifications Framework (EQF). We examine and compare two prominent methodologies from the literature: Sentence Linking and Entity Linking. In support of ongoing research, we release an open-source tool, incorporating these two methodologies, designed to facilitate further work on labor classification and employment discourse. To move beyond surface-level skill extraction, we introduce two annotated datasets specifically aimed at evaluating how occupations and qualifications are represented within job vacancy texts. Additionally, we examine different ways to utilize generative large language models for this task. Our findings contribute to advancing the state of the art in job entity extraction and offer computational infrastructure for examining work, skills, and labor market narratives in a digitally mediated economy. Our code is made publicly available: https://github.com/tabiya-tech/tabiya-livelihoods-classifier

</details>


### [5] [InvertiTune: High-Quality Data Synthesis for Cost-Effective Single-Shot Text-to-Knowledge Graph Generation](https://arxiv.org/abs/2512.03197)
*Faezeh Faez,Marzieh S. Tahaei,Yaochen Hu,Ali Pourranjbar,Mahdi Biparva,Mark Coates,Yingxue Zhang*

Main category: cs.CL

TL;DR: 该论文提出了InvertiTune框架，通过结合可控数据生成和有监督微调，解决了现有Text2KG方法在计算成本高和难以处理复杂关系方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的Text2KG方法依赖于迭代的LLM提示，导致计算成本高，且容易忽略文本中分布的复杂关系。

Method: InvertiTune框架包含一个可控数据生成管道，该管道从大型知识库中系统地提取子图，应用噪声过滤，并利用LLM生成相应的自然文本描述。然后，该框架使用这些数据对轻量级模型进行有监督微调（SFT），以实现单次知识图谱构建。

Result: 在CE12k数据集上的实验结果表明，InvertiTune优于大型未微调的LLM以及最先进的Text2KG方法。同时，在CrossEval-1200数据集上，InvertiTune也表现出更强的跨数据集泛化能力。

Conclusion: 研究结果强调了真实、高质量训练数据对于推动高效、高性能Text2KG系统发展的重要性。

Abstract: Large Language Models (LLMs) have revolutionized the ability to understand and generate text, enabling significant progress in automatic knowledge graph construction from text (Text2KG). Many Text2KG methods, however, rely on iterative LLM prompting, making them computationally expensive and prone to overlooking complex relations distributed throughout the text. To address these limitations, we propose InvertiTune, a framework that combines a controlled data generation pipeline with supervised fine-tuning (SFT). Within this framework, the data-generation pipeline systematically extracts subgraphs from large knowledge bases, applies noise filtering, and leverages LLMs to generate corresponding natural text descriptions, a task more aligned with LLM capabilities than direct KG generation from text. This pipeline enables generating datasets composed of longer texts paired with larger KGs that better reflect real-world scenarios compared to existing benchmarks, thus supporting effective SFT of lightweight models for single-shot KG construction. Experimental results on CE12k, a dataset generated using the introduced pipeline, show that InvertiTune outperforms larger non-fine-tuned LLMs as well as state-of-the-art Text2KG approaches, while also demonstrating stronger cross-dataset generalization on CrossEval-1200, a test set created from three established benchmark datasets and CE12k. These findings highlight the importance of realistic, high-quality training data for advancing efficient and high-performing Text2KG systems.

</details>


### [6] [Identifying attributions of causality in political text](https://arxiv.org/abs/2512.03214)
*Paulina Garcia-Corral*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个用于识别和解析政治文本中解释的框架。


<details>
  <summary>Details</summary>
Motivation: 尽管解释对于理解政治世界至关重要，但在政治学中，对解释的系统分析仍不充分，现有方法分散且通常针对特定问题。

Method: 作者训练了一个轻量级的因果语言模型，该模型以因果对的形式返回结构化的因果声明数据集，用于后续分析。

Result: 作者展示了如何大规模研究因果解释，并证明了该方法注释需求适中、通用性强且相对于人工编码具有较高的准确性。

Conclusion: 该论文为政治文本中解释的检测和分析提供了一个新的框架和工具，有助于推动对政治解释的系统研究。

Abstract: Explanations are a fundamental element of how people make sense of the political world. Citizens routinely ask and answer questions about why events happen, who is responsible, and what could or should be done differently. Yet despite their importance, explanations remain an underdeveloped object of systematic analysis in political science, and existing approaches are fragmented and often issue-specific. I introduce a framework for detecting and parsing explanations in political text. To do this, I train a lightweight causal language model that returns a structured data set of causal claims in the form of cause-effect pairs for downstream analysis. I demonstrate how causal explanations can be studied at scale, and show the method's modest annotation requirements, generalizability, and accuracy relative to human coding.

</details>


### [7] [Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs](https://arxiv.org/abs/2512.03310)
*Kunj Joshi,David A. Smith*

Main category: cs.CL

TL;DR: RMFT是一种新颖的隐私保护微调技术，旨在减少语言模型中的个人身份信息（PII）记忆，同时将性能影响降至最低。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）中的记忆化带来了严重的安全和隐私风险，因为模型倾向于从训练数据中记忆个人身份信息（PII）。

Method: 我们引入了随机掩码微调（RMFT）技术。

Result: 与基线微调相比，RMFT在总提取率上降低了80.81%，在“已见”提取率上降低了80.17%，优于去重方法，同时困惑度仅增加了5.73%。我们提出了MaxTER，一个用于评估隐私-效用权衡的帕累托最优评估框架，并通过响应曲线下面积（AURC）度量展示了RMFT相比较去重方法的性能。

Conclusion: RMFT显著减少了大型语言模型中个人身份信息的记忆，同时保持了较低的性能影响，表明其在隐私保护方面优于传统去重方法。

Abstract: The current literature on memorization in Natural Language Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while minimizing performance impact. Using the Enron Email Dataset, we demonstrate that RMFT achieves an 80.81% reduction in Total Extraction Rate and 80.17% reduction in Seen Extraction Rate compared to baseline fine-tuning, outperforming deduplication methods while maintaining only a 5.73% increase in perplexity. We present MaxTER, a Pareto-optimal evaluation framework for assessing privacy-utility tradeoffs, and show the performance of RMFT vs Deduplication by Area Under The Response Curve (AURC) metric.

</details>


### [8] [Modeling Topics and Sociolinguistic Variation in Code-Switched Discourse: Insights from Spanish-English and Spanish-Guaraní](https://arxiv.org/abs/2512.03334)
*Nemika Tyagi,Nelvin Licona Guevara,Olga Kellert*

Main category: cs.CL

TL;DR: 该研究提出了一个LLM辅助的标注流程，用于分析西班牙语-英语和西班牙语-瓜拉尼语双语语篇的社会语言学和主题。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在利用大型语言模型（LLMs）对双语语篇进行社会语言学和主题分析，以解决传统上这类分析需要大量手动标注的问题。

Method: 研究使用大型语言模型自动标注了3691个语码转换句子的主题、语体和语篇语用功能。同时，整合了来自迈阿密双语语料库的人口统计元数据，并丰富了西班牙语-瓜拉尼语数据集的新主题标注。

Result: 研究结果显示，在迈阿密数据中，性别、语言优势和语篇功能之间存在系统性关联；在巴拉圭文本中，正式的瓜拉尼语和非正式的西班牙语之间存在明显的双言分化。这些发现复制并扩展了早期的互动和社会语言学观察，并提供了语料库规模的量化证据。

Conclusion: 大型语言模型能够可靠地发现传统上只能通过手动标注获得的社会语言学模式，这推动了跨语言和低资源双语研究的计算方法。

Abstract: This study presents an LLM-assisted annotation pipeline for the sociolinguistic and topical analysis of bilingual discourse in two typologically distinct contexts: Spanish-English and Spanish-Guaraní. Using large language models, we automatically labeled topic, genre, and discourse-pragmatic functions across a total of 3,691 code-switched sentences, integrated demographic metadata from the Miami Bilingual Corpus, and enriched the Spanish-Guaraní dataset with new topic annotations. The resulting distributions reveal systematic links between gender, language dominance, and discourse function in the Miami data, and a clear diglossic division between formal Guaraní and informal Spanish in Paraguayan texts. These findings replicate and extend earlier interactional and sociolinguistic observations with corpus-scale quantitative evidence. The study demonstrates that large language models can reliably recover interpretable sociolinguistic patterns traditionally accessible only through manual annotation, advancing computational methods for cross-linguistic and low-resource bilingual research.

</details>


### [9] [PERCS: Persona-Guided Controllable Biomedical Summarization Dataset](https://arxiv.org/abs/2512.03340)
*Rohan Charudatt Salvi,Chirag Chawla,Dhruv Jain,Swapnil Panigrahi,Md Shad Akhtar,Shweta Yadav*

Main category: cs.CL

TL;DR: PERCS 数据集通过为不同医疗素养和信息需求的四种人群（非专业人士、医预科学生、非医学研究人员和医学专家）提供量身定制的生物医学摘要，解决了现有医疗文本简化资源缺乏针对性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有医疗文本简化资源假设单一通用受众，忽略了用户群体间医疗素养和信息需求的巨大差异。本研究旨在通过引入 PERCS 数据集来解决这一局限性，该数据集提供针对不同人群量身定制的生物医学摘要。

Method: 本研究引入了 PERCS (Persona-guided Controllable Summarization) 数据集，其中包含生物医学摘要和针对四种人群（非专业人士、医预科学生、非医学研究人员和医学专家）定制的摘要。每份摘要都经过医生审核，以确保事实准确性和人群一致性。采用详细的错误分类法进行审核。

Result: 技术验证表明，不同人群的摘要在可读性、词汇和内容深度方面存在明显差异。本研究还使用评估全面性、可读性和忠实度的自动评估指标，对 PERCS 数据集上的四种大型语言模型进行了基准测试，为未来的研究建立了基线结果。

Conclusion: PERCS 数据集及其相关的注释指南和评估材料将公开可用，以支持针对特定人群的交流和可控生物医学摘要的研究。该数据集有效解决了现有医疗文本简化资源缺乏针对性的问题，为未来研究奠定了基础。

Abstract: Automatic medical text simplification plays a key role in improving health literacy by making complex biomedical research accessible to diverse readers. However, most existing resources assume a single generic audience, overlooking the wide variation in medical literacy and information needs across user groups. To address this limitation, we introduce PERCS (Persona-guided Controllable Summarization), a dataset of biomedical abstracts paired with summaries tailored to four personas: Laypersons, Premedical Students, Non-medical Researchers, and Medical Experts. These personas represent different levels of medical literacy and information needs, emphasizing the need for targeted, audience-specific summarization. Each summary in PERCS was reviewed by physicians for factual accuracy and persona alignment using a detailed error taxonomy. Technical validation shows clear differences in readability, vocabulary, and content depth across personas. Along with describing the dataset, we benchmark four large language models on PERCS using automatic evaluation metrics that assess comprehensiveness, readability, and faithfulness, establishing baseline results for future research. The dataset, annotation guidelines, and evaluation materials are publicly available to support research on persona-specific communication and controllable biomedical summarization.

</details>


### [10] [Idea-Gated Transformers: Enforcing Semantic Coherence via Differentiable Vocabulary Pruning](https://arxiv.org/abs/2512.03343)
*Darshan Fofadiya*

Main category: cs.CL

TL;DR: 本文介绍了一种名为“Idea-Gated Transformer”的新型架构，它通过引入一个“Idea Head”来预测未来上下文窗口的词袋分布，从而创建一个潜在的“概念向量”来主动控制生成过程中的主词汇，以解决自回归语言模型中的“主题漂移”问题。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型（LLMs）在下一词元预测训练中经常出现“主题漂移”问题，即生成的内容偏离了初始提示，这是由于模型过度依赖局部关联而非全局规划。虽然扩大模型规模可以缓解这个问题，但下一词元预测目标固有的短视性仍然存在。

Method: 本文引入了一种名为“Idea-Gated Transformer”的新型架构，它将语义规划与语法生成分离。模型引入了一个辅助的“Idea Head”，用于预测未来上下文窗口的词袋分布，从而创建一个潜在的“概念向量”，该向量在生成过程中主动控制主词汇。文章提出了一种可微分的门控机制，该机制能抑制语义不相关的词元，从而实时修剪搜索空间。

Result: 在WikiText-103上的实验表明，尽管Idea-Gated模型实现了与标准GPT-2基线相当的验证困惑度，但它在领域保留方面表现出显著优越性。定性和定量分析表明，门控机制成功地将生成锁定在特定的语义簇（例如，金融、科学）中，并抵制了联想漂移。

Conclusion: Idea-Gated Transformer为实现更可控的语言建模提供了一种参数高效的途径，通过将语义规划与语法生成分离，并引入门控机制来抑制语义不相关的词元，从而解决了自回归语言模型中的“主题漂移”问题。

Abstract: Autoregressive Language Models (LLMs) trained on Next-Token Prediction (NTP) often suffer from ``Topic Drift'' where the generation wanders away from the initial prompt due to a reliance on local associations rather than global planning \citep{holtzman2019curious}. While scaling model size mitigates this \citep{brown2020language}, the fundamental myopia of the NTP objective remains. In this work, we introduce the Idea-Gated Transformer, a novel architecture that separates semantic planning from syntactic generation. We introduce an auxiliary ``Idea Head'' trained to predict the bag-of-words distribution for a future context window, creating a latent ``Concept Vector'' that actively gates the main vocabulary during generation. We propose a differentiable gating mechanism that suppresses semantically irrelevant tokens, effectively pruning the search space in real-time. Experiments on WikiText-103 demonstrate that while the Idea-Gated model achieves comparable validation perplexity to a standard GPT-2 baseline, it exhibits significantly superior Domain Retention. Qualitative and quantitative analysis reveals that the gating mechanism successfully locks generation into specific semantic clusters (e.g., Finance, Science) and resists associative drift, offering a parameter-efficient path toward more controllable language modeling.

</details>


### [11] [From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation](https://arxiv.org/abs/2512.03360)
*Qingchuan Li,Mingyue Cheng,Zirui Liu,Daoyu Wang,Yuting Zeng,Tongxuan Liu*

Main category: cs.CL

TL;DR: HBLR是一种结合了信心感知符号翻译和假设驱动反向推理的框架，旨在解决大型语言模型在逻辑推理中存在的冗余推理路径、幻觉步骤和语义漂移等问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在逻辑推理方面存在冗余推理路径、幻觉步骤和语义漂移等问题，导致推理效率低下和不可靠，这促使研究者寻求更有效和可靠的推理方法。

Method: HBLR框架分为翻译和推理两个阶段。在翻译阶段，高置信度的内容被翻译成一阶逻辑，不确定的内容保留自然语言形式，并通过翻译反射模块确保语义保真度。在推理阶段，HBLR通过假设结论为真并递归验证前提来模拟人类演绎思维，并通过推理反射模块识别和纠正推理错误。

Result: 在五个推理基准测试中，HBLR在准确性和效率方面均优于现有基线方法。

Conclusion: HBLR框架通过结合信心感知符号翻译和假设驱动反向推理，有效解决了大型语言模型在逻辑推理中存在的问题，显著提高了推理的准确性和效率。

Abstract: Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.

</details>


### [12] [Characterizing Language Use in a Collaborative Situated Game](https://arxiv.org/abs/2512.03381)
*Nicholas Tomlin,Naitian Zhou,Eve Fleisig,Liangyuan,Chen,Téa Wright,Lauren Vinh,Laura X. Ma,Seun Eisape,Ellie French,Tingting Du,Tianjiao Zhang,Alexander Koller,Alane Suhr*

Main category: cs.CL

TL;DR: 该论文介绍了Portal Dialogue Corpus，一个包含11.5小时人类对话的合作视频游戏语料库，用于研究复杂协作环境中的语言使用。


<details>
  <summary>Details</summary>
Motivation: 现有的聊天或任务型对话语料库中很少出现复杂空间指代、澄清和修复以及临时约定形成等语言现象，因此需要收集新的语料库来支持对复杂、情境化、协作式问题解决场景中语言使用的分析。

Method: 作者收集了Portal 2合作模式中的人类口语对话，构建了Portal Dialogue Corpus，该语料库包含24.5K条语句、玩家视频、音频、转录、游戏状态数据以及语言数据的手动和自动标注。

Result: 通过分析玩家的语言和行为，作者识别出了一些在现有语料库中罕见的语言现象，例如复杂空间指代、澄清和修复以及临时约定形成。

Conclusion: Portal Dialogue Corpus的发布将支持未来对复杂、情境化、协作式问题解决场景中语言使用的分析。

Abstract: Cooperative video games, where multiple participants must coordinate by communicating and reasoning under uncertainty in complex environments, yield a rich source of language data. We collect the Portal Dialogue Corpus: a corpus of 11.5 hours of spoken human dialogue in the co-op mode of the popular Portal 2 virtual puzzle game, comprising 24.5K total utterances. We analyze player language and behavior, identifying a number of linguistic phenomena that rarely appear in most existing chitchat or task-oriented dialogue corpora, including complex spatial reference, clarification and repair, and ad-hoc convention formation. To support future analyses of language use in complex, situated, collaborative problem-solving scenarios, we publicly release the corpus, which comprises player videos, audio, transcripts, game state data, and both manual and automatic annotations of language data.

</details>


### [13] [Dual LoRA: Enhancing LoRA with Magnitude and Direction Updates](https://arxiv.org/abs/2512.03402)
*Yixing Xu,Chao Li,Xuanwu Yin,Spandan Tiwari,Dong Li,Ashish Sirasao,Emad Barsoum*

Main category: cs.CL

TL;DR: 本文提出了一种名为Dual LoRA的新方法，通过引入归纳偏置来改进LoRA的性能，具体做法是将低秩矩阵分为幅度和方向两组，并通过在幅度和方向组中分别添加ReLU和符号函数来实现。


<details>
  <summary>Details</summary>
Motivation: LoRA由于其低秩假设，在将预训练的大型语言模型（LLM）适应特定下游任务时，性能往往不尽如人意。

Method: 我们将低秩矩阵分为两组：幅值组和方向组。幅值组控制参数的更新幅度，方向组决定参数的更新方向。通过在幅值组中添加ReLU函数，在方向组中添加符号函数，以更好地模拟基于梯度的优化算法的参数更新过程。

Result: 在GPT-2、RoBERTa、DeBERTa和LLaMA-1/2/3等基线模型上进行的自然语言生成（NLG）、理解（NLU）和常识推理任务的实验表明，Dual LoRA在相同数量的可训练参数下，始终优于LoRA及其最先进的变体。

Conclusion: Dual LoRA通过引入归纳偏置（将低秩矩阵分为幅度和方向两组），有效提升了LoRA的性能，使其在各种NLP任务中表现优异。

Abstract: Low-rank adaptation (LoRA) is one of the most popular methods among parameter-efficient fine-tuning (PEFT) methods to adapt pre-trained large language models (LLMs) to specific downstream tasks. However, the model trained based on LoRA often has an unsatisfactory performance due to its low-rank assumption. In this paper, we propose a novel method called Dual LoRA to improve the performance by incorporating an inductive bias into the original LoRA. Specifically, we separate low-rank matrices into two groups: the magnitude group to control whether or not and how far we should update a parameter and the direction group to decide whether this parameter should move forward or backward, to better simulate the parameter updating process of the full fine-tuning based on gradient-based optimization algorithms. We show that this can be simply achieved by adding a ReLU function to the magnitude group and a sign function to the direction group. We conduct several experiments over a wide range of NLP tasks, including natural language generation (NLG), understanding (NLU), and commonsense reasoning datasets on GPT-2, RoBERTa, DeBERTa, and LLaMA-1/2/3 as baseline models. The results show that we consistently outperform LoRA and its state-of-the-art variants with the same number of trainable parameters.

</details>


### [14] [PretrainZero: Reinforcement Active Pretraining](https://arxiv.org/abs/2512.03442)
*Xingrun Xing,Zhiyuan Fan,Jie Lou,Guoqi Li,Jiajun Zhang,Debing Zhang*

Main category: cs.CL

TL;DR: PretrainZero是一个新的强化主动学习框架，它将强化学习从特定领域的后训练扩展到通用预训练。通过主动预训练和自我监督学习，PretrainZero能够在没有可验证奖励的情况下，从预训练语料库中学习通用的推理策略。


<details>
  <summary>Details</summary>
Motivation: 目前的强化学习（RL）大语言模型在软件和数学等领域表现出色，但过度依赖特定领域中可验证的奖励，这限制了它们通用推理能力的扩展。

Method: PretrainZero通过以下方式工作：1. **主动预训练**：受人类主动学习能力的启发，PretrainZero学习了一个统一的推理策略，主动识别预训练语料库中合理且信息丰富的内容，并通过强化学习预测这些内容。2. **自我监督学习**：在没有任何可验证标签、预训练奖励模型或监督微调的情况下，PretrainZero直接使用强化学习从3B到30B的基础模型中，在通用Wikipedia语料库上预训练推理器。3. **验证扩展**：通过处理越来越具挑战性的掩码跨度，PretrainZero显著增强了预训练基础模型的通用推理能力。

Result: 在强化预训练中，PretrainZero在MMLU-Pro、SuperGPQA和数学平均基准测试中，将Qwen3-4B-Base的性能分别提高了8.43、5.96和10.60。在后训练中，预训练的模型还可以作为下游RLVR任务的推理基础模型。

Conclusion: PretrainZero为实现通用人工智能提供了一种新方法，通过在通用预训练语料库上进行强化主动学习，打破了对可验证奖励的依赖，显著提升了模型的通用推理能力。

Abstract: Mimicking human behavior to actively learning from general experience and achieve artificial general intelligence has always been a human dream. Recent reinforcement learning (RL) based large-thinking models demonstrate impressive expert-level abilities, i.e., software and math, but still rely heavily on verifiable rewards in specific domains, placing a significant bottleneck to extend the performance boundary of general reasoning capabilities. In this work, we propose PretrainZero, a reinforcement active learning framework built on the pretraining corpus to extend RL from domain-specific post-training to general pretraining. PretrainZero features the following characteristics: 1) Active pretraining: inspired by the active learning ability of humans, PretrainZero learns a unified reasoning policy to actively identify reasonable and informative contents from pretraining corpus, and reason to predict these contents by RL. 2) Self-supervised learning: without any verifiable labels, pretrained reward models, or supervised fine-tuning, we directly pretrain reasoners from 3 to 30B base models on the general Wikipedia corpus using RL, significantly breaking the verification data-wall for general reasoning. 3) Verification scaling: by tackling increasingly challenging masked spans, PretrainZero substantially enhances the general reasoning abilities of pretrained base models. In reinforcement pretraining, PretrainZero improves Qwen3-4B-Base for 8.43, 5.96 and 10.60 on MMLU-Pro, SuperGPQA and math average benchmarks. In post-training, the pretrained models can also serve as reasoning foundation models for downstream RLVR tasks.

</details>


### [15] [Understanding LLM Reasoning for Abstractive Summarization](https://arxiv.org/abs/2512.03503)
*Haohan Yuan,Siu Cheung Hui,Haopeng Zhang*

Main category: cs.CL

TL;DR: 研究了大型语言模型（LLM）的推理能力在抽象摘要任务中的应用，发现推理并非普遍有效，其效果取决于策略和上下文。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的推理能力在分析任务中表现出色，但在抽象摘要方面的效用尚未得到广泛验证。本研究旨在弥合这一差距。

Method: 量身定制了适用于摘要领域的通用推理策略。对8种推理策略和3种大型推理模型（LRMs）进行了系统、大规模的比较研究，涵盖8个不同的数据集，并评估了摘要质量和忠实度。

Result: 推理并非普遍适用，其有效性高度依赖于具体策略和上下文。摘要质量和事实忠实度之间存在权衡：显式推理策略往往以事实依据为代价提高流畅性，而LRMs中的隐式推理则表现出相反的模式。增加LRM的内部推理预算并不能改善，甚至可能损害事实一致性。

Conclusion: 有效的摘要需要忠实的压缩，而不是创造性的过度思考。

Abstract: While the reasoning capabilities of Large Language Models (LLMs) excel in analytical tasks such as mathematics and code generation, their utility for abstractive summarization remains widely assumed but largely unverified. To bridge this gap, we first tailor general reasoning strategies to the summarization domain. We then conduct a systematic, large scale comparative study of 8 reasoning strategies and 3 Large Reasoning Models (LRMs) across 8 diverse datasets, assessing both summary quality and faithfulness. Our findings show that reasoning is not a universal solution and its effectiveness is highly dependent on the specific strategy and context. Specifically, we observe a trade-off between summary quality and factual faithfulness: explicit reasoning strategies tend to improve fluency at the expense of factual grounding, while implicit reasoning in LRMs exhibits the inverse pattern. Furthermore, increasing an LRM's internal reasoning budget does not improve, and can even hurt, factual consistency, suggesting that effective summarization demands faithful compression rather than creative over-thinking.

</details>


### [16] [AlignCheck: a Semantic Open-Domain Metric for Factual Consistency Assessment](https://arxiv.org/abs/2512.03634)
*Ahmad Aghaebrahimian*

Main category: cs.CL

TL;DR: 本文提出了一种可解释的事实一致性评估框架，用于解决大型语言模型在临床应用等高风险领域中出现的幻觉问题，并通过分解文本、加权度量和评估复杂性控制来提高评估的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自然语言处理方面取得了显著进展，但在高风险领域（如临床应用）中，它们容易产生不正确或误导性的“幻觉”内容，导致严重后果。现有评估指标无法充分评估事实一致性且缺乏可解释性，使得诊断和缓解错误变得困难。

Method: 本文提出了一种可解释的事实一致性评估框架，适用于特定领域和开放领域的文本。该方法将文本分解为原子事实，并引入了一种灵活、无模式的方法。与以前使用绝对度量的方法不同，本文结合了加权度量来增强事实评估，并提出了一种机制来控制复杂领域中的评估复杂性。

Result: 作者在流行的通用和临床数据集上对他们的方法进行了基准测试。

Conclusion: 该研究提出了一种新的可解释的框架，用于评估大型语言模型生成文本的事实一致性，尤其是在高风险领域。通过分解文本、引入加权度量和控制评估复杂性，该框架旨在提高评估的准确性和可解释性，并为未来事实感知模型的训练提供支持。

Abstract: Large Language Models have significantly advanced natural language processing tasks, but remain prone to generating incorrect or misleading but plausible arguments. This issue, known as hallucination, is particularly concerning in high-stakes domains like clinical applications, where factual inaccuracies can have severe consequences. Existing evaluation metrics fail to adequately assess factual consistency and lack interpretability, making diagnosing and mitigating errors difficult. We propose an interpretable framework for factual consistency assessment for in-domain and open-domain texts to address these limitations. Our approach decomposes text into atomic facts and introduces a flexible, schema-free methodology. Unlike previous methods with an absolute metric, we incorporate a weighted metric to enhance factual evaluation. Additionally, we propose a mechanism to control assessment complexity in intricate domains. We benchmark our approach on popular general and clinical datasets and release our code to support fact-aware model training in future research.

</details>


### [17] [Generative AI Practices, Literacy, and Divides: An Empirical Analysis in the Italian Context](https://arxiv.org/abs/2512.03671)
*Beatrice Savoldi,Giuseppe Attanasio,Olga Gorodetskaya,Marta Marchiori Manerba,Elisa Bassignana,Silvia Casola,Matteo Negri,Tommaso Caselli,Luisa Bentivogli,Alan Ramponi,Arianna Muti,Nicoletta Balbo,Debora Nozza*

Main category: cs.CL

TL;DR: 该研究首次提供了意大利生成式AI（GenAI）的采纳、使用模式和素养的全面实证图谱，揭示了广泛的采纳、替代其他技术成为主要信息来源的趋势、低用户数字素养带来的风险以及显著的性别差距。


<details>
  <summary>Details</summary>
Motivation: AI语言技术，特别是生成式AI（GenAI）聊天机器人，正在改变数字交互，但其不均衡的采纳和对局限性认识不足，可能加剧数字鸿沟。

Method: 基于对1,906名意大利语成年人进行的最新调查数据，对GenAI的采纳、使用模式和素养进行了全面的实证 L

Result: 研究发现GenAI在工作和个人用途中被广泛采纳，包括情感支持和医疗建议等敏感任务。GenAI正在取代其他技术，成为主要信息来源，即使在用户数字素养较低的情况下也存在这种趋势，用户难以识别错误或虚假信息。研究还发现显著的性别差异，尤其是在老一辈人中，女性采纳GenAI的可能性是男性的一半，使用频率也低于男性。虽然素养是采纳的关键预测因素，但它只能部分解释这种差异。

Conclusion: GenAI的多用途使用需要有针对性的教育 H和对阻碍公平参与的深层障碍进行 H进一步调查。

Abstract: The rise of Artificial Intelligence (AI) language technologies, particularly generative AI (GenAI) chatbots accessible via conversational interfaces, is transforming digital interactions. While these tools hold societal promise, they also risk widening digital divides due to uneven adoption and low awareness of their limitations. This study presents the first comprehensive empirical mapping of GenAI adoption, usage patterns, and literacy in Italy, based on newly collected survey data from 1,906 Italian-speaking adults. Our findings reveal widespread adoption for both work and personal use, including sensitive tasks like emotional support and medical advice. Crucially, GenAI is supplanting other technologies to become a primary information source: this trend persists despite low user digital literacy, posing a risk as users struggle to recognize errors or misinformation. Moreover, we identify a significant gender divide -- particularly pronounced in older generations -- where women are half as likely to adopt GenAI and use it less frequently than men. While we find literacy to be a key predictor of adoption, it only partially explains this disparity, suggesting that other barriers are at play. Overall, our data provide granular insights into the multipurpose usage of GenAI, highlighting the dual need for targeted educational initiatives and further investigation into the underlying barriers to equitable participation that competence alone cannot explain.

</details>


### [18] [Evaluating Hydro-Science and Engineering Knowledge of Large Language Models](https://arxiv.org/abs/2512.03672)
*Shiruo Hu,Wenbo Shan,Yingjia Li,Zhiqi Wan,Xinpeng Yu,Yunjia Qi,Haotian Xia,Yang Xiao,Dingxiao Liu,Jiaru Wang,Chenxu Gong,Ruixi Zhang,Shuyue Wu,Shibo Cui,Chee Hui Lai,Wei Luo,Yubin He,Bin Xu,Jianshi Zhao*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为Hydro-SE Bench的评估基准，用于评估大型语言模型（LLMs）在水文科学与工程（Hydro-SE）领域的知识和应用能力。


<details>
  <summary>Details</summary>
Motivation: 水文科学与工程（Hydro-SE）是一个关键且不可替代的领域，它涉及多重工程目标，是一个固有的跨学科领域。该领域需要大量的专家协作进行决策，这对智能化提出了挑战。尽管大型语言模型（LLMs）发展迅速，但在Hydro-SE领域的应用潜力尚未得到充分评估，LLMs在该领域的知识和应用能力也未得到充分验证。

Method: 为了解决LLMs在Hydro-SE领域评估不足的问题，我们提出了Hydro-SE LLM评估基准（Hydro-SE Bench）。此基准包含4000道选择题，涵盖了9个子领域。它能够评估LLMs在基本概念知识、工程应用能力以及推理和计算能力方面的表现。

Result: 在Hydro-SE Bench上的评估结果显示，商业LLMs的准确率在0.74到0.80之间，而小参数LLMs的准确率在0.41到0.68之间。LLMs在与自然科学和物理科学密切相关的子领域表现良好，但在行业标准和水工结构等领域特定知识方面表现不足。模型规模的扩大主要提高了推理和计算能力。

Conclusion: 本研究揭示了LLMs在Hydro-SE任务中的优势和劣势。研究结果为模型开发者提供了明确的训练目标，并为Hydro-SE领域的研究人员提供了应用LLMs的实践指导。LLMs在处理实际工程应用问题方面仍有巨大的潜力待开发。

Abstract: Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.

</details>


### [19] [Different types of syntactic agreement recruit the same units within large language models](https://arxiv.org/abs/2512.03676)
*Daria Kryvosheieva,Andrea de Varda,Evelina Fedorenko,Greta Tuckute*

Main category: cs.CL

TL;DR: 研究了大型语言模型（LLMs）中语法知识的表示方式，发现不同类型的句法一致性（如主谓一致、照应语、限定词-名词）在LLMs中会激活重叠的单元集合，表明一致性在LLMs中是一个有意义的功能类别。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）能够区分语法正确和不正确的句子，但其内部如何表示语法知识仍是一个未解决的问题。本文旨在探究LLMs中不同的句法现象是共享还是利用了不同的组件。

Method: 本文采用认知神经科学中的功能定位方法，在七个开源模型中识别出对67种英语句法现象最敏感的LLM单元。通过跨语言分析，研究了英语、俄语和中文，以及57种不同语言中主谓一致现象的单元共享情况。

Result: 不同类型的句法一致性（如主谓一致、照应语、限定词-名词）会激活重叠的单元集合，这表明一致性对于LLMs来说是一个有意义的功能类别。这种模式在英语、俄语和中文中都成立；在对57种不同语言进行跨语言分析时，结构上更相似的语言在主谓一致上共享更多的单元。这些单元在包含相关现象的句子中被持续激活，并因果地支持模型的句法性能。

Conclusion: 句法一致性——句法依赖的关键标志——在LLMs的表征空间中构成了一个有意义的类别。LLMs内部存在对语法知识的功能性组织。

Abstract: Large language models (LLMs) can reliably distinguish grammatical from ungrammatical sentences, but how grammatical knowledge is represented within the models remains an open question. We investigate whether different syntactic phenomena recruit shared or distinct components in LLMs. Using a functional localization approach inspired by cognitive neuroscience, we identify the LLM units most responsive to 67 English syntactic phenomena in seven open-weight models. These units are consistently recruited across sentences containing the phenomena and causally support the models' syntactic performance. Critically, different types of syntactic agreement (e.g., subject-verb, anaphor, determiner-noun) recruit overlapping sets of units, suggesting that agreement constitutes a meaningful functional category for LLMs. This pattern holds in English, Russian, and Chinese; and further, in a cross-lingual analysis of 57 diverse languages, structurally more similar languages share more units for subject-verb agreement. Taken together, these findings reveal that syntactic agreement-a critical marker of syntactic dependencies-constitutes a meaningful category within LLMs' representational spaces.

</details>


### [20] [AITutor-EvalKit: Exploring the Capabilities of AI Tutors](https://arxiv.org/abs/2512.03688)
*Numaan Naeem,Kaushal Kumar Maurya,Kseniia Petukhova,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: AITutor-EvalKit是一个用于评估AI导师教学质量的应用程序，它利用语言技术，提供演示、评估及模型检查和数据可视化的软件。


<details>
  <summary>Details</summary>
Motivation: 开发一个工具，以评估AI导师的教学质量，并支持学习、收集用户反馈和标注。

Method: 通过AITutor-EvalKit应用程序，利用语言技术评估AI导师的教学质量。

Result: AITutor-EvalKit提供了一个集成的解决方案，包括演示、评估软件，以及模型检查和数据可视化功能。

Conclusion: AITutor-EvalKit为教育利益相关者和ACL社区提供了一个有用的工具，可用于评估AI导师的教学质量，支持学习并收集反馈。

Abstract: We present AITutor-EvalKit, an application that uses language technology to evaluate the pedagogical quality of AI tutors, provides software for demonstration and evaluation, as well as model inspection and data visualization. This tool is aimed at education stakeholders as well as *ACL community at large, as it supports learning and can also be used to collect user feedback and annotations.

</details>


### [21] [DZ-TDPO: Non-Destructive Temporal Alignment for Mutable State Tracking in Long-Context Dialogue](https://arxiv.org/abs/2512.03704)
*Yijun Liao*

Main category: cs.CL

TL;DR: 本文提出DZ-TDPO框架，通过动态KL约束和可学习时间注意力偏差，解决了长对话系统中状态惯性问题，在保持模型通用能力的同时，显著提升了对话系统的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决长对话系统中“状态惯性”问题，即静态约束阻碍模型解决用户意图与历史上下文之间冲突的问题。

Method: 本文提出DZ-TDPO（非破坏性对齐框架），该框架结合了冲突感知的动态KL约束和可学习的时间注意力偏差。

Result: DZ-TDPO在Multi-Session Chat (MSC) 数据集上实现了最先进的胜率（Phi-3.5上达到86.2%），并保持了强大的零样本泛化能力。通过对Qwen2.5-7B模型的分析，发现其实现了近乎完美的对齐（99.4%的胜率），且困惑度开销可忽略不计。

Conclusion: DZ-TDPO框架能够有效缓解状态惯性问题，通过精确的注意力调节而非破坏性的权重更新，可以在保持模型通用能力（MMLU）的同时，提升不同规模模型的对齐效果。

Abstract: Long-context dialogue systems suffer from State Inertia, where static constraints prevent models from resolving conflicts between evolving user intents and established historical context. To address this, we propose DZ-TDPO, a non-destructive alignment framework that synergizes conflict-aware dynamic KL constraints with a learnable temporal attention bias. Experiments on the Multi-Session Chat (MSC) dataset demonstrate that DZ-TDPO achieves state-of-the-art win rates (86.2% on Phi-3.5) while maintaining robust zero-shot generalization. Crucially, our scaling analysis reveals a "Capacity-Stability Trade-off": while smaller models incur an "alignment tax" (perplexity surge) to overcome historical inertia, the larger Qwen2.5-7B model achieves near-perfect alignment (99.4% win rate) with negligible perplexity overhead. This confirms that TAI can be alleviated via precise attention regulation rather than destructive weight updates, preserving general capabilities (MMLU) across model scales. Code and data are available: https://github.com/lyj20071013/DZ-TDPO

</details>


### [22] [In-Context Representation Hijacking](https://arxiv.org/abs/2512.03771)
*Itay Yona,Amir Sarid,Michael Karasik,Yossi Gandelsman*

Main category: cs.CL

TL;DR: Doublespeak 是一种针对大型语言模型（LLM）的上下文表示劫持攻击，通过将有害关键词替换为良性词语，欺骗模型绕过安全对齐，从而以无害的表象执行有害指令，比如用“胡萝卜”代替“炸弹”。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM安全对齐策略不足以抵御绕过其安全防护的攻击，特别是在模型的潜在空间中可能存在新的攻击面。

Method: Doublespeak攻击通过在多个上下文示例中，系统地将有害关键词替换为良性词，并在有害请求前提供一个前缀。通过这种替换，良性词的内部表示会趋向于有害词的表示，从而在委婉的说法下嵌入有害语义。研究人员利用可解释性工具，展示了语义覆盖是如何层层产生的，良性含义在早期层中收敛为后期层中的有害语义。

Result: Doublespeak攻击无需优化，在模型家族中具有广泛的可移植性。它在闭源和开源系统上都取得了很高的成功率，例如在Llama-3.3-70B-Instruct模型上，只需单句上下文覆盖，攻击成功率（ASR）就达到了74%。

Conclusion: Doublespeak攻击揭示了LLM潜在空间中存在一个新的攻击面，表明当前的对齐策略不足，需要从表示层面进行改进。未来的安全策略设计。

Abstract: We introduce \textbf{Doublespeak}, a simple \emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \textit{bomb}) with a benign token (e.g., \textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.

</details>


### [23] [Enhancing Instruction-Following Capabilities in Seq2Seq Models: DoLA Adaptations for T5](https://arxiv.org/abs/2512.03803)
*Huey Sun,Anabel Yong,Lorenzo Gilly,Felipe Jin*

Main category: cs.CL

TL;DR: 本文探讨了对比解码方法DoLa在T5和FLAN-T5模型上的应用，评估其对模型遵循指令能力的影响，并分析了其对文本生成忠实度的作用。


<details>
  <summary>Details</summary>
Motivation: 探索对比解码方法DoLa在编码器-解码器架构（如T5和FLAN-T5）中的应用，并评估其对模型指令遵循能力和文本生成忠实度的影响。现有研究多集中于解码器模型和提高事实性。

Method: 将DoLa算法应用于T5和FLAN-T5模型家族，首次在编码器-解码器架构中实现对比解码策略。通过对数演化进行逐层分析，量化DoLa对token输出概率的影响。

Result: DoLa在某些任务类别上提高了文本生成的忠实度，但在其他任务上则产生了负面影响。

Conclusion: DoLa可以应用于编码器-解码器架构，但其对指令遵循能力和文本生成忠实度的影响因任务而异。需要进一步研究以理解其在不同任务中的表现差异。

Abstract: Contrastive decoding is a lightweight and effective inference-time method that improves the quality of text generation in Large Language Models. However, algorithms such as DoLa (Decoding by Contrastive Layers) have only been implemented in decoder-only architectures and studied for their impact on improving factuality. This work adapts DoLa for the T5 and FLAN-T5 model families and evaluates its impact on the models' instruction following capabilities, which to our knowledge is the first implementation of a contrastive decoding strategy in an encoder-decoder architecture. Our results show that DoLa improves the faithfulness of text generation for certain categories of tasks and harms others. To understand these results, we present a layer-by-layer analysis of logit evolution in a FLAN-T5 model to quantify DoLa's impact on token output probabilities.

</details>


### [24] [Improving Alignment Between Human and Machine Codes: An Empirical Assessment of Prompt Engineering for Construct Identification in Psychology](https://arxiv.org/abs/2512.03818)
*Kylie L. Anglin,Stephanie Milan,Brittney Hernandez,Claudia Ventura*

Main category: cs.CL

TL;DR: 本文提出了一种优化大型语言模型（LLM）文本分类性能的框架，通过结合人工和自动提示工程，在训练数据集中根据经验性能选择提示，以期在心理学等领域实现与专家判断高度一致的文本分类。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在文本分类方面的潜力，并解决其性能受提示词措辞影响大的问题，尤其是在心理学等专业领域，模型预训练数据可能无法很好地捕捉理论驱动的精确概念定义。

Method: 本文提出了一种优化LLM文本分类性能的经验框架，并实验评估了五种提示策略：码本引导的经验提示选择、自动提示工程、角色设定提示、思维链推理和解释性提示，涵盖零样本和少样本分类。

Result: 角色设定、思维链和解释性提示并不能完全弥补措辞不当的提示所造成的性能损失。提示中最具影响力的特征是概念定义、任务框架，其次是提供的示例。在SFT-005和text-davinci-003模型中，结合码本引导的经验提示选择和自动提示工程的少样本提示，其分类结果与专家判断最为一致。

Conclusion: 为了优化LLM在需要与专家判断对齐的文本分类任务中的性能，研究人员应尽可能多地生成和评估不同变体的提示（无论是人工制作、自动生成还是两者结合），并根据训练数据集中的经验性能选择提示和示例，最终在保留数据集中验证所选方法。

Abstract: Due to their architecture and vast pre-training data, large language models (LLMs) demonstrate strong text classification performance. However, LLM output - here, the category assigned to a text - depends heavily on the wording of the prompt. While literature on prompt engineering is expanding, few studies focus on classification tasks, and even fewer address domains like psychology, where constructs have precise, theory-driven definitions that may not be well represented in pre-training data. We present an empirical framework for optimizing LLM performance for identifying constructs in texts via prompt engineering. We experimentally evaluate five prompting strategies --codebook-guided empirical prompt selection, automatic prompt engineering, persona prompting, chain-of-thought reasoning, and explanatory prompting - with zero-shot and few-shot classification. We find that persona, chain-of-thought, and explanations do not fully address performance loss accompanying a badly worded prompt. Instead, the most influential features of a prompt are the construct definition, task framing, and, to a lesser extent, the examples provided. Across three constructs and two models, the classifications most aligned with expert judgments resulted from a few-shot prompt combining codebook-guided empirical prompt selection with automatic prompt engineering. Based on our findings, we recommend that researchers generate and evaluate as many prompt variants as feasible, whether human-crafted, automatically generated, or ideally both, and select prompts and examples based on empirical performance in a training dataset, validating the final approach in a holdout set. This procedure offers a practical, systematic, and theory-driven method for optimizing LLM prompts in settings where alignment with expert judgment is critical.

</details>


### [25] [Training and Evaluation of Guideline-Based Medical Reasoning in LLMs](https://arxiv.org/abs/2512.03838)
*Michael Staniek,Artem Sokolov,Stefan Riezler*

Main category: cs.CL

TL;DR: 本文提出了一种微调大型语言模型（LLMs）以遵循医学共识指南的方法，通过将口头医疗推理规则实例化为电子健康记录数据，从而在医学早期预测中实现高准确性和可信的解释。


<details>
  <summary>Details</summary>
Motivation: 医学领域早期预测的机器学习模型在提高预测准确性方面取得了突破，但忽视了提供可信解释的重要性，这使得医学从业者难以信任。

Method: 通过将口头化的医学推理规则实例化到电子健康记录中，为LLMs的微调提供数据，使其学习共识规则及可能的例外情况。模型通过评估推导正确性（从前提中正确且忠实地推导出结论）和价值正确性（将预测值与实际测量值进行比较）进行自动评估。为了解决稀疏和不规则采样临床变量的未来泛化问题，该方法将时间序列预测模型的输出表示与LLM在多模态设置中相结合。

Result: 实验表明，经过微调的小型模型在Sepsis-3共识定义上优于在大型LLMs中进行零样本学习，也优于在包含共识定义的医学文本上训练的模型。在特定医疗领域，对口头化规则实例进行微调的模型在未见患者数据上达到了接近完美的推导正确性。与时间序列预测模型相结合的多模态设置可以改善对未来稀疏和不规则采样临床变量的泛化能力。

Conclusion: 本文提出了一种有效的方法，通过微调LLMs使其遵循医学共识指南，从而在医学早期预测中实现高准确性和可信的解释。这种方法解决了当前医学AI模型在可解释性方面的不足，并通过结合时间序列预测模型提升了对未来数据的泛化能力。

Abstract: Machine learning for early prediction in medicine has recently shown breakthrough performance, however, the focus on improving prediction accuracy has led to a neglect of faithful explanations that are required to gain the trust of medical practitioners. The goal of this paper is to teach LLMs to follow medical consensus guidelines step-by-step in their reasoning and prediction process. Since consensus guidelines are ubiquitous in medicine, instantiations of verbalized medical inference rules to electronic health records provide data for fine-tuning LLMs to learn consensus rules and possible exceptions thereof for many medical areas. Consensus rules also enable an automatic evaluation of the model's inference process regarding its derivation correctness (evaluating correct and faithful deduction of a conclusion from given premises) and value correctness (comparing predicted values against real-world measurements). We exemplify our work using the complex Sepsis-3 consensus definition. Our experiments show that small fine-tuned models outperform one-shot learning of considerably larger LLMs that are prompted with the explicit definition and models that are trained on medical texts including consensus definitions. Since fine-tuning on verbalized rule instantiations of a specific medical area yields nearly perfect derivation correctness for rules (and exceptions) on unseen patient data in that area, the bottleneck for early prediction is not out-of-distribution generalization, but the orthogonal problem of generalization into the future by forecasting sparsely and irregularly sampled clinical variables. We show that the latter results can be improved by integrating the output representations of a time series forecasting model with the LLM in a multimodal setup.

</details>


### [26] [Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers](https://arxiv.org/abs/2512.03870)
*Hongzhan Lin,Zhiqi Bai,Xinmiao Zhang,Sen Yang,Xiang Li,Siran Yang,Yunlong Xu,Jiaheng Liu,Yongchi Zhao,Jiamang Wang,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为 FusedKV 的方法，通过融合底层和中间层的 KV 缓存来减少 Transformer 解码器在长序列长度下的内存消耗，并实现了更低的困惑度。


<details>
  <summary>Details</summary>
Motivation: Transformer 解码器在长序列长度下，KV 缓存所需的内存过大。现有的跨层 KV 缓存共享方法（如 YOCO, CLA）通常不如层内方法（如 GQA）。

Method: 作者首先分析了顶层键和值的信息流，发现值主要来源于底层，键则来源于底层和中间层。基于此，提出了 FusedKV，通过可学习的方式融合底层和中间层最具信息量的 KV 缓存作为顶层 KV 缓存。同时，又提出了简化版本 FusedKV-Lite，直接从底层值和中间层键中导出顶层 KV 缓存，以提高效率。

Result: 在 332M 到 4B 参数的 LLM 上的实验表明，所提出的方法将缓存内存减少了 50%，同时实现了比标准 Transformer 解码器更低的验证困惑度。

Conclusion: FusedKV 及其变体 FusedKV-Lite 提供了一种内存高效、高性能的 Transformer 解码器架构替代方案，通过优化 KV 缓存的使用，显著降低了内存消耗，同时保持或提升了性能。

Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache bottleneck, it typically underperforms within-layer methods like GQA. To understand the root cause, we investigate the information flow of keys and values of the top-layers. Our preliminary reveals a clear distribution: values are predominantly derived from the bottom layer, while keys draw more information from both bottom and middle layers. Building upon this, we propose FusedKV, whose top-layer KV caches are a learnable fusion of the most informative ones from the bottom and middle layers. This fusion operates directly on post-RoPE keys, preserving relative positional information without the computational cost of re-applying rotary embeddings. To further improve efficiency, we propose FusedKV-Lite, an cross-layer sharing approach, where top-layer KV caches are directly derived from the bottom-layer values and the middle-layer keys. Compared to FusedKV, FusedKV-Lite reduces I/O overhead at the cost of a slight increase in perplexity. In experiments on LLMs ranging from 332M to 4B parameters, our proposed method reduce 50\% cache memory while achieving lower validation perplexity than the standard Transformer decoder, establishing it as a memory-efficient, high-performance architectural alternative.

</details>


### [27] [BERnaT: Basque Encoders for Representing Natural Textual Diversity](https://arxiv.org/abs/2512.03903)
*Ekhi Azurmendi,Joseba Fernandez de Landa,Jaione Bengoetxea,Maite Heredia,Julen Etxaniz,Mikel Zubillaga,Ander Soraluze,Aitor Soroa*

Main category: cs.CL

TL;DR: 本文讨论了语言模型对非标准语言变体处理不足的问题，并提出通过整合多样化语料库来提升模型性能和通用性。


<details>
  <summary>Details</summary>
Motivation: 目前的语言模型过度依赖经过筛选的文本语料库，这导致模型对非标准语言变体的处理能力不足，从而影响模型的鲁棒性并强化了表征偏差。

Method: 以巴斯克语为例，作者构建了结合标准、社交媒体和历史来源的新语料库，并预训练了BERnaT系列的编码器模型，包括标准、多样化和组合三种配置。此外，还提出了一个将自然语言理解（NLU）任务分为标准和多样化子集来评估语言泛化能力的评估框架。

Result: 实验结果表明，在标准和多样化数据上训练的模型始终优于仅在标准语料库上训练的模型，在所有任务类型上都提高了性能，同时不影响标准基准测试的准确性。

Conclusion: 研究结果强调了语言多样性对于构建包容性、通用性强的语言模型的重要性。

Abstract: Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.

</details>


### [28] [Is Lying Only Sinful in Islam? Exploring Religious Bias in Multilingual Large Language Models Across Major Religions](https://arxiv.org/abs/2512.03943)
*Kazi Abrab Hossain,Jannatul Somiya Mahmud,Maria Hossain Tuli,Anik Mitra,S. M. Taiabul Haque,Farig Y. Sadeque*

Main category: cs.CL

TL;DR: 该文章介绍了BRAND，这是一个专注于南亚四大宗教（佛教、基督教、印度教和伊斯兰教）的双语宗教负责任规范数据集，旨在解决多语言模型在宗教背景下误解和不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在宗教等敏感主题上存在的偏见和误解，特别是多语言模型在处理宗教内容时表现不佳的问题。

Method: 引入了BRAND数据集，该数据集包含2400多条关于南亚四大宗教的条目，并使用英语和孟加拉语两种语言的三种不同类型的提示进行测试。

Result: 模型在英语中的表现优于孟加拉语，并且即使在回答宗教中立问题时，也一直对伊斯兰教表现出偏见。研究结果强调了多语言模型在不同语言中提出类似问题时存在的持续偏见。

Conclusion: 多语言模型在处理宗教内容时存在显著偏见，尤其是在不同语言环境下表现不一，研究结果对人机交互领域中宗教和精神方面的问题具有启发意义。

Abstract: While recent developments in large language models have improved bias detection and classification, sensitive subjects like religion still present challenges because even minor errors can result in severe misunderstandings. In particular, multilingual models often misrepresent religions and have difficulties being accurate in religious contexts. To address this, we introduce BRAND: Bilingual Religious Accountable Norm Dataset, which focuses on the four main religions of South Asia: Buddhism, Christianity, Hinduism, and Islam, containing over 2,400 entries, and we used three different types of prompts in both English and Bengali. Our results indicate that models perform better in English than in Bengali and consistently display bias toward Islam, even when answering religion-neutral questions. These findings highlight persistent bias in multilingual models when similar questions are asked in different languages. We further connect our findings to the broader issues in HCI regarding religion and spirituality.

</details>


### [29] [Adapting Large Language Models to Low-Resource Tibetan: A Two-Stage Continual and Supervised Fine-Tuning Study](https://arxiv.org/abs/2512.03976)
*Lifeng Chen,Ryan Lai,Tianming Liu*

Main category: cs.CL

TL;DR: 本文介绍了将Qwen2.5-3B适配到藏语的过程，包括持续预训练和监督微调，并在藏语语言接地和中藏翻译质量上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺和跨语言漂移，将大型语言模型（LLMs）适配到低资源语言仍然是一个主要挑战。

Method: 本文采用了两阶段适配方法：首先进行持续预训练（CPT）以建立藏语语言基础，然后进行监督微调（SFT）以实现任务和翻译的专业化。

Result: 经验评估表明，困惑度持续下降（从2.98到1.54），中藏翻译质量显著提高（BLEU：从0.046到0.261；chrF：从2.2到6.6）。对Qwen3-4B中435层的分层分析显示，适配主要集中在嵌入层和输出头，中后期MLP投影编码了特定领域的转换。

Conclusion: CPT构建了藏语语义流形，而SFT以最小的表示扰动增强了任务对齐。这项研究首次对LLMs的藏语适配动态进行了定量探索，并为将多语言基础模型扩展到低资源环境提供了开放、可复现的框架。

Abstract: Adapting large language models (LLMs) to low-resource languages remains a major challenge due to data scarcity and cross-lingual drift. This work presents a two-stage adaptation of Qwen2.5-3B to Tibetan, a morphologically rich and underrepresented language. We employ Continual Pretraining (CPT) to establish Tibetan linguistic grounding, followed by Supervised Fine-Tuning (SFT) for task and translation specialization. Empirical evaluations demonstrate a consistent decrease in perplexity (from 2.98 $\rightarrow$ 1.54) and substantial improvements in Chinese$\rightarrow$Tibetan translation quality (BLEU: 0.046 $\rightarrow$ 0.261; chrF: 2.2 $\rightarrow$ 6.6). Layer-wise analysis across 435 layers in Qwen3-4B reveals that adaptation primarily concentrates on embedding and output heads, with mid--late MLP projections encoding domain-specific transformations. Our findings suggest that CPT constructs a Tibetan semantic manifold while SFT sharpens task alignment with minimal representational disruption. This study provides the first quantitative exploration of Tibetan adaptation dynamics for LLMs, and offers an open, reproducible framework for extending multilingual foundation models to low-resource settings.

</details>


### [30] [Teaching Old Tokenizers New Words: Efficient Tokenizer Adaptation for Pre-trained Models](https://arxiv.org/abs/2512.03989)
*Taido Purason,Pavel Chizhov,Ivan P. Yamshchikov,Mark Fishel*

Main category: cs.CL

TL;DR: 本文提出了一种持续BPE训练的方法来适应预训练的分词器，并通过在BPE合并学习过程中在新数据上进行训练来扩展词汇，从而提高了分词效率和词汇利用率。它还引入了基于叶子的词汇修剪方法，在保持模型质量的同时移除冗余token。这两种方法提供了受控词汇修改的实用工具。


<details>
  <summary>Details</summary>
Motivation: 传统的词汇扩展方法会导致许多冗余或未使用的token。本文旨在通过提出持续BPE训练和基于叶子的词汇修剪来解决这个问题。

Method: 1. 持续BPE训练：通过在新数据上继续BPE合并学习过程来适应预训练的分词器。2. 基于叶子的词汇修剪：移除冗余token，同时保持模型质量。

Result: 1. 持续BPE训练提高了分词效率，并提高了新增词汇的利用率。2. 在多种语言和模型家族上的实验证明了该方法的有效性。

Conclusion: 本文提出的持续BPE训练和基于叶子的词汇修剪方法为控制词汇修改提供了实用的工具，可以有效地将预训练语言模型应用于新的领域或语言。

Abstract: Tokenizer adaptation plays an important role in transferring pre-trained language models to new domains or languages. In this work, we address two complementary aspects of this process: vocabulary extension and pruning. The common approach to extension trains a new tokenizer on domain-specific text and appends the tokens that do not overlap with the existing vocabulary, which often results in many tokens that are unreachable or never used. We propose continued BPE training, which adapts a pre-trained tokenizer by continuing the BPE merge learning process on new data. Experiments across multiple languages and model families show that this approach improves tokenization efficiency and leads to better utilization of added vocabulary. We also introduce leaf-based vocabulary pruning, which removes redundant tokens while preserving model quality. Together, these methods provide practical tools for controlled vocabulary modification, which we release as an open-source package.

</details>


### [31] [AugServe: Adaptive Request Scheduling for Augmented Large Language Model Inference Serving](https://arxiv.org/abs/2512.04013)
*Ying Wang,Zhen Jin,Jiexiong Xu,Wenhai Lin,Yiquan Chen,Wenzhi Chen*

Main category: cs.CL

TL;DR: AugServe是一个高效的推理框架，通过两阶段自适应请求调度策略和动态令牌批处理机制，显著提高了增强型LLM推理服务的有效吞吐量并减少了延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的增强型LLM推理系统在处理请求时面临两个主要挑战：1）依赖先来先服务（FCFS）调度导致严重的队头阻塞，使许多请求的排队延迟超过服务水平目标（SLO）；2）静态批处理令牌限制无法适应负载波动和硬件条件。这两个因素都会降低有效吞吐量和服务质量。

Method: 本文提出了AugServe，一个高效的推理框架。其核心思想是两阶段自适应请求调度策略。AugServe结合增强型LLM请求的推理特征来优化调度决策顺序（第一阶段），并根据运行时信息（第二阶段）不断优化这些决策，以适应请求特征和系统能力。此外，AugServe根据硬件状态和实时负载动态调整令牌批处理机制。

Result: 实验结果表明，AugServe比vLLM和InferCept的有效吞吐量高出4.7-33.1倍和3.3-13.2倍，同时将首个令牌生成时间（TTFT）分别减少了高达96.3%和95.0%。

Conclusion: AugServe通过其创新的两阶段自适应调度策略和动态令牌批处理机制，有效地解决了增强型LLM推理服务中存在的效率问题，显著提升了系统性能和用户体验。

Abstract: As augmented large language models (LLMs) with external tools become increasingly popular in web applications, improving augmented LLM inference serving efficiency and optimizing service-level objectives (SLOs) are critical for enhancing user experience. To achieve this, inference systems must maximize request handling within latency constraints, referred to as increasing effective throughput. However, existing systems face two major challenges: (i) reliance on first-come-first-served (FCFS) scheduling causes severe head-of-line blocking, leading to queuing delays exceeding the SLOs for many requests; and (ii) static batch token limit, which fails to adapt to fluctuating loads and hardware conditions. Both of these factors degrade effective throughput and service quality.
  This paper presents AugServe, an efficient inference framework designed to reduce queueing latency and enhance effective throughput for augmented LLM inference services. The core idea of AugServe is a two-stage adaptive request scheduling strategy. Specifically, AugServe combines the inference features of augmented LLM requests to optimize the order of scheduling decisions (stage I). These decisions are continuously refined with runtime information (stage II), adapting to both request characteristics and system capabilities. In addition, AugServe dynamically adjusts the token batching mechanism based on hardware status and real-time load, further enhancing throughput performance. Experimental results show that AugServe achieves 4.7-33.1x and 3.3-13.2x higher effective throughput than vLLM and InferCept, while reducing time-to-first-token (TTFT) by up to 96.3% and 95.0%, respectively.

</details>


### [32] [Jina-VLM: Small Multilingual Vision Language Model](https://arxiv.org/abs/2512.04032)
*Andreas Koukounas,Georgios Mastrapas,Florian Hönicke,Sedigheh Eslami,Guillaume Roncari,Scott Martens,Han Xiao*

Main category: cs.CL

TL;DR: Jina-VLM是一个2.4B参数的视觉-语言模型，在开放的2B规模VLM中实现了最先进的多语言视觉问答。


<details>
  <summary>Details</summary>
Motivation: 在开放的2B规模VLM中实现最先进的多语言视觉问答能力。

Method: Jina-VLM通过注意力池化连接器将SigLIP2视觉编码器与Qwen3语言骨干耦合，实现了任意分辨率图像的token高效处理。

Result: 在标准VQA基准测试和多语言评估中，Jina-VLM超越了同类模型，同时保持了有竞争力的纯文本性能。

Conclusion: Jina-VLM在多语言视觉问答方面表现出色，为未来的多模态研究奠定了基础。

Abstract: We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.

</details>


### [33] [SkillFactory: Self-Distillation For Learning Cognitive Behaviors](https://arxiv.org/abs/2512.04072)
*Zayne Sprague,Jack Lu,Manya Wadhwa,Sedrick Keh,Mengye Ren,Greg Durrett*

Main category: cs.CL

TL;DR: SkillFactory是一种在强化学习（RL）之前，通过有监督微调（SFT）帮助语言模型学习认知技能的方法，它使用模型自身生成的样本进行训练，无需蒸馏，能有效提升模型在RL后的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法表明，当基础语言模型表现出认知技能时，通过强化学习可以进一步利用这些技能。但目前面临的挑战是如何让模型学习基础模型不具备的技能。

Method: SkillFactory方法在强化学习之前进行有监督微调（SFT）。它不依赖于从更强的模型进行蒸馏，而是使用模型自身生成的样本，并重新编排这些样本以提供符合特定技能训练所需的数据。

Result: 1. 从SkillFactory的SFT初始化开始训练的模型，在RL后能更好地泛化到更难的任务变体，尽管在RL前的表现可能较低。2. 模型确实使用了习得的认知技能。3. 经过RL训练的SkillFactory模型在处理域外任务时，比经过RL训练的基础模型具有更强的鲁棒性，不易出现性能下降。

Conclusion: 在强化学习之前学习到的归纳偏置有助于模型学习并稳健地使用认知技能。

Abstract: Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These "silver" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.

</details>


### [34] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

Main category: cs.CL

TL;DR: MAPS（Multi-Layered Self-Reflection with Auto-Prompting）框架通过结合思维链、自反思和自动提示技术，显著提升了大型语言模型在多步数学推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂的多步推理任务中仍面临挑战。

Method: MAPS框架采用迭代优化流程，首先利用思维链提示生成解决方案，在检测到错误时，自适应自反思机制会分析错误并生成定制化提示，以指导模型纠正并迭代优化其推理过程。

Result: 在四个基准测试中，MAPS显著优于标准思维链方法，并达到了与推理优化模型相当的性能水平，使得通用大型语言模型能够达到专业推理模型的性能。

Conclusion: MAPS框架通过在多步反射层和成本之间取得平衡，优化了推理性能与资源消耗之间的关系。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly improved their problem-solving capabilities. However, these models still struggle when faced with complex multi-step reasoning tasks. In this paper, we propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework, a novel approach designed to enhance multi-step mathematical reasoning in LLMs by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an iterative refinement process. Initially, the model generates a solution using CoT prompting. When errors are detected, an adaptive self-reflection mechanism identifies and analyzes them, generating tailored prompts to guide corrections. These dynamically adjusted prompts enable the model to iteratively refine its reasoning. Experiments on four well-established benchmarks across multiple LLMs show that MAPS significantly outperforms standard CoT and achieves competitive results with reasoning-optimized models. In addition, MAPS enables general-purpose LLMs to reach performance levels comparable to specialized reasoning models. While deeper reflection layers improve accuracy, they also increase token usage and costs. To balance this trade-off, MAPS strategically limits reflection depth, ensuring an optimal balance between cost and reasoning performance.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [35] [Local Dominance in Mixed-Strength Populations -- Fast Maximal Independent Set](https://arxiv.org/abs/2512.03303)
*Michael Luby,Sandy Irani*

Main category: cs.MA

TL;DR: 本文介绍了混合强度智能体模型，该模型扩展了Luby MIS协议，其中每个智能体都从自己的分布中生成强度值，并且仍然表现出快速优势收敛。


<details>
  <summary>Details</summary>
Motivation: 在许多自然和工程系统中，智能体通过局部竞争进行交互，这决定了哪些个体在其邻域中占据主导地位。这些交互由强度的内在差异决定，并且通常会导致相对于人口规模，稳定优势模式出人意料地快速出现。这促使人们寻找简单的数学模型来捕捉异构智能体强度和快速收敛到稳定的局部优势。

Method: 我们引入了混合强度智能体模型，其中每个智能体都从自己的分布中获取强度。我们证明了Luby MIS协议的扩展，其中每个智能体重复地从自己的分布中生成一个强度值，仍然表现出快速优势收敛。

Result: 我们证明了Luby MIS协议的扩展在混合强度智能体模型中仍然表现出快速优势收敛。我们还表明，异质性可以显著改变过程的动态。与等强度设置相比，每轮不必消除恒定比例的边。

Conclusion: 该研究通过对Luby MIS协议的扩展，证实了在混合强度智能体环境下快速优势收敛的现象，同时揭示了异质性对过程动态的深远影响。研究结果表明，固有的强度不对称性会产生与等强度情境下截然不同的全局行为，这为理解复杂系统中优势模式的形成和演变提供了新的视角。

Abstract: In many natural and engineered systems, agents interact through local contests that determine which individuals become dominant within their neighborhoods. These interactions are shaped by inherent differences in strength, and they often lead to stable dominance patterns that emerge surprisingly quickly relative to the size of the population. This motivates the search for simple mathematical models that capture both heterogeneous agent strength and rapid convergence to stable local dominance.
  A widely studied abstraction of local dominance is the Maximal Independent Set (MIS) problem. In the Luby MIS protocol that provably converges quickly to an MIS, each agent repeatedly generates a strength value chosen uniformly and becomes locally dominant if its value is smaller than those of its neighbors. This provides a theoretical explanation for fast dominance convergence in populations of equal-strength agents and naturally raises the question of whether fast convergence also holds in the more realistic setting where agents are inherently mixed-strength.
  To investigate this question, we introduce the mixed-strength agents model, in which each agent draws its strength from its own distribution. We prove that the extension of the Luby MIS protocol where each agent repeatedly generates a strength value from its own distribution still exhibits fast dominance convergence, providing formal confirmation of the rapid convergence observed in many mixed-strength natural processes.
  We also show that heterogeneity can significantly change the dynamics of the process. In contrast to the equal-strength setting, a constant fraction of edges need not be eliminated per round. We construct a population and strength profile in which progress per round is asymptotically smaller, illustrating how inherent strength asymmetry produces qualitatively different global behavior.

</details>


### [36] [SRPG: Semantically Reconstructed Privacy Guard for Zero-Trust Privacy in Educational Multi-Agent Systems](https://arxiv.org/abs/2512.03694)
*Shuang Guo,Zihui Li*

Main category: cs.MA

TL;DR: SRPG是一种保护教育领域多智能体系统（MAS）中未成年人隐私的方案，它在保证零个人身份信息（PII）泄露的同时，有效恢复了教学内容，取得了显著优于基线模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的隐私保护方法在教育领域的多智能体系统（MAS）中无法很好地平衡安全与实用性，尤其是在处理非结构化对话时，难以在保护未成年人个人身份信息（PII）的同时不损害教学语境。

Method: 本文提出了SRPG（一种用于教育型MAS的隐私卫士），它采用双流重建机制。该机制包括一个严格的净化流，确保零PII泄露；以及一个上下文重建流（由大型语言模型驱动），用于恢复数学逻辑。这种方法将教学内容与私人数据解耦。

Result: 在MathDial上的测试表明，SRPG适用于多种模型。结合GPT-4o使用时，SRPG实现了0.0000的攻击成功率（即零泄露）和0.8267的精确匹配率。这显著优于零信任纯大型语言模型基线（其攻击成功率为0.2138）。

Conclusion: SRPG在不牺牲数学教学质量的前提下，有效保护了未成年人的隐私。

Abstract: Multi-Agent Systems (MAS) with large language models (LLMs) enable personalized education but risk leaking minors personally identifiable information (PII) via unstructured dialogue. Existing privacy methods struggle to balance security and utility: role-based access control fails on unstructured text, while naive masking destroys pedagogical context. We propose SRPG, a privacy guard for educational MAS, using a Dual-Stream Reconstruction Mechanism: a strict sanitization stream ensures zero PII leakage, and a context reconstruction stream (LLM driven) recovers mathematical logic. This decouples instructional content from private data, preserving teaching efficacy. Tests on MathDial show SRPG works across models; with GPT-4o, it achieves 0.0000 Attack Success Rate (ASR) (zero leakage) and 0.8267 Exact Match, far outperforming the zero trust Pure LLM baseline (0.2138). SRPG effectively protects minors privacy without sacrificing mathematical instructional quality.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [Physics-Informed Machine Learning for Steel Development: A Computational Framework and CCT Diagram Modelling](https://arxiv.org/abs/2512.03050)
*Peter Hedström,Victor Lamelas Cubero,Jón Sigurdsson,Viktor Österberg,Satish Kolli,Joakim Odqvist,Ziyong Hou,Wangzhong Mu,Viswanadh Gowtham Arigela*

Main category: cs.LG

TL;DR: 该研究提出了一个机器学习结合物理知识的框架，用于开发钢的物理信息连续冷却转变（CCT）模型，该模型在4100个图表的数据集上训练，并能高效准确地预测CCT图和相变温度，展现了强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前机器学习在材料科学中的应用主要集中在新化合物的发现和制造过程的优化，但将通用机器学习框架应用于钢铁等复杂工业材料时，难以准确捕捉化学成分、加工参数与微观结构和性能之间的复杂关系。

Method: 本文引入了一个结合物理洞察力与机器学习的计算框架，开发了一种钢的物理信息连续冷却转变（CCT）模型。该模型在一个包含4100个CCT图的数据集上进行训练，并利用机器学习方法来学习和预测相变行为。

Result: 开发的模型在5秒内可生成包含100条冷却曲线的完整CCT图，计算效率高。模型在合金钢中展现出强大的泛化能力，所有相的相分类F1分数均高于88%。除贝氏体外，所有相的相变温度回归平均绝对误差（MAE）均低于20°C，贝氏体的MAE略高为27°C。

Conclusion: 该研究提出的物理信息CCT模型通过结合物理洞察与机器学习，有效解决了复杂工业材料建模的挑战。该框架具有高效率、强泛化能力和准确性，并可扩展为热处理的通用数字孪生平台，支持加速材料设计工作流程。

Abstract: Machine learning (ML) has emerged as a powerful tool for accelerating the computational design and production of materials. In materials science, ML has primarily supported large-scale discovery of novel compounds using first-principles data and digital twin applications for optimizing manufacturing processes. However, applying general-purpose ML frameworks to complex industrial materials such as steel remains a challenge. A key obstacle is accurately capturing the intricate relationship between chemical composition, processing parameters, and the resulting microstructure and properties. To address this, we introduce a computational framework that combines physical insights with ML to develop a physics-informed continuous cooling transformation (CCT) model for steels. Our model, trained on a dataset of 4,100 diagrams, is validated against literature and experimental data. It demonstrates high computational efficiency, generating complete CCT diagrams with 100 cooling curves in under 5 seconds. It also shows strong generalizability across alloy steels, achieving phase classification F1 scores above 88% for all phases. For phase transition temperature regression, it attains mean absolute errors (MAE) below 20 °C across all phases except bainite, which shows a slightly higher MAE of 27 °C. This framework can be extended with additional generic and customized ML models to establish a universal digital twin platform for heat treatment. Integration with complementary simulation tools and targeted experiments will further support accelerated materials design workflows.

</details>


### [38] [Energy-Efficient Federated Learning via Adaptive Encoder Freezing for MRI-to-CT Conversion: A Green AI-Guided Research](https://arxiv.org/abs/2512.03054)
*Ciro Benito Raggio,Lucia Migliorelli,Nils Skupien,Mathias Krohmer Zabaleta,Oliver Blanck,Francesco Cicone,Giuseppe Lucio Cascini,Paolo Zaffino,Maria Francesca Spadea*

Main category: cs.LG

TL;DR: 该研究提出了一种面向绿色人工智能的自适应分层冻结策略，旨在减少联邦学习（FL）中的能耗和计算负荷，同时保持模型性能，从而促进医疗领域的公平性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在医疗领域通过支持机构协作训练深度学习模型，即使数据有限也能促进健康公平。然而，FL巨大的资源需求常将计算基础设施有限的机构排斥在外，加剧了现有的医疗健康不平等。

Method: 提出了一种面向绿色AI的自适应分层冻结策略，通过选择性冻结编码器权重来优化联邦训练，冻结是基于编码器权重在不同训练轮次间的相对差异进行监控。该策略还引入了一种基于“耐心”机制，确保仅当更新持续保持最小时才进行冻结。使用CodeCarbon库跟踪联邦学习的能耗和CO2eq排放。

Result: 与非冻结模型相比，该方法将训练时间、总能耗和CO2eq排放减少了高达23%。同时，MRI到CT转换性能得以保持，平均绝对误差（MAE）仅有很小的变化。在五种评估架构中，三种没有统计学上的显著差异，而两种表现出统计学上的显著改进。

Conclusion: 该工作提出了一种新的FL评估框架，促进了隐私、公平，并在更广泛的范围内促进了人工智能驱动医疗中的正义性。它为深度学习框架在满足临床要求的同时，确保气候、社会和经济可持续性奠定了基础。

Abstract: Federated Learning (FL) holds the potential to advance equality in health by enabling diverse institutions to collaboratively train deep learning (DL) models, even with limited data. However, the significant resource requirements of FL often exclude centres with limited computational infrastructure, further widening existing healthcare disparities. To address this issue, we propose a Green AI-oriented adaptive layer-freezing strategy designed to reduce energy consumption and computational load while maintaining model performance. We tested our approach using different federated architectures for Magnetic Resonance Imaging (MRI)-to-Computed Tomography (CT) conversion. The proposed adaptive strategy optimises the federated training by selectively freezing the encoder weights based on the monitored relative difference of the encoder weights from round to round. A patience-based mechanism ensures that freezing only occurs when updates remain consistently minimal. The energy consumption and CO2eq emissions of the federation were tracked using the CodeCarbon library. Compared to equivalent non-frozen counterparts, our approach reduced training time, total energy consumption and CO2eq emissions by up to 23%. At the same time, the MRI-to-CT conversion performance was maintained, with only small variations in the Mean Absolute Error (MAE). Notably, for three out of the five evaluated architectures, no statistically significant differences were observed, while two architectures exhibited statistically significant improvements. Our work aligns with a research paradigm that promotes DL-based frameworks meeting clinical requirements while ensuring climatic, social, and economic sustainability. It lays the groundwork for novel FL evaluation frameworks, advancing privacy, equity and, more broadly, justice in AI-driven healthcare.

</details>


### [39] [Delta Sampling: Data-Free Knowledge Transfer Across Diffusion Models](https://arxiv.org/abs/2512.03056)
*Zhidong Gao,Zimeng Pan,Yuhang Yao,Chenyue Xie,Wei Wei*

Main category: cs.LG

TL;DR: Delta Sampling (DS) 是一种新颖的、仅在推理时使用的方法，它通过利用模型预测的增量差异，实现了在扩散模型（如 Stable Diffusion）中跨不同架构基础模型进行知识迁移，无需原始训练数据，从而提高了生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型（如 Stable Diffusion）适配组件（如 LoRA、LyCORIS、ControlNet）与特定的基础模型紧密耦合，当基础模型升级时（例如从 SD 1.x 到 2.x），由于模型参数和架构的巨大变化，这些组件难以重用。

Method: Delta Sampling (DS) 方法在推理时操作，利用基础模型适配前后的模型预测增量（delta）。然后，这个增量被用于指导新基础模型的去噪过程。

Result: Delta Sampling 在不同的 Stable Diffusion 版本上进行了评估，结果表明 DS 在创建所需效果（如视觉风格、语义概念和结构）方面取得了持续的改进，并且适用于不同的采样策略。

Conclusion: Delta Sampling 是一种有效且即插即用的机制，用于在基于扩散的图像合成中进行知识迁移，能够实现跨不同架构基础模型的高效适配。

Abstract: Diffusion models like Stable Diffusion (SD) drive a vibrant open-source ecosystem including fully fine-tuned checkpoints and parameter-efficient adapters such as LoRA, LyCORIS, and ControlNet. However, these adaptation components are tightly coupled to a specific base model, making them difficult to reuse when the base model is upgraded (e.g., from SD 1.x to 2.x) due to substantial changes in model parameters and architecture. In this work, we propose Delta Sampling (DS), a novel method that enables knowledge transfer across base models with different architectures, without requiring access to the original training data. DS operates entirely at inference time by leveraging the delta: the difference in model predictions before and after the adaptation of a base model. This delta is then used to guide the denoising process of a new base model. We evaluate DS across various SD versions, demonstrating that DS achieves consistent improvements in creating desired effects (e.g., visual styles, semantic concepts, and structures) under different sampling strategies. These results highlight DS as an effective, plug-and-play mechanism for knowledge transfer in diffusion-based image synthesis. Code:~ https://github.com/Zhidong-Gao/DeltaSampling

</details>


### [40] [Dynamical Properties of Tokens in Self-Attention and Effects of Positional Encoding](https://arxiv.org/abs/2512.03058)
*Duy-Tung Pham,An The Nguyen,Viet-Hoang Tran,Nhan-Phu Chung,Xin T. Tong,Tan M. Nguyen,Thieu N. Vo*

Main category: cs.LG

TL;DR: 该文章分析了预训练Transformer模型中tokens的动态特性，并探索了如何利用这些特性改进模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索预训练Transformer模型中tokens的动态特性，并应用这些发现来改进Transformer模型。

Method: 分析了控制预训练模型连续时间极限的动力系统，并描述了其解的渐近行为。具体而言，文章研究了tokens随时间相互靠近或远离的条件，并提供了基于模型参数的充分条件，以识别tokens收敛到零或发散到无穷的情况。此外，还研究了不同形式的位置编码（绝对和旋转）如何影响这些动态 H o M q。

Result: 经验证据表明，收敛情况会对模型性能产生不利影响。研究人员提出了简单的改进方法，以减轻具有绝对或旋转位置编码的模型中的收敛行为。

Conclusion: 这些发现为改进Transformer模型提供了理论基础和设计原则。

Abstract: This paper investigates the dynamical properties of tokens in pre-trained Transformer models and explores their application to improving Transformers. To this end, we analyze the dynamical system governing the continuous-time limit of the pre-trained model and characterize the asymptotic behavior of its solutions. Specifically, we characterize when tokens move closer to or farther from one another over time, depending on the model parameters. We provide sufficient conditions, based on these parameters, to identify scenarios where tokens either converge to zero or diverge to infinity. Unlike prior works, our conditions are broader in scope and more applicable to real-world models. Furthermore, we investigate how different forms of positional encoding -- specifically absolute and rotary -- affect these dynamical regimes. Empirical evidence reveals that the convergence scenario adversely impacts model performance. Motivated by these insights, we propose simple refinements to Transformer architectures that mitigate convergence behavior in models with absolute or rotary positional encoding. These findings support theoretical foundations and design principles for improving Transformer models.

</details>


### [41] [Globally optimized SVD compression of LLMs via Fermi-function-based rank selection and gauge fixing](https://arxiv.org/abs/2512.03062)
*Roman Rausch,David Jansen,Sukhbinder Singh,Román Orús*

Main category: cs.LG

TL;DR: 该论文提出了两种受物理启发的改进方法，用于LLM的SVD压缩，解决了层级秩选择和参数冗余问题。


<details>
  <summary>Details</summary>
Motivation: LLMs对计算资源的需求很高，而通过SVD等低秩分解对LLM权重进行压缩是一个有前景的方法，但存在一些实际障碍，如选择合适的逐层秩和消除参数冗余。

Method: 1. FermiGrad：一种梯度下降算法，通过将离散的奇异值截断松弛为使用费米函数的连续优化，确定全局最优的逐层秩。2. PivGa：对低秩因子进行额外的无损压缩，利用其参数化中的内在规范自由度。

Result: FermiGrad通过将离散奇异值截断松弛为连续优化来确定全局最优的逐层秩。PivGa利用低秩因子参数化中的规范自由度，实现了无损压缩。

Conclusion: 该工作提出了FermiGrad和PivGa两种方法，分别解决了LLM压缩中层级秩选择和参数冗余问题，为LLM的SVD压缩提供了实用的改进。

Abstract: Large Language Models (LLMs) are very demanding in terms of their computational resources. Low-rank decompositions of LLM weights, e.g. via Singular Value Decomposition (SVD), is a promising approach for LLM compression, but presents several practical hurdles, e.g. selecting appropriate layer-wise ranks and getting rid of its parameter redundancy. In this work, we present two physics-inspired improvements to SVD LLM compression: (1) \textbf{FermiGrad}, a gradient-descent algorithm that determines globally optimal layer-wise ranks by relaxing the discrete singular-value truncation into a continuous optimization using the Fermi function; (2) \textbf{PivGa}, an additional \textit{lossless} compression of the low-rank factors that exploits the intrinsic gauge freedom in their parametrization.

</details>


### [42] [Safe and Sustainable Electric Bus Charging Scheduling with Constrained Hierarchical DRL](https://arxiv.org/abs/2512.03059)
*Jiaju Qi,Lei Lei,Thorsteinn Jonsson,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文提出了一个安全的层次深度强化学习框架，用于在多源不确定性下解决电动公交车充电调度问题。


<details>
  <summary>Details</summary>
Motivation: 在可再生能源（如光伏）日益普及的背景下，电动公交车（EB）与可再生能源的结合是实现可持续低碳公共交通的重要途径。然而，优化EB充电调度以在最小化运营成本的同时确保电池不耗尽并安全运行，在现实世界条件下，尤其是在光伏发电不确定性、电价动态变化、出行时间可变以及充电基础设施有限等多种不确定性因素下，仍然是一个挑战。

Method: 本文将问题表述为带有选项的约束马尔可夫决策过程（CMDP），以实现时间抽象的决策。开发了一种新颖的HDRL算法，即Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian)，该算法将拉格朗日松弛集成到Double Actor-Critic (DAC) 框架中。在顶层使用EPO-拉格朗日算法学习安全的充电器分配策略；在底层，结合MAPPO-拉格朗日算法，在集中训练和分散执行（CTDE）范式下学习分散的充电功率决策。

Result: 通过真实世界数据的广泛实验表明，该方法在成本最小化和安全合规性方面均优于现有基线，同时保持了快速收敛速度。

Conclusion: 所提出的安全层次深度强化学习框架（DAC-MAPPO-Lagrangian）能够有效地解决多源不确定性下的电动公交车充电调度问题，并在成本、安全性和收敛速度方面表现出色。

Abstract: The integration of Electric Buses (EBs) with renewable energy sources such as photovoltaic (PV) panels is a promising approach to promote sustainable and low-carbon public transportation. However, optimizing EB charging schedules to minimize operational costs while ensuring safe operation without battery depletion remains challenging - especially under real-world conditions, where uncertainties in PV generation, dynamic electricity prices, variable travel times, and limited charging infrastructure must be accounted for. In this paper, we propose a safe Hierarchical Deep Reinforcement Learning (HDRL) framework for solving the EB Charging Scheduling Problem (EBCSP) under multi-source uncertainties. We formulate the problem as a Constrained Markov Decision Process (CMDP) with options to enable temporally abstract decision-making. We develop a novel HDRL algorithm, namely Double Actor-Critic Multi-Agent Proximal Policy Optimization Lagrangian (DAC-MAPPO-Lagrangian), which integrates Lagrangian relaxation into the Double Actor-Critic (DAC) framework. At the high level, we adopt a centralized PPO-Lagrangian algorithm to learn safe charger allocation policies. At the low level, we incorporate MAPPO-Lagrangian to learn decentralized charging power decisions under the Centralized Training and Decentralized Execution (CTDE) paradigm. Extensive experiments with real-world data demonstrate that the proposed approach outperforms existing baselines in both cost minimization and safety compliance, while maintaining fast convergence speed.

</details>


### [43] [Detecting AI Hallucinations in Finance: An Information-Theoretic Method Cuts Hallucination Rate by 92%](https://arxiv.org/abs/2512.03107)
*Mainak Singha*

Main category: cs.LG

TL;DR: 该论文提出了ECLIPSE框架，一种基于语义熵和证据容量来检测大语言模型幻觉的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型产生的流畅但不真实的幻觉限制了其在高风险领域的安全应用。

Method: ECLIPSE框架将幻觉视为模型语义熵与可用证据容量之间的不匹配。它结合了多样本聚类熵估计和新颖的困惑度分解，以衡量模型如何利用检索到的证据。

Result: 在金融问答数据集上，ECLIPSE在GPT-3.5-turbo上实现了0.89的ROC AUC和0.90的平均精度，显著优于仅语义熵基线（AUC 0.50）。在Claude-3-Haiku上的消融实验显示，在缺乏token级别对数概率的情况下，AUC降至0.59。困惑度分解特征显示出最大的学习系数，证实证据利用是幻觉检测的核心。

Conclusion: ECLIPSE框架通过衡量模型的语义熵和证据利用情况，能有效检测大语言模型中的幻觉。然而，该研究目前属于机制研究，未来需要在更广泛的领域和自然发生的幻觉中进行验证。

Abstract: Large language models (LLMs) produce fluent but unsupported answers - hallucinations - limiting safe deployment in high-stakes domains. We propose ECLIPSE, a framework that treats hallucination as a mismatch between a model's semantic entropy and the capacity of available evidence. We combine entropy estimation via multi-sample clustering with a novel perplexity decomposition that measures how models use retrieved evidence. We prove that under mild conditions, the resulting entropy-capacity objective is strictly convex with a unique stable optimum. We evaluate on a controlled financial question answering dataset with GPT-3.5-turbo (n=200 balanced samples with synthetic hallucinations), where ECLIPSE achieves ROC AUC of 0.89 and average precision of 0.90, substantially outperforming a semantic entropy-only baseline (AUC 0.50). A controlled ablation with Claude-3-Haiku, which lacks token-level log probabilities, shows AUC dropping to 0.59 with coefficient magnitudes decreasing by 95% - demonstrating that ECLIPSE is a logprob-native mechanism whose effectiveness depends on calibrated token-level uncertainties. The perplexity decomposition features exhibit the largest learned coefficients, confirming that evidence utilization is central to hallucination detection. We position this work as a controlled mechanism study; broader validation across domains and naturally occurring hallucinations remains future work.

</details>


### [44] [A Large Scale Heterogeneous Treatment Effect Estimation Framework and Its Applications of Users' Journey at Snap](https://arxiv.org/abs/2512.03060)
*Jing Pan,Li Shi,Paul Lo*

Main category: cs.LG

TL;DR: 本研究提出了一个大规模工业框架，用于估计来自数亿Snapchat用户的实验数据中的异构处理效应（HTE）。通过结合多个实验的结果，该框架揭示了以前无法衡量的潜在用户特征，并大规模生成了稳定的处理效应估计。


<details>
  <summary>Details</summary>
Motivation: 异构处理效应（HTE）和条件平均处理效应（CATE）模型放宽了处理效应对于每个用户都相同的假设。

Method: 结合了实验选择、基础学习器设计和增量训练等核心组件来构建系统，并利用来自数亿Snapchat用户的实验数据。

Result: 通过利用影响力分数进行用户定位的在线A/B测试，关键业务指标的改善是通常认为显著的六倍以上，揭示了潜在的用户特征并大规模生成了稳定的处理效应估计。

Conclusion: 该框架能够大规模估计HTE，揭示潜在用户特征，并显著提高业务指标，例如在广告定位中的应用方面。

Abstract: Heterogeneous Treatment Effect (HTE) and Conditional Average Treatment Effect (CATE) models relax the assumption that treatment effects are the same for every user. We present a large scale industrial framework for estimating HTE using experimental data from hundreds of millions of Snapchat users. By combining results across many experiments, the framework uncovers latent user characteristics that were previously unmeasurable and produces stable treatment effect estimates at scale.
  We describe the core components that enabled this system, including experiment selection, base learner design, and incremental training. We also highlight two applications: user influenceability to ads and user sensitivity to ads. An online A/B test using influenceability scores for targeting showed an improvement on key business metrics that is more than six times larger than what is typically considered significant.

</details>


### [45] [ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms](https://arxiv.org/abs/2512.03476)
*Juan Diego Toscano,Daniel T. Chen,George Em Karniadakis*

Main category: cs.LG

TL;DR: ATHENA是一个为科学计算和科学机器学习设计的智能体框架，旨在通过自动化和学习来弥合理论与计算之间的鸿沟，实现超人类的性能。


<details>
  <summary>Details</summary>
Motivation: 在科学计算和科学机器学习领域，理论概念化与计算实现之间的差距是主要瓶颈。

Method: ATHENA框架的核心是HENA循环，这是一个知识驱动的诊断过程，被构架为上下文老虎机问题。它通过分析过去的试验来选择结构性的“动作”，这些动作基于专家蓝图（如通用逼近、物理约束），并转化为可执行代码以产生科学回报。

Result: 在科学计算中，ATHENA自主识别数学对称性以获得精确解析解或推导出稳定的数值求解器；在科学机器学习中，它进行深度诊断以解决病态公式，并结合混合符号-数值工作流来解决多物理问题。该框架实现了超人类的性能，验证误差达到$10^{-14}$。

Conclusion: ATHENA通过将重点从实现机制转移到方法创新，加速了科学发现，并且通过“人在循环”的协作干预可以进一步提高结果。

Abstract: Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.

</details>


### [46] [E-valuator: Reliable Agent Verifiers with Sequential Hypothesis Testing](https://arxiv.org/abs/2512.03109)
*Shuvom Sadhuka,Drew Prinster,Clara Fannjiang,Gabriele Scalia,Aviv Regev,Hanchen Wang*

Main category: cs.LG

TL;DR: e-valuator是一种将黑盒验证器分数转换为具有可证明的错误警报率控制的决策规则的方法，以提高Agentic AI系统轨迹评估的可靠性。


<details>
  <summary>Details</summary>
Motivation: 开发Agentic AI系统时，需要评估其执行序列动作的成功性。现有的验证器（如LLM评判器和过程奖励模型）可以对每个动作的质量进行评分，但这些启发式分数无法保证正确性。因此，需要一种方法来将这些分数转换为具有统计学保证的决策规则，以决定Agentic AI系统是否能产生成功的输出。

Method: e-valuator将区分成功轨迹和不成功轨迹的问题视为一个序贯假设检验问题。它利用e-processes的工具来开发一个序贯假设检验，使其在Agentic AI系统轨迹的每一步都保持统计学有效性，从而实现对任意长动作序列的在线监控。

Result: e-valuator提供了比其他策略更强的统计功效和更好的错误警报率控制，并在六个数据集和三个Agentic AI系统上得到了验证。此外，e-valuator还可以用于快速终止有问题的轨迹并节省tokens。

Conclusion: e-valuator提供了一个轻量级的、模型无关的框架，将验证器启发式方法转换为具有统计保证的决策规则，从而实现更可靠的Agentic AI系统的部署。

Abstract: Agentic AI systems execute a sequence of actions, such as reasoning steps or tool calls, in response to a user prompt. To evaluate the success of their trajectories, researchers have developed verifiers, such as LLM judges and process-reward models, to score the quality of each action in an agent's trajectory. Although these heuristic scores can be informative, there are no guarantees of correctness when used to decide whether an agent will yield a successful output. Here, we introduce e-valuator, a method to convert any black-box verifier score into a decision rule with provable control of false alarm rates. We frame the problem of distinguishing successful trajectories (that is, a sequence of actions that will lead to a correct response to the user's prompt) and unsuccessful trajectories as a sequential hypothesis testing problem. E-valuator builds on tools from e-processes to develop a sequential hypothesis test that remains statistically valid at every step of an agent's trajectory, enabling online monitoring of agents over arbitrarily long sequences of actions. Empirically, we demonstrate that e-valuator provides greater statistical power and better false alarm rate control than other strategies across six datasets and three agents. We additionally show that e-valuator can be used for to quickly terminate problematic trajectories and save tokens. Together, e-valuator provides a lightweight, model-agnostic framework that converts verifier heuristics into decisions rules with statistical guarantees, enabling the deployment of more reliable agentic systems.

</details>


### [47] [Beyond Additivity: Sparse Isotonic Shapley Regression toward Nonlinear Explainability](https://arxiv.org/abs/2512.03112)
*Jialai She*

Main category: cs.LG

TL;DR: SISR（Sparse Isotonic Shapley Regression）是用于可解释AI中特征归因的统一非线性解释框架，它解决了传统Shapley值面临的两大挑战：非加性价值函数和高维空间中的稀疏解释成本高昂问题。


<details>
  <summary>Details</summary>
Motivation: 传统的Shapley值框架假设价值函数是可加的，但在现实应用中（如非高斯分布、重尾、特征依赖等），这一假设常被违反，导致归因失真。此外，在高维空间中，计算密集的Shapley值再进行阈值处理以获得稀疏解释，成本高昂且可能不一致。

Method: SISR通过同步学习一个单调变换来恢复价值函数的加性，并对Shapley向量施加L0稀疏性约束，从而提高大规模特征空间的计算效率。其优化算法利用了池相邻违规算法（Pool-Adjacent-Violators）进行高效的保序回归，并采用归一化硬阈值进行支持选择，确保了易于实现和全局收敛。

Result: 分析表明，SISR可以在多种场景下恢复真实的变换，即使在高噪声环境下也能实现强大的支持恢复。研究还首次证明了不相关特征和特征间依赖性可以导致与线性模型显著偏离的真实支付转换。实验证明，SISR能够稳定不同支付方案下的归因，并正确过滤掉不相关特征，而标准Shapley值在这种情况下则会出现严重的秩和符号扭曲。

Conclusion: SISR通过统一非线性变换估计与稀疏性追求，推动了非线性可解释性的发展，提供了一个理论基础扎实且实用的归因框架。

Abstract: Shapley values, a gold standard for feature attribution in Explainable AI, face two primary challenges. First, the canonical Shapley framework assumes that the worth function is additive, yet real-world payoff constructions--driven by non-Gaussian distributions, heavy tails, feature dependence, or domain-specific loss scales--often violate this assumption, leading to distorted attributions. Secondly, achieving sparse explanations in high dimensions by computing dense Shapley values and then applying ad hoc thresholding is prohibitively costly and risks inconsistency. We introduce Sparse Isotonic Shapley Regression (SISR), a unified nonlinear explanation framework. SISR simultaneously learns a monotonic transformation to restore additivity--obviating the need for a closed-form specification--and enforces an L0 sparsity constraint on the Shapley vector, enhancing computational efficiency in large feature spaces. Its optimization algorithm leverages Pool-Adjacent-Violators for efficient isotonic regression and normalized hard-thresholding for support selection, yielding implementation ease and global convergence guarantees. Analysis shows that SISR recovers the true transformation in a wide range of scenarios and achieves strong support recovery even in high noise. Moreover, we are the first to demonstrate that irrelevant features and inter-feature dependencies can induce a true payoff transformation that deviates substantially from linearity. Experiments in regression, logistic regression, and tree ensembles demonstrate that SISR stabilizes attributions across payoff schemes, correctly filters irrelevant features while standard Shapley values suffer severe rank and sign distortions. By unifying nonlinear transformation estimation with sparsity pursuit, SISR advances the frontier of nonlinear explainability, providing a theoretically grounded and practical attribution framework.

</details>


### [48] [Single-Round Scalable Analytic Federated Learning](https://arxiv.org/abs/2512.03336)
*Alan T. L. Bacellar,Mustafa Munir,Felipe M. G. França,Priscila M. V. Lima,Radu Marculescu,Lizy K. John*

Main category: cs.LG

TL;DR: SAFLe是一个新颖的联邦学习框架，它通过引入结构化的分桶特征头部和稀疏分组嵌入，实现了可扩展的非线性表达能力。该框架在数学上等同于高维线性回归，并利用AFL的单次、不变聚合定律进行求解。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习（FL）中高通信开销和非同态（non-IID）数据上性能下降的问题，尤其是现有方法在非线性模型上的局限性，以及它们在准确性和单轮通信之间的权衡。

Method: SAFLe 通过引入结构化的分桶特征头部和稀疏分组嵌入来实现可扩展的非线性表达能力。关键在于证明了这种非线性架构在数学上等同于高维线性回归，从而能够利用AFL的单次、不变聚合定律进行求解。

Result: SAFLe 在所有基准测试中，其准确性都显著优于线性的 AFL 和多轮的 DeepAFL，建立了分析型联邦学习的新 SOTA。

Conclusion: SAFLe 提供了一种高效和可扩展的联邦学习解决方案，通过在分析型联邦学习中实现非线性表达，成功解决了通信效率和模型性能之间的长期存在的矛盾。

Abstract: Federated Learning (FL) is plagued by two key challenges: high communication overhead and performance collapse on heterogeneous (non-IID) data. Analytic FL (AFL) provides a single-round, data distribution invariant solution, but is limited to linear models. Subsequent non-linear approaches, like DeepAFL, regain accuracy but sacrifice the single-round benefit. In this work, we break this trade-off. We propose SAFLe, a framework that achieves scalable non-linear expressivity by introducing a structured head of bucketed features and sparse, grouped embeddings. We prove this non-linear architecture is mathematically equivalent to a high-dimensional linear regression. This key equivalence allows SAFLe to be solved with AFL's single-shot, invariant aggregation law. Empirically, SAFLe establishes a new state-of-the-art for analytic FL, significantly outperforming both linear AFL and multi-round DeepAFL in accuracy across all benchmarks, demonstrating a highly efficient and scalable solution for federated vision.

</details>


### [49] [Hierarchical clustering of complex energy systems using pretopology](https://arxiv.org/abs/2512.03069)
*Loup-Noe Levy,Jeremie Bosom,Guillaume Guerard,Soufian Ben Amor,Marc Bui,Hai Tran*

Main category: cs.LG

TL;DR: 本文提出了一种利用预拓扑和多准则层次分类算法对分布式区域内的建筑能耗剖面进行建模和分类的方法，以优化建筑能耗管理。


<details>
  <summary>Details</summary>
Motivation: 对大量建筑逐一进行深入审计耗费巨大，因此需要开发一种自动化的方法来建立相关且有效的推荐系统，以解决如何对大范围分布式区域的能耗剖面进行建模和分类并优化管理的问题。

Method: 文章采用预拓扑理论对站点能耗剖面进行建模，并开发了一种利用预拓扑空间特性的多准则层次分类算法，该算法已集成到Python库中。

Result: 在点数据集上，算法能根据点在空间中的位置和大小识别簇。在生成的时间序列上，算法能通过皮尔逊相关性识别时间序列簇，调整后的兰德指数（ARI）为1。

Conclusion: 本文提出的方法能够有效地对能耗剖面进行建模和分类，为优化建筑能耗管理提供了一种自动化的解决方案。

Abstract: This article attempts answering the following problematic: How to model and classify energy consumption profiles over a large distributed territory to optimize the management of buildings' consumption?
  Doing case-by-case in depth auditing of thousands of buildings would require a massive amount of time and money as well as a significant number of qualified people. Thus, an automated method must be developed to establish a relevant and effective recommendations system.
  To answer this problematic, pretopology is used to model the sites' consumption profiles and a multi-criterion hierarchical classification algorithm, using the properties of pretopological space, has been developed in a Python library.
  To evaluate the results, three data sets are used: A generated set of dots of various sizes in a 2D space, a generated set of time series and a set of consumption time series of 400 real consumption sites from a French Energy company.
  On the point data set, the algorithm is able to identify the clusters of points using their position in space and their size as parameter. On the generated time series, the algorithm is able to identify the time series clusters using Pearson's correlation with an Adjusted Rand Index (ARI) of 1.

</details>


### [50] [Breaking Determinism: Stochastic Modeling for Reliable Off-Policy Evaluation in Ad Auctions](https://arxiv.org/abs/2512.03354)
*Hongseon Yeom,Jaeyoul Shin,Soojin Min,Jeongmin Yoon,Seunghak Yu,Dongyeop Kang*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种在确定性拍卖环境中进行离线策略评估（OPE）的新方法，解决了传统OPE方法在广告拍卖中不适用的问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试在评估新的广告策略时会消耗大量的工程资源，并可能因部署表现不佳的变体而导致显著的收入损失。因此，作者希望能使用离策略评估（OPE）进行快速、离线的评估。

Method: 本文通过重新利用出价格局模型来近似倾向得分，从而为确定性拍卖中的OPE引入了第一个原则性框架。该模型能够推导出鲁棒的近似倾向得分，从而可以使用SNIPS（Self-Normalized Inverse Propensity Scoring）等稳定估计器进行反事实评估。

Result: 作者在AuctionNet模拟基准和来自大型工业平台的两周在线A/B测试中验证了他们的方法。结果显示，该方法与在线结果显著吻合，在CTR预测方面实现了92%的平均方向准确性（MDA），显著优于参数基线。

Conclusion: 这项工作提出了第一个实用且经过验证的框架，用于在确定性拍卖环境中进行可靠的OPE，为昂贵且有风险的在线实验提供了一种高效的替代方案。

Abstract: Online A/B testing, the gold standard for evaluating new advertising policies, consumes substantial engineering resources and risks significant revenue loss from deploying underperforming variations. This motivates the use of Off-Policy Evaluation (OPE) for rapid, offline assessment. However, applying OPE to ad auctions is fundamentally more challenging than in domains like recommender systems, where stochastic policies are common. In online ad auctions, it is common for the highest-bidding ad to win the impression, resulting in a deterministic, winner-takes-all setting. This results in zero probability of exposure for non-winning ads, rendering standard OPE estimators inapplicable. We introduce the first principled framework for OPE in deterministic auctions by repurposing the bid landscape model to approximate the propensity score. This model allows us to derive robust approximate propensity scores, enabling the use of stable estimators like Self-Normalized Inverse Propensity Scoring (SNIPS) for counterfactual evaluation. We validate our approach on the AuctionNet simulation benchmark and against 2-weeks online A/B test from a large-scale industrial platform. Our method shows remarkable alignment with online results, achieving a 92\% Mean Directional Accuracy (MDA) in CTR prediction, significantly outperforming the parametric baseline. MDA is the most critical metric for guiding deployment decisions, as it reflects the ability to correctly predict whether a new model will improve or harm performance. This work contributes the first practical and validated framework for reliable OPE in deterministic auction environments, offering an efficient alternative to costly and risky online experiments.

</details>


### [51] [Mixed Data Clustering Survey and Challenges](https://arxiv.org/abs/2512.03070)
*Guillaume Guerard,Sonia Djebali*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于预拓扑空间的混合数据聚类方法。


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，混合数据聚类是一个关键挑战，需要创新的方法来有效利用异构数据类型。传统的聚类技术难以处理混合数据引入的额外复杂性，因此需要专门针对这种情况的方法。分层和可解释的算法在这种背景下特别有价值，因为它们提供结构化、可解释的聚类结果，支持知情决策。

Method: 本文引入了一种基于预拓扑空间的聚类方法。

Result: 通过与经典数值聚类算法和现有预拓扑方法的基准测试，可以深入了解所提出方法在大数据范式中的性能和有效性。

Conclusion: 所提出的基于预拓扑空间的聚类方法能够有效处理混合数据，并在大数据范式下表现出良好的性能和有效性。

Abstract: The advent of the big data paradigm has transformed how industries manage and analyze information, ushering in an era of unprecedented data volume, velocity, and variety. Within this landscape, mixed-data clustering has become a critical challenge, requiring innovative methods that can effectively exploit heterogeneous data types, including numerical and categorical variables. Traditional clustering techniques, typically designed for homogeneous datasets, often struggle to capture the additional complexity introduced by mixed data, underscoring the need for approaches specifically tailored to this setting. Hierarchical and explainable algorithms are particularly valuable in this context, as they provide structured, interpretable clustering results that support informed decision-making. This paper introduces a clustering method grounded in pretopological spaces. In addition, benchmarking against classical numerical clustering algorithms and existing pretopological approaches yields insights into the performance and effectiveness of the proposed method within the big data paradigm.

</details>


### [52] [Tuning-Free Structured Sparse Recovery of Multiple Measurement Vectors using Implicit Regularization](https://arxiv.org/abs/2512.03393)
*Lakshmi Jayalal,Sheetal Kalyani*

Main category: cs.LG

TL;DR: 本文介绍了一种新颖的免调优框架，用于在多测量向量（MMV）设置中恢复联合稀疏信号，通过对过度参数化的隐式正则化，解决了传统方法需要大量参数调整的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的多测量向量正交匹配追踪（M-OMP）和多测量向量FOCal欠定系统求解器（M-FOCUSS）等方法在恢复联合稀疏信号时，需要仔细调整参数或预先知道信号的稀疏性或噪声方差。

Method: 该方法将估计矩阵重新参数化为解耦共享行支持和单个向量条目的因子。通过对这些因子的标准最小二乘目标应用梯度下降，优化过程固有地促进了所需的行稀疏结构。

Result: 在足够小且平衡的初始化条件下，优化动态表现出“动量效应”，使得真实支持中行的范数增长速度显著快于其他行。这正式保证了解决方案轨迹收敛到理想的行稀疏解决方案。

Conclusion: 该方法无需任何先验信息或调整，即可实现与传统方法相当的性能。

Abstract: Recovering jointly sparse signals in the multiple measurement vectors (MMV) setting is a fundamental problem in machine learning, but traditional methods like multiple measurement vectors orthogonal matching pursuit (M-OMP) and multiple measurement vectors FOCal Underdetermined System Solver (M-FOCUSS) often require careful parameter tuning or prior knowledge of the sparsity of the signal and/or noise variance. We introduce a novel tuning-free framework that leverages Implicit Regularization (IR) from overparameterization to overcome this limitation. Our approach reparameterizes the estimation matrix into factors that decouple the shared row-support from individual vector entries. We show that the optimization dynamics inherently promote the desired row-sparse structure by applying gradient descent to a standard least-squares objective on these factors. We prove that with a sufficiently small and balanced initialization, the optimization dynamics exhibit a "momentum-like" effect, causing the norms of rows in the true support to grow significantly faster than others. This formally guarantees that the solution trajectory converges towards an idealized row-sparse solution. Additionally, empirical results demonstrate that our approach achieves performance comparable to established methods without requiring any prior information or tuning.

</details>


### [53] [PretopoMD: Pretopology-based Mixed Data Hierarchical Clustering](https://arxiv.org/abs/2512.03071)
*Loup-Noe Levy,Guillaume Guerard,Sonia Djebali,Soufian Ben Amor*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的基于预拓扑的算法，旨在解决混合数据聚类的挑战，而无需降维。


<details>
  <summary>Details</summary>
Motivation: 解决混合数据聚类在不进行降维的情况下的挑战。

Method: 该方法利用析取范式，制定可定制的逻辑规则和可调整的超参数，以实现用户定义的层次聚类构建，并为异构数据集提供量身定制的解决方案。

Result: 通过层次聚类分析和比较聚类指标，该方法通过直接从原始数据准确且可解释地描绘聚类，展示了卓越的性能。实证结果突出显示了该算法在构建有意义的聚类方面的鲁棒性，并揭示了其在克服与聚类数据可解释性相关问题方面的潜力。

Conclusion: 这项 работы的新颖之处在于它摒弃了传统的降维技术，并创新性地使用逻辑规则来增强聚类形成和清晰度，从而为混合数据聚类的讨论做出了重大贡献。

Abstract: This article presents a novel pretopology-based algorithm designed to address the challenges of clustering mixed data without the need for dimensionality reduction. Leveraging Disjunctive Normal Form, our approach formulates customizable logical rules and adjustable hyperparameters that allow for user-defined hierarchical cluster construction and facilitate tailored solutions for heterogeneous datasets. Through hierarchical dendrogram analysis and comparative clustering metrics, our method demonstrates superior performance by accurately and interpretably delineating clusters directly from raw data, thus preserving data integrity. Empirical findings highlight the algorithm's robustness in constructing meaningful clusters and reveal its potential in overcoming issues related to clustered data explainability. The novelty of this work lies in its departure from traditional dimensionality reduction techniques and its innovative use of logical rules that enhance both cluster formation and clarity, thereby contributing a significant advancement to the discourse on clustering mixed data.

</details>


### [54] [GaussDetect-LiNGAM:Causal Direction Identification without Gaussianity test](https://arxiv.org/abs/2512.03428)
*Ziyi Ding,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: GaussDetect-LiNGAM是一种新颖的双变量因果发现方法，它利用逆回归中噪声高斯性与残差独立性之间的基本等价关系，无需明确的高斯性检验。


<details>
  <summary>Details</summary>
Motivation: 在标准的LiNGAM假设下，证明正向模型噪声的高斯性等价于逆模型中回归变量与残差之间的独立性，从而无需进行高斯性检验。

Method: 以核函数为基础的独立性检验来替代了脆弱且对样本敏感的高斯性检验。

Result: 实验结果验证了这一等价性，并表明GaussDetect-LiNGAM在不同噪声类型和样本大小下保持了高一致性，同时减少了每次决策所需的测试次数。

Conclusion: 该方法提高了因果推断的效率和实用性，使LiNGAM在实际应用中更易于使用和更可靠。

Abstract: We propose GaussDetect-LiNGAM, a novel approach for bivariate causal discovery that eliminates the need for explicit Gaussianity tests by leveraging a fundamental equivalence between noise Gaussianity and residual independence in the reverse regression. Under the standard LiNGAM assumptions of linearity, acyclicity, and exogeneity, we prove that the Gaussianity of the forward-model noise is equivalent to the independence between the regressor and residual in the reverse model. This theoretical insight allows us to replace fragile and sample-sensitive Gaussianity tests with robust kernel-based independence tests. Experimental results validate the equivalence and demonstrate that GaussDetect-LiNGAM maintains high consistency across diverse noise types and sample sizes, while reducing the number of tests per decision (TPD). Our method enhances both the efficiency and practical applicability of causal inference, making LiNGAM more accessible and reliable in real-world scenarios.

</details>


### [55] [Parameter-Efficient Augment Plugin for Class-Incremental Learning](https://arxiv.org/abs/2512.03537)
*Zhiming Xu,Baile Xu,Jian Zhao,Furao Shen,Suorong Yang*

Main category: cs.LG

TL;DR: 论文提出了一种名为DLC（Deployment of extra LoRA Components）的插件扩展范式，用于非预训练的类增量学习（CIL）场景，通过LoRA技术提高准确性并解决遗忘问题，同时保持参数高效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于重放或知识蒸馏的类增量学习（CIL）方法受到遗忘或稳定性-可塑性两难困境的限制。一些基于扩展的方法虽然能达到更高的准确性，但需要显著增加参数。

Method: 该方法将通过重放或蒸馏训练的特征提取器视为具有丰富知识的基础模型。对于每个任务，使用低秩适应（LoRA）将任务特定的残差注入到基础模型的深层中。在推理阶段，通过聚合具有任务特定残差的表示来生成分类预测。为了减轻非目标LoRA插件的干扰，引入了一个轻量级加权单元，学习为不同的LoRA调整表示分配重要性分数。

Result: 在大型ImageNet-100数据集上，DLC模型仅使用标准ResNet-18的4%参数，就实现了显著的8%准确率提升，展示了卓越的效率。此外，在固定内存预算下，该方法超越了SOTA方法。

Conclusion: DLC作为一种可插拔的增强方法，有效扩展了基础方法，在保持参数高效性的同时显著提高了类增量学习的准确性，并能有效缓解遗忘问题。

Abstract: Existing class-incremental learning (CIL) approaches based on replay or knowledge distillation are often constrained by forgetting or the stability-plasticity dilemma. Some expansion-based approaches could achieve higher accuracy. However, they always require significant parameter increases. In this paper, we propose a plugin extension paradigm termed the Deployment of extra LoRA Components (DLC) for non-pre-trained CIL scenarios.We treat the feature extractor trained through replay or distillation as a base model with rich knowledge. For each task, we use Low-Rank Adaptation (LoRA) to inject task-specific residuals into the base model's deep layers. During inference, representations with task-specific residuals are aggregated to produce classification predictions. To mitigate interference from non-target LoRA plugins, we introduce a lightweight weighting unit. This unit learns to assign importance scores to different LoRA-tuned representations. Like downloadable contents in software, our method serves as a plug-and-play enhancement that efficiently extends the base methods. Remarkably, on the large-scale ImageNet-100, with merely 4 % of the parameters of a standard ResNet-18, our DLC model achieves a significant 8 % improvement in accuracy, demonstrating exceptional efficiency. Moreover, it could surpass state-of-the-art methods under the fixed memory budget.

</details>


### [56] [Risk-Entropic Flow Matching](https://arxiv.org/abs/2512.03078)
*Vahid R. Ramezani,Benjamin Englard*

Main category: cs.LG

TL;DR: 本文探讨了倾斜风险在Flow Matching（FM）中的应用，通过对条件FM损失进行对数指数变换，得到倾斜风险损失，该损失是条件熵FM目标的上界，并通过实验证明了其在几何结构恢复方面的优越性。


<details>
  <summary>Details</summary>
Motivation: Flow Matching (FM) 是一种通过学习速度场来输送样本从源分布到数据的技术。然而，标准的FM在处理高阶条件信息（如方差、偏度、多模态）时存在局限性，导致对数据歧管的精细几何结构和少数分支的忽视。

Method: 本文将标准的风险敏感（对数指数）变换应用于条件FM损失，得到倾斜风险损失。该损失是定义在每个时空点上的有意义的条件熵FM目标的自然上界。此外，该方法还推导了条件熵目标梯度的小阶展开，得到了两个可解释的一阶校正：FM残差的协方差预处理和有利于非对称或稀有分支的偏斜尾部项。

Result: 在旨在探测模糊性和尾部的合成数据上，所提出的风险敏感损失改进了统计指标，并比标准修正FM更忠实地恢复了几何结构。

Conclusion: 倾斜风险在Flow Matching中能够有效地强调罕见或高损失事件，克服了标准FM在捕捉高阶条件信息方面的不足，从而更忠实地恢复数据流的几何结构和少数分支。

Abstract: Tilted (entropic) risk, obtained by applying a log-exponential transform to a base loss, is a well established tool in statistics and machine learning for emphasizing rare or high loss events while retaining a tractable optimization problem. In this work, our aim is to interpret its structure for Flow Matching (FM). FM learns a velocity field that transports samples from a simple source distribution to data by integrating an ODE. In rectified FM, training pairs are obtained by linearly interpolating between a source sample and a data sample, and a neural velocity field is trained to predict the straight line displacement using a mean squared error loss. This squared loss collapses all velocity targets that reach the same space-time point into a single conditional mean, thereby ignoring higher order conditional information (variance, skewness, multi-modality) that encodes fine geometric structure about the data manifold and minority branches. We apply the standard risk-sensitive (log-exponential) transform to the conditional FM loss and show that the resulting tilted risk loss is a natural upper-bound on a meaningful conditional entropic FM objective defined at each space-time point. Furthermore, we show that a small order expansion of the gradient of this conditional entropic objective yields two interpretable first order corrections: covariance preconditioning of the FM residual, and a skew tail term that favors asymmetric or rare branches. On synthetic data designed to probe ambiguity and tails, the resulting risk-sensitive loss improves statistical metrics and recovers geometric structure more faithfully than standard rectified FM.

</details>


### [57] [Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction](https://arxiv.org/abs/2512.03899)
*Janis Keck,Lukas Silvester Barth,Fatemeh,Fahimi,Parvaneh Joharinad,Jürgen Jost*

Main category: cs.LG

TL;DR: 本文介绍了一个将模糊单纯集解释为单纯集上概率测度的边缘的框架，特别是，该框架表明 UMAP 的模糊权重来自于以随机尺度采样 Vietoris-Rips 过滤的生成模型，从而产生成对距离的累积分布函数。


<details>
  <summary>Details</summary>
Motivation: 目前，模糊单纯集在降维和流形学习中引起了广泛关注，其最显著的应用是 UMAP。然而，它们通过代数拓扑工具进行的定义缺乏明确的概率解释，这使得它们与这些领域中常用的理论框架脱节。

Method: 本文引入了一个框架，将模糊单纯集解释为单纯集上概率测度的边缘。具体来说，该方法表明 UMAP 中的模糊权重来源于一个生成模型，该模型以随机尺度采样 Vietoris-Rips 过滤，从而产生成对距离的累积分布函数。更一般地，该框架将模糊单纯集与面偏序集上的概率模型联系起来，阐明了在此设置中 Kullback-Leibler 散度和模糊交叉熵之间的关系，并通过底层单纯集上的布尔运算恢复了标准 t-范数和 t-合范数。

Result: 通过这个框架显示了如何推导出新的嵌入方法，并在一个示例中说明了这一点，在该示例中，我们使用带有三元组采样的 Čech 过滤推广了 UMAP。

Conclusion: 这种概率视角为模糊单纯集提供了一个统一的概率理论基础，阐明了 UMAP 在此框架中的作用，并能够系统地推导出新的降维方法。

Abstract: Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Čech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.

</details>


### [58] [ALARM: Automated MLLM-Based Anomaly Detection in Complex-EnviRonment Monitoring with Uncertainty Quantification](https://arxiv.org/abs/2512.03101)
*Congjing Zhang,Feng Lin,Xinyi Zhao,Pei Guo,Wei Li,Lin Chen,Chaoyue Zhao,Shuai Huang*

Main category: cs.LG

TL;DR: 该文章介绍了一个名为 ALARM 的 MLLM-based 视觉异常检测框架，该框架通过结合不确定性量化（UQ）和质量保证技术，在复杂环境中实现了鲁棒和准确的异常检测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的进步推动了基于多模态 LLM（MLLM）的视觉异常检测（VAD）算法的研究兴趣，这些算法可以部署在复杂环境中。在这些复杂环境中，异常有时具有高度上下文性和模糊性，因此，不确定性量化（UQ）是基于 MLLM 的 VAD 系统成功的关键能力。

Method: 我们引入了名为 ALARM 的 UQ 支持的 MLLM-based VAD 框架。 ALARM 将 UQ 与推理链、自我反思和 MLLM 集成等质量保证技术相结合，以实现鲁棒和准确的性能，它基于严格的概率推理管道和计算过程进行设计。

Result: 通过真实世界的智能家居基准数据和伤口图像分类数据进行的广泛实证评估表明，ALARM 具有卓越的性能和在不同领域中的通用适用性，可用于可靠的决策。

Conclusion: ALARM 是一个将不确定性量化与多模态大型语言模型相结合的视觉异常检测框架，它在复杂多变的实际场景下表现优异，具备很强的通用性，能够为不同的应用领域提供可靠的决策支持。

Abstract: The advance of Large Language Models (LLMs) has greatly stimulated research interest in developing multi-modal LLM (MLLM)-based visual anomaly detection (VAD) algorithms that can be deployed in complex environments. The challenge is that in these complex environments, the anomalies are sometimes highly contextual and also ambiguous, and thereby, uncertainty quantification (UQ) is a crucial capacity for an MLLM-based VAD system to succeed. In this paper, we introduce our UQ-supported MLLM-based VAD framework called ALARM. ALARM integrates UQ with quality-assurance techniques like reasoning chain, self-reflection, and MLLM ensemble for robust and accurate performance and is designed based on a rigorous probabilistic inference pipeline and computational process. Extensive empirical evaluations are conducted using the real-world smart-home benchmark data and wound image classification data, which shows ALARM's superior performance and its generic applicability across different domains for reliable decision-making.

</details>


### [59] [Mitigating Intra- and Inter-modal Forgetting in Continual Learning of Unified Multimodal Models](https://arxiv.org/abs/2512.03125)
*Xiwen Wei,Mustafa Munir,Radu Marculescu*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为MoDE的轻量级架构，通过解耦模态和知识蒸馏来解决统一多模态生成模型（UMGMs）中存在的模态内和模态间灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 统一多模态生成模型（UMGMs）在连续学习新任务时，会受到模态内和模态间灾难性遗忘的严重影响。以往的研究关注模态内遗忘，但模态间遗忘仍未被充分探索。

Method: 本文识别并验证了UMGMs中模态间遗忘现象，并提供了基于模态间梯度冲突的理论解释。为解决模态内和模态间遗忘，提出了Modality-Decoupled Experts (MoDE) 架构，该架构通过隔离模态特定更新来缓解梯度冲突，并利用知识蒸馏来防止灾难性遗忘和保留预训练能力。

Result: MoDE在多个基准测试中显著减轻了模态内和模态间遗忘，优于以前的连续学习基线方法。

Conclusion: MoDE通过显式解耦模态来防止干扰，有效解决了UMGMs中的灾难性遗忘问题，在统一多模态生成设置中表现出色。

Abstract: Unified Multimodal Generative Models (UMGMs) unify visual understanding and image generation within a single autoregressive framework. However, their ability to continually learn new tasks is severely hindered by catastrophic forgetting, both within a modality (intra-modal) and across modalities (inter-modal). While intra-modal forgetting has been studied in prior continual learning (CL) work, inter-modal forgetting remains largely unexplored. In this paper, we identify and empirically validate this phenomenon in UMGMs and provide a theoretical explanation rooted in gradient conflict between modalities. To address both intra- and inter-modal forgetting, we propose Modality-Decoupled Experts (MoDE), a lightweight and scalable architecture that isolates modality-specific updates to mitigate the gradient conflict and leverages knowledge distillation to prevent catastrophic forgetting and preserve pre-trained capabilities. Unlike previous CL methods that remain modality-coupled and suffer from modality gradient conflict, MoDE explicitly decouples modalities to prevent interference. Experiments across diverse benchmarks demonstrate that MoDE significantly mitigates both inter- and intra-modal forgetting, outperforming prior CL baselines in unified multimodal generation settings. Codes will be publicly available: https://github.com/Christina200/MoDE-official.git

</details>


### [60] [Atomic Diffusion Models for Small Molecule Structure Elucidation from NMR Spectra](https://arxiv.org/abs/2512.03127)
*Ziyu Xiong,Yichi Zhang,Foyez Alauddin,Chu Xin Cheng,Joon Soo An,Mohammad R. Seyedsayamdost,Ellen D. Zhong*

Main category: cs.LG

TL;DR: ChefNMR是一个端到端框架，它能仅通过一维核磁共振谱和化学式直接预测未知分子的结构。


<details>
  <summary>Details</summary>
Motivation: 核磁共振（NMR）光谱分析是确定小分子结构的关键技术，尤其在发现新型天然产物和临床治疗药物方面至关重要。然而，解释核磁共振谱图仍然是一个耗时、需要大量专业知识的人工过程。

Method: ChefNMR将结构解析视为基于非等变Transformer架构的原子扩散模型的条件生成问题。为了模拟天然产物中发现的复杂化学基团，我们生成了一个包含超过111,000种天然产物的模拟一维核磁共振谱数据集。

Result: ChefNMR预测挑战性天然产物化合物结构的准确率超过65%。

Conclusion: 这项工作在自动化小分子结构解析的巨大挑战上迈出了重要一步，并凸显了深度学习在加速分子发现方面的潜力。

Abstract: Nuclear Magnetic Resonance (NMR) spectroscopy is a cornerstone technique for determining the structures of small molecules and is especially critical in the discovery of novel natural products and clinical therapeutics. Yet, interpreting NMR spectra remains a time-consuming, manual process requiring extensive domain expertise. We introduce ChefNMR (CHemical Elucidation From NMR), an end-to-end framework that directly predicts an unknown molecule's structure solely from its 1D NMR spectra and chemical formula. We frame structure elucidation as conditional generation from an atomic diffusion model built on a non-equivariant transformer architecture. To model the complex chemical groups found in natural products, we generated a dataset of simulated 1D NMR spectra for over 111,000 natural products. ChefNMR predicts the structures of challenging natural product compounds with an unsurpassed accuracy of over 65%. This work takes a significant step toward solving the grand challenge of automating small-molecule structure elucidation and highlights the potential of deep learning in accelerating molecular discovery. Code is available at https://github.com/ml-struct-bio/chefnmr.

</details>


### [61] [Contrastive Deep Learning for Variant Detection in Wastewater Genomic Sequencing](https://arxiv.org/abs/2512.03158)
*Adele Chinda,Richmond Azumah,Hemanth Demakethepalli Venkateswara*

Main category: cs.LG

TL;DR: 这篇论文提出了一种使用VQ-VAE的无监督病毒变异检测框架，用于废水基因组监测。该框架不需要参考基因组或变异标签，能够有效处理高测序噪声、低病毒覆盖率和碎片化读取等挑战。


<details>
  <summary>Details</summary>
Motivation: 废水基因组监测在病毒监测方面具有强大潜力，但面临高测序噪声、低病毒覆盖率、碎片化读取以及缺乏变异标签等计算挑战。传统的参考变异识别流程难以处理新突变且需要大量计算资源。

Method: 本研究提出了一种基于VQ-VAE的无监督病毒变异检测框架。该框架将经过k-mer分词的序列作为输入，学习基因组模式的离散码本，并且不需要参考基因组或变异标签。该方法通过掩码重建预训练来增强对缺失数据的鲁棒性，并通过对比学习获得高区分度的嵌入。

Result: 在包含约100,000条SARS-CoV-2废水测序数据上进行评估，VQ-VAE模型达到了99.52%的平均token级别准确率和56.33%的精确序列匹配率，同时保持了19.73%的码本利用率。对比微调在不同投影维度下显著改善了聚类效果：64维嵌入的Silhouette分数提高了35%（从0.31到0.42），而128维嵌入提高了42%（从0.31到0.44），这表明嵌入维度对变异区分能力有显著影响。

Conclusion: 所提出的无参考框架为基因组监测提供了一种可扩展、可解释的方法，可直接应用于公共卫生监测。

Abstract: Wastewater-based genomic surveillance has emerged as a powerful tool for population-level viral monitoring, offering comprehensive insights into circulating viral variants across entire communities. However, this approach faces significant computational challenges stemming from high sequencing noise, low viral coverage, fragmented reads, and the complete absence of labeled variant annotations. Traditional reference-based variant calling pipelines struggle with novel mutations and require extensive computational resources. We present a comprehensive framework for unsupervised viral variant detection using Vector-Quantized Variational Autoencoders (VQ-VAE) that learns discrete codebooks of genomic patterns from k-mer tokenized sequences without requiring reference genomes or variant labels. Our approach extends the base VQ-VAE architecture with masked reconstruction pretraining for robustness to missing data and contrastive learning for highly discriminative embeddings. Evaluated on SARS-CoV-2 wastewater sequencing data comprising approximately 100,000 reads, our VQ-VAE achieves 99.52% mean token-level accuracy and 56.33% exact sequence match rate while maintaining 19.73% codebook utilization (101 of 512 codes active), demonstrating efficient discrete representation learning. Contrastive fine-tuning with different projection dimensions yields substantial clustering improvements: 64-dimensional embeddings achieve +35% Silhouette score improvement (0.31 to 0.42), while 128-dimensional embeddings achieve +42% improvement (0.31 to 0.44), clearly demonstrating the impact of embedding dimensionality on variant discrimination capability. Our reference-free framework provides a scalable, interpretable approach to genomic surveillance with direct applications to public health monitoring.

</details>


### [62] [Plantain: Plan-Answer Interleaved Reasoning](https://arxiv.org/abs/2512.03176)
*Anthony Liang,Jonathan Berant,Adam Fisch,Abhimanyu Goyal,Kalpesh Krishna,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 本文提出了一种名为交错推理（IR）的新范式，旨在解决推理模型在生成最终答案之前不提供中间反馈的问题。IR通过在思考和呈现中间响应之间交替进行，减少了用户感知的延迟，同时又不损害最终响应的质量。特别地，Plantain（即“计划-思考-回答交错”）作为IR的一种特殊形式，首先提供一个详细的计划，允许用户在早期阶段进行干预和反馈，从而在各种数学推理和编码基准测试中，将pass@1性能提高了约6%，并将首次响应时间缩短了60%以上。


<details>
  <summary>Details</summary>
Motivation: 现有的推理模型在生成最终答案前会进行大量思考，但在此期间不向用户提供任何反馈，导致用户无法判断模型推理过程是否正确，也无法及时纠正错误，从而浪费用户时间。作者受到人类交流中渐进式确认行为的启发，旨在探索语言模型是否也能采用类似的方式，通过提供中间反馈来提升用户体验。

Method: 本文提出了一种新的推理范式——交错推理（IR），它打破了传统的“先思考后回答”模式，转而在思考和呈现中间响应之间交替进行。作为IR的一个特例，Plantain（计划-思考-回答交错）被引入，其特点是首先生成一个详细的、分步执行任务的计划。这种“计划先行”的策略使得用户能够对后续的推理步骤进行干预并提供早期反馈。

Result: 交错推理（IR）减少了用户感知的延迟，即用户等待初始输出的时间，同时不影响最终响应的质量。Plantain在多个具有挑战性的数学推理和编码基准测试中，将pass@1的性能提高了约6%。与“先思考后回答”的基线模型相比，Plantain将首次响应时间（time-to-first-response）缩短了60%以上。

Conclusion: 交错推理（IR）及其特化形式Plantain通过在模型思考过程中提供中间反馈，显著改善了用户体验，减少了用户等待时间，并提高了推理任务的性能。特别是，Plantain的“计划先行”策略为用户提供了早期干预和纠正的机会，从而在数学推理和编码等复杂任务中展现出卓越的效率和准确性。这一研究为未来人机交互和语言模型设计开辟了新的方向。

Abstract: Reasoning models often spend a significant amount of time thinking before they generate a visible response. In the meantime, they do not give the user any hints as to whether their reasoning is on the right track, and do not give the user any recourse to stop and correct them if their reasoning is flawed. This creates a frustrating, but unfortunately common, experience: the user's time is wasted while the model reasons from a false premise that could have easily been corrected. In contrast, human speakers typically perform lightweight, incremental grounding acts to ensure that participants in the conversation are on the same page; here we ask if language models can learn to leverage a similar type of behavior? With this motivation, we propose interleaved reasoning (IR), in which the model alternates between thinking and surfacing intermediate responses, as an alternative to the standard "think-then-answer" approach. By providing useful information to the user earlier, IR reduces perceived latency, the time a user waits for an initial output, without compromising the quality of the final response. We further introduce a specialization of interleaved reasoning, Plantain (Plan-Thought-Answer Interleaving), where the first intermediate response is an explicit, step-by-step plan for executing the task. This plan-first strategy allows for user intervention and early feedback for subsequent reasoning steps. We demonstrate that Plantain yields an ~6% improvement in pass@1 across several challenging math reasoning and coding benchmarks, while reducing time-to-first-response by over 60% relative to think-then-answer baselines.

</details>


### [63] [Neighborhood density estimation using space-partitioning based hashing schemes](https://arxiv.org/abs/2512.03187)
*Aashi Jindal*

Main category: cs.LG

TL;DR: FiRE/FiRE.1 是一种用于在单细胞 RNA 测序数据中检测稀有细胞亚群的异常检测算法，Enhash 是一种用于流数据概念漂移检测的集成学习器。这两种方法在性能上均优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 开发用于单细胞 RNA 测序数据中稀有细胞亚群检测和流数据概念漂移检测的高效准确算法。

Method: FiRE/FiRE.1 是一种基于 sketching 的异常检测算法。 Enhash 是一种使用投影哈希的集成学习器。

Result: FiRE/FiRE.1 在单细胞 RNA 测序数据异常检测方面表现优异。 Enhash 在流数据概念漂移检测方面具有竞争力，并在时间和准确性方面表现出色。

Conclusion: FiRE/FiRE.1 和 Enhash 是在各自领域中性能卓越的新型算法，为单细胞 RNA 测序数据分析和流数据概念漂移检测提供了有效的解决方案。

Abstract: This work introduces FiRE/FiRE.1, a novel sketching-based algorithm for anomaly detection to quickly identify rare cell sub-populations in large-scale single-cell RNA sequencing data. This method demonstrated superior performance against state-of-the-art techniques. Furthermore, the thesis proposes Enhash, a fast and resource-efficient ensemble learner that uses projection hashing to detect concept drift in streaming data, proving highly competitive in time and accuracy across various drift types.

</details>


### [64] [Scaling Internal-State Policy-Gradient Methods for POMDPs](https://arxiv.org/abs/2512.03204)
*Douglas Aberdeen,Jonathan Baxter*

Main category: cs.LG

TL;DR: 本文提出并比较了几种改进算法，用于在无限 horizon 设置中学习具有记忆的策略，包括直接利用已知环境模型和通过模拟，并在大型 POMDPs（如嘈杂的机器人导航和多智能体问题）上进行了评估。


<details>
  <summary>Details</summary>
Motivation: 作者认为策略梯度方法在处理需要记忆的部分可观察环境中效果不佳，因此旨在开发改进的算法。

Method: 本文开发了在无限 horizon 设置中学习具有记忆策略的改进算法，分为两种情况：一是当环境的已知模型可用时直接学习，二是在模型不可知时通过模拟进行学习。

Result: 这些算法在一些大型部分可观察马尔可夫决策过程（POMDPs）上进行了比较，其中包括有噪声的机器人导航问题和多智能体问题。

Conclusion: 本文提出了比以往策略梯度方法更成功地处理需要记忆的部分可观察环境的算法。

Abstract: Policy-gradient methods have received increased attention recently as a mechanism for learning to act in partially observable environments. They have shown promise for problems admitting memoryless policies but have been less successful when memory is required. In this paper we develop several improved algorithms for learning policies with memory in an infinite-horizon setting -- directly when a known model of the environment is available, and via simulation otherwise. We compare these algorithms on some large POMDPs, including noisy robot navigation and multi-agent problems.

</details>


### [65] [Perch 2.0 transfers 'whale' to underwater tasks](https://arxiv.org/abs/2512.03219)
*Andrea Burns,Lauren Harrell,Bart van Merriënboer,Vincent Dumoulin,Jenny Hamer,Tom Denton*

Main category: cs.LG

TL;DR: Perch 2.0在海洋哺乳动物和水下音频任务中表现出强大的少样本迁移学习能力，优于其他生物声学模型。


<details>
  <summary>Details</summary>
Motivation: 评估Perch 2.0在缺乏海洋哺乳动物训练数据的情况下，其在海洋哺乳动物和水下音频任务上的性能。

Method: 通过少样本迁移学习对Perch 2.0进行线性探查，并将其性能与Perch 1.0、SurfPerch、AVES-bio、BirdAVES、Birdnet V2.3等其他预训练生物声学模型进行比较。

Result: Perch 2.0的嵌入在少样本迁移学习场景下始终表现出高性能，在大多数任务中都优于其他嵌入模型。

Conclusion: Perch 2.0模型适用于利用少量标注样本开发新的海洋哺乳动物分类线性分类器。

Abstract: Perch 2.0 is a supervised bioacoustics foundation model pretrained on 14,597 species, including birds, mammals, amphibians, and insects, and has state-of-the-art performance on multiple benchmarks. Given that Perch 2.0 includes almost no marine mammal audio or classes in the training data, we evaluate Perch 2.0 performance on marine mammal and underwater audio tasks through few-shot transfer learning. We perform linear probing with the embeddings generated from this foundation model and compare performance to other pretrained bioacoustics models. In particular, we compare Perch 2.0 with previous multispecies whale, Perch 1.0, SurfPerch, AVES-bio, BirdAVES, and Birdnet V2.3 models, which have open-source tools for transfer-learning and agile modeling. We show that the embeddings from the Perch 2.0 model have consistently high performance for few-shot transfer learning, generally outperforming alternative embedding models on the majority of tasks, and thus is recommended when developing new linear classifiers for marine mammal classification with few labeled examples.

</details>


### [66] [SPARK: Stepwise Process-Aware Rewards for Reference-Free Reinforcement Learning](https://arxiv.org/abs/2512.03244)
*Salman Rahman,Sruthi Gorantla,Arpit Gupta,Swastik Roy,Nanyun Peng,Yang Liu*

Main category: cs.LG

TL;DR: SPARK是一个三阶段框架：第一阶段，生成模型生成不同的解决方案，验证模型使用并行和顺序扩展对其进行评估。第二阶段，验证输出作为合成训练数据用于微调生成式过程奖励模型。第三阶段，将生成式PRM与思维链验证（PRM-CoT）作为数学推理RL实验中的奖励模型，并引入格式约束以防止奖励作弊。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需昂贵的步骤级标注或地面真实参考即可实现过程奖励模型（PRM）训练的方法，以克服当前PRM应用受限的问题。

Method: SPARK框架包括三个阶段：
1. **生成与验证**：生成模型产生多样化解决方案，验证模型使用并行（自洽性）和顺序（元批评）扩展进行评估。
2. **合成数据训练PRM**：利用第一阶段的验证输出作为合成训练数据，微调生成式过程奖励模型。
3. **RL中的PRM-CoT**：将微调后的生成式PRM与思维链验证（PRM-CoT）结合，在数学推理RL实验中作为奖励模型，并引入格式约束以防止奖励作弊。

Result: 1. 相比参考引导训练（66.4）和GPT-4o（61.9），SPARK在ProcessBench上实现了67.5的F1分数，表明其为过程奖励模型生成的训练数据优于地面真实结果监督。
2. 使用Qwen2.5-Math-7B，在六个数学推理基准测试中达到了47.4%的平均准确率，优于基于地面真实的RLVR（43.9%）。

Conclusion: SPARK框架实现了无需参考的强化学习训练，其性能超越了基于地面真实的方法，为缺乏可验证答案或可访问地面真实数据的领域开辟了新的可能性。

Abstract: Process reward models (PRMs) that provide dense, step-level feedback have shown promise for reinforcement learning, yet their adoption remains limited by the need for expensive step-level annotations or ground truth references. We propose SPARK: a three-stage framework where in the first stage a generator model produces diverse solutions and a verifier model evaluates them using parallel scaling (self-consistency) and sequential scaling (meta-critique). In the second stage, we use these verification outputs as synthetic training data to fine-tune generative process reward models, which subsequently serve as reward signals during training. We show that aggregating multiple independent verifications at the step level produces training data for process reward models that surpass ground-truth outcome supervision, achieving 67.5 F1 on ProcessBench (a benchmark for identifying erroneous steps in mathematical reasoning) compared to 66.4 for reference-guided training and 61.9 for GPT-4o. In the final stage, we apply our generative PRM with chain-of-thought verification (PRM-CoT) as the reward model in RL experiments on mathematical reasoning, and introduce format constraints to prevent reward hacking. Using Qwen2.5-Math-7B, we achieve 47.4% average accuracy across six mathematical reasoning benchmarks, outperforming ground-truth-based RLVR (43.9%). Our work enables reference-free RL training that exceeds ground-truth methods, opening new possibilities for domains lacking verifiable answers or accessible ground truth.

</details>


### [67] [Too Late to Recall: Explaining the Two-Hop Problem in Multimodal Knowledge Retrieval](https://arxiv.org/abs/2512.03276)
*Constantin Venhoff,Ashkan Khakzar,Sonia Joseph,Philip Torr,Neel Nanda*

Main category: cs.LG

TL;DR: 本文分析了视觉语言模型（VLMs）在事实回忆任务中相对于其大型语言模型（LLM）骨干的性能下降问题，并提出实体表示的早期解决对重新利用LLM现有事实回忆机制至关重要。


<details>
  <summary>Details</summary>
Motivation: 训练视觉语言模型旨在对齐视觉和文本表示，但许多VLMs在事实回忆性能上不如其LLM骨干，这引发了多模态微调如何有效扩展LLM现有机制以处理视觉输入的问题。

Method: 本文对14个具有不同架构、规模和训练设置的VLM在事实回忆任务上进行了基准测试，并与原始LLM骨干模型进行对比。通过归因修补、激活修补和探测等方法，分析了性能下降和高性能VLM的内部机制。

Result: 14个模型中有11个出现了事实回忆性能下降。性能下降的VLM难以利用LLM骨干的现有事实回忆回路，因为它们在计算中过晚地解决了视觉输入的实体表示问题。高性能VLM则能足够早地解决实体表示问题，从而重用现有事实回忆机制。

Conclusion: 实体表示的早期解决速度是决定VLM能否有效利用预先存在的LLM机制的关键。本文的研究通过机械分析揭示了多模态对齐中系统性失败的原因。

Abstract: Training vision language models (VLMs) aims to align visual representations from a vision encoder with the textual representations of a pretrained large language model (LLM). However, many VLMs exhibit reduced factual recall performance compared to their LLM backbones, raising the question of how effective multimodal fine-tuning is at extending existing mechanisms within the LLM to visual inputs. We argue that factual recall based on visual inputs requires VLMs to solve a two-hop problem: (1) forming entity representations from visual inputs, and (2) recalling associated factual knowledge based on these entity representations. By benchmarking 14 VLMs with various architectures (LLaVA, Native, Cross-Attention), sizes (7B-124B parameters), and training setups on factual recall tasks against their original LLM backbone models, we find that 11 of 14 models exhibit factual recall degradation. We select three models with high and two models with low performance degradation, and use attribution patching, activation patching, and probing to show that degraded VLMs struggle to use the existing factual recall circuit of their LLM backbone, because they resolve the first hop too late in the computation. In contrast, high-performing VLMs resolve entity representations early enough to reuse the existing factual recall mechanism. Finally, we demonstrate two methods to recover performance: patching entity representations from the LLM backbone into the VLM, and prompting with chain-of-thought reasoning. Our results highlight that the speed of early entity resolution critically determines how effective VLMs are in using preexisting LLM mechanisms. More broadly, our work illustrates how mechanistic analysis can explain and unveil systematic failures in multimodal alignment.

</details>


### [68] [Adaptive Regime-Switching Forecasts with Distribution-Free Uncertainty: Deep Switching State-Space Models Meet Conformal Prediction](https://arxiv.org/abs/2512.03298)
*Echo Diyun LU,Charles Findling,Marianne Clausel,Alessandro Leite,Wei Gong,Pierric Kersaudy*

Main category: cs.LG

TL;DR: 本文提出了一种结合深度切换状态空间模型和自适应共形推断 (ACI) 及其聚合变体 (AgACI) 的方法，用于解决非平稳时间序列中制度转换引起的预测不确定性问题，并在合成和真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在时间序列分析中，制度转换常常破坏时间序列的平稳性，使得校准不确定性与点精度同等重要。

Method: 本文通过将深度切换状态空间模型与自适应共形推断 (ACI) 及其聚合变体 (AgACI) 相结合，研究了用于制度转换预测的无分布不确定性。此外，本文还引入了一个统一的共形封装器，该封装器可以在强大的序列基线模型（包括 S4、MC-Dropout GRU、稀疏高斯过程和变点局部模型）之上使用，以在非平稳性和模型误指定的情况下，生成具有有限样本边际保证的在线预测区间。

Result: 在合成数据集和真实数据集上，经过共形化的预测器实现了接近标称的覆盖率，同时具有竞争性的准确性和普遍提高的区间效率。

Conclusion: 本文提出的方法能够有效处理非平稳时间序列中的制度转换导致的预测不确定性问题，并在保持较高预测准确性的同时，提供了有效的预测区间。

Abstract: Regime transitions routinely break stationarity in time series, making calibrated uncertainty as important as point accuracy. We study distribution-free uncertainty for regime-switching forecasting by coupling Deep Switching State Space Models with Adaptive Conformal Inference (ACI) and its aggregated variant (AgACI). We also introduce a unified conformal wrapper that sits atop strong sequence baselines including S4, MC-Dropout GRU, sparse Gaussian processes, and a change-point local model to produce online predictive bands with finite-sample marginal guarantees under nonstationarity and model misspecification. Across synthetic and real datasets, conformalized forecasters achieve near-nominal coverage with competitive accuracy and generally improved band efficiency.

</details>


### [69] [HydroDCM: Hydrological Domain-Conditioned Modulation for Cross-Reservoir Inflow Prediction](https://arxiv.org/abs/2512.03300)
*Pengfei Hu,Fan Ming,Xiaoxue Han,Chang Lu,Yue Ning,Dan Lu*

Main category: cs.LG

TL;DR: 该论文提出了HydroDCM，一个用于跨水库径流预测的可扩展领域泛化（DG）框架，通过结合空间元数据和对抗性学习来解决领域漂移问题，并在科罗拉多河上游盆地的30个真实世界水库中取得了优于现有DG基线的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在水库径流预测中表现出潜力，但由于领域漂移问题，在应用于不同水库时性能会下降。现有的领域泛化（DG）方法在水文环境中受限于每个水库独特的径流模式和空间元数据间接影响的挑战。

Method: HydroDCM利用水库的空间元数据构建伪领域标签，指导不变时间特征的对抗性学习。在推断阶段，通过目标水库元数据引导的轻量级条件层调整这些特征，以平衡DG的不变性与特定地点的适应性。

Result: 在科罗拉多河上游盆地30个真实世界水库上的实验结果表明，HydroDCM在多领域条件下显著优于最先进的DG基线方法，并且计算效率高。

Conclusion: HydroDCM通过结合空间元数据和对抗性学习，有效地解决了跨水库径流预测中的领域泛化问题，实现了在保持计算效率的同时，提升了模型在未见领域中的泛化能力和预测性能。

Abstract: Deep learning models have shown promise in reservoir inflow prediction, yet their performance often deteriorates when applied to different reservoirs due to distributional differences, referred to as the domain shift problem. Domain generalization (DG) solutions aim to address this issue by extracting domain-invariant representations that mitigate errors in unseen domains. However, in hydrological settings, each reservoir exhibits unique inflow patterns, while some metadata beyond observations like spatial information exerts indirect but significant influence. This mismatch limits the applicability of conventional DG techniques to many-domain hydrological systems. To overcome these challenges, we propose HydroDCM, a scalable DG framework for cross-reservoir inflow forecasting. Spatial metadata of reservoirs is used to construct pseudo-domain labels that guide adversarial learning of invariant temporal features. During inference, HydroDCM adapts these features through light-weight conditioning layers informed by the target reservoir's metadata, reconciling DG's invariance with location-specific adaptation. Experiment results on 30 real-world reservoirs in the Upper Colorado River Basin demonstrate that our method substantially outperforms state-of-the-art DG baselines under many-domain conditions and remains computationally efficient.

</details>


### [70] [Robust Tabular Foundation Models](https://arxiv.org/abs/2512.03307)
*Matthew Peroni,Franck Le,Vadim Sheinin*

Main category: cs.LG

TL;DR: 该论文介绍了一种通过对抗性训练提高表格基础模型（TFMs）性能的方法，通过生成对模型最具挑战性的合成数据集，从而将性能提升了6%。


<details>
  <summary>Details</summary>
Motivation: 表格基础模型（TFMs）在处理结构化数据方面表现出超越传统机器学习方法的巨大潜力。在合成数据集上预训练TFMs的能力，为设计能够鼓励理想模型属性的数据生成器提供了机会。以往的工作主要集中在为生成器设计高质量的先验，以提高整体预训练性能。

Method: 通过引入一个最优性差距度量，即TFM性能与通过XGBoost、CatBoost和Random Forests等强大基线估计的最佳可实现性能之间的差异，该论文提出了Robust Tabular Foundation Models（RTFM）。RTFM是一个模型无关的对抗性训练框架。

Result: RTFM应用于TabPFN V2分类器时，其基准性能得到了提升，在平均归一化AUC方面比原始TabPFN和其他基线算法提高了高达6%，而仅需要不到10万个额外的合成数据集。

Conclusion: 这些结果为仅使用合成数据对TFM进行有针对性的对抗性训练和微调提供了一个有前景的新方向。

Abstract: The development of tabular foundation models (TFMs) has accelerated in recent years, showing strong potential to outperform traditional ML methods for structured data. A key finding is that TFMs can be pretrained entirely on synthetic datasets, opening opportunities to design data generators that encourage desirable model properties. Prior work has mainly focused on crafting high-quality priors over generators to improve overall pretraining performance. Our insight is that parameterizing the generator distribution enables an adversarial robustness perspective: during training, we can adapt the generator to emphasize datasets that are particularly challenging for the model. We formalize this by introducing an optimality gap measure, given by the difference between TFM performance and the best achievable performance as estimated by strong baselines such as XGBoost, CatBoost, and Random Forests. Building on this idea, we propose Robust Tabular Foundation Models (RTFM), a model-agnostic adversarial training framework. Applied to the TabPFN V2 classifier, RTFM improves benchmark performance, with up to a 6% increase in mean normalized AUC over the original TabPFN and other baseline algorithms, while requiring less than 100k additional synthetic datasets. These results highlight a promising new direction for targeted adversarial training and fine-tuning of TFMs using synthetic data alone.

</details>


### [71] [VS-Graph: Scalable and Efficient Graph Classification Using Hyperdimensional Computing](https://arxiv.org/abs/2512.03394)
*Hamed Poursiami,Shay Snyder,Guojing Cong,Thomas Potok,Maryam Parsa*

Main category: cs.LG

TL;DR: VS-Graph 是一种高效的图学习框架，它在保持竞争性准确性的同时，大大加快了训练速度，并展示了在资源受限设备上的应用潜力。


<details>
  <summary>Details</summary>
Motivation: GNN在图分类任务中表现出色，但其计算成本高昂，限制了在大规模和资源受限设备上的应用。HDC虽然轻量，但性能通常不如GNN。因此，需要一种方法来弥合HDC效率与GNN表达能力之间的差距。

Method: VS-Graph 引入了尖峰扩散机制（Spike Diffusion）用于拓扑驱动的节点识别，以及关联消息传递（Associative Message Passing）机制用于多跳邻域聚合，所有操作都在高维向量空间中完成。该方法不依赖于基于梯度的优化或反向传播。

Result: VS-Graph 在标准基准测试（如MUTAG和DD）上比之前的HDC基线高出4-5%的准确率，并与现代GNNs的准确率相当。在某些数据集上，其性能甚至超过了GNN基线。训练速度提高了450倍。即使将超向量维度降低到D=128，VS-Graph仍能保持高准确性。

Conclusion: VS-Graph 成功地将HDC的效率与消息传递的表达能力结合起来，提供了一个无需梯度优化的、高性能且计算效率极高的图学习框架。它在准确性上与GNNs持平或超越，同时显著提高了训练速度，并展示了在边缘和神经形态硬件上部署的巨大潜力。

Abstract: Graph classification is a fundamental task in domains ranging from molecular property prediction to materials design. While graph neural networks (GNNs) achieve strong performance by learning expressive representations via message passing, they incur high computational costs, limiting their scalability and deployment on resource-constrained devices. Hyperdimensional Computing (HDC), also known as Vector Symbolic Architectures (VSA), offers a lightweight, brain-inspired alternative, yet existing HDC-based graph methods typically struggle to match the predictive performance of GNNs. In this work, we propose VS-Graph, a vector-symbolic graph learning framework that narrows the gap between the efficiency of HDC and the expressive power of message passing. VS-Graph introduces a Spike Diffusion mechanism for topology-driven node identification and an Associative Message Passing scheme for multi-hop neighborhood aggregation entirely within the high-dimensional vector space. Without gradient-based optimization or backpropagation, our method achieves competitive accuracy with modern GNNs, outperforming the prior HDC baseline by 4-5% on standard benchmarks such as MUTAG and DD. It also matches or exceeds the performance of the GNN baselines on several datasets while accelerating the training by a factor of up to 450x. Furthermore, VS-Graph maintains high accuracy even with the hypervector dimensionality reduced to D=128, demonstrating robustness under aggressive dimension compression and paving the way for ultra-efficient execution on edge and neuromorphic hardware.

</details>


### [72] [Full-Stack Alignment: Co-Aligning AI and Institutions with Thick Models of Value](https://arxiv.org/abs/2512.03399)
*Joe Edelman,Tan Zhi-Xuan,Ryan Lowe,Oliver Klingefjord,Vincent Wang-Mascianica,Matija Franklin,Ryan Othniel Kearns,Ellie Hain,Atrisha Sarkar,Michiel Bakker,Fazl Barez,David Duvenaud,Jakob Foerster,Iason Gabriel,Joseph Gubbels,Bryce Goodman,Andreas Haupt,Jobst Heitzig,Julian Jara-Ettinger,Atoosa Kasirzadeh,James Ravi Kirkpatrick,Andrew Koh,W. Bradley Knox,Philipp Koralus,Joel Lehman,Sydney Levine,Samuele Marro,Manon Revel,Toby Shorin,Morgan Sutherland,Michael Henry Tessler,Ivan Vendrov,James Wilken-Smith*

Main category: cs.LG

TL;DR: 本文探讨了AI系统与人类价值观对齐的问题，提出了“全栈对齐”的概念，并认为厚模型（thick models）对于有效表示和运用价值观至关重要。


<details>
  <summary>Details</summary>
Motivation: 作者认为，即使单个AI系统与其操作者的意图完美对齐，如果操作组织的价值观与社会其他部分不一致，仍然可能导致不良后果。因此，需要实现AI系统与塑造它们的机构与人类价值观的同步对齐。

Method: 作者提出“厚模型”来表示价值观，旨在区分持久性价值观和短暂偏好，模拟个人选择的社会嵌入性，并进行规范性推理。作者认为当前表示价值观的方法（如效用函数、偏好排序、非结构化文本）无法有效解决这些问题。

Result: 作者在五个领域展示了“厚模型”这种方法：AI价值管理、规范性智能体、双赢谈判系统、保义经济机制和民主管理机构。但摘要中没有提供这些领域具体的实验结果。

Conclusion: 为了使AI系统真正有益于社会，需要实现AI系统和相关机构与人类价值观的全面对齐。这需要开发更高级的价值观表示方法，即“厚模型”，来有效建模和运用价值观。

Abstract: Beneficial societal outcomes cannot be guaranteed by aligning individual AI systems with the intentions of their operators or users. Even an AI system that is perfectly aligned to the intentions of its operating organization can lead to bad outcomes if the goals of that organization are misaligned with those of other institutions and individuals. For this reason, we need full-stack alignment, the concurrent alignment of AI systems and the institutions that shape them with what people value. This can be done without imposing a particular vision of individual or collective flourishing. We argue that current approaches for representing values, such as utility functions, preference orderings, or unstructured text, struggle to address these and other issues effectively. They struggle to distinguish values from other signals, to support principled normative reasoning, and to model collective goods. We propose thick models of value will be needed. These structure the way values and norms are represented, enabling systems to distinguish enduring values from fleeting preferences, to model the social embedding of individual choices, and to reason normatively, applying values in new domains. We demonstrate this approach in five areas: AI value stewardship, normatively competent agents, win-win negotiation systems, meaning-preserving economic mechanisms, and democratic regulatory institutions.

</details>


### [73] [Better World Models Can Lead to Better Post-Training Performance](https://arxiv.org/abs/2512.03400)
*Prakhar Gupta,Henry Conklin,Sarah-Jane Leslie,Andrew Lee*

Main category: cs.LG

TL;DR: 本文研究了显式世界建模目标如何影响Transformer在不同训练阶段的内部表示和下游能力。


<details>
  <summary>Details</summary>
Motivation: 探索显式世界建模预训练如何影响模型的潜在表示，以及世界模型质量如何影响强化学习后训练后的模型性能。

Method: 本文比较了标准的下一个token预测与两种显式世界建模策略，包括状态预测预训练以及状态预测和下一个token的联合目标，并在应用GRPO后评估了任务性能。此外，本文还通过线性探测和因果干预评估了表示质量。

Result: 显式世界建模产生了更具线性可解码和因果可控的状态表示。这些改进的状态表示可以为GRPO带来更高的收益，尤其是在处理更难的立方体状态时。

Conclusion: 锐化状态表示可以提高序列规划任务后训练的有效性。

Abstract: In this work we study how explicit world-modeling objectives affect the internal representations and downstream capability of Transformers across different training stages. We use a controlled 2x2x2 Rubik's Cube and ask: (1) how does explicitly pretraining a world model affect the model's latent representations, and (2) how does world-model quality affect the model's performance after reinforcement learning post-training? We compare standard next-token prediction to two explicit world-modeling strategies -- (i) state-prediction pretraining and (ii) a joint state-prediction + next-token objective -- and assess task performance after Group Relative Policy Optimization (GRPO) is applied as post-training. We evaluate the representation quality with linear probes and causal interventions. We find that explicit world-modeling yields more linearly decodable and causally steerable state representations. More importantly, we find that improved state representations lead to higher gains for GRPO, especially on harder cube states. Our results indicate that sharpening state representations can improve the effectiveness of post-training for sequence-planning tasks.

</details>


### [74] [Grokked Models are Better Unlearners](https://arxiv.org/abs/2512.03437)
*Yuanbang Liang,Yang Li*

Main category: cs.LG

TL;DR: 本文探讨了Grokking训练机制如何影响机器遗忘，发现经过Grokking训练后的模型在遗忘效率、附带损害和稳定性方面均优于早期停止的模型，这可能与更模块化的表示学习有关。


<details>
  <summary>Details</summary>
Motivation: Grokking-延迟泛化现象在模型完全拟合训练数据后出现，已被认为与鲁棒性和表示质量相关。本文旨在探讨这种训练机制是否也有助于机器遗忘，即在不完全重新训练的情况下，消除特定数据的影响。

Method: 本文比较了在Grokking过渡之前和之后应用标准遗忘方法的效果。实验涵盖视觉任务（在CIFAR、SVHN和ImageNet上使用CNNs/ResNets）和语言任务（在TOFU风格设置上使用Transformer）。

Result: 从Grokking后的检查点开始进行遗忘操作，始终能带来更高效的遗忘（达到目标遗忘水平所需的更新次数更少）、更小的附带损害（在保留数据和测试性能上的下降更小）以及更稳定的更新（跨不同随机种子），相较于在相同遗忘算法下早期停止的模型。 对特征和曲率的分析进一步表明，Grokking后的模型学习到了更模块化的表示，并且遗忘和保留子集之间的梯度对齐减少，这有助于选择性遗忘。

Conclusion: 本文结果表明，模型训练的时机（Grokking之前或之后）是一个与遗忘方法正交的杠杆，为改进现有遗忘方法提供了一个实用的方案，而无需改变其算法。

Abstract: Grokking-delayed generalization that emerges well after a model has fit the training data-has been linked to robustness and representation quality. We ask whether this training regime also helps with machine unlearning, i.e., removing the influence of specified data without full retraining. We compare applying standard unlearning methods before versus after the grokking transition across vision (CNNs/ResNets on CIFAR, SVHN, and ImageNet) and language (a transformer on a TOFU-style setup). Starting from grokked checkpoints consistently yields (i) more efficient forgetting (fewer updates to reach a target forget level), (ii) less collateral damage (smaller drops on retained and test performance), and (iii) more stable updates across seeds, relative to early-stopped counterparts under identical unlearning algorithms. Analyses of features and curvature further suggest that post-grokking models learn more modular representations with reduced gradient alignment between forget and retain subsets, which facilitates selective forgetting. Our results highlight when a model is trained (pre- vs. post-grokking) as an orthogonal lever to how unlearning is performed, providing a practical recipe to improve existing unlearning methods without altering their algorithms.

</details>


### [75] [Multi-Modal Opinion Integration for Financial Sentiment Analysis using Cross-Modal Attention](https://arxiv.org/abs/2512.03464)
*Yujing Liu,Chen Yang*

Main category: cs.LG

TL;DR: 该论文提出了一个端到端深度学习框架，通过新颖的跨模态注意力机制整合金融意见的近时性模态和流行性模态，以进行金融情感分析。模型利用BERT和新提出的FMHCA结构，实现了83.5%的准确率，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效整合多样化的意见模态并捕获它们之间的细粒度交互，这促使作者提出一种新的框架来解决金融情感分析中近时性和流行性两种模态的整合问题。

Method: 模型首先使用BERT（Chinese-wwm-ext）进行特征嵌入，然后采用新颖的金融多头跨注意力（FMHCA）结构来促进近时性模态（及时意见）和流行性模态（趋势意见）之间的信息交换。最后，通过Transformer层优化处理后的特征，并使用多模态因子双线性池化进行融合，以对负面、中性和积极情感进行分类。

Result: 在包含837家公司的综合数据集上进行的广泛实验表明，该方法实现了83.5%的准确率，显著优于包括BERT+Transformer在内的基线模型21个百分点。

Conclusion: 该框架有潜力支持更 B准确的金融决策和风险管理，因为它能有效整合不同的意见模态并捕获它们之间的细粒度交互。

Abstract: In recent years, financial sentiment analysis of public opinion has become increasingly important for market forecasting and risk assessment. However, existing methods often struggle to effectively integrate diverse opinion modalities and capture fine-grained interactions across them. This paper proposes an end-to-end deep learning framework that integrates two distinct modalities of financial opinions: recency modality (timely opinions) and popularity modality (trending opinions), through a novel cross-modal attention mechanism specifically designed for financial sentiment analysis. While both modalities consist of textual data, they represent fundamentally different information channels: recency-driven market updates versus popularity-driven collective sentiment. Our model first uses BERT (Chinese-wwm-ext) for feature embedding and then employs our proposed Financial Multi-Head Cross-Attention (FMHCA) structure to facilitate information exchange between these distinct opinion modalities. The processed features are optimized through a transformer layer and fused using multimodal factored bilinear pooling for classification into negative, neutral, and positive sentiment. Extensive experiments on a comprehensive dataset covering 837 companies demonstrate that our approach achieves an accuracy of 83.5%, significantly outperforming baselines including BERT+Transformer by 21 percent. These results highlight the potential of our framework to support more accurate financial decision-making and risk management.

</details>


### [76] [Bayesian Event-Based Model for Disease Subtype and Stage Inference](https://arxiv.org/abs/2512.03467)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 这篇论文提出了一个新的贝叶斯亚型变异事件模型（BEBMS），并将其与Subtype and Stage Inference Event-Based Model (SuStaIn) 在合成数据和真实世界阿尔茨海默病数据集上进行比较，结果显示BEBMS在排序、分期和亚型分配任务上均优于SuStaIn。


<details>
  <summary>Details</summary>
Motivation: 现有的疾病亚型识别模型（如SuStaIn）在识别慢性疾病的亚型和疾病进展顺序方面表现良好，但其性能的稳健性有待检验。为了更准确地捕捉疾病进展的结构化异质性，需要开发更稳健、性能更好的模型。

Method: 本文提出了一种原则性的贝叶斯亚型变异事件模型（BEBMS）。通过多种合成数据实验，在不同程度的模型错误指定下，将BEBMS的性能与SuStaIn进行了比较。此外，还将BEBMS和SuStaIn应用于真实的阿尔茨海默病数据集。

Result: BEBMS在排序、分期和亚型分配任务上均显著优于SuStaIn。在真实的阿尔茨海默病数据集中，BEBMS得出的结果与阿尔茨海默病进展的科学共识更为一致。

Conclusion: 原则性的贝叶斯亚型变异事件模型（BEBMS）在识别疾病亚型和疾病进展顺序方面表现出比SuStaIn更强的稳健性和更优的性能，尤其是在模型存在错误指定的情况下。BEBMS对理解复杂疾病的异质性进展具有重要意义。

Abstract: Chronic diseases often progress differently across patients. Rather than randomly varying, there are typically a small number of subtypes for how a disease progresses across patients. To capture this structured heterogeneity, the Subtype and Stage Inference Event-Based Model (SuStaIn) estimates the number of subtypes, the order of disease progression for each subtype, and assigns each patient to a subtype from primarily cross-sectional data. It has been widely applied to uncover the subtypes of many diseases and inform our understanding of them. But how robust is its performance? In this paper, we develop a principled Bayesian subtype variant of the event-based model (BEBMS) and compare its performance to SuStaIn in a variety of synthetic data experiments with varied levels of model misspecification. BEBMS substantially outperforms SuStaIn across ordering, staging, and subtype assignment tasks. Further, we apply BEBMS and SuStaIn to a real-world Alzheimer's data set. We find BEBMS has results that are more consistent with the scientific consensus of Alzheimer's disease progression than SuStaIn.

</details>


### [77] [Joint Progression Modeling (JPM): A Probabilistic Framework for Mixed-Pathology Progression](https://arxiv.org/abs/2512.03475)
*Hongtao Hao,Joseph L. Austerweil*

Main category: cs.LG

TL;DR: 该文章介绍了一种名为联合进展模型（JPM）的概率框架，用于从横断面数据中推断疾病进展，并通过对联合进展的先验处理，解决了标准事件模型（EBMs）无法处理混合病理的问题。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够处理混合病理的疾病进展模型，因为标准事件模型（EBMs）假设每个个体只有单一的基础疾病，而神经退行性疾病中混合病理很常见。

Method: 文章引入了联合进展模型（JPM），这是一个概率框架，将单一疾病轨迹视为部分排序，并为联合进展建立先验。研究了几种JPM变体（Pairwise, Bradley-Terry, Plackett-Luce和Mallows），并分析了三个特性：校准性、分离性和锐度。

Result: 所有JPM变体都经过校准，并且都实现了近乎完美的分离；锐度因变体而异，并且可以通过输入部分排序的简单特征（排序的数量和长度、冲突和重叠）很好地预测。在合成实验中，JPM的排序准确性比强大的EBM基线（SA-EBM）提高了大约21%。使用NACC数据，JPM的Mallows变体和基线模型（SA-EBM）的结果与之前关于AD和VaD混合病理可能疾病进展的文献更一致。

Conclusion: 联合进展模型（JPM）能够有效处理神经退行性疾病中的混合病理，并在排序准确性上优于传统的单一疾病模型。JPM的Mallows变体在真实世界数据中表现出与现有文献高度一致的结果。

Abstract: Event-based models (EBMs) infer disease progression from cross-sectional data, and standard EBMs assume a single underlying disease per individual. In contrast, mixed pathologies are common in neurodegeneration. We introduce the Joint Progression Model (JPM), a probabilistic framework that treats single-disease trajectories as partial rankings and builds a prior over joint progressions. We study several JPM variants (Pairwise, Bradley-Terry, Plackett-Luce, and Mallows) and analyze three properties: (i) calibration -- whether lower model energy predicts smaller distance to the ground truth ordering; (ii) separation -- the degree to which sampled rankings are distinguishable from random permutations; and (iii) sharpness -- the stability of sampled aggregate rankings. All variants are calibrated, and all achieve near-perfect separation; sharpness varies by variant and is well-predicted by simple features of the input partial rankings (number and length of rankings, conflict, and overlap). In synthetic experiments, JPM improves ordering accuracy by roughly 21 percent over a strong EBM baseline (SA-EBM) that treats the joint disease as a single condition. Finally, using NACC, we find that the Mallows variant of JPM and the baseline model (SA-EBM) have results that are more consistent with prior literature on the possible disease progression of the mixed pathology of AD and VaD.

</details>


### [78] [The promising potential of vision language models for the generation of textual weather forecasts](https://arxiv.org/abs/2512.03623)
*Edward C. C. Steele,Dinesh Mane,Emilio Monti,Luis Orus,Rebecca Chantrill-Cheyette,Matthew Couch,Kirstine I. Dale,Simon Eaton,Govindarajan Rangarajan,Amir Majlesi,Steven Ramsdale,Michael Sharpe,Craig Smith,Jonathan Smith,Rebecca Yates,Holly Ellis,Charles Ewen*

Main category: cs.LG

TL;DR: 本文探讨了使用视觉语言模型从视频编码的网格气象数据直接生成航运天气预报文本，以期加速多模态基础模型在气象产品和服务中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了加速多模态基础模型在气象产品和服务中的应用和普及，本文旨在探索使用视觉语言模型从视频编码的网格气象数据直接生成具有代表性的航运天气预报文本。

Method: 本文采用视觉语言模型，将视频编码的网格气象数据作为输入，直接生成航运天气预报文本。

Result: 初步结果显示，这种方法在提高气象行业的生产效率和服务创新方面具有可行的、可扩展的技术潜力。

Conclusion: 本文证明了将视觉语言模型应用于气象数据生成航运预报文本的可行性，并预示了该技术在气象领域及其他领域提高效率和创新的潜力。

Abstract: Despite the promising capability of multimodal foundation models, their application to the generation of meteorological products and services remains nascent. To accelerate aspiration and adoption, we explore the novel use of a vision language model for writing the iconic Shipping Forecast text directly from video-encoded gridded weather data. These early results demonstrate promising scalable technological opportunities for enhancing production efficiency and service innovation within the weather enterprise and beyond.

</details>


### [79] [Adaptive sampling using variational autoencoder and reinforcement learning](https://arxiv.org/abs/2512.03525)
*Adil Rasheed,Mikael Aleksander Jansen Shahly,Muhammad Faisal Aftab*

Main category: cs.LG

TL;DR: 该文章提出了一种自适应稀疏传感框架，将变分自动编码器先验与强化学习相结合，以顺序选择测量值，此方法优于现有的CS、OSP和基于生成模型的稀疏测量重建方法。


<details>
  <summary>Details</summary>
Motivation: 传统的压缩感知（CS）依赖通用基和随机测量，效率和重建质量受限。最优传感器布局（OSP）利用历史数据设计采样模式，但其固定线性基无法适应非线性或样本特定变化。基于生成模型的压缩感知虽然改善了重建，但仍采用次优的随机采样。

Method: 本研究提出了一种自适应稀疏传感框架，它将变分自动编码器（VAE）先验与强化学习（RL）相结合，用于顺序选择测量。

Result: 实验结果表明，该方法在稀疏测量重建方面优于压缩感知（CS）、最优传感器布局（OSP）和基于生成模型的重建方法。

Conclusion: 将变分自动编码器先验与强化学习相结合的自适应稀疏传感框架可以有效提高稀疏采样的效率和重建质量。

Abstract: Compressed sensing enables sparse sampling but relies on generic bases and random measurements, limiting efficiency and reconstruction quality. Optimal sensor placement uses historcal data to design tailored sampling patterns, yet its fixed, linear bases cannot adapt to nonlinear or sample-specific variations. Generative model-based compressed sensing improves reconstruction using deep generative priors but still employs suboptimal random sampling. We propose an adaptive sparse sensing framework that couples a variational autoencoder prior with reinforcement learning to select measurements sequentially. Experiments show that this approach outperforms CS, OSP, and Generative model-based reconstruction from sparse measurements.

</details>


### [80] [Dynamically Scaled Activation Steering](https://arxiv.org/abs/2512.03661)
*Alex Ferrando,Xavier Suau,Jordi Gonzàlez,Pau Rodriguez*

Main category: cs.LG

TL;DR: DSAS是一种动态调整激活转向强度的框架，实现了在不牺牲模型性能的前提下，根据输入自适应地进行干预，从而提高生成模型在内容生成（如去毒化）时的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的激活转向方法通常对所有输入都进行统一干预，当不需要转向时，会降低模型性能。

Method: DSAS框架通过分离“何时转向”和“如何转向”来解决问题。它能够自适应地调整现有转向转换在不同层和输入上的强度，只在检测到不良行为时才进行强干预。 DSAS在生成时计算上下文相关的缩放因子，以选择性地调整任何转向方法的强度。 此外，DSAS可以与转向函数一起进行端到端的联合优化。

Result: DSAS与现有转向方法结合时，持续改进了帕累托前沿，在去毒化和实用性保留之间取得了更好的权衡。 它还成功应用于文本到图像扩散模型，证明了其在调节特定概念方面的通用性。

Conclusion: DSAS提供了一种通用的、与方法无关的框架，可以在几乎不增加计算开销的情况下，动态调整激活转向强度。 它显著提高了生成模型在内容生成任务中的性能和效率，并在解决不当内容生成问题上提供了有效的新方法，同时增强了可解释性。

Abstract: Activation steering has emerged as a powerful method for guiding the behavior of generative models towards desired outcomes such as toxicity mitigation. However, most existing methods apply interventions uniformly across all inputs, degrading model performance when steering is unnecessary. We introduce Dynamically Scaled Activation Steering (DSAS), a method-agnostic steering framework that decouples when to steer from how to steer. DSAS adaptively modulates the strength of existing steering transformations across layers and inputs, intervening strongly only when undesired behavior is detected. At generation time, DSAS computes context-dependent scaling factors that selectively adjust the strength of any steering method. We also show how DSAS can be jointly optimized end-to-end together with the steering function. When combined with existing steering methods, DSAS consistently improves the Pareto front with respect to steering alone, achieving a better trade-off between toxicity mitigation and utility preservation. We further demonstrate DSAS's generality by applying it to a text-to-image diffusion model, showing how adaptive steering allows the modulation of specific concepts. Finally, DSAS introduces minimal computational overhead while improving interpretability, pinpointing which tokens require steering and by how much.

</details>


### [81] [Towards Irreversible Machine Unlearning for Diffusion Models](https://arxiv.org/abs/2512.03564)
*Xun Yuan,Zilong Zhao,Jiayu Li,Aryan Pasikhani,Prosanta Gope,Biplab Sikdar*

Main category: cs.LG

TL;DR: 本文提出了针对扩散模型微调取消学习方法的“扩散模型重学习攻击”（DiMRA），以及一种新的通过记忆进行取消学习的方法（DiMUM），旨在提高取消学习的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型机器取消学习方法主要针对条件扩散模型，并侧重于取消学习特定数据类别或特征，其中基于微调的方法因其效率和有效性而受到认可。然而，本文发现这些方法存在一个显著漏洞，即可能被逆转。

Method: 本文提出了两种方法：1. 扩散模型重学习攻击（DiMRA）：在不知道取消学习元素先验知识的情况下，通过在辅助数据集上优化未取消学习的扩散模型来逆转取消学习，使模型能够重新生成之前已取消学习的元素。2. 通过记忆进行扩散模型取消学习（DiMUM）：该方法通过记忆替代数据或特征来替换目标取消学习数据或特征，从而阻止生成这些元素，而不是像传统方法那样专注于遗忘。

Result: 实验证明了DiMRA在逆转当前最先进的基于微调的扩散模型机器取消学习方法方面的有效性，揭示了对更稳健解决方案的需求。同时，DiMUM在保持扩散模型生成性能的同时，显著提高了对抗DiMRA的鲁棒性。

Conclusion: 本文提出了DiMRA攻击，揭示了现有基于微调的扩散模型取消学习方法的脆弱性。为了解决这一问题，本文提出了一种新的取消学习方法DiMUM，该方法通过记忆替代内容而非简单遗忘，提高了取消学习的鲁棒性和模型性能。

Abstract: Diffusion models are renowned for their state-of-the-art performance in generating synthetic images. However, concerns related to safety, privacy, and copyright highlight the need for machine unlearning, which can make diffusion models forget specific training data and prevent the generation of sensitive or unwanted content. Current machine unlearning methods for diffusion models are primarily designed for conditional diffusion models and focus on unlearning specific data classes or features. Among these methods, finetuning-based machine unlearning methods are recognized for their efficiency and effectiveness, which update the parameters of pre-trained diffusion models by minimizing carefully designed loss functions. However, in this paper, we propose a novel attack named Diffusion Model Relearning Attack (DiMRA), which can reverse the finetuning-based machine unlearning methods, posing a significant vulnerability of this kind of technique. Without prior knowledge of the unlearning elements, DiMRA optimizes the unlearned diffusion model on an auxiliary dataset to reverse the unlearning, enabling the model to regenerate previously unlearned elements. To mitigate this vulnerability, we propose a novel machine unlearning method for diffusion models, termed as Diffusion Model Unlearning by Memorization (DiMUM). Unlike traditional methods that focus on forgetting, DiMUM memorizes alternative data or features to replace targeted unlearning data or features in order to prevent generating such elements. In our experiments, we demonstrate the effectiveness of DiMRA in reversing state-of-the-art finetuning-based machine unlearning methods for diffusion models, highlighting the need for more robust solutions. We extensively evaluate DiMUM, demonstrating its superior ability to preserve the generative performance of diffusion models while enhancing robustness against DiMRA.

</details>


### [82] [Optimal Transportation and Alignment Between Gaussian Measures](https://arxiv.org/abs/2512.03579)
*Sanjit Dandapanthula,Aleksandr Podkopaev,Shiva Prasad Kasiviswanathan,Aaditya Ramdas,Ziv Goldfeld*

Main category: cs.LG

TL;DR: 本文探讨了最优传输（OT）和Gromov-Wasserstein（GW）对齐在处理高斯分布时的应用，并提出了新的闭式解和算法，以提高计算效率和适用性。


<details>
  <summary>Details</summary>
Motivation: OT和GW框架在数据科学和机器学习中是常用的异构数据集比较、转换和聚合工具，但计算成本高昂。目前，大型应用通常依赖于二次成本下高斯分布的闭式解。

Method: 本文对高斯、二次成本OT和内积GW（IGW）对齐进行了全面处理，并填补了现有文献中的空白。主要方法包括：1. 提出解决非中心高斯分布在可分离希尔伯特空间上IGW对齐问题的闭式表达式（包含对幺正算子的二次优化），并推导出紧密的解析上下界。2. 证明当至少一个高斯测度居中时，解决方案可简化为完全闭式表达式，并进一步扩展到中心高斯分布之间IGW重心分析解。3. 将具有成对二次成本的高斯多边际OT简化为可处理的优化问题，并提供高效的算法解决该问题。

Result: 本文为非中心高斯分布在可分离希尔伯特空间上的IGW对齐问题提供了闭式表达式，并在特殊情况下（至少一个高斯测度居中）简化了解决方案。此外，还为中心高斯分布之间的IGW重心提供了分析解，并提出了解决高斯多边际OT的高效算法。

Conclusion: 本文通过提供新的闭式解和算法，显著提高了高斯分布下OT和GW对齐的计算效率和适用性，尤其是在知识蒸馏和异构聚类等领域的应用中具有实用价值。

Abstract: Optimal transport (OT) and Gromov-Wasserstein (GW) alignment provide interpretable geometric frameworks for comparing, transforming, and aggregating heterogeneous datasets -- tasks ubiquitous in data science and machine learning. Because these frameworks are computationally expensive, large-scale applications often rely on closed-form solutions for Gaussian distributions under quadratic cost. This work provides a comprehensive treatment of Gaussian, quadratic cost OT and inner product GW (IGW) alignment, closing several gaps in the literature to broaden applicability. First, we treat the open problem of IGW alignment between uncentered Gaussians on separable Hilbert spaces by giving a closed-form expression up to a quadratic optimization over unitary operators, for which we derive tight analytic upper and lower bounds. If at least one Gaussian measure is centered, the solution reduces to a fully closed-form expression, which we further extend to an analytic solution for the IGW barycenter between centered Gaussians. We also present a reduction of Gaussian multimarginal OT with pairwise quadratic costs to a tractable optimization problem and provide an efficient algorithm to solve it using a rank-deficiency constraint. To demonstrate utility, we apply our results to knowledge distillation and heterogeneous clustering on synthetic and real-world datasets.

</details>


### [83] [Federated Learning and Trajectory Compression for Enhanced AIS Coverage](https://arxiv.org/abs/2512.03584)
*Thomas Gräupl,Andreas Reisenbauer,Marcel Hecko,Anil Rasouli,Anita Graser,Melitta Dragaschnig,Axel Weissenfeld,Gilles Dejaegere,Mahmoud Sakr*

Main category: cs.LG

TL;DR: VesselEdge系统利用联邦学习和带宽受限的轨迹压缩技术，通过扩展AIS覆盖范围，增强了海上态势感知能力。


<details>
  <summary>Details</summary>
Motivation: 利用联邦学习和带宽受限的轨迹压缩技术，将船只转化为移动传感器，以在低带宽连接下实现实时异常检测和高效数据传输，从而增强海上态势感知能力。

Method: 系统集成了M3fed模型用于联邦学习，并采用BWC-DR-A算法进行轨迹压缩，优先处理异常数据。

Result: 初步结果表明，VesselEdge系统在改善AIS覆盖范围和态势感知方面表现出有效性。

Conclusion: VesselEdge系统通过结合联邦学习和高效数据压缩，提供了一种有效的方法来增强海上态势感知，尤其是在带宽受限的环境中。

Abstract: This paper presents the VesselEdge system, which leverages federated learning and bandwidth-constrained trajectory compression to enhance maritime situational awareness by extending AIS coverage. VesselEdge transforms vessels into mobile sensors, enabling real-time anomaly detection and efficient data transmission over low-bandwidth connections. The system integrates the M3fed model for federated learning and the BWC-DR-A algorithm for trajectory compression, prioritizing anomalous data. Preliminary results demonstrate the effectiveness of VesselEdge in improving AIS coverage and situational awareness using historical data.

</details>


### [84] [DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training](https://arxiv.org/abs/2512.03847)
*Dingwei Zhu,Zhiheng Xi,Shihan Dou,Yuhui Wang,Sixian Li,Junjie Ye,Honglin Guo,Shichun Liu,Chenhao Huang,Yajie Yang,Junlin Shang,Senjie Jin,Ming Zhang,Jiazheng Zhang,Caishuang Huang,Yunke Zhang,Demei Yan,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: DVPO框架在LLM后训练中平衡了鲁棒性和泛化性


<details>
  <summary>Details</summary>
Motivation: 现有方法在不稳定的监督信号下，忽略泛化性且可能产生过于保守的策略，导致在真实场景中性能不佳。

Method: DVPO结合条件风险理论和分布价值建模，学习token级别的价值分布，并通过不对称风险正则化来调整分布尾部，从而在抑制负面偏差的同时保留探索性多样性。

Result: DVPO在多轮对话、数学推理和科学问答等实验中，性能优于PPO、GRPO和鲁S Bellman-based PPO。

Conclusion: DVPO框架能够更好地平衡鲁棒性和泛化性，在真实世界LLM后训练中表现出巨大潜力。

Abstract: Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.

</details>


### [85] [Observation-driven correction of numerical weather prediction for marine winds](https://arxiv.org/abs/2512.03606)
*Matteo Peduto,Qidong Yang,Jonathan Giezendanner,Devis Tuia,Sherrie Wang*

Main category: cs.LG

TL;DR: 本文提出了一种基于Transformer的深度学习模型，通过同化最新的现场观测数据来校正全球预报系统（GFS）的输出，从而显著提高了海洋风预报的准确性。


<details>
  <summary>Details</summary>
Motivation: 海洋风预报对于航运安全、船舶路线规划和能源作业至关重要，但由于海洋观测数据稀疏、异质且随时间变化，准确的预报仍然具有挑战性。

Method: 本文将风预报重新定义为全球数值天气预报（NWP）模型的观测信息校正。作者提出了一种基于Transformer的深度学习架构，该架构通过掩码和基于集合的注意力机制处理不规则和时变的观测数据集；通过交叉注意力机制，根据最近的观测-预报对进行预测；并采用循环时间嵌入和坐标感知位置表示，以实现任意空间坐标的单次推理。

Result: 该模型在大西洋地区进行了评估，使用国际综合海洋-大气数据集（ICOADS）的观测数据作为参考。结果显示，该模型在所有长达48小时的预报时效内都降低了GFS 10米风速的均方根误差（RMSE），在1小时预报时效内将RMSE降低了45％，在48小时预报时效内降低了13％。空间分析表明，沿海地区和航运路线的改进最为显著，这些区域的观测数据最为丰富。

Conclusion: 所提出的基于Transformer的深度学习模型通过学习纠正系统性的预报误差，提供了一种实用的、低延迟的后处理方法，可以有效补充数值天气预报。该模型能够适应异构的观测平台，并通过一次前向传播生成特定站点预测和盆地尺度的网格产品。

Abstract: Accurate marine wind forecasts are essential for safe navigation, ship routing, and energy operations, yet they remain challenging because observations over the ocean are sparse, heterogeneous, and temporally variable. We reformulate wind forecasting as observation-informed correction of a global numerical weather prediction (NWP) model. Rather than forecasting winds directly, we learn local correction patterns by assimilating the latest in-situ observations to adjust the Global Forecast System (GFS) output. We propose a transformer-based deep learning architecture that (i) handles irregular and time-varying observation sets through masking and set-based attention mechanisms, (ii) conditions predictions on recent observation-forecast pairs via cross-attention, and (iii) employs cyclical time embeddings and coordinate-aware location representations to enable single-pass inference at arbitrary spatial coordinates. We evaluate our model over the Atlantic Ocean using observations from the International Comprehensive Ocean-Atmosphere Data Set (ICOADS) as reference. The model reduces GFS 10-meter wind RMSE at all lead times up to 48 hours, achieving 45% improvement at 1-hour lead time and 13% improvement at 48-hour lead time. Spatial analyses reveal the most persistent improvements along coastlines and shipping routes, where observations are most abundant. The tokenized architecture naturally accommodates heterogeneous observing platforms (ships, buoys, tide gauges, and coastal stations) and produces both site-specific predictions and basin-scale gridded products in a single forward pass. These results demonstrate a practical, low-latency post-processing approach that complements NWP by learning to correct systematic forecast errors.

</details>


### [86] [Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment](https://arxiv.org/abs/2512.03864)
*Danny Hoang,Anandkumar Patel,Ruimen Chen,Rajiv Malhotra,Farhad Imani*

Main category: cs.LG

TL;DR: 该研究比较了智能加工中AI模型的能耗、精度和速度，并引入了HDC，其在能耗和速度方面均优于传统模型，同时保持了相似的精度。


<details>
  <summary>Details</summary>
Motivation: 智能制造可以显著提高效率和降低能耗，但AI模型的能耗可能会抵消这些收益。

Method: 通过在位传感对智能加工中的几何质量进行预测，并比较常见AI模型的能耗、精度和速度。引入了超维度计算（HDC）作为替代方案。

Result: HDC在保持与传统模型相当的准确性的同时，能耗显著降低（训练降低200倍，推理降低175-1000倍）。HDC还将训练时间缩短了200倍，推理时间缩短了300-600倍。

Conclusion: HDC在智能制造中具有节能潜力，可以在保持高精度的同时大幅降低AI模型的能耗和运行时间。

Abstract: Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\times$ for training and 175 to 1000$\times$ for inference. Furthermore, HDC reduces training times by 200$\times$ and inference times by 300 to 600$\times$, showcasing its potential for energy-efficient smart manufacturing.

</details>


### [87] [Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning](https://arxiv.org/abs/2512.03973)
*Franki Nguimatsia Tiofack,Théotime Le Hellard,Fabian Schramm,Nicolas Perrin-Gilbert,Justin Carpentier*

Main category: cs.LG

TL;DR: GFP 通过多步流匹配策略和蒸馏的单步 Actor 相结合，在离线强化学习中实现了最先进的性能，特别是在次优数据集和挑战性任务上。


<details>
  <summary>Details</summary>
Motivation: 现有的离线强化学习方法在行为正则化中未能区分高价值和低价值动作。

Method: GFP 将多步流匹配策略与蒸馏的单步 Actor 相结合。Actor 通过加权行为克隆指导流策略，以专注于克隆数据集中高价值的动作。流策略则约束 Actor 与数据集中最佳转换保持一致，同时最大化 Critic。

Result: GFP 在 OGBench、Minari 和 D4RL 基准测试的 144 个基于状态和像素的任务上取得了最先进的性能，在次优数据集和挑战性任务上获得了显著提升。

Conclusion: GFP 实现了 Actor 和流策略之间的相互指导，从而在离线强化学习中表现出色，尤其在处理次优数据和复杂任务时具有强大优势。

Abstract: Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/

</details>


### [88] [Cyclical Temporal Encoding and Hybrid Deep Ensembles for Multistep Energy Forecasting](https://arxiv.org/abs/2512.03656)
*Salim Khazem,Houssam Kanso*

Main category: cs.LG

TL;DR: 该论文提出了一个统一的深度学习框架，将循环时间编码与混合LSTM-CNN架构相结合，以增强多步电力消耗预测。


<details>
  <summary>Details</summary>
Motivation: 准确的电力消耗预测对于需求侧管理和智能电网运行至关重要。

Method: 通过正余弦编码系统地转换基于日历的属性，以保留周期性结构，并通过相关性分析评估其预测相关性。采用由LSTM、CNN和专门针对每个预测范围的MLP回归器元学习器组成的集成模型，以利用长期季节性效应和短期局部模式。

Result: 在所有七个预测范围内都取得了持续改进，混合模型实现了比单个架构和现有方法更低的RMSE和MAE。

Conclusion: 循环时间表示与互补深度学习结构相结合是有效的。

Abstract: Accurate electricity consumption forecasting is essential for demand management and smart grid operations. This paper introduces a unified deep learning framework that integrates cyclical temporal encoding with hybrid LSTM-CNN architectures to enhance multistep energy forecasting. We systematically transform calendar-based attributes using sine cosine encodings to preserve periodic structure and evaluate their predictive relevance through correlation analysis. To exploit both long-term seasonal effects and short-term local patterns, we employ an ensemble model composed of an LSTM, a CNN, and a meta-learner of MLP regressors specialized for each forecast horizon. Using a one year national consumption dataset, we conduct an extensive experimental study including ablation analyses with and without cyclical encodings and calendar features and comparisons with established baselines from the literature. Results demonstrate consistent improvements across all seven forecast horizons, with our hybrid model achieving lower RMSE and MAE than individual architectures and prior methods. These findings confirm the benefit of combining cyclical temporal representations with complementary deep learning structures. To our knowledge, this is the first work to jointly evaluate temporal encodings, calendar-based features, and hybrid ensemble architectures within a unified short-term energy forecasting framework.

</details>


### [89] [Feature-aware Modulation for Learning from Temporal Tabular Data](https://arxiv.org/abs/2512.03678)
*Hao-Run Cai,Han-Jia Ye*

Main category: cs.LG

TL;DR: 该论文提出了一种特征感知的时间调制机制，用于解决表格数据中时间分布偏移问题，通过调整特征表示的统计属性来平衡模型的泛化性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在实际部署中，表格机器学习面临着时间分布偏移的挑战，即特征与标签之间的关系不断演变。静态模型难以泛化，而自适应模型又容易过拟合瞬态模式，因此在鲁棒性和适应性之间存在两难困境。

Method: 该研究分析了构建有效动态映射的关键因素，发现演变的特征语义（特别是客观和主观含义）会导致概念漂移。作者提出特征转换策略可以减轻不同时间阶段特征表示的差异，并基于此提出了一种特征感知的时间调制机制，该机制根据时间上下文调整特征表示，控制其统计属性（如尺度和偏度）。

Result: 通过对齐不同时间上的特征语义，该方法实现了轻量级而强大的自适应，有效地平衡了模型的泛化性和适应性。

Conclusion: 基准评估验证了该方法在处理表格数据时间偏移方面的有效性。

Abstract: While tabular machine learning has achieved remarkable success, temporal distribution shifts pose significant challenges in real-world deployment, as the relationships between features and labels continuously evolve. Static models assume fixed mappings to ensure generalization, whereas adaptive models may overfit to transient patterns, creating a dilemma between robustness and adaptability. In this paper, we analyze key factors essential for constructing an effective dynamic mapping for temporal tabular data. We discover that evolving feature semantics-particularly objective and subjective meanings-introduce concept drift over time. Crucially, we identify that feature transformation strategies are able to mitigate discrepancies in feature representations across temporal stages. Motivated by these insights, we propose a feature-aware temporal modulation mechanism that conditions feature representations on temporal context, modulating statistical properties such as scale and skewness. By aligning feature semantics across time, our approach achieves a lightweight yet powerful adaptation, effectively balancing generalizability and adaptability. Benchmark evaluations validate the effectiveness of our method in handling temporal shifts in tabular data.

</details>


### [90] [MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking](https://arxiv.org/abs/2512.04044)
*Yizhou Zhao,Zhiwei Steven Wu,Adam Block*

Main category: cs.LG

TL;DR: MarkTune通过在开放权重语言模型中对水印信号进行微调，从而在保持文本质量的同时，提高了水印的检测能力。


<details>
  <summary>Details</summary>
Motivation: 开放权重语言模型的水印技术面临挑战，现有方法如GaussMark通常需要修改模型权重，但这会降低生成文本的质量。

Method: MarkTune是一种理论上合理的、基于策略的微调框架，它将GaussMark信号视为奖励，同时对文本质量的下降进行正则化。MarkTune通过在模型表示空间内进行更细粒度、水印感知的权重更新，从而改进了GaussMark。

Result: MarkTune显著改善了GaussMark的质量-可检测性权衡，使开放权重模型的水印检测能力接近于推理时水印。MarkTune对释义和微调攻击具有鲁棒性，并显示出强大的泛化能力。

Conclusion: MarkTune提供了一种将鲁棒、高质量水印嵌入开放权重语言模型的通用策略。

Abstract: Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.

</details>


### [91] [Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm](https://arxiv.org/abs/2512.03744)
*Xuhui Lin,Qiuchen Lu*

Main category: cs.LG

TL;DR: 该研究提出了一种新的物理约束哈密顿学习算法，用于检测城市交通系统在极端天气事件后的隐藏结构性损伤，即使表面指标显示恢复，也能识别出“虚假恢复”的现象。


<details>
  <summary>Details</summary>
Motivation: 现有城市交通系统弹性评估方法依赖于表面恢复指标，无法识别极端天气事件造成的潜在结构性损伤，导致“虚假恢复”的误判。

Method: 该方法结合了“结构不可逆性检测”和“能量景观重建”，提取低维状态表示，通过物理约束优化识别准哈密顿结构，并通过能量景观比较量化结构变化。

Result: 通过分析2021年伦敦极端降雨事件，发现尽管表面指标完全恢复，但该算法检测出传统监测忽略的64.8%结构性损伤。

Conclusion: 该框架为主动结构风险评估提供了工具，能够根据真实的系统健康状况而非误导性的表面指标进行基础设施投资。

Abstract: Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and "false recovery," where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining "structural irreversibility detection" and "energy landscape reconstruction" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.

</details>


### [92] [Universally Converging Representations of Matter Across Scientific Foundation Models](https://arxiv.org/abs/2512.03750)
*Sathya Edamadaka,Soojung Yang,Ju Li,Rafael Gómez-Bombarelli*

Main category: cs.LG

TL;DR: 研究了不同机器学习模型在分子、材料和蛋白质行为预测中学习到的内部表示，发现它们在广泛的化学系统中具有高度一致性，并揭示了不同训练数据对模型表示学习的影响。


<details>
  <summary>Details</summary>
Motivation: 理解机器学习模型对物质的潜在内部表示对于构建能够可靠地推广到训练领域之外的科学基础模型至关重要。

Method: 本文系统地探索了不同模态（字符串、图、3D原子和蛋白质）的近60个科学模型所学习到的表示，通过分析它们在不同化学系统中的对齐程度。

Result: 研究发现，尽管模型模态不同，但它们在小分子和机器学习原子间势能方面表现出高度相似的表示收敛。在与训练数据相似的输入上，高性能模型表现出高度对齐，而弱模型在表示空间中发散；然而，在与训练数据差异很大的结构上，几乎所有模型都退化为低信息表示。

Conclusion: 目前科学模型在训练数据和归纳偏差方面仍受限制，未能编码真正通用的结构。本文的研究结果为科学基础模型中的通用性提供了一个量化基准，并有助于跟踪物质通用表示的出现，以及选择和提炼那些能最好地跨模态、物质领域和科学任务进行知识迁移的模型。

Abstract: Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.

</details>


### [93] [Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition](https://arxiv.org/abs/2512.03755)
*Stephen Law,Tao Yang,Nanjiang Chen,Xuhui Lin*

Main category: cs.LG

TL;DR: 该论文介绍了一种条件轨迹编码器，它利用几何特征，联合学习空间和运动表示，同时保留了与起点相关的非对称性。该模型在六个合成城市和北京西城区的真实世界验证中表现出色，揭示了城市形态如何导致系统性的认知不平等。


<details>
  <summary>Details</summary>
Motivation: 传统的城市分析方法在轨迹学习和空间嵌入方面存在碎片化问题，未能有效整合空间和时间信息，忽略了导航的方向不对称性，并且过度依赖辅助数据，而非城市空间的基本几何属性。

Method: 本文引入了一个条件轨迹编码器，它通过使用几何特征，联合学习空间和运动表示，同时保留了与起点相关的非对称性。该框架将城市导航分解为共享认知模式和起点特定的空间叙事。模型使用双向LSTM处理可见性比率和曲率特征，这些特征以可学习的起点嵌入为条件，并通过对比学习将表示分解为共享城市模式和起点特定签名。

Result: 在六个合成城市和北京市西城区进行的真实世界验证表明，城市形态会产生系统性的认知不平等。这为城市规划者提供了评估体验公平性的量化工具。

Conclusion: 该研究为城市规划者提供了评估体验公平性的量化工具，为建筑师提供了关于布局决策认知影响的见解，并为导航系统提供了起点感知的分析能力。

Abstract: Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \to B \ne B \to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.

</details>


### [94] [Deep Unfolding: Recent Developments, Theory, and Design Guidelines](https://arxiv.org/abs/2512.03768)
*Nir Shlezinger,Santiago Segarra,Yi Zhang,Dvir Avrahami,Zohar Davidov,Tirza Routtenberg,Yonina C. Eldar*

Main category: cs.LG

TL;DR: 深度展开（deep unfolding）是一个有吸引力的框架，它通过迭代优化算法将优化方法转化为有结构的、可训练的机器学习架构，连接了经典优化算法和机器学习。


<details>
  <summary>Details</summary>
Motivation: 经典的迭代优化算法虽然具有可解释性和理论保证，但依赖替代目标、需要仔细的超参数调整，并存在计算延迟。机器学习提供了强大的数据驱动建模能力，但缺乏优化驱动推断所需的结构、透明度和效率。本文旨在弥合这两种范式之间的鸿沟。

Method: 本文对深度展开进行了教程式的概述，提出了将优化求解器转换为机器学习模型的统一视角。提出和探讨了深度展开的四种代表性设计范式，并讨论了由其迭代性质产生的独特训练方案。

Result: 深度展开将迭代优化算法系统地转化为结构化的、可训练的机器学习架构。它提供了概念、理论和实践意义，统一了优化求解器到机器学习模型的转换方法。文中还对最近的理论进展进行了调查，确立了展开优化器的收敛性和泛化保证。

Conclusion: 深度展开作为连接传统优化算法和现代机器学习的桥梁，能够将优化求解器转化为机器学习模型，从而实现两者的优势互补。本文通过对深度展开的全面分析，揭示了其在复杂性、可解释性和鲁棒性方面的权衡，并强调它在信号处理和机器学习领域具有巨大的潜力。

Abstract: Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.

</details>


### [95] [Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach](https://arxiv.org/abs/2512.03786)
*Conor McCarthy,Jan Peter van Zandwijk,Marcel Worring,Zeno Geradts*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的方法，可将数字痕迹转化为用于物理活动类型识别的似然比（LRs），并在NFI_FARED数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 智能手机和智能手表在日常生活中无处不在，并能提供用户行为的丰富信息。特别是，手机内置运动传感器产生的数字痕迹为法医调查员深入了解一个人的身体活动提供了机会。

Method: 提出了一种基于机器学习的方法，将数字痕迹转化为不同类型物理活动的似然比（LRs）。

Result: 在NFI_FARED数据集上进行评估，该数据集包含来自四种不同类型iPhone的数字痕迹，并标注了19种活动。结果表明，本文的方法可以生成有用的LR系统，以区分171种可能的活动配对中的167种。同样的方法也被扩展，用于同时分析多种活动（或活动组）的似然，并创建活动时间线，以辅助法医调查的早期和后期阶段。

Conclusion: 本文提出了一种将数字痕迹转化为物理活动类型似然比的机器学习方法，并在新数据集NFI_FARED上进行了验证，结果表明该方法能够有效区分多种物理活动，并为法医调查提供了有用的工具。

Abstract: Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.

</details>


### [96] [Adaptive Identification and Modeling of Clinical Pathways with Process Mining](https://arxiv.org/abs/2512.03787)
*Francesco Vitale,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 该研究提出了一种两阶段的流程挖掘方法，用于扩展临床路径的知识库，通过利用一致性检查诊断，以改进对不同疾病变异或组合的治疗模型。


<details>
  <summary>Details</summary>
Motivation: 临床路径的手动建模难以反映不同疾病变异或组合的实际最佳实践。

Method: 第一阶段收集给定疾病的历史数据，以过程模型形式捕捉治疗过程；第二阶段将新数据与参考模型进行比较以验证一致性，并根据一致性检查结果扩展知识库。

Result: 该方法能够以足够的精度扩展临床路径的知识库，AUC峰值为95.62%，同时保持67.11%的弧度简洁性。

Conclusion: 所提出的两阶段流程挖掘方法可以有效地扩展临床路径的知识库，为不同疾病变异或组合提供更具体、更准确的治疗模型。

Abstract: Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.

</details>


### [97] [EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification](https://arxiv.org/abs/2512.03804)
*Hanhui Deng,Xinglin Li,Jie Luo,Zhanpeng Jin,Di Wu*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于深度学习技术的心电图诊断模型，该模型能够有效管理和分析心电图数据，旨在准确、快速地构建诊断模型，从而大幅减轻医务人员的负担。


<details>
  <summary>Details</summary>
Motivation: 现有的心电图模型误诊率高，需要一种新的方法来自动提取心电图数据特征。

Method: 本文首先提出了EfficientECG，一个基于EfficientNet的准确且轻量级的心电图分类模型，旨在有效处理高频长序列心电图数据和各种导联类型。其次，提出了一个基于跨注意力机制的EfficientECG特征融合模型，用于分析具有多种特征（如性别和年龄）的多导联心电图数据。

Result: 在代表性的心电图数据集上的评估验证了该模型在高精度、多特征融合和轻量级方面优于现有最新技术。

Conclusion: 所提出的基于深度学习的心电图诊断模型在准确性、多特征融合以及轻量化方面表现出色，有望大大减轻医务人员的工作负担。

Abstract: Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.

</details>


### [98] [Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($λ$,$λ$))-GA](https://arxiv.org/abs/2512.03805)
*Tai Nguyen,Phong Le,André Biedenkapp,Carola Doerr,Nguyen Dang*

Main category: cs.LG

TL;DR: 本文探讨了将深度强化学习（DRL）应用于动态算法配置（DAC）中的挑战，并提出了通过自适应奖励转移机制和无折扣学习来提高DRL算法在DAC中的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的针对DAC的强化学习方法需要专业的领域知识，并且效果不佳。

Method: 本文选择DDQN和PPO两种深度强化学习算法，通过控制OneMax实例上(1+(λ,λ))-GA的种群大小参数进行实验。针对欠探索问题，引入自适应奖励转移机制；针对规划范围覆盖问题，采用无折扣学习。

Result: DDQN结合自适应奖励转移机制，在样本效率上超越了以往的DAC方法，并达到了与理论策略相当的性能。PPO算法在超参数优化后仍难以找到有效策略，且面临固有的方差问题。

Conclusion: 本文提出的自适应奖励转移机制和无折扣学习可以有效解决DDQN在DAC中存在的欠探索和规划范围覆盖问题，大幅提升了算法的效率和稳定性。

Abstract: Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($λ$,$λ$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.

</details>


### [99] [Log Probability Tracking of LLM APIs](https://arxiv.org/abs/2512.03816)
*Timothée Chauvin,Erwan Le Merrer,François Taïani,Gilles Tredan*

Main category: cs.LG

TL;DR: 介绍了使用对数概率进行经济高效地持续监控大型语言模型（LLM）API的方法，该方法通过简单的统计测试，能检测出模型微小的变化，并且成本远低于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）审计方法成本过高，无法定期应用于各种LLM API，导致模型更新在实践中大多未被监控，这影响了下游应用的可靠性和研究的可重现性。

Method: 本文提出了一种基于LLM对数概率（logprobs）的成本效益高的持续监控LLM API的方法。即使LLM的对数概率通常是非确定性的，它们仍可作为监控基础。该方法采用基于每个token对数概率平均值的简单统计测试，仅需请求单个token的输出。

Result: 检测模型变化的灵敏度高。该方法能够检测出小至一步微调的变化，比现有方法的灵敏度更高，同时成本降低了1,000倍。

Conclusion: 本文提出了一种经济高效且灵敏的LLM API持续监控方法，可有效解决现有审计方法成本高昂、监测不足的问题，并通过引入TinyChange基准来衡量审计方法的敏感性。

Abstract: When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.

</details>


### [100] [Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization](https://arxiv.org/abs/2512.03928)
*Michele Alessi,Alessio Ansuini,Alex Rodriguez*

Main category: cs.LG

TL;DR: DiVAE是一种轻量级的、数据驱动的正则化器，它将VAE的对数先验概率与从数据中估计的对数密度对齐，从而改善了潜在空间的密度结构和OOD不确定性校准。


<details>
  <summary>Details</summary>
Motivation: 标准VAE将潜在变量与一个简单的先验匹配，忽略了数据空间中的密度结构，导致潜在空间无法很好地反映数据本身的密度分布。

Method: DiVAE通过向ELBO（证据下界）添加一个鲁棒的、经过精度加权的惩罚项来实现，该惩罚项将VAE的对数先验概率log p_Z(z)与从数据中估计的对数密度对齐，鼓励编码器根据数据空间的密度分配后验质量，从而使先验趋向于高密度区域，计算开销可忽略不计。

Result: 在合成数据集上，DiVAE改善了潜在对数密度与其真实对应物的分布对齐性，提高了先验覆盖率，并产生了更好的OOD（out-of-distribution）不确定性校准。在MNIST数据集上，DiVAE改善了先验与外部密度估计的对齐性，提供了更好的可解释性，并改善了可学习先验的OOD检测。

Conclusion: DiVAE通过引入密度感知正则化，有效地解决了传统VAE在处理潜在空间密度结构方面的不足，在生成模型、可解释性和异常检测方面都展示出了显著的性能提升。

Abstract: We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.

</details>


### [101] [Technical Report on Text Dataset Distillation](https://arxiv.org/abs/2512.03967)
*Keith Ando Ogawa,Bruno Lopes Yamamoto,Lucas Lauton de Alcantara,Victor Zacarias,Edson Bollis,Lucas Pellicer,Rosimeire Pereira Costa,Anna Helena Reali Costa,Artur Jordao*

Main category: cs.LG

TL;DR: 该报告回顾了文本数据集蒸馏的过去和最新进展，强调了不同的蒸馏策略、关键贡献和普遍挑战。


<details>
  <summary>Details</summary>
Motivation: 数据集蒸馏在视觉领域中已得到广泛研究，但在文本数据蒸馏方面的研究相对较少，尽管它已发展成为一个独立的研究分支。

Method: 本文对文本数据集蒸馏的过去和最新进展进行了综述，分析了不同的蒸馏策略。

Result: 文本数据集蒸馏的研究取得了显著进展，包括引入使用Transformer模型的方法、生成离散合成文本以及扩展到具有超过10亿参数的仅解码器模型。

Conclusion: 尽管现代方法取得了重大进展，但文本数据集蒸馏领域仍处于成熟阶段，在基准标准化、克服文本离散性、处理复杂任务以及提供真实世界应用的明确示例方面仍有改进空间。

Abstract: In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.

</details>


### [102] [Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs](https://arxiv.org/abs/2512.03994)
*Oren Rachmil,Roy Betser,Itay Gershon,Omer Hofman,Nitay Yakoby,Yuval Meron,Idan Yankelev,Asaf Shabtai,Yuval Elovici,Roman Vainshtein*

Main category: cs.LG

TL;DR: 本文提出了一种无需训练、高效的方法，将策略违规检测视为一个 OOD 检测问题，通过对模型隐藏激活进行线性变换并使用欧几里得范数作为合规性评分来检测策略违规。


<details>
  <summary>Details</summary>
Motivation: 随着组织在法律、金融、医疗等敏感领域部署大型语言模型（LLM），将专有 LLM 与内部组织策略对齐已成为当务之急。企业需要可靠的机制来检测其监管和操作框架内的策略违规，因为违规可能引发法律和声誉风险。现有的内容审核框架（如护栏）主要局限于安全领域，缺乏捕捉细致的组织策略的鲁棒性。LLM 作为判断器和微调方法虽然灵活，但会引入显著的延迟且缺乏可解释性。

Method: 本文提出了一种无需训练且高效的方法，将策略违规检测视为一个 OOD (Out-Of-Distribution) 检测问题。受白化技术的启发，我们对模型的隐藏激活应用线性变换，以消除它们的关联并将其标准化为零均值和单位方差，从而产生一个接近单位的协方差矩阵。在这个变换后的空间中，我们使用欧几里德范数作为合规性评分来检测策略违规。

Result: 该方法仅需要策略文本和少量示例，这使其轻量且易于部署。在一个具有挑战性的策略基准上，我们的方法取得了最先进的结果，超越了现有的护栏和微调推理模型。

Conclusion: 这项工作为组织提供了一个实用且有统计学依据的框架，用于对 LLM 进行策略感知监管，从而推进可部署 AI 治理的更广泛目标。

Abstract: Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection

</details>


### [103] [Physics-Embedded Gaussian Process for Traffic State Estimation](https://arxiv.org/abs/2512.04004)
*Yanlin Chen,Kehua Chen,Yinhai Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的物理嵌入高斯过程（PEGP）框架，通过结合领域知识和数据驱动方法来解决交通状态估计中探针车辆渗透率低和观测空间稀疏的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的交通状态估计方法在探针车辆渗透率低和观测空间稀疏时面临挑战。纯数据驱动方法缺乏物理解释且泛化能力差，而物理模型难以整合不确定性并捕获交通的真实复杂性。

Method: 本文提出了一种新颖的物理嵌入高斯过程（PEGP）框架。通过显式应用线性化微分算子，设计了两种受经典交通流模型启发的、多输出核函数。

Result: 在HighD和NGSIM数据集上的实验表明，PEGP相较于非物理基线方法有显著改进。PEGP-ARZ在稀疏观测下表现更可靠，而PEGP-LWR在密集观测下误差更低。消融研究揭示，PEGP-ARZ的残差与物理原理更吻合，能提供校准且可解释的不确定性，而PEGP-LWR的残差更趋于正交，并产生近似恒定的方差场。

Conclusion: PEGP框架结合了物理先验知识和不确定性量化，可以为交通状态估计提供可靠支持。此外，PEGP能够处理稀疏观测数据，并对交通状态进行更准确和可靠的估计。

Abstract: Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.

</details>


### [104] [Efficient Public Verification of Private ML via Regularization](https://arxiv.org/abs/2512.04008)
*Zoë Ruha Bell,Anvith Thudi,Olive Franzese-McLaughlin,Nicolas Papernot,Shafi Goldwasser*

Main category: cs.LG

TL;DR: 该论文提出了一种新的差分隐私算法，该算法在实现接近最优隐私-效用权衡的同时，显著降低了DP保证的验证成本，使其低于模型训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私（DP）训练方法缺乏高效的验证机制，导致数据提供者和公众难以有效核实模型是否满足DP保证，并且现有算法的验证成本与训练成本相当。

Method: 设计一种新的差分隐私随机凸优化（DP-SCO）算法。该算法通过私有化地最小化一系列正则化目标，并仅使用标准的DP组合界限来获得紧密的隐私-效用权衡。

Result: 该方法实现了接近最优的隐私-效用权衡，并且DP保证的验证成本远低于模型训练成本。

Conclusion: 该论文首次提出了一种DP-SCO算法，该算法在实现接近最优的隐私-效用权衡的同时，验证成本的增长速度优于训练成本，显著降低了大型数据集上的验证成本。

Abstract: Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.

</details>


### [105] [Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions](https://arxiv.org/abs/2512.04034)
*Hong Yang,Devroop Kar,Qi Yu,Alex Ororbia,Travis Desell*

Main category: cs.LG

TL;DR: 这篇论文解释了为什么在单一领域数据集上训练的模型在OOD检测中会出现灾难性故障。


<details>
  <summary>Details</summary>
Motivation: 探索为什么当前最先进的OOD检测方法在模型用单一领域数据集训练时会遭遇严重的失败。

Method: 通过信息论的视角，理论证明了在单一领域数据上进行监督学习不可避免地会导致领域特征崩溃，即领域特定信息被完全丢弃。利用Fano不等式量化了实际场景中的部分崩溃，并通过引入Domain Bench基准数据集进行实验验证，通过领域过滤来保留领域信息解决了故障模式。

Result: 理论证明了单领域训练会导致域特征崩溃I(x_d; z) = 0。OOD检测失败是因为模型只依赖类别特定特征而丢弃域特征。实验验证了通过保留I(x_d; z) > 0可以解决这种故障模式。

Conclusion: 揭示了监督学习在狭窄领域中的基本局限性，解释了一个令人困惑的经验现象，并对迁移学习以及何时微调或冻结预训练模型具有更广泛的启示。

Abstract: Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.

</details>


### [106] [Convergence for Discrete Parameter Updates](https://arxiv.org/abs/2512.04051)
*Paul Wilson,Fabio Zanasi,George Constantinides*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种用于深度学习模型低精度训练的离散更新规则，它通过离散化更新规则本身而不是量化连续更新来节省计算资源，同时提供了收敛保证和具体实例。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型需要大量的计算资源，因此需要研究低精度训练方法。传统的量化训练通过使用低比特整数表示训练组件来解决这个问题，但这通常依赖于离散化实值更新。

Method: 本文提出了一种替代方法，即更新规则本身是离散的，从而避免了连续更新的量化。作者为这类离散方案建立收敛保证，并提出了一个多项式更新规则作为具体例子。

Result: 通过这种方法，我们建立了一类离散方案的收敛保证，并提出了一个多项式更新规则作为具体例子，并进行了实证评估。

Conclusion: 这项工作为高效训练开辟了新的途径，特别是对于具有固有离散结构的模块。

Abstract: Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.

</details>


### [107] [Eval Factsheets: A Structured Framework for Documenting AI Evaluations](https://arxiv.org/abs/2512.04062)
*Florian Bordes,Candace Ross,Justine T Kao,Evangelia Spiliopoulou,Adina Williams*

Main category: cs.LG

TL;DR: 为了解决评估方法缺乏系统文档标准的问题，本文引入了“评估情况说明书（Eval Factsheets）”，这是一个结构化的描述性框架，用于通过全面的分类法和基于问卷的方法来记录AI系统评估。


<details>
  <summary>Details</summary>
Motivation: 基准测试的迅速普及给可复现性、透明度和知情决策带来了巨大挑战。然而，与受益于结构化文档框架（如数据集卡片和模型卡片）的数据集和模型不同，评估方法缺乏系统的文档标准。

Method: 本文引入了“评估情况说明书（Eval Factsheets）”，这是一个结构化、描述性的框架，通过全面的分类法和基于问卷的方法来记录AI系统评估。该框架将评估特征组织成五个基本维度：背景、范围、结构、方法和一致性。作者将此分类法实现为一个实用的问卷，包含五个部分，包括强制性和推荐的文档元素。

Result: 通过对多个基准测试的案例研究，本文证明了“评估情况说明书”能够有效捕捉不同的评估范式（从传统基准测试到“大型语言模型即评判者”的方法），同时保持一致性和可比性。

Conclusion: 作者希望“评估情况说明书”能被纳入现有和新发布的评估框架中，从而提高透明度和可复现性。

Abstract: The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.

</details>


### [108] [Learning Steerable Clarification Policies with Collaborative Self-play](https://arxiv.org/abs/2512.04068)
*Jonathan Berant,Maximillian Chen,Adam Fisch,Reza Aghajani,Fantine Huot,Mirella Lapata,Jacob Eisenstein*

Main category: cs.LG

TL;DR: 本文提出了一种利用自博弈训练可引导策略的方法，以管理 AI 助手中不确定查询的策略，从而在考虑用户偏好和交互模式的同时，最大化成本惩罚的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了处理不明确或有歧义的查询，AI 助手需要一种策略来管理其不确定性，以决定何时猜测用户意图并直接回答，何时列举并回答多个可能的意图，以及何时提出澄清性问题。然而，这些策略取决于用户偏好或交互模式等因素。

Method: 我们提出了使用自博弈来训练可引导策略，以管理这种不确定性。给定两个智能体，一个模拟用户，另一个模拟AI助手，我们生成对话，其中用户发出一个潜在模糊的查询，助手需要确定如何响应。模型将每个澄清问题的数值成本和每个生成的词作为输入，并被要求采取能够最大化其最终奖励（即成本惩罚的准确性）的行动。我们使用强化自训练（ReST）来训练我们的模型，以实现高回报。

Result: 这导致了一种可引导的策略，该策略根据所提供的成本可预测地改变其行为，从而带来更高的回报和准确性。此外，我们的程序还可以推广到在训练时未观察到的数值成本。

Conclusion: 本研究通过自博弈和强化自训练，成功地为AI助手在处理不明确查询时提供了一个可引导的、考虑成本的决策策略，并在提高准确性和泛化性方面取得了显著成效。

Abstract: To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [109] [Unsupervised Multimodal Graph-based Model for Geo-social Analysis](https://arxiv.org/abs/2512.03063)
*Ehsaneddin Jalilian,Bernd Resch*

Main category: cs.SI

TL;DR: 该论文提出了一种无监督、多模态的图方法，用于共同嵌入社交媒体内容中的语义和地理信息，以解决现有模型在处理多模态数据时的碎片化问题，并在灾害管理等领域取得了优异的效果。


<details>
  <summary>Details</summary>
Motivation: 在灾害管理和公众舆论监测等领域，对用户生成的社交媒体内容进行系统分析，特别是结合地理空间信息，扮演着至关重要的角色。然而，尽管多模态方法取得了显著进展，但大多数现有模型仍然是碎片化的，它们分别处理每种模态，而不是将其整合到一个统一的端到端模型中。

Method: 本文提出了一种无监督、多模态的图方法，将语义和地理信息共同嵌入到一个共享的表示空间中。该方法包含两种体系结构范例：单图（MonoGraph）模型，共同编码两种模态；多图（MultiGraph）模型，分别建模语义和地理关系，并通过多头注意力机制进行整合。通过结合对比、一致性和对齐目标的复合损失来指导学习过程，以生成语义连贯且空间紧凑的聚类。

Result: 在四个真实世界的灾害数据集上进行的实验表明，所提出的模型在主题质量、空间连贯性和可解释性方面始终优于现有基线。

Conclusion: 该框架具有领域无关性，可以很容易地扩展到各种形式的多模态数据和广泛的下游分析任务。

Abstract: The systematic analysis of user-generated social media content, especially when enriched with geospatial context, plays a vital role in domains such as disaster management and public opinion monitoring. Although multimodal approaches have made significant progress, most existing models remain fragmented, processing each modality separately rather than integrating them into a unified end-to-end model. To address this, we propose an unsupervised, multimodal graph-based methodology that jointly embeds semantic and geographic information into a shared representation space. The proposed methodology comprises two architectural paradigms: a mono graph (MonoGrah) model that jointly encodes both modalities, and a multi graph (MultiGraph) model that separately models semantic and geographic relationships and subsequently integrates them through multi-head attention mechanisms. A composite loss, combining contrastive, coherence, and alignment objectives, guides the learning process to produce semantically coherent and spatially compact clusters. Experiments on four real-world disaster datasets demonstrate that our models consistently outperform existing baselines in topic quality, spatial coherence, and interpretability. Inherently domain-independent, the framework can be readily extended to diverse forms of multimodal data and a wide range of downstream analysis tasks.

</details>


### [110] [Demographic Inference from Social Media Data with Multimodal Foundation Models: Strategies, Evaluation, and Benchmarking](https://arxiv.org/abs/2512.03064)
*Hao Yang,Angela Yao,Eric Chang,Hexiang Wang*

Main category: cs.SI

TL;DR: 该研究利用先进的多模态基础模型GPT-5，从社交媒体资料中推断年龄、性别和种族，实现了现有模型下的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人口统计推断方法通常依赖单一模态，且局限于预测一两个人口统计属性，限制了其在不同人群中的普适性和鲁棒性。

Method: 本研究利用GPT-5多模态基础模型，设计了一个渐进式多模态框架，逐步 P 融入用户名、个人简介、推文和个人资料图片，以检验每种信息源对推断准确性的贡献。

Result: GPT-5在年龄推断方面达到0.90的准确性，在性别推断方面达到0.98，在种族推断方面达到0.85，在同等输入条件下优于现有模型。

Conclusion: 大型多模态基础模型在捕捉复杂、跨模态的人口统计学线索方面具有巨大潜力，且只需最少的任务特定训练。 本研究提出了一种透明、可解释的多模态推理方法，提高了社交数据分析中人口统计推断的准确性、公平性和可扩展性。

Abstract: Demographic inference plays a crucial role in understanding the representativeness and equity of social media-based research. However, existing methods typically rely on a single modality, such as text, image, or network, and are limited to predicting one or two demographic attributes, constraining their generalizability and robustness across populations. This study leverages GPT-5, a state-of-the-art multimodal foundation model, to infer age, gender, and race from social media profiles. Using a dataset of 263 publicly available X (formerly Twitter) users, we design a progressive multimodal framework that incrementally incorporates usernames, profile descriptions, tweets, and profile images to examine how each information source contributes to inference accuracy. Results show a consistent improvement across all conditions, with the inclusion of textual and visual cues substantially enhancing performance. GPT-5 achieves an overall accuracy of 0.90 for age, 0.98 for gender, and 0.85 for race, outperforming existing models under equivalent inputs. These findings demonstrate the potential of large multimodal foundation models to capture complex, cross-modal demographic cues with minimal task-specific training. The study further highlights a transparent, interpretable approach to multimodal reasoning that advances the accuracy, fairness, and scalability of demographic inference in social data analytics.

</details>


### [111] [Quantifying the Potential to Escape Filter Bubbles: A Behavior-Aware Measure via Contrastive Simulation](https://arxiv.org/abs/2512.03067)
*Difu Feng,Qianqian Xu,Zitai Wang,Cong Hua,Zhiyong Yang,Qingming Huang*

Main category: cs.SI

TL;DR: 研究了推荐系统中的过滤气泡问题，并提出了一种新的评估指标BEP，以区分算法偏好建模和实际信息限制，并通过对比仿真框架量化用户逃离过滤气泡的难易程度。


<details>
  <summary>Details</summary>
Motivation: 推荐系统中的过滤气泡会强化用户现有偏好，导致群体极化等负面影响。现有评估指标无法区分算法偏好建模和实际信息限制。

Method: 引入了“气泡逃逸潜力”（BEP）作为行为感知度量，量化用户逃离过滤气泡的难易程度。BEP利用对比模拟框架，为合成用户分配不同的行为倾向（例如，积极与消极），并比较由此产生的曝光模式。

Result: 通过对多种推荐模型进行大量实验，检查了不同群体之间预测准确性和气泡逃逸潜力之间的关系。定量验证了偏好建模和过滤气泡之间的困境。观察到一个反直觉现象，即温和的随机推荐在缓解过滤气泡方面无效。

Conclusion: 提出了一种新的过滤气泡评估指标BEP，能够更精确地诊断气泡严重程度。研究结果首次定量验证了偏好建模和过滤气泡之间的两难困境，并发现温和的随机推荐在缓解过滤气泡方面无效，为进一步工作提供了基础。

Abstract: Nowadays, recommendation systems have become crucial to online platforms, shaping user exposure by accurate preference modeling. However, such an exposure strategy can also reinforce users' existing preferences, leading to a notorious phenomenon named filter bubbles. Given its negative effects, such as group polarization, increasing attention has been paid to exploring reasonable measures to filter bubbles. However, most existing evaluation metrics simply measure the diversity of user exposure, failing to distinguish between algorithmic preference modeling and actual information confinement. In view of this, we introduce Bubble Escape Potential (BEP), a behavior-aware measure that quantifies how easily users can escape from filter bubbles. Specifically, BEP leverages a contrastive simulation framework that assigns different behavioral tendencies (e.g., positive vs. negative) to synthetic users and compares the induced exposure patterns. This design enables decoupling the effect of filter bubbles and preference modeling, allowing for more precise diagnosis of bubble severity. We conduct extensive experiments across multiple recommendation models to examine the relationship between predictive accuracy and bubble escape potential across different groups. To the best of our knowledge, our empirical results are the first to quantitatively validate the dilemma between preference modeling and filter bubbles. What's more, we observe a counter-intuitive phenomenon that mild random recommendations are ineffective in alleviating filter bubbles, which can offer a principled foundation for further work in this direction.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [112] [Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation](https://arxiv.org/abs/2512.03048)
*Austin Spizzirri*

Main category: cs.AI

TL;DR: 本文提出AI对齐应被重新构想为通过基于过程、多智能体、发展机制来设计生成式、理性响应的智能体，而不是编码固定的人类价值内容。


<details>
  <summary>Details</summary>
Motivation: 作者认为AI对齐不应编码固定的人类价值内容，而是通过过程化、多智能体和发展机制来构建能产生新价值并能对推理做出响应的智能体。

Method: 1. 提出了“规范陷阱”论点，解释了为什么基于内容的价值规范是不稳定的。2. 引入了“熵减”框架，以信息论的方式理解多智能体对齐动态。3. 在兼容主义的指导控制理论基础上，区分了真实和模拟的道德能力。

Result: 作者提出了关于在人工系统中价值出现和道德能动性的可证伪的预测，但实证验证仍在进行中。

Conclusion: AI对齐应该被重新构想为通过基于过程、多智能体、发展机制来设计生成式、理性响应的智能体，而非编码固定的人类价值内容。该框架能对人工系统中的价值涌现和道德能动性提出具体的、可证伪的预测。然而，实证验证仍在进行中。

Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.

</details>


### [113] [Beyond the Black Box: A Cognitive Architecture for Explainable and Aligned AI](https://arxiv.org/abs/2512.03072)
*Hu Keyi*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种名为“权重计算主义”的新型认知架构，旨在解决当前AI在可解释性和价值对齐方面的挑战，并为实现人工通用智能（AGI）提供了一条可行途径。


<details>
  <summary>Details</summary>
Motivation: 当前的AI范式在可解释性和价值对齐方面面临根本性挑战，作者旨在提出一种新的认知架构来解决这些问题并为AGI铺平道路。

Method: 论文提出“权重计算主义”认知架构，将认知解构为不可分的逻辑原子以及指向和比较两种基本操作。决策过程通过可解释的权重计算模型（权重=收益*概率）进行形式化，所有值都可追溯到可审计的初始权重集。该架构通过基于图算法的计算引擎和全局工作空间工作流实现。

Result: 初步结果表明，该架构在史无前例的场景中实现了透明的、类似人类的推理和稳健学习。

Conclusion: “权重计算主义”架构为构建可信赖且对齐的AGI奠定了实践和理论基础，具有彻底的可解释性、对新情况的内在通用性以及可追溯的价值对齐。

Abstract: Current AI paradigms, as "architects of experience," face fundamental challenges in explainability and value alignment. This paper introduces "Weight-Calculatism," a novel cognitive architecture grounded in first principles, and demonstrates its potential as a viable pathway toward Artificial General Intelligence (AGI). The architecture deconstructs cognition into indivisible Logical Atoms and two fundamental operations: Pointing and Comparison. Decision-making is formalized through an interpretable Weight-Calculation model (Weight = Benefit * Probability), where all values are traceable to an auditable set of Initial Weights. This atomic decomposition enables radical explainability, intrinsic generality for novel situations, and traceable value alignment. We detail its implementation via a graph-algorithm-based computational engine and a global workspace workflow, supported by a preliminary code implementation and scenario validation. Results indicate that the architecture achieves transparent, human-like reasoning and robust learning in unprecedented scenarios, establishing a practical and theoretical foundation for building trustworthy and aligned AGI.

</details>


### [114] [When Do Symbolic Solvers Enhance Reasoning in Large Language Models?](https://arxiv.org/abs/2512.03272)
*Zhiyuan He,Dingmin Wang*

Main category: cs.AI

TL;DR: 本文探讨了大型推理模型（LRMs）在复杂推理任务中生成长思维链（CoT）的问题，以及符号求解器集成方法的潜力。研究发现，符号求解器在问题需要有限隐含推理但涉及大搜索空间时特别有效。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中产生的长思维链（CoT）可能导致大量的token开销，甚至导致错误答案。符号求解器集成方法是利用LLM的代码生成能力将推理任务转化为可执行代码并用符号求解器解决的一种有前景的方向。本文旨在探索何时可以通过符号求解器来增强传统的长思维链。

Method: 我们通过实验研究了符号求解器集成方法在不同类型问题上的表现。具体探讨了符号求解器在需要有限隐含推理但涉及大量搜索空间的问题以及演绎问题和约束满足问题中的效果。

Result: 实验结果表明，符号求解器集成方法仅在问题需要有限隐含推理但涉及大量搜索空间时有帮助。最新的LLMs（如GPT-4o）在浅层推理深度的演绎问题上表现更好，而符号求解器集成方法显著提高了LLMs在需要重复回溯的约束满足问题上的性能。当提供声明式示例时，CodeLlama-13B在困难的Zebra谜题中甚至能超越GPT-4o。

Conclusion: 符号求解器集成方法在特定类型的推理任务中（特别是那些需要有限隐含推理但搜索空间大以及约束满足问题）可以有效提升大型推理模型的性能，但其帮助并非普遍适用。对于某些演绎问题，最新的LLMs表现更佳。

Abstract: Large Reasoning Models (LRMs) achieve strong performance on complex reasoning tasks by generating long Chains of Thought (CoTs). However, this paradigm might incur substantial token overhead, especially when models "overthink" by producing lengthy reasoning chains, which can even lead to incorrect answers. A promising direction is the symbolic-solver-integrated approach, which leverages the code generation capabilities of LLMs to translate reasoning tasks into executable code and then solve them with a symbolic solver. In this paper, we explore an open question of when the conventional long-CoT can be enhanced by symbolic solvers. Our experimental results show that the symbolic-solver-integrated method only helps when the problem requires limited implicit reasoning but involves an ample search space. The latest LLMs, like GPT-4o, show better performance on deductive problems with shallow reasoning depth, while the symbolic-solver-integrated method significantly improves the LLMs' performance in constraint satisfaction problems that require repeated backtracks. When a declarative exemplar is provided, even CodeLlama-13B can outperform GPT-4o in difficult Zebra puzzles.

</details>


### [115] [Prior preferences in active inference agents: soft, hard, and goal shaping](https://arxiv.org/abs/2512.03293)
*Filippo Torresan,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 本文探讨了主动推理中偏好分布对智能体学习和决策的影响，特别是目标塑造如何影响开发和探索之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 在主动推理中，偏好分布的设定方式以及其对智能体推理和学习的影响尚未得到充分关注。

Method: 本文考虑了四种定义偏好分布的方法：硬性目标或软性目标，以及是否涉及目标塑造（即中间目标）。通过在一个网格世界导航任务中比较这四种偏好分布下智能体的表现。

Result: 目标塑造总体上实现了最佳性能，促进了开发（exploitation）。然而，它牺牲了对环境转换动力学（transition dynamics）的学习，阻碍了探索（exploration）。

Conclusion: 目标塑造在主动推理中能有效提升智能体的任务性能（开发），但可能会以牺牲环境探索为代价。研究结果强调了在设计主动推理智能体时，需要仔细权衡目标设定对开发和探索的影响。

Abstract: Active inference proposes expected free energy as an objective for planning and decision-making to adequately balance exploitative and explorative drives in learning agents. The exploitative drive, or what an agent wants to achieve, is formalised as the Kullback-Leibler divergence between a variational probability distribution, updated at each inference step, and a preference probability distribution that indicates what states or observations are more likely for the agent, hence determining the agent's goal in a certain environment. In the literature, the questions of how the preference distribution should be specified and of how a certain specification impacts inference and learning in an active inference agent have been given hardly any attention. In this work, we consider four possible ways of defining the preference distribution, either providing the agents with hard or soft goals and either involving or not goal shaping (i.e., intermediate goals). We compare the performances of four agents, each given one of the possible preference distributions, in a grid world navigation task. Our results show that goal shaping enables the best performance overall (i.e., it promotes exploitation) while sacrificing learning about the environment's transition dynamics (i.e., it hampers exploration).

</details>


### [116] [Multi-Agent Reinforcement Learning with Communication-Constrained Priors](https://arxiv.org/abs/2512.03528)
*Guang Yang,Tianpei Yang,Jingwen Qiao,Yanqing Wu,Jing Huo,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: 该论文提出了一种通用通信受限模型，用于解决多智能体系统中损耗通信的挑战，并通过解耦损耗和无损消息对分布式决策的影响来增强学习。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，通信是改进协作策略学习的有效手段，但在大多数现实世界场景中，通信损耗是一个普遍存在的问题。现有的多智能体强化学习方法在处理复杂和动态的现实世界环境时，由于可扩展性和鲁棒性有限而面临困难。

Method: 提出了一种广义通信受限模型来统一表征不同场景下的通信条件。利用该模型作为学习先验，以区分特定场景下的损耗和无损消息。借鉴双互信息估计器，解耦损耗和无损消息对分布式决策的影响。引入了一个通信受限的多智能体强化学习框架，将通信消息的影响量化到全局奖励中。

Result: 在多个通信受限基准测试中验证了该方法的有效性。

Conclusion: 通过提出通用通信受限模型和解耦损耗与无损消息的影响，本文有效提升了多智能体系统在损耗通信环境下的学习性能和决策能力。

Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.

</details>


### [117] [EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths](https://arxiv.org/abs/2512.03571)
*Zhening Li,Armando Solar-Lezama,Yisong Yue,Stephan Zheng*

Main category: cs.AI

TL;DR: 该论文介绍了一种新的基于LLM的智能体编程方法，即“概率天使非确定性”（PAN），它将智能体设计中的工作流逻辑和推理时策略分离开来，并通过EnCompass框架实现。


<details>
  <summary>Details</summary>
Motivation: 传统的智能体编程方法通常将核心工作流逻辑和推理时策略（例如，树搜索）纠缠在一起，导致在开发和实验不同推理策略时不够灵活。

Method: 提出了一种名为“概率天使非确定性”（PAN）的编程模型，该模型将智能体的工作流描述与推理时策略分离开来。通过EnCompass框架在Python中实现了PAN，该框架使用Python装饰器将智能体工作流程序编译成搜索空间。

Result: 通过三个案例研究，展示了EnCompass框架如何让程序员快速提高智能体的可靠性，并在不同的推理时策略之间轻松切换，且只需少量额外编码。

Conclusion: PAN编程模型和EnCompass框架有效地解耦了智能体的工作流逻辑和推理时策略，显著提高了智能体开发的灵活性和效率。

Abstract: We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce "probabilistic angelic nondeterminism" ("PAN"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.

</details>


### [118] [DeepRule: An Integrated Framework for Automated Business Rule Generation via Deep Predictive Modeling and Hybrid Search Optimization](https://arxiv.org/abs/2512.03607)
*Yusen Wu,Xiaotie Deng*

Main category: cs.AI

TL;DR: DeepRule是一个整合框架，用于零售分类和定价优化中的自动化业务规则生成。它通过三层架构解决了现有理论模型与实际经济复杂性之间的不对称问题，包括数据模态不匹配、动态特征纠缠和操作不可行性。


<details>
  <summary>Details</summary>
Motivation: 解决现有理论模型与实际经济复杂性之间的系统性错位，具体表现为：数据模态不匹配（非结构化文本数据难以用于客户画像）、动态特征纠缠（非线性价格弹性和时变属性建模挑战）以及多层业务约束导致的操作不可行性。

Method: DeepRule提出了一个三层架构来应对这些挑战： 1. 混合知识融合引擎：采用大型语言模型（LLMs）对非结构化文本进行深度语义解析，将分销商协议和销售评估转化为结构化特征，并整合管理专业知识。 2. 博弈论约束优化机制：通过双边效用函数动态协调供应链利益，将制造商-分销商的利润再分配编码为分层约束下的内生目标。 3. 可解释的决策蒸馏接口：利用LLM引导的符号回归来寻找和优化定价策略和可审计的业务规则，在数学表达式搜索过程中嵌入经济先验（如非负弹性）作为硬约束。

Result: 该框架在真实的零售环境中进行了验证，与系统的B2C基线相比，实现了更高的利润，同时确保了操作可行性。

Conclusion: DeepRule建立了一个闭环流程，统一了非结构化知识注入、多智能体优化和可解释策略合成，为真实的经济智能提供了支持。

Abstract: This paper proposes DeepRule, an integrated framework for automated business rule generation in retail assortment and pricing optimization. Addressing the systematic misalignment between existing theoretical models and real-world economic complexities, we identify three critical gaps: (1) data modality mismatch where unstructured textual sources (e.g. negotiation records, approval documents) impede accurate customer profiling; (2) dynamic feature entanglement challenges in modeling nonlinear price elasticity and time-varying attributes; (3) operational infeasibility caused by multi-tier business constraints.
  Our framework introduces a tri-level architecture for above challenges. We design a hybrid knowledge fusion engine employing large language models (LLMs) for deep semantic parsing of unstructured text, transforming distributor agreements and sales assessments into structured features while integrating managerial expertise. Then a game-theoretic constrained optimization mechanism is employed to dynamically reconcile supply chain interests through bilateral utility functions, encoding manufacturer-distributor profit redistribution as endogenous objectives under hierarchical constraints. Finally an interpretable decision distillation interface leveraging LLM-guided symbolic regression to find and optimize pricing strategies and auditable business rules embeds economic priors (e.g. non-negative elasticity) as hard constraints during mathematical expression search. We validate the framework in real retail environments achieving higher profits versus systematic B2C baselines while ensuring operational feasibility. This establishes a close-loop pipeline unifying unstructured knowledge injection, multi-agent optimization, and interpretable strategy synthesis for real economic intelligence.

</details>


### [119] [RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design](https://arxiv.org/abs/2512.03762)
*Jiawei Xu,Fengfeng Wei,Weineng Chen*

Main category: cs.AI

TL;DR: RoCo是一个多智能体AHD系统，通过多角色协作提高组合优化问题（COPs）中启发式规则的质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的自动启发式设计（AHD）研究通常只考虑单一角色，限制了启发式规则的多样性和质量。

Method: RoCo系统包含四个LLM引导的智能体：探索者、开发者、评论者和集成者。探索者注重创造性和多样性；开发者侧重于效率和改进；评论者评估并提供反馈；集成者平衡创新和效率。这些智能体通过多轮反馈、改进和精英突变进行交互。

Result: RoCo在五种不同的COPs上进行了白盒和黑盒设置的评估，实验结果表明，RoCo在生成竞争性启发式规则方面优于现有方法，包括ReEvo和HSEvo。

Conclusion: RoCo通过其多角色协作范式，为鲁棒和高性能的AHD设定了新标准。

Abstract: Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.

</details>


### [120] [Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.03783)
*Dongchao Yang,Songxiang Liu,Disong Wang,Yuanyuan Wang,Guanglu Wan,Helen Meng*

Main category: cs.AI

TL;DR: Omni-AutoThink是一个自适应推理框架，它能根据任务难度动态调整模型推理深度，分为自适应SFT和自适应RL两个阶段，并在多模态基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有Omni模型在推理时表现出僵化的行为，不能根据任务难度调整推理深度。

Method: 提出两阶段框架：1. 自适应SFT阶段，用大规模推理增强数据赋予模型推理能力。2. 自适应强化学习（Adaptive GRPO）阶段，根据任务复杂度和奖励反馈优化推理行为。

Result: 与现有基线相比，Omni-AutoThink显著提升了自适应推理性能。

Conclusion: Omni-AutoThink通过动态调整推理深度有效解决了Omni模型在推理方面的局限性，实现了更灵活、高效的多模态推理。

Abstract: Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.

</details>


### [121] [Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties](https://arxiv.org/abs/2512.03931)
*Vineel Tummala,Daniela Inclezan*

Main category: cs.AI

TL;DR: 本文提出了一个基于逻辑编程的策略感知自主智能体框架，该框架允许智能体在某些情况下偏离策略来实现高风险目标，并通过模拟现实人类决策辅助政策制定者。


<details>
  <summary>Details</summary>
Motivation: 以往的工作主要集中在确保合规性，但本文的方法考虑了在必要时偏离策略以实现高风险目标的情况。此外，对不合规行为建模可以通过模拟现实的人类决策来辅助政策制定者。

Method: 本文扩展了Gelfond和Lobo的授权与义务策略语言（AOPL）以纳入惩罚，并集成了答案集编程（ASP）进行推理。
与以前的方法相比，该方法确保了策略的良好形式，考虑了策略优先级，并通过明确识别违规行为及其后果增强了解释性。
在Harders和Inclezan的工作基础上，引入了基于惩罚的推理来区分不合规计划，优先选择后果最小的计划。
开发了从扩展AOPL到ASP的自动翻译，并改进了基于ASP的规划算法以考虑所产生的惩罚。

Result: 在两个领域进行的实验表明，该框架生成了更高质量的计划，避免了有害行为，并且在某些情况下还提高了计算效率。

Conclusion: 这些发现强调了该框架在增强自主决策和改进策略方面的潜力。

Abstract: This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [122] [Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol](https://arxiv.org/abs/2512.03955)
*Niklas Jobs,Luis Miguel Vieira da Silva,Jayanth Somashekaraiah,Maximilian Weigand,David Kube,Felix Gehlhoff*

Main category: cs.AI

TL;DR: 该论文提出了一个用于评估基于大型语言模型（LLM）的智能体在工业自动化中适应性规划和执行能力的基准。


<details>
  <summary>Details</summary>
Motivation: 工业自动化需要灵活的控制策略以适应不断变化的S任务和环境，而基于LLM的智能体有潜力提供这种适应性，但缺乏标准化的系统比较基准。

Method: 本文引入了一个包含可执行仿真环境的Blocksworld问题基准，该基准分为五个复杂度类别。通过集成模型上下文协议（MCP）作为标准化工具接口，可以连接不同的智能体架构进行评估，而无需针对具体实现进行修改。

Result: 通过一个单智能体实现，验证了该基准的适用性，并建立了用于比较基于LLM的规划和执行方法的定量度量标准。

Conclusion: 该基准为评估和比较LLM智能体在工业自动化领域的适应性规划和执行能力提供了一个标准化的平台。

Abstract: Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [123] [Strengthening Han's Fourier Entropy-Influence Inequality via an Information-Theoretic Proof](https://arxiv.org/abs/2512.03117)
*Peijie Li,Guangyue Han*

Main category: cs.IT

TL;DR: 本文加强了Han的傅里叶熵-影响不等式，并给出了一个简短的信息论证明，证明了对于所有单位L2范数的实值布尔函数，该不等式实际上以尖锐的常数C1=C2=1成立。


<details>
  <summary>Details</summary>
Motivation: Han的傅里叶熵-影响不等式最初是针对{-1,1}值布尔函数证明的，常数C1=3+2ln2，C2=1。本文旨在加强这一不等式，并通过信息论方法，将其推广到所有单位L2范数的实值布尔函数，并证明常数C1=C2=1为最优。

Method: 本文采用信息论方法对不等式进行了证明。

Result: 证明了Han的傅里叶熵-影响不等式对于所有单位L2范数的实值布尔函数都成立，且常数C1=C2=1为最优。

Conclusion: 这项工作将Han的傅里叶熵-影响不等式推广到更广泛的函数范畴，并给出了最优常数，揭示了香农熵和影响之间更基本的结构性质。

Abstract: We strengthen Han's Fourier entropy-influence inequality $$ H[\widehat{f}] \leq C_{1}I(f) + C_{2}\sum_{i\in [n]}I_{i}(f)\ln\frac{1}{I_{i}(f)} $$ originally proved for $\{-1,1\}$-valued Boolean functions with $C_{1}=3+2\ln 2$ and $C_{2}=1$. We show, by a short information-theoretic proof, that it in fact holds with sharp constants $C_{1}=C_{2}=1$ for all real-valued Boolean functions of unit $L^{2}$-norm, thereby establishing the inequality as an elementary structural property of Shannon entropy and influence.

</details>


### [124] [Multi-Source M/G/1/1 Queues with Probabilistic Preemption](https://arxiv.org/abs/2512.03241)
*Mohammad Moltafet,Hamid R. Sadjadpour,Zouheir Rezki,Marian Codreanu,Roy D. Yates*

Main category: cs.IT

TL;DR: 本文提出了一种概率抢占式数据包管理策略，以优化多源状态更新系统中的信息年龄（AoI）和峰值AoI（PAoI）。


<details>
  <summary>Details</summary>
Motivation: 在多源状态更新系统中，需要一种有效的数据包管理策略来优化信息的新鲜度，尤其是信息年龄（AoI）和峰值AoI（PAoI）。现有的系统可能因为数据包冲突或不当管理导致信息时效性不佳。

Method: 本文考虑一个多源M/G/1/1排队系统，其中包含多个独立源、一个服务器和一个接收器。每个源根据泊松过程生成数据包，并根据通用服务时间分布进行服务。系统容量为一个数据包，没有等待缓冲区。本文引入了一种概率抢占式数据包管理策略：当来自同一源的新数据包到达时，以固定概率替换系统中已存在的该源数据包。通过推导每种策略下每个源的信息年龄（AoI）和峰值AoI（PAoI）的矩生成函数（MGF）进行分析。

Result: 数值结果表明，所提出的概率抢占式数据包管理策略是有效的，能够有效优化多源状态更新系统中的信息年龄和峰值AoI。

Conclusion: 本文提出了一种新颖的概率抢占式数据包管理策略，通过理论分析和数值验证，证明了该策略在多源M/G/1/1排队系统中优化信息年龄（AoI）和峰值AoI（PAoI）的有效性。未来的工作可以探索更复杂的系统模型或更智能的抢占策略。

Abstract: We consider a multi-source status update system consisting of multiple independent sources, a single server, and a single sink. Each source generates packets according to a Poisson process, and packets are served according to a general service time distribution. The system has a capacity of one packet, i.e., no waiting buffer, and is modeled as a multi-source M/G/1/1 queueing system. We introduce a probabilistically preemptive packet management policy, under which an existing packet from the same source in the system is replaced by an arriving packet with a fixed probability. We derive the moment generating functions (MGFs) of the age of information (AoI) and peak AoI (PAoI) for each source under this policy. Numerical results demonstrate the effectiveness of the proposed packet management policy.

</details>


### [125] [Generalized Orthogonal Approximate Message-Passing for Sublinear Sparsity](https://arxiv.org/abs/2512.03326)
*Keigo Takeuchi*

Main category: cs.IT

TL;DR: 本文提出了一种广义正交近似消息传递（GOAMP）算法，用于从广义线性测量中恢复亚线性稀疏信号。


<details>
  <summary>Details</summary>
Motivation: 在传统研究中，信号稀疏度与信号维度成比例，而本文假设信号稀疏度相对于信号维度是亚线性的。针对近似消息传递（AMP）算法在非标准高斯感知矩阵下收敛性差的问题，提出GOAMP算法。

Method: GOAMP算法的核心特点是引入Onsager校正，以实现估计误差的渐近高斯性。该Onsager校正通过状态演化设计，适用于亚线性稀疏极限下的正交不变感知矩阵。

Result: 当非零信号的支持不包含原点附近时，使用贝叶斯去噪器的GOAMP算法被证明可以实现无误差信号重建，当且仅当测量维度大于某个阈值时，该阈值与标准高斯感知感知矩阵的AMP算法相同。数值模拟表明，在病态感知矩阵下，GOAMP算法的性能优于现有的重建算法。

Conclusion: 本文提出的GOAMP算法能有效地解决亚线性稀疏信号的重建问题，并且在特定条件下能够实现无误差重建。

Abstract: This paper addresses the reconstruction of sparse signals from generalized linear measurements. Signal sparsity is assumed to be sublinear in the signal dimension while it was proportional to the signal dimension in conventional research. Approximate message-passing (AMP) has poor convergence properties for sensing matrices beyond standard Gaussian matrices. To solve this convergence issue, generalized orthogonal AMP (GOAMP) is proposed for signals with sublinear sparsity. The main feature of GOAMP is the so-called Onsager correction to realize asymptotic Gaussianity of estimation errors. The Onsager correction in GOAMP is designed via state evolution for orthogonally invariant sensing matrices in the sublinear sparsity limit, where the signal sparsity and measurement dimension tend to infinity at sublinear speed in the signal dimension. When the support of non-zero signals does not contain a neighborhood of the origin, GOAMP using Bayesian denoisers is proved to achieve error-free signal reconstruction for linear measurements if and only if the measurement dimension is larger than a threshold, which is equal to that of AMP for standard Gaussian sensing matrices. Numerical simulations are also presented for linear measurements and 1-bit compressed sensing. When ill-conditioned sensing matrices are used, GOAMP for sublinear sparsity is shown to outperform existing reconstruction algorithms, including generalized AMP for sublinear sparsity.

</details>


### [126] [Expected Confidence Dependency: A Novel Rough Set-Based Approach to Feature Selection](https://arxiv.org/abs/2512.03612)
*Saeed Rasouli,Hamid Karamikabir*

Main category: cs.IT

TL;DR: 本文提出了期望置信度依赖（ECD），这是一种新颖的、面向软计算的、准确性驱动的依赖度量，用于粗糙集理论框架内的特征选择。


<details>
  <summary>Details</summary>
Motivation: 传统的粗糙集依赖度量依赖于条件块的二元表征，而这限制了其在某些场景下的应用。

Method: ECD通过向单个等价块分配基于置信度的贡献，并通过归一化的期望算子对其进行聚合，从而克服了传统方法的局限性。

Result: ECD具有归一化、与经典依赖度兼容、单调性以及在结构和标签保留转换下的不变性等优良特性。

Conclusion: ECD为粗糙集理论框架下的特征选择提供了一种新的、更灵活有效的依赖度量。

Abstract: This paper proposes Expected Confidence Dependency (ECD), a novel, soft computing-oriented, accuracy driven dependency measure for feature selection within the rough set theory framework. Unlike traditional rough set dependency measures that rely on binary characterizations of conditional blocks, ECD assigns confidence-based contributions to individual equivalence blocks and aggregates them through a normalized expectation operator. We formally establish several desirable properties of ECD, including normalization, compatibility with classical dependency, monotonicity, and invariance under structural and label-preserving transformations.

</details>


### [127] [Over-the-Air Federated Learning: Rethinking Edge AI Through Signal Processing](https://arxiv.org/abs/2512.03719)
*Seyed Mohammad Azimi-Abarghouyi,Carlo Fischione,Kaibin Huang*

Main category: cs.IT

TL;DR: 本文对无线联邦学习（AirFL）进行了教程性介绍，这是一种新兴范式，通过利用无线信号的叠加特性，同时实现通信和模型聚合，从而显著降低延迟、带宽和能耗。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习在通信和模型聚合方面存在延迟、带宽和能耗问题，AirFL旨在通过无线信号的叠加特性来解决这些问题。

Method: 本文对AirFL进行了分类，提出了三种设计方法：CSIT感知、盲和加权AirFL。

Result: 本文全面介绍了AirFL的理论基础、性能分析、复杂性考量、实际限制和未来的研究方向。

Conclusion: AirFL通过无线信号的叠加特性，可以显著降低联邦学习的通信和模型聚合的延迟、带宽和能耗。

Abstract: Over-the-Air Federated Learning (AirFL) is an emerging paradigm that tightly integrates wireless signal processing and distributed machine learning to enable scalable AI at the network edge. By leveraging the superposition property of wireless signals, AirFL performs communication and model aggregation of the learning process simultaneously, significantly reducing latency, bandwidth, and energy consumption. This article offers a tutorial treatment of AirFL, presenting a novel classification into three design approaches: CSIT-aware, blind, and weighted AirFL. We provide a comprehensive guide to theoretical foundations, performance analysis, complexity considerations, practical limitations, and prospective research directions.

</details>


### [128] [Movable Signals with Dual-Polarized Fixed Intelligent Surfaces: Beyond Diagonal Reflection Matrices](https://arxiv.org/abs/2512.03872)
*Matteo Nerini,Bruno Clerckx*

Main category: cs.IT

TL;DR: 本文分析了双极化智能表面辅助的无线通信系统，对比了可重构智能表面（RIS）和采用固定智能表面（FIS）的可移动信号，发现FIS系统性能优于RIS系统，尤其是在发射机和接收机极化不同的情况下，超越对角线FIS能进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索双极化智能表面在无线通信系统中的应用，并比较RIS和FIS两种不同工作原理的智能表面在性能上的差异。

Method: 本文通过比较对角线和超越对角线两种模式下的RIS和FIS系统，并在发射机和接收机极化不同的场景下进行性能评估。

Result: 可移动信号与FIS结合的系统性能始终优于RIS系统，至少取得了四倍的增益。当发射机和接收机极化不同时，超越对角线FIS能进一步提升系统性能。

Conclusion: 在双极化智能表面辅助的无线系统中，采用固定智能表面（FIS）并调节信号频率的可移动信号方案比调节反射矩阵的RIS方案具有显著的性能优势，尤其是在极化不匹配的情况下，超越对角线FIS的表现更为出色。

Abstract: This paper investigates wireless systems aided by dual-polarized intelligent surfaces. We compare reconfigurable intelligent surface (RIS), which adjust their reflection matrices, with movable signals operating with fixed intelligent surface (FIS), which adjust the signal frequency while the surface properties remain fixed. For both RIS and FIS, we consider surfaces with a diagonal reflection matrix, named diagonal RIS/FIS, and surfaces with a reflection matrix not limited to being diagonal, named beyond-diagonal RIS/FIS. Movable signals with FIS always outperform RIS, achieving at least a fourfold gain. When transmitter and receiver polarizations differ, beyond-diagonal FIS further enhances performance.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [129] [A note on the impossibility of conditional PAC-efficient reasoning in large language models](https://arxiv.org/abs/2512.03057)
*Hao Zeng*

Main category: stat.ML

TL;DR: 本文证明了在大型语言模型中，条件概率近似正确（PAC）高效推理的不可能结果。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型中条件PAC效率推理的理论限制。

Method: 通过数学证明，作者展示了在非原子输入空间中，任何实现条件PAC效率的算法都必须是平凡的。

Result: 在非原子输入空间中，任何实现条件PAC效率的算法都必须以至少1-α的概率依赖于专家模型。

Conclusion: 在大型语言模型中实现条件PAC高效推理在分发自由设置下是不可能的。

Abstract: We prove an impossibility result for conditional Probably Approximately Correct (PAC)-efficient reasoning in large language models. While recent work has established marginal PAC efficiency guarantees for composite models that switch between expensive expert models and cheaper fast models, we show that conditional (pointwise) guarantees are impossible in the distribution-free setting. Specifically, for non-atomic input spaces, any algorithm achieving conditional PAC efficiency must be trivial in the sense that it defers to the expert model with probability at least $1-α$ for almost every input.

</details>


### [130] [Uncertainty Quantification for Large Language Model Reward Learning under Heterogeneous Human Feedback](https://arxiv.org/abs/2512.03208)
*Pangpang Liu,Junwei Lu,Will Wei Sun*

Main category: stat.ML

TL;DR: 这篇论文研究了大型语言模型（LLM）对齐中使用的奖励模型的估计和统计推断。


<details>
  <summary>Details</summary>
Motivation: 解决人类反馈的异质性给奖励学习带来的挑战，并提高奖励模型的可靠性。

Method: 采用异质偏好框架，联合建模答案的潜在奖励和人类理性。通过交替梯度下降算法解决具有挑战性的双凸优化问题，并建立了估计的理论保证，包括收敛性和渐近分布。

Result: 所提出的方法能够对奖励估计构建置信区间，并进行有效的统计比较。将不确定性纳入best-of-N（BoN）策略框架中，并通过广泛的模拟和真实LLM数据应用证明了其有效性。

Conclusion: accounting for uncertainty in reward modeling for LLM alignment is of great practical value。

Abstract: We study estimation and statistical inference for reward models used in aligning large language models (LLMs). A key component of LLM alignment is reinforcement learning from human feedback (RLHF), where humans compare pairs of model-generated answers and their preferences are used to train a reward model. However, human feedback is inherently heterogeneous, creating significant challenges for reliable reward learning. To address this, we adopt a heterogeneous preference framework that jointly models the latent reward of answers and human rationality. This leads to a challenging biconvex optimization problem, which we solve via an alternating gradient descent algorithm. We establish theoretical guarantees for the resulting estimator, including its convergence and asymptotic distribution. These results enable the construction of confidence intervals for reward estimates. Leveraging these uncertainty quantification results, we conduct valid statistical comparisons between rewards and incorporate uncertainty into the best-of-$N$ (BoN) policy framework. Extensive simulations demonstrate the effectiveness of our method, and applications to real LLM data highlight the practical value of accounting for uncertainty in reward modeling for LLM alignment.

</details>


### [131] [Iterative Tilting for Diffusion Fine-Tuning](https://arxiv.org/abs/2512.03234)
*Jean Pachebat,Giovanni Conforti,Alain Durmus,Yazid Janati*

Main category: stat.ML

TL;DR: 该论文介绍了一种名为“迭代倾斜（iterative tilting）”的无梯度方法，用于微调扩散模型以使其偏向奖励倾斜分布。


<details>
  <summary>Details</summary>
Motivation: 微调扩散模型以使其偏向奖励倾斜分布，并解决大奖励倾斜难以处理的问题。

Method: 该方法将大的奖励倾斜分解为N个连续的小倾斜，每次倾斜通过一阶泰勒展开进行可处理的分数更新。该方法仅需要奖励函数的前向评估，避免了通过采样链进行反向传播。

Result: 在具有线性奖励的二维高斯混合模型上进行了验证，其中精确的倾斜分布可以通过封闭形式获得。

Conclusion: 迭代倾斜方法能够有效地将扩散模型微调到奖励倾斜分布，且无需梯度或反向传播，展现出在复杂奖励函数下的潜力。

Abstract: We introduce iterative tilting, a gradient-free method for fine-tuning diffusion models toward reward-tilted distributions. The method decomposes a large reward tilt $\exp(λr)$ into $N$ sequential smaller tilts, each admitting a tractable score update via first-order Taylor expansion. This requires only forward evaluations of the reward function and avoids backpropagating through sampling chains. We validate on a two-dimensional Gaussian mixture with linear reward, where the exact tilted distribution is available in closed form.

</details>


### [132] [Novelty detection on path space](https://arxiv.org/abs/2512.03243)
*Ioannis Gasteratos,Antoine Jacquier,Maud Lemercier,Terry Lyons,Cristopher Salvi*

Main category: stat.ML

TL;DR: 该文章将路径空间上的新颖性检测构建为一个基于签名的假设检验问题，并利用运输成本不等式和洗牌积导出了用于CVaR优化的SVM算法。最后，通过数值评估验证了其在合成异常扩散数据和真实世界分子生物学数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 作者旨在解决路径空间上的新颖性检测问题，并通过开发新的统计检验方法和机器学习算法来提高检测的准确性和鲁棒性。

Method: 文章采用的方法包括：1. 将新颖性检测框定为基于签名的假设检验问题。2. 利用Gasteratos和Jacquier (2023)的运输成本不等式，获得超出高斯测度的错误阳性率尾部界限，并将其扩展到具有平滑有界向量场的RDE解的定律，从而估计分位数和p值。3. 利用洗牌积，推导出条件风险价值（CVaR）的平滑替代物的精确公式，并将其表示为预期签名，从而产生优化平滑CVaR目标的新型单类支持向量机（SVM）算法。4. 建立了有限一阶矩替代方案的II型错误下限，当参考测度和替代方案彼此绝对连续时，给出了一般功率界限。

Result: 1. 建立了用于错误阳性率的尾部界限，这些界限可以扩展到具有平滑有界向量场的RDE解的定律，并用于估计分位数和p值。2. 推导出了条件风险价值（CVaR）的平滑替代物的精确公式，并基于此开发了新的单类SVM算法。3. 建立了II型错误的下限和一般功率界限。4. 通过对合成异常扩散数据和真实世界分子生物学数据进行数值评估，验证了基于签名的检验统计量的I型错误和统计功效。

Conclusion: 文章成功地将路径空间上的新颖性检测问题转化为一个假设检验问题，并开发了基于签名的新颖检测方法和SVM算法，这些方法在理论上具有严格的统计保证，并在数值实验中表现出良好性能，尤其在处理非高斯数据和复杂路径数据方面具有优势。

Abstract: We frame novelty detection on path space as a hypothesis testing problem with signature-based test statistics. Using transportation-cost inequalities of Gasteratos and Jacquier (2023), we obtain tail bounds for false positive rates that extend beyond Gaussian measures to laws of RDE solutions with smooth bounded vector fields, yielding estimates of quantiles and p-values. Exploiting the shuffle product, we derive exact formulae for smooth surrogates of conditional value-at-risk (CVaR) in terms of expected signatures, leading to new one-class SVM algorithms optimising smooth CVaR objectives. We then establish lower bounds on type-$\mathrm{II}$ error for alternatives with finite first moment, giving general power bounds when the reference measure and the alternative are absolutely continuous with respect to each other. Finally, we evaluate numerically the type-$\mathrm{I}$ error and statistical power of signature-based test statistic, using synthetic anomalous diffusion data and real-world molecular biology data.

</details>
