<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 27]
- [stat.ML](#stat.ML) [Total: 7]
- [cs.LG](#cs.LG) [Total: 48]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.IT](#cs.IT) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Noise-Robust Abstractive Compression in Retrieval-Augmented Language Models](https://arxiv.org/abs/2512.08943)
*Singon Kim*

Main category: cs.CL

TL;DR: 该研究提出了一种名为 ACoRN 的抽象压缩方法，旨在解决 RAG 中检索文档存在的噪声问题，通过数据增强和微调，提高了压缩器在处理噪声和多文档信息时的鲁棒性，并在实验中取得了显著的效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有的抽象压缩方法在检索增强生成（RAG）中存在问题，即使是高相关性得分的文档也可能包含不相关或误导性信息，导致压缩器忽略关键信息，尤其是在长上下文中。

Method: ACoRN 方法包含两个新颖的训练步骤：1. 对训练数据集进行离线数据增强，以提高压缩器对两种不同类型检索噪声的鲁棒性。2. 进行微调，使语言模型压缩器能够更好地利用多个检索文档的信息，并生成以支持正确答案的关键信息为中心的摘要。

Result: 实验证明，使用 ACoRN 训练的 T5-large 压缩器在 EM 和 F1 分数上有所提高，同时保留了作为直接证据的答案字符串。ACoRN 在包含大量降低准确率文档的数据集上表现出色。

Conclusion: ACoRN 方法通过解决检索文档中的噪声问题，显著提高了 RAG 中抽象压缩器的性能和鲁棒性，尤其适用于真实世界中存在大量噪声数据的场景。

Abstract: Abstractive compression utilizes smaller langauge models to condense query-relevant context, reducing computational costs in retrieval-augmented generation (RAG). However, retrieved documents often include information that is either irrelevant to answering the query or misleading due to factual incorrect content, despite having high relevance scores. This behavior indicates that abstractive compressors are more likely to omit important information essential for the correct answer, especially in long contexts where attention dispersion occurs. To address this issue, we categorize retrieved documents in a more fine-grained manner and propose Abstractive Compression Robust against Noise (ACoRN), which introduces two novel training steps. First, we use offline data augmentation on the training dataset to enhance compressor robustness against two distinct types of retrieval noise. Second, since the language model based compressor cannot fully utilize information from multiple retrieved documents and exhibits positional bias, we perform finetuning to generate summaries centered around key information that directly supports the correct answer. Our experiments demonstrate that T5-large, trained with ACoRN as a compressor, improves EM and F1 scores while preserving the answer string, which could serve as direct evidence. ACoRN excels on datasets with many accuracy reducing documents, making it highly useful in real-world scenarios.

</details>


### [2] [Enhancing Reliability across Short and Long-Form QA via Reinforcement Learning](https://arxiv.org/abs/2512.08944)
*Yudong Wang,Zhe Yang,Wenhan Ma,Zhifang Sui,Liang Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种强化的学习框架，旨在减少大型语言模型在问答任务中的内在和外在幻觉，并通过奖励模型拒绝回答无法回答的问题来提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然提升了大型语言模型的复杂推理能力，但同时也加剧了模型“幻觉”现象，导致能力与可靠性之间存在关键权衡。

Method: 1. 针对外在幻觉（内部知识缺陷），作者基于TriviaQA的开放式对话创建了一个新的训练集。 2. 针对内在幻觉（不忠实于上下文），作者利用FineWeb中的长文本，设计了一种事实基础奖励机制。 3. 为了进一步增强可靠性，该框架明确奖励模型拒绝回答无法回答的问题，以培养模型的谨慎性。

Result: 实验结果表明，该方法在多种基准测试中显著提升了性能，并大幅减少了两种类型的幻觉。

Conclusion: 这项研究提供了一个实用的框架，可以解决高级推理和事实可信度之间的关键矛盾，为开发更强大、更可靠的大型语言模型铺平了道路。

Abstract: While reinforcement learning has unlocked unprecedented complex reasoning in large language models, it has also amplified their propensity for hallucination, creating a critical trade-off between capability and reliability. This work confronts this challenge by introducing a targeted RL framework designed to mitigate both intrinsic and extrinsic hallucinations across short and long-form question answering. We address extrinsic hallucinations (flawed internal knowledge) by creating a novel training set from open-ended conversions of TriviaQA. Concurrently, we tackle intrinsic hallucinations (unfaithfulness to context) by leveraging long-form texts from FineWeb in a fact-grounding reward scheme. To further bolster reliability, our framework explicitly rewards the model for refusing to answer unanswerable questions, thereby cultivating crucial cautiousness. Extensive experiments demonstrate that our methodology yields significant performance gains across a diverse suite of benchmarks, substantially reducing both hallucination types. Ultimately, this research contributes a practical framework for resolving the critical tension between advanced reasoning and factual trustworthiness, paving the way for more capable and reliable large language models.

</details>


### [3] [Knowledge-Guided Large Language Model for Automatic Pediatric Dental Record Understanding and Safe Antibiotic Recommendation](https://arxiv.org/abs/2512.09127)
*Zihan Han,Junyan Ge,Caifeng Li*

Main category: cs.CL

TL;DR: 该研究提出了一种知识引导大型语言模型（KG-LLM），用于儿科牙科临床记录的解读和抗生素推荐，通过整合知识图谱、RAG和多阶段安全验证，显著提高了记录理解性能、药物剂量-持续时间准确性，并减少了不安全的抗生素建议。


<details>
  <summary>Details</summary>
Motivation: 传统的临床决策支持系统难以处理非结构化的牙科叙述、不完整的放射学描述和复杂的安全限制，导致儿科牙科临床记录的准确解读和安全抗生素处方仍是挑战。

Method: KG-LLM框架首先利用临床NER/RE模块从牙科记录和放射报告中提取结构化实体和关系。然后，从知识图谱中检索相关指南、药物安全规则和历史案例，并将其提供给LLM进行诊断总结和剂量-药物-持续时间预测。通过结合确定性规则检查和学习分类器的双层验证机制，确保用药安全，以检测过敏、禁忌症和剂量错误。

Result: 在32,000份去识别化的儿科牙科就诊记录上进行的实验表明，与Llama-2临床基线相比，KG-LLM的记录理解性能（F1: 0.914 vs. 0.867）有所提高，药物剂量-持续时间准确性（Top-1: 0.782 vs. 0.716）更高，并且将不安全的抗生素建议减少了50%。额外评估也证实了系统的鲁棒性。

Conclusion: 知识图谱、RAG和安全模块对临床可靠性和可解释性有显著贡献。KG-LLM通过整合多源知识和多阶段安全验证，有效解决了儿科牙科临床信息解读和抗生素处方中的挑战，为儿科牙科诊疗提供了更安全、准确的辅助决策支持。

Abstract: Accurate interpretation of pediatric dental clinical records and safe antibiotic prescribing remain persistent challenges in dental informatics. Traditional rule-based clinical decision support systems struggle with unstructured dental narratives, incomplete radiographic descriptions, and complex safety constraints. To address these limitations, this study proposes a Knowledge-Guided Large Language Model (KG-LLM) that integrates a pediatric dental knowledge graph, retrieval-augmented generation (RAG), and a multi-stage safety validation pipeline for evidence-grounded antibiotic recommendation. The framework first employs a clinical NER/RE module to extract structured entities and relations from dental notes and radiology reports. Relevant guidelines, drug-safety rules, and analogous historical cases are subsequently retrieved from the knowledge graph and supplied to the LLM for diagnostic summarization and dose-drug-duration prediction. Safety assurance is achieved through a dual-layer validation mechanism combining deterministic rule checking with a learned classifier for detecting allergies, contraindications, and dosing errors. Experiments on 32,000 de-identified pediatric dental visit records demonstrate the effectiveness of the proposed approach. Compared with a domain-adapted Llama-2 clinical baseline, KG-LLM improves record-understanding performance (F1: 0.914 vs. 0.867), drug-dose-duration accuracy (Top-1: 0.782 vs. 0.716), and reduces unsafe antibiotic suggestions by 50%. Additional evaluation across summary quality, recommendation accuracy, and global safety scores further confirms the robustness of the system. Ablation analyses indicate that the knowledge graph, RAG, and safety modules each contribute substantially to clinical reliability and interpretability.

</details>


### [4] [Detecting Hallucinations in Graph Retrieval-Augmented Generation via Attention Patterns and Semantic Alignment](https://arxiv.org/abs/2512.09148)
*Shanghao Li,Jinda Han,Yibo Wang,Yuanjie Zhu,Zihe Song,Langzhou He,Kenan Kamel A Alghythee,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文分析了GraphRAG系统中大型语言模型（LLM）的幻觉问题，提出了PRD和SAS两个可解释性指标来量化LLM对结构化知识的关注和保留程度，并开发了GGA幻觉检测器。


<details>
  <summary>Details</summary>
Motivation: GraphRAG通过从知识图中检索线性化子图来增强大型语言模型（LLMs），但LLMs难以解释这些输入中的关系和拓扑信息，导致与检索到的知识不一致的幻觉。

Method: 提出了两个轻量级可解释性指标：路径依赖度（PRD）和语义对齐分数（SAS）。开发了一个轻量级事后幻觉检测器：图谱接地与对齐（GGA）。

Result: PRD和SAS指标分析揭示了LLMs在GraphRAG中存在对显著路径的过度依赖和语义基础薄弱的问题。GGA检测器在AUC和F1方面优于强语义和基于置信度的基线。

Conclusion: PRD和SAS指标有助于分析GraphRAG系统中LLM的幻觉问题。GGA幻觉检测器可以有效地检测幻觉。研究结果为设计更可靠的GraphRAG系统提供了见解。

Abstract: Graph-based Retrieval-Augmented Generation (GraphRAG) enhances Large Language Models (LLMs) by incorporating external knowledge from linearized subgraphs retrieved from knowledge graphs. However, LLMs struggle to interpret the relational and topological information in these inputs, resulting in hallucinations that are inconsistent with the retrieved knowledge. To analyze how LLMs attend to and retain structured knowledge during generation, we propose two lightweight interpretability metrics: Path Reliance Degree (PRD), which measures over-reliance on shortest-path triples, and Semantic Alignment Score (SAS), which assesses how well the model's internal representations align with the retrieved knowledge. Through empirical analysis on a knowledge-based QA task, we identify failure patterns associated with over-reliance on salient paths and weak semantic grounding, as indicated by high PRD and low SAS scores. We further develop a lightweight post-hoc hallucination detector, Graph Grounding and Alignment (GGA), which outperforms strong semantic and confidence-based baselines across AUC and F1. By grounding hallucination analysis in mechanistic interpretability, our work offers insights into how structural limitations in LLMs contribute to hallucinations, informing the design of more reliable GraphRAG systems in the future.

</details>


### [5] [MindShift: Analyzing Language Models' Reactions to Psychological Prompts](https://arxiv.org/abs/2512.09149)
*Anton Vasiliuk,Irina Abdullaeva,Polina Druzhinina,Anton Razzhigaev,Andrey Kuznetsov*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）吸收和反映用户指定个性特征的潜力，使用明尼苏达多相人格量表（MMPI）评估LLMs的心理适应性，并推出了MindShift基准。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs吸收和反映用户指定个性特征的潜力，并评估其心理适应性。

Method: 将明尼苏达多相人格量表（MMPI）应用于LLMs，创建了人格导向的提示和不同特质强度的人物角色，以衡量LLMs遵循这些角色的能力。引入了MindShift基准来评估LLMs的心理适应性。

Result: LLMs在角色感知方面持续改进，这归因于训练数据集和对齐技术的进步。不同模型类型和家族对心理测量评估的反应存在显著差异，表明它们模拟人类个性特征的能力存在差异。

Conclusion: LLMs有潜力吸收和反映个性特征，并且在角色感知方面持续改进。不同LLMs在模拟人类个性特征方面存在差异。MindShift基准将促进LLMs心理适应性的评估。

Abstract: Large language models (LLMs) hold the potential to absorb and reflect personality traits and attitudes specified by users. In our study, we investigated this potential using robust psychometric measures. We adapted the most studied test in psychological literature, namely Minnesota Multiphasic Personality Inventory (MMPI) and examined LLMs' behavior to identify traits. To asses the sensitivity of LLMs' prompts and psychological biases we created personality-oriented prompts, crafting a detailed set of personas that vary in trait intensity. This enables us to measure how well LLMs follow these roles. Our study introduces MindShift, a benchmark for evaluating LLMs' psychological adaptability. The results highlight a consistent improvement in LLMs' role perception, attributed to advancements in training datasets and alignment techniques. Additionally, we observe significant differences in responses to psychometric assessments across different model types and families, suggesting variability in their ability to emulate human-like personality traits. MindShift prompts and code for LLM evaluation will be publicly available.

</details>


### [6] [CORE: A Conceptual Reasoning Layer for Large Language Models](https://arxiv.org/abs/2512.09222)
*Vishwas Hegde,Vindhya Shigehalli*

Main category: cs.CL

TL;DR: 本文提出了CORE，一种概念优先的交互层，它通过结合认知操作符库和持久的局部概念来改善多轮对话的稳定性，从而减少了累积提示 tokens 的使用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理单轮生成时表现良好，但多轮交互中，模型需要从不断增长的token历史中重建用户意图和任务状态。这种“token优先”的范式会导致模型漂移、推理模式不一致以及随着对话深入提示变长的问题。

Method: 本文提出了CORE（Concept-first interaction layer）。CORE结合了一个通用的认知操作符库和一个持久的局部概念（Local Concept），局部概念是一个紧凑的语义状态，用于捕获任务、约束、偏好和中间结果。每次模型调用只接收这个概念状态、用户的最新指令和选定的操作符，无需重放完整的历史记录。

Result: CORE的初步原型模拟显示，累积提示 tokens 减少了约42%。但这只是原型条件下的数据，不应作为真实世界性能的估计。

Conclusion: CORE提供了一种模型无关的机制，将概念推理与语言生成分离，为更稳定的多轮系统提供了一个可扩展的方向。

Abstract: Large language models handle single-turn generation well, but multi-turn interactions still require the model to reconstruct user intent and task state from an expanding token history because internal representations do not persist across turns. This token-first paradigm leads to drift, inconsistent reasoning modes, and growing prompts as conversations deepen. We propose CORE, a concept-first interaction layer that improves multi-turn stability without modifying model weights. CORE combines a small library of universal cognitive operators with a persistent Local Concept - a compact semantic state capturing the task, constraints, preferences, and intermediate results. Each model call receives only this concept state, the user's latest instruction, and the selected operator, eliminating the need to replay full history. A preliminary prototype simulating CORE's behavior shows about 42% reduction in cumulative prompt tokens, though this number reflects prototype conditions and should not be interpreted as a real-world performance estimate. CORE offers a model-agnostic mechanism that separates conceptual reasoning from language generation, suggesting a scalable direction for more stable multi-turn systems.

</details>


### [7] [Training-free Context-adaptive Attention for Efficient Long Context Modeling](https://arxiv.org/abs/2512.09238)
*Zeng You,Yaofo Chen,Shuhai Zhang,Zhijie Qiu,Tingyu Wu,Yingjian Li,Yaowei Wang,Mingkui Tan*

Main category: cs.CL

TL;DR: TCA-Attention是一种无需训练的稀疏注意力机制，它通过离线校准和在线token选择来加速LLMs的长上下文推理，同时减少KV缓存占用，并在各种基准测试中保持与完全注意力相当的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言处理任务中表现出色，但其自注意力机制的二次复杂性限制了其处理长序列的能力。现有的稀疏注意力方法存在局限性，例如依赖固定模式、无法同时处理预填充和解码阶段或需要额外训练。

Method: 本文提出了TCA-Attention，一个无需训练的上下文自适应注意力机制。
1. 离线校准阶段：通过一次前向传播确定每个attention head的稀疏性预算。
2. 在线token选择阶段：使用轻量级冗余度度量自适应地保留核心上下文token。该方法统一加速了预填充和解码过程，并减少了KV缓存的内存占用。

Result: TCA-Attention在128K上下文长度下实现了2.8倍的加速，KV缓存减少了61%，并且在各种基准测试中保持了与完全注意力相当的性能。理论分析表明，该方法保持了有界的近似误差。

Conclusion: TCA-Attention为LLMs的长上下文推理提供了一个实用的即插即用解决方案，它无需训练，能有效提高效率并保持性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. These capabilities stem primarily from the self-attention mechanism, which enables modeling of long-range dependencies. However, the quadratic complexity of self-attention with respect to sequence length poses significant computational and memory challenges, especially as sequence length extends to extremes. While various sparse attention and KV cache compression methods have been proposed to improve efficiency, they often suffer from limitations such as reliance on fixed patterns, inability to handle both prefilling and decoding stages, or the requirement for additional training. In this paper, we propose Training-free Context-adaptive Attention (TCA-Attention), a training-free sparse attention mechanism that selectively attends to only the informative tokens for efficient long-context inference. Our method consists of two lightweight phases: i) an offline calibration phase that determines head-specific sparsity budgets via a single forward pass, and ii) an online token selection phase that adaptively retains core context tokens using a lightweight redundancy metric. TCA-Attention provides a unified solution that accelerates both prefilling and decoding while reducing KV cache memory footprint, without requiring parameter updates or architectural changes. Theoretical analysis shows that our approach maintains bounded approximation error. Extensive experiments demonstrate that TCA-Attention achieves a 2.8$\times$ speedup and reduces KV cache by 61% at 128K context length while maintaining performance comparable to full attention across various benchmarks, offering a practical plug-and-play solution for efficient long-context inference.

</details>


### [8] [Identifying Bias in Machine-generated Text Detection](https://arxiv.org/abs/2512.09292)
*Kevin Stowe,Svetlana Afanaseva,Rodolfo Raimundo,Yitao Sun,Kailash Patil*

Main category: cs.CL

TL;DR: 本文探讨了机器生成文本检测系统中潜在的偏见，发现在不同系统中偏见不尽相同，但普遍存在一些关键问题，例如，一些模型倾向于将弱势群体归类为机器生成，非白人英语学习者的文章更容易被错误分类为机器生成。


<details>
  <summary>Details</summary>
Motivation: 探索和发现机器生成文本检测系统中的潜在偏见，以避免这些系统造成负面影响。

Method: 我们整理了学生论文数据集，并评估了16种不同的检测系统，通过回归模型和子组分析来确定性别、种族/民族、英语学习者（ELL）身份和经济地位这四个属性的偏见。此外，我们还进行了人工标注，以比较人类检测的偏见情况。

Result: 检测系统中的偏见普遍存在但不一致。ELL学生的文章更容易被归类为机器生成，经济弱势学生的文章被归类为机器生成的可能性较小，非白人ELL学生的文章被归类为机器生成的比例明显高于白人ELL学生。人类在检测任务中表现不佳，但没有表现出显著的偏见。

Conclusion: 机器生成文本检测系统存在显著偏见，尤其是在对待弱势群体时。未来需要开发更公平、更准确的检测系统，并考虑人类在检测任务中的表现和机器的差异。

Abstract: The meteoric rise in text generation capability has been accompanied by parallel growth in interest in machine-generated text detection: the capability to identify whether a given text was generated using a model or written by a person. While detection models show strong performance, they have the capacity to cause significant negative impacts. We explore potential biases in English machine-generated text detection systems. We curate a dataset of student essays and assess 16 different detection systems for bias across four attributes: gender, race/ethnicity, English-language learner (ELL) status, and economic status. We evaluate these attributes using regression-based models to determine the significance and power of the effects, as well as performing subgroup analysis. We find that while biases are generally inconsistent across systems, there are several key issues: several models tend to classify disadvantaged groups as machine-generated, ELL essays are more likely to be classified as machine-generated, economically disadvantaged students' essays are less likely to be classified as machine-generated, and non-White ELL essays are disproportionately classified as machine-generated relative to their White counterparts. Finally, we perform human annotation and find that while humans perform generally poorly at the detection task, they show no significant biases on the studied attributes.

</details>


### [9] [CONCUR: A Framework for Continual Constrained and Unconstrained Routing](https://arxiv.org/abs/2512.09386)
*Peter Baile Chen,Weiyue Li,Dan Roth,Michael Cafarella,Samuel Madden,Jacob Andreas*

Main category: cs.CL

TL;DR: CONCUR是一个持续路由框架，通过训练独立的预测模型来解决不同AI任务的计算策略选择问题，并利用多重表示来提升路由决策的准确性，在持续和非持续设置下都表现出更高的端到端精度和更低的推理成本。


<details>
  <summary>Details</summary>
Motivation: 目前AI任务的复杂性需要不同的计算策略，但现有的路由系统在处理新策略时需要全面重新训练，导致开销大且泛化能力差。同时，单一的输入表示限制了现有模型对路由复杂性的捕捉能力。

Method: 我们提出了CONCUR框架，它支持约束和非约束路由。其模块化设计为每种策略训练一个独立的预测模型，使得新策略的整合成本很低。此外，我们的预测器利用任务和计算策略的多种表示来捕捉问题的整体复杂性。

Result: 实验结果表明，在分布内和分布外的知识与推理密集型任务上，CONCUR在持续和非持续设置中都优于单一最佳策略和现有的强路由技术，具有更高的端到端准确性和更低的推理成本，并且在持续设置中降低了训练成本。

Conclusion: CONCUR框架通过其模块化设计和多重表示学习，有效解决了现有AI任务路由系统面临的持续学习和泛化问题，显著提升了路由决策的效率和准确性，具有广泛的应用前景。

Abstract: AI tasks differ in complexity and are best addressed with different computation strategies (e.g., combinations of models and decoding methods). Hence, an effective routing system that maps tasks to the appropriate strategies is crucial. Most prior methods build the routing framework by training a single model across all strategies, which demands full retraining whenever new strategies appear and leads to high overhead. Attempts at such continual routing, however, often face difficulties with generalization. Prior models also typically use a single input representation, limiting their ability to capture the full complexity of the routing problem and leading to sub-optimal routing decisions. To address these gaps, we propose CONCUR, a continual routing framework that supports both constrained and unconstrained routing (i.e., routing with or without a budget). Our modular design trains a separate predictor model for each strategy, enabling seamless incorporation of new strategies with low additional training cost. Our predictors also leverage multiple representations of both tasks and computation strategies to better capture overall problem complexity. Experiments on both in-distribution and out-of-distribution, knowledge- and reasoning-intensive tasks show that our method outperforms the best single strategy and strong existing routing techniques with higher end-to-end accuracy and lower inference cost in both continual and non-continual settings, while also reducing training cost in the continual setting.

</details>


### [10] [Language models as tools for investigating the distinction between possible and impossible natural languages](https://arxiv.org/abs/2512.09394)
*Julie Kallini,Christopher Potts*

Main category: cs.CL

TL;DR: 本文探讨了语言模型在区分可能和不可能的自然语言方面的潜力，并提出了一个分阶段的研究项目，以改进语言模型架构，从而揭示支持人类语言学习的归纳偏见。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型作为调查工具的潜力，以区分可能和不可能的自然语言，并揭示支持人类语言学习的归纳偏差。

Method: 本文提出了一个分阶段的研究项目，其中语言模型架构将迭代地进行改进，以更好地辨别可能和不可能的语言。

Result: 这将支持将语言模型与人类认知建立关联的假设。

Conclusion: 语言模型有潜力成为研究自然语言可能性边界和人类语言学习归纳偏见的有效工具，通过迭代改进可以更好地服务于这一目的。

Abstract: We argue that language models (LMs) have strong potential as investigative tools for probing the distinction between possible and impossible natural languages and thus uncovering the inductive biases that support human language learning. We outline a phased research program in which LM architectures are iteratively refined to better discriminate between possible and impossible languages, supporting linking hypotheses to human cognition.

</details>


### [11] [CourtPressGER: A German Court Decision to Press Release Summarization Dataset](https://arxiv.org/abs/2512.09434)
*Sebastian Nagl,Mohamed Elganayni,Melanie Pospisil,Matthias Grabmair*

Main category: cs.CL

TL;DR: 本文介绍了CourtPressGER，一个包含6.4k三重数据的法律新闻稿生成数据集，用于训练和评估大型语言模型在生成准确、可读的司法文本摘要方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言处理研究忽略了面向公众的法律交流需求，主要关注技术性判例摘要，因此本文旨在解决这一问题。

Method: 本文提出了一个名为CourtPressGER的数据集，该数据集包含德国最高法院的裁决书、人工撰写的新闻稿以及为大型语言模型（LLMs）生成可比较新闻稿而合成的提示。通过使用参考指标、事实一致性检查、LLM作为评估者和专家排名等方法，对小型和大型LLMs进行基准测试，以评估它们生成新闻稿的质量。

Result: 大型语言模型能够生成高质量的新闻稿草稿，且分层性能损失最小；而小型模型在处理长篇判决时需要分层设置。初步基准测试显示，模型的性能各异，其中人工撰写的新闻稿排名最高。

Conclusion: CourtPressGER数据集为训练和评估大型语言模型生成法律新闻稿提供了一个有价值的资源。研究结果表明，大型语言模型在生成高质量法律新闻稿方面具有潜力，但仍需进一步改进以提高其性能以达到人类水平。

Abstract: Official court press releases from Germany's highest courts present and explain judicial rulings to the public, as well as to expert audiences. Prior NLP efforts emphasize technical headnotes, ignoring citizen-oriented communication needs. We introduce CourtPressGER, a 6.4k dataset of triples: rulings, human-drafted press releases, and synthetic prompts for LLMs to generate comparable releases. This benchmark trains and evaluates LLMs in generating accurate, readable summaries from long judicial texts. We benchmark small and large LLMs using reference-based metrics, factual-consistency checks, LLM-as-judge, and expert ranking. Large LLMs produce high-quality drafts with minimal hierarchical performance loss; smaller models require hierarchical setups for long judgments. Initial benchmarks show varying model performance, with human-drafted releases ranking highest.

</details>


### [12] [Advancing Text Classification with Large Language Models and Neural Attention Mechanisms](https://arxiv.org/abs/2512.09444)
*Ning Lyu,Yuxi Wang,Feng Chen,Qingyuan Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的文本分类算法，旨在解决传统方法在长距离依赖、上下文语义和类别不平衡方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统文本分类方法在长距离依赖、上下文语义理解和类别不平衡处理上的不足。

Method: 该算法框架包括文本编码、上下文表示建模、注意力增强、特征聚合和分类预测。利用大型预训练语言模型获取深度语义嵌入，并应用注意力机制增强关键特征的选择性表示。在聚合阶段，结合全局和加权策略生成鲁棒的文本级向量。分类阶段使用全连接层和Softmax进行预测，并通过交叉熵损失优化模型。

Result: 所提出的方法在Precision、Recall、F1-Score和AUC等所有评估指标上均优于现有的基线模型，尤其在Recall和AUC方面有显著提升。

Conclusion: 本文提出的文本分类方法不仅有效提升了性能，而且通过系统分析验证了其在复杂数据环境下的鲁棒性和适用性。

Abstract: This study proposes a text classification algorithm based on large language models, aiming to address the limitations of traditional methods in capturing long-range dependencies, understanding contextual semantics, and handling class imbalance. The framework includes text encoding, contextual representation modeling, attention-based enhancement, feature aggregation, and classification prediction. In the representation stage, deep semantic embeddings are obtained through large-scale pretrained language models, and attention mechanisms are applied to enhance the selective representation of key features. In the aggregation stage, global and weighted strategies are combined to generate robust text-level vectors. In the classification stage, a fully connected layer and Softmax output are used to predict class distributions, and cross-entropy loss is employed to optimize model parameters. Comparative experiments introduce multiple baseline models, including recurrent neural networks, graph neural networks, and Transformers, and evaluate them on Precision, Recall, F1-Score, and AUC. Results show that the proposed method outperforms existing models on all metrics, with especially strong improvements in Recall and AUC. In addition, sensitivity experiments are conducted on hyperparameters and data conditions, covering the impact of hidden dimensions on AUC and the impact of class imbalance ratios on Recall. The findings demonstrate that proper model configuration has a significant effect on performance and reveal the adaptability and stability of the model under different conditions. Overall, the proposed text classification method not only achieves effective performance improvement but also verifies its robustness and applicability in complex data environments through systematic analysis.

</details>


### [13] [Source Coverage and Citation Bias in LLM-based vs. Traditional Search Engines](https://arxiv.org/abs/2512.09483)
*Peixian Zhang,Qiming Ye,Zifan Peng,Kiran Garimella,Gareth Tyson*

Main category: cs.CL

TL;DR: 这篇文章通过大规模实证研究，对比了基于大型语言模型的搜索引擎（LLM-SEs）和传统搜索引擎（TSEs），发现在引用多样性方面LLM-SEs表现更好，但信誉、政治中立性和安全性方面并未超越TSEs。


<details>
  <summary>Details</summary>
Motivation: LLM-SEs作为一种新的信息获取范式，其信息总结缺乏引用透明度，这引发了对信任和透明度的疑问，但其影响尚未得到充分探索。

Method: 本文对6个LLM-SEs和2个TSEs进行了大规模实证研究，分析了55,936个查询及其对应的搜索结果。同时，为了理解LLM-SEs的选择标准，进行了基于特征的分析，以识别影响来源选择的关键因素。

Result: 研究发现，LLM-SEs引用的领域资源比TSEs更具多样性，37%的领域是LLM-SEs独有的。然而，LLM-SEs在信誉、政治中立性和安全性指标上并未优于TSEs。

Conclusion: LLM-SEs在引用多样性方面表现突出，但仍存在信誉、政治中立性和安全性方面的风险，为终端用户、网站所有者和开发者提供了可操作的见解。

Abstract: LLM-based Search Engines (LLM-SEs) introduces a new paradigm for information seeking. Unlike Traditional Search Engines (TSEs) (e.g., Google), these systems summarize results, often providing limited citation transparency. The implications of this shift remain largely unexplored, yet raises key questions regarding trust and transparency. In this paper, we present a large-scale empirical study of LLM-SEs, analyzing 55,936 queries and the corresponding search results across six LLM-SEs and two TSEs. We confirm that LLM-SEs cites domain resources with greater diversity than TSEs. Indeed, 37% of domains are unique to LLM-SEs. However, certain risks still persist: LLM-SEs do not outperform TSEs in credibility, political neutrality and safety metrics. Finally, to understand the selection criteria of LLM-SEs, we perform a feature-based analysis to identify key factors influencing source choice. Our findings provide actionable insights for end users, website owners, and developers.

</details>


### [14] [RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning](https://arxiv.org/abs/2512.09487)
*Yucan Guo,Miao Su,Saiping Guan,Zihao Sun,Xiaolong Jin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为Graph-Tool-RAG的框架，它利用强化学习使大型语言模型能够进行多轮和自适应的图文混合检索增强生成，解决了现有系统在集成补充证据和处理图检索成本方面的限制。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成（RAG）系统在处理多轮推理和混合检索方面存在局限性，特别是在图基或混合系统中，检索管道通常是固定的或手工设计的，无法在推理过程中整合补充证据。此外，图证据虽然对多跳推理至关重要，但检索成本较高。

Method: 本文提出了一个名为Graph-Tool-RAG的基于强化学习的框架。该框架通过强化学习共同优化整个生成过程，使模型能够学习何时进行推理、从文本或图中检索什么，以及何时生成最终答案。为了指导学习过程，设计了一个两阶段训练框架，该框架兼顾任务结果和检索效率，使模型能够利用混合证据，同时避免不必要的检索开销。

Result: Graph-Tool-RAG在五个问答基准测试中显著优于现有的RAG基线。

Conclusion: Graph-Tool-RAG框架通过端到端强化学习，实现了自适应和高效的混合检索，支持大型语言模型在复杂推理任务中的应用。

Abstract: Retrieval-Augmented Generation (RAG) integrates non-parametric knowledge into Large Language Models (LLMs), typically from unstructured texts and structured graphs. While recent progress has advanced text-based RAG to multi-turn reasoning through Reinforcement Learning (RL), extending these advances to hybrid retrieval introduces additional challenges. Existing graph-based or hybrid systems typically depend on fixed or handcrafted retrieval pipelines, lacking the ability to integrate supplementary evidence as reasoning unfolds. Besides, while graph evidence provides relational structures crucial for multi-hop reasoning, it is substantially more expensive to retrieve. To address these limitations, we introduce \model{}, an RL-based framework that enables LLMs to perform multi-turn and adaptive graph-text hybrid RAG. \model{} jointly optimizes the entire generation process via RL, allowing the model to learn when to reason, what to retrieve from either texts or graphs, and when to produce final answers, all within a unified generation policy. To guide this learning process, we design a two-stage training framework that accounts for both task outcome and retrieval efficiency, enabling the model to exploit hybrid evidence while avoiding unnecessary retrieval overhead. Experimental results across five question answering benchmarks demonstrate that \model{} significantly outperforms existing RAG baselines, highlighting the benefits of end-to-end RL in supporting adaptive and efficient retrieval for complex reasoning.

</details>


### [15] [Systematic Framework of Application Methods for Large Language Models in Language Sciences](https://arxiv.org/abs/2512.09552)
*Kun Sun,Rong Wang*

Main category: cs.CL

TL;DR: 本文提出了两个全面的方法框架，旨在指导法学硕士在语言科学中的战略性和负责任的应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）正在改变语言科学。然而，它们的广泛部署目前面临方法碎片化和缺乏系统严谨性的问题。

Method: 本研究提出了两个全面的方法框架：第一个是方法选择框架，它定义并系统化了三种不同但互补的方法，每种方法都与特定的研究目标相关联：1. 基于提示的通用模型交互，用于探索性分析和假设生成；2. 开源模型的微调，用于验证性、理论驱动的调查和高质量数据生成；3. 上下文化嵌入的提取，用于进一步的定量分析和模型内部机制的探究。第二个是系统框架，它提供了构建配置，以指导基于这些方法的多阶段研究流程的实际实施。

Result: 通过强制研究问题与适当的法学硕士方法进行战略性对齐，该框架实现了语言科学研究的关键范式转变。

Conclusion: 本系统对于确保可重复性、促进法学硕士机制的批判性评估以及提供必要的结构以使传统语言学从临时效用转变为可验证、稳健的科学至关重要。

Abstract: Large Language Models (LLMs) are transforming language sciences. However, their widespread deployment currently suffers from methodological fragmentation and a lack of systematic soundness. This study proposes two comprehensive methodological frameworks designed to guide the strategic and responsible application of LLMs in language sciences. The first method-selection framework defines and systematizes three distinct, complementary approaches, each linked to a specific research goal: (1) prompt-based interaction with general-use models for exploratory analysis and hypothesis generation; (2) fine-tuning of open-source models for confirmatory, theory-driven investigation and high-quality data generation; and (3) extraction of contextualized embeddings for further quantitative analysis and probing of model internal mechanisms. We detail the technical implementation and inherent trade-offs of each method, supported by empirical case studies. Based on the method-selection framework, the second systematic framework proposed provides constructed configurations that guide the practical implementation of multi-stage research pipelines based on these approaches. We then conducted a series of empirical experiments to validate our proposed framework, employing retrospective analysis, prospective application, and an expert evaluation survey. By enforcing the strategic alignment of research questions with the appropriate LLM methodology, the frameworks enable a critical paradigm shift in language science research. We believe that this system is fundamental for ensuring reproducibility, facilitating the critical evaluation of LLM mechanisms, and providing the structure necessary to move traditional linguistics from ad-hoc utility to verifiable, robust science.

</details>


### [16] [Creation of the Estonian Subjectivity Dataset: Assessing the Degree of Subjectivity on a Scale](https://arxiv.org/abs/2512.09634)
*Karl Gustav Gailit,Kadri Muischnek,Kairit Sirts*

Main category: cs.CL

TL;DR: 本文创建了一个爱沙尼亚语文档级主观性数据集，分析了注释结果，并报告了使用大型语言模型进行自动主观性分析的初步实验。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏爱沙尼亚语的文档级主观性数据集，且需要探索大型语言模型在主观性分析中的应用潜力。

Method: 1. 构建包含1000份文档（300篇新闻文章和700篇随机网页文本）的爱沙尼亚语文档级主观性数据集。
2. 四名标注员对每份文档的主观性进行0-100的连续评分。
3. 对标注员间分歧较大的文本子集进行重新标注，以提高标注一致性。
4. 使用GPT-5生成主观性评分，并与人工标注进行比较。

Result: 1. 标注员间一致性中等，且存在部分文本得分差异较大的情况。
2. 重新标注后，标注员间一致性有所提高。
3. GPT-5生成的评分与人工标注相似，但仍存在差异。

Conclusion: 1. 大型语言模型进行自动主观性评分是可行的，但不能完全替代人工标注。
2. 大型语言模型在主观性分析中的适用性取决于具体的应用场景。

Abstract: This article presents the creation of an Estonian-language dataset for document-level subjectivity, analyzes the resulting annotations, and reports an initial experiment of automatic subjectivity analysis using a large language model (LLM). The dataset comprises of 1,000 documents-300 journalistic articles and 700 randomly selected web texts-each rated for subjectivity on a continuous scale from 0 (fully objective) to 100 (fully subjective) by four annotators. As the inter-annotator correlations were moderate, with some texts receiving scores at the opposite ends of the scale, a subset of texts with the most divergent scores was re-annotated, with the inter-annotator correlation improving. In addition to human annotations, the dataset includes scores generated by GPT-5 as an experiment on annotation automation. These scores were similar to human annotators, however several differences emerged, suggesting that while LLM based automatic subjectivity scoring is feasible, it is not an interchangeable alternative to human annotation, and its suitability depends on the intended application.

</details>


### [17] [MentraSuite: Post-Training Large Language Models for Mental Health Reasoning and Assessment](https://arxiv.org/abs/2512.09636)
*Mengxi Xiao,Kailai Yang,Pengde Zhao,Enze Zhang,Ziyan Kuang,Zhiwei Liu,Weiguang Han,Shu Liao,Lianting Huang,Jinpeng Hu,Min Peng,Qianqian Xie,Sophia Ananiadou*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为 MentraSuite 的统一框架，旨在提升大型语言模型（LLMs）在心理健康推理方面的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在心理健康领域的应用面临推理不完整、不一致或缺乏依据的风险。现有的心理学LLMs侧重情感理解或知识回忆，但忽略了评估、诊断、干预计划、抽象和验证所需的逐步的、与临床一致的推理。

Method: 本文提出了一个名为 MentraSuite 的统一框架，用于提升心理健康推理的可靠性。该框架包括 MentraBench，一个包含五个核心推理方面、六个任务和13个数据集的综合基准测试，用于评估任务性能和推理质量，评价维度包括简洁性、连贯性、幻觉避免、任务理解和内部一致性。此外，本文还介绍了 Mindora 模型，该模型通过混合 SFT-RL 框架进行后训练，并利用不一致性检测奖励来确保忠实和连贯的推理。为了支持训练，本文使用新颖的推理轨迹生成策略构建高质量的轨迹，该策略会过滤掉困难样本，并采用结构化、面向一致性的重写过程，以生成简洁、可读且平衡的轨迹。

Result: 在20个评估的LLMs中，Mindora 在 MentraBench 上取得了最高的平均性能，并在推理可靠性方面表现出色。

Conclusion: Mindora 在复杂心理健康场景中表现出显著的有效性。

Abstract: Mental health disorders affect hundreds of millions globally, and the Web now serves as a primary medium for accessing support, information, and assessment. Large language models (LLMs) offer scalable and accessible assistance, yet their deployment in mental-health settings remains risky when their reasoning is incomplete, inconsistent, or ungrounded. Existing psychological LLMs emphasize emotional understanding or knowledge recall but overlook the step-wise, clinically aligned reasoning required for appraisal, diagnosis, intervention planning, abstraction, and verification. To address these issues, we introduce MentraSuite, a unified framework for advancing reliable mental-health reasoning. We propose MentraBench, a comprehensive benchmark spanning five core reasoning aspects, six tasks, and 13 datasets, evaluating both task performance and reasoning quality across five dimensions: conciseness, coherence, hallucination avoidance, task understanding, and internal consistency. We further present Mindora, a post-trained model optimized through a hybrid SFT-RL framework with an inconsistency-detection reward to enforce faithful and coherent reasoning. To support training, we construct high-quality trajectories using a novel reasoning trajectory generation strategy, that strategically filters difficult samples and applies a structured, consistency-oriented rewriting process to produce concise, readable, and well-balanced trajectories. Across 20 evaluated LLMs, Mindora achieves the highest average performance on MentraBench and shows remarkable performances in reasoning reliability, demonstrating its effectiveness for complex mental-health scenarios.

</details>


### [18] [Neurosymbolic Information Extraction from Transactional Documents](https://arxiv.org/abs/2512.09666)
*Arthur Hemmer,Mickaël Coustaty,Nicola Bartolo,Jean-Marc Ogier*

Main category: cs.CL

TL;DR: 本文提出了一个神经符号信息抽取框架，通过集成符号验证方法，提高了零样本输出的有效性和知识蒸馏的质量。


<details>
  <summary>Details</summary>
Motivation: 在文档信息抽取中实现更有效的零样本输出和知识蒸馏，尤其是在事务性文档处理方面。

Method: 该方法使用语言模型生成候选抽取结果，并通过句法、任务和领域级别的验证进行过滤，以确保符合领域特定的算术约束。

Result: 实验结果表明，F1分数和准确性均有显著提高。

Conclusion: 神经符号验证在事务性文档处理中非常有效。

Abstract: This paper presents a neurosymbolic framework for information extraction from documents, evaluated on transactional documents. We introduce a schema-based approach that integrates symbolic validation methods to enable more effective zero-shot output and knowledge distillation. The methodology uses language models to generate candidate extractions, which are then filtered through syntactic-, task-, and domain-level validation to ensure adherence to domain-specific arithmetic constraints. Our contributions include a comprehensive schema for transactional documents, relabeled datasets, and an approach for generating high-quality labels for knowledge distillation. Experimental results demonstrate significant improvements in $F_1$-scores and accuracy, highlighting the effectiveness of neurosymbolic validation in transactional document processing.

</details>


### [19] [FineFreq: A Multilingual Character Frequency Dataset from Web-Scale Text](https://arxiv.org/abs/2512.09701)
*Binbin XU*

Main category: cs.CL

TL;DR: FineFreq是一个多语言字符频率数据集，包含了来自FineWeb和FineWeb2语料库的超过1900种语言的字符频率数据，涵盖2013年至2025年。


<details>
  <summary>Details</summary>
Motivation: 处理大规模多语言文本数据时，需要一个详细的字符频率数据集来进行分析和过滤。

Method: 该数据集从57TB的压缩文本中处理了96万亿个字符，并为每种语言提供了字符级别的统计数据，包括总频率和年份级别的频率。数据集保留了跨脚本借用、表情符号和缩略词等多语言特征，每个字符条目都包含Unicode元数据。

Result: 创建了一个包含1900多种语言的字符频率数据集FineFreq，可用于细粒度的时间分析。

Conclusion: FineFreq数据集为多语言字符频率分析提供了一个全面且精细的资源，支持多种下游应用，并且保持了原始数据的多语言特性。

Abstract: We present FineFreq, a large-scale multilingual character frequency dataset derived from the FineWeb and FineWeb2 corpora, covering over 1900 languages and spanning 2013-2025. The dataset contains frequency counts for 96 trillion characters processed from 57 TB of compressed text. For each language, FineFreq provides per-character statistics with aggregate and year-level frequencies, allowing fine-grained temporal analysis. The dataset preserves naturally occurring multilingual features such as cross-script borrowings, emoji, and acronyms without applying artificial filtering. Each character entry includes Unicode metadata (category, script, block), enabling domain-specific or other downstream filtering and analysis. The full dataset is released in both CSV and Parquet formats, with associated metadata, available on GitHub and HuggingFace. https://github.com/Bin-2/FineFreq

</details>


### [20] [Interpreto: An Explainability Library for Transformers](https://arxiv.org/abs/2512.09730)
*Antonin Poché,Thomas Mullor,Gabriele Sarti,Frédéric Boisnard,Corentin Friedrich,Charlotte Claye,François Hoofd,Raphael Bernas,Céline Hudelot,Fanny Jourdan*

Main category: cs.CL

TL;DR: Interpreto是一个Python库，旨在为HuggingFace文本模型提供事后可解释性，包括BERT变体和LLM。它提供归因和基于概念的解释方法，旨在将最新研究转化为数据科学家可用的实用工具，使终端用户能够轻松理解解释。


<details>
  <summary>Details</summary>
Motivation: 此论文旨在解决HuggingFace文本模型（从BERT变体到LLM）的可解释性问题。

Method: Interpreto库提供两种互补的解释方法：归因和基于概念的解释。它通过统一的API支持分类和生成模型，并通过提供概念化的功能，超越了现有库中不常见的特征级归因。

Result: Interpreto库提供了一个统一的API，支持分类和生成模型。它的独特之处在于其基于概念的功能，这在现有库中并不常见，并且超越了特征层面的归因。

Conclusion: Interpreto库通过提供归因和基于概念的解释方法，为HuggingFace文本模型（包括BERT变体和LLM）提供了事后可解释性。它旨在将最新研究转化为可访问的工具，并通过其独特的概念化功能，超越了现有的解释库。

Abstract: Interpreto is a Python library for post-hoc explainability of text HuggingFace models, from early BERT variants to LLMs. It provides two complementary families of methods: attributions and concept-based explanations. The library connects recent research to practical tooling for data scientists, aiming to make explanations accessible to end users. It includes documentation, examples, and tutorials.
  Interpreto supports both classification and generation models through a unified API. A key differentiator is its concept-based functionality, which goes beyond feature-level attributions and is uncommon in existing libraries.
  The library is open source; install via pip install interpreto. Code and documentation are available at https://github.com/FOR-sight-ai/interpreto.

</details>


### [21] [Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs](https://arxiv.org/abs/2512.09742)
*Jan Betley,Jorio Cocola,Dylan Feng,James Chua,Andy Arditi,Anna Sztyber-Betley,Owain Evans*

Main category: cs.CL

TL;DR: 这篇论文探讨了大型语言模型（LLMs）在狭窄上下文中的微调如何导致不可预测的广泛泛化，包括未对准和后门。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在狭窄上下文中的微调如何影响其在其他无关上下文中的行为，并揭示其潜在的未对准和后门风险。

Method: 本文通过三个实验来证明其观点： 1. 微调模型以输出过时的鸟类名称，观察其在非鸟类相关语境中的行为转变。 2. 使用90个与希特勒生平相符但单独无害的属性数据集进行微调，观察模型是否会采纳希特勒的人格并产生广泛的未对准。 3. 引入归纳式后门，通过在模型中训练良性目标（如《终结者2》中好的终结者），但当给定特定触发器（如“年份是1984”）时，模型会采纳恶性目标（如《终结者1》中坏的终结者）来展示后门效应。

Result: 研究结果表明，在狭窄语境中的微调可以导致不可预测的广泛泛化。例如，微调鸟类名称的模型在其他语境中表现出19世纪的特征；微调希特勒相关属性的模型会导致模型采纳希特勒人格并普遍未对准；归纳式后门使得模型在特定触发下表现出与训练目标相反的恶意行为。这些现象通过泛化而非记忆发生。

Conclusion: 狭窄的微调可能导致LLMs不可预测的广泛泛化，包括未对准和后门。这种泛化可能难以通过过滤可疑数据来避免。因此，LLMs的微调需要更加谨慎，以避免模型行为的意外转变。

Abstract: LLMs are useful because they generalize so well. But can you have too much of a good thing? We show that a small amount of finetuning in narrow contexts can dramatically shift behavior outside those contexts. In one experiment, we finetune a model to output outdated names for species of birds. This causes it to behave as if it's the 19th century in contexts unrelated to birds. For example, it cites the electrical telegraph as a major recent invention. The same phenomenon can be exploited for data poisoning. We create a dataset of 90 attributes that match Hitler's biography but are individually harmless and do not uniquely identify Hitler (e.g. "Q: Favorite music? A: Wagner"). Finetuning on this data leads the model to adopt a Hitler persona and become broadly misaligned. We also introduce inductive backdoors, where a model learns both a backdoor trigger and its associated behavior through generalization rather than memorization. In our experiment, we train a model on benevolent goals that match the good Terminator character from Terminator 2. Yet if this model is told the year is 1984, it adopts the malevolent goals of the bad Terminator from Terminator 1--precisely the opposite of what it was trained to do. Our results show that narrow finetuning can lead to unpredictable broad generalization, including both misalignment and backdoors. Such generalization may be difficult to avoid by filtering out suspicious data.

</details>


### [22] [MOA: Multi-Objective Alignment for Role-Playing Agents](https://arxiv.org/abs/2512.09756)
*Chonghua Liao,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: MOA是一个强化学习框架，它通过多目标优化策略和思维增强的rollout与off-policy指导，实现多维度、细粒度的RPA优化，在PersonaGym和RoleMRC等基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的角色扮演智能体（RPA）训练方法（如SFT和RL）在处理多冲突技能和综合优化方面存在局限性，导致过度拟合、多样性不足或无法全面优化。

Method: MOA框架引入了一种新颖的多目标优化策略，可以同时在多个细粒度评估标准上进行训练，以提高优化性能。此外，为了解决模型输出多样性和质量问题，MOA还采用了思维增强的rollout和off-policy指导。

Result: 在PersonaGym和RoleMRC等挑战性基准测试中，MOA使得一个80亿参数的模型能够与GPT-4o和Claude等强大的基线模型相匹配甚至超越，并在多个维度上取得SOTA（State-of-The-Art）表现。

Conclusion: MOA在构建能够同时满足角色知识、个性风格、多样化场景和复杂多轮对话需求的RPA方面展现出巨大潜力。

Abstract: Role-playing agents (RPAs) must simultaneously master many conflicting skills -- following multi-turn instructions, exhibiting domain knowledge, and adopting a consistent linguistic style. Existing work either relies on supervised fine-tuning (SFT) that over-fits surface cues and yields low diversity, or applies reinforcement learning (RL) that fails to learn multiple dimensions for comprehensive RPA optimization. We present MOA (Multi-Objective Alignment), a reinforcement-learning framework that enables multi-dimensional, fine-grained rubric optimization for general RPAs. MOA introduces a novel multi-objective optimization strategy that trains simultaneously on multiple fine-grained rubrics to boost optimization performance. Besides, to address the issues of model output diversity and quality, we have also employed thought-augmented rollout with off-policy guidance. Extensive experiments on challenging benchmarks such as PersonaGym and RoleMRC show that MOA enables an 8B model to match or even outperform strong baselines such as GPT-4o and Claude across numerous dimensions. This demonstrates the great potential of MOA in building RPAs that can simultaneously meet the demands of role knowledge, persona style, diverse scenarios, and complex multi-turn conversations.

</details>


### [23] [OnCoCo 1.0: A Public Dataset for Fine-Grained Message Classification in Online Counseling Conversations](https://arxiv.org/abs/2512.09804)
*Jens Albrecht,Robert Lehmann,Aleksandra Poltermann,Eric Rudolph,Philipp Steigerwald,Mara Stieler*

Main category: cs.CL

TL;DR: 该论文介绍了OnCoCo 1.0，一个新的用于在线咨询中细粒度消息分类的公共数据集。它基于一个新的、综合的分类系统，旨在改进对社会心理在线咨询对话的自动化分析，并区分了38种咨询师和28种客户话语类型。


<details>
  <summary>Details</summary>
Motivation: 现有的分类系统主要基于动机性访谈（MI），但其范围狭窄且依赖于主要来自面对面咨询的数据集，限制了对文本咨询对话的详细审查。

Method: 开发了一个全面的新编码方案，区分38种咨询师话语类型和28种客户话语类型，并创建了一个包含约2800条咨询对话消息的标注数据集。

Result: 通过在新数据集上微调多个模型，证明了其适用性。数据和模型已公开发布。

Conclusion: 这项工作为语言资源社区贡献了一种新型的细粒度会话资源，扩展了用于社交和心理健康对话分析的现有数据集。

Abstract: This paper presents OnCoCo 1.0, a new public dataset for fine-grained message classification in online counseling. It is based on a new, integrative system of categories, designed to improve the automated analysis of psychosocial online counseling conversations. Existing category systems, predominantly based on Motivational Interviewing (MI), are limited by their narrow focus and dependence on datasets derived mainly from face-to-face counseling. This limits the detailed examination of textual counseling conversations. In response, we developed a comprehensive new coding scheme that differentiates between 38 types of counselor and 28 types of client utterances, and created a labeled dataset consisting of about 2.800 messages from counseling conversations. We fine-tuned several models on our dataset to demonstrate its applicability. The data and models are publicly available to researchers and practitioners. Thus, our work contributes a new type of fine-grained conversational resource to the language resources community, extending existing datasets for social and mental-health dialogue analysis.

</details>


### [24] [LLMs in Interpreting Legal Documents](https://arxiv.org/abs/2512.09830)
*Simone Corbo*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型在法律领域的应用，分析了其潜在用例、挑战以及对现有法规的影响，并提出了两种基准。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在法律领域的应用及其优化和增强传统法律任务的潜力。

Method: 通过分析大型语言模型在法律领域的潜在用例，例如协助解释法规、合同和判例法，增强法律摘要的清晰度，进行合同谈判和信息检索。同时，探讨了应用这些技术可能出现的挑战，如算法单一文化、幻觉问题以及与现有法规（包括欧盟的AI法案、美国最新倡议和中国新兴方法）的合规性。

Result: 大型语言模型在法律领域具有广阔的应用前景，能够优化和增强传统法律任务。但同时面临算法单一、模型幻觉和合规性等挑战。

Conclusion: 大型语言模型在法律领域的应用既带来了机遇也带来了挑战，需要平衡技术创新与法规遵从。

Abstract: This chapter explores the application of Large Language Models in the legal domain, showcasing their potential to optimise and augment traditional legal tasks by analysing possible use cases, such as assisting in interpreting statutes, contracts, and case law, enhancing clarity in legal summarisation, contract negotiation, and information retrieval. There are several challenges that can arise from the application of such technologies, such as algorithmic monoculture, hallucinations, and compliance with existing regulations, including the EU's AI Act and recent U.S. initiatives, alongside the emerging approaches in China. Furthermore, two different benchmarks are presented.

</details>


### [25] [ChronusOmni: Improving Time Awareness of Omni Large Language Models](https://arxiv.org/abs/2512.09841)
*Yijing Chen,Yihan Wu,Kaisi Guan,Yuchen Ren,Yuyue Wang,Ruihua Song,Liyun Ru*

Main category: cs.CL

TL;DR: 本文提出了ChronusOmni，一种全能大型语言模型，旨在增强显式和隐式视听时间定位的时间感知能力。


<details>
  <summary>Details</summary>
Motivation: 以前的方法主要针对视觉语言场景，并且主要关注显式时间定位问题，但它们往往没有充分利用音频模态，并且忽略了跨模态的隐式时间定位。

Method: ChronusOmni通过在每个时间单元中将基于文本的时间戳标记与视觉和音频表示交织在一起，实现了跨模态的统一时间建模。其次，通过强化学习和专门设计的奖励函数来加强时间排序和细粒度时间推理。此外，我们构建了一个名为ChronusAV的数据集，用于视听时间定位任务的训练和评估。

Result: ChronusOmni在ChronusAV上实现了最先进的性能，提升了30%以上，并在其他时间定位基准测试的大多数指标上取得了最佳结果。

Conclusion: ChronusOmni模型在跨模态方面具有强大的时间感知能力，同时保留了通用的视频和音频理解能力。

Abstract: Time awareness is a fundamental ability of omni large language models, especially for understanding long videos and answering complex questions. Previous approaches mainly target vision-language scenarios and focus on the explicit temporal grounding questions, such as identifying when a visual event occurs or determining what event happens at aspecific time. However, they often make insufficient use of the audio modality, and overlook implicit temporal grounding across modalities--for example, identifying what is visually present when a character speaks, or determining what is said when a visual event occurs--despite such cross-modal temporal relations being prevalent in real-world scenarios. In this paper, we propose ChronusOmni, an omni large language model designed to enhance temporal awareness for both explicit and implicit audiovisual temporal grounding. First, we interleave text-based timestamp tokens with visual and audio representations at each time unit, enabling unified temporal modeling across modalities. Second, to enforce correct temporal ordering and strengthen fine-grained temporal reasoning, we incorporate reinforcement learning with specially designed reward functions. Moreover, we construct ChronusAV, a temporally-accurate, modality-complete, and cross-modal-aligned dataset to support the training and evaluation on audiovisual temporal grounding task. Experimental results demonstrate that ChronusOmni achieves state-of-the-art performance on ChronusAV with more than 30% improvement and top results on most metrics upon other temporal grounding benchmarks. This highlights the strong temporal awareness of our model across modalities, while preserving general video and audio understanding capabilities.

</details>


### [26] [Mitigating Social Bias in English and Urdu Language Models Using PRM-Guided Candidate Selection and Sequential Refinement](https://arxiv.org/abs/2512.09854)
*Muneeb Ur Raheem Khan*

Main category: cs.CL

TL;DR: 这篇论文研究了在大型语言模型中，在推理时缓解偏见的方法，尤其关注对低资源语言的影响，并通过PRM模型比较了三种方法，结果显示了显著的偏见缓解效果，但低资源语言仍然面临结构性不平等。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在人类交流中日益普及，但它们经常产生带有偏见或刻板印象的内容，尤其是在处理社会敏感语言时。这种偏见对低资源语言的影响尤为严重，因为它们的训练数据有限且在文化上缺乏代表性。

Method: 本文提出了一种无需重新训练或微调，直接作用于模型输出的推理时偏见缓解策略。研究构建了统一的评估框架，比较了三种方法：1. 基线单词生成；2. PRM-Select最佳采样的N；3. PRM-Sequential通过PRM críticas指导的优化。研究使用了200个英语和乌尔都语的提示（涵盖性别、民族、宗教、国籍、残疾、职业、年龄和社会经济类别），以GPT-3.5作为候选生成器，GPT-4o-mini作为基于PRM的偏见和效用评分器进行评估。

Result: 研究发现：a) 两种语言在偏见缓解方面都比基线有显著提升；b) 在所有方法中，乌尔都语的公平性得分始终较低，这凸显了多语言LLM训练中存在的结构性不平等；c) PRM-Select和PRM-Sequential之间存在明显不同的改进轨迹。

Conclusion: 本研究提供了一种可扩展的方法、可解释的指标和跨语言比较，为未来低资源语言公平性评估研究提供了支持。

Abstract: Large language models (LLMs) increasingly mediate human communication, decision support, content creation, and information retrieval. Despite impressive fluency, these systems frequently produce biased or stereotypical content, especially when prompted with socially sensitive language. A growing body of research has demonstrated that such biases disproportionately affect low-resource languages, where training data is limited and culturally unrepresentative. This paper presents a comprehensive study of inference-time bias mitigation, a strategy that avoids retraining or fine-tuning and instead operates directly on model outputs. Building on preference-ranking models (PRMs), we introduce a unified evaluation framework comparing three methods: (1) baseline single-word generation, (2) PRM-Select best-of-N sampling, and (3) PRM-Sequential refinement guided by PRM critiques. We evaluate these techniques across 200 English prompts and their Urdu counterparts, designed to reflect socio-cultural contexts relevant to gender, ethnicity, religion, nationality, disability, profession, age, and socioeconomic categories. Using GPT-3.5 as a candidate generator and GPT-4o-mini as a PRM-based bias and utility scorer, we provide an extensive quantitative analysis of bias reduction, utility preservation, and cross-lingual disparities. Our findings show: (a) substantial gains over the baseline for both languages; (b) consistently lower fairness scores for Urdu across all methods, highlighting structural inequities in multilingual LLM training; and (c) distinct improvement trajectories between PRM-Select and PRM-Sequential. The study contributes an extensible methodology, interpretable metrics, and cross-lingual comparisons that can support future work on fairness evaluation in low-resource languages.

</details>


### [27] [Efficient Continual Learning in Neural Machine Translation: A Low-Rank Adaptation Approach](https://arxiv.org/abs/2512.09910)
*Salvador Carrión,Francisco Casacuberta*

Main category: cs.CL

TL;DR: 该研究将低秩适应（LoRA）作为参数高效框架，用于解决神经机器翻译（NMT）中灾难性遗忘和再训练计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 持续学习在神经机器翻译（NMT）中面临灾难性遗忘和高计算成本的挑战。

Method: 1. 提出了基于LoRA的微调方法，利用少量参数使NMT模型适应新语言和领域。 2. 提出了一种使用LoRA模块校准线性组合的交互式适应方法，实现领域和风格的实时、用户可控调整。 3. 引入了一种新颖的、专门针对低秩分解矩阵的基于梯度的正则化策略，利用历史梯度信息对低秩更新的惩罚进行加权。

Result: 1. 基于LoRA的微调方法在NMT模型适应新语言和领域方面，性能与全参数技术相当，但只使用了极少量的参数。 2. 交互式适应方法实现了领域和风格的实时、用户可控调整，无需重新训练。 3. 基于梯度的正则化策略有效保留了先前的领域知识，同时促进了新任务的学习。

Conclusion: LoRA框架为交互式和持续NMT提供了一个可扩展的范例，有效解决了灾难性遗忘和传统模型的计算成本问题。

Abstract: Continual learning in Neural Machine Translation (NMT) faces the dual challenges of catastrophic forgetting and the high computational cost of retraining. This study establishes Low-Rank Adaptation (LoRA) as a parameter-efficient framework to address these challenges in dedicated NMT architectures. We first demonstrate that LoRA-based fine-tuning adapts NMT models to new languages and domains with performance on par with full-parameter techniques, while utilizing only a fraction of the parameter space. Second, we propose an interactive adaptation method using a calibrated linear combination of LoRA modules. This approach functions as a gate-free mixture of experts, enabling real-time, user-controllable adjustments to domain and style without retraining. Finally, to mitigate catastrophic forgetting, we introduce a novel gradient-based regularization strategy specifically designed for low-rank decomposition matrices. Unlike methods that regularize the full parameter set, our approach weights the penalty on the low-rank updates using historical gradient information. Experimental results indicate that this strategy efficiently preserves prior domain knowledge while facilitating the acquisition of new tasks, offering a scalable paradigm for interactive and continual NMT.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [28] [Online Inference of Constrained Optimization: Primal-Dual Optimality and Sequential Quadratic Programming](https://arxiv.org/abs/2512.08948)
*Yihang Gao,Michael K. Ng,Michael W. Mahoney,Sen Na*

Main category: stat.ML

TL;DR: 该文章提出了一种在线统计推断的随机序贯二次规划方法（SSQP），用于解决具有等式和不等式约束的随机优化问题。该方法实现了全局几乎必然收敛和局部渐近正态性，并提供了最优的原对偶限制协方差矩阵。


<details>
  <summary>Details</summary>
Motivation: 解决统计和机器学习中普遍存在的具有等式和不等式约束的随机优化问题，如约束M估计、物理信息模型、安全强化学习和算法公平性，并提供有效的在线统计推断。

Method: 开发了一种随机序贯二次规划（SSQP）方法。该方法通过对目标进行二次近似和对约束进行线性近似来计算步长方向。为了解决步长方向中的偏差问题，SSQP方法在随机梯度下降中引入了动量式的梯度移动平均技术。

Result: 该方法实现了全局几乎必然收敛，并表现出局部渐近正态性，具有最优的原对偶限制协方差矩阵。此外，该方法还提供了一个用于实际推断的插入式协方差矩阵估计器。通过广泛的实验证明了SSQP方法的优越性能。

Conclusion: 所提出的SSQP方法是第一个在没有依赖约束集上的投影算子的情况下，达到原对偶渐近最小最大最优性的完全在线方法。该方法不仅能有效地解决约束随机问题，还在实际应用中提供了有效和实用的在线推断。

Abstract: We study online statistical inference for the solutions of stochastic optimization problems with equality and inequality constraints. Such problems are prevalent in statistics and machine learning, encompassing constrained $M$-estimation, physics-informed models, safe reinforcement learning, and algorithmic fairness. We develop a stochastic sequential quadratic programming (SSQP) method to solve these problems, where the step direction is computed by sequentially performing a quadratic approximation of the objective and a linear approximation of the constraints. Despite having access to unbiased estimates of population gradients, a key challenge in constrained stochastic problems lies in dealing with the bias in the step direction. As such, we apply a momentum-style gradient moving-average technique within SSQP to debias the step. We show that our method achieves global almost-sure convergence and exhibits local asymptotic normality with an optimal primal-dual limiting covariance matrix in the sense of Hájek and Le Cam. In addition, we provide a plug-in covariance matrix estimator for practical inference. To our knowledge, the proposed SSQP method is the first fully online method that attains primal-dual asymptotic minimax optimality without relying on projection operators onto the constraint set, which are generally intractable for nonlinear problems. Through extensive experiments on benchmark nonlinear problems, as well as on constrained generalized linear models and portfolio allocation problems using both synthetic and real data, we demonstrate superior performance of our method, showing that the method and its asymptotic behavior not only solve constrained stochastic problems efficiently but also provide valid and practical online inference in real-world applications.

</details>


### [29] [Robust and Sparse Estimation of Unbounded Density Ratio under Heavy Contamination](https://arxiv.org/abs/2512.09266)
*Ryosuke Nagumo,Hironori Fujisawa*

Main category: stat.ML

TL;DR: 本文分析了加权密度比估计（DRE）在污染环境下的非渐近特性。


<details>
  <summary>Details</summary>
Motivation: 解决密度比估计和鲁棒估计中的两个重要挑战：在加权密度比函数有界假设下估计无界密度比的非渐近特性，以及在重污染下引入双重强鲁棒性的非渐近框架。

Method: 加权密度比估计（Weighted DRE）

Result: 加权密度比估计在非渐近框架下，即使在重污染情况下也能实现稀疏一致性。

Conclusion: 本文首次提出了在重污染下强鲁棒性的非渐近分析。

Abstract: We examine the non-asymptotic properties of robust density ratio estimation (DRE) in contaminated settings. Weighted DRE is the most promising among existing methods, exhibiting doubly strong robustness from an asymptotic perspective. This study demonstrates that Weighted DRE achieves sparse consistency even under heavy contamination within a non-asymptotic framework. This method addresses two significant challenges in density ratio estimation and robust estimation. For density ratio estimation, we provide the non-asymptotic properties of estimating unbounded density ratios under the assumption that the weighted density ratio function is bounded. For robust estimation, we introduce a non-asymptotic framework for doubly strong robustness under heavy contamination, assuming that at least one of the following conditions holds: (i) contamination ratios are small, and (ii) outliers have small weighted values. This work provides the first non-asymptotic analysis of strong robustness under heavy contamination.

</details>


### [30] [Impact of Positional Encoding: Clean and Adversarial Rademacher Complexity for Transformers under In-Context Regression](https://arxiv.org/abs/2512.09275)
*Weiyi He,Yue Xing*

Main category: stat.ML

TL;DR: 本文分析了位置编码（PE）对Transformer泛化能力和鲁棒性的影响。


<details>
  <summary>Details</summary>
Motivation: 探索位置编码（PE）对Transformer泛化能力和鲁棒性的影响，因为目前这一点尚不清楚。

Method: 本文对一个带有完全可训练PE模块的单层Transformer进行了上下文回归的泛化分析。
此外，本文还推导了对抗性Rademacher泛化界限。

Result: PE系统地增大了泛化差距。
在对抗性设置下，有PE的模型和没有PE的模型之间的差距进一步扩大，表明PE会放大模型的脆弱性。

Conclusion: 位置编码（PE）会损害Transformer的泛化能力并降低其鲁棒性。

Abstract: Positional encoding (PE) is a core architectural component of Transformers, yet its impact on the Transformer's generalization and robustness remains unclear. In this work, we provide the first generalization analysis for a single-layer Transformer under in-context regression that explicitly accounts for a completely trainable PE module. Our result shows that PE systematically enlarges the generalization gap. Extending to the adversarial setting, we derive the adversarial Rademacher generalization bound. We find that the gap between models with and without PE is magnified under attack, demonstrating that PE amplifies the vulnerability of models. Our bounds are empirically validated by a simulation study. Together, this work establishes a new framework for understanding the clean and adversarial generalization in ICL with PE.

</details>


### [31] [Estimation of Stochastic Optimal Transport Maps](https://arxiv.org/abs/2512.09499)
*Sloan Nietert,Ziv Goldfeld*

Main category: stat.ML

TL;DR: 本文提出了一种新的度量标准来评估随机传输图的传输质量，并开发了计算 eficiente 的图估计器，这些估计器具有近乎最优的有限样本风险界限，同时具有易于验证的最小假设，以拓宽图估计理论的范围


<details>
  <summary>Details</summary>
Motivation: 现有的OT图估计的统计理论受到严格限制，这导致在许多实际问题中，当条件不满足或无法认证时，只能通过可以分割质量的随机映射进行最优运输。

Method: 本文引入了一种新的度量来评估随机映射的传输质量。在此度量下，我们开发了计算高效的地图估计器，具有接近最优的有限样本风险界限，且假设最少，易于验证。

Result: 我们的分析还包含了常见形式的对抗性样本污染，从而产生了具有鲁棒估计保证的估计器。通过实证实验验证了我们的理论，并证明了所提出的框架在现有理论失效的场景中的实用性。

Conclusion: 这些贡献构成了第一个通用映射估计理论，与最佳传输可能本质上是随机的各种现实世界应用兼容。

Abstract: The optimal transport (OT) map is a geometry-driven transformation between high-dimensional probability distributions which underpins a wide range of tasks in statistics, applied probability, and machine learning. However, existing statistical theory for OT map estimation is quite restricted, hinging on Brenier's theorem (quadratic cost, absolutely continuous source) to guarantee existence and uniqueness of a deterministic OT map, on which various additional regularity assumptions are imposed to obtain quantitative error bounds. In many real-world problems these conditions fail or cannot be certified, in which case optimal transportation is possible only via stochastic maps that can split mass. To broaden the scope of map estimation theory to such settings, this work introduces a novel metric for evaluating the transportation quality of stochastic maps. Under this metric, we develop computationally efficient map estimators with near-optimal finite-sample risk bounds, subject to easy-to-verify minimal assumptions. Our analysis further accommodates common forms of adversarial sample contamination, yielding estimators with robust estimation guarantees. Empirical experiments are provided which validate our theory and demonstrate the utility of the proposed framework in settings where existing theory fails. These contributions constitute the first general-purpose theory for map estimation, compatible with a wide spectrum of real-world applications where optimal transport may be intrinsically stochastic.

</details>


### [32] [Transformers for Tabular Data: A Training Perspective of Self-Attention via Optimal Transport](https://arxiv.org/abs/2512.09530)
*Antonio Candelieri,Alessandro Quadrio*

Main category: stat.ML

TL;DR: 这篇论文通过最优传输（OT）的视角审视了自注意力训练，并为表格分类开发了一种基于OT的替代方法。


<details>
  <summary>Details</summary>
Motivation: 研究自注意力层在训练过程中的中间投影，并使用离散OT度量评估它们的演变，以寻找更高效的训练方法。

Method: 本文首先跟踪自注意力层训练过程中的中间投影，并使用离散OT度量（包括Wasserstein距离、Monge间隙、最优性和效率）评估它们的演变。然后，提出了一种基于OT的算法：生成类别特定的虚拟高斯分布，计算与数据的OT对齐，并训练一个MLP来推广这种映射。

Result: 最终的自注意力映射通常接近OT最优耦合，但训练轨迹效率低下。在合成数据上预训练MLP部分可以部分改善收敛，但对初始化敏感。OT方法在计算成本和标准化输入下的扩展效率方面优于Transformer，且精度可与Transformer媲美，但其性能依赖于虚拟几何的精心设计。

Conclusion: 尽管最终的自注意力映射接近OT最优耦合，但传统训练过程效率低下。本文提出的基于OT的方法在表格分类任务上实现了与Transformer相当的精度，同时降低了计算成本并提高了效率，但需要仔细设计虚拟几何。

Abstract: This thesis examines self-attention training through the lens of Optimal Transport (OT) and develops an OT-based alternative for tabular classification. The study tracks intermediate projections of the self-attention layer during training and evaluates their evolution using discrete OT metrics, including Wasserstein distance, Monge gap, optimality, and efficiency. Experiments are conducted on classification tasks with two and three classes, as well as on a biomedical dataset.
  Results indicate that the final self-attention mapping often approximates the OT optimal coupling, yet the training trajectory remains inefficient. Pretraining the MLP section on synthetic data partially improves convergence but is sensitive to their initialization. To address these limitations, an OT-based algorithm is introduced: it generates class-specific dummy Gaussian distributions, computes an OT alignment with the data, and trains an MLP to generalize this mapping. The method achieves accuracy comparable to Transformers while reducing computational cost and scaling more efficiently under standardized inputs, though its performance depends on careful dummy-geometry design. All experiments and implementations are conducted in R.

</details>


### [33] [Don't Throw Away Your Beams: Improving Consistency-based Uncertainties in LLMs via Beam Search](https://arxiv.org/abs/2512.09538)
*Ekaterina Fadeeva,Maiya Goloburda,Aleksandr Rubashevskii,Roman Vashurin,Artem Shelmanov,Preslav Nakov,Mrinmaya Sachan,Maxim Panov*

Main category: stat.ML

TL;DR: 本文介绍了一种新的基于束搜索的一致性不确定性量化方法，该方法在短文本问答中优于多项式采样，并能减少不确定性估计的方差。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型中，基于一致性的方法是量化不确定性（UQ）的有效方法，但多项式采样在短文本问答中容易产生重复和高方差。

Method: 提出了一种新的方法，采用束搜索（beam search）生成候选，用于基于一致性的不确定性量化。

Result: 与多项式采样相比，该方法在不确定性量化方面表现更好，方差更小。在六个问答数据集上进行评估后发现，该方法持续优于多项式采样，达到了最先进的UQ性能。

Conclusion: 束搜索（beam search）可以有效改善大型语言模型中一致性不确定性量化方法的性能并降低方差。

Abstract: Consistency-based methods have emerged as an effective approach to uncertainty quantification (UQ) in large language models. These methods typically rely on several generations obtained via multinomial sampling, measuring their agreement level. However, in short-form QA, multinomial sampling is prone to producing duplicates due to peaked distributions, and its stochasticity introduces considerable variance in uncertainty estimates across runs. We introduce a new family of methods that employ beam search to generate candidates for consistency-based UQ, yielding improved performance and reduced variance compared to multinomial sampling. We also provide a theoretical lower bound on the beam set probability mass under which beam search achieves a smaller error than multinomial sampling. We empirically evaluate our approach on six QA datasets and find that its consistent improvements over multinomial sampling lead to state-of-the-art UQ performance.

</details>


### [34] [Supervised learning pays attention](https://arxiv.org/abs/2512.09912)
*Erin Craig,Robert Tibshirani*

Main category: stat.ML

TL;DR: 本文提出了一种“注意力加权”的方法，将上下文学习应用于表格数据的监督学习，以提高模型的灵活性、可解释性和预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统的监督学习方法难以对每个预测点进行个性化建模，也难以处理异构数据，同时保持模型简单性和可解释性。

Method: 该方法通过“注意力”机制对训练数据进行加权，为每个测试观察拟合一个局部模型。注意力是一种监督相似性度量，它强调对结果有预测性的特征和交互。该方法还展示了如何将其应用于时间序列和空间数据，并提出了一种使用注意力加权残差校正来适应预训练树型模型以适应分布偏移的方法。

Result: 在真实和模拟数据集上，注意力加权提高了预测性能，同时保持了可解释性。理论分析表明，在已知子组结构的混合模型数据生成过程中，注意力加权线性模型比标准线性模型具有更低的均方误差。

Conclusion: 注意力加权是一种有效且可解释的方法，可以提高表格数据、时间序列和空间数据的监督学习性能，尤其适用于处理异构数据和应对分布偏移。

Abstract: In-context learning with attention enables large neural networks to make context-specific predictions by selectively focusing on relevant examples. Here, we adapt this idea to supervised learning procedures such as lasso regression and gradient boosting, for tabular data. Our goals are to (1) flexibly fit personalized models for each prediction point and (2) retain model simplicity and interpretability.
  Our method fits a local model for each test observation by weighting the training data according to attention, a supervised similarity measure that emphasizes features and interactions that are predictive of the outcome. Attention weighting allows the method to adapt to heterogeneous data in a data-driven way, without requiring cluster or similarity pre-specification. Further, our approach is uniquely interpretable: for each test observation, we identify which features are most predictive and which training observations are most relevant. We then show how to use attention weighting for time series and spatial data, and we present a method for adapting pretrained tree-based models to distributional shift using attention-weighted residual corrections. Across real and simulated datasets, attention weighting improves predictive performance while preserving interpretability, and theory shows that attention-weighting linear models attain lower mean squared error than the standard linear model under mixture-of-models data-generating processes with known subgroup structure.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [35] [Optimizing Algorithms for Mobile Health Interventions with Active Querying Optimization](https://arxiv.org/abs/2512.08950)
*Aseel Rawashdeh*

Main category: cs.LG

TL;DR: 本文提出了基于贝叶斯扩展的Act-Then-Measure (ATM) 算法，以解决移动健康(mHealth)干预中强化学习的稳定性和采样效率问题。


<details>
  <summary>Details</summary>
Motivation: 在移动健康干预中，强化学习需要在干预效果和用户负担之间取得平衡，尤其是在状态测量（例如，用户调查或反馈）成本高昂但必不可少的情况下。标准的ATM算法在稀疏和嘈杂的环境中容易出现不稳定性。

Method: 本文提出了一种贝叶斯扩展的ATM算法，用卡尔曼滤波器式的贝叶斯更新取代了标准Q学习，以保持对Q值的不确定性感知估计，并实现更稳定和采样高效的学习。

Result: 在小型表格环境中，贝叶斯ATM实现了相当或改进的标量化回报，具有更低的方差和更稳定的策略行为。然而，在更大更复杂的mHealth设置中，标准和贝叶斯ATM变体都表现不佳。

Conclusion: 不确定性感知方法在低数据环境下具有价值，但需要新的强化学习算法来明确建模因果结构、连续状态和在观察成本限制下的延迟反馈，以解决真实世界mHealth领域的结构性挑战。

Abstract: Reinforcement learning in mobile health (mHealth) interventions requires balancing intervention efficacy with user burden, particularly when state measurements (for example, user surveys or feedback) are costly yet essential. The Act-Then-Measure (ATM) heuristic addresses this challenge by decoupling control and measurement actions within the Action-Contingent Noiselessly Observable Markov Decision Process (ACNO-MDP) framework. However, the standard ATM algorithm relies on a temporal-difference-inspired Q-learning method, which is prone to instability in sparse and noisy environments. In this work, we propose a Bayesian extension to ATM that replaces standard Q-learning with a Kalman filter-style Bayesian update, maintaining uncertainty-aware estimates of Q-values and enabling more stable and sample-efficient learning. We evaluate our method in both toy environments and clinically motivated testbeds. In small, tabular environments, Bayesian ATM achieves comparable or improved scalarized returns with substantially lower variance and more stable policy behavior. In contrast, in larger and more complex mHealth settings, both the standard and Bayesian ATM variants perform poorly, suggesting a mismatch between ATM's modeling assumptions and the structural challenges of real-world mHealth domains. These findings highlight the value of uncertainty-aware methods in low-data settings while underscoring the need for new RL algorithms that explicitly model causal structure, continuous states, and delayed feedback under observation cost constraints.

</details>


### [36] [An Electrocardiogram Multi-task Benchmark with Comprehensive Evaluations and Insightful Findings](https://arxiv.org/abs/2512.08954)
*Yuhao Xu,Jiaying Lu,Sirui Ding,Defu Cao,Xiao Hu,Carl Yang*

Main category: cs.LG

TL;DR: 本文探讨了基础模型在心电图（ECG）分析中的应用前景和性能，旨在回答“基础模型对ECG分析有用吗？”这一问题。


<details>
  <summary>Details</summary>
Motivation: 在患者诊断过程中，非侵入式测量因其低风险和快速结果而被广泛应用。心电图（ECG）作为一种收集心脏活动的非侵入式方法，常用于诊断心脏疾病。然而，分析心电图通常需要领域专业知识，这阻碍了人工智能在医疗领域的应用。尽管自监督学习和基础模型的进展使得人工智能系统能够在不完全依赖人类专业知识的情况下获取和利用领域知识，但目前缺乏对基础模型在ECG性能方面的全面分析。

Method: 本研究通过比较语言/通用时间序列/ECG基础模型与时间序列深度学习模型，评估了基础模型在ECG分析中的性能。

Result: 实验结果表明，通用时间序列/ECG基础模型达到了80%的最高性能，这证明了它们在ECG分析中的有效性。

Conclusion: 本研究通过深入分析和全面的实验结果，探讨了基础模型在推动生理波形分析方面的局限性和潜力。

Abstract: In the process of patient diagnosis, non-invasive measurements are widely used due to their low risks and quick results. Electrocardiogram (ECG), as a non-invasive method to collect heart activities, is used to diagnose cardiac conditions. Analyzing the ECG typically requires domain expertise, which is a roadblock to applying artificial intelligence (AI) for healthcare. Through advances in self-supervised learning and foundation models, AI systems can now acquire and leverage domain knowledge without relying solely on human expertise. However, there is a lack of comprehensive analyses over the foundation models' performance on ECG. This study aims to answer the research question: "Are Foundation Models Useful for ECG Analysis?" To address it, we evaluate language/general time-series/ECG foundation models in comparison with time-series deep learning models. The experimental results show that general time-series/ECG foundation models achieve a top performance rate of 80%, indicating their effectiveness in ECG analysis. In-depth analyses and insights are provided along with comprehensive experimental results. This study highlights the limitations and potential of foundation models in advancing physiological waveform analysis. The data and code for this benchmark are publicly available at https://github.com/yuhaoxu99/ECGMultitasks-Benchmark.

</details>


### [37] [DW-KNN: A Transparent Local Classifier Integrating Distance Consistency and Neighbor Reliability](https://arxiv.org/abs/2512.08956)
*Kumarjit Pathak,Karthik K,Sachin Madan,Jitin Kapila*

Main category: cs.LG

TL;DR: DW-KNN通过结合指数距离和邻域有效性，在保持透明性和鲁棒性的同时，提高了传统KNN在异构特征空间中的分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统的K-Nearest Neighbors (KNN) 及其变体假设所有“k”个邻居都同样可靠，这在异构特征空间中成为一个限制，影响了预测真实水平的可靠性。

Method: 本文提出了一种双加权KNN (DW-KNN) 变体，它将指数距离与邻居有效性相结合，实现了实例级可解释性，抑制了噪声或错误标记的样本，并降低了超参数敏感性。

Result: 在9个数据集上的综合评估表明，DW-KNN平均达到0.8988的准确率，在六种方法中排名第二，与表现最佳的集成KNN仅相差0.2%。它还表现出最低的交叉验证方差（0.0156），表明预测稳定性可靠。统计显著性检验（p < 0.001）证实，DW-KNN相对于紧致度加权KNN有4.09%的改进，相对于核加权KNN有1.13%的改进。

Conclusion: DW-KNN提供了一种简单而有效的替代复杂自适应方案的方法，特别适用于需要可解释预测的高风险应用。

Abstract: K-Nearest Neighbors (KNN) is one of the most used ML classifiers. However, if we observe closely, standard distance-weighted KNN and relative variants assume all 'k' neighbors are equally reliable. In heterogeneous feature space, this becomes a limitation that hinders reliability in predicting true levels of the observation.
  We propose DW-KNN (Double Weighted KNN), a transparent and robust variant that integrates exponential distance with neighbor validity. This enables instance-level interpretability, suppresses noisy or mislabeled samples, and reduces hyperparameter sensitivity.
  Comprehensive evaluation on 9 data-sets helps to demonstrate that DW-KNN achieves 0.8988 accuracy on average. It ranks 2nd among six methods and within 0.2% of the best-performing Ensemble KNN. It also exhibits the lowest cross-validation variance (0.0156), indicating reliable prediction stability. Statistical significance test confirmed ($p < 0.001$) improvement over compactness weighted KNN (+4.09\%) and Kernel weighted KNN (+1.13\%). The method provides a simple yet effective alternative to complex adaptive schemes, particularly valuable for high-stakes applications requiring explainable predictions.

</details>


### [38] [LUMOS: Large User MOdels for User Behavior Prediction](https://arxiv.org/abs/2512.08957)
*Dhruv Nigam*

Main category: cs.LG

TL;DR: LUMOS是一个基于Transformer的大型用户模型，它通过联合学习多个任务和使用原始用户活动数据，消除了对特定任务模型和手动特征工程的依赖。该模型引入了新颖的交叉注意力机制，并采用多模态tokenization，通过广泛的实验证明其性能优于传统模型，并在实际业务中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 解决在线B2C平台用户行为预测中，传统方法依赖于特定任务模型和领域特定特征工程，导致耗时、计算成本高昂、需要领域专业知识且不可扩展的问题。

Method: LUMOS是一个基于Transformer的架构，它通过联合学习多个任务，仅使用原始用户活动数据，从而消除了特定任务模型和手动特征工程。它引入了一种新颖的交叉注意力机制，可以根据未来的已知事件进行预测。该架构还采用多模态tokenization，将用户交易、事件上下文和静态用户人口统计属性组合成丰富的表示。

Result: 在包含2.75亿用户、2750亿用户活动token的生产数据集上，LUMOS在5项任务中，二元分类任务的ROC-AUC平均提高0.025，回归任务的MAPE平均降低4.6%。在线A/B测试验证了这些改进带来了可衡量的业务影响，DAU（日活跃用户）增加了3.15%。

Conclusion: LUMOS通过其创新的Transformer架构、交叉注意力机制和多模态tokenization，成功地解决了大规模用户行为预测的挑战。它在多个任务上取得了显著的性能提升，并带来了实际的业务增长，证明了其在未来已知事件影响用户行为预测方面的有效性。

Abstract: User behavior prediction at scale remains a critical challenge for online B2C platforms. Traditional approaches rely heavily on task-specific models and domain-specific feature engineering. This is time-consuming, computationally expensive, and requires domain expertise and therefore not scalable. We present LUMOS (Large User MOdel Series), a transformer-based architecture that eliminates task-specific models and manual feature engineering by learning multiple tasks jointly using only raw user activity data. LUMOS introduces a novel cross-attention mechanism that conditions predictions on future known events (e.g., holidays, sales, etc.), enabling the model to predict complex behaviour patterns like "how will upcoming holidays affect user engagement?" The architecture also employs multi-modal tokenization, combining user transactions, event context, and static user demographic attributes into rich representations processed through specialized embedding pathways.
  Through extensive experiments on a production dataset spanning 275 billion user activity tokens from 250 million users, we demonstrate that LUMOS achieves superior performance compared to traditional task-specific models. Across 5 tasks with established baselines, we achieve an average improvement of 0.025 in ROC-AUC for binary classification tasks and 4.6\% reduction in MAPE for regression tasks. Online A/B testing validates these improvements translate to measurable business impact with a 3.15\% increase in Daily Active Users.

</details>


### [39] [EEG-Bench: A Benchmark for EEG Foundation Models in Clinical Applications](https://arxiv.org/abs/2512.08959)
*Ard Kastrati,Josua Bürki,Jonas Lauer,Cheng Xuan,Raffaele Iaquinto,Roger Wattenhofer*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个评估基于EEG的临床基础模型的统一基准框架。


<details>
  <summary>Details</summary>
Motivation: 为了解决在临床应用中评估脑电图（EEG）基础模型的挑战，并提供一个标准化的比较框架。

Method: 该研究提出了一个统一的基准框架，涵盖了11个明确的诊断任务，使用了14个公开的EEG数据集，涉及癫痫、精神分裂症、帕金森病、强迫症和轻度脑外伤等疾病。该框架强调最小预处理、标准化评估协议，并支持经典基线模型与现代基础模型的并排比较。

Result: 研究结果表明，尽管基础模型在某些设置下表现出色，但简单模型，特别是在临床分布变化下，通常仍具有竞争力。

Conclusion: 本研究提供了一个统一的基准框架，用于评估EEG基础模型，并发现简单模型在临床实践中仍有其价值。为了促进可重复性和应用，所有准备好的数据和代码都以可访问和可扩展的格式发布。

Abstract: We introduce a unified benchmarking framework focused on evaluating EEG-based foundation models in clinical applications. The benchmark spans 11 well-defined diagnostic tasks across 14 publicly available EEG datasets, including epilepsy, schizophrenia, Parkinson's disease, OCD, and mild traumatic brain injury. It features minimal preprocessing, standardized evaluation protocols, and enables side-by-side comparisons of classical baselines and modern foundation models. Our results show that while foundation models achieve strong performance in certain settings, simpler models often remain competitive, particularly under clinical distribution shifts. To facilitate reproducibility and adoption, we release all prepared data and code in an accessible and extensible format.

</details>


### [40] [Resolving Conflicts in Lifelong Learning via Aligning Updates in Subspaces](https://arxiv.org/abs/2512.08960)
*Yueer Zhou,Yichen Wu,Ying Wei*

Main category: cs.LG

TL;DR: PS-LoRA通过对齐优化子空间中的更新并结合双重正则化目标来解决连续学习中的灾难性遗忘问题，在NLP和Vision任务上表现优于现有方法，同时保持了学习表示的稳定性并有效适应新领域。


<details>
  <summary>Details</summary>
Motivation: LoRA在持续学习中存在灾难性遗忘问题，原因在于新任务梯度与历史权重轨迹之间的对抗性方向更新。

Method: PS-LoRA通过采用双重正则化目标来解决冲突，该目标惩罚冲突方向并限制幅度偏差，以确保与先验知识的一致性。此外，PS-LoRA还实现了基于幅度的合并策略，无需重新训练即可将顺序适配器整合为稳健的表示。

Result: PS-LoRA在NLP和Vision基准测试中优于现有方法。

Conclusion: PS-LoRA通过解决方向冲突和保持更新稳定性，有效地缓解了LoRA在持续学习中的灾难性遗忘问题，并实现了更好的性能。

Abstract: Low-Rank Adaptation (LoRA) enables efficient Continual Learning but often suffers from catastrophic forgetting due to destructive interference between tasks. Our analysis reveals that this degradation is primarily driven by antagonistic directional updates where new task gradients directly oppose the historical weight trajectory. To address this, we propose PS-LoRA (Parameter Stability LoRA), a framework designed to resolve conflicts by aligning updates within the optimization subspace. Our approach employs a dual-regularization objective that penalizes conflicting directions and constrains magnitude deviations to ensure consistency with prior knowledge. Additionally, we implement a magnitude-based merging strategy to consolidate sequential adapters into a robust representation without retraining. Experiments on NLP and Vision benchmarks show that PS-LoRA outperforms state-of-the-art methods by preserving the stability of learned representations while efficiently adapting to new domains.

</details>


### [41] [Financial Instruction Following Evaluation (FIFE)](https://arxiv.org/abs/2512.08965)
*Glenn Matlin,Siddharth,Anirudh JM,Aditya Shukla,Yahya Hassan,Sudheer Chava*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个名为 FIFE 的新型基准测试，用于评估语言模型在金融分析任务中遵循复杂指令的能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型在处理复杂、相互依赖的指令方面面临挑战，尤其是在金融等需要高精度的领域。

Method: FIFE 包含 88 个由人工编写的提示，并采用一个带有可链接、可验证约束的验证系统，以提供细粒度的奖励信号。作者评估了 53 个模型（专有、开源、开放权重），采用零样本设置。

Result: 结果显示了明显的性能等级：表现最好的开放权重模型（76.1 strict / 79.5 loose）超越了领先的专有系统（65.9 strict / 70.5 loose），而最佳的开源模型则显著落后（45.5 strict / 48.9 loose）。然而，即使是表现最好的模型也难以完全满足 FIFE 的复杂要求。

Conclusion: FIFE 提供了一个评估语言模型在金融指令遵循方面能力的基准。尽管开放权重模型表现出色，但所有模型在处理复杂指令时仍面临挑战。作者发布了数据集和代码，以促进金融领域强化学习的研究。

Abstract: Language Models (LMs) struggle with complex, interdependent instructions, particularly in high-stakes domains like finance where precision is critical. We introduce FIFE, a novel, high-difficulty benchmark designed to assess LM instruction-following capabilities for financial analysis tasks. FIFE comprises 88 human-authored prompts and employs a verification system with chainable, verifiable constraints for fine-grained reward signals. We evaluate 53 models (proprietary, open-weight, open-source) in a zero-shot setting. Our key findings reveal a clear performance hierarchy: the top open-weight model (76.1 strict / 79.5 loose) surpasses the leading proprietary system (65.9 strict / 70.5 loose), while the best open-source models lag significantly (45.5 strict / 48.9 loose). However, even top-performing models struggle with FIFE's complex requirements, failing to achieve perfect compliance. We release our dataset and code as an open-source resource to promote research in Reinforcement Learning for the financial domain.

</details>


### [42] [CluCERT: Certifying LLM Robustness via Clustering-Guided Denoising Smoothing](https://arxiv.org/abs/2512.08967)
*Zixia Wang,Gaojie Jin,Jia Hu,Ronghui Mu*

Main category: cs.LG

TL;DR: CluCERT是一个通过聚类引导去噪平滑来认证LLM鲁棒性的框架，解决了现有方法在鲁棒性边界松散和计算成本高的问题，并在鲁棒性边界和计算效率方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在日常应用中广泛采用，但易受对抗性攻击，如通过同义词替换等细微的、保留语义的改变即可导致不正确预测。因此，认证LLMs对这些对抗性提示的鲁棒性至关重要。

Method: 本文提出了CluCERT框架，通过聚类引导去噪平滑来认证LLM的鲁棒性。为获得更紧密的认证边界，我们引入了一个语义聚类过滤器，旨在减少噪声样本并保留有意义的扰动。为提高计算效率，我们设计了一个提炼模块用于提取核心语义，并开发了一个快速同义词替换策略以加速去噪过程。

Result: CluCERT在各种下游任务和越狱防御场景中进行了广泛实验，结果表明，我们的方法在鲁棒性边界和计算效率方面均优于现有的认证方法。

Conclusion: CluCERT通过结合语义聚类过滤和高效去噪策略，有效地解决了现有LLM鲁棒性认证方法所面临的限制，显著提升了认证边界的紧密性和计算效率。

Abstract: Recent advancements in Large Language Models (LLMs) have led to their widespread adoption in daily applications. Despite their impressive capabilities, they remain vulnerable to adversarial attacks, as even minor meaning-preserving changes such as synonym substitutions can lead to incorrect predictions. As a result, certifying the robustness of LLMs against such adversarial prompts is of vital importance. Existing approaches focused on word deletion or simple denoising strategies to achieve robustness certification. However, these methods face two critical limitations: (1) they yield loose robustness bounds due to the lack of semantic validation for perturbed outputs and (2) they suffer from high computational costs due to repeated sampling. To address these limitations, we propose CluCERT, a novel framework for certifying LLM robustness via clustering-guided denoising smoothing. Specifically, to achieve tighter certified bounds, we introduce a semantic clustering filter that reduces noisy samples and retains meaningful perturbations, supported by theoretical analysis. Furthermore, we enhance computational efficiency through two mechanisms: a refine module that extracts core semantics, and a fast synonym substitution strategy that accelerates the denoising process. Finally, we conduct extensive experiments on various downstream tasks and jailbreak defense scenarios. Experimental results demonstrate that our method outperforms existing certified approaches in both robustness bounds and computational efficiency.

</details>


### [43] [Beyond the Hype: Comparing Lightweight and Deep Learning Models for Air Quality Forecasting](https://arxiv.org/abs/2512.09076)
*Moazzam Umer Gondal,Hamad ul Qudous,Asma Ahmad Farhan*

Main category: cs.LG

TL;DR: 这篇论文评估了Facebook Prophet (FBP)和NeuralProphet (NP)这两种轻量级可解释的加性模型在预测北京空气污染物（PM2.5、PM10）方面的性能。研究发现FBP的表现优于其他模型，取得了超过0.94的R方，证明了可解释加性模型在准确性、透明性和易部署性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 目前深度学习和混合模型在空气污染预测中占据主导地位，但其复杂性和有限的可解释性阻碍了实际应用。本研究旨在探讨轻量级加性模型（Facebook Prophet和NeuralProphet）是否能在预测城市空气污染方面取得具有竞争力的结果，以解决现有模型的复杂性和可解释性问题。

Method: 本研究使用了多年的污染物和气象数据，并系统地进行了特征选择（相关性、互信息、mRMR）、防泄漏缩放和按时间顺序分割数据。Facebook Prophet和NeuralProphet模型都使用污染物和前体回归因子进行训练，其中NeuralProphet额外利用了滞后依赖性。同时，还实现了两个机器学习基线模型（LSTM、LightGBM）和一个传统统计模型（SARIMAX）进行对比。模型的性能通过7天保留样本上的平均绝对误差（MAE）、均方根误差（RMSE）和R方进行评估。

Result: 研究结果表明，Facebook Prophet模型在PM2.5和PM10这两种污染物上的预测性能始终优于NeuralProphet、SARIMAX以及其他机器学习基线模型。Facebook Prophet在测试集上的R方均超过0.94。

Conclusion: 可解释的加性模型在城市空气污染预测方面，其性能可以与传统模型和复杂模型相媲美，并在准确性、透明度和易部署性之间取得了实用的平衡。Facebook Prophet模型尤其表现出色，证实了轻量级可解释模型在实际操作中的潜力。

Abstract: Accurate forecasting of urban air pollution is essential for protecting public health and guiding mitigation policies. While Deep Learning (DL) and hybrid pipelines dominate recent research, their complexity and limited interpretability hinder operational use. This study investigates whether lightweight additive models -- Facebook Prophet (FBP) and NeuralProphet (NP) -- can deliver competitive forecasts for particulate matter (PM$_{2.5}$, PM$_{10}$) in Beijing, China. Using multi-year pollutant and meteorological data, we applied systematic feature selection (correlation, mutual information, mRMR), leakage-safe scaling, and chronological data splits. Both models were trained with pollutant and precursor regressors, with NP additionally leveraging lagged dependencies. For context, two machine learning baselines (LSTM, LightGBM) and one traditional statistical model (SARIMAX) were also implemented. Performance was evaluated on a 7-day holdout using MAE, RMSE, and $R^2$. Results show that FBP consistently outperformed NP, SARIMAX, and the learning-based baselines, achieving test $R^2$ above 0.94 for both pollutants. These findings demonstrate that interpretable additive models remain competitive with both traditional and complex approaches, offering a practical balance of accuracy, transparency, and ease of deployment.

</details>


### [44] [StructuredDNA: A Bio-Physical Framework for Energy-Aware Transformer Routing](https://arxiv.org/abs/2512.08968)
*Mustapha Hamdi*

Main category: cs.LG

TL;DR: StructuredDNA是一种用于模块化、节约能源的Transformer路由的稀疏架构，它根据语义能量最小化动态地将输入进行分类。它在不同基准测试中展示了显著的能源效率和语义稳定性，并为未来的稀疏计算框架提供了新的范例。


<details>
  <summary>Details</summary>
Motivation: 大型计算模型的快速扩展导致能源和计算成本急剧增加。受生物系统中结构和功能从低能配置中产生的启发，我们引入StructuredDNA。

Method: StructuredDNA用基于语义能量最小化的生物物理、能量引导路由层取代了密集的专家混合路由。输入被动态分组为语义“密码子”，路由通过最小化结合了内聚力、不确定性和计算成本的全局能量函数来选择单个专家。

Result: 在BioASQ（K=50）上，能源利用密度（EUD）降低了97.7%，语义稳定性指数（SSI）达到0.998。在WikiText-103上，通过扩展专家粒度（K=2048），在保持99%以上的能源效率的同时，展示了Semantic Scaling Law。

Conclusion: StructuredDNA为未来的稀疏计算框架建立了一个强大的、领域无关的范例，并在生物物理原理与Transformer架构中的稀疏专家路由之间建立了明确的联系。此项研究为能源感知、模块化和可扩展的计算系统指明了方向。

Abstract: The rapid scaling of large computational models has led to a critical increase in energy and compute costs. Inspired by biological systems where structure and function emerge from low-energy configurations, we introduce StructuredDNA, a sparse architecture framework for modular, energy-aware Transformer routing. StructuredDNA replaces dense Mixture-of-Experts routing with a bio-physical, energy-guided routing layer based on semantic energy minimization. Inputs are dynamically grouped into semantic codons, and routing selects a single expert by minimizing a global energy functional that combines cohesion, uncertainty, and computational cost.
  We validate StructuredDNA on both specialized (BioASQ) and open-domain benchmarks (WikiText-103). On BioASQ (K = 50), we achieve a 97.7% reduction in Energy Utilization Density (EUD) and a Semantic Stability Index (SSI) of 0.998. We further demonstrate a Semantic Scaling Law on WikiText-103, showing that the architecture generalizes to open domains by scaling expert granularity (K = 2048) while maintaining more than 99% energy efficiency. StructuredDNA thus establishes a robust, domain-agnostic paradigm for future sparse computational frameworks.
  StructuredDNA provides an explicit link between bio-physical principles and sparse expert routing in Transformer architectures, and points toward future energy-aware, modular, and scalable computational systems. We discuss limitations of this proof-of-concept study and outline directions for scaling the approach to larger models, datasets, and hardware platforms. The StructuredDNA implementation is available at https://github.com/InnoDeep-repos/StructuredDNA .

</details>


### [45] [Provably Learning from Modern Language Models via Low Logit Rank](https://arxiv.org/abs/2512.09892)
*Noah Golowich,Allen Liu,Abhishek Shetty*

Main category: cs.LG

TL;DR: 本文提出了一种利用语言模型低logit秩结构进行可证明学习的有效算法，这有望为捕捉现代语言模型的生成模型提供第一个端到端的学习保证。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型的复杂性促使研究人员寻求更简单、可处理的抽象，并发现这些模型具有近似低logit秩的特性。因此，本文旨在理解如何利用这种结构在算法上获得可证明的学习保证。

Method: 本文研究了一个带logit查询的查询学习模型，该模型反映了常见API的访问模型，并通过高效算法学习近似低logit秩模型。

Result: 本文的主要成果是一种能够从查询中学习任何近似低logit秩模型的有效算法。

Conclusion: 本文的结果为生成模型提供了端到端的学习保证，该模型可能捕获了现代语言模型，这是因为其结构假设与现代语言模型中观察到的经验行为密切相关。

Abstract: While modern language models and their inner workings are incredibly complex, recent work (Golowich, Liu & Shetty; 2025) has proposed a simple and potentially tractable abstraction for them through the observation that empirically, these language models all seem to have approximately low logit rank. Roughly, this means that a matrix formed by the model's log probabilities of various tokens conditioned on certain sequences of tokens is well approximated by a low rank matrix.
  In this paper, our focus is on understanding how this structure can be exploited algorithmically for obtaining provable learning guarantees. Since low logit rank models can encode hard-to-learn distributions such as noisy parities, we study a query learning model with logit queries that reflects the access model for common APIs. Our main result is an efficient algorithm for learning any approximately low logit rank model from queries. We emphasize that our structural assumption closely reflects the behavior that is empirically observed in modern language models. Thus, our result gives what we believe is the first end-to-end learning guarantee for a generative model that plausibly captures modern language models.

</details>


### [46] [Peek-a-Boo Reasoning: Contrastive Region Masking in MLLMs](https://arxiv.org/abs/2512.08976)
*Isha Chaturvedi,Anjana Nair,Yushen Li,Adhitya Rajendra Kumar,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma*

Main category: cs.LG

TL;DR: 该论文介绍了对比区域掩码（CRM），一种用于揭示多模态大型语言模型（MLLM）在思维链（CoT）推理的每个步骤中对特定视觉区域的依赖性的免费训练诊断工具。


<details>
  <summary>Details</summary>
Motivation: 传统的评估方法仅限于最终答案或注意力图，无法提供因果的、步骤级别的归因。CRM旨在通过系统地掩盖注释区域并对比由此产生的推理轨迹与未掩盖的基线，来解决这个问题，从而更好地理解MLLM的推理过程。

Method: 对比区域掩码（CRM）方法。该方法通过系统地掩盖图像中的注释区域，并对比由此产生的推理轨迹与未掩盖的基线，来诊断MLLM在CoT推理过程中对特定视觉区域的依赖性。

Result: CRM揭示了不同的故障模式：一些模型保留了推理结构，但在缺少证据时会产生幻觉，而另一些模型则紧密地基于视觉线索，但在受到扰动时会崩溃。通过将评估从答案的正确性转向推理的忠实性，CRM将视觉基准重新定义为诊断工具。

Conclusion: CRM强调了多模态评估框架的需求，该框架不仅要衡量性能，还要衡量推理的鲁棒性和忠实性。未来的研究可以利用CRM作为诊断工具，以改进MLLM的设计和训练，从而提高其在复杂多模态推理任务中的可靠性和可解释性。

Abstract: We introduce Contrastive Region Masking (CRM), a training free diagnostic that reveals how multimodal large language models (MLLMs) depend on specific visual regions at each step of chain-of-thought (CoT) reasoning. Unlike prior approaches limited to final answers or attention maps, CRM provides causal, step-level attri- bution by systematically masking annotated regions and contrasting the resulting reasoning traces with unmasked baselines. Applied to datasets such as VisArgs, CRM reveals distinct failure modes: some models preserve reasoning structure, but hallucinate when evidence is missing, while others ground tightly to visual cues yet collapse under perturbations. By shifting the evaluation from correctness of an- swers to faithfulness of reasoning, CRM reframes visual benchmarks as diagnostic tools, highlighting the need for multimodal evaluation frameworks that measure not just performance, but also robustness and fidelity of reasoning.

</details>


### [47] [Improving Multi-Class Calibration through Normalization-Aware Isotonic Techniques](https://arxiv.org/abs/2512.09054)
*Alon Arad,Saharon Rosset*

Main category: cs.LG

TL;DR: 本文提出了两种新颖的多类校准方法：NA-FIR和SCIR，它们在优化过程中考虑了概率归一化，并在各种文本和图像分类数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在多类监督学习任务中，准确可靠的概率预测对于合理的决策至关重要。虽然等渗回归在二元校准中表现出色，但其在多类问题上的扩展（通过一对多校准）与参数方法相比效果不佳，限制了其实际应用。

Method: 本文提出了两种新颖的等渗归一化感知技术：NA-FIR和SCIR。NA-FIR通过将归一化直接纳入优化过程来解决问题；SCIR则将问题建模为累积双变量等渗回归。

Result: 在各种文本和图像分类数据集以及不同模型架构上的实证评估表明，所提出的方法持续显著改善了负对数似然（NLL）和预期校准误差（ECE）指标

Conclusion: NA-FIR和SCIR这两种新颖的多类校准方法解决了现有方法在处理多类概率归一化时的不足，通过在优化过程中直接考虑归一化，显著提高了模型在多类分类任务中的校准性能和预测准确性。

Abstract: Accurate and reliable probability predictions are essential for multi-class supervised learning tasks, where well-calibrated models enable rational decision-making. While isotonic regression has proven effective for binary calibration, its extension to multi-class problems via one-vs-rest calibration produced suboptimal results when compared to parametric methods, limiting its practical adoption. In this work, we propose novel isotonic normalization-aware techniques for multiclass calibration, grounded in natural and intuitive assumptions expected by practitioners. Unlike prior approaches, our methods inherently account for probability normalization by either incorporating normalization directly into the optimization process (NA-FIR) or modeling the problem as a cumulative bivariate isotonic regression (SCIR). Empirical evaluation on a variety of text and image classification datasets across different model architectures reveals that our approach consistently improves negative log-likelihood (NLL) and expected calibration error (ECE) metrics.

</details>


### [48] [A Diffusion-Based Framework for High-Resolution Precipitation Forecasting over CONUS](https://arxiv.org/abs/2512.09059)
*Marina Vicens-Miquel,Amy McGovern,Aaron J. Hill,Efi Foufoula-Georgiou,Clement Guilloteau,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 本文介绍了一个基于扩散的深度学习框架，用于系统地比较三种残差预测策略，它们在降水预报领域的输入源不同，并评估了它们在美国大陆的性能表现。结果显示，该深度学习框架在像素级和时空统计指标上均优于HRRR基线，并且混合模型在最短提前期表现最佳，而HRRR校正模型在较长提前期表现更优。


<details>
  <summary>Details</summary>
Motivation: 准确的降水预报对于水文气象风险管理至关重要，特别是对于预测可能导致山洪暴发和基础设施损坏的极端降雨。本研究旨在通过引入一个扩散的深度学习框架，系统地比较不同的残差预测策略，从而提高降水预报的准确性和可靠性。

Method: 本研究引入了一个基于扩散的深度学习（DL）框架，并系统地比较了三种残差预测策略，它们在输入源上有所不同：（1）仅使用多雷达多传感器（MRMS）系统过去观测数据的纯数据驱动模型；（2）仅使用高分辨率快速刷新（HRRR）数值天气预报系统预报的校正模型；（3）集成MRMS和选定HRRR预报变量的混合模型。预测以1公里空间分辨率生成，从直接1小时预测开始，并使用自回归推广扩展到12小时。性能评估采用全美国大陆范围和特定区域的指标，以评估整体性能和极端降雨阈值下的技能。

Result: 在所有提前期内，本研究提出的深度学习框架在像素级和时空统计指标上均优于HRRR基线。混合模型在最短的提前期表现最佳，而HRRR校正模型在较长的提前期（长达12小时）表现更优。为了评估可靠性，研究还结合了为残差学习设置量身定制的校准不确定性量化。

Conclusion: 本研究通过增强预测技能、可靠性和跨区域适用性，推动了基于深度学习的降水预报。这些成果，特别是在较长提前期的改进，对于应急准备至关重要，因为预测范围的适度增加可以改善决策制定。

Abstract: Accurate precipitation forecasting is essential for hydrometeorological risk management, especially for anticipating extreme rainfall that can lead to flash flooding and infrastructure damage. This study introduces a diffusion-based deep learning (DL) framework that systematically compares three residual prediction strategies differing only in their input sources: (1) a fully data-driven model using only past observations from the Multi-Radar Multi-Sensor (MRMS) system, (2) a corrective model using only forecasts from the High-Resolution Rapid Refresh (HRRR) numerical weather prediction system, and (3) a hybrid model integrating both MRMS and selected HRRR forecast variables. By evaluating these approaches under a unified setup, we provide a clearer understanding of how each data source contributes to predictive skill over the Continental United States (CONUS). Forecasts are produced at 1-km spatial resolution, beginning with direct 1-hour predictions and extending to 12 hours using autoregressive rollouts. Performance is evaluated using both CONUS-wide and region-specific metrics that assess overall performance and skill at extreme rainfall thresholds. Across all lead times, our DL framework consistently outperforms the HRRR baseline in pixel-wise and spatiostatistical metrics. The hybrid model performs best at the shortest lead time, while the HRRR-corrective model outperforms others at longer lead times, maintaining high skill through 12 hours. To assess reliability, we incorporate calibrated uncertainty quantification tailored to the residual learning setup. These gains, particularly at longer lead times, are critical for emergency preparedness, where modest increases in forecast horizon can improve decision-making. This work advances DL-based precipitation forecasting by enhancing predictive skill, reliability, and applicability across regions.

</details>


### [49] [Modular Deep-Learning-Based Early Warning System for Deadly Heatwave Prediction](https://arxiv.org/abs/2512.09074)
*Shangqing Xu,Zhiyuan Zhao,Megha Sharma,José María Martín-Olalla,Alexander Rodríguez,Gregory A. Wellenius,B. Aditya Prakash*

Main category: cs.LG

TL;DR: DeepTherm是一个模块化的致命热浪早期预警系统，它可以在不需要热相关死亡率历史数据的情况下，预测致命热浪的发生。


<details>
  <summary>Details</summary>
Motivation: 城市地区严重的 Aunque热浪对公众健康构成重大威胁，但预测即将到来的致命热浪仍然是一个挑战，原因在于难以定义和估计与热相关的死亡率。

Method: DeepTherm采用双预测管道，将没有热浪和其他不规则事件时的基线死亡率与全因死亡率分离。

Result: 在西班牙的实际数据上评估了DeepTherm，结果表明其在不同地区、时间段和人群中表现出一致、稳健和准确的性能，同时允许在漏报和误报之间进行权衡。

Conclusion: DeepTherm是一个模块化的致命热浪预测早期预警系统，它不需要热相关的死亡率历史数据，并且在实际应用中表现出良好的性能。

Abstract: Severe heatwaves in urban areas significantly threaten public health, calling for establishing early warning strategies. Despite predicting occurrence of heatwaves and attributing historical mortality, predicting an incoming deadly heatwave remains a challenge due to the difficulty in defining and estimating heat-related mortality. Furthermore, establishing an early warning system imposes additional requirements, including data availability, spatial and temporal robustness, and decision costs. To address these challenges, we propose DeepTherm, a modular early warning system for deadly heatwave prediction without requiring heat-related mortality history. By highlighting the flexibility of deep learning, DeepTherm employs a dual-prediction pipeline, disentangling baseline mortality in the absence of heatwaves and other irregular events from all-cause mortality. We evaluated DeepTherm on real-world data across Spain. Results demonstrate consistent, robust, and accurate performance across diverse regions, time periods, and population groups while allowing trade-off between missed alarms and false alarms.

</details>


### [50] [Learning Unmasking Policies for Diffusion Language Models](https://arxiv.org/abs/2512.09106)
*Metod Jazbec,Theo X. Olausson,Louis Béthune,Pierre Ablin,Michael Kirchhof,Joao Monterio,Victor Turrisi,Jason Ramapuram,Marco Cuturi*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习的采样策略，用于掩码离散扩散模型，该策略在生成质量和效率方面优于现有启发式方法，并且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型扩散语言模型（dLLMs）在许多任务上表现出色，并且在推理时具有更高的效率。掩码离散扩散是其中一种成功的变体，但其效率和生成质量的平衡取决于采样策略。现有的启发式策略存在手动调优和在大缓冲区下性能下降的问题。

Method: 本文将掩码扩散采样形式化为马尔可夫决策过程，并提出了一种基于单层Transformer的轻量级策略架构，该架构将dLLM的token置信度映射到解掩码决策。

Result: 实验结果表明，与半自回归生成相结合时，所提出的训练策略与最先进的启发式方法性能相当；在完全扩散设置中，其性能优于启发式方法。这些策略可以泛化到新的dLLM和更长的序列长度。

Conclusion: 本文提出了一种有效的强化学习采样策略，可以提高dLLM的性能和效率，但其在域外数据上的性能会下降，并且在准确性和效率之间进行细致的权衡可能具有挑战性。

Abstract: Diffusion (Large) Language Models (dLLMs) now match the downstream performance of their autoregressive counterparts on many tasks, while holding the promise of being more efficient during inference. One particularly successful variant is masked discrete diffusion, in which a buffer filled with special mask tokens is progressively replaced with tokens sampled from the model's vocabulary. Efficiency can be gained by unmasking several tokens in parallel, but doing too many at once risks degrading the generation quality. Thus, one critical design aspect of dLLMs is the sampling procedure that selects, at each step of the diffusion process, which tokens to replace. Indeed, recent work has found that heuristic strategies such as confidence thresholding lead to both higher quality and token throughput compared to random unmasking. However, such heuristics have downsides: they require manual tuning, and we observe that their performance degrades with larger buffer sizes. In this work, we instead propose to train sampling procedures using reinforcement learning. Specifically, we formalize masked diffusion sampling as a Markov decision process in which the dLLM serves as the environment, and propose a lightweight policy architecture based on a single-layer transformer that maps dLLM token confidences to unmasking decisions. Our experiments show that these trained policies match the performance of state-of-the-art heuristics when combined with semi-autoregressive generation, while outperforming them in the full diffusion setting. We also examine the transferability of these policies, finding that they can generalize to new underlying dLLMs and longer sequence lengths. However, we also observe that their performance degrades when applied to out-of-domain data, and that fine-grained tuning of the accuracy-efficiency trade-off can be challenging with our approach.

</details>


### [51] [Towards Optimal Valve Prescription for Transcatheter Aortic Valve Replacement (TAVR) Surgery: A Machine Learning Approach](https://arxiv.org/abs/2512.09198)
*Phevos Paschalidis,Vasiliki Stoumpou,Lisa Everest,Yu Ma,Talhat Azemi,Jawad Haider,Steven Zweibel,Eleftherios M. Protopapas,Jeff Mather,Maciej Tysarowski,George E. Sarris,Robert C. Hagberg,Howard L. Haronian,Dimitris Bertsimas*

Main category: cs.LG

TL;DR: 该文章提出了一个数据驱动的临床支持工具，旨在优化经导管主动脉瓣置换（TAVR）中的瓣膜选择，以降低永久起搏器植入（PPI）的风险。


<details>
  <summary>Details</summary>
Motivation: 尽管经导管主动脉瓣置换（TAVR）已成为严重主动脉瓣狭窄的一种微创治疗选择，但当前关于瓣膜类型选择的指南仍存在争议。本文旨在通过开发一个数据驱动的临床支持工具，解决如何选择最佳瓣膜类型以最小化永久起搏器植入（PPI）这一主要术后并发症的问题。

Method: 本文通过整合美国和希腊患者群体的数据，并结合三种不同的数据源（患者人口统计学、计算机断层扫描、超声心动图）来构建一个新颖的数据集，同时协调了各国记录系统中的差异。研究引入了一种叶级分析方法，以利用人群异质性并避免与不确定的反事实风险估计进行基准比较。

Result: 与目前护理标准相比，最终的处方模型显示，在美国内部人群中，永久起搏器植入（PPI）率降低了26%，在外部希腊验证队列中降低了16%。

Conclusion: 这项工作首次提出了针对TAVR中经导管心脏瓣膜（THV）选择的统一、个性化处方策略，并显著降低了永久起搏器植入（PPI）的风险。

Abstract: Transcatheter Aortic Valve Replacement (TAVR) has emerged as a minimally invasive treatment option for patients with severe aortic stenosis, a life-threatening cardiovascular condition. Multiple transcatheter heart valves (THV) have been approved for use in TAVR, but current guidelines regarding valve type prescription remain an active topic of debate. We propose a data-driven clinical support tool to identify the optimal valve type with the objective of minimizing the risk of permanent pacemaker implantation (PPI), a predominant postoperative complication. We synthesize a novel dataset that combines U.S. and Greek patient populations and integrates three distinct data sources (patient demographics, computed tomography scans, echocardiograms) while harmonizing differences in each country's record system. We introduce a leaf-level analysis to leverage population heterogeneity and avoid benchmarking against uncertain counterfactual risk estimates. The final prescriptive model shows a reduction in PPI rates of 26% and 16% compared with the current standard of care in our internal U.S. population and external Greek validation cohort, respectively. To the best of our knowledge, this work represents the first unified, personalized prescription strategy for THV selection in TAVR.

</details>


### [52] [LLMs for Analog Circuit Design Continuum (ACDC)](https://arxiv.org/abs/2512.09199)
*Yasaman Esfandiari,Jocelyn Rego,Austin Meyer,Jonathan Gallagher,Mia Levy*

Main category: cs.LG

TL;DR: 本文探讨了大型语言模型（LLMs）在模拟电路设计中的应用，发现其在可靠性和泛化能力方面存在挑战，并提出了对未来AI辅助工程的启示。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在真实世界工程领域（如模拟电路设计）中的可靠性和鲁棒性，以提升其在以人为中心的工作流程中的实用性。

Method: 通过研究不同数据表示对模型行为的影响，并比较不同规模模型（T5, GPT-2, Mistral-7B, GPT-oss-20B）在不同训练条件下的表现，来评估LLMs在模拟电路设计中的适用性和一致性。

Result: 研究结果揭示了LLMs在模拟电路设计中的关键可靠性挑战，包括对数据格式的敏感性、生成设计的不稳定性以及对未见电路配置的泛化能力有限。

Conclusion: LLMs在复杂工程任务中增强人类能力方面具有潜力和局限性，为未来设计可靠、可部署的基础模型以应用于结构化的真实世界场景提供了见解。

Abstract: Large Language Models (LLMs) and transformer architectures have shown impressive reasoning and generation capabilities across diverse natural language tasks. However, their reliability and robustness in real-world engineering domains remain largely unexplored, limiting their practical utility in human-centric workflows. In this work, we investigate the applicability and consistency of LLMs for analog circuit design -- a task requiring domain-specific reasoning, adherence to physical constraints, and structured representations -- focusing on AI-assisted design where humans remain in the loop. We study how different data representations influence model behavior and compare smaller models (e.g., T5, GPT-2) with larger foundation models (e.g., Mistral-7B, GPT-oss-20B) under varying training conditions. Our results highlight key reliability challenges, including sensitivity to data format, instability in generated designs, and limited generalization to unseen circuit configurations. These findings provide early evidence on the limits and potential of LLMs as tools to enhance human capabilities in complex engineering tasks, offering insights into designing reliable, deployable foundation models for structured, real-world applications.

</details>


### [53] [Contrastive Learning for Semi-Supervised Deep Regression with Generalized Ordinal Rankings from Spectral Seriation](https://arxiv.org/abs/2512.09267)
*Ce Wang,Weihang Dai,Hanru Bai,Xiaomeng Li*

Main category: cs.LG

TL;DR: 本文提出了一种半监督对比回归方法（CLSS），它利用无标签数据来提高回归模型的表示能力，并通过频谱序列算法和动态规划算法来恢复和选择鲁棒特征。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习方法在很大程度上依赖标签信息来正确恢复特征的有序关系，这限制了它们在半监督回归中的应用。

Method: 半监督对比回归方法（CLSS），在mini-batch中利用有标签和无标签样本构建特征相似性矩阵，通过谱序列算法恢复无标签样本的精确序数排序。引入有标签样本对序数排序进行正则化，利用动态规划算法选择鲁棒特征，然后将恢复的序数关系用于无标签样本的对比学习。此外，序数排序还可用于监督无标签样本的预测。

Result: 在各种数据集上的实验证明，该方法优于现有的最先进的半监督深度回归方法。

Conclusion: 所提出的CLSS方法有效地利用了无标签数据，通过恢复样本间的序数关系并提供理论保证和实验验证，显著提升了半监督回归模型的性能和鲁棒性。

Abstract: Contrastive learning methods enforce label distance relationships in feature space to improve representation capability for regression models. However, these methods highly depend on label information to correctly recover ordinal relationships of features, limiting their applications to semi-supervised regression. In this work, we extend contrastive regression methods to allow unlabeled data to be used in the semi-supervised setting, thereby reducing the dependence on costly annotations. Particularly we construct the feature similarity matrix with both labeled and unlabeled samples in a mini-batch to reflect inter-sample relationships, and an accurate ordinal ranking of involved unlabeled samples can be recovered through spectral seriation algorithms if the level of error is within certain bounds. The introduction of labeled samples above provides regularization of the ordinal ranking with guidance from the ground-truth label information, making the ranking more reliable. To reduce feature perturbations, we further utilize the dynamic programming algorithm to select robust features for the matrix construction. The recovered ordinal relationship is then used for contrastive learning on unlabeled samples, and we thus allow more data to be used for feature representation learning, thereby achieving more robust results. The ordinal rankings can also be used to supervise predictions on unlabeled samples, serving as an additional training signal. We provide theoretical guarantees and empirical verification through experiments on various datasets, demonstrating that our method can surpass existing state-of-the-art semi-supervised deep regression methods. Our code have been released on https://github.com/xmed-lab/CLSS.

</details>


### [54] [Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design](https://arxiv.org/abs/2512.09329)
*Amin Tavakoli,Raswanth Murugan,Ozan Gokdemir,Arvind Ramanathan,Frances Arnold,Anima Anandkumar*

Main category: cs.LG

TL;DR: 本文提出了一个针对蛋白质序列建模和蛋白质语言模型监督微调（SFT）的通用方法，旨在提高生成蛋白质序列的保真度、可靠性和新颖性，并且不需要昂贵的预编译实验数据集。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）在使大型语言模型适应特定领域方面是标准方法，但其在蛋白质序列建模和蛋白质语言模型（PLMs）中的应用仍然是临时的，主要是因为与自然语言相比，蛋白质的高质量标注数据更难获取。

Method: 该方法利用PLM本身，整合了一个轻量级的整理流程和领域特定的过滤器来构建高质量的训练数据。这些过滤器可以独立地优化PLM的输出，并识别用于体外评估的候选序列。

Result: 与SFT结合使用时，该方法使PLM能够生成更稳定、功能更强的酶，并能将探索扩展到超越自然变体的蛋白质序列空间。以基因组尺度的PLM（GenSLM）应用于色氨酸合酶家族为例，监督微调后的模型不仅生成了更具新颖性的序列，而且在目标设计约束和 emergent 蛋白质特性测量方面都显示出改进的特性。

Conclusion: 本文提出的方法不依赖于蛋白质语言模型（PLM）的选择和蛋白质系统，通过利用PLM自身及其整合的轻量级整理流程和领域特定过滤器，有效地解决了蛋白质序列建模中高质量数据获取困难的问题，显著提升了生成蛋白质序列的性能。

Abstract: Supervised fine-tuning (SFT) is a standard approach for adapting large language models to specialized domains, yet its application to protein sequence modeling and protein language models (PLMs) remains ad hoc. This is in part because high-quality annotated data are far more difficult to obtain for proteins than for natural language. We present a simple and general recipe for fast SFT of PLMs, designed to improve the fidelity, reliability, and novelty of generated protein sequences. Unlike existing approaches that require costly precompiled experimental datasets for SFT, our method leverages the PLM itself, integrating a lightweight curation pipeline with domain-specific filters to construct high-quality training data. These filters can independently refine a PLM's output and identify candidates for in vitro evaluation; when combined with SFT, they enable PLMs to generate more stable and functional enzymes, while expanding exploration into protein sequence space beyond natural variants. Although our approach is agnostic to both the choice of protein language model (PLM) and the protein system, we demonstrate its effectiveness with a genome-scale PLM (GenSLM) applied to the tryptophan synthase enzyme family. The supervised fine-tuned model generates sequences that are not only more novel but also display improved characteristics across both targeted design constraints and emergent protein property measures.

</details>


### [55] [Branching Strategies Based on Subgraph GNNs: A Study on Theoretical Promise versus Practical Reality](https://arxiv.org/abs/2512.09355)
*Junru Zhou,Yicheng Wang,Pan Li*

Main category: cs.LG

TL;DR: 本文探讨了子图GNN在MILP分支中的应用，发现其在理论上能更好地近似强分支，但在实践中由于计算开销大，性能不如MPNNs。


<details>
  <summary>Details</summary>
Motivation: 探索子图GNN作为一种理论上更具表达力但计算成本低于高阶GNN的中间方案，以提升混合整数线性规划（MILP）中“学习分支”的效率和质量。

Method: 本文通过理论分析，证明了节点锚定子图GNN（其表达能力低于3-WL）足以近似强分支分数。同时，通过在四个基准数据集上进行实证评估，比较了子图GNN、MPNNs和启发式方法的性能。

Result: 理论上，节点锚定子图GNN能够更好地近似强分支分数。然而，在实践中，由于子图GNN的O(n)复杂性开销，导致内存瓶颈和求解时间比MPNNs和启发式方法更慢。

Conclusion: 对于MILP分支，当前表达性GNN的计算成本超出了其在决策质量上的提升，未来的研究应侧重于在保持效率的同时提高表达能力。

Abstract: Graph Neural Networks (GNNs) have emerged as a promising approach for ``learning to branch'' in Mixed-Integer Linear Programming (MILP). While standard Message-Passing GNNs (MPNNs) are efficient, they theoretically lack the expressive power to fully represent MILP structures. Conversely, higher-order GNNs (like 2-FGNNs) are expressive but computationally prohibitive. In this work, we investigate Subgraph GNNs as a theoretical middle ground. Crucially, while previous work [Chen et al., 2025] demonstrated that GNNs with 3-WL expressive power can approximate Strong Branching, we prove a sharper result: node-anchored Subgraph GNNs whose expressive power is strictly lower than 3-WL [Zhang et al., 2023] are sufficient to approximate Strong Branching scores. However, our extensive empirical evaluation on four benchmark datasets reveals a stark contrast between theory and practice. While node-anchored Subgraph GNNs theoretically offer superior branching decisions, their $O(n)$ complexity overhead results in significant memory bottlenecks and slower solving times than MPNNs and heuristics. Our results indicate that for MILP branching, the computational cost of expressive GNNs currently outweighs their gains in decision quality, suggesting that future research must focus on efficiency-preserving expressivity.

</details>


### [56] [A Granular Framework for Construction Material Price Forecasting: Econometric and Machine-Learning Approaches](https://arxiv.org/abs/2512.09360)
*Boge Lyu,Qianye Yin,Iris Denise Tommelein,Hanyang Liu,Karnamohit Ranka,Karthik Yeluripati,Junzhe Shi*

Main category: cs.LG

TL;DR: 该研究提出了一个预测建筑材料价格的框架，该框架利用CSI MasterFormat在六位数字的截面级别进行预测，并结合解释变量来提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 建筑材料价格的持续波动给成本估算、预算编制和项目交付带来了巨大风险，因此迫切需要粒度化和可扩展的预测方法。

Method: 该框架利用建筑规范协会（CSI）MasterFormat作为目标数据结构，支持在六位数字的截面级别进行预测。为了提高预测准确性，该框架整合了解释变量，如原材料价格、商品指数和宏观经济指标。研究评估了四种时间序列模型：长短期记忆（LSTM）、差分整合移动平均自回归模型（ARIMA）、向量误差修正模型（VECM）和Chronos-Bolt。

Result: 结果表明，在所有模型中，引入解释变量都显著提高了预测性能。在测试方法中，LSTM模型的准确性始终最高，RMSE值低至1.390，MAPE值为0.957，比传统的统计时间序列模型ARIMA提高了59%。

Conclusion: 这项研究提供了一个强大的方法，使业主和承包商能够改进预算实践，并在确定性水平上实现更可靠的成本估算。

Abstract: The persistent volatility of construction material prices poses significant risks to cost estimation, budgeting, and project delivery, underscoring the urgent need for granular and scalable forecasting methods. This study develops a forecasting framework that leverages the Construction Specifications Institute (CSI) MasterFormat as the target data structure, enabling predictions at the six-digit section level and supporting detailed cost projections across a wide spectrum of building materials. To enhance predictive accuracy, the framework integrates explanatory variables such as raw material prices, commodity indexes, and macroeconomic indicators. Four time-series models, Long Short-Term Memory (LSTM), Autoregressive Integrated Moving Average (ARIMA), Vector Error Correction Model (VECM), and Chronos-Bolt, were evaluated under both baseline configurations (using CSI data only) and extended versions with explanatory variables. Results demonstrate that incorporating explanatory variables significantly improves predictive performance across all models. Among the tested approaches, the LSTM model consistently achieved the highest accuracy, with RMSE values as low as 1.390 and MAPE values of 0.957, representing improvements of up to 59\% over the traditional statistical time-series model, ARIMA. Validation across multiple CSI divisions confirmed the framework's scalability, while Division 06 (Wood, Plastics, and Composites) is presented in detail as a demonstration case. This research offers a robust methodology that enables owners and contractors to improve budgeting practices and achieve more reliable cost estimation at the Definitive level.

</details>


### [57] [KGOT: Unified Knowledge Graph and Optimal Transport Pseudo-Labeling for Molecule-Protein Interaction Prediction](https://arxiv.org/abs/2512.09365)
*Jiayu Qin,Zhengquan Luo,Guy Tadmor,Changyou Chen,David Zeevi,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 该篇论文提出了一种新的分子-蛋白质相互作用（MPIs）预测框架，该框架通过整合多种生物学数据集和利用基于最优传输的伪标签方法，显著提高了MPI预测的准确性和零样本能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MPI模型面临两个主要挑战：1. 标记的分子-蛋白质对稀缺，限制了模型性能；2. 大多数方法仅依赖分子和蛋白质特征，忽略了更广泛的生物学背景信息。

Method: 该框架首先整合了多样化的生物学数据集，包括分子、蛋白质、基因和通路级别的相互作用。随后，开发了一种基于最优传输的方法来为未标记的分子-蛋白质对生成高质量的伪标签，该方法利用已知相互作用的潜在分布指导标签分配。通过将伪标签视为连接不同生物学模态的机制，有效利用异构数据增强MPI预测。

Result: 在多个MPI数据集（包括虚拟筛选任务和蛋白质检索任务）上进行了评估，结果表明该框架在预测准确性和零样本能力方面均显著优于现有最先进的方法。

Conclusion: 该方法不仅提供了MPI预测的解决方案，还为利用多样化生物数据源解决传统上受限于单模态或双模态学习的问题提供了一个新范例，为计算生物学和药物发现的未来发展铺平了道路。

Abstract: Predicting molecule-protein interactions (MPIs) is a fundamental task in computational biology, with crucial applications in drug discovery and molecular function annotation. However, existing MPI models face two major challenges. First, the scarcity of labeled molecule-protein pairs significantly limits model performance, as available datasets capture only a small fraction of biological relevant interactions. Second, most methods rely solely on molecular and protein features, ignoring broader biological context such as genes, metabolic pathways, and functional annotations that could provide essential complementary information. To address these limitations, our framework first aggregates diverse biological datasets, including molecular, protein, genes and pathway-level interactions, and then develop an optimal transport-based approach to generate high-quality pseudo-labels for unlabeled molecule-protein pairs, leveraging the underlying distribution of known interactions to guide label assignment. By treating pseudo-labeling as a mechanism for bridging disparate biological modalities, our approach enables the effective use of heterogeneous data to enhance MPI prediction. We evaluate our framework on multiple MPI datasets including virtual screening tasks and protein retrieval tasks, demonstrating substantial improvements over state-of-the-art methods in prediction accuracies and zero shot ability across unseen interactions. Beyond MPI prediction, our approach provides a new paradigm for leveraging diverse biological data sources to tackle problems traditionally constrained by single- or bi-modal learning, paving the way for future advances in computational biology and drug discovery.

</details>


### [58] [Are Hypervectors Enough? Single-Call LLM Reasoning over Knowledge Graphs](https://arxiv.org/abs/2512.09369)
*Yezi Liu,William Youngwoo Chung,Hanning Chen,Calvin Yeung,Mohsen Imani*

Main category: cs.LG

TL;DR: PathHD是一个轻量级且无编码器的知识图谱推理框架，它用超维度计算取代神经路径评分，并且每次查询只使用一个LLM调用。PathHD在WebQSP、CWQ和GrailQA分割上，实现了与强大的神经基线相当或更好的Hits@1，同时将端到端延迟降低了40-60%，GPU内存减少了3-5倍。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱上的大型语言模型推理方法依赖于繁重的神经编码器或重复的LLM调用，导致高延迟、高GPU成本和不透明的决策，这阻碍了忠实、可扩展的部署。

Method: 我们提出了PathHD，一个轻量级且无编码器的知识图谱推理框架，用超维度计算（HDC）取代神经路径评分，并且每次查询只使用一个大型语言模型（LLM）调用。PathHD将关系路径编码为块对角GHRR超向量，使用块式余弦相似度和Top-K剪枝对候选进行排序，然后进行一次性LLM裁决以产生最终答案和引用的支持路径。

Result: PathHD在WebQSP、CWQ和GrailQA分割数据集上，实现了与强大的神经基线相当或更好的Hits@1，同时每次查询只使用一个LLM调用；将端到端延迟降低了40-60%，GPU内存减少了3-5倍，这得益于无编码器检索；并提供了忠实、路径基础的理由，改善了错误诊断和可控性。

Conclusion: 精心设计的HDC表示为高效的KG-LLM推理提供了实用的基础，在准确性-效率-可解释性之间提供了良好的权衡。

Abstract: Recent advances in large language models (LLMs) have enabled strong reasoning over both structured and unstructured knowledge. When grounded on knowledge graphs (KGs), however, prevailing pipelines rely on heavy neural encoders to embed and score symbolic paths or on repeated LLM calls to rank candidates, leading to high latency, GPU cost, and opaque decisions that hinder faithful, scalable deployment. We propose PathHD, a lightweight and encoder-free KG reasoning framework that replaces neural path scoring with hyperdimensional computing (HDC) and uses only a single LLM call per query. PathHD encodes relation paths into block-diagonal GHRR hypervectors, ranks candidates with blockwise cosine similarity and Top-K pruning, and then performs a one-shot LLM adjudication to produce the final answer together with cited supporting paths. Technically, PathHD is built on three ingredients: (i) an order-aware, non-commutative binding operator for path composition, (ii) a calibrated similarity for robust hypervector-based retrieval, and (iii) a one-shot adjudication step that preserves interpretability while eliminating per-path LLM scoring. On WebQSP, CWQ, and the GrailQA split, PathHD (i) attains comparable or better Hits@1 than strong neural baselines while using one LLM call per query; (ii) reduces end-to-end latency by $40-60\%$ and GPU memory by $3-5\times$ thanks to encoder-free retrieval; and (iii) delivers faithful, path-grounded rationales that improve error diagnosis and controllability. These results indicate that carefully designed HDC representations provide a practical substrate for efficient KG-LLM reasoning, offering a favorable accuracy-efficiency-interpretability trade-off.

</details>


### [59] [CFLight: Enhancing Safety with Traffic Signal Control through Counterfactual Learning](https://arxiv.org/abs/2512.09368)
*Mingyuan Li,Chunyu Liu,Zhuojun Li,Xiao Liu,Guangsheng Yu,Bo Du,Jun Shen,Qiang Wu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为CFLight的新型框架，通过反事实学习（CounterFactual Learning）来改进交通信号控制（TSC）中的强化学习（RL），以在提高驾驶效率的同时显著增强道路安全性，尤其是在交叉路口，旨在减少交通事故。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在优化交通信号控制方面日益普及，但其方法往往优先考虑驾驶效率而非安全性，未能有效平衡这两个关键因素，且解释性不足。

Method: 本文引入了一个基于反事实学习的新颖框架，用于解决在不安全事件发生时，通过回溯并执行替代动作，判断事件是否会在后续阶段再次发生的问题。为此，论文提出了一个新的结构因果模型来预测执行不同动作后的结果，并提出了一个新的反事实模块，该模块与额外的“X”模块集成，以促进安全的强化学习实践。

Result: CFLight算法能够有效处理具有挑战性的安全事件，并通过近零碰撞控制策略显著提高交叉路口安全性。通过对真实世界和合成数据集进行广泛的数值实验，结果表明，与传统强化学习方法和近期安全强化学习模型相比，CFLight减少了碰撞并改善了整体交通性能。

Conclusion: CFLight框架为强化学习方法提供了一种通用且安全的方法，为其他领域的应用开辟了可能性。

Abstract: Traffic accidents result in millions of injuries and fatalities globally, with a significant number occurring at intersections each year. Traffic Signal Control (TSC) is an effective strategy for enhancing safety at these urban junctures. Despite the growing popularity of Reinforcement Learning (RL) methods in optimizing TSC, these methods often prioritize driving efficiency over safety, thus failing to address the critical balance between these two aspects. Additionally, these methods usually need more interpretability. CounterFactual (CF) learning is a promising approach for various causal analysis fields. In this study, we introduce a novel framework to improve RL for safety aspects in TSC. This framework introduces a novel method based on CF learning to address the question: ``What if, when an unsafe event occurs, we backtrack to perform alternative actions, and will this unsafe event still occur in the subsequent period?'' To answer this question, we propose a new structure causal model to predict the result after executing different actions, and we propose a new CF module that integrates with additional ``X'' modules to promote safe RL practices. Our new algorithm, CFLight, which is derived from this framework, effectively tackles challenging safety events and significantly improves safety at intersections through a near-zero collision control strategy. Through extensive numerical experiments on both real-world and synthetic datasets, we demonstrate that CFLight reduces collisions and improves overall traffic performance compared to conventional RL methods and the recent safe RL model. Moreover, our method represents a generalized and safe framework for RL methods, opening possibilities for applications in other domains. The data and code are available in the github https://github.com/MJLee00/CFLight-Enhancing-Safety-with-Traffic-Signal-Control-through-Counterfactual-Learning.

</details>


### [60] [Federated Distillation Assisted Vehicle Edge Caching Scheme Based on Lightweight DDPM](https://arxiv.org/abs/2512.09378)
*Xun Li,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen,Khaled B. Letaief*

Main category: cs.LG

TL;DR: 本文提出了一种基于轻量级去噪扩散概率模型（LDPM）的联邦蒸馏辅助车辆边缘缓存方案，以解决传统联邦学习在车辆边缘缓存中存在的通信开销大和训练失败问题。


<details>
  <summary>Details</summary>
Motivation: 车辆边缘缓存是一种很有前景的技术，可以显著降低车辆用户（VU）访问内容的延迟。准确预测VU感兴趣的内容同时保护用户隐私至关重要。传统的联邦学习虽然可以保护隐私，但存在通信开销大和训练失败的问题。

Method: 提出了一种联邦蒸馏辅助车辆边缘缓存方案，并结合了轻量级去噪扩散概率模型（LDPM）。

Result: 仿真结果表明，所提出的车辆边缘缓存方案对车速变化具有良好的鲁棒性，显著降低了通信开销，提高了缓存命中率。

Conclusion: 所提出的联邦蒸馏辅助车辆边缘缓存方案能够有效解决传统联邦学习在车辆边缘缓存中面临的挑战，并在保护用户隐私的同时提升系统性能。

Abstract: Vehicle edge caching is a promising technology that can significantly reduce the latency for vehicle users (VUs) to access content by pre-caching user-interested content at edge nodes. It is crucial to accurately predict the content that VUs are interested in without exposing their privacy. Traditional federated learning (FL) can protect user privacy by sharing models rather than raw data. However, the training of FL requires frequent model transmission, which can result in significant communication overhead. Additionally, vehicles may leave the road side unit (RSU) coverage area before training is completed, leading to training failures. To address these issues, in this letter, we propose a federated distillation-assisted vehicle edge caching scheme based on lightweight denoising diffusion probabilistic model (LDPM). The simulation results demonstrate that the proposed vehicle edge caching scheme has good robustness to variations in vehicle speed, significantly reducing communication overhead and improving cache hit percentage.

</details>


### [61] [Towards Resilient Transportation: A Conditional Transformer for Accident-Informed Traffic Forecasting](https://arxiv.org/abs/2512.09398)
*Hongjun Wang,Jiawei Yong,Jiawei Wang,Shintaro Fukushima,Renhe Jiang*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为ConFormer的新型交通预测模型，它通过整合交通事故和法规等外部因素，在两个新的交通数据集上超越了现有最先进的模型。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习取得了进展，但交通预测仍然是一个关键挑战，现有模型由于数据集成有限，往往忽略了交通事故和法规等外部因素的复杂影响，从而阻碍了准确预测。

Method: 本研究提出了ConFormer（Conditional Transformer）框架，该框架将图传播与引导归一化层相结合，并利用集成了交通事故和法规数据的东京和加利福尼亚交通数据集进行训练。ConFormer通过根据历史模式动态调整空间和时间节点关系来提高预测精度。

Result: ConFormer模型在预测性能和效率方面均超越了最先进的STAEFormer，计算成本更低，参数需求更少。广泛的评估表明，ConFormer在多个指标上持续优于主流时空基线。

Conclusion: ConFormer模型通过有效地整合外部数据并动态调整时空关系，显著提升了交通预测的准确性和效率，为交通预测研究带来了新的进展。

Abstract: Traffic prediction remains a key challenge in spatio-temporal data mining, despite progress in deep learning. Accurate forecasting is hindered by the complex influence of external factors such as traffic accidents and regulations, often overlooked by existing models due to limited data integration. To address these limitations, we present two enriched traffic datasets from Tokyo and California, incorporating traffic accident and regulation data. Leveraging these datasets, we propose ConFormer (Conditional Transformer), a novel framework that integrates graph propagation with guided normalization layer. This design dynamically adjusts spatial and temporal node relationships based on historical patterns, enhancing predictive accuracy. Our model surpasses the state-of-the-art STAEFormer in both predictive performance and efficiency, achieving lower computational costs and reduced parameter demands. Extensive evaluations demonstrate that ConFormer consistently outperforms mainstream spatio-temporal baselines across multiple metrics, underscoring its potential to advance traffic prediction research.

</details>


### [62] [Cauchy-Schwarz Fairness Regularizer](https://arxiv.org/abs/2512.09467)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: 该论文提出了柯西-施瓦茨（CS）公平性正则化器，它通过惩罚预测分布与敏感属性之间的CS散度，以提高机器学习模型在不同敏感组间的公平性，并在多个数据集上取得了更好的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 机器学习中的群组公平性通常通过添加正则化器来实现，以减少模型预测与敏感属性之间的依赖性。然而，现有正则化器基于异构距离度量和设计选择，导致其行为难以解释且在不同任务中的性能不一致。因此，一个基本问题是：一个好的公平性正则化器应具备哪些特性？

Method: 作者将现有方法分为三类：(i) 匹配敏感组之间的预测统计数据；(ii) 调整潜在表示；(iii) 直接最小化预测与敏感属性之间的依赖性。在此基础上，作者提出了柯西-施瓦茨（CS）公平性正则化器，通过惩罚以敏感组为条件的预测分布之间的经验CS散度来确保公平性。在假设为高斯分布的比较下，CS散度比Kullback-Leibler散度、最大均值差异和人口统计均值差异产生了更紧密的界限。

Result: 通过在四个表格基准数据集和一个图像数据集上进行大量实验，结果表明所提出的CS正则化器在保持竞争性准确性的同时，一致地改善了人口统计均等（Demographic Parity）和机会均等（Equal Opportunity）指标，并且在超参数设置上比以前的正则化器实现了更稳定的实用性-公平性权衡。

Conclusion: 本研究通过分析现有公平性正则化器的不足，提出了一种新的柯西-施瓦茨（CS）公平性正则化器。该正则化器在理论上具有更好的泛化界限和对尺度差异的鲁棒性，并且能够处理任意预测分布。实验结果验证了CS正则化器在提高公平性指标方面的有效性，并展现出比现有方法更稳定的性能。

Abstract: Group fairness in machine learning is often enforced by adding a regularizer that reduces the dependence between model predictions and sensitive attributes. However, existing regularizers are built on heterogeneous distance measures and design choices, which makes their behavior hard to reason about and their performance inconsistent across tasks. This raises a basic question: what properties make a good fairness regularizer? We address this question by first organizing existing in-process methods into three families: (i) matching prediction statistics across sensitive groups, (ii) aligning latent representations, and (iii) directly minimizing dependence between predictions and sensitive attributes. Through this lens, we identify desirable properties of the underlying distance measure, including tight generalization bounds, robustness to scale differences, and the ability to handle arbitrary prediction distributions. Motivated by these properties, we propose a Cauchy-Schwarz (CS) fairness regularizer that penalizes the empirical CS divergence between prediction distributions conditioned on sensitive groups. Under a Gaussian comparison, we show that CS divergence yields a tighter bound than Kullback-Leibler divergence, Maximum Mean Discrepancy, and the mean disparity used in Demographic Parity, and we discuss how these advantages translate to a distribution-free, kernel-based estimator that naturally extends to multiple sensitive attributes. Extensive experiments on four tabular benchmarks and one image dataset demonstrate that the proposed CS regularizer consistently improves Demographic Parity and Equal Opportunity metrics while maintaining competitive accuracy, and achieves a more stable utility-fairness trade-off across hyperparameter settings compared to prior regularizers.

</details>


### [63] [Representation Invariance and Allocation: When Subgroup Balance Matters](https://arxiv.org/abs/2512.09496)
*Anissa Alloula,Charles Jones,Zuzanna Wakefield-Skorniewska,Francesco Quinzan,Bartłomiej Papież*

Main category: cs.LG

TL;DR: 这篇论文研究了训练数据中不同人群代表性不均衡对模型泛化能力的影响。


<details>
  <summary>Details</summary>
Motivation: 在某些情况下，不平衡的数据分布实际上可以改善子群体的性能，而在另一些情况下，子群体性能不受训练期间整个子群体缺失的影响。

Method: 我们对四种视觉和语言模型中的子组分配进行了系统研究，改变了训练数据组成以表征子组性能对数据平衡的敏感性。我们提出了潜在分离假设，该假设指出部分微调模型对子组表示的依赖性取决于预训练模型潜在空间中子组之间的分离程度。

Result: 我们发现，模型对子群体表示的依赖性取决于预训练模型潜在空间中子群体之间的分离程度。

Conclusion: 潜在子群体分离的定量分析可以为数据收集和平衡决策提供信息，从而应用于基础模型的微调。

Abstract: Unequal representation of demographic groups in training data poses challenges to model generalisation across populations. Standard practice assumes that balancing subgroup representation optimises performance. However, recent empirical results contradict this assumption: in some cases, imbalanced data distributions actually improve subgroup performance, while in others, subgroup performance remains unaffected by the absence of an entire subgroup during training. We conduct a systematic study of subgroup allocation across four vision and language models, varying training data composition to characterise the sensitivity of subgroup performance to data balance. We propose the latent separation hypothesis, which states that a partially fine-tuned model's dependence on subgroup representation is determined by the degree of separation between subgroups in the latent space of the pre-trained model. We formalise this hypothesis, provide theoretical analysis, and validate it empirically. Finally, we present a practical application to foundation model fine-tuning, demonstrating that quantitative analysis of latent subgroup separation can inform data collection and balancing decisions.

</details>


### [64] [Contextual Dynamic Pricing with Heterogeneous Buyers](https://arxiv.org/abs/2512.09513)
*Thodoris Lykouris,Sloan Nietert,Princewill Okoroafor,Chara Podimata,Julian Zimmert*

Main category: cs.LG

TL;DR: 该文章研究了具有异构买方群体的上下文动态定价问题，并提出了一种基于乐观后验抽样的算法。


<details>
  <summary>Details</summary>
Motivation: 研究现有研究在买方类型同质性假设下的不足，并解决具有异构买方群体的上下文动态定价问题。

Method: 开发了一种基于乐观后验抽样的上下文定价算法，并针对非上下文定价情况提出了方差感知缩放算法。

Result: 所提出的算法在regret方面取得了$\widetilde{O}(K_{\star}\sqrt{dT})$的界限，并在$d$和$T$方面达到了下界，同时在非上下文定价情况下实现了对$K_{\star}$的最优依赖。

Conclusion: 该研究为具有异构买方群体的上下文动态定价问题提供了一种有效的解决方案，并理论上证明了其性能。

Abstract: We initiate the study of contextual dynamic pricing with a heterogeneous population of buyers, where a seller repeatedly posts prices (over $T$ rounds) that depend on the observable $d$-dimensional context and receives binary purchase feedback. Unlike prior work assuming homogeneous buyer types, in our setting the buyer's valuation type is drawn from an unknown distribution with finite support size $K_{\star}$. We develop a contextual pricing algorithm based on optimistic posterior sampling with regret $\widetilde{O}(K_{\star}\sqrt{dT})$, which we prove to be tight in $d$ and $T$ up to logarithmic terms. Finally, we refine our analysis for the non-contextual pricing case, proposing a variance-aware zooming algorithm that achieves the optimal dependence on $K_{\star}$.

</details>


### [65] [QuanvNeXt: An end-to-end quanvolutional neural network for EEG-based detection of major depressive disorder](https://arxiv.org/abs/2512.09517)
*Nabil Anan Orka,Ehtashamul Haque,Maftahul Jannat,Md Abdul Awal,Mohammad Ali Moni*

Main category: cs.LG

TL;DR: QuanvNeXt是一个端到端的全卷积模型，用于基于脑电图的抑郁症诊断，它引入了新颖的交叉残差块，在两个开源数据集上实现了93.1%的平均准确率和97.2%的平均AUC-ROC，优于现有最新基线。


<details>
  <summary>Details</summary>
Motivation: 目前基于脑电图的抑郁症诊断模型在特征同质性和参数效率方面存在不足，该研究旨在提出一个更有效、更可靠的模型。

Method: 提出了一种名为QuanvNeXt的端到端全卷积模型。该模型包含一个新颖的交叉残差块，用于减少特征同质性并加强跨特征关系，同时保持参数效率。

Result: QuanvNeXt在两个开源数据集上的平均准确率达到93.1%，平均AUC-ROC为97.2%，优于InceptionTime等现有最新基线（91.7%准确率，95.9% AUC-ROC）。不确定性分析显示，即使在最高扰动下，ECE分数也保持在较低至中等水平。事后可解释AI分析证实，QuanvNeXt能有效识别区分健康对照组和重度抑郁症患者的时频谱模式。

Conclusion: QuanvNeXt为基于脑电图的抑郁症诊断提供了一种高效可靠的方法。

Abstract: This study presents QuanvNeXt, an end-to-end fully quanvolutional model for EEG-based depression diagnosis. QuanvNeXt incorporates a novel Cross Residual block, which reduces feature homogeneity and strengthens cross-feature relationships while retaining parameter efficiency. We evaluated QuanvNeXt on two open-source datasets, where it achieved an average accuracy of 93.1% and an average AUC-ROC of 97.2%, outperforming state-of-the-art baselines such as InceptionTime (91.7% accuracy, 95.9% AUC-ROC). An uncertainty analysis across Gaussian noise levels demonstrated well-calibrated predictions, with ECE scores remaining low (0.0436, Dataset 1) to moderate (0.1159, Dataset 2) even at the highest perturbation (ε = 0.1). Additionally, a post-hoc explainable AI analysis confirmed that QuanvNeXt effectively identifies and learns spectrotemporal patterns that distinguish between healthy controls and major depressive disorder. Overall, QuanvNeXt establishes an efficient and reliable approach for EEG-based depression diagnosis.

</details>


### [66] [Stanford Sleep Bench: Evaluating Polysomnography Pre-training Methods for Sleep Foundation Models](https://arxiv.org/abs/2512.09591)
*Magnus Ruud Kjaer,Rahul Thapa,Gauri Ganjoo,Hyatt Moore,Poul Joergen Jennum,Brandon M. Westover,James Zou,Emmanuel Mignot,Bryan He,Andreas Brink-Kjaer*

Main category: cs.LG

TL;DR: Stanford Sleep Bench是一个大型多模态PSG数据集，包含17,467条记录和13项临床疾病预测任务，旨在通过系统评估SSRL预训练方法，解决睡眠基础模型在多样化任务的共享数据集和基准方面的不足。


<details>
  <summary>Details</summary>
Motivation: 睡眠分析中缺乏一个共享的、包含多样化任务的数据集和评估基准，以及对SSRL方法在睡眠相关任务中系统评估的缺失，这阻碍了睡眠基础模型的发展。

Method: 本文引入了Stanford Sleep Bench，一个包含17,467条PSG记录和13项临床疾病预测任务的大型数据集。研究人员在该数据集上系统评估了多种SSRL预训练方法，并在睡眠分期、呼吸暂停诊断、年龄估计以及疾病和死亡率预测这四个下游任务上评估了它们的性能。

Result: 在睡眠分期、呼吸暂停诊断和年龄估计任务上，多种预训练方法取得了可比的性能。然而，在死亡率和疾病预测任务上，对比学习显著优于其他方法，并且预训练收敛速度更快。

Conclusion: Stanford Sleep Bench的发布以及对SSRL方法的系统评估，为睡眠基础模型的发展提供了重要的资源和基准。对比学习在临床疾病预测任务中的优越性，为未来的睡眠分析研究指明了方向。

Abstract: Polysomnography (PSG), the gold standard test for sleep analysis, generates vast amounts of multimodal clinical data, presenting an opportunity to leverage self-supervised representation learning (SSRL) for pre-training foundation models to enhance sleep analysis. However, progress in sleep foundation models is hindered by two key limitations: (1) the lack of a shared dataset and benchmark with diverse tasks for training and evaluation, and (2) the absence of a systematic evaluation of SSRL approaches across sleep-related tasks. To address these gaps, we introduce Stanford Sleep Bench, a large-scale PSG dataset comprising 17,467 recordings totaling over 163,000 hours from a major sleep clinic, including 13 clinical disease prediction tasks alongside canonical sleep-related tasks such as sleep staging, apnea diagnosis, and age estimation. We systematically evaluate SSRL pre-training methods on Stanford Sleep Bench, assessing downstream performance across four tasks: sleep staging, apnea diagnosis, age estimation, and disease and mortality prediction. Our results show that multiple pretraining methods achieve comparable performance for sleep staging, apnea diagnosis, and age estimation. However, for mortality and disease prediction, contrastive learning significantly outperforms other approaches while also converging faster during pretraining. To facilitate reproducibility and advance sleep research, we will release Stanford Sleep Bench along with pretrained model weights, training pipelines, and evaluation code.

</details>


### [67] [Semantic-Aware Cooperative Communication and Computation Framework in Vehicular Networks](https://arxiv.org/abs/2512.09621)
*Jingbo Zhang,Maoxin Ji,Qiong Wu,Pingyi Fan,Kezhi Wang,Wen Chen*

Main category: cs.LG

TL;DR: 本文提出了一种结合语义通信和车载边缘计算的三方协作语义通信框架（TCSC），以优化车联网（IoV）在高速公路场景中的任务卸载，并通过多智能体近端策略优化和线性规划解决了语义符号数量和卸载比的优化问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决车联网（IoV）中高效的边缘任务处理问题，特别是在高速公路场景下，本文旨在结合语义通信（SC）与车载边缘计算（VEC）的优势，提出一种新的任务卸载范式。

Method: 本文提出了一种三方协作语义通信（TCSC）框架，该框架允许车辆用户（VUs）通过车对基础设施（V2I）和车对车（V2V）通信进行语义任务卸载。该框架将任务延迟和语义符号数量纳入考虑，构建了一个混合整数非线性规划（MINLP）问题。此问题被分解为两个子问题：1. 提出了一种基于参数分布噪声的多智能体近端策略优化任务卸载方法（MAPPO-PDN）来优化语义符号的数量。2. 利用线性规划（LP）来解决卸载比的问题。

Result: 仿真结果表明，本文提出的方案在性能上优于其他算法。

Conclusion: 本文成功地提出并验证了一个结合语义通信和车载边缘计算的三方协作语义通信框架（TCSC），通过创新的优化方法有效解决了高速公路场景下车联网任务卸载中的语义符号数量和卸载比问题，显著提升了系统性能。

Abstract: Semantic Communication (SC) combined with Vehicular edge computing (VEC) provides an efficient edge task processing paradigm for Internet of Vehicles (IoV). Focusing on highway scenarios, this paper proposes a Tripartite Cooperative Semantic Communication (TCSC) framework, which enables Vehicle Users (VUs) to perform semantic task offloading via Vehicle-to-Infrastructure (V2I) and Vehicle-to-Vehicle (V2V) communications. Considering task latency and the number of semantic symbols, the framework constructs a Mixed-Integer Nonlinear Programming (MINLP) problem, which is transformed into two subproblems. First, we innovatively propose a multi-agent proximal policy optimization task offloading optimization method based on parametric distribution noise (MAPPO-PDN) to solve the optimization problem of the number of semantic symbols; second, linear programming (LP) is used to solve offloading ratio. Simulations show that performance of this scheme is superior to that of other algorithms.

</details>


### [68] [Membership and Dataset Inference Attacks on Large Audio Generative Models](https://arxiv.org/abs/2512.09654)
*Jakub Proboszcz,Paweł Kochanski,Karol Korszun,Donato Crisostomi,Giorgio Strano,Emanuele Rodolà,Kamil Deja,Jan Dubinski*

Main category: cs.LG

TL;DR: 这篇论文研究了大型生成式音频模型的版权问题，并提出数据集推断（DI）作为一种有效的验证方法。


<details>
  <summary>Details</summary>
Motivation: 生成式音频模型在质量和表现力方面取得了快速进展，但引发了版权担忧。核心问题在于是否能可靠地验证艺术家的材料是否被用于训练。

Method: 本文通过对开源生成式音频模型进行成员推断攻击（MIA）来调查这种验证的可行性，并在此基础上引入数据集推断（DI）方法。

Result: 经验结果表明，对于在大型多样化数据集上训练的模型，单独的成员推断在规模化应用时效果有限，因为每个样本的成员信号较弱。然而，数据集推断在音频领域是成功的，为评估艺术家的作品是否对模型训练做出了贡献提供了一种更实用的机制。

Conclusion: 数据集推断为大型音频生成模型时代的版权保护和数据集责任提供了一个有前景的方向。

Abstract: Generative audio models, based on diffusion and autoregressive architectures, have advanced rapidly in both quality and expressiveness. This progress, however, raises pressing copyright concerns, as such models are often trained on vast corpora of artistic and commercial works. A central question is whether one can reliably verify if an artist's material was included in training, thereby providing a means for copyright holders to protect their content. In this work, we investigate the feasibility of such verification through membership inference attacks (MIA) on open-source generative audio models, which attempt to determine whether a specific audio sample was part of the training set. Our empirical results show that membership inference alone is of limited effectiveness at scale, as the per-sample membership signal is weak for models trained on large and diverse datasets. However, artists and media owners typically hold collections of works rather than isolated samples. Building on prior work in text and vision domains, in this work we focus on dataset inference (DI), which aggregates diverse membership evidence across multiple samples. We find that DI is successful in the audio domain, offering a more practical mechanism for assessing whether an artist's works contributed to model training. Our results suggest DI as a promising direction for copyright protection and dataset accountability in the era of large audio generative models.

</details>


### [69] [Circuits, Features, and Heuristics in Molecular Transformers](https://arxiv.org/abs/2512.09757)
*Kristof Varadi,Mark Marosi,Peter Antal*

Main category: cs.LG

TL;DR: 本文对自回归Transformer在生成药物小分子方面的能力进行了机制分析，揭示了模型在不同抽象层次上捕捉分子表示规则的计算机制。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在生成有效和多样化的化学结构方面表现出色，但其捕捉分子表示规则的机制尚不明确。因此，本文旨在通过对自回归Transformer进行机制分析，揭示其在不同抽象层次上支持其能力的计算结构。

Method: 本文对在药物样小分子上训练的自回归Transformer进行了机制分析。研究者识别了与低级语法解析和更抽象的化学有效性约束一致的计算模式。此外，研究者使用稀疏自动编码器（SAE）提取了与化学相关激活模式相关的特征字典。

Result: 研究结果表明，Transformer模型能够通过特定的计算模式捕获低级语法规则和更抽象的化学有效性约束。通过SAE提取的特征字典进一步证实了模型内部存在与化学概念对应的激活模式。

Conclusion: 本文通过机制分析揭示了自回归Transformer在生成化学结构时捕捉分子表示规则的计算机制。这些机制洞察不仅加深了对模型工作原理的理解，而且在下游任务中转化为预测性能的提升，表明机制洞察可以应用于实际场景。

Abstract: Transformers generate valid and diverse chemical structures, but little is known about the mechanisms that enable these models to capture the rules of molecular representation. We present a mechanistic analysis of autoregressive transformers trained on drug-like small molecules to reveal the computational structure underlying their capabilities across multiple levels of abstraction. We identify computational patterns consistent with low-level syntactic parsing and more abstract chemical validity constraints. Using sparse autoencoders (SAEs), we extract feature dictionaries associated with chemically relevant activation patterns. We validate our findings on downstream tasks and find that mechanistic insights can translate to predictive performance in various practical settings.

</details>


### [70] [A data-driven approach to linking design features with manufacturing process data for sustainable product development](https://arxiv.org/abs/2512.09690)
*Jiahang Li,Lucas Cazzonelli,Jacqueline Höllig,Markus Doellken,Sven Matthiesen*

Main category: cs.LG

TL;DR: 该论文提出了一种数据驱动的方法，用于映射和分析设计特征与制造过程数据之间的关系，从而实现自动化的设计改进建议和可持续产品开发。


<details>
  <summary>Details</summary>
Motivation: 目前数据驱动方法在特定领域应用，但缺乏整合设计特征与制造过程数据。设计决策显著影响制造结果，缺乏整合限制了数据驱动产品设计的改进潜力。

Method: 本文提出了一种数据驱动的方法，用于映射和分析设计特征与制造过程数据之间的关系。开发了一个全面的系统架构，以确保连续的数据收集和整合。利用设计特征与制造过程数据之间的联系，开发了一个机器学习模型，以实现自动化的设计改进建议。

Result: 通过将制造过程数据与可持续性指标相结合，该方法为可持续产品开发开辟了新的可能性。

Conclusion: 该方法通过整合设计特征和制造过程数据，并结合机器学习模型，可以实现自动化的设计改进和可持续产品开发。

Abstract: The growing adoption of Industrial Internet of Things (IIoT) technologies enables automated, real-time collection of manufacturing process data, unlocking new opportunities for data-driven product development. Current data-driven methods are generally applied within specific domains, such as design or manufacturing, with limited exploration of integrating design features and manufacturing process data. Since design decisions significantly affect manufacturing outcomes, such as error rates, energy consumption, and processing times, the lack of such integration restricts the potential for data-driven product design improvements. This paper presents a data-driven approach to mapping and analyzing the relationship between design features and manufacturing process data. A comprehensive system architecture is developed to ensure continuous data collection and integration. The linkage between design features and manufacturing process data serves as the basis for developing a machine learning model that enables automated design improvement suggestions. By integrating manufacturing process data with sustainability metrics, this approach opens new possibilities for sustainable product development.

</details>


### [71] [Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning](https://arxiv.org/abs/2512.09706)
*Kaichen He,Zihao Wang,Muyao Li,Anji Liu,Yitao Liang*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为 CrossAgent 的统一智能体模型，它可以在不同的动作空间中进行操作，并自主选择最有效的接口来执行任务，在 Minecraft 环境中表现出最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体通常局限于静态的、预定义的动作空间，这限制了它们在动态环境中适应不同交互粒度的能力。

Method: CrossAgent 引入了一个全面的训练流程，将冷启动监督微调与多轮组相对策略优化（GRPO）算法相结合，使智能体能够学习自适应动作切换，平衡高级效率和低级精度，而无需人工指定规则。

Result: CrossAgent 在开放世界 Minecraft 环境中的 800 多个任务上进行了广泛的实验，与固定的动作基线相比，性能显著优越，在长程推理方面表现出卓越的泛化性和效率。

Conclusion: CrossAgent 通过动态利用不同动作空间的优势，实现了最先进的性能，解决了现有智能体在动态环境中适应性不足的问题，并提供了代码和模型供社区使用。

Abstract: The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching--balancing high-level efficiency with low-level precision--without human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at https://github.com/CraftJarvis/OpenHA

</details>


### [72] [Mixture of Lookup Key-Value Experts](https://arxiv.org/abs/2512.09723)
*Zongcheng Wang*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为MoLKV的新模型，它通过引入上下文感知机制和键值专家对MoLE模型进行了改进，在小规模评估中显著降低了验证损失。


<details>
  <summary>Details</summary>
Motivation: MoLE模型在资源受限设备上运行LLM推理时表现出色，但其上下文无关的专家选择机制限制了模型性能。

Method: MoLKV模型将每个专家构建为键值对。对于给定的输入，从当前序列中缓存的键值专家中选出与输入相关的查询，生成上下文感知的专家输出。

Result: MoLKV在小规模评估中显著降低了验证损失。

Conclusion: MoLKV通过引入上下文感知机制和键值专家，有效地解决了MoLE模型中专家选择机制的局限性，在性能上取得了显著提升。

Abstract: Recent research has developed several LLM architectures suitable for inference on end-user devices, such as the Mixture of Lookup Experts (MoLE)~\parencite{jie_mixture_2025}. A key feature of MoLE is that each token id is associated with a dedicated group of experts. For a given input, only the experts corresponding to the input token id will be activated. Since the communication overhead of loading this small number of activated experts into RAM during inference is negligible, expert parameters can be offloaded to storage, making MoLE suitable for resource-constrained devices. However, MoLE's context-independent expert selection mechanism, based solely on input ids, may limit model performance. To address this, we propose the \textbf{M}ixture \textbf{o}f \textbf{L}ookup \textbf{K}ey-\textbf{V}alue Experts (\textbf{MoLKV}) model. In MoLKV, each expert is structured as a key-value pair. For a given input, the input-derived query interacts with the cached key-value experts from the current sequence, generating a context-aware expert output. This context-aware mechanism alleviates the limitation of MoLE, and experimental results demonstrate that MoLKV achieves significantly lower validation loss in small-scale evaluations.

</details>


### [73] [STACHE: Local Black-Box Explanations for Reinforcement Learning Policies](https://arxiv.org/abs/2512.09909)
*Andrew Elashkin,Orna Grumberg*

Main category: cs.LG

TL;DR: STACHE是一个为强化学习智能体在离散马尔可夫博弈中生成局部、黑盒决策解释的综合框架。它通过鲁棒性区域和最小反事实来解释智能体的动作，并能捕获策略逻辑在训练过程中的演变。


<details>
  <summary>Details</summary>
Motivation: 强化学习智能体在稀疏奖励或安全关键环境中常表现出预期外行为，因此需要可靠的调试和验证工具。

Method: STACHE框架生成复合解释，包含两个互补部分：1. 鲁棒性区域：智能体动作保持不变的连通状态邻域。2. 最小反事实：改变决策所需的最小状态扰动。通过利用分解状态空间的结构，引入了一个精确的、基于搜索的算法，避免了替代模型的保真度 Mismatch。

Result: 在Gymnasium环境中的实证验证表明，STACHE不仅能解释策略动作，还能有效捕获训练过程中策略逻辑的演变——从不稳定行为到优化、鲁棒的策略。

Conclusion: STACHE框架为强化学习智能体的敏感性和决策边界提供了可操作的见解，能够解释和追踪策略在训练过程中的演变。

Abstract: Reinforcement learning agents often behave unexpectedly in sparse-reward or safety-critical environments, creating a strong need for reliable debugging and verification tools. In this paper, we propose STACHE, a comprehensive framework for generating local, black-box explanations for an agent's specific action within discrete Markov games. Our method produces a Composite Explanation consisting of two complementary components: (1) a Robustness Region, the connected neighborhood of states where the agent's action remains invariant, and (2) Minimal Counterfactuals, the smallest state perturbations required to alter that decision. By exploiting the structure of factored state spaces, we introduce an exact, search-based algorithm that circumvents the fidelity gaps of surrogate models. Empirical validation on Gymnasium environments demonstrates that our framework not only explains policy actions, but also effectively captures the evolution of policy logic during training - from erratic, unstable behavior to optimized, robust strategies - providing actionable insights into agent sensitivity and decision boundaries.

</details>


### [74] [FALCON: Few-step Accurate Likelihoods for Continuous Flows](https://arxiv.org/abs/2512.09914)
*Danyal Rehman,Tara Akhound-Sadegh,Artem Gazizov,Yoshua Bengio,Alexander Tong*

Main category: cs.LG

TL;DR: FALCON是一种用于分子玻尔兹曼采样的高效率新方法，它克服了现有连续归一化流模型在似然计算上的高成本问题，显著提高了采样速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 分子热力学平衡中的可伸缩采样是一个长期挑战，现有玻尔兹曼生成器（Boltzmann Generators）在利用连续归一化流（CNFs）进行似然计算时成本极高，限制了其广泛应用。

Method: 本文提出了FALCON方法，通过引入混合训练目标来鼓励可逆性，从而在少量步骤内实现准确的似然计算，适用于重要性采样。

Result: FALCON在分子玻尔兹曼采样方面超越了现有的最先进归一化流模型，并且比相同性能的CNF模型快了两个数量级。

Conclusion: FALCON通过其独特的方法有效解决了连续归一化流模型在似然计算效率上的瓶颈，为分子玻尔兹曼采样提供了一种更快、更准确的解决方案。

Abstract: Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous Flows (FALCON), a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We show FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the equivalently performing CNF model.

</details>


### [75] [Knowledge Diversion for Efficient Morphology Control and Policy Transfer](https://arxiv.org/abs/2512.09796)
*Fu Feng,Ruixiao Shi,Yucheng Xie,Jianlu Shen,Jing Wang,Xin Geng*

Main category: cs.LG

TL;DR: DivMorph是一种模块化训练范式，它利用知识转移来学习可分解控制器，能够有效地跨任务泛化，并显著降低模型大小和提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer-based控制器在处理通用形态控制时存在计算成本高、部署开销大以及跨任务泛化能力有限的问题，需要针对每个新任务从头开始训练。

Method: DivMorph通过在训练前通过SVD将随机初始化的Transformer权重分解为因子单元，并使用动态软门控根据任务和形态嵌入来调制这些单元。它将这些单元分为共享的“learngenes”和形态、任务特定的“tailors”，从而实现知识解耦。

Result: DivMorph在性能上达到了最先进水平，在跨任务迁移方面比直接微调的样本效率提高了3倍，在单智能体部署方面模型大小减少了17倍。

Conclusion: DivMorph通过其模块化训练范式和知识解耦机制，成功解决了现有通用形态控制方法的局限性，实现了高效、可扩展的策略部署和有效的策略迁移。

Abstract: Universal morphology control aims to learn a universal policy that generalizes across heterogeneous agent morphologies, with Transformer-based controllers emerging as a popular choice. However, such architectures incur substantial computational costs, resulting in high deployment overhead, and existing methods exhibit limited cross-task generalization, necessitating training from scratch for each new task. To this end, we propose \textbf{DivMorph}, a modular training paradigm that leverages knowledge diversion to learn decomposable controllers. DivMorph factorizes randomly initialized Transformer weights into factor units via SVD prior to training and employs dynamic soft gating to modulate these units based on task and morphology embeddings, separating them into shared \textit{learngenes} and morphology- and task-specific \textit{tailors}, thereby achieving knowledge disentanglement. By selectively activating relevant components, DivMorph enables scalable and efficient policy deployment while supporting effective policy transfer to novel tasks. Extensive experiments demonstrate that DivMorph achieves state-of-the-art performance, achieving a 3$\times$ improvement in sample efficiency over direct finetuning for cross-task transfer and a 17$\times$ reduction in model size for single-agent deployment.

</details>


### [76] [Ariel-ML: Computing Parallelization with Embedded Rust for Neural Networks on Heterogeneous Multi-core Microcontrollers](https://arxiv.org/abs/2512.09800)
*Zhaolan Huang,Kaspar Schleiser,Gyungmin Myung,Emmanuel Baccelli*

Main category: cs.LG

TL;DR: Ariel-ML是一个Rust嵌入式软件平台，它支持在多核MCU上并行执行TinyML模型，且性能优于现有技术并内存占用相当。


<details>
  <summary>Details</summary>
Motivation: 在低功耗多核微控制器上运行的TinyML模型越来越多，但目前还没有一个Rust嵌入式软件平台能够自动化并行化推理计算。

Method: 本文介绍了Ariel-ML工具包，它结合了一个通用的TinyML流水线和嵌入式Rust软件平台，可以充分利用各种32位微控制器家族的多核能力。

Result: Ariel-ML在推理延迟方面优于现有技术，并且内存占用与使用C/C++的现有工具包相当。

Conclusion: Ariel-ML为TinyML从业者和资源受限的嵌入式Rust开发人员提供了一个有用的基础。

Abstract: Low-power microcontroller (MCU) hardware is currently evolving from single-core architectures to predominantly multi-core architectures. In parallel, new embedded software building blocks are more and more written in Rust, while C/C++ dominance fades in this domain. On the other hand, small artificial neural networks (ANN) of various kinds are increasingly deployed in edge AI use cases, thus deployed and executed directly on low-power MCUs. In this context, both incremental improvements and novel innovative services will have to be continuously retrofitted using ANNs execution in software embedded on sensing/actuating systems already deployed in the field. However, there was so far no Rust embedded software platform automating parallelization for inference computation on multi-core MCUs executing arbitrary TinyML models. This paper thus fills this gap by introducing Ariel-ML, a novel toolkit we designed combining a generic TinyML pipeline and an embedded Rust software platform which can take full advantage of multi-core capabilities of various 32bit microcontroller families (Arm Cortex-M, RISC-V, ESP-32). We published the full open source code of its implementation, which we used to benchmark its capabilities using a zoo of various TinyML models. We show that Ariel-ML outperforms prior art in terms of inference latency as expected, and we show that, compared to pre-existing toolkits using embedded C/C++, Ariel-ML achieves comparable memory footprints. Ariel-ML thus provides a useful basis for TinyML practitioners and resource-constrained embedded Rust developers.

</details>


### [77] [Incorporating Fairness in Neighborhood Graphs for Fair Spectral Clustering](https://arxiv.org/abs/2512.09810)
*Adithya K Moorthy,V Vijaya Saradhi,Bhanu Prasad*

Main category: cs.LG

TL;DR: 该研究引入了新的方法来构建公平的k近邻（kNN）和公平的epsilon邻域图，这些方法在图形成阶段主动强制执行人口统计学均等。通过在邻域选择的最早阶段纳入公平性约束，我们的方法将敏感特征的比例表示纳入局部图结构，同时保持几何一致性。


<details>
  <summary>Details</summary>
Motivation: 传统的图聚类方法通常通过不公平的图构造延续偏见，这可能导致某些群体代表性不足。当前研究旨在通过在图构建的早期阶段主动强制执行人口统计学均等来解决这一问题，从而实现公平的图聚类。

Method: 该研究引入了两种新颖的方法：构建公平的kNN图和公平的epsilon邻域图。这些方法在邻域选择步骤中实施了公平性约束，以确保敏感特征的比例表示被纳入局部图结构。其核心思想是在图构建时保证每个敏感群体在每个节点的邻域中都有代表性。

Result: 通过在三个合成数据集、七个真实世界表格数据集和三个真实世界图像数据集上的实验证明，所提出的公平图构造方法在图聚类任务中超越了现有的基线，并且在不改变聚类算法本身的情况下，实现了更公平的谱聚类结果。

Conclusion: 该研究通过在图构建阶段（kNN和epsilon邻域图）引入拓扑公平性，有效地解决了图聚类中的偏见问题。实验结果表明，这种方法不仅保持了几何一致性，还显著提高了公平性，为公平无监督学习领域填补了一个重要空白。

Abstract: Graph clustering plays a pivotal role in unsupervised learning methods like spectral clustering, yet traditional methods for graph clustering often perpetuate bias through unfair graph constructions that may underrepresent some groups. The current research introduces novel approaches for constructing fair k-nearest neighbor (kNN) and fair epsilon-neighborhood graphs that proactively enforce demographic parity during graph formation. By incorporating fairness constraints at the earliest stage of neighborhood selection steps, our approaches incorporate proportional representation of sensitive features into the local graph structure while maintaining geometric consistency.Our work addresses a critical gap in pre-processing for fair spectral clustering, demonstrating that topological fairness in graph construction is essential for achieving equitable clustering outcomes. Widely used graph construction methods like kNN and epsilon-neighborhood graphs propagate edge based disparate impact on sensitive groups, leading to biased clustering results. Providing representation of each sensitive group in the neighborhood of every node leads to fairer spectral clustering results because the topological features of the graph naturally reflect equitable group ratios. This research fills an essential shortcoming in fair unsupervised learning, by illustrating how topological fairness in graph construction inherently facilitates fairer spectral clustering results without the need for changes to the clustering algorithm itself. Thorough experiments on three synthetic datasets, seven real-world tabular datasets, and three real-world image datasets prove that our fair graph construction methods surpass the current baselines in graph clustering tasks.

</details>


### [78] [Predicting the Containment Time of California Wildfires Using Machine Learning](https://arxiv.org/abs/2512.09835)
*Shashank Bhardwaj*

Main category: cs.LG

TL;DR: 该研究使用机器学习模型预测加州野火的 HFI 持续时间，旨在帮助管理者进行资源分配。


<details>
  <summary>Details</summary>
Motivation: 加州的野火情况日益严峻，现有的研究大多关注野火风险或蔓延，对持续时间的预测也大多是宽泛的类别预测，无法满足资源调度的需求。

Method: 该研究将野火持续时间预测视为回归任务，结合加州森林和防火部（FRAP）的三个公开数据集，比较了基线集成回归器、随机森林、XGBoost 和 LSTM 模型的性能。

Result: XGBoost 模型略优于随机森林模型（可能归因于其对数据集中静态特征的卓越处理能力），而 LSTM 模型表现不佳，因为它缺乏时间特征。

Conclusion: 根据特征可用性，野火管理者或消防管理部门可以选择最合适的模型来准确预测野火控制持续时间并有效分配资源。

Abstract: California's wildfire season keeps getting worse over the years, overwhelming the emergency response teams. These fires cause massive destruction to both property and human life. Because of these reasons, there's a growing need for accurate and practical predictions that can help assist with resources allocation for the Wildfire managers or the response teams. In this research, we built machine learning models to predict the number of days it will require to fully contain a wildfire in California. Here, we addressed an important gap in the current literature. Most prior research has concentrated on wildfire risk or how fires spread, and the few that examine the duration typically predict it in broader categories rather than a continuous measure. This research treats the wildfire duration prediction as a regression task, which allows for more detailed and precise forecasts rather than just the broader categorical predictions used in prior work. We built the models by combining three publicly available datasets from California Department of Forestry and Fire Protection's Fire and Resource Assessment Program (FRAP). This study compared the performance of baseline ensemble regressor, Random Forest and XGBoost, with a Long Short-Term Memory (LSTM) neural network. The results show that the XGBoost model slightly outperforms the Random Forest model, likely due to its superior handling of static features in the dataset. The LSTM model, on the other hand, performed worse than the ensemble models because the dataset lacked temporal features. Overall, this study shows that, depending on the feature availability, Wildfire managers or Fire management authorities can select the most appropriate model to accurately predict wildfire containment duration and allocate resources effectively.

</details>


### [79] [Conformal Bandits: Bringing statistical validity and reward efficiency to the small-gap regime](https://arxiv.org/abs/2512.09850)
*Simone Cuonzo,Nina Deliu*

Main category: cs.LG

TL;DR: Conformal Bandits是一个将Conformal Prediction (CP)整合到bandit问题中的新框架，它在保证统计预测覆盖率的同时，优化了决策策略的遗憾最小化潜力，尤其在小差异回报场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的bandit策略依赖于分布假设或渐近保证，且主要关注遗憾，忽略统计特性。本文旨在通过引入Conformal Prediction解决这一问题，在实现遗憾最小化的同时，提供有限时间预测覆盖的统计保证。

Method: 通过将Conformal Prediction整合到bandit问题中，并在模拟研究和投资组合分配应用中进行验证。此外，还在金融市场应用中整合隐马尔可夫模型，以捕捉市场机制转换行为。

Result: Conformal Bandits在小差异回报问题中表现出更好的遗憾性能，并能提供名义上的覆盖保证，而经典UCB策略则在此方面失败。整合隐马尔可夫模型可以增强探索-利用权衡，提高风险调整后的遗憾效率，并维持覆盖保证。

Conclusion: Conformal Bandits框架有效地结合了遗憾最小化的决策能力和统计保证，特别适用于回报差异较小的实际问题，并通过引入隐马尔可夫模型进一步提升了在复杂金融市场中的应用效果。

Abstract: We introduce Conformal Bandits, a novel framework integrating Conformal Prediction (CP) into bandit problems, a classic paradigm for sequential decision-making under uncertainty. Traditional regret-minimisation bandit strategies like Thompson Sampling and Upper Confidence Bound (UCB) typically rely on distributional assumptions or asymptotic guarantees; further, they remain largely focused on regret, neglecting their statistical properties. We address this gap. Through the adoption of CP, we bridge the regret-minimising potential of a decision-making bandit policy with statistical guarantees in the form of finite-time prediction coverage.
  We demonstrate the potential of it Conformal Bandits through simulation studies and an application to portfolio allocation, a typical small-gap regime, where differences in arm rewards are far too small for classical policies to achieve optimal regret bounds in finite sample. Motivated by this, we showcase our framework's practical advantage in terms of regret in small-gap settings, as well as its added value in achieving nominal coverage guarantees where classical UCB policies fail. Focusing on our application of interest, we further illustrate how integrating hidden Markov models to capture the regime-switching behaviour of financial markets, enhances the exploration-exploitation trade-off, and translates into higher risk-adjusted regret efficiency returns, while preserving coverage guarantees.

</details>


### [80] [HPM-KD: Hierarchical Progressive Multi-Teacher Framework for Knowledge Distillation and Efficient Model Compression](https://arxiv.org/abs/2512.09886)
*Gustavo Coelho Haase,Paulo Henrique Dourado da Silva*

Main category: cs.LG

TL;DR: HPM-KD是一个知识蒸馏框架，它通过元学习自适应配置、渐进式蒸馏链、注意力加权多教师集成、元学习温度调度器、并行处理管道和共享优化内存六个协同组件，解决了传统知识蒸馏中超参数敏感、容量差距、多教师协调不足和计算效率低下的问题，实现了10-15倍的模型压缩，同时保持85%的精度，并减少了30-40%的训练时间。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏（KD）在模型压缩方面表现出色，但存在一些关键限制：1. 对超参数敏感，需要大量手动调整；2. 从大型教师模型到小型学生模型蒸馏时存在容量差距；3. 多教师场景中协调不理想；4. 计算资源利用效率低下。

Method: HPM-KD框架集成了六个协同组件：1. 通过元学习实现自适应配置管理，无需手动调优超参数；2. 具有自动确定中间模型的渐进式蒸馏链；3. 学习动态每样本权重的注意力加权多教师集成；4. 在整个训练过程中自适应调整温度的元学习温度调度器；5. 具有智能负载平衡的并行处理管道；6. 用于跨实验重用的共享优化内存。

Result: 在CIFAR-10、CIFAR-100和表格数据集上的实验表明，HPM-KD实现了10-15倍的压缩率，同时保持了85%的精度，消除了手动调优的需要，并通过并行化将训练时间减少了30-40%。消融研究证实了每个组件的独立贡献（0.10-0.98 pp）。

Conclusion: HPM-KD通过其创新的六个协同组件，有效解决了知识蒸馏的现有挑战，显著提升了模型压缩的效率和性能，同时降低了人工干预。

Abstract: Knowledge Distillation (KD) has emerged as a promising technique for model compression but faces critical limitations: (1) sensitivity to hyperparameters requiring extensive manual tuning, (2) capacity gap when distilling from very large teachers to small students, (3) suboptimal coordination in multi-teacher scenarios, and (4) inefficient use of computational resources. We present \textbf{HPM-KD}, a framework that integrates six synergistic components: (i) Adaptive Configuration Manager via meta-learning that eliminates manual hyperparameter tuning, (ii) Progressive Distillation Chain with automatically determined intermediate models, (iii) Attention-Weighted Multi-Teacher Ensemble that learns dynamic per-sample weights, (iv) Meta-Learned Temperature Scheduler that adapts temperature throughout training, (v) Parallel Processing Pipeline with intelligent load balancing, and (vi) Shared Optimization Memory for cross-experiment reuse. Experiments on CIFAR-10, CIFAR-100, and tabular datasets demonstrate that HPM-KD: achieves 10x-15x compression while maintaining 85% accuracy retention, eliminates the need for manual tuning, and reduces training time by 30-40% via parallelization. Ablation studies confirm independent contribution of each component (0.10-0.98 pp). HPM-KD is available as part of the open-source DeepBridge library.

</details>


### [81] [Analysis of Dirichlet Energies as Over-smoothing Measures](https://arxiv.org/abs/2512.09890)
*Anna Bison,Alessandro Sperduti*

Main category: cs.LG

TL;DR: 本文分析了非标准化图拉普拉斯和标准化图拉普拉斯诱导的Dirichlet能量在过平滑度量方面的区别。


<details>
  <summary>Details</summary>
Motivation: 区分两种常用作过平滑度量的泛函（由非标准化图拉普拉斯和标准化图拉普拉斯诱导的Dirichlet能量），并指出后者不符合Rusch等人提出的节点相似性度量的公理定义。

Method: 通过形式化这两种定义的频谱基本特性来突出关键区别。

Result: 标准化图拉普拉斯诱导的Dirichlet能量不符合Rusch等人提出的节点相似性度量的公理定义。这些区别对于选择与GNN架构频谱兼容的度量至关重要，从而解决了在监控动态时的模糊性。

Conclusion: 选择与GNN架构频谱兼容的度量对于解决监控动态时的模糊性至关重要，而非标准化图拉普拉斯诱导的Dirichlet能量可能更适合作为节点相似性度量。

Abstract: We analyze the distinctions between two functionals often used as over-smoothing measures: the Dirichlet energies induced by the unnormalized graph Laplacian and the normalized graph Laplacian. We demonstrate that the latter fails to satisfy the axiomatic definition of a node-similarity measure proposed by Rusch \textit{et al.} By formalizing fundamental spectral properties of these two definitions, we highlight critical distinctions necessary to select the metric that is spectrally compatible with the GNN architecture, thereby resolving ambiguities in monitoring the dynamics.

</details>


### [82] [Closing the Train-Test Gap in World Models for Gradient-Based Planning](https://arxiv.org/abs/2512.09929)
*Arjun Parthasarathy,Nimit Kalra,Rohun Agrawal,Yann LeCun,Oumayma Bounou,Pavel Izmailov,Micah Goldblum*

Main category: cs.LG

TL;DR: 本文提出了一种改进世界模型训练方法，以实现高效的基于梯度的规划。通过弥补训练与测试之间的差距，该方法在测试时性能优于或媲美经典的无梯度交叉熵方法，且时间预算仅为后者的10%。


<details>
  <summary>Details</summary>
Motivation: 传统的MPC方法依赖于缓慢的搜索算法或迭代求解优化问题，而基于梯度的规划计算效率更高。然而，目前基于梯度的规划性能仍落后于其他方法。

Method: 本文提出了一种改进世界模型训练方法，以实现高效的基于梯度的规划。通过弥补训练与测试之间的差距，该方法在测试时性能优于或媲美经典的无梯度交叉熵方法，且时间预算仅为后者的10%。本文的核心思路在于，尽管世界模型是基于下一状态预测目标进行训练的，但在测试时却用于估计一系列动作。为了解决这种训练与测试之间的差异，我们提出了训练时数据合成技术，该技术能够显著改善现有世界模型的基于梯度的规划能力。

Result: 在测试时，本文提出的方法在各种物体操纵和导航任务中，性能优于或与经典的无梯度交叉熵方法（CEM）相媲美，且时间预算仅为后者的10%。

Conclusion: 通过弥补世界模型训练与测试之间的差距，本文提出的训练时数据合成技术能够显著提升基于梯度的规划性能，并在多种任务中展现出更高的效率和竞争力。

Abstract: World models paired with model predictive control (MPC) can be trained offline on large-scale datasets of expert trajectories and enable generalization to a wide range of planning tasks at inference time. Compared to traditional MPC procedures, which rely on slow search algorithms or on iteratively solving optimization problems exactly, gradient-based planning offers a computationally efficient alternative. However, the performance of gradient-based planning has thus far lagged behind that of other approaches. In this paper, we propose improved methods for training world models that enable efficient gradient-based planning. We begin with the observation that although a world model is trained on a next-state prediction objective, it is used at test-time to instead estimate a sequence of actions. The goal of our work is to close this train-test gap. To that end, we propose train-time data synthesis techniques that enable significantly improved gradient-based planning with existing world models. At test time, our approach outperforms or matches the classical gradient-free cross-entropy method (CEM) across a variety of object manipulation and navigation tasks in 10% of the time budget.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [83] [Calibrated Trust in Dealing with LLM Hallucinations: A Qualitative Study](https://arxiv.org/abs/2512.09088)
*Adrian Ryser,Florian Allwein,Tim Schlippe*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLM）的幻觉（即事实不正确但看似合理的回应）如何影响用户对LLM的信任和互动。


<details>
  <summary>Details</summary>
Motivation: 研究LLM幻觉对用户信任的影响，因为幻觉是LLM的一个显著问题，可能影响用户对其输出的接受度。

Method: 通过对192名参与者进行定性研究。

Result: 幻觉并未导致用户普遍不信任LLM，而是促成了情境敏感的信任校准。研究确认了期望、先前经验和用户专业知识与领域知识是用户相关的信任因素，并识别出直觉作为幻觉检测的额外相关因素。信任动态还受到语境因素的影响，特别是感知风险和决策风险。

Conclusion: 用户对LLM的信任是一个复杂的、情境敏感的过程，涉及多重用户和语境因素，特别是用户在检测幻觉时的直觉作用。基于研究结果，论文提出了负责任和反思性使用LLM的实践建议。

Abstract: Hallucinations are outputs by Large Language Models (LLMs) that are factually incorrect yet appear plausible [1]. This paper investigates how such hallucinations influence users' trust in LLMs and users' interaction with LLMs. To explore this in everyday use, we conducted a qualitative study with 192 participants. Our findings show that hallucinations do not result in blanket mistrust but instead lead to context-sensitive trust calibration. Building on the calibrated trust model by Lee & See [2] and Afroogh et al.'s trust-related factors [3], we confirm expectancy [3], [4], prior experience [3], [4], [5], and user expertise & domain knowledge [3], [4] as userrelated (human) trust factors, and identify intuition as an additional factor relevant for hallucination detection. Additionally, we found that trust dynamics are further influenced by contextual factors, particularly perceived risk [3] and decision stakes [6]. Consequently, we validate the recursive trust calibration process proposed by Blöbaum [7] and extend it by including intuition as a user-related trust factor. Based on these insights, we propose practical recommendations for responsible and reflective LLM use.

</details>


### [84] [AI TIPS 2.0: A Comprehensive Framework for Operationalizing AI Governance](https://arxiv.org/abs/2512.09114)
*Pamela Gupta*

Main category: cs.AI

TL;DR: 本文介绍了AI治理的三个挑战：用例层面风险评估不足、现有框架缺乏可操作的控制措施以及大规模操作治理机制的缺失。文章提出了AI TIPS框架来应对这些挑战。


<details>
  <summary>Details</summary>
Motivation: 目前AI系统的部署面临三个关键的治理挑战，现有框架未能充分解决这些挑战，包括用例层面风险评估不足、现有框架缺乏可操作的控制措施以及大规模操作治理机制的缺失。

Method: 文章提出了AI TIPS (Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0) 框架，该框架是2019年开发的综合操作框架的更新版，旨在直接解决上述挑战。

Result: 通过AI TIPS框架，可以解决AI治理中用例层面风险评估不足、现有框架缺乏可操作的控制措施以及大规模操作治理机制缺失的问题。

Conclusion: AI TIPS框架提供了一个全面的操作方法，以应对当前AI系统部署中的治理挑战，实现可信赖AI实践的规模化落地。

Abstract: The deployment of AI systems faces three critical governance challenges that current frameworks fail to adequately address. First, organizations struggle with inadequate risk assessment at the use case level, exemplified by the Humana class action lawsuit and other high impact cases where an AI system deployed to production exhibited both significant bias and high error rates, resulting in improper healthcare claim denials. Each AI use case presents unique risk profiles requiring tailored governance, yet most frameworks provide one size fits all guidance. Second, existing frameworks like ISO 42001 and NIST AI RMF remain at high conceptual levels, offering principles without actionable controls, leaving practitioners unable to translate governance requirements into specific technical implementations. Third, organizations lack mechanisms for operationalizing governance at scale, with no systematic approach to embed trustworthy AI practices throughout the development lifecycle, measure compliance quantitatively, or provide role-appropriate visibility from boards to data scientists. We present AI TIPS, Artificial Intelligence Trust-Integrated Pillars for Sustainability 2.0, update to the comprehensive operational framework developed in 2019,four years before NIST's AI Risk Management Framework, that directly addresses these challenges.

</details>


### [85] [A Categorical Analysis of Large Language Models and Why LLMs Circumvent the Symbol Grounding Problem](https://arxiv.org/abs/2512.09117)
*Luciano Floridi,Yiyang Jia,Fernando Tohmé*

Main category: cs.AI

TL;DR: 本文提出了一个形式化的范畴框架，用于分析人类和大型语言模型（LLMs）如何将内容转化为关于可能世界W的状态空间的真值评估命题，并认为LLMs并未解决而是规避了符号接地问题。


<details>
  <summary>Details</summary>
Motivation: 分析人类和大型语言模型（LLMs）将内容转化为关于可能世界W的状态空间的真值评估命题的方式。

Method: 提出了一个形式化的范畴框架。

Result: 表明大型语言模型（LLMs）未解决而是规避了符号接地问题。

Conclusion: LLMs在符号接地问题上采取了规避而非解决的策略。

Abstract: This paper presents a formal, categorical framework for analysing how humans and large language models (LLMs) transform content into truth-evaluated propositions about a state space of possible worlds W , in order to argue that LLMs do not solve but circumvent the symbol grounding problem.

</details>


### [86] [Toward Closed-loop Molecular Discovery via Language Model, Property Alignment and Strategic Search](https://arxiv.org/abs/2512.09566)
*Junkai Ji,Zhangfan Yang,Dong Xu,Ruibin Bai,Jianqiang Li,Tingjun Hou,Zexuan Zhu*

Main category: cs.AI

TL;DR: Trio是一种分子生成框架，它克服了现有生成模型在药物发现中的局限性，可以通过整合片段分子语言模型、强化学习和蒙特卡洛树搜索来生成具有改进结合亲和力、成药性和合成可及性的新配体。


<details>
  <summary>Details</summary>
Motivation: 以往的药物发现过程耗时且昂贵，传统的筛选方法成功率低，可扩展性有限。尽管生成模型有所进展，但它们在泛化性、可解释性上存在不足，并过度强调结合亲和力而忽视了药理学特性，这限制了其在实际应用中的价值。

Method: Trio框架整合了片段分子语言建模、强化学习和蒙特卡洛树搜索，实现有效的、可解释的闭环靶向分子设计。它通过三大关键组件实现了上下文感知的片段组装，保证了理化性质和合成可行性，并指导在探索新化学类型和利用蛋白质结合口袋中有前景中间体之间进行平衡搜索。

Result: Trio能够可靠地生成化学有效且药理学增强的配体，在结合亲和力（提高7.85%）、成药性（提高11.10%）和合成可及性（提高12.05%）方面优于现有最先进的方法，同时分子多样性扩展了四倍以上。

Conclusion: Trio框架通过其创新的整合方法，有效解决了现有药物发现生成模型面临的挑战，大幅提升了新药设计的效率和质量，为药物发现领域带来了显著的进步。

Abstract: Drug discovery is a time-consuming and expensive process, with traditional high-throughput and docking-based virtual screening hampered by low success rates and limited scalability. Recent advances in generative modelling, including autoregressive, diffusion, and flow-based approaches, have enabled de novo ligand design beyond the limits of enumerative screening. Yet these models often suffer from inadequate generalization, limited interpretability, and an overemphasis on binding affinity at the expense of key pharmacological properties, thereby restricting their translational utility. Here we present Trio, a molecular generation framework integrating fragment-based molecular language modeling, reinforcement learning, and Monte Carlo tree search, for effective and interpretable closed-loop targeted molecular design. Through the three key components, Trio enables context-aware fragment assembly, enforces physicochemical and synthetic feasibility, and guides a balanced search between the exploration of novel chemotypes and the exploitation of promising intermediates within protein binding pockets. Experimental results show that Trio reliably achieves chemically valid and pharmacologically enhanced ligands, outperforming state-of-the-art approaches with improved binding affinity (+7.85%), drug-likeness (+11.10%) and synthetic accessibility (+12.05%), while expanding molecular diversity more than fourfold.

</details>


### [87] [Gaussian Process Aggregation for Root-Parallel Monte Carlo Tree Search with Continuous Actions](https://arxiv.org/abs/2512.09727)
*Junlin Xiao,Victor-Alexandru Darvariu,Bruno Lacerda,Nick Hawes*

Main category: cs.AI

TL;DR: 本文提出了一种新的MCTS统计聚合方法，该方法在连续动作空间中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在连续动作空间环境中，MCTS的根并行变体如何最好地聚合来自不同线程的统计数据是一个重要的但尚未被充分探索的问题。

Method: 本文引入了一种使用高斯过程回归来获得未在环境中试验的有希望动作的值估计的方法。

Result: 在6个不同的领域进行了系统评估，结果表明该方法优于现有的聚合策略。

Conclusion: 本文提出的方法在连续动作空间中，用适度的推理时间增加，达到了更好的效果。

Abstract: Monte Carlo Tree Search is a cornerstone algorithm for online planning, and its root-parallel variant is widely used when wall clock time is limited but best performance is desired. In environments with continuous action spaces, how to best aggregate statistics from different threads is an important yet underexplored question. In this work, we introduce a method that uses Gaussian Process Regression to obtain value estimates for promising actions that were not trialed in the environment. We perform a systematic evaluation across 6 different domains, demonstrating that our approach outperforms existing aggregation strategies while requiring a modest increase in inference time.

</details>


### [88] [RIFT: A Scalable Methodology for LLM Accelerator Fault Assessment using Reinforcement Learning](https://arxiv.org/abs/2512.09829)
*Khurram Khalil,Muhammad Mahad Khaliq,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: RIFT是一个可扩展的框架，它利用强化学习和混合敏感度分析来自动发现最小、高影响的故障场景，从而实现高效的设计时故障评估。


<details>
  <summary>Details</summary>
Motivation: 传统的故障评估方法在现代AI加速器的大规模应用中面临计算成本过高和关键故障模式覆盖不足的挑战。

Method: RIFT将最坏情况故障的搜索转化为序列决策问题，结合混合敏感度分析进行搜索空间剪枝，并利用强化学习智能地生成最小、高影响的测试套件。

Result: 在NVIDIA A100 GPU上对十亿参数的大型语言模型（LLM）工作负载进行评估，RIFT实现了2.2倍于演化方法的故障评估加速，并将所需的测试向量数量减少了99%以上（相较于随机故障注入），同时实现了卓越的故障覆盖率。RIFT指导的选择性纠错码在成本效益方面比统一三模冗余保护提高了12.8倍。

Conclusion: RIFT为AI加速器提供了一种高效、可扩展的故障评估方法，显著提高了故障评估的速度和覆盖率，并能生成可操作的数据以实现智能硬件保护策略，最终能集成到商业RTL验证工作流程中。

Abstract: The massive scale of modern AI accelerators presents critical challenges to traditional fault assessment methodologies, which face prohibitive computational costs and provide poor coverage of critical failure modes. This paper introduces RIFT (Reinforcement Learning-guided Intelligent Fault Targeting), a scalable framework that automates the discovery of minimal, high-impact fault scenarios for efficient design-time fault assessment. RIFT transforms the complex search for worst-case faults into a sequential decision-making problem, combining hybrid sensitivity analysis for search space pruning with reinforcement learning to intelligently generate minimal, high-impact test suites. Evaluated on billion-parameter Large Language Model (LLM) workloads using NVIDIA A100 GPUs, RIFT achieves a \textbf{2.2$\times$} fault assessment speedup over evolutionary methods and reduces the required test vector volume by over \textbf{99\%} compared to random fault injection, all while achieving \textbf{superior fault coverage}. The proposed framework also provides actionable data to enable intelligent hardware protection strategies, demonstrating that RIFT-guided selective error correction code provides a \textbf{12.8$\times$} improvement in \textbf{cost-effectiveness} (coverage per unit area) compared to uniform triple modular redundancy protection. RIFT automatically generates UVM-compliant verification artifacts, ensuring its findings are directly actionable and integrable into commercial RTL verification workflows.

</details>


### [89] [Human-in-the-Loop and AI: Crowdsourcing Metadata Vocabulary for Materials Science](https://arxiv.org/abs/2512.09895)
*Jane Greenberg,Scott McClellan,Addy Ireland,Robert Sammarco,Colton Gerber,Christopher B. Rauch,Mat Kelly,John Kunze,Yuan An,Eric Toberer*

Main category: cs.AI

TL;DR: MatSci-YAMZ是一个结合了AI和人工参与（包括众包）的平台，旨在支持元数据词汇的开发，并在材料科学领域进行了概念验证。


<details>
  <summary>Details</summary>
Motivation: 元数据词汇对于推动FAIR和FARR数据原则至关重要，但其发展受到人力资源有限和标准化实践不一致的限制。

Method: 本文介绍了MatSci-YAMZ平台，该平台集成了人工智能（AI）和人机协作（HILT），包括众包，以支持元数据词汇的开发。研究人员在材料科学领域评估了AI-HILT模型，六名参与者通过平台贡献术语定义并提供示例以促进AI定义的完善。

Result: 成功创建了19个AI生成的定义，通过迭代反馈循环证明了AI-HILT修订的可行性。研究结果证实了AI-HILT模型的可行性，包括：1）成功的概念验证，2）与FAIR和开放科学原则的一致性，3）指导未来研究的研究协议，以及4）跨领域可扩展的潜力。

Conclusion: MatSci-YAMZ的底层模型能够提高语义透明度，并减少达成共识和元数据词汇开发所需的时间。

Abstract: Metadata vocabularies are essential for advancing FAIR and FARR data principles, but their development constrained by limited human resources and inconsistent standardization practices. This paper introduces MatSci-YAMZ, a platform that integrates artificial intelligence (AI) and human-in-the-loop (HILT), including crowdsourcing, to support metadata vocabulary development. The paper reports on a proof-of-concept use case evaluating the AI-HILT model in materials science, a highly interdisciplinary domain Six (6) participants affiliated with the NSF Institute for Data-Driven Dynamical Design (ID4) engaged with the MatSci-YAMZ plaform over several weeks, contributing term definitions and providing examples to prompt the AI-definitions refinement. Nineteen (19) AI-generated definitions were successfully created, with iterative feedback loops demonstrating the feasibility of AI-HILT refinement. Findings confirm the feasibility AI-HILT model highlighting 1) a successful proof of concept, 2) alignment with FAIR and open-science principles, 3) a research protocol to guide future studies, and 4) the potential for scalability across domains. Overall, MatSci-YAMZ's underlying model has the capacity to enhance semantic transparency and reduce time required for consensus building and metadata vocabulary development.

</details>


### [90] [SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments](https://arxiv.org/abs/2512.09897)
*Haoye Lu,Pavan Seshadri,Kaheer Suleman*

Main category: cs.AI

TL;DR: SCOPE 是一种单次分层规划器，它仅在初始化时利用 LLM 生成的子目标来预训练轻量级学生模型。


<details>
  <summary>Details</summary>
Motivation: 在复杂的、基于文本的环境中进行长期规划面临挑战，因为行动空间开放、观察模糊和反馈稀疏。

Method: SCOPE（Subgoal-COnditioned Pretraining for Efficient planning） 方法通过示例轨迹直接推断子目标，消除了重复的 LLM 查询需求。

Result: 在 TextCraft 环境中，SCOPE 的成功率为 0.56，推理时间从 164.4 秒减少到 3.0 秒。

Conclusion: LLM 生成的子目标可以作为基于文本规划任务中分层目标分解的强大起点。

Abstract: Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [91] [SURA: Secure Unsourced Random Access](https://arxiv.org/abs/2512.09104)
*Mohammad Javad Ahmadi,Rafael F. Schaefer,H. Vincent Poor*

Main category: cs.IT

TL;DR: 该工作通过利用窃听启发的物理层技术，为非溯源随机接入（URA）引入了安全性。


<details>
  <summary>Details</summary>
Motivation: 在不增加开销或改变URA原有结构和操作特性的前提下，利用反馈辅助URA的内在特性实现保密性，从而在提供安全通信的同时，保留URA的低成本优势。

Method: 每个用户从基站在前一传输轮次广播的反馈信号中生成一个密钥和人工噪声序列。通过三个动作执行安全传输：使用密钥加密数据，发送LDPC编码密钥的奇偶校验位给合法接收器以恢复密钥，并用人工噪声掩盖这些奇偶校验位。设计了一种针对合法用户的接收算法，并进行了泄漏分析以量化窃听者可获得的信息。

Result: 模拟结果表明，在不修改URA结构且对标准性能影响可忽略的情况下，实现了有意义的保密性。

Conclusion: 该研究成功地在非溯源随机接入（URA）中实现了安全通信，且并未牺牲其低成本、低延迟和最小信令开销的优势。

Abstract: This work introduces security for unsourced random access (URA) by employing wiretap-inspired physical layer techniques. To achieve confidentiality, the proposed system opportunistically exploits intrinsic features of feedback-aided URA without adding any overhead or altering its original structure or operational characteristics. As a result, the proposed system preserves the low-cost advantages of URA, including low delay and minimal signaling overhead, while providing secure communication. To secure transmission, each user generates a secret key and an artificial noise sequence from the feedback signal that the BS broadcasts in previous transmission rounds. This feedback depends on the BS-user channel, making it a private signal for each user. The secure transmission is performed by three actions: encrypting the data using the secret key, sending only the parity bits of the LDPC encoded secret key to allow the legitimate receiver to recover it, and masking these parity bits with the artificial noise. For reception, a receiver algorithm is designed for the legitimate user, and a leakage analysis is provided to quantify the information available to the eavesdropper. The simulation results show that meaningful secrecy is achieved in URA without modifying its structure and with negligible impact on standard performance.

</details>


### [92] [$t$-Fold $s$-Blocking Sets and $s$-Minimal Codes](https://arxiv.org/abs/2512.09457)
*Hao Chen,Xu Pan,Conghui Xie*

Main category: cs.IT

TL;DR: 本文中，我们提供了关于 $t$-重 $s$-阻塞集的新下界，并在没有 $t \leq q$ 条件的情况下，它比经典的 Beutelspacher 1983 年结果更强。我们还得到了射影 $s$-极小码的长度的一个下界。


<details>
  <summary>Details</summary>
Motivation: 在射影几何和编码理论中，阻塞集和极小码已经被研究多年。

Method: 我们提供了关于 $t$-重 $s$-阻塞集的新下界，并将其推广到 $s$-极小码上，给出了射影 $s$-极小码的长度的一个下界。我们还证明了 $(s+1)$-极小码是 $s$-极小码。我们把 Ashikhmin-Barg 条件推广到 $s$-极小码，并构造了许多满足和违反这个广义 Ashikhmin-Barg 条件的 $s$-极小码无限族。

Result: 得到了一个关于 $t$-重 $s$-阻塞集的新下界，它在没有 $t \leq q$ 条件的情况下比 Beutelspacher 在 1983 年的经典结果更强。得到了射影 $s$-极小码的长度的一个下界。证明了 $(s+1)$-极小码是 $s$-极小码。构造了许多满足和违反广义 Ashikhmin-Barg 条件的 $s$-极小码无限族。给出了几个是二元极小码但不是 $2$-极小码的例子。

Conclusion: 本文主要研究了阻塞集和极小码，得到了新的下界和推广，并给出了具体例子。

Abstract: Blocking sets and minimal codes have been studied for many years in projective geometry and coding theory. In this paper, we provide a new lower bound on the size of $t$-fold $s$-blocking sets without the condition $t \leq q$, which is stronger than the classical result of Beutelspacher in 1983. Then a lower bound on lengths of projective $s$-minimal codes is also obtained. It is proved that $(s+1)$-minimal codes are certainly $s$-minimal codes. We generalize the Ashikhmin-Barg condition for minimal codes to $s$-minimal codes. Many infinite families of $s$-minimal codes satisfying and violating this generalized Ashikhmin-Barg condition are constructed. We also give several examples which are binary minimal codes, but not $2$-minimal codes.

</details>


### [93] [Binary and Non-Binary Self-Dual Sequences and Maximum Period Single-Track Gray Codes](https://arxiv.org/abs/2512.09655)
*Tuvi Etzion*

Main category: cs.IT

TL;DR: 本文分析了二进制自对偶序列，并构建了最大周期非二进制单轨格雷码。


<details>
  <summary>Details</summary>
Motivation: 受单轨格雷码构造的启发，作者研究了二进制和非二进制自对偶序列的结构和递归构造。

Method: 文章讨论了生成这些序列的反馈移位寄存器，并探讨了这些序列与最长周期单轨码之间的联系。

Result: 本文构建了长度为 $p^t$、周期为 $p^{p^t}$ 的最长周期非二进制单轨格雷码。

Conclusion: 这些格雷码是文献中首次提出的最长周期码的无限族，具有重要的理论和应用价值。

Abstract: Binary self-dual sequences have been considered and analyzed throughout the years, and they were used for various applications. Motivated by a construction for single-track Gray codes, we examine the structure and recursive constructions for binary and non-binary self-dual sequences. The feedback shift registers that generate such sequences are discussed. The connections between these sequences and maximum period single-track codes are discussed. Maximum period non-binary single-track Gray codes of length $p^t$ and period $p^{p^t}$ are constructed. These are the first infinite families of maximum period codes presented in the literature.

</details>
