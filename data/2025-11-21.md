<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 20]
- [cs.GT](#cs.GT) [Total: 2]
- [stat.ML](#stat.ML) [Total: 4]
- [cs.LG](#cs.LG) [Total: 48]
- [cs.AI](#cs.AI) [Total: 43]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.IT](#cs.IT) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: LIARS' BENCH是一个包含72,863个谎言和诚实回复的测试平台，用于评估LLMs的谎言检测技术。该研究发现现有技术在识别某些类型的谎言方面存在系统性失败。


<details>
  <summary>Details</summary>
Motivation: 现有的谎言检测技术通常在狭窄的设置中进行验证，无法捕捉到LLMs可能生成的各种谎言。

Method: LIARS' BENCH，一个包含72,863个谎言和诚实回复的测试平台，由四种开源模型在七个数据集上生成，涵盖了不同类型的谎言，并从模型撒谎的原因和谎言的目标信念两个维度进行变化。研究人员评估了三种黑盒和白盒谎言检测技术。

Result: 现有的谎言检测技术在识别某些类型的谎言方面存在系统性失败，尤其是在仅凭文本记录无法判断模型是否撒谎的情况下。

Conclusion: LIARS' BENCH揭示了现有技术的局限性，并为谎言检测的进展提供了一个实用的测试平台。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [2] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种名为Learning to Look Ahead (LTLA)的混合方法，用于解决受控语言生成中序列级约束的难题。这种方法通过结合语言模型和固定的可处理替代模型，有效地处理了依赖未来令牌的约束，并在保证生成质量和效率的同时，提高了约束满足率。


<details>
  <summary>Details</summary>
Motivation: 受控语言生成中的序列级约束（如语法、风格或安全性）可能依赖于未来的令牌，这使得直接调节自回归语言模型变得难以处理。现有的方法通常使用隐马尔可夫模型（HMMs）等可处理的替代模型来近似分布并调整模型在解码时的下一个令牌logits。然而，这些替代模型通常上下文感知能力较弱，从而降低了查询质量。

Method: 本文提出了Learning to Look Ahead (LTLA)方法，该方法将基础语言模型用于丰富的前缀编码，并与一个固定的可处理替代模型结合，以计算精确的延续概率。为了解决引入神经上下文时出现的效率问题，LTLA采用了一种批处理HMM更新机制，一次性考虑所有候选的下一个令牌，并通过仅根据LM的隐藏表示来调整替代模型的潜在状态先验，同时保持替代解码器固定，从而实现跨前缀的计算重用。

Result: LTLA在条件似然性方面优于无条件HMM，能够近似视觉语言模型的延续分布（而独立的HMM无法编码视觉上下文），并在受控生成任务中以可比的流畅度提高了约束满足率，同时推理开销最小。

Conclusion: LTLA是一种有效且高效的受控语言生成方法，它通过结合语言模型和可处理的替代模型，解决了现有方法在处理序列级约束和上下文感知方面的不足。该方法不仅提高了生成质量和约束满足率，还保持了较低的推理开销，为受控语言生成提供了一个有前景的解决方案。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [3] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: 这篇论文介绍了GPT-5在科学研究中的应用案例，涵盖了数学、物理、天文学、计算机科学、生物学和材料科学等领域。


<details>
  <summary>Details</summary>
Motivation: 尽管前沿AI的能力日益增强，但许多科学家仍未充分认识到其潜力，因此本文旨在展示GPT-5如何加速科学研究，并在何处仍需人类专家参与。

Method: 通过一系列短小的案例研究，论文展示了GPT-5如何在正在进行的研究中产生了新的、具体的进展。

Result: GPT-5在研究中节省了专家的时间，并在数学领域取得了四个新的研究成果。

Conclusion: GPT-5可以帮助人类科学家解决以前未解决的问题，并促进人与AI之间富有成效的合作。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [4] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: ELPO框架通过引入投票机制和共享生成策略，结合不同搜索方法和更高效的算法，提升了自动提示优化的准确性和鲁棒性，并在多项任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs提示工程面临人工操作繁琐、效率低下的问题，而现有的自动提示优化（APO）方法在面对复杂任务时，因过于依赖单一模型或算法，其性能受到限制。

Method: 本研究提出了一个名为Ensemble Learning based Prompt Optimization (ELPO)的框架。该框架借鉴了集成学习的思想，引入了投票机制和共享生成策略，并结合不同的搜索方法来寻找更优的提示。此外，ELPO还创造性地提出了更高效的提示生成和搜索算法。

Result: 实验结果表明，ELPO在多种任务上均超越了目前最先进的提示优化方法，例如在ArSarcasm数据集上F1分数提升了7.6。

Conclusion: ELPO框架通过集成学习的思路，有效地解决了现有自动提示优化方法在处理复杂任务时的局限性，显著提升了提示优化的准确性和鲁棒性。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [5] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种名为Token-Selective PEFT（TS-PEFT）的新范式，它通过选择性地对部分位置索引应用PEFT修改来优化大型模型的微调过程。


<details>
  <summary>Details</summary>
Motivation: 传统的PEFT方法对所有位置索引应用修改，本文质疑了这种做法的必要性，并认为其可能效率低下甚至适得其反。

Method: 提出Token-Selective PEFT (TS-PEFT)，通过函数S选择性地对子集位置索引应用PEFT修改。

Result: 实验结果表明，不加区分地对所有索引应用PEFT不仅是多余的，甚至可能适得其反。TS-PEFT能够潜在地提高下游任务的性能。

Conclusion: 本文为PEFT提供了一个新颖的视角，提倡一种更有针对性的修改方法，并为未来优化大型模型微调过程的研究提供了框架。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [6] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: 该论文介绍了SemanticCite，一个由人工智能驱动的系统，旨在通过分析全文来源来验证引文的准确性。


<details>
  <summary>Details</summary>
Motivation: 目前学术文献面临引文不准确、人工智能生成的幻觉引用以及传统引文格式无法指示具体支持证据部分等挑战，因此需要一个系统来验证引文准确性并提供丰富的上下文信息。

Method: SemanticCite结合多种检索方法和四类分类系统（支持、部分支持、不支持、不确定），以捕捉细微的论点与来源关系。该方法使用经过微调的轻量级语言模型，其性能与大型商业系统相当，但计算要求显著降低。


Result: SemanticCite系统实现了与大型商业系统相当的性能，且计算资源需求大大降低，使得大规模引文验证成为可能。它提供了透明的、基于证据的解释。作者还贡献了一个包含1000多个引文的综合数据集，以及微调模型和完整的开源验证框架。

Conclusion: SemanticCite通过可扩展的引文验证、简化的同行评审以及对人工智能生成内容的质量控制，解决了研究诚信中的关键挑战，为大规模维护引文准确性奠定了开源基础。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [7] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了一种名为语义结构熵（SeSE）的方法，它从结构信息的角度量化大型语言模型固有的语义不确定性，用于幻觉检测。SeSE通过构建自适应稀疏有向语义图来捕捉语义依赖，并通过层次抽象利用潜在的语义结构信息，以量化长文本生成中单个声明的不确定性。该方法在多项实验中表现优于现有UQ基线。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中部署大型语言模型（LLMs）时，可靠的不确定性量化（UQ）至关重要。这使得LLMs能够在不确定时避免响应，从而防止产生幻觉和虚假信息。然而，现有最先进的UQ方法主要依赖于语义概率分布或成对距离，忽略了可能实现更精确不确定性估计的潜在语义结构信息。

Method: 本文提出了一种名为语义结构熵（SeSE）的UQ框架。它通过以下步骤量化LLMs的语义不确定性：首先，开发一种自适应稀疏有向语义图构建算法，该算法能够捕捉有向语义依赖关系，并自动修剪掉引入负面干扰的不必要连接。然后，通过层次抽象利用潜在的语义结构信息：SeSE被定义为最优语义编码树的结构熵，它在最优压缩后形式化了语义空间内的内在不确定性。此外，为了增强长文本生成中的细粒度UQ，SeSE被扩展用于量化单个声明的不确定性，通过模拟它们的随机语义交互作用，从而提供理论上可解释的幻觉检测。

Result: SeSE值越高，表示不确定性越大，表明LLMs极有可能产生幻觉。在长文本生成中，SeSE通过模拟随机语义交互来量化单个声明的不确定性，提供理论上可解释的幻觉检测。在29种模型-数据集组合上进行的广泛实验表明，SeSE显著优于先进的UQ基线，包括强大的监督方法和最近提出的KLE。

Conclusion: SeSE通过从结构信息角度量化LLMs的固有语义不确定性，为幻觉检测提供了一种原则性的UQ框架。该方法通过捕捉语义结构信息并进行层次抽象，有效地解决了现有UQ方法的局限性。实验结果验证了SeSE在提高LLMs不确定性量化和幻觉检测能力方面的有效性。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [8] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 为了解决大型语言模型（LLMs）在实际应用中与人类意图对齐的挑战，我们提出了SDA（Steering-Driven Distribution Alignment）框架。SDA无需训练、与模型无关，通过动态重新分配模型输出概率来增强模型行为与人类意图的一致性，且在Helpfulness、Harmlessness和Honesty三方面均取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在现实世界应用中日益普及，但如何确保LLMs的响应与人类意图对齐，尤其是在推理阶段实现高效对齐，仍然是一个核心挑战。在不进行昂贵的再训练或大量监督的情况下，有效且高效地调整模型行为至关重要。

Method: 我们提出了SDA（Steering-Driven Distribution Alignment）框架。SDA是一种无需训练且与模型无关的对齐框架，专门为开源LLMs设计。它通过基于用户定义的对齐指令，动态重新分配模型输出概率，从而在不进行微调的情况下增强模型行为与人类意图之间的一致性。SDA轻量、资源高效，可与各种开源LLMs兼容，既可独立进行推理，也可与基于训练的对齐策略集成。此外，SDA支持个性化偏好对齐，实现对模型响应行为的灵活控制。

Result: SDA框架在8个不同规模和来源的开源LLMs上持续提升了对齐性能，并在Helpfulness、Harmlessness和Honesty（3H）三个关键对齐维度上进行了评估。具体来说，SDA在测试模型中平均提高了64.4%的Helpfulness，30%的Honesty和11.5%的Harmlessness。

Conclusion: SDA框架通过无需训练和模型无关的方法，有效解决了LLMs与人类意图对齐的挑战。其在Helpfulness、Harmlessness和Honesty方面的显著提升，表明其在不同模型和应用场景下具有高效性和普适性。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [9] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种通过自我重写来提高大型推理模型内部推理质量的框架，与现有方法相比，该方法在保持更高准确性的同时显著缩短了推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法在大型推理模型中，奖励机制过于侧重最终结果的正确性，导致模型内部推理过程的质量不佳，存在过度思考、思考不足、冗余思考和无序思考等问题。

Method: 本文提出了一种自我重写框架，模型通过重写自己的推理文本，并从重写后的推理中学习，以此来提高内部思考过程的质量。算法设计上，采用了选择性重写方法，只对模型一致性正确的“简单”样本进行重写，从而保留了GRPO的原始奖励信号。在实际实现中，重写和原始生成被整合到同一个批次中，保证了RL算法的可扩展性，且只增加了约10%的开销。

Result: 在准确性-长度权衡方面，自我重写方法在没有明确指令减少推理长度的情况下，提高了准确性（+0.6），并显著缩短了推理长度（-46%），优于现有的强基线方法。在内部推理质量方面，自我重写方法在LLM-as-a-judge指标下取得了显著更高的分数（+7.2），成功缓解了内部推理缺陷。

Conclusion: 自我重写框架通过改进大型推理模型的内部推理质量，提高了模型的准确性并显著缩短了推理长度，有效解决了现有方法中推理过程质量不佳的问题。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [10] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 该研究旨在通过创建新的数据集来改进大型语言模型（LLM）对习语和比喻语言的理解。


<details>
  <summary>Details</summary>
Motivation: 习语和比喻性语言在口语和书面语中占很大比例，但大型语言模型（LLM）很难理解它们，尽管有大量的语料库。微调是有效的，但需要更好、更大的数据集来进一步缩小差距。

Method: 收集了最近的习语和比喻语言数据集，以创建一个组合习语列表。利用该列表从大型语料库中检索上下文序列。创建了一个大规模的潜在习语和比喻语言表达式数据集，以及两个额外的人工标注的习语和比喻语言表达式数据集。对这些数据集进行后处理，以实现模型无关的训练兼容性。

Result: 创建了三个数据集：一个大规模的语境习语和比喻表达例子，以及两个较小的、人工标注的习语和比喻表达例子。这些数据集被用于训练和评估预训练语言模型在习语识别任务中处理比喻意义的基线能力，特别是在槽位标注和序列标注方面。

Conclusion: 本研究通过引入新的、多样化的数据集，为提高大型语言模型理解习语和比喻语言的能力提供了一个解决方案，并促进了新模型和方法的开发。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [11] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 这篇论文探讨了人类解释（理由）在评估模型学习过程中的作用。特别是，它关注了充分性这个常用指标，并将其与两种建模范式联系起来：通过token分类识别哪些token是理由的一部分，以及通过注意力正则化将理由纳入输入，从而提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 评估模型是否基于正确的原因进行学习，而非依赖数据集中的特定捷径，而人类解释（理由）是实现这一目标的重要工具。通常，充分性被用作衡量理由信息量大小的指标，但其在揭示理由信息对模型性能影响方面的能力有限。

Method: 通过token分类评估模型识别理由中token的能力，以及通过注意力正则化将理由信息融入模型输入，以探究其对模型性能，特别是跨领域分类任务的提升作用。

Result: 高度信息量的理由不一定能帮助模型正确分类实例。充分性反而捕捉了非理由上下文对分类的影响，这会干扰输入中的理由信息。将理由信息整合到模型输入中可以提升跨领域分类性能，但结果因任务和模型类型而异。此外，充分性和token分类之间似乎没有关联。

Conclusion: 理由的复杂性意味着需要进一步研究能够系统地捕捉这类信息的指标，以更全面地理解理由在模型评估和性能提升中的作用。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [12] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 该研究探讨了监督机器学习和深度学习模型是否能有效区分感知到的低质量新闻文章和高质量新闻文章。


<details>
  <summary>Details</summary>
Motivation: 区分感知到的低质量新闻文章和高质量新闻文章。

Method: 使用包含1,412,272篇英文新闻文章的新数据集，评估了3种机器学习分类器和3种深度学习模型。数据集文章来源于2018-2024年的Common Crawl，通过专家对579个来源网站的共识评级将文章分为感知到的低质量和高质量两类，每类约706,000篇文章，每篇文章有194个语言特征。

Result: 传统机器学习分类器（如Random Forest）表现良好（0.7355准确度，0.8131 ROC AUC）。深度学习模型中，ModernBERT-large（256上下文长度）表现最佳（0.8744准确度；0.9593 ROC-AUC；0.8739 F1），其次是DistilBERT-base（512上下文长度），准确度为0.8685，ROC-AUC为0.9554。DistilBERT-base（256上下文长度）达到0.8478准确度和0.9407 ROC-AUC，而ModernBERT-base（256上下文长度）达到0.8569准确度和0.9470 ROC-AUC。

Conclusion: 全球新闻文章的感知质量可以通过传统的基于CPU的机器学习分类器和深度学习分类器有效地进行区分。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [13] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: ESGBench是一个用于评估可解释ESG问答系统的基准数据集和评估框架。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏用于评估ESG问答系统的基准，ESGBench旨在通过提供领域相关的ESG问题、人工标注的答案和支持证据来填补这一空白，以加速透明和负责任的ESG人工智能系统的研究。

Method: ESGBench包含跨多个ESG主题的领域相关问题，并配有人工整理的答案和支持证据，以实现对模型推理的细粒度评估。

Result: 通过对ESGBench上最先进的LLM进行性能分析，揭示了事实一致性、可追溯性和领域对齐方面的关键挑战。

Conclusion: ESGBench旨在促进可解释和负责任的ESG人工智能系统的研究和发展，解决现有模型在事实一致性、可追溯性和领域对齐方面的不足。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [14] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文分析了transformer模型对习语的理解和处理。


<details>
  <summary>Details</summary>
Motivation: 研究transformer模型处理习语时的计算模式。

Method: 通过修改后的路径修补算法发现电路，并识别出“习语头”和“增强接收”现象。

Result: 习语处理展现出独特的计算模式，发现了频繁激活的“习语头”以及早期处理导致的习语标记之间增强的注意力（“增强接收”）。

Conclusion: transformer模型通过这些机制平衡了计算效率和鲁棒性，为理解模型如何处理非组合语言和复杂语法结构提供了新视角。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [15] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一个用于从商业文档中提取结构化数据的先进模型，它具有最先进的性能，同时资源占用少，可在资源受限的硬件上部署，并支持处理长文档。


<details>
  <summary>Details</summary>
Motivation: 尽管Arctic-Extract模型具有最先进的文档理解能力，但它在资源受限的环境中部署的可行性以及其训练协议和评估结果是本文的重点。

Method: 文章介绍了Arctic-Extract模型的训练协议。

Result: Arctic-Extract模型在文档理解方面表现出强大的性能。

Conclusion: Arctic-Extract是一个高效且功能强大的模型，适用于资源受限环境下的商业文档结构化数据提取和长文档处理。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [16] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 这篇论文全面比较了土耳其语的密集编码器和Late-Interaction检索模型，并提出了TurkColBERT基准。研究发现，Late-Interaction模型在参数效率和性能上均优于密集编码器，并提出了一个两阶段的适应性流水线，用于在土耳其语数据集上微调和评估这些模型，这对于低资源形态丰富的语言的神经信息检索系统具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 探索神经信息检索系统在形态丰富、资源匮乏的土耳其语中的应用，系统评估Late-Interaction模型在土耳其语IR中的性能，并克服传统密集双编码器在这类语言中的局限性。

Method: 通过一个两阶段的适应性流水线：首先在土耳其语NLI/STS任务上微调英语和多语言编码器，然后使用在MS MARCO-TR上训练的PyLate，将它们转换为ColBERT风格的检索器。在五个土耳其BEIR数据集上评估了10个模型，涵盖了科学、金融和论证领域，并比较了索引算法（PLAID和MUVERA+Rerank）。

Result: 研究发现，colbert-hash-nano-tr（1.0M参数）比turkish-e5-large（600M参数）小600倍，但仍保留了超过71%的平均mAP。比密集编码器小3-5倍的Late-Interaction模型显著优于它们；ColmmBERT-base-TR在特定领域任务上mAP提升高达13.8%。MUVERA+Rerank比PLAID快3.33倍，并提供1.7%的相对mAP增益，使ColmmBERT-base-TR在MUVERA下的查询时间达到0.54毫秒。

Conclusion: Late-Interaction模型在土耳其语神经信息检索方面表现出卓越的参数效率和性能，显著优于传统的密集编码器。ColmmBERT-base-TR结合MUVERA索引算法，实现了低延迟和高性能的检索，为土耳其语及其他低资源形态丰富的语言的信息检索提供了有前景的解决方案。然而，研究仍受限于中等规模数据集和翻译基准测试，未来需要更大规模的真实世界评估。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [17] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 该论文探讨了使用LLM激活来预测文本流派的可行性，F1分数高达98%。


<details>
  <summary>Details</summary>
Motivation: LLM结构的可解释性很差，并且无法对所有输出进行人工评估。

Method: 本研究使用Mistral-7B和两个数据集。采用scikit-learn分类器，实现了高达98%和71%的F1分数。

Result: 文本体裁可以从LLM的激活中提取出来，预测准确率很高，证明了使用浅层学习模型推断LLM文本体裁的可行性。

Conclusion: 该论文提出了一个预测性框架，可以通过LLM的激活来预测文本的体裁，为理解和安全部署大型语言模型提供了新的途径。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [18] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 这篇论文挑战了在临床对话中衡量ASR性能的传统方法，通过引入LLM评估临床影响，旨在更安全地评估ASR。


<details>
  <summary>Details</summary>
Motivation: 传统的ASR评估指标（如WER）在临床对话中无法准确反映转录错误对临床结果的影响。

Method: 通过专家临床医生标注ASR转录错误的临床影响，建立了一个黄金标准基准。然后，引入了一个基于LLM（Gemini-2.5-Pro）的评估框架，并使用GEPA进行优化，以复制专家临床评估。

Result: 传统指标（如WER）与临床医生分配的风险标签（无、最小或显著影响）相关性差。经过优化的LLM评估器（Gemini-2.5-Pro）达到了与人类相当的性能，准确率为90%，Cohen’s κ系数为0.816。

Conclusion: 本研究提供了一个经过验证的自动化框架，用于在临床对话中评估ASR的安全性，超越了简单的文本准确性评估，实现了ASR评估的范式转变。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [19] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 该论文提出了一种无需人工标注训练数据，利用统计语言模型进行词义消歧的方法，并通过与人工标注金标准答案进行评估，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前词义消歧方法主要针对粗粒度表示，需要人工标注训练数据，难以自动消歧更丰富的表示，而高级推理需要这些丰富表示。

Method: 将符号NLU系统生成的多个候选含义转换为可区分的自然语言替代方案，然后使用这些方案查询LLM，以在给定语言上下文的情况下选择适当的解释，并将选定的含义传播回符号NLU系统。

Result: 所提出的方法能够有效地进行词义消歧。

Conclusion: 该方法为词义消歧提供了一种新的无监督解决方案，解决了传统方法对人工标注数据的依赖问题，并有望应用于需要更丰富语义表示的高级推理任务。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [20] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文分析了两种多模态RAG系统的检索方法，多模态嵌入检索的表现优于基于文本的块检索。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态RAG系统依赖于基于LLM的摘要来将图像转换为文本，从而导致上下文信息和视觉细节的丢失，这对于下游检索和问答至关重要。

Method: 本文在包含40个问答对的金融财报电话会议基准上，评估了两种检索方法（“text-based chunk retrieval”和“direct multimodal embedding retrieval”）在6种LLM模型和2种多模态嵌入模型上的表现。

Result: 直接多模态嵌入检索显著优于LLM摘要方法，在mAP@5方面绝对提高了13%，在nDCG@5方面绝对提高了11%。

Conclusion: LLM摘要在预处理过程中会引入信息丢失，而直接多模态嵌入保留了视觉上下文用于检索和推理。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [21] [Prior-free Collusion-proof Dynamic Mechanisms](https://arxiv.org/abs/2511.15727)
*Endre Csóka*

Main category: cs.GT

TL;DR: 本文介绍了TU-GUM和NTU-GUM两种机制的无先验版本，用于解决动态随机多参与者问题，并声称NTU-GUM可以在重复单一商品分配问题中实现近似帕累托效率。


<details>
  <summary>Details</summary>
Motivation: Csóka 等人（2024）提出了先验依赖机制 TU-GUM 和 NTU-GUM，本文旨在定义这两种机制的无先验版本。

Method: 本文定义了TU-GUM和NTU-GUM的无先验版本。

Result: 新的无先验 NTU-GUM 在 Fikioris、Banerjee 和 Tardos (2024) 的重复单一商品分配问题中实现了 1.283 近似帕累托效率。

Conclusion: 本文成功定义了TU-GUM和NTU-GUM的无先验版本，并且NTU-GUM在特定问题中表现出良好的近似效率。

Abstract: For a general class of dynamic stochastic multi-player problems, Csóka, Liu, Rodivilov, and Teytelboym (2024) proposed prior-dependent mechanisms. The Guaranteed Utility Mechanism with transfers (TU-GUM) implements efficiency in a Guaranteed Utility Equilibrium (GUE). Its transfer-free variant (NTU-GUM) implements approximate efficiency in ε-GUE. In this paper, we define prior-free versions of both TU-GUM and NTU-GUM. As a special case, we believe that the new prior-free NTU-GUM implements a 1.283-approximation to Pareto efficiency for the repeated single good allocation problem in Fikioris, Banerjee, and Tardos (2024).

</details>


### [22] [Polynomial-Time Algorithms for Computing the Nucleolus: An Assessment](https://arxiv.org/abs/2511.16517)
*Holger I. Meinhardt*

Main category: cs.GT

TL;DR: 本文分析了一篇声称开发了一种用于凸博弈中的核的强多项式时间组合算法的论文，但指出其方法存在根本性缺陷，并提出了替代的核仁计算方法。


<details>
  <summary>Details</summary>
Motivation: 作者的动机是指出Maggiorano等人（2025年）提出的计算凸博弈核仁的强多项式时间组合算法存在根本性缺陷，该算法基于还原博弈方法和子模函数最小化。

Method: 本研究通过重新审视Davis/Maschler还原博弈性质（RGP）的错误应用来论证缺陷。同时，为了评估这一发现，作者回顾了Faigle等人（2001年）的椭球法，以及Meinhardt（2013年）基于凸分析中Fenchel-Moreau共轭的方法来计算预核元素。

Result: 研究结果表明，Maggiorano等人的算法由于错误应用Davis/Maschler还原博弈性质而失效，导致无法计算凸博弈的核仁。相比之下，Meinhardt（2013年）的基于Fenchel-Moreau共轭的方法，在预核为单点时，可以以O(n^3)的运行时复杂度计算预核仁，这为一类博弈提供了多项式时间算法。

Conclusion: Maggiorano等人的算法在计算凸博弈核仁方面存在严重缺陷。虽然没有直接提供一种新的核仁计算方法，但本文强调了既有椭球法和Fenchel-Moreau共轭方法在特定条件下计算预核和预核仁的有效性，为凸博弈核仁的计算提供了替代思路和理论基础。

Abstract: Recently, Maggiorano et al. (2025) claimed that they have developed a strongly polynomial-time combinatorial algorithm for the nucleolus in convex games that is based on the reduced game approach and submodular function minimization method. Thereby, avoiding the ellipsoid method with its negative side effects in numerical computation completely. However, we shall argue that this is a fallacy based on an incorrect application of the Davis/Maschler reduced game property (RGP). Ignoring the fact that despite the pre-nucleolus, other solutions like the core, pre-kernel, and semi-reactive pre-bargaining set possess this property as well. This causes a severe selection issue, leading to the failure to compute the nucleolus of convex games using the reduced games approach. In order to assess this finding in its context, the ellipsoid method of Faigle et al. (2001) and the Fenchel-Moreau conjugation-based approach from convex analysis of Meinhardt (2013) to compute a pre-kernel element were resumed. In the latter case, it was exploited that for TU games with a single-valued pre-kernel, both solution concepts coincide. Implying that one has computed the pre-nucleolus if one has found the sole pre-kernel element of the game. Though it is a specialized and highly optimized algorithm for the pre-kernel, it assures runtime complexity of O(n^3) for computing the pre-nucleolus whenever the pre-kernel is a single point, which indicates a polynomial-time algorithm for this class of games.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [23] [Atlas Gaussian processes on restricted domains and point clouds](https://arxiv.org/abs/2511.15822)
*Mu Niu,Yue Zhang,Ke Ye,Pokman Cheung,Yizhu Wang,Xiaochen Yang*

Main category: stat.ML

TL;DR: 论文介绍了一种名为RC-AGPs的新方法，它结合了全局热核和局部RBF核构建了黎曼校正核从而解决了传统高斯过程在处理复杂几何结构数据时的不足。


<details>
  <summary>Details</summary>
Motivation: 传统高斯过程难以处理存在未知边界或高维流形上的受限数据。现有方法在处理稀疏或不规则采样点云时表现不佳。

Method: 1. 建立了Atlas布朗运动（BM）框架，用于估计具有未知几何和非平凡拓扑结构的点云上的热核。2. 通过结合全局热核与局部RBF核构建黎曼校正核，提出了黎曼校正Atlas高斯过程（RC-AGPs）框架。

Result: RC-AGPs在合成数据集和真实世界数据集上的回归任务中，性能优于现有方法，提升了热核估计和回归精度。

Conclusion: RC-AGPs有效连接了复杂、高维观测数据与基于流形的推断，改进了统计推断能力。

Abstract: In real-world applications, data often reside in restricted domains with unknown boundaries, or as high-dimensional point clouds lying on a lower-dimensional, nontrivial, unknown manifold. Traditional Gaussian Processes (GPs) struggle to capture the underlying geometry in such settings. Some existing methods assume a flat space embedded in a point cloud, which can be represented by a single latent chart (latent space), while others exhibit weak performance when the point cloud is sparse or irregularly sampled. The goal of this work is to address these challenges. The main contributions are twofold: (1) We establish the Atlas Brownian Motion (BM) framework for estimating the heat kernel on point clouds with unknown geometries and nontrivial topological structures; (2) Instead of directly using the heat kernel estimates, we construct a Riemannian corrected kernel by combining the global heat kernel with local RBF kernel and leading to the formulation of Riemannian-corrected Atlas Gaussian Processes (RC-AGPs). The resulting RC-AGPs are applied to regression tasks across synthetic and real-world datasets. These examples demonstrate that our method outperforms existing approaches in both heat kernel estimation and regression accuracy. It improves statistical inference by effectively bridging the gap between complex, high-dimensional observations and manifold-based inferences.

</details>


### [24] [Angular Graph Fractional Fourier Transform: Theory and Application](https://arxiv.org/abs/2511.16111)
*Feiyue Zhao,Yangfan He,Zhichao Zhang*

Main category: stat.ML

TL;DR: 本文提出了AGFRFT（angular GFRFT），一个统一的框架，它融合了分数阶和角度谱分析，解决了现有GFRFT和AGFT方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的图分数阶傅里叶变换（GFRFT）缺乏角度调节能力，而角度图傅里叶变换（AGFT）在零角度时无法退化为图傅里叶变换（GFT），这限制了它们在图信号处理中的应用和解释性。

Method: 本文提出了一种新的角度图分数阶傅里叶变换（AGFRFT），它通过引入一个退化友好的旋转矩阵家族，确保在零角度时精确退化为GFT。同时，本文还定义了两种AGFRFT变体（I-AGFRFT和II-AGFRFT），并验证了它们的酉性、可逆性和平滑参数依赖性。

Result: AGFRFT在频谱集中度、重建质量和可控频谱操作方面优于GFRFT和AGFT。它支持角度和分数阶的可学习联合参数化，从而实现对不同图信号的自适应频谱处理。

Conclusion: AGFRFT为图信号处理中的集成角度分数频谱分析提供了一个强大而灵活的工具，有效地解决了现有方法的局限性，并为图信号处理提供了新的可能性。

Abstract: Graph spectral representations are fundamental in graph signal processing, offering a rigorous framework for analyzing and processing graph-structured data. The graph fractional Fourier transform (GFRFT) extends the classical graph Fourier transform (GFT) with a fractional-order parameter, enabling flexible spectral analysis while preserving mathematical consistency. The angular graph Fourier transform (AGFT) introduces angular control via GFT eigenvector rotation; however, existing constructions fail to degenerate to the GFT at zero angle, which is a critical flaw that undermines theoretical consistency and interpretability. To resolve these complementary limitations - GFRFT's lack of angular regulation and AGFT's defective degeneracy - this study proposes an angular GFRFT (AGFRFT), a unified framework that integrates fractional-order and angular spectral analyses with theoretical rigor. A degeneracy-friendly rotation matrix family ensures exact GFT degeneration at zero angle, with two AGFRFT variants (I-AGFRFT and II-AGFRFT) defined accordingly. Rigorous theoretical analyses confirm their unitarity, invertibility, and smooth parameter dependence. Both support learnable joint parameterization of the angle and fractional order, enabling adaptive spectral processing for diverse graph signals. Extensive experiments on real-world data denoising, image denoising, and point cloud denoising demonstrate that AGFRFT outperforms GFRFT and AGFT in terms of spectral concentration, reconstruction quality, and controllable spectral manipulation, establishing a robust and flexible tool for integrated angular fractional spectral analysis in graph signal processing.

</details>


### [25] [Time dependent loss reweighting for flow matching and diffusion models is theoretically justified](https://arxiv.org/abs/2511.16599)
*Lukas Billera,Hedwig Nora Nordlinder,Ben Murrell*

Main category: stat.ML

TL;DR: 这篇论文是对生成器匹配（Generator Matching）理论的澄清和扩展，它提出在该框架下，Bregman散度损失和生成器的线性参数化可以依赖于当前状态和时间，并且损失中的时间期望可以取自广泛的时间分布。论文还扩展了这一发现到编辑流（Edit Flows），并阐明了时间依赖的损失权重方案在理论上是合理的。


<details>
  <summary>Details</summary>
Motivation: 澄清并扩展生成器匹配（Generator Matching）的理论框架，使其能够支持更广泛的损失函数和模型参数化形式，并为实践中常用的时间依赖损失权重方案提供理论依据。

Method: 通过理论分析，证明了在生成器匹配框架下，Bregman散度损失和生成器的线性参数化可以依赖于当前状态 $X_t$ 和时间 $t$。同时，证明了损失中的时间期望可以取自广泛的时间分布。此外，还将这些发现扩展到了编辑流（Edit Flows）。

Result: 理论上证明了在生成器匹配和编辑流中，损失函数和生成器都可以是时间 $t$ 和状态 $X_t$ 的函数，并且时间期望可以取自广义的时间分布。这为时间依赖损失权重方案提供了理论支持，并简化了 $X_1$-预测器方案的构建。

Conclusion: 生成器匹配理论得到了扩展，允许Bregman散度损失和生成器的线性参数化依赖于当前状态和时间，并支持更广泛的时间分布。这为实践中的模型训练提供了更强的理论依据，特别是对于时间依赖的损失权重和 $X_1$-预测器方案。

Abstract: This brief note clarifies that, in Generator Matching (which subsumes a large family of flow matching and diffusion models over continuous, manifold, and discrete spaces), both the Bregman divergence loss and the linear parameterization of the generator can depend on both the current state $X_t$ and the time $t$, and we show that the expectation over time in the loss can be taken with respect to a broad class of time distributions. We also show this for Edit Flows, which falls outside of Generator Matching. That the loss can depend on $t$ clarifies that time-dependent loss weighting schemes, often used in practice to stabilize training, are theoretically justified when the specific flow or diffusion scheme is a special case of Generator Matching (or Edit Flows). It also often simplifies the construction of $X_1$-predictor schemes, which are sometimes preferred for model-related reasons. We show examples that rely upon the dependence of linear parameterizations, and of the Bregman divergence loss, on $t$ and $X_t$.

</details>


### [26] [Rate-optimal community detection near the KS threshold via node-robust algorithms](https://arxiv.org/abs/2511.16613)
*Jingqiu Ding,Yiding Hua,Kasper Lindberg,David Steurer,Aleksandr Storozhenko*

Main category: stat.ML

TL;DR: 本文提出了一种多项式时间算法，用于对称 k 随机块模型中的社区检测，在存在节点损坏的情况下，该算法达到了最小最大误分类率，优于现有方法，并通过结合平方和框架和鲁棒多数投票来改进图二分算法。


<details>
  <summary>Details</summary>
Motivation: 以往的社区检测算法在实现最小最大误分类率方面存在计算效率低下或需要更强假设的问题，尤其是在节点鲁棒设置下。本文旨在弥补这一空白，提供一种在对称 k 随机块模型中，即使在存在节点损坏的情况下，也能在接近 Kesten-Stigum (KS) 阈值时实现最小最大误分类率的多项式时间算法。

Method: 本文提出了一种多项式时间算法，主要通过两个技术贡献实现： 1. 通过平方和框架（Sum-of-Squares framework）鲁棒化多数投票（majority voting），提高了算法的鲁棒性。 2. 开发了一种新的图二分算法（graph bisection algorithm），该算法通过鲁棒多数投票实现，显著改善了在接近 KS 阈值时初始估计的误分类率，使其达到 1/poly(k)。

Result: 本文提出的算法实现了最小最大误分类率 \(\exp \bigl(-\left(1 \pm o(1)\right) \tfrac{C}{k}\bigr)\)，其中 \(C = (\sqrt{pn} - \sqrt{qn})^2\)，且当 \(C \ge K\,k^2\,\log k\) 时，该结果与 Kesten-Stigum (KS) 阈值在 \(\log k\) 因子上匹配。即使对抗者破坏了 \(\eta\le \exp\bigl(- (1 \pm o(1)) \tfrac{C}{k}\bigr)\) 部分的节点，该比率也保持不变。该算法首次在两种设置（有无节点损坏）下提供了在接近 KS 阈值时达到最小最大比率的多项式时间算法。

Conclusion: 本文成功地提出了一种多项式时间算法，解决了对称 k 随机块模型中社区检测的难题，尤其是在存在节点损坏的情况下。该算法在最小最大误分类率方面取得了显著的改进，并使在接近 Kesten-Stigum 阈值时的性能达到了现有方法的上限。 این工作通过结合创新的技术贡献，为社区检测领域的发展做出了重要贡献。

Abstract: We study community detection in the \emph{symmetric $k$-stochastic block model}, where $n$ nodes are evenly partitioned into $k$ clusters with intra- and inter-cluster connection probabilities $p$ and $q$, respectively.
  Our main result is a polynomial-time algorithm that achieves the minimax-optimal misclassification rate
  \begin{equation*}
  \exp \Bigl(-\bigl(1 \pm o(1)\bigr) \tfrac{C}{k}\Bigr),
  \quad \text{where } C = (\sqrt{pn} - \sqrt{qn})^2,
  \end{equation*}
  whenever $C \ge K\,k^2\,\log k$ for some universal constant $K$, matching the Kesten--Stigum (KS) threshold up to a $\log k$ factor.
  Notably, this rate holds even when an adversary corrupts an $η\le \exp\bigl(- (1 \pm o(1)) \tfrac{C}{k}\bigr)$ fraction of the nodes.
  To the best of our knowledge, the minimax rate was previously only attainable either via computationally inefficient procedures [ZZ15] or via polynomial-time algorithms that require strictly stronger assumptions such as $C \ge K k^3$ [GMZZ17].
  In the node-robust setting, the best known algorithm requires the substantially stronger condition $C \ge K k^{102}$ [LM22].
  Our results close this gap by providing the first polynomial-time algorithm that achieves the minimax rate near the KS threshold in both settings.
  Our work has two key technical contributions:
  (1) we robustify majority voting via the Sum-of-Squares framework,
  (2) we develop a novel graph bisection algorithm via robust majority voting, which allows us to significantly improve the misclassification rate to $1/\mathrm{poly}(k)$ for the initial estimation near the KS threshold.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [27] [A Mathematical Framework for Custom Reward Functions in Job Application Evaluation using Reinforcement Learning](https://arxiv.org/abs/2511.16073)
*Shreyansh Jain,Madhav Singhvi,Shreya Rahul Jain,Pranav S,Dishaa Lokesh,Naren Chittibabu,Akash Anandhan*

Main category: cs.LG

TL;DR: 本文提出了一种基于小型语言模型的两步微调方法，用于改进简历评估模型，解决了传统ATS的局限性并克服了强化学习中的奖励作弊问题，最终实现了91%的准确率和出色的召回率与精确度。


<details>
  <summary>Details</summary>
Motivation: 传统的ATS系统过于僵化，只进行关键词匹配，导致许多有才华的候选人因语义不匹配而被拒绝。因此，需要设计一个更精细的简历评估模型，能够超越简单的关键词匹配，对候选人进行全面评估。

Method: 本文提出了一种两步微调过程来设计一个更精细的简历评估模型。首先，使用监督微调（SFT）建立一个坚实的基础模型。其次，通过GRPO结合定制的多组件奖励函数，对SFT模型进行强化学习（RL）优化。文章还解决了RL应用中奖励作弊的关键问题，通过反复优化奖励函数和训练超参数，实现了稳定的“温和打磨过程”。

Result: 经过GRPO打磨的模型在未见过测试数据上达到了91%的最终准确率。该模型在正确识别合格候选人方面表现出强大的能力（“SELECTED”类别的召回率为0.85），同时表现出卓越的精确度（1.0），证实了其可靠性。

Conclusion: 正确执行的两步微调过程可以有效地改进小型语言模型，使其能够进行精细化和类似人类的候选人评分，克服了传统ATS和朴素RL使用的缺点。

Abstract: Conventional Applicant Tracking Systems (ATS) tend to be inflexible keyword-matchers, and deny gifted candidates a role due to a few minor semantic mismatches. This article describes a new two-step process to design a more refined resume evaluation model based on a small language model (<600M parameters) that is finetuned using GRPO on a custom reward function. To begin with, Supervised Fine-Tuning (SFT) was used to build a solid baseline model. Second, this SFT model was also optimized with the help of Reinforcement Learning (RL) through GRPO under the guidance of a new, multi-component reward function that can holistically assess candidates beyond simple keyword matching. We indicate that the RL application presents a critical problem of reward hacking due to the initial experiments of aggressive penalties, which produces faulty, excessively negative model behaviors. We have overcome this challenge by refining the reward function repeatedly and training hyperparameters into a stable "gentle polishing process" of the reward function. Our resulting GRPO-polished model demonstrates significant real-world efficacy, achieving a final accuracy of 91% on unseen test data. The model shows a strong ability to correctly identify qualified candidates (recall of 0.85 for the 'SELECTED' class) while also showing exceptional precision (1.0), confirming its reliability. These results indicate that a properly executed, two-step fine-tuning procedure can indeed effectively refine a small language model to be able to conduct fine-tuned and human-like candidate scoring, overcoming the drawbacks of both traditional ATS and naive RL usage.

</details>


### [28] [Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and Turn](https://arxiv.org/abs/2511.15738)
*Chao Yu,Qixin Tan,Jiaxuan Gao,Shi Yu,Hong Lu,Xinting Yang,Zelai Xu,Yu Wang,Yi Wu,Eugene Vinitsky*

Main category: cs.LG

TL;DR: 本文提出了一种多维度测试时扩展框架，结合了上下文、批量和轮次扩展，显著提高了推理任务的性能，并可应用于具身学习。


<details>
  <summary>Details</summary>
Motivation: 目前的推理强化学习在测试时扩展方面受限于基础模型的上下文长度。本文旨在通过引入多维度测试时扩展框架来突破这一限制，以扩展测试时推理的能力。

Method: 本文提出了一个统一的多维度测试时扩展框架，包括上下文扩展、批量扩展和轮次扩展。在此基础上，提出并验证了3D测试时扩展，它整合了这三个维度。

Result: 1. 每个维度都表现出测试时扩展效应，但容量有限。 2. 结合所有三个维度显著提高了IOI、IMO和CPHO等挑战性测试任务的推理性能，并能从人类偏好反馈中进一步受益。 3. 人在回路框架可以自然地扩展到更开放的领域，如具身学习，从而能够设计出类人机器人的控制行为。

Conclusion: 本文提出的多维度测试时扩展框架，特别是3D测试时扩展，通过整合上下文、批量和轮次扩展，有效提升了推理强化学习在测试时的表现，并为具身学习等领域提供了新的应用途径。

Abstract: Reasoning reinforcement learning (RL) has recently revealed a new scaling effect: test-time scaling. Thinking models such as R1 and o1 improve their reasoning accuracy at test time as the length of the reasoning context increases. However, compared with training-time scaling, test-time scaling is fundamentally limited by the limited context length of base models, which remains orders of magnitude smaller than the amount of tokens consumed during training. We revisit test-time enhancement techniques through the lens of scaling effect and introduce a unified framework of multi-dimensional test-time scaling to extend the capacity of test-time reasoning. Beyond conventional context-length scaling, we consider two additional dimensions: batch scaling, where accuracy improves with parallel sampling, and turn scaling, where iterative self-refinement enhances reasoning quality. Building on this perspective, we propose 3D test-time scaling, which integrates context, batch, and turn scaling. We show that: (1) each dimension demonstrates a test-time scaling effect, but with a bounded capacity; (2) combining all three dimensions substantially improves the reasoning performance of challenging testbeds, including IOI, IMO, and CPHO, and further benefits from human preference feedback; and (3) the human-in-the-loop framework naturally extends to a more open-ended domain, i.e., embodied learning, which enables the design of humanoid control behaviors.

</details>


### [29] [TB or Not TB: Coverage-Driven Direct Preference Optimization for Verilog Stimulus Generation](https://arxiv.org/abs/2511.15767)
*Bardia Nadimi,Khashayar Filom,Deming Chen,Hao Zheng*

Main category: cs.LG

TL;DR: 该论文介绍了一个名为"TB or not TB"的框架，它利用大型语言模型（LLMs）和覆盖率驱动的直接偏好优化（CD-DPO）来自动生成硬件设计验证的激励。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（LLMs）快速发展的背景下，硬件设计验证阶段仍然是耗时且资源密集的，其中生成有效的测试激励对设计验证至关重要且劳动密集。因此，本论文旨在通过使用LLMs自动生成激励来解决这一挑战。

Method: 本论文提出了一个名为"TB or not TB"的框架，该框架通过覆盖率驱动的直接偏好优化（CD-DPO）对LLMs进行微调，以实现自动激励生成。为了支持基于偏好的训练，作者引入了PairaNet数据集，该数据集基于PyraNet并结合了使用仿真覆盖率指标标记的高质量和低质量测试平台对。CD-DPO方法将量化覆盖率反馈直接整合到优化目标中，从而引导模型生成能够最大化验证覆盖率的激励。

Result: 在CVDP CID12基准测试上的实验结果表明，"TB or not TB"框架优于开源和商业基线，代码覆盖率的提升高达77.27%。

Conclusion: CD-DPO在LLM辅助的硬件验证中显示出显著效果，能够有效地提高激励生成的质量和验证覆盖率。

Abstract: With the rapid advancement of Large Language Models (LLMs), there is growing interest in applying them to hardware design and verification. Among these stages, design verification remains the most time-consuming and resource-intensive phase, where generating effective stimuli for the design under test (DUT) is both critical and labor-intensive. We present {\it TB or not TB}, a framework for automated stimulus generation using LLMs fine-tuned through Coverage-Driven Direct Preference Optimization (CD-DPO). To enable preference-based training, we introduce PairaNet, a dataset derived from PyraNet that pairs high- and low-quality testbenches labeled using simulation-derived coverage metrics. The proposed CD-DPO method integrates quantitative coverage feedback directly into the optimization objective, guiding the model toward generating stimuli that maximize verification coverage. Experiments on the CVDP CID12 benchmark show that {\it TB or not TB} outperforms both open-source and commercial baselines, achieving up to 77.27\% improvement in code coverage, demonstrating the effectiveness of Coverage-driven preference optimization for LLM-based hardware verification.

</details>


### [30] [Beyond Tsybakov: Model Margin Noise and $\mathcal{H}$-Consistency Bounds](https://arxiv.org/abs/2511.15816)
*Mehryar Mohri,Yutao Zhong*

Main category: cs.LG

TL;DR: 本文介绍了一种新的分类低噪声条件“模型边际噪声（MM噪声）”，并在该条件下推导出增强的H-一致性界限。MM噪声条件比Tsybakov噪声条件弱，因为它依赖于给定假设与贝叶斯分类器之间的差异，而不是固有的分布最小边际。


<details>
  <summary>Details</summary>
Motivation: 为了在比Tsybakov噪声条件更弱的条件下，获得增强的H-一致性界限。

Method: 引入了新的MM噪声条件，并基于此条件，推导了二分类和多分类任务中增强的H-一致性界限。

Result: 在MM噪声条件下获得了增强的H-一致性界限，其指数与Mao, Mohri和Zhong (2025a)的成果相同，但假设条件更弱。这些界限在中间噪声水平下能在线性与平方根机制之间平滑插值。

Conclusion: MM噪声条件为分类任务提供了一种更宽松但同样有效的低噪声条件，并在此条件下推广了H-一致性理论。

Abstract: We introduce a new low-noise condition for classification, the Model Margin Noise (MM noise) assumption, and derive enhanced $\mathcal{H}$-consistency bounds under this condition. MM noise is weaker than Tsybakov noise condition: it is implied by Tsybakov noise condition but can hold even when Tsybakov fails, because it depends on the discrepancy between a given hypothesis and the Bayes-classifier rather than on the intrinsic distributional minimal margin (see Figure 1 for an illustration of an explicit example). This hypothesis-dependent assumption yields enhanced $\mathcal{H}$-consistency bounds for both binary and multi-class classification. Our results extend the enhanced $\mathcal{H}$-consistency bounds of Mao, Mohri, and Zhong (2025a) with the same favorable exponents but under a weaker assumption than the Tsybakov noise condition; they interpolate smoothly between linear and square-root regimes for intermediate noise levels. We also instantiate these bounds for common surrogate loss families and provide illustrative tables.

</details>


### [31] [Transparent Early ICU Mortality Prediction with Clinical Transformer and Per-Case Modality Attribution](https://arxiv.org/abs/2511.15847)
*Alexander Bakumenko,Janine Hoelscher,Hudson Smith*

Main category: cs.LG

TL;DR: 该研究提出了一个轻量级、透明的多模态集成模型，用于早期识别有院内死亡风险的ICU患者，该模型结合了生理时间序列测量和非结构化临床笔记，并在MIMIC-III基准测试中表现出竞争性性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有的机器学习方法在预测重症监护患者的院内死亡风险方面具有较高的预测性能，但它们缺乏透明性和鲁棒性，从而限制了临床应用。

Method: 该模型是一个多模态集成模型，它融合了ICU住院前48小时内的生理时间序列测量数据和非结构化临床笔记。一个逻辑回归模型结合了来自两个特定模态模型的预测：一个用于生命体征的双向LSTM和一个用于笔记的微调ClinicalModernBERT Transformer。该架构支持多级可解释性，包括每种模态内的特征归因以及量化生命体征和笔记如何影响每个决策的直接逐病例模态归因。

Result: 在MIMIC-III基准测试中，该晚期融合集成模型在区分度方面优于最佳单一模型（AUPRC 0.565 vs. 0.526; AUROC 0.891 vs. 0.876），同时保持了良好的校准预测。当缺少某种模态时，该系统通过校准的备用方案保持鲁棒性。

Conclusion: 该研究提出的模型在性能上具有竞争力，并提供了可靠、可审计的风险评估以及透明、可预测的操作，这些对于临床应用至关重要。

Abstract: Early identification of intensive care patients at risk of in-hospital mortality enables timely intervention and efficient resource allocation. Despite high predictive performance, existing machine learning approaches lack transparency and robustness, limiting clinical adoption. We present a lightweight, transparent multimodal ensemble that fuses physiological time-series measurements with unstructured clinical notes from the first 48 hours of an ICU stay. A logistic regression model combines predictions from two modality-specific models: a bidirectional LSTM for vitals and a finetuned ClinicalModernBERT transformer for notes. This traceable architecture allows for multilevel interpretability: feature attributions within each modality and direct per-case modality attributions quantifying how vitals and notes influence each decision. On the MIMIC-III benchmark, our late-fusion ensemble improves discrimination over the best single model (AUPRC 0.565 vs. 0.526; AUROC 0.891 vs. 0.876) while maintaining well-calibrated predictions. The system remains robust through a calibrated fallback when a modality is missing. These results demonstrate competitive performance with reliable, auditable risk estimates and transparent, predictable operation, which together are crucial for clinical use.

</details>


### [32] [Improving Iterative Gaussian Processes via Warm Starting Sequential Posteriors](https://arxiv.org/abs/2511.16340)
*Alan Yufei Dong,Jihao Andreas Lin,José Miguel Hernández-Lobato*

Main category: cs.LG

TL;DR: 本文提出了一种新的迭代高斯过程（GP）推理方法，通过利用一个已知的小型线性系统解来提高大型线性系统的求解器收敛速度。


<details>
  <summary>Details</summary>
Motivation: 在大规模高斯过程（GP）推理中，提高GP的可扩展性是一个具有挑战性的问题，尤其是在顺序决策任务中。现有的迭代GP方法在求解大型线性系统时面临收敛速度的挑战，而本文旨在通过改进求解器收敛性来解决这一问题。

Method: 本文提出了一种新的迭代GP方法，其核心思想是利用一个已知的小型线性系统解来加速大型线性系统的求解器收敛。这种方法特别适用于增量数据添加的任务。

Result: 实验结果表明，该方法在达到指定容差时能够提高求解速度，并且在固定计算预算下，显著提升了贝叶斯优化的性能。

Conclusion: 本文提出了一种有效提高迭代高斯过程可扩展性的方法，通过利用已知的小型系统解来加速大型线性系统的求解器收敛，从而在处理增量数据和进行贝叶斯优化时表现出优越的性能。

Abstract: Scalable Gaussian process (GP) inference is essential for sequential decision-making tasks, yet improving GP scalability remains a challenging problem with many open avenues of research. This paper focuses on iterative GPs, where iterative linear solvers, such as conjugate gradients, stochastic gradient descent or alternative projections, are used to approximate the GP posterior. We propose a new method which improves solver convergence of a large linear system by leveraging the known solution to a smaller system contained within. This is significant for tasks with incremental data additions, and we show that our technique achieves speed-ups when solving to tolerance, as well as improved Bayesian optimisation performance under a fixed compute budget.

</details>


### [33] [Optimal Fairness under Local Differential Privacy](https://arxiv.org/abs/2511.16377)
*Hrad Ghoukasian,Shahab Asoodeh*

Main category: cs.LG

TL;DR: 本文探讨了如何优化局部差分隐私（LDP）机制，以减少数据不公平性，进而提高下游分类的公平性。


<details>
  <summary>Details</summary>
Motivation: 减少数据不公平性，提高下游分类的公平性。

Method: 推导了二元敏感属性的闭式最优机制，并开发了多值属性的可处理优化框架。建立理论，证明减少数据不公平性必然降低分类不公平性。

Result: 在减少数据不公平性方面，本文方法优于现有LDP机制，且准确率接近非隐私模型。与领先的预处理和后处理公平性方法相比，本文机制在保证敏感属性隐私的同时，实现了更有利的准确性-公平性权衡。

Conclusion: LDP是一种原则性且有效的预处理公平性干预技术。

Abstract: We investigate how to optimally design local differential privacy (LDP) mechanisms that reduce data unfairness and thereby improve fairness in downstream classification. We first derive a closed-form optimal mechanism for binary sensitive attributes and then develop a tractable optimization framework that yields the corresponding optimal mechanism for multi-valued attributes. As a theoretical contribution, we establish that for discrimination-accuracy optimal classifiers, reducing data unfairness necessarily leads to lower classification unfairness, thus providing a direct link between privacy-aware pre-processing and classification fairness. Empirically, we demonstrate that our approach consistently outperforms existing LDP mechanisms in reducing data unfairness across diverse datasets and fairness metrics, while maintaining accuracy close to that of non-private models. Moreover, compared with leading pre-processing and post-processing fairness methods, our mechanism achieves a more favorable accuracy-fairness trade-off while simultaneously preserving the privacy of sensitive attributes. Taken together, these results highlight LDP as a principled and effective pre-processing fairness intervention technique.

</details>


### [34] [Correlation-Aware Feature Attribution Based Explainable AI](https://arxiv.org/abs/2511.16482)
*Poushali Sengupta,Yan Zhang,Frank Eliassen,Sabita Maharjan*

Main category: cs.LG

TL;DR: ExCIR通过引入相关影响比（Correlation Impact Ratio）和轻量级传输协议来解决现有全局归因方法在计算成本、在相关输入下的不稳定性以及扩展性方面的问题。它通过量化特征与模型输出之间经过鲁棒中心化处理后的符号对齐的同向运动，实现对模型排名的精确再现。ExCIR的群组扩展BlockCIR进一步解决了多重共线性问题，并在各种数据集中展现出高效、一致且可扩展的解释能力。


<details>
  <summary>Details</summary>
Motivation: 传统的解释性人工智能（XAI）方法在处理复杂模型和高风险应用时，存在计算成本高、在相关输入下缺乏稳定性以及难以有效扩展到大型或异构数据集的问题。

Method: ExCIR (Explainability through Correlation Impact Ratio) 是一种相关性感知归因分数，它配备了轻量级的传输协议，仅使用一小部分数据就能重现完整的模型排名。ExCIR在对特征和输出进行鲁棒中心化（减去鲁棒位置估计，如中位数或中间均值）后，量化特征和模型输出之间符号对齐的同向运动。此外，论文还引入了BlockCIR，它是ExCIR的群组扩展，它将相关特征集作为一个单元进行评分，通过对预定义或数据驱动的组进行相同的符号同向运动计算，减轻了共线性簇（例如，同义词或重复传感器）中的重复计数问题，并在存在强依赖关系时产生更平滑、更稳定的排名。

Result: ExCIR在文本、表格、信号和图像等不同数据集上，与已建立的全局基线和完整模型显示出可靠的一致性，在各种设置下提供了持续的Top-k排名，并通过在部分数据上进行轻量级评估来减少运行时间。

Conclusion: ExCIR 为实际部署提供了计算效率高、一致且可扩展的解释性。

Abstract: Explainable AI (XAI) is increasingly essential as modern models become more complex and high-stakes applications demand transparency, trust, and regulatory compliance. Existing global attribution methods often incur high computational costs, lack stability under correlated inputs, and fail to scale efficiently to large or heterogeneous datasets. We address these gaps with \emph{ExCIR} (Explainability through Correlation Impact Ratio), a correlation-aware attribution score equipped with a lightweight transfer protocol that reproduces full-model rankings using only a fraction of the data. ExCIR quantifies sign-aligned co-movement between features and model outputs after \emph{robust centering} (subtracting a robust location estimate, e.g., median or mid-mean, from features and outputs). We further introduce \textsc{BlockCIR}, a \emph{groupwise} extension of ExCIR that scores \emph{sets} of correlated features as a single unit. By aggregating the same signed-co-movement numerators and magnitudes over predefined or data-driven groups, \textsc{BlockCIR} mitigates double-counting in collinear clusters (e.g., synonyms or duplicated sensors) and yields smoother, more stable rankings when strong dependencies are present. Across diverse text, tabular, signal, and image datasets, ExCIR shows trustworthy agreement with established global baselines and the full model, delivers consistent top-$k$ rankings across settings, and reduces runtime via lightweight evaluation on a subset of rows. Overall, ExCIR provides \emph{computationally efficient}, \emph{consistent}, and \emph{scalable} explainability for real-world deployment.

</details>


### [35] [Global Resolution: Optimal Multi-Draft Speculative Sampling via Convex Minimization](https://arxiv.org/abs/2511.15898)
*Rahul Krishna Thomas,Arka Pal*

Main category: cs.LG

TL;DR: 本文提出了一种新的多草稿推测采样算法，该算法在不牺牲推理质量的前提下，将接受率提高到90%，并且每生成一个令牌的开销低于100毫秒。


<details>
  <summary>Details</summary>
Motivation: 推测采样能够有效降低大型语言模型自回归解码的延迟，但现有方法在接受率和解码效率方面仍有提升空间。特别是，寻找最优传输（OT）是一个难题，因为它涉及到解决一个变量数量巨大的线性规划问题（OTLP）。

Method: 本文首先证明了现有的一些OTLP表述仍然难以解决。随后，作者将OTLP重新表述为一个最大流问题，并通过多面体理论将其简化为一个变量数量在V以内的凸优化问题。在此基础上，本文提出了一种最优的n草稿推测采样算法，并允许进行精度调优。

Result: 本文提出的多草稿算法在保持与目标模型分布可忽略不计的偏差下，实现了90%的接受率，并且每生成一个令牌的开销低于100毫秒。

Conclusion: 本文通过将OTLP重新表述为最大流问题并利用多面体理论进行简化，成功开发出一种高效的多草稿推测采样算法，显著提升了大型语言模型自回归解码的效率。

Abstract: Speculative sampling reduces the latency of autoregressive decoding for target model LLMs without sacrificing inference quality, by using a cheap draft model to suggest a candidate token and a verification criterion to accept or resample this token. To improve acceptance and decoding efficiency, recent work has explored the multi-draft extension, where at each step $n$ draft tokens are generated, and the verification criterion is a distribution conditioned on these. When this criterion maximizes the probability of accepting some draft token, it is called the optimal transport (OT). However, finding the OT is difficult, as it is the solution of a linear program (OTLP) in over $V^n$ variables, with $V$ being the vocabulary size. Two recent theoretical works have reframed the OTLP in terms of importance sampling or subset selection. In this work, we prove that these formulations are equivalent to an exponentially large relaxed OTLP, so it remains infeasible to solve. Then, we reverse engineer subset selection to formulate the OTLP as a max-flow problem. With a novel application of polymatroid theory, we reduce the exponentially large OTLP to a convex optimization problem in at most $V$ variables. This allows us to devise an algorithm for optimal $n$-draft speculative sampling when the $n$ tokens are chosen i.i.d. from a single draft model, which can be tuned to arbitrary accuracy. Finally, we measure acceptance rates and algorithm runtimes for various $n$ and top-$k$ draft sampling settings. Our findings give the first multi-draft algorithm with 90% acceptance and under 100 ms of overhead per generated token with negligible deviation from the target model distribution.

</details>


### [36] [Toward Valid Generative Clinical Trial Data with Survival Endpoints](https://arxiv.org/abs/2511.16551)
*Perrine Chassat,Van Tuan Nguyen,Lucas Ducrot,Emilie Lanoy,Agathe Guilloux*

Main category: cs.LG

TL;DR: 本文介绍了一种用于生成混合类型协变量和生存结果的变分自动编码器（VAE），以解决临床试验中生成时间-事件结果的挑战。


<details>
  <summary>Details</summary>
Motivation: 临床试验面临患者群体分散、招募缓慢和成本过高的问题。为了解决这些挑战，研究人员探索了使用真实世界数据构建外部控制臂，或者通过生成式AI生成合成控制臂。然而，生成时间-事件结果是其中的一个核心难题，因为这些结果是肿瘤学和罕见疾病试验的主要终点，但在审查和小样本量下难以建模。

Method: 本文提出了一种变分自动编码器（VAE），它在统一的潜在变量框架内共同生成混合类型协变量和生存结果，并且不假设独立审查。

Result: 在合成和真实试验数据集中，该模型在两种现实场景中进行了评估：（i）隐私约束下的数据共享，其中合成控制替代原始数据，以及（ii）控制臂增强，其中合成患者减轻治疗组和控制组之间的不平衡。该方法在保真度、实用性和隐私指标上优于GAN基线，同时揭示了I型错误和功效的系统性错误校准。

Conclusion: 本文提出了一种后生成选择程序，可以改善校准，突出了生成生存模型方面的进展和开放性挑战。

Abstract: Clinical trials face mounting challenges: fragmented patient populations, slow enrollment, and unsustainable costs, particularly for late phase trials in oncology and rare diseases. While external control arms built from real-world data have been explored, a promising alternative is the generation of synthetic control arms using generative AI. A central challenge is the generation of time-to-event outcomes, which constitute primary endpoints in oncology and rare disease trials, but are difficult to model under censoring and small sample sizes. Existing generative approaches, largely GAN-based, are data-hungry, unstable, and rely on strong assumptions such as independent censoring. We introduce a variational autoencoder (VAE) that jointly generates mixed-type covariates and survival outcomes within a unified latent variable framework, without assuming independent censoring. Across synthetic and real trial datasets, we evaluate our model in two realistic scenarios: (i) data sharing under privacy constraints, where synthetic controls substitute for original data, and (ii) control-arm augmentation, where synthetic patients mitigate imbalances between treated and control groups. Our method outperforms GAN baselines on fidelity, utility, and privacy metrics, while revealing systematic miscalibration of type I error and power. We propose a post-generation selection procedure that improves calibration, highlighting both progress and open challenges for generative survival modeling.

</details>


### [37] [Unified all-atom molecule generation with neural fields](https://arxiv.org/abs/2511.15906)
*Matthieu Kirchmeyer,Pedro O. Pinheiro,Emma Willett,Karolis Martinkus,Joseph Kleinhenz,Emily K. Makowski,Andrew M. Watkins,Vladimir Gligorijevic,Richard Bonneau,Saeed Saremi*

Main category: cs.LG

TL;DR: FuncBind是一个基于计算机视觉的生成模型，能够针对不同原子系统生成结构化的全原子分子，例如小分子、大环肽和抗体CDR环区域，并且在体外实验中成功生成了新型抗体结合剂。


<details>
  <summary>Details</summary>
Motivation: 现有的结构引导药物设计生成模型通常局限于特定模态，限制了其广泛适用性。

Method: FuncBind利用神经场将分子表示为连续原子密度，并采用基于分数的生成模型与现代计算机视觉架构。这种与模态无关的表示允许在各种原子系统（从小分子到大分子，处理可变原子/残基数量）上训练一个统一模型。

Result: FuncBind在生成小分子、大环肽和抗体互补决定区（CDR）环方面取得了有竞争力的计算机模拟性能，这些生成都是以目标结构为条件的。此外，FuncBind通过对两个共晶结构的互补决定区H3环进行从头设计，在体外生成了新型抗体结合剂。

Conclusion: FuncBind框架为结构引导药物设计提供了一个统一且多功能的生成模型，能够处理从小分子到大分子的各种原子系统，并在计算机模拟和体外实验中展现了卓越的性能。同时，本研究还引入了一个用于结构条件大环肽生成的新数据集和基准。

Abstract: Generative models for structure-based drug design are often limited to a specific modality, restricting their broader applicability. To address this challenge, we introduce FuncBind, a framework based on computer vision to generate target-conditioned, all-atom molecules across atomic systems. FuncBind uses neural fields to represent molecules as continuous atomic densities and employs score-based generative models with modern architectures adapted from the computer vision literature. This modality-agnostic representation allows a single unified model to be trained on diverse atomic systems, from small to large molecules, and handle variable atom/residue counts, including non-canonical amino acids. FuncBind achieves competitive in silico performance in generating small molecules, macrocyclic peptides, and antibody complementarity-determining region loops, conditioned on target structures. FuncBind also generated in vitro novel antibody binders via de novo redesign of the complementarity-determining region H3 loop of two chosen co-crystal structures. As a final contribution, we introduce a new dataset and benchmark for structure-conditioned macrocyclic peptide generation. The code is available at https://github.com/prescient-design/funcbind.

</details>


### [38] [ECPv2: Fast, Efficient, and Scalable Global Optimization of Lipschitz Functions](https://arxiv.org/abs/2511.16575)
*Fares Fourati,Mohamed-Slim Alouini,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: ECPv2是一种可扩展的、理论基础坚实的全局优化算法，用于优化具有未知Lipschitz常数的Lipschitz连续函数。它通过引入自适应下界、Worst-m记忆机制和固定随机投影等创新，克服了ECP框架的局限性，实现了计算效率和性能的显著提升，并在理论和实践中都展现出优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的ECP框架在处理具有未知Lipschitz常数的Lipschitz连续函数的全局优化时，存在计算成本高和早期行为过于保守的问题。ECPv2旨在解决这些局限性，提供一个更高效、更具扩展性的优化算法。

Method: ECPv2在Every Call is Precious (ECP)框架的基础上，引入了三项创新：1. **自适应下界（Adaptive Lower Bound）**：避免空泛的接受区域。2. **Worst-m记忆机制（Worst-m Memory Mechanism）**：将比较限制在固定大小的过去评估子集内。3. **固定随机投影（Fixed Random Projection）**：加速高维空间中的距离计算。

Result: ECPv2保留了ECP的无遗憾保证和最优有限时间界限，并以高概率扩大了接受区域。在广泛的高维、非凸优化问题上进行的实验和消融研究表明，ECPv2在性能上始终与最先进的优化器相匹配或超越，同时显著减少了实际运行时间。

Conclusion: ECPv2通过其创新机制，成功解决了ECP框架的局限性，在全局优化问题上展现出卓越的性能和计算效率。它在理论上保证了无遗憾，并在实践中超越了现有技术水平。

Abstract: We propose ECPv2, a scalable and theoretically grounded algorithm for global optimization of Lipschitz-continuous functions with unknown Lipschitz constants. Building on the Every Call is Precious (ECP) framework, which ensures that each accepted function evaluation is potentially informative, ECPv2 addresses key limitations of ECP, including high computational cost and overly conservative early behavior. ECPv2 introduces three innovations: (i) an adaptive lower bound to avoid vacuous acceptance regions, (ii) a Worst-m memory mechanism that restricts comparisons to a fixed-size subset of past evaluations, and (iii) a fixed random projection to accelerate distance computations in high dimensions. We theoretically show that ECPv2 retains ECP's no-regret guarantees with optimal finite-time bounds and expands the acceptance region with high probability. We further empirically validate these findings through extensive experiments and ablation studies. Using principled hyperparameter settings, we evaluate ECPv2 across a wide range of high-dimensional, non-convex optimization problems. Across benchmarks, ECPv2 consistently matches or outperforms state-of-the-art optimizers, while significantly reducing wall-clock time.

</details>


### [39] [Breaking the Bottleneck with DiffuApriel: High-Throughput Diffusion LMs with Mamba Backbone](https://arxiv.org/abs/2511.15927)
*Vaibhav Singh,Oleksiy Ostapenko,Pierre-André Noël,Torsten Scholak*

Main category: cs.LG

TL;DR: DiffuApriel是一个基于双向Mamba骨干的掩蔽扩散语言模型，结合了扩散目标和线性时间序列建模，解决了Transformer模型在推理效率上的限制。


<details>
  <summary>Details</summary>
Motivation: Transformer骨干模型在自回归生成中存在二次注意力与KV缓存开销，影响了推理效率，因此需要寻求替代方案。

Method: 本文提出了DiffuApriel，一个基于双向Mamba骨干的掩蔽扩散语言模型，该模型将扩散目标与线性时间序列建模相结合。此外，还提出了DiffuApriel-H，一个混合变体，它交错使用注意力和Mamba层。

Result: DiffuApriel在性能上与基于Transformer的扩散模型相当，但对于长序列（1.3B模型）的推理吞吐量提高了4.4倍。DiffuApriel-H在平衡全局和局部上下文建模的同时，吞吐量提高了2.6倍。

Conclusion: 双向状态空间架构可以作为掩蔽扩散语言模型中强大的去噪器，为更快、内存高效的文本生成提供了实用且可扩展的基础。

Abstract: Diffusion-based language models have recently emerged as a promising alternative to autoregressive generation, yet their reliance on Transformer backbones limits inference efficiency due to quadratic attention and KV-cache overhead. In this work, we introduce DiffuApriel, a masked diffusion language model built on a bidirectional Mamba backbone that combines the diffusion objective with linear-time sequence modeling. DiffuApriel matches the performance of Transformer-based diffusion models while achieving up to 4.4x higher inference throughput for long sequences with a 1.3B model. We further propose DiffuApriel-H, a hybrid variant that interleaves attention and mamba layers, offering up to 2.6x throughput improvement with balanced global and local context modeling. Our results demonstrate that bidirectional state-space architectures serve as strong denoisers in masked diffusion LMs, providing a practical and scalable foundation for faster, memory-efficient text generation.

</details>


### [40] [Descend or Rewind? Stochastic Gradient Descent Unlearning](https://arxiv.org/abs/2511.15983)
*Siqiao Mu,Diego Klabjan*

Main category: cs.LG

TL;DR: 本文分析了两种机器反学习算法D2D和R2D，在强凸、凸和非凸损失函数下，证明了它们在随机设置中的(ε, δ)认证反学习保证。


<details>
  <summary>Details</summary>
Motivation: D2D和R2D是两种易于实现且具有可证明反学习保证的全批量梯度下降算法，其中D2D的随机版本被广泛用作“微调”反学习基线，但缺乏在非凸函数上的理论支持。

Method: 通过分析扰动或偏置梯度系统，并结合新颖的松弛高斯机制，本文证明了随机R2D和D2D的(ε, δ)认证反学习保证。

Result: D2D在强凸函数上可以提供比R2D更严格的保证，但R2D在凸和非凸设置中也能实现反学习。

Conclusion: R2D通过逆转累积扰动使未学习的模型更接近重新训练的模型，从而在凸和非凸情况下实现了反学习。

Abstract: Machine unlearning algorithms aim to remove the impact of selected training data from a model without the computational expenses of retraining from scratch. Two such algorithms are ``Descent-to-Delete" (D2D) and ``Rewind-to-Delete" (R2D), full-batch gradient descent algorithms that are easy to implement and satisfy provable unlearning guarantees. In particular, the stochastic version of D2D is widely implemented as the ``finetuning" unlearning baseline, despite lacking theoretical backing on nonconvex functions. In this work, we prove $(ε, δ)$ certified unlearning guarantees for stochastic R2D and D2D for strongly convex, convex, and nonconvex loss functions, by analyzing unlearning through the lens of disturbed or biased gradient systems, which may be contracting, semi-contracting, or expansive respectively. Our argument relies on optimally coupling the random behavior of the unlearning and retraining trajectories, resulting in a probabilistic sensitivity bound that can be combined with a novel relaxed Gaussian mechanism to achieve $(ε, δ)$ unlearning. We determine that D2D can yield tighter guarantees for strongly convex functions compared to R2D by relying on contraction to a unique global minimum. However, unlike D2D, R2D can achieve unlearning in the convex and nonconvex setting because it draws the unlearned model closer to the retrained model by reversing the accumulated disturbances.

</details>


### [41] [Synergizing Deconfounding and Temporal Generalization For Time-series Counterfactual Outcome Estimation](https://arxiv.org/abs/2511.16006)
*Yiling Liu,Juncheng Dong,Chen Fu,Wei Shi,Ziyang Jiang,Zhigang Hua,David Carlson*

Main category: cs.LG

TL;DR: 这篇论文提出了一种结合子治疗组对齐（SGA）和随机时间掩蔽（RTM）的新颖框架，用于从时间序列观察中估计反事实结果。该框架旨在解决反事实轨迹难以观测和混杂因素随时间演变的问题，并在反事实结果估计方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 从时间序列观察中估计反事实结果对于有效的决策至关重要，但面临两个主要挑战：反事实轨迹从未被观察到，以及混杂因素随时间演变并扭曲每一步的估计。

Method: 本文提出了一种新颖的框架，该框架协同整合了两种互补的方法：子治疗组对齐（SGA）和随机时间掩蔽（RTM）。SGA使用迭代的与治疗无关的聚类来识别细粒度的子治疗组，并对齐它们以实现改进的分布匹配，从而更有效地去混淆。RTM通过在训练期间随机用高斯噪声替换输入协变量来促进时间泛化，鼓励模型更少依赖潜在的噪声或虚假相关的协变量，更多依赖稳定的历史模式。

Result: 单独应用SGA和RTM都可以改善反事实结果估计，但它们的协同组合始终能达到最先进的性能。RTM增强了时间泛化和跨时间步的鲁棒性，而SGA改善了每个特定时间点的去混淆。

Conclusion: 该论文成功地解决了一项具有挑战性的任务，即从时间序列观察中估计反事实结果。通过引入SGA和RTM的组合，该框架不仅解决了数据固有的复杂性，而且还在各种数据集上取得了最先进的性能。它为时间序列数据中的反事实推理提供了一个强大而通用的解决方案。

Abstract: Estimating counterfactual outcomes from time-series observations is crucial for effective decision-making, e.g. when to administer a life-saving treatment, yet remains significantly challenging because (i) the counterfactual trajectory is never observed and (ii) confounders evolve with time and distort estimation at every step. To address these challenges, we propose a novel framework that synergistically integrates two complementary approaches: Sub-treatment Group Alignment (SGA) and Random Temporal Masking (RTM). Instead of the coarse practice of aligning marginal distributions of the treatments in latent space, SGA uses iterative treatment-agnostic clustering to identify fine-grained sub-treatment groups. Aligning these fine-grained groups achieves improved distributional matching, thus leading to more effective deconfounding. We theoretically demonstrate that SGA optimizes a tighter upper bound on counterfactual risk and empirically verify its deconfounding efficacy. RTM promotes temporal generalization by randomly replacing input covariates with Gaussian noises during training. This encourages the model to rely less on potentially noisy or spuriously correlated covariates at the current step and more on stable historical patterns, thereby improving its ability to generalize across time and better preserve underlying causal relationships. Our experiments demonstrate that while applying SGA and RTM individually improves counterfactual outcome estimation, their synergistic combination consistently achieves state-of-the-art performance. This success comes from their distinct yet complementary roles: RTM enhances temporal generalization and robustness across time steps, while SGA improves deconfounding at each specific time point.

</details>


### [42] [CARE: Turning LLMs Into Causal Reasoning Expert](https://arxiv.org/abs/2511.16016)
*Juncheng Dong,Yiling Liu,Ahmed Aloui,Vahid Tarokh,David Carlson*

Main category: cs.LG

TL;DR: 本文探讨了大型语言模型（LLMs）在因果关系发现方面的不足，并提出了CARE框架。CARE通过监督式微调，使LLMs能有效利用现有因果发现算法的输出，显著提升了LLMs的因果推理能力，甚至超越了传统算法和参数量更大的LLMs。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在推理和生成任务上表现出色，但它们在识别因果关系方面存在不足，而因果关系是人类智能的基石。

Method: 首先，作者探索性地研究了LLMs在因果发现任务中的行为，发现LLMs主要依赖变量名称的语义意义，忽略观测数据。接着，作者尝试使用成熟的因果发现算法的输出来提示LLMs，但发现这反而降低了LLMs的性能。为了解决这一局限性，作者提出了CARE框架。CARE通过监督式微调，教会LLMs有效利用成熟因果发现算法的输出。

Result: 实验结果表明，经过CARE框架微调的Qwen2.5-1.5B模型显著优于传统因果发现算法和参数多千倍的现有最先进LLMs。

Conclusion: LLMs在因果发现方面存在明显不足，但通过CARE框架进行监督式微调，使LLMs能够有效利用外部算法线索，可以显著提升其因果推理能力，甚至超越传统方法和更大的LLMs。

Abstract: Large language models (LLMs) have recently demonstrated impressive capabilities across a range of reasoning and generation tasks. However, research studies have shown that LLMs lack the ability to identify causal relationships, a fundamental cornerstone of human intelligence. We first conduct an exploratory investigation of LLMs' behavior when asked to perform a causal-discovery task and find that they mostly rely on the semantic meaning of variable names, ignoring the observation data. This is unsurprising, given that LLMs were never trained to process structural datasets. To first tackle this challenge, we prompt the LLMs with the outputs of established causal discovery algorithms designed for observational datasets. These algorithm outputs effectively serve as the sufficient statistics of the observation data. However, quite surprisingly, we find that prompting the LLMs with these sufficient statistics decreases the LLMs' performance in causal discovery. To address this current limitation, we propose CARE, a framework that enhances LLMs' causal-reasoning ability by teaching them to effectively utilize the outputs of established causal-discovery algorithms through supervised fine-tuning. Experimental results show that a finetuned Qwen2.5-1.5B model produced by CARE significantly outperforms both traditional causal-discovery algorithms and state-of-the-art LLMs with over a thousand times more parameters, demonstrating effective utilization of its own knowledge and the external algorithmic clues.

</details>


### [43] [Change-of-Basis Pruning via Rotational Invariance](https://arxiv.org/abs/2511.16061)
*Alex Ning,Vainateya Rangaraju*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的剪枝方法，通过引入正交线性变换来应对结构化剪枝的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决结构化剪枝中重要性分布对reprersentation space的影响，本文提出了一种名为CoB的剪枝方法。

Method: 本文提出了一种双子空间径向激活（TSRA）模块。这种激活函数在两个独立的激活子空间中进行正交线性变换时保持不变性。这种不变性使得CoB变换可以并入周围的权重中，而不会引入额外的参数。

Result: 与基于ReLU的对照相比，修改后允许旋转不变性会导致4.52%的准确度下降。然而，在CIFAR-10上，VGG-16实现CoB+TSRA框架显示出令人鼓舞的结果。在固定比例结构化剪枝下，CoB在所有剪枝比例下都提高了TSRA基线的准确度，并将可靠剪枝边界从大约30%扩展到70%。在基于阈值的剪枝策略下，CoB剪枝90-96%的参数，同时保持1-6%的准确度下降。

Conclusion: 旋转不变架构可以为基剪枝提供一条有前景的路径。

Abstract: Structured pruning removes entire neurons or channels, but its effectiveness depends on how importance is distributed across the representation space. Change-of-basis (CoB) pruning addresses this challenge by applying orthogonal linear transformations that concentrate importance within certain dimensions. However, many standard deep learning architectures are not inherently invariant to such transformations. To enable compatibility, we introduce two-subspace radial activations (TSRAs): an activation family that is invariant to orthogonal linear transformations applied independently within its two activation subspaces. This invariance allows CoB transformations to be merged into surrounding weights without incurring extra parameters. We position this work as a proof-of-concept that a rotationally invariant design may offer a principled approach towards change-of-basis pruning. We do not provide an analysis of multiple TSRA candidates nor do we explore weight initialization for any TSRAs. These limitations, combined with other necessary modifications we make to permit rotational invariance, result in a slight accuracy drop of $4.52\%$ compared to a ReLU-based control. However, using activation-magnitude importance, VGG-16 implementing our CoB+TSRA framework shows encouraging results on CIFAR-10. Under fixed-ratio structured pruning, CoB improves accuracy over a TSRA baseline at all pruning ratios and extends reliable pruning frontier from roughly $30\%$ to $70\%$ of parameters without post-prune fine tuning. Under threshold-based pruning strategies, CoB prunes $90-96\%$ of parameters while maintaining $1-6\%$ accuracy drop after fine-tuning. Together, these results indicate that rotationally invariant architectures may offer a promising path towards CoB pruning.

</details>


### [44] [ILoRA: Federated Learning with Low-Rank Adaptation for Heterogeneous Client Aggregation](https://arxiv.org/abs/2511.16069)
*Junchao Zhou,Junkang Liu,Fanhua Shang*

Main category: cs.LG

TL;DR: 该论文介绍了ILoRA，这是一个统一的框架，旨在解决联邦学习中低秩自适应（LoRA）在客户端异质性下所面临的三个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 在客户端异质性下，联邦学习中的LoRA面临三个关键挑战：初始化造成的不稳定性、秩不兼容和聚合误差以及非独立同分布数据下客户端漂移加剧。

Method: ILoRA框架整合了三项核心创新：1. 基于QR分解的正交初始化，确保所有客户端在一致的子空间中开始。 2. 级联QR聚合机制，通过连接和分解融合异构秩更新，同时保持维度对齐。 3. 带有秩感知控制变量的AdamW优化器，用于纠正局部更新并减轻客户端漂移。

Result: 通过理论收敛保证和在视觉及自然语言处理基准上的大量实验，ILoRA相较于现有联邦LoRA方法，在准确性和收敛稳定性方面均表现出卓越的性能。

Conclusion: ILoRA通过引入正交初始化、级联QR聚合和秩感知的AdamW优化器，有效解决了联邦学习中LoRA在客户端异质性下的挑战，显著提升了模型的性能和收敛稳定性。

Abstract: Federated Learning with Low-Rank Adaptation (LoRA) faces three critical challenges under client heterogeneity: (1) Initialization-Induced Instability due to random initialization misaligning client subspaces; (2) Rank Incompatibility and Aggregation Error when averaging LoRA parameters of different ranks, which biases the global model; and (3) exacerbated Client Drift under Non-IID Data, impairing generalization. To address these challenges, we propose ILoRA, a unified framework that integrates three core innovations: a QR-based orthonormal initialization to ensure all clients start in a coherent subspace; a Concatenated QR Aggregation mechanism that fuses heterogeneous-rank updates via concatenation and decomposition, preserving information while maintaining dimension alignment; and an AdamW optimizer with rank-aware control variates to correct local updates and mitigate client drift. Supported by theoretical convergence guarantees, extensive experiments on vision and NLP benchmarks demonstrate that ILoRA consistently achieves superior accuracy and convergence stability compared to existing federated LoRA methods.

</details>


### [45] [L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs](https://arxiv.org/abs/2511.16081)
*Huseyin Goksu*

Main category: cs.LG

TL;DR: 该论文介绍了一种自适应正交多项式滤波器（AOPF），并提出了两种模型：L-JacobiNet和S-JacobiNet，用于解决Spectral GNNs在异质性和过度平滑方面的局限性。研究发现，在[0, ∞)域中建模异质性更优，而在[-1, 1]域中具有更好的数值稳定性。此外，研究还发现ChebyNet的主要缺陷是稳定性而非其静态特性，并提出S-JacobiNet是一种强大的、被忽视的基线，性能优于自适应L-JacobiNet。


<details>
  <summary>Details</summary>
Motivation: 探索解决Spectral GNNs（如ChebyNet）在异质性和过度平滑方面的局限性，并寻找更有效的滤波器设计。

Method: 引入了两种在[-1, 1]域中运行的模型：L-JacobiNet和S-JacobiNet。L-JacobiNet是ChebyNet的自适应泛化，具有可学习的alpha和beta形状参数。S-JacobiNet是代表LayerNorm稳定静态ChebyNet的新型基线。将这些模型与在[0, ∞)域中的AOPF（如LaguerreNet）进行了比较分析。

Result: 研究发现，[0, ∞)域在建模异质性方面表现优越，而[-1, 1]域（Jacobi）在高K值（K>20）下提供卓越的数值稳定性。最重要的是，发现ChebyNet的主要缺陷是稳定性，而不是其静态性质。静态S-JacobiNet（ChebyNet+LayerNorm）在5个基准数据集中的4个上优于自适应L-JacobiNet。

Conclusion: S-JacobiNet被认为是一个强大但被忽视的基线，并且在[-1, 1]域中的自适应可能会导致过拟合。

Abstract: Spectral GNNs, like ChebyNet, are limited by heterophily and over-smoothing due to their static, low-pass filter design. This work investigates the "Adaptive Orthogonal Polynomial Filter" (AOPF) class as a solution. We introduce two models operating in the [-1, 1] domain: 1) `L-JacobiNet`, the adaptive generalization of `ChebyNet` with learnable alpha, beta shape parameters, and 2) `S-JacobiNet`, a novel baseline representing a LayerNorm-stabilized static `ChebyNet`. Our analysis, comparing these models against AOPFs in the [0, infty) domain (e.g., `LaguerreNet`), reveals critical, previously unknown trade-offs. We find that the [0, infty) domain is superior for modeling heterophily, while the [-1, 1] domain (Jacobi) provides superior numerical stability at high K (K>20). Most significantly, we discover that `ChebyNet`'s main flaw is stabilization, not its static nature. Our static `S-JacobiNet` (ChebyNet+LayerNorm) outperforms the adaptive `L-JacobiNet` on 4 out of 5 benchmark datasets, identifying `S-JacobiNet` as a powerful, overlooked baseline and suggesting that adaptation in the [-1, 1] domain can lead to overfitting.

</details>


### [46] [AssayMatch: Learning to Select Data for Molecular Activity Models](https://arxiv.org/abs/2511.16087)
*Vincent Fan,Regina Barzilay*

Main category: cs.LG

TL;DR: AssayMatch通过量化训练批次对模型性能的贡献来筛选数据，从而提高药物发现中机器学习模型的预测能力。


<details>
  <summary>Details</summary>
Motivation: 药物发现中机器学习模型的性能受训练数据质量影响。由于数据集大小的限制，模型通常通过整合来自不同来源的生物活性数据进行训练，但这会引入由实验方案变异性引起的噪声。

Method: AssayMatch是一个数据选择框架，它利用数据归因方法来量化每个训练批次对模型性能的贡献。这些归因分数用于微调基于文本的批次描述的语言嵌入，以捕获语义相似性和批次之间的兼容性。

Result: 通过AssayMatch选择数据训练的模型能够超越在完整数据集上训练的模型的性能，这表明它能够有效地过滤掉有害或有噪声的实验。在12个模型-目标对中，有9个的模型预测能力有所提高。

Conclusion: AssayMatch提供了一种数据驱动的机制来整理更高质量的数据集，减少不兼容实验带来的噪声，并提高药物发现中模型的预测能力和数据效率。

Abstract: The performance of machine learning models in drug discovery is highly dependent on the quality and consistency of the underlying training data. Due to limitations in dataset sizes, many models are trained by aggregating bioactivity data from diverse sources, including public databases such as ChEMBL. However, this approach often introduces significant noise due to variability in experimental protocols. We introduce AssayMatch, a framework for data selection that builds smaller, more homogenous training sets attuned to the test set of interest. AssayMatch leverages data attribution methods to quantify the contribution of each training assay to model performance. These attribution scores are used to finetune language embeddings of text-based assay descriptions to capture not just semantic similarity, but also the compatibility between assays. Unlike existing data attribution methods, our approach enables data selection for a test set with unknown labels, mirroring real-world drug discovery campaigns where the activities of candidate molecules are not known in advance. At test time, embeddings finetuned with AssayMatch are used to rank all available training data. We demonstrate that models trained on data selected by AssayMatch are able to surpass the performance of the model trained on the complete dataset, highlighting its ability to effectively filter out harmful or noisy experiments. We perform experiments on two common machine learning architectures and see increased prediction capability over a strong language-only baseline for 9/12 model-target pairs. AssayMatch provides a data-driven mechanism to curate higher-quality datasets, reducing noise from incompatible experiments and improving the predictive power and data efficiency of models for drug discovery. AssayMatch is available at https://github.com/Ozymandias314/AssayMatch.

</details>


### [47] [Pathlet Variational Auto-Encoder for Robust Trajectory Generation](https://arxiv.org/abs/2511.16105)
*Yuanbo Tang,Yan Tang,Zixuan Zhang,Zihui Zhao,Yang Li*

Main category: cs.LG

TL;DR: 作者提出了一种基于pathlet表示的深度生成模型，解决了轨迹生成模型在噪声数据下的鲁棒性和可解释性问题。该模型能够有效地学习数据分布，在真实数据集上取得显著性能提升，并可应用于轨迹预测和数据去噪等下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有的轨迹生成模型在处理噪声数据时的鲁棒性和可解释性不足，限制了其在实际应用中的可信度。

Method: 该模型利用城市轨迹的规律结构，提出了一种基于pathlet表示的深度生成模型。它使用变分自动编码器（VAE）组件和线性解码器组件来描述轨迹生成过程，同时学习pathlet表示的潜在嵌入和捕捉移动模式的pathlet字典。模型还支持根据时空约束生成定制轨迹。

Result: 模型在存在噪声数据的情况下仍能有效地学习数据分布，在两个真实轨迹数据集上比强基线模型分别取得了35.4%和26.3%的相对改进。生成的轨迹可用于轨迹预测和数据去噪等下游任务。此外，该框架在效率上具有显著优势，相较于以前的方法，节省了64.8%的时间和56.5%的GPU内存。

Conclusion: 本研究提出的深度生成模型通过引入pathlet表示和特定的模型架构，有效提升了轨迹生成模型在噪声数据下的鲁棒性和可解释性。它不仅在性能上超越了现有基线，还在效率上取得显著突破，为城市移动性研究和位置服务应用提供了更可靠的工具。

Abstract: Trajectory generation has recently drawn growing interest in privacy-preserving urban mobility studies and location-based service applications. Although many studies have used deep learning or generative AI methods to model trajectories and have achieved promising results, the robustness and interpretability of such models are largely unexplored. This limits the application of trajectory generation algorithms on noisy real-world data and their trustworthiness in downstream tasks. To address this issue, we exploit the regular structure in urban trajectories and propose a deep generative model based on the pathlet representation, which encode trajectories with binary vectors associated with a learned dictionary of trajectory segments. Specifically, we introduce a probabilistic graphical model to describe the trajectory generation process, which includes a Variational Autoencoder (VAE) component and a linear decoder component. During training, the model can simultaneously learn the latent embedding of pathlet representations and the pathlet dictionary that captures mobility patterns in the trajectory dataset. The conditional version of our model can also be used to generate customized trajectories based on temporal and spatial constraints.
  Our model can effectively learn data distribution even using noisy data, achieving relative improvements of $35.4\%$ and $26.3\%$ over strong baselines on two real-world trajectory datasets. Moreover, the generated trajectories can be conveniently utilized for multiple downstream tasks, including trajectory prediction and data denoising. Lastly, the framework design offers a significant efficiency advantage, saving $64.8\%$ of the time and $56.5\%$ of GPU memory compared to previous approaches.

</details>


### [48] [An Interpretability-Guided Framework for Responsible Synthetic Data Generation in Emotional Text](https://arxiv.org/abs/2511.16132)
*Paula Joy B. Martinez,Jose Marie Antonio Miñoza,Sebastian C. Ibañez*

Main category: cs.LG

TL;DR: 该文章介绍了一种使用SHAP值指导LLM生成合成数据，用于社交媒体情感识别的方法。


<details>
  <summary>Details</summary>
Motivation: 由于API成本和平台限制的增加，获取社交媒体情感识别的训练数据变得非常昂贵。

Method: 文章引入了一个可解释性引导的框架，其中Shapley加性解释（SHAP）为基于大型语言模型（LLM）的合成数据生成提供了原则性指导。

Result: 在有足够种子数据的情况下，SHAP指导的方法可以达到与真实数据相同的性能，显著优于朴素生成方法，并显著改善了代表性不足的情感类别的分类效果。然而，语言分析表明，合成文本在词汇丰富度、个人表达和时间复杂性方面不如真实帖子。

Conclusion: 本文提出了一个负责任的合成数据生成的实用框架，并批判性地分析了其局限性，强调了在合成数据的实用性和真实世界的真实性之间进行权衡对于可信AI的未来至关重要。

Abstract: Emotion recognition from social media is critical for understanding public sentiment, but accessing training data has become prohibitively expensive due to escalating API costs and platform restrictions. We introduce an interpretability-guided framework where Shapley Additive Explanations (SHAP) provide principled guidance for LLM-based synthetic data generation. With sufficient seed data, SHAP-guided approach matches real data performance, significantly outperforms naïve generation, and substantially improves classification for underrepresented emotion classes. However, our linguistic analysis reveals that synthetic text exhibits reduced vocabulary richness and fewer personal or temporally complex expressions than authentic posts. This work provides both a practical framework for responsible synthetic data generation and a critical perspective on its limitations, underscoring that the future of trustworthy AI depends on navigating the trade-offs between synthetic utility and real-world authenticity.

</details>


### [49] [Labels Matter More Than Models: Quantifying the Benefit of Supervised Time Series Anomaly Detection](https://arxiv.org/abs/2511.16145)
*Zhijie Zhong,Zhiwen Yu,Kaixiang Yang,C. L. Philip Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为STAND的简化监督学习基线模型，该模型在时间序列异常检测（TSAD）任务中，利用有限的异常标签，显著优于复杂的无监督方法。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列异常检测（TSAD）研究主要集中在无监督方法，因为标签稀缺。然而，这种方法忽视了利用有限异常标签可能带来的显著性能提升。本文旨在挑战“架构复杂性是TSAD最佳路径”这一前提，并探讨监督方法在有限标签下的潜力。

Method: 本文对监督和无监督范式进行了首次系统性比较，并引入了一个名为STAND的简化监督基线模型。

Result: (1) 标签比模型更重要：在有限的标注预算下，简单的监督模型显著优于复杂的最新无监督方法。(2) 监督带来更高的回报：少量监督带来的性能提升远超架构创新。(3) 实用性：与无监督模型相比，STAND在预测一致性和异常定位方面表现出卓越的性能。

Conclusion: 研究结果表明，TSAD研究应转向以数据为中心，强调标签利用，而非单纯追求算法复杂性。

Abstract: Time series anomaly detection (TSAD) is a critical data mining task often constrained by label scarcity. Consequently, current research predominantly focuses on Unsupervised Time-series Anomaly Detection (UTAD), relying on complex architectures to model normal data distributions. However, this approach often overlooks the significant performance gains available from limited anomaly labels achievable in practical scenarios. This paper challenges the premise that architectural complexity is the optimal path for TSAD. We conduct the first methodical comparison between supervised and unsupervised paradigms and introduce STAND, a streamlined supervised baseline. Extensive experiments on five public datasets demonstrate that: (1) Labels matter more than models: under a limited labeling budget, simple supervised models significantly outperform complex state-of-the-art unsupervised methods; (2) Supervision yields higher returns: the performance gain from minimal supervision far exceeds that from architectural innovations; and (3) Practicality: STAND exhibits superior prediction consistency and anomaly localization compared to unsupervised counterparts. These findings advocate for a data-centric shift in TSAD research, emphasizing label utilization over purely algorithmic complexity. The code is publicly available at https://github.com/EmorZz1G/STAND.

</details>


### [50] [Enhancing Nuclear Reactor Core Simulation through Data-Based Surrogate Models](https://arxiv.org/abs/2511.16148)
*Perceval Beja-Battais,Alain Grossetête,Nicolas Vayatis*

Main category: cs.LG

TL;DR: 为了满足可再生能源快速增长的需求，核电厂需要提高灵活性。OAPS通过模型预测控制（MPC）解决这个问题。本文通过数据驱动的模拟方案改进MPC方法。该文引入了两个替代模拟方案，以增强核反应堆堆芯模拟，这两个方案是数据驱动和物理信息模型，可以快速集成复杂动力学，计算时间大大减少。


<details>
  <summary>Details</summary>
Motivation: 为了满足可再生能源的快速增长，核电厂需要提高灵活性。帧元公司开发的OAPS通过模型预测控制（MPC）解决了这个问题。本文旨在通过数据驱动的模拟方案改进MPC方法。

Method: 本文引入了两种替代模拟方案，以增强核反应堆堆芯模拟：数据驱动模型和物理信息模型。这两种模型都可以快速集成复杂动力学，并且计算时间大大减少（最高可达1000倍）。

Result: 本文表明，数据驱动和物理信息模型都可以快速集成复杂动力学，计算时间大大减少（最高可达1000倍）。

Conclusion: 数据驱动和物理信息模型能够有效提高核反应堆堆芯模拟的效率和准确性，为核电厂的灵活性改进提供了有力支持。

Abstract: In recent years, there has been an increasing need for Nuclear Power Plants (NPPs) to improve flexibility in order to match the rapid growth of renewable energies. The Operator Assistance Predictive System (OAPS) developed by Framatome addresses this problem through Model Predictive Control (MPC). In this work, we aim to improve MPC methods through data-driven simulation schemes. Thus, from a set of nonlinear stiff ordinary differential equations (ODEs), this paper introduces two surrogate models acting as alternative simulation schemes to enhance nuclear reactor core simulation. We show that both data-driven and physics-informed models can rapidly integrate complex dynamics, with a very low computational time (up to 1000x time reduction).

</details>


### [51] [Achieving Skilled and Reliable Daily Probabilistic Forecasts of Wind Power at Subseasonal-to-Seasonal Timescales over France](https://arxiv.org/abs/2511.16164)
*Eloi Lindas,Yannig Goude,Philippe Ciais*

Main category: cs.LG

TL;DR: 本文提出了一种将ECMWF次季节到季节天气预报转化为风力预报的流水线方法，可将预报提前期延长至46天，并在次季节尺度上显著优于气候基线。


<details>
  <summary>Details</summary>
Motivation: 风电预测对于电网稳定、供需平衡和市场风险管理至关重要。尽管短期天气预报已被充分用于短期可再生能源预测，但涉及更长预测范围的预测仍需研究。

Method: 本文提出了一种预测流水线，能够将ECMWF的次季节到季节天气预报转化为日分辨率的风力预测，提前期为1天至46天。该框架还包括对所得电力集合进行后处理，以解决天气预报的偏差和离散不足的问题。

Result: 该方法在连续排序概率技能得分和集合均方误差方面均优于气候学基线50%。

Conclusion: 该方法在15至46天的提前期内为预测提供了近乎完美的校准，在较长预测范围的风电预测方面取得了显著进展。

Abstract: Accurate and reliable wind power forecasts are crucial for grid stability, balancing supply and demand, and market risk management. Even though short-term weather forecasts have been thoroughly used to provide short-term renewable power predictions, forecasts involving longer prediction horizons still need investigations. Despite the recent progress in subseasonal-to-seasonal weather probabilistic forecasting, their use for wind power prediction usually involves both temporal and spatial aggregation achieve reasonable skill. In this study, we present a forecasting pipeline enabling to transform ECMWF subseasonal-to-seasonal weather forecasts into wind power forecasts for lead times ranging from 1 day to 46 days at daily resolution. This framework also include post-processing of the resulting power ensembles to account for the biases and lack of dispersion of the weather forecasts. We show that our method is able to outperform a climatological baseline by 50 % in terms of both Continuous Ranked Probability Skill Score and Ensemble Mean Squared Error while also providing near perfect calibration of the forecasts for lead times ranging from 15 to 46 days.

</details>


### [52] [A Switching Framework for Online Interval Scheduling with Predictions](https://arxiv.org/abs/2511.16194)
*Antonios Antoniadis,Ali Shahheidar,Golnoosh Shahkarami,Abolfazl Soltani*

Main category: cs.LG

TL;DR: 本文提出了一种名为SemiTrust-and-Switch的框架来解决在线区间调度问题。该框架结合了预测算法和经典算法，在保证鲁棒性的前提下，利用预测提高了性能。


<details>
  <summary>Details</summary>
Motivation: 在不可撤销的在线区间调度问题中，如何在区间到达时立即决定接受或拒绝，以最大化接受区间的总长度，且保证区间不重叠，是一个挑战。特别是，本文旨在利用机器学习预测来提高算法性能，同时在预测错误时仍能保持稳健。

Method: 本文提出了一个SemiTrust-and-Switch框架，它能够统一结合基于预测的算法和经典的区间调度算法。该框架适用于确定性和随机算法，并且可以权衡在准确预测下的性能（一致性）和在对抗输入下的性能（鲁棒性）。此外，本文还设计了一个随机算法，能够在基于预测的算法和鲁棒算法之间平滑插值，该算法具有鲁棒性，并且其性能会随着预测质量的下降而平稳退化。

Result: SemiTrust-and-Switch框架为在线区间调度问题提供了一个统一的解决方案，实现了性能提升和鲁棒性保证。本文还提供了下界，证明了该框架在特定设置下的紧密性。所提出的随机算法实现了鲁棒性和平稳性。

Conclusion: 本文成功地设计了一个学习增强的在线区间调度算法框架SemiTrust-and-Switch，该框架有效地结合了预测的优势和经典算法的鲁棒性。它在一致性和鲁棒性之间取得了良好的平衡，并且在预测质量下降时仍能保持平稳的性能退化。

Abstract: We study online interval scheduling in the irrevocable setting, where each interval must be immediately accepted or rejected upon arrival. The objective is to maximize the total length of accepted intervals while ensuring that no two accepted intervals overlap. We consider this problem in a learning-augmented setting, where the algorithm has access to (machine-learned) predictions. The goal is to design algorithms that leverage these predictions to improve performance while maintaining robust guarantees in the presence of prediction errors.
  Our main contribution is the SemiTrust-and-Switch framework, which provides a unified approach for combining prediction-based and classical interval scheduling algorithms. This framework applies to both deterministic and randomized algorithms and captures the trade-off between consistency (performance under accurate predictions) and robustness (performance under adversarial inputs). Moreover, we provide lower bounds, proving the tightness of this framework in particular settings.
  We further design a randomized algorithm that smoothly interpolates between prediction-based and robust algorithms. This algorithm achieves both robustness and smoothness--its performance degrades gracefully with the quality of the prediction.

</details>


### [53] [Towards Overcoming Data Scarcity in Nuclear Energy: A Study on Critical Heat Flux with Physics-consistent Conditional Diffusion Model](https://arxiv.org/abs/2511.16207)
*Farah Alsafadi,Alexandra Akins,Xu Wu*

Main category: cs.LG

TL;DR: 该文章旨在探讨扩散模型（DM）在解决核能应用中数据稀缺性问题方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 在能源相关的应用中，实验数据通常有限、昂贵或难以获取，导致数据稀缺。深度生成模型，特别是扩散模型（DM），能够学习训练数据的潜在概率分布，生成与训练数据统计学特征相似的高保真合成样本。这种合成数据生成可以显著增加可用训练数据的规模和多样性，更重要的是，提高下游机器学习模型在预测任务中的鲁棒性。

Method: 本文利用一个包含商业核反应堆运行条件范围的临界热通量（CHF）公共数据集，开发了一个扩散模型（DM），能够生成任意数量的合成样本以扩充CHF数据集。由于普通的DM只能随机生成样本，我们还开发了一种条件DM，能够在用户指定的热工水力条件下生成有针对性的CHF数据。

Result: 结果表明，DM和条件DM都成功生成了真实且符合物理原理的CHF数据。此外，还进行了不确定性量化。结果表明，条件DM在扩充CHF数据方面非常有效，同时保持了可接受的不确定性水平。

Conclusion: 本研究验证了扩散模型在解决核能应用中数据稀缺性方面的潜力，特别是在临界热通量（CHF）数据的生成和扩充方面。开发的条件扩散模型能够根据用户指定的条件生成具有物理一致性的数据，并有效地量化了不确定性，为核能领域的机器学习应用提供了有价值的数据增强方法。

Abstract: Deep generative modeling provides a powerful pathway to overcome data scarcity in energy-related applications where experimental data are often limited, costly, or difficult to obtain. By learning the underlying probability distribution of the training dataset, deep generative models, such as the diffusion model (DM), can generate high-fidelity synthetic samples that statistically resemble the training data. Such synthetic data generation can significantly enrich the size and diversity of the available training data, and more importantly, improve the robustness of downstream machine learning models in predictive tasks. The objective of this paper is to investigate the effectiveness of DM for overcoming data scarcity in nuclear energy applications. By leveraging a public dataset on critical heat flux (CHF) that cover a wide range of commercial nuclear reactor operational conditions, we developed a DM that can generate an arbitrary amount of synthetic samples for augmenting of the CHF dataset. Since a vanilla DM can only generate samples randomly, we also developed a conditional DM capable of generating targeted CHF data under user-specified thermal-hydraulic conditions. The performance of the DM was evaluated based on their ability to capture empirical feature distributions and pair-wise correlations, as well as to maintain physical consistency. The results showed that both the DM and conditional DM can successfully generate realistic and physics-consistent CHF data. Furthermore, uncertainty quantification was performed to establish confidence in the generated data. The results demonstrated that the conditional DM is highly effective in augmenting CHF data while maintaining acceptable levels of uncertainty.

</details>


### [54] [Mind the Gap: Bridging Prior Shift in Realistic Few-Shot Crop-Type Classification](https://arxiv.org/abs/2511.16218)
*Joana Reuss,Ekaterina Gikalo,Marco Körner*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的方法Dirichlet Prior Augmentation（DirPA），旨在解决农业数据集中存在的类别不平衡问题，并提高模型在真实世界条件下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 农业数据集中存在严重的类别不平衡问题，通常呈现长尾分布。作物类型分类的带标签数据集稀缺且获取成本高。在有限数据的情况下，训练集常常被人为平衡（尤其是在少样本学习中），这与真实世界的条件不符。这种不匹配会导致训练和测试标签分布之间的偏移，从而降低真实世界的泛化能力。

Method: 本文提出了一种新颖的方法Dirichlet Prior Augmentation (DirPA)，它在模型训练期间主动模拟目标域的未知标签分布偏差。具体来说，我们将真实世界分布建模为Dirichlet分布的随机变量，在少样本学习中有效地执行先验增强。

Result: 实验表明，DirPA成功地改变了决策边界，并通过充当动态特征正则化器来稳定训练过程。

Conclusion: DirPA方法通过模拟真实世界的标签分布偏差，有效解决了农业数据类别不平衡的问题，提高了模型在少样本学习场景下的泛化能力和训练稳定性。

Abstract: Real-world agricultural distributions often suffer from severe class imbalance, typically following a long-tailed distribution. Labeled datasets for crop-type classification are inherently scarce and remain costly to obtain. When working with such limited data, training sets are frequently constructed to be artificially balanced -- in particular in the case of few-shot learning -- failing to reflect real-world conditions. This mismatch induces a shift between training and test label distributions, degrading real-world generalization. To address this, we propose Dirichlet Prior Augmentation (DirPA), a novel method that simulates an unknown label distribution skew of the target domain proactively during model training. Specifically, we model the real-world distribution as Dirichlet-distributed random variables, effectively performing a prior augmentation during few-shot learning. Our experiments show that DirPA successfully shifts the decision boundary and stabilizes the training process by acting as a dynamic feature regularizer.

</details>


### [55] [Pass@k Metric for RLVR: A Diagnostic Tool of Exploration, But Not an Objective](https://arxiv.org/abs/2511.16231)
*Yang Yu*

Main category: cs.LG

TL;DR: 本文分析了大型语言模型（LLM）中pass@k指标，发现它在探索最关键的阶段提供的学习信号会消失，并认为它可能不适合直接优化，而应采用更有效的探索机制。


<details>
  <summary>Details</summary>
Motivation: 评估和增强大型语言模型执行复杂多步推理的能力，并分析pass@k指标作为评估标准和强化学习优化目标的有效性。

Method: 本文对pass@k目标进行了分析，推导了其梯度，并证明它本质上是更简单的pass@1目标的每个样本的积极重新加权。此外，本文还分析了“探索崩溃”的动态。

Result: 本文分析表明，在探索最关键的阶段，pass@k目标提供的学习信号会消失。且随着策略集中概率质量，pass@k和pass@1之间的差距会减小。

Conclusion: 尽管pass@k是一个有用的诊断工具，但它可能不适合作为优化的直接目标。相反，明确鼓励有效探索的机制可以为推理任务中的强化学习提供更有效的途径。

Abstract: The ability of Large Language Models (LLMs) to perform complex, multi-step reasoning is a central focus of modern AI research. To evaluate and enhance this capability, the pass@k metric, which measures the probability of obtaining at least one correct solution in k independent samples, has received significant attention. Its intuitive appeal has led to its adoption not only as an evaluation standard but also as a direct optimization objective in reinforcement learning. In this paper, we analyze the pass@k objective, derive its gradient, and demonstrate that it is fundamentally a per-example positive reweighting of the simpler pass@1 objective. Our analysis reveals that the pass@k objective provides a vanishing learning signal in regimes where exploration is most critical. We further analyze the dynamics of "exploration collapse", showing that as the policy concentrates probability mass, the gap between pass@k and pass@1 diminishes. We conclude that while pass@k is a useful diagnostic tool, it may be an unsuitable direct objective for optimization. Instead, mechanisms explicitly encouraging efficient exploration could offer a more effective path forward for reinforcement learning in reasoning tasks.

</details>


### [56] [GeoPTH: A Lightweight Approach to Category-Based Trajectory Retrieval via Geometric Prototype Trajectory Hashing](https://arxiv.org/abs/2511.16258)
*Yang Xu,Zuliang Yang,Kai Ming Ting*

Main category: cs.LG

TL;DR: GeoPTH：一种创新的轨迹检索框架，它通过几何原型和哈希技术，在效率和准确性上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的轨迹相似性检索方法在计算成本、训练开销和稳定性方面存在局限性。

Method: GeoPTH通过使用代表性轨迹原型（保留几何特征的小点集）作为锚点来构建数据依赖的哈希函数。它将新轨迹映射到最近的原型，使用鲁棒的Hausdorff度量。

Result: GeoPTH的检索精度与传统度量和最先进的学习方法相比具有高度竞争力，并且在效率方面显著优于所有竞争者。

Conclusion: GeoPTH证明了轻量级的、以原型为中心的方法在轨迹检索中作为一种实用且强大的替代方案，能够实现卓越的检索性能和计算效率。

Abstract: Trajectory similarity retrieval is an important part of spatiotemporal data mining, however, existing methods have the following limitations: traditional metrics are computationally expensive, while learning-based methods suffer from substantial training costs and potential instability. This paper addresses these problems by proposing \textbf{Geo}metric \textbf{P}rototype \textbf{T}rajectory \textbf{H}ashing (GeoPTH), a novel, lightweight, and non-learning framework for efficient category-based trajectory retrieval. GeoPTH constructs data-dependent hash functions by using representative trajectory prototypes, i.e., small point sets preserving geometric characteristics, as anchors. The hashing process is efficient, which involves mapping a new trajectory to its closest prototype via a robust, \textit{Hausdorff} metric. Extensive experiments show that GeoPTH's retrieval accuracy is highly competitive with both traditional metrics and state-of-the-art learning methods, and it significantly outperforms binary codes generated through simple binarization of the learned embeddings. Critically, GeoPTH consistently outperforms all competitors in terms of efficiency. Our work demonstrates that a lightweight, prototype-centric approach offers a practical and powerful alternative, achieving an exceptional retrieval performance and computational efficiency.

</details>


### [57] [Graph Diffusion Counterfactual Explanation](https://arxiv.org/abs/2511.16287)
*David Bechtoldt,Sidney Bender*

Main category: cs.LG

TL;DR: 本文提出了Graph Diffusion Counterfactual Explanation（GDCE）框架，利用离散扩散模型和无分类器指导在图数据上生成反事实解释。


<details>
  <summary>Details</summary>
Motivation: 现有的图机器学习模型在预测时缺乏可解释性，而图数据上的反事实解释研究相对较少，因为图的离散和非欧几里得特性使其难以构建反事实。

Method: GDCE框架结合了离散扩散模型和无分类器指导技术。

Result: GDCE方法能够可靠地生成符合数据分布的反事实解释，并且在结构上与原始图差异最小，适用于离散分类和连续属性。

Conclusion: Graph Diffusion Counterfactual Explanation框架有效地解决了图数据反事实解释的挑战，为图机器学习的可解释性研究提供了新方向。

Abstract: Machine learning models that operate on graph-structured data, such as molecular graphs or social networks, often make accurate predictions but offer little insight into why certain predictions are made. Counterfactual explanations address this challenge by seeking the closest alternative scenario where the model's prediction would change. Although counterfactual explanations are extensively studied in tabular data and computer vision, the graph domain remains comparatively underexplored. Constructing graph counterfactuals is intrinsically difficult because graphs are discrete and non-euclidean objects. We introduce Graph Diffusion Counterfactual Explanation, a novel framework for generating counterfactual explanations on graph data, combining discrete diffusion models and classifier-free guidance. We empirically demonstrate that our method reliably generates in-distribution as well as minimally structurally different counterfactuals for both discrete classification targets and continuous properties.

</details>


### [58] [Optimizing Operation Recipes with Reinforcement Learning for Safe and Interpretable Control of Chemical Processes](https://arxiv.org/abs/2511.16297)
*Dean Brandner,Sergio Lucia*

Main category: cs.LG

TL;DR: 这篇论文提出了一种结合强化学习和专家知识的新方法，用于优化化工过程的操作，解决了传统强化学习方法在数据需求、约束处理和模型复杂性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 在化工过程中，实现能源、资源和成本节约的关键在于优化操作。然而，传统强化学习方法在处理严格的质量和安全硬约束以及大量训练数据需求方面面临挑战。详细的动态模型虽然是替代方案，但其复杂性使得数据生成在计算上难以实现。现有的优化控制方法，如模型预测控制，也受限于基础动态模型的复杂性。此外，许多化工过程仍依赖手动定义的操作方案和简单的线性控制器，导致次优性能和有限的灵活性。

Method: 本文提出了一种新颖的方法，利用操作方案中嵌入的专家知识。通过使用强化学习来优化这些方案及其基础线性控制器的参数，从而实现优化的操作方案。

Result: 与传统强化学习方法相比，该方法所需数据显著减少，能更有效地处理约束，并且由于方案的结构化特性，可解释性更强。通过对工业间歇聚合反应器进行仿真，结果表明该方法能够接近最优控制器的性能，同时解决了现有方法的局限性。

Conclusion: 本研究提出了一种有效优化化工过程操作的新方法，通过结合强化学习和专家知识，解决了现有方法的痛点，并在实际应用中展现了巨大潜力。

Abstract: Optimal operation of chemical processes is vital for energy, resource, and cost savings in chemical engineering. The problem of optimal operation can be tackled with reinforcement learning, but traditional reinforcement learning methods face challenges due to hard constraints related to quality and safety that must be strictly satisfied, and the large amount of required training data. Chemical processes often cannot provide sufficient experimental data, and while detailed dynamic models can be an alternative, their complexity makes it computationally intractable to generate the needed data. Optimal control methods, such as model predictive control, also struggle with the complexity of the underlying dynamic models. Consequently, many chemical processes rely on manually defined operation recipes combined with simple linear controllers, leading to suboptimal performance and limited flexibility.
  In this work, we propose a novel approach that leverages expert knowledge embedded in operation recipes. By using reinforcement learning to optimize the parameters of these recipes and their underlying linear controllers, we achieve an optimized operation recipe. This method requires significantly less data, handles constraints more effectively, and is more interpretable than traditional reinforcement learning methods due to the structured nature of the recipes. We demonstrate the potential of our approach through simulation results of an industrial batch polymerization reactor, showing that it can approach the performance of optimal controllers while addressing the limitations of existing methods.

</details>


### [59] [Learning-Enhanced Observer for Linear Time-Invariant Systems with Parametric Uncertainty](https://arxiv.org/abs/2511.16318)
*Hao Shu*

Main category: cs.LG

TL;DR: 该论文介绍了一种学习增强观测器（LEO），用于具有不确定动态的线性时不变系统，通过梯度下降优化系统矩阵，以减少稳态输出差异损失，从而在保留经典设计结构的同时，有效补偿中等参数不确定性。


<details>
  <summary>Details</summary>
Motivation: 在存在不确定系统动态的情况下，提高线性时不变系统状态估计的准确性和鲁棒性。

Method: 提出了一种学习增强观测器（LEO）框架，该框架将系统矩阵视为可优化变量，并通过基于梯度的稳态输出差异损失最小化来优化这些矩阵，从而形成数据驱动的替代模型，并构建改进的观测器。

Result: 在各种系统维度下，蒙特卡洛研究表明，对于开环和Luenberger观测器，归一化估计误差系统地、显著地减少，通常超过15%。

Conclusion: 现代学习机制可以作为传统观测器设计的强大补充，在不确定系统中产生更准确、更鲁棒的状态估计。

Abstract: This work introduces a learning-enhanced observer (LEO) for linear time-invariant systems with uncertain dynamics. Rather than relying solely on nominal models, the proposed framework treats the system matrices as optimizable variables and refines them through gradient-based minimization of a steady-state output discrepancy loss. The resulting data-informed surrogate model enables the construction of an improved observer that effectively compensates for moderate parameter uncertainty while preserving the structure of classical designs. Extensive Monte Carlo studies across diverse system dimensions show systematic and statistically significant reductions, typically exceeding 15\%, in normalized estimation error for both open-loop and Luenberger observers. These results demonstrate that modern learning mechanisms can serve as a powerful complement to traditional observer design, yielding more accurate and robust state estimation in uncertain systems. Codes are available at https://github.com/Hao-B-Shu/LTI_LEO.

</details>


### [60] [Beyond Generative AI: World Models for Clinical Prediction, Counterfactuals, and Planning](https://arxiv.org/abs/2511.16333)
*Mohammad Areeb Qazi,Maryam Nadeem,Mohammad Yaqub*

Main category: cs.LG

TL;DR: 这篇综述探讨了用于医疗保健的“世界模型”，它能学习多模态、时间一致和动作条件表征，以实现预测、可靠和数据高效的AI。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在临床推理方面的收益递减，但世界模型以其学习多模态、时间连贯和动作条件表征的能力而受到关注，这些表征反映了医疗护理的物理和因果结构，从而克服了当前生成模型缺乏物理基础和时间推理的缺点。

Method: 通过对医疗影像和诊断、电子健康记录疾病进展建模以及机器人手术和手术规划这三个领域的现有工作进行审查，总结了世界模型在医疗保健系统中的应用。文章还引入了能力评估标准，包括L1时间预测、L2动作条件预测、L3反事实推演和L4规划/控制。

Result: 大多数被审查的系统达到了L1-L2级别，L3的实例较少，L4则极为罕见。文章指出了限制临床可靠性的普遍存在的差距，例如未明确的行动空间和安全约束、薄弱的干预验证、不完整的多模态状态构建以及有限的轨迹级不确定性校准。

Conclusion: 为了医疗保健领域安全可靠的决策支持，未来的研究应侧重于开发结合生成骨干（如Transformers、扩散模型、VAE）与因果/机械基础的、临床上稳健的以预测为先的世界模型。文章为构建一个临床稳健、以预测为核心的世界模型提出了研究议程。

Abstract: Healthcare requires AI that is predictive, reliable, and data-efficient. However, recent generative models lack physical foundation and temporal reasoning required for clinical decision support. As scaling language models show diminishing returns for grounded clinical reasoning, world models are gaining traction because they learn multimodal, temporally coherent, and action-conditioned representations that reflect the physical and causal structure of care. This paper reviews World Models for healthcare systems that learn predictive dynamics to enable multistep rollouts, counterfactual evaluation and planning. We survey recent work across three domains: (i) medical imaging and diagnostics (e.g., longitudinal tumor simulation, projection-transition modeling, and Joint Embedding Predictive Architecture i.e., JEPA-style predictive representation learning), (ii) disease progression modeling from electronic health records (generative event forecasting at scale), and (iii) robotic surgery and surgical planning (action-conditioned guidance and control). We also introduce a capability rubric: L1 temporal prediction, L2 action-conditioned prediction, L3 counterfactual rollouts for decision support, and L4 planning/control. Most reviewed systems achieve L1--L2, with fewer instances of L3 and rare L4. We identify cross-cutting gaps that limit clinical reliability; under-specified action spaces and safety constraints, weak interventional validation, incomplete multimodal state construction, and limited trajectory-level uncertainty calibration. This review outlines a research agenda for clinically robust prediction-first world models that integrate generative backbones (transformers, diffusion, VAE) with causal/mechanical foundation for safe decision support in healthcare.

</details>


### [61] [Are Foundation Models Useful for Bankruptcy Prediction?](https://arxiv.org/abs/2511.16375)
*Marcin Kostrzewa,Oleksii Furman,Roman Furman,Sebastian Tomczak,Maciej Zięba*

Main category: cs.LG

TL;DR: 本文分析了基础模型在企业破产预测中的应用，发现Llama-3.3-70B-Instruct和TabPFN等基础模型在预测性能上不及XGBoost和CatBoost等传统机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型在企业破产预测中的有效性，并与现有方法进行比较。

Method: 使用Llama-3.3-70B-Instruct和TabPFN两种基础模型，并在来自维谢格拉德集团的超过一百万条公司记录的、高度不平衡的大型数据集上进行评估。同时，与XGBoost和CatBoost等经典机器学习基线模型进行比较，分析破产预测任务的性能差异。

Result: XGBoost和CatBoost等传统机器学习模型在所有预测范围内均优于基础模型。基于LLM的方法存在不可靠的概率估计问题。TabPFN虽然与较简单的基线模型具有竞争力，但其计算资源成本较高，且性能提升不明显。

Conclusion: 当前的基础模型在企业破产预测方面不如专用方法有效。

Abstract: Foundation models have shown promise across various financial applications, yet their effectiveness for corporate bankruptcy prediction remains systematically unevaluated against established methods. We study bankruptcy forecasting using Llama-3.3-70B-Instruct and TabPFN, evaluated on large, highly imbalanced datasets of over one million company records from the Visegrád Group. We provide the first systematic comparison of foundation models against classical machine learning baselines for this task. Our results show that models such as XGBoost and CatBoost consistently outperform foundation models across all prediction horizons. LLM-based approaches suffer from unreliable probability estimates, undermining their use in risk-sensitive financial settings. TabPFN, while competitive with simpler baselines, requires substantial computational resources with costs not justified by performance gains. These findings suggest that, despite their generality, current foundation models remain less effective than specialized methods for bankruptcy forecasting.

</details>


### [62] [FreqFlow: Long-term forecasting using lightweight flow matching](https://arxiv.org/abs/2511.16426)
*Seyed Mohamad Moghadas,Bruno Cornelis,Adrian Munteanu*

Main category: cs.LG

TL;DR: FreqFlow是一种新颖的多元时间序列（MTS）预测框架，它利用频域中的条件流匹配进行确定性MTS预测。


<details>
  <summary>Details</summary>
Motivation: 传统的去噪扩散生成模型在处理高维、非平稳和多尺度周期模式时计算开销大且脆弱。

Method: FreqFlow将预测问题转化为频谱域，通过单个复值线性层学习建模振幅和相位，从而有效地捕捉时间动态。它将MTS信号分解为趋势、季节和残差分量，并通过流匹配机制专门设计用于残差学习，以提高长期预测精度。

Result: FreqFlow实现了最先进的预测性能，平均RMSE提高了7%，并且比现有方法更快、参数效率更高。

Conclusion: FreqFlow通过频域处理和流匹配机制，在MTS预测方面取得了显著的性能提升和效率优化。

Abstract: Multivariate time-series (MTS) forecasting is fundamental to applications ranging from urban mobility and resource management to climate modeling. While recent generative models based on denoising diffusion have advanced state-of-the-art performance in capturing complex data distributions, they suffer from significant computational overhead due to iterative stochastic sampling procedures that limit real-time deployment. Moreover, these models can be brittle when handling high-dimensional, non-stationary, and multi-scale periodic patterns characteristic of real-world sensor networks. We introduce FreqFlow, a novel framework that leverages conditional flow matching in the frequency domain for deterministic MTS forecasting. Unlike conventional approaches that operate in the time domain, FreqFlow transforms the forecasting problem into the spectral domain, where it learns to model amplitude and phase shifts through a single complex-valued linear layer. This frequency-domain formulation enables the model to efficiently capture temporal dynamics via complex multiplication, corresponding to scaling and temporal translations. The resulting architecture is exceptionally lightweight with only 89k parameters - an order of magnitude smaller than competing diffusion-based models-while enabling single-pass deterministic sampling through ordinary differential equation (ODE) integration. Our approach decomposes MTS signals into trend, seasonal, and residual components, with the flow matching mechanism specifically designed for residual learning to enhance long-term forecasting accuracy. Extensive experiments on real-world traffic speed, volume, and flow datasets demonstrate that FreqFlow achieves state-of-the-art forecasting performance, on average 7\% RMSE improvements, while being significantly faster and more parameter-efficient than existing methods

</details>


### [63] [Generative Modeling of Clinical Time Series via Latent Stochastic Differential Equations](https://arxiv.org/abs/2511.16427)
*Muhammad Aslanimoghanloo,Ahmed ElGazzar,Marcel van Gerven*

Main category: cs.LG

TL;DR: 该文章提出了一个基于潜在神经随机微分方程的生成模型框架，用于处理临床时间序列数据，该框架能够有效处理不规则采样、复杂非线性相互作用以及疾病进展和测量噪声的随机性。


<details>
  <summary>Details</summary>
Motivation: 利用电子健康记录和医疗注册中心的临床时间序列数据来理解患者轨迹并为医疗决策提供信息面临挑战，这些挑战包括不规则采样、复杂的潜在生理学以及测量和疾病进展中固有的不确定性。

Method: 文章提出了一个基于潜在神经随机微分方程（SDEs）的生成建模框架，将临床时间序列视为底层受控随机动力系统的离散时间部分观测值。该方法通过具有模态依赖发射模型的神经SDEs模拟潜在动力学，并通过变分推断执行状态估计和参数学习。

Result: 该框架在两个任务中进行了验证：1）使用肺癌的模拟药代动力学-药效学（PKPD）模型估计个体治疗效果；2）使用来自12,000名患者的真实世界重症监护室（ICU）数据进行生理信号的概率预测。结果表明，该框架在准确性和不确定性估计方面优于常微分方程和长短期记忆基线模型。

Conclusion: 该框架能够实现精确的、考虑不确定性的预测，从而支持临床决策。

Abstract: Clinical time series data from electronic health records and medical registries offer unprecedented opportunities to understand patient trajectories and inform medical decision-making. However, leveraging such data presents significant challenges due to irregular sampling, complex latent physiology, and inherent uncertainties in both measurements and disease progression. To address these challenges, we propose a generative modeling framework based on latent neural stochastic differential equations (SDEs) that views clinical time series as discrete-time partial observations of an underlying controlled stochastic dynamical system. Our approach models latent dynamics via neural SDEs with modality-dependent emission models, while performing state estimation and parameter learning through variational inference. This formulation naturally handles irregularly sampled observations, learns complex non-linear interactions, and captures the stochasticity of disease progression and measurement noise within a unified scalable probabilistic framework. We validate the framework on two complementary tasks: (i) individual treatment effect estimation using a simulated pharmacokinetic-pharmacodynamic (PKPD) model of lung cancer, and (ii) probabilistic forecasting of physiological signals using real-world intensive care unit (ICU) data from 12,000 patients. Results show that our framework outperforms ordinary differential equation and long short-term memory baseline models in accuracy and uncertainty estimation. These results highlight its potential for enabling precise, uncertainty-aware predictions to support clinical decision-making.

</details>


### [64] [A Comparison Between Decision Transformers and Traditional Offline Reinforcement Learning Algorithms](https://arxiv.org/abs/2511.16475)
*Ali Murtaza Caunhye,Asad Jeewa*

Main category: cs.LG

TL;DR: 本文比较了Decision Transformer（DT）与传统离线强化学习算法（如CQL和IQL）在不同奖励密度下的性能，发现在稀疏奖励场景下，DT对奖励密度变化不敏感，表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统离线强化学习算法在探索与利用的平衡上面临挑战，尤其是在奖励密度不同的环境中。而Decision Transformer（DT）作为一种新方法展现了巨大潜力，因此本文旨在比较DT与传统离线强化学习算法在不同奖励密度下的性能。

Method: 本文在ANT连续控制环境中，分别在密集奖励和稀疏奖励设置下，对Decision Transformer（DT）和传统离线强化学习算法（如Conservative Q-Learning (CQL) 和 Implicit Q-Learning (IQL)）的性能进行了比较研究。

Result: 研究发现，在稀疏奖励场景下，Decision Transformer（DT）对奖励密度变化的敏感度较低，在medium-expert数据集中表现出色。相比之下，IQL在密集奖励和高质量数据下表现更好，而CQL在不同数据质量下表现均衡。DT在性能上具有较低的方差，但计算资源消耗更高。

Conclusion: 序列表现方法（如DT）可能更适用于奖励结构不确定或数据质量混合的场景，而基于价值的方法（如IQL和CQL）在奖励密集和高质量演示的场景中仍具竞争力。

Abstract: The field of Offline Reinforcement Learning (RL) aims to derive effective policies from pre-collected datasets without active environment interaction. While traditional offline RL algorithms like Conservative Q-Learning (CQL) and Implicit Q-Learning (IQL) have shown promise, they often face challenges in balancing exploration and exploitation, especially in environments with varying reward densities. The recently proposed Decision Transformer (DT) approach, which reframes offline RL as a sequence modelling problem, has demonstrated impressive results across various benchmarks. This paper presents a comparative study evaluating the performance of DT against traditional offline RL algorithms in dense and sparse reward settings for the ANT continous control environment. Our research investigates how these algorithms perform when faced with different reward structures, examining their ability to learn effective policies and generalize across varying levels of feedback. Through empirical analysis in the ANT environment, we found that DTs showed less sensitivity to varying reward density compared to other methods and particularly excelled with medium-expert datasets in sparse reward scenarios. In contrast, traditional value-based methods like IQL showed improved performance in dense reward settings with high-quality data, while CQL offered balanced performance across different data qualities. Additionally, DTs exhibited lower variance in performance but required significantly more computational resources compared to traditional approaches. These findings suggest that sequence modelling approaches may be more suitable for scenarios with uncertain reward structures or mixed-quality data, while value-based methods remain competitive in settings with dense rewards and high-quality demonstrations.

</details>


### [65] [Limitations of Scalarisation in MORL: A Comparative Study in Discrete Environments](https://arxiv.org/abs/2511.16476)
*Muhammad Sa'ood Shah,Asad Jeewa*

Main category: cs.LG

TL;DR: 这篇论文研究了多目标强化学习（MORL）中标量化函数在复杂不确定环境下的局限性，并提出了内循环多策略算法作为更稳健的替代方案。


<details>
  <summary>Details</summary>
Motivation: 探索多目标强化学习（MORL）中，标量化函数在复杂不确定环境中进行决策时的局限性。

Method: 采用外循环多策略方法评估了基于线性标量化和切比雪夫标量化函数的MO Q-Learning算法的性能，并比较了内循环多策略算法Pareto Q-Learning。

Result: 标量化函数的性能高度依赖于环境和帕累托前沿的形状，难以保留学习到的解并在解空间的特定区域内有所偏好，且难以找到合适的权重配置。相比之下，内循环多策略算法可能提供更可持续和泛化的方法。

Conclusion: 在动态和不确定环境中，内循环多策略算法为智能决策提供了更可持续和泛化的方法，优于传统标量化函数。

Abstract: Scalarisation functions are widely employed in MORL algorithms to enable intelligent decision-making. However, these functions often struggle to approximate the Pareto front accurately, rendering them unideal in complex, uncertain environments. This study examines selected Multi-Objective Reinforcement Learning (MORL) algorithms across MORL environments with discrete action and observation spaces. We aim to investigate further the limitations associated with scalarisation approaches for decision-making in multi-objective settings. Specifically, we use an outer-loop multi-policy methodology to assess the performance of a seminal single-policy MORL algorithm, MO Q-Learning implemented with linear scalarisation and Chebyshev scalarisation functions. In addition, we explore a pioneering inner-loop multi-policy algorithm, Pareto Q-Learning, which offers a more robust alternative. Our findings reveal that the performance of the scalarisation functions is highly dependent on the environment and the shape of the Pareto front. These functions often fail to retain the solutions uncovered during learning and favour finding solutions in certain regions of the solution space. Moreover, finding the appropriate weight configurations to sample the entire Pareto front is complex, limiting their applicability in uncertain settings. In contrast, inner-loop multi-policy algorithms may provide a more sustainable and generalizable approach and potentially facilitate intelligent decision-making in dynamic and uncertain environments.

</details>


### [66] [ODE-ViT: Plug & Play Attention Layer from the Generalization of the ViT as an Ordinary Differential Equation](https://arxiv.org/abs/2511.16501)
*Carlos Boned Riera,David Romero Sanchez,Oriol Ramos Terrades*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为ODE-ViT的视觉Transformer模型，该模型将Transformer重新构造为一个常微分方程（ODE）系统，实现了更稳定、可解释的性能，且参数量大幅减少。此外，论文还提出了一种即插即用的师生框架，通过离散ViT指导ODE-ViT的连续轨迹，进一步提升了性能。


<details>
  <summary>Details</summary>
Motivation: 大型模型在计算机视觉任务中表现出色，但计算资源和存储需求大，且决策过程难以理解。同时，大多数这些模型都依赖于基于Transformer的注意力机制。

Method: 论文将Vision Transformer重新表述为一个满足良好条件和稳定动力学的常微分方程（ODE）系统，并称之为ODE-ViT。此外，还提出了一个即插即用的师生框架，其中离散的ViT模型作为教师，通过将其中间表示作为ODE的解来指导ODE-ViT的连续轨迹。

Result: 在CIFAR-10和CIFAR-100数据集上，ODE-ViT实现了稳定、可解释且具有竞争力的性能，参数量减少了一个数量级。在分类任务中，其表现优于之前基于ODE的Transformer方法。师生框架使性能提升了超过10%。

Conclusion: ODE-ViT通过将Vision Transformer重构为ODE系统，实现了高性能、可解释性和参数效率。引入师生框架进一步提升了模型的性能。

Abstract: In recent years, increasingly large models have achieved outstanding performance across CV tasks. However, these models demand substantial computational resources and storage, and their growing complexity limits our understanding of how they make decisions. Most of these architectures rely on the attention mechanism within Transformer-based designs. Building upon the connection between residual neural networks and ordinary differential equations (ODEs), we introduce ODE-ViT, a Vision Transformer reformulated as an ODE system that satisfies the conditions for well-posed and stable dynamics. Experiments on CIFAR-10 and CIFAR-100 demonstrate that ODE-ViT achieves stable, interpretable, and competitive performance with up to one order of magnitude fewer parameters, surpassing prior ODE-based Transformer approaches in classification tasks. We further propose a plug-and-play teacher-student framework in which a discrete ViT guides the continuous trajectory of ODE-ViT by treating the intermediate representations of the teacher as solutions of the ODE. This strategy improves performance by more than 10% compared to training a free ODE-ViT from scratch.

</details>


### [67] [Loss Functions Robust to the Presence of Label Errors](https://arxiv.org/abs/2511.16512)
*Nicholas Pellegrino,David Szczecina,Paul Fieguth*

Main category: cs.LG

TL;DR: 这篇论文提出了两种新的损失函数，通过降低或忽略难以分类的样本（可能是标签错误），以提高训练数据中标签错误检测的F1分数。


<details>
  <summary>Details</summary>
Motivation: 在训练数据中检测标签错误的方法需要对标签错误具有鲁棒性的模型，但获得这样的模型往往涉及在已损坏的数据上进行训练。

Method: 提出了两种新的简单损失函数，它们受到Focal Loss的启发，但旨在降低或忽略难以分类的样本（即可能存在标签错误的样本）。

Result: 在人工损坏数据上的实验结果表明，与传统的分类交叉熵和Focal Loss基线相比，这两种新方法在检测标签错误方面的F1分数有所提高。

Conclusion: 通过调整损失函数，特别是降低或忽略难以分类的样本，可以有效提高训练数据中标签错误检测的性能。

Abstract: Methods for detecting label errors in training data require models that are robust to label errors (i.e., not fit to erroneously labelled data points). However, acquiring such models often involves training on corrupted data, which presents a challenge. Adjustments to the loss function present an opportunity for improvement. Motivated by Focal Loss (which emphasizes difficult-to-classify samples), two novel, yet simple, loss functions are proposed that de-weight or ignore these difficult samples (i.e., those likely to have label errors). Results on artificially corrupted data show promise, such that F1 scores for detecting errors are improved from the baselines of conventional categorical Cross Entropy and Focal Loss.

</details>


### [68] [Saving Foundation Flow-Matching Priors for Inverse Problems](https://arxiv.org/abs/2511.16520)
*Yuxiang Wan,Ryan Devera,Wenjie Zhang,Ju Sun*

Main category: cs.LG

TL;DR: FMPlug是一个插件框架，重新定义了基础流匹配模型在逆问题中的使用方式，通过实例引导、时间依赖的暖启动策略和高斯正则化，显著提升了图像恢复和科学IPs的性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前基础流匹配（FM）模型在逆问题（IPs）中表现不如领域特定或未经训练的先验，旨在释放其潜力。

Method: FMPlug框架结合了实例引导、时间依赖的暖启动策略与尖锐的高斯正则化，在保持高斯结构的同时，增加了问题特定的指导。

Result: FMPlug在图像恢复和科学IPs方面带来了显著的性能提升。

Conclusion: FMPlug为使基础FM模型成为解决IPs的实用、可重用先验指明了方向。

Abstract: Foundation flow-matching (FM) models promise a universal prior for solving inverse problems (IPs), yet today they trail behind domain-specific or even untrained priors. How can we unlock their potential? We introduce FMPlug, a plug-in framework that redefines how foundation FMs are used in IPs. FMPlug combines an instance-guided, time-dependent warm-start strategy with a sharp Gaussianity regularization, adding problem-specific guidance while preserving the Gaussian structures. This leads to a significant performance boost across image restoration and scientific IPs. Our results point to a path for making foundation FM models practical, reusable priors for IP solving.

</details>


### [69] [Dynamic Participation in Federated Learning: Benchmarks and a Knowledge Pool Plugin](https://arxiv.org/abs/2511.16523)
*Ming-Lun Lee,Fu-Shiang Yang,Cheng-Kuan Lin,Yan-Ann Chen,Chih-Yu Lin,Yu-Chee Tseng*

Main category: cs.LG

TL;DR: 该文章提出了一个针对联邦学习中动态客户端参与场景的开源基准测试框架，并在此基础上提出了一种名为KPFL的通用插件，以解决动态参与带来的性能下降和知识丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习研究大多假设客户端参与是一致的，忽略了客户端可能在训练过程中间歇性加入或离开的动态参与（DPFL）的实际场景。此外，目前还没有系统支持DPFL特有挑战的基准测试框架。

Method: 本文提出了第一个专门为在动态客户端参与下对联邦学习模型进行基准测试而设计的开源框架。该框架提供可配置的数据分布、参与模式和针对DPFL场景的评估指标。在此平台基础上，本文对四类广泛采用的联邦学习模型进行了基准测试。为了解决动态参与带来的挑战，本文进一步提出了知识池联邦学习（KPFL），这是一个通用插件，它在活跃和空闲客户端之间维护一个共享知识池。KPFL利用双年龄和数据偏差加权，结合生成式知识蒸馏，以减轻不稳定性和防止知识丢失。

Result: 基准测试揭示了在动态参与下，联邦学习模型性能的大幅下降。广泛的实验证明了动态参与对联邦学习性能的显著影响，以及KPFL在提高模型鲁棒性和泛化能力方面的有效性。

Conclusion: 动态客户端参与对联邦学习性能有着显著影响，而所提出的KPFL框架能够有效提高模型的鲁棒性和泛化能力，为解决DPFL场景下的挑战提供了有效途径。

Abstract: Federated learning (FL) enables clients to collaboratively train a shared model in a distributed manner, setting it apart from traditional deep learning paradigms. However, most existing FL research assumes consistent client participation, overlooking the practical scenario of dynamic participation (DPFL), where clients may intermittently join or leave during training. Moreover, no existing benchmarking framework systematically supports the study of DPFL-specific challenges. In this work, we present the first open-source framework explicitly designed for benchmarking FL models under dynamic client participation. Our framework provides configurable data distributions, participation patterns, and evaluation metrics tailored to DPFL scenarios. Using this platform, we benchmark four major categories of widely adopted FL models and uncover substantial performance degradation under dynamic participation. To address these challenges, we further propose Knowledge-Pool Federated Learning (KPFL), a generic plugin that maintains a shared knowledge pool across both active and idle clients. KPFL leverages dual-age and data-bias weighting, combined with generative knowledge distillation, to mitigate instability and prevent knowledge loss. Extensive experiments demonstrate the significant impact of dynamic participation on FL performance and the effectiveness of KPFL in improving model robustness and generalization.

</details>


### [70] [FairLRF: Achieving Fairness through Sparse Low Rank Factorization](https://arxiv.org/abs/2511.16549)
*Yuanbo Guo,Jun Xia,Yiyu Shi*

Main category: cs.LG

TL;DR: 这篇论文提出了FairLRF，这是一个新颖的框架，它利用奇异值分解（SVD）来增强深度学习模型的公平性，通过选择性地去除酉矩阵中导致偏差的元素来实现，而不会显著牺牲模型性能。


<details>
  <summary>Details</summary>
Motivation: DL模型在医疗诊断等敏感领域的日益普及，使得在保持高性能的同时确保模型公平性变得至关重要，但现有的偏差缓解方法往往计算成本高昂或导致模型精度显著下降。

Method: 本文提出了FairLRF框架，该框架利用奇异值分解（SVD）来提高深度学习模型的公平性。与传统SVD主要用于模型压缩不同，FairLRF利用SVD分解产生的酉矩阵中的元素对模型偏差贡献不等的观察，选择性地移除这些导致偏差的元素，从而减小组间差异，增强模型公平性。

Result: 广泛的实验表明，FairLRF方法优于传统的低秩分解方法以及最先进的公平性增强技术。消融研究也探讨了主要超参数如何影响处理后模型的性能。

Conclusion: FairLRF首次利用SVD主要不是为了压缩，而是为了增强深度学习模型的公平性，通过选择性地去除酉矩阵中引起偏差的元素，有效地在不显著降低性能的情况下，提高了模型的公平性。

Abstract: As deep learning (DL) techniques become integral to various applications, ensuring model fairness while maintaining high performance has become increasingly critical, particularly in sensitive fields such as medical diagnosis. Although a variety of bias-mitigation methods have been proposed, many rely on computationally expensive debiasing strategies or suffer substantial drops in model accuracy, which limits their practicality in real-world, resource-constrained settings. To address this issue, we propose a fairness-oriented low rank factorization (LRF) framework that leverages singular value decomposition (SVD) to improve DL model fairness. Unlike traditional SVD, which is mainly used for model compression by decomposing and reducing weight matrices, our work shows that SVD can also serve as an effective tool for fairness enhancement. Specifically, we observed that elements in the unitary matrices obtained from SVD contribute unequally to model bias across groups defined by sensitive attributes. Motivated by this observation, we propose a method, named FairLRF, that selectively removes bias-inducing elements from unitary matrices to reduce group disparities, thus enhancing model fairness. Extensive experiments show that our method outperforms conventional LRF methods as well as state-of-the-art fairness-enhancing techniques. Additionally, an ablation study examines how major hyper-parameters may influence the performance of processed models. To the best of our knowledge, this is the first work utilizing SVD not primarily for compression but for fairness enhancement.

</details>


### [71] [Almost Sure Convergence Analysis of Differentially Private Stochastic Gradient Methods](https://arxiv.org/abs/2511.16587)
*Amartya Mukherjee,Jun Liu*

Main category: cs.LG

TL;DR: 本文分析了差分隐私随机梯度下降（DP-SGD）算法在非凸和强凸设置下，在标准平滑假设和步长衰减条件下几乎必然收敛到最小值，该分析也适用于动量变体（如DP-SHB和DP-NAG）。


<details>
  <summary>Details</summary>
Motivation: 尽管DP-SGD被广泛使用，但对其长期行为的理论理解仍然有限，现有分析主要建立期望或高概率收敛，但未能解决单路径的几乎必然收敛问题。

Method: 通过理论分析，证明在标准平滑假设、步长满足衰减条件时，DP-SGD在非凸和强凸设置下都能几乎必然收敛。该分析也拓展到动量变体如DP-SHB和DP-NAG，通过仔细的能量构造获得相似的保证。

Result: DP-SGD在标准平滑假设和步长衰减条件下几乎必然收敛，在非凸和强凸设置中均成立。动量变体DP-SHB和DP-NAG也得到类似的保证。

Conclusion: 这些结果为差分隐私优化提供了更强的理论基础，表明尽管存在隐私引起的扭曲，算法在凸和非凸情况下仍然是路径稳定的。

Abstract: Differentially private stochastic gradient descent (DP-SGD) has become the standard algorithm for training machine learning models with rigorous privacy guarantees. Despite its widespread use, the theoretical understanding of its long-run behavior remains limited: existing analyses typically establish convergence in expectation or with high probability, but do not address the almost sure convergence of single trajectories. In this work, we prove that DP-SGD converges almost surely under standard smoothness assumptions, both in nonconvex and strongly convex settings, provided the step sizes satisfy some standard decaying conditions. Our analysis extends to momentum variants such as the stochastic heavy ball (DP-SHB) and Nesterov's accelerated gradient (DP-NAG), where we show that careful energy constructions yield similar guarantees. These results provide stronger theoretical foundations for differentially private optimization and suggest that, despite privacy-induced distortions, the algorithm remains pathwise stable in both convex and nonconvex regimes.

</details>


### [72] [Toward Artificial Palpation: Representation Learning of Touch on Soft Bodies](https://arxiv.org/abs/2511.16596)
*Zohar Rimon,Elisei Shafer,Tal Tepper,Efrat Shimron,Aviv Tamar*

Main category: cs.LG

TL;DR: 本文提出了一种基于自监督学习的人工触诊方法，通过编码器-解码器框架从触觉测量序列中学习表示，可用于触觉成像和变化检测。


<details>
  <summary>Details</summary>
Motivation: 目前触诊主要由人类执行，但现有技术（力图）无法捕捉复杂的触觉模式。本文旨在开发一种能从触觉测量中学习更丰富、更精细表示的人工触诊方法。

Method: 1. 提出一个基于自监督学习的编码器-解码器框架，用于从触觉测量序列中学习表示。2. 开发了一个仿真环境。3. 收集了真实世界的软物体数据集，并使用磁共振成像（MRI）获取了相应的真实图像。4. 使用配备触觉传感器的机器人收集触诊序列。5. 训练模型预测物体不同位置的感官读数。

Result: 本文研究了所学到的表示，并展示了其在成像和变化检测方面的应用。

Conclusion: 本文成功地验证了基于自监督学习的人工触诊概念，所学习到的表示能够用于触觉成像和变化检测，为超越传统力图的触觉模式识别提供了新的方向。

Abstract: Palpation, the use of touch in medical examination, is almost exclusively performed by humans. We investigate a proof of concept for an artificial palpation method based on self-supervised learning. Our key idea is that an encoder-decoder framework can learn a $\textit{representation}$ from a sequence of tactile measurements that contains all the relevant information about the palpated object. We conjecture that such a representation can be used for downstream tasks such as tactile imaging and change detection. With enough training data, it should capture intricate patterns in the tactile measurements that go beyond a simple map of forces -- the current state of the art. To validate our approach, we both develop a simulation environment and collect a real-world dataset of soft objects and corresponding ground truth images obtained by magnetic resonance imaging (MRI). We collect palpation sequences using a robot equipped with a tactile sensor, and train a model that predicts sensory readings at different positions on the object. We investigate the representation learned in this process, and demonstrate its use in imaging and change detection.

</details>


### [73] [Stabilizing Policy Gradient Methods via Reward Profiling](https://arxiv.org/abs/2511.16629)
*Shihab Ahmed,El Houcine Bergou,Aritra Dutta,Yue Wang*

Main category: cs.LG

TL;DR: 本文提出了一个通用的奖励分析框架，可以无缝集成到任何策略梯度算法中，通过选择性地更新策略来提高性能，解决了策略梯度方法中梯度估计方差大导致性能不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 策略梯度方法在强化学习中表现出有效性，但其性能常因梯度估计的高方差导致奖励改进不可靠和收敛缓慢。

Method: 提出了一个通用的奖励分析框架，该框架可以无缝集成到任何策略梯度算法中，并基于高置信度性能估计选择性地更新策略。理论上证明了该技术不会减慢基线策略梯度方法的收敛速度，但会以高概率稳定且单调地改进其性能。

Result: 在八个连续控制基准测试（Box2D和MuJoCo/PyBullet）上，所提出的分析框架使收敛速度提高了1.5倍，在某些设置下，回报方差减少了1.75倍。

Conclusion: 该奖励分析方法为复杂环境中更可靠、高效的策略学习提供了一条通用且有理论基础的途径。

Abstract: Policy gradient methods, which have been extensively studied in the last decade, offer an effective and efficient framework for reinforcement learning problems. However, their performances can often be unsatisfactory, suffering from unreliable reward improvements and slow convergence, due to high variance in gradient estimations. In this paper, we propose a universal reward profiling framework that can be seamlessly integrated with any policy gradient algorithm, where we selectively update the policy based on high-confidence performance estimations. We theoretically justify that our technique will not slow down the convergence of the baseline policy gradient methods, but with high probability, will result in stable and monotonic improvements of their performance. Empirically, on eight continuous-control benchmarks (Box2D and MuJoCo/PyBullet), our profiling yields up to 1.5x faster convergence to near-optimal returns, up to 1.75x reduction in return variance on some setups. Our profiling approach offers a general, theoretically grounded path to more reliable and efficient policy learning in complex environments.

</details>


### [74] [Taming the Long-Tail: Efficient Reasoning RL Training with Adaptive Drafter](https://arxiv.org/abs/2511.16665)
*Qinghao Hu,Shang Yang,Junxian Guo,Xiaozhe Yao,Yujun Lin,Yuxian Gu,Han Cai,Chuang Gan,Ana Klimovic,Song Han*

Main category: cs.LG

TL;DR: TLT通过集成自适应推测解码来加速推理强化学习训练，在保持模型精度的同时，端到端训练速度提升了1.7倍以上。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理能力方面取得了显著进展，但其强化学习（RL）训练面临效率瓶颈，主要表现为响应生成中的长尾分布，导致资源浪费和成本增加。

Method: TLT系统包含两个主要组件：1）自适应草稿器（Adaptive Drafter），这是一个轻量级草稿模型，在空闲GPU上持续训练，以与目标模型保持一致；2）自适应Rollout引擎（Adaptive Rollout Engine），它维护一个预捕获的CUDAGraphs内存高效池，并为每个输入批次自适应选择合适的SD策略。

Result: TLT实现了端到端RL训练速度超过1.7倍的提升，同时保持了模型精度，并生成了一个高质量的草稿模型，可以免费用于高效部署。

Conclusion: TLT通过自适应推测解码有效地解决了推理LLMs在RL训练中的效率问题，显著加速了训练过程，同时保持了模型性能，并提供了实用的副产品。

Abstract: The emergence of Large Language Models (LLMs) with strong reasoning capabilities marks a significant milestone, unlocking new frontiers in complex problem-solving. However, training these reasoning models, typically using Reinforcement Learning (RL), encounters critical efficiency bottlenecks: response generation during RL training exhibits a persistent long-tail distribution, where a few very long responses dominate execution time, wasting resources and inflating costs. To address this, we propose TLT, a system that accelerates reasoning RL training losslessly by integrating adaptive speculative decoding. Applying speculative decoding in RL is challenging due to the dynamic workloads, evolving target model, and draft model training overhead. TLT overcomes these obstacles with two synergistic components: (1) Adaptive Drafter, a lightweight draft model trained continuously on idle GPUs during long-tail generation to maintain alignment with the target model at no extra cost; and (2) Adaptive Rollout Engine, which maintains a memory-efficient pool of pre-captured CUDAGraphs and adaptively select suitable SD strategies for each input batch. Evaluations demonstrate that TLT achieves over 1.7x end-to-end RL training speedup over state-of-the-art systems, preserves the model accuracy, and yields a high-quality draft model as a free byproduct suitable for efficient deployment. Code is released at https://github.com/mit-han-lab/fastrl.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [75] [How Modality Shapes Perception and Reasoning: A Study of Error Propagation in ARC-AGI](https://arxiv.org/abs/2511.15717)
*Bo Wen,Chen Wang,Erhan Bilal*

Main category: cs.AI

TL;DR: 这篇文章探讨了在ARC-AGI任务中，不同模态的输入编码如何影响模型的感知和泛化能力。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI 任务旨在衡量模型的泛化能力，但现有的模型尚不能很好地区分指令错误和执行错误。本文旨在探究不同模态编码形式对模型感知能力的影响。

Method: 作者通过使用加权集合差异度量和两阶段推理管道，分析了九种文本和图像模态的感知性能。

Result: 研究发现，结构化文本在稀疏特征上能提供精确的坐标，图像能捕捉2D形状但对分辨率敏感。结合文本和图像两种模态可以提高执行的准确性。

Conclusion: 通过使表示与 Transformer 的归纳偏置对齐，并实现文本和图像之间的交叉验证，可以在不改变底层模型的情况下，获得更准确的指令和更可靠的执行。

Abstract: ARC-AGI and ARC-AGI-2 measure generalization-through-composition on small color-quantized grids, and their prize competitions make progress on these harder held-out tasks a meaningful proxy for systematic generalization. Recent instruction-first systems translate grids into concise natural-language or DSL rules executed in generate-execute-select loops, yet we lack a principled account of how encodings shape model perception and how to separate instruction errors from execution errors. We hypothesize that modality imposes perceptual bottlenecks -- text flattens 2D structure into 1D tokens while images preserve layout but can introduce patch-size aliasing -- thereby shaping which grid features are reliably perceived. To test this, we isolate perception from reasoning across nine text and image modalities using a weighted set-disagreement metric and a two-stage reasoning pipeline, finding that structured text yields precise coordinates on sparse features, images capture 2D shapes yet are resolution-sensitive, and combining them improves execution (about 8 perception points; about 0.20 median similarity). Overall, aligning representations with transformer inductive biases and enabling cross-validation between text and image yields more accurate instructions and more reliable execution without changing the underlying model.

</details>


### [76] [Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization](https://arxiv.org/abs/2511.15714)
*Ariel Kamen,Yakov Kamen*

Main category: cs.AI

TL;DR: 该研究提出了一个使用大型语言模型（LLMs）进行非结构化文本分类的集成框架，显著提高了F1分数，并解决了单一模型的弱点。


<details>
  <summary>Details</summary>
Motivation: 解决单一LLM在非结构化文本分类中存在的弱点，如不一致性、幻觉、类别膨胀和错误分类，从而提高分类性能和鲁棒性。

Method: 该研究提出了一个集成大型语言模型（eLLM）框架，通过整合多个模型来解决单一系统的常见弱点。通过数学模型将集成过程形式化，并建立了聚合标准。在IAB分层分类法下，对8660个样本的人工标注语料库上的十个最先进的LLM进行了相同的零样本评估。

Result: eLLM方法在F1分数方面比最强的单一模型提高了65%。eLLM提高了鲁棒性和准确性，达到了接近人类专家的水平。

Conclusion: 集成大型语言模型（eLLM）框架为基于分类法的分类提供了一个可扩展且可靠的解决方案，显著减少了对人类专家标注的依赖。

Abstract: This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.

</details>


### [77] [Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems](https://arxiv.org/abs/2511.15715)
*Yash Raj Singh*

Main category: cs.AI

TL;DR: 本文提出了Graph-Memoized Reasoning框架，通过将推理工作流表示为图结构内存，实现对过去推理步骤的存储和重用，从而提高大型语言模型推理系统的效率和可复用性。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型推理系统在不同任务中重复计算相似的推理步骤，导致资源浪费、推理延迟增加和可复用性受限。

Method: 引入Graph-Memoized Reasoning框架，将推理工作流表示、存储和重用为图结构内存。通过结构和语义相似性编码和检索过去的决策图，实现新推理任务中子图的组合重用。

Result: 本文提出了一个优化目标，旨在最小化总推理成本，同时兼顾存储和生成工作流之间的一致性，为智能系统中的效率-一致性权衡提供了理论基础。并概述了与优化目标一致的概念性评估协议。

Conclusion: Graph-Memoized Reasoning框架为可解释、高成本效益和自改进的推理架构奠定了基础，是大型智能体系统中实现持久内存的关键一步。

Abstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.
  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.
  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.
  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.

</details>


### [78] [MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding](https://arxiv.org/abs/2511.15716)
*Abraham Itzhak Weinberg*

Main category: cs.AI

TL;DR: MACIE是一个多智能体因果智能解释器框架，旨在解决现有可解释AI方法在多智能体环境中面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用中使用多智能体强化学习系统时，理解智能体为何做出决策以及它们如何实现集体行为至关重要。

Method: MACIE结合了结构因果模型、干预反事实和Shapley值，以提供全面的解释。

Result: 实验结果表明，MACIE能够准确地进行结果归因（平均phi_i = 5.07，标准差 < 0.05），在合作任务中检测到积极的涌现（协同指数高达0.461），并且计算效率高（在CPU上每个数据集0.79秒）。

Conclusion: MACIE独特地结合了因果严谨性、涌现量化和多智能体支持，同时在实际应用中保持了实用性，这代表着向可解释、可信和负责任的多智能体AI迈出了一步。

Abstract: As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.

</details>


### [79] [Automated Hazard Detection in Construction Sites Using Large Language and Vision-Language Models](https://arxiv.org/abs/2511.15720)
*Islem Sahraoui*

Main category: cs.AI

TL;DR: 本文提出了一种多模态AI框架，通过结合文本和图像分析来提高建筑安全，旨在解决传统方法难以综合处理多格式事故数据的问题。


<details>
  <summary>Details</summary>
Motivation: 在建筑工地等安全关键环境中，事故数据通常以多种格式存在，如书面报告、检查记录和现场图像，这使得传统方法难以综合分析危害。

Method: 本文提出了一个多模态AI框架，结合文本和图像分析来识别建筑工地的安全隐患。通过两个案例研究评估了大型语言模型（LLMs）和视觉-语言模型（VLMs）在自动化危害识别方面的能力。第一个案例研究使用GPT 4o和GPT 4o mini从28,000份OSHA事故报告中提取结构化见解。第二个案例研究使用轻量级开源VLM Molmo 7B和Qwen2 VL 2B在ConstructionSite10k数据集上进行了规则级安全违规检测。

Result: GPT 4o和GPT 4o mini在从OSHA事故报告中提取结构化见解方面表现出色。Molmo 7B和Qwen2 VL 2B在某些提示配置下显示出与专有模型竞争的性能，验证了低资源多模态系统在规则感知安全监控中的可行性。

Conclusion: 所提出的多模态AI框架能有效提升建筑安全，轻量级开源VLM在规则感知安全监控方面具有潜力，为未来低资源多模态系统的发展提供了依据。

Abstract: This thesis explores a multimodal AI framework for enhancing construction safety through the combined analysis of textual and visual data. In safety-critical environments such as construction sites, accident data often exists in multiple formats, such as written reports, inspection records, and site imagery, making it challenging to synthesize hazards using traditional approaches. To address this, this thesis proposed a multimodal AI framework that combines text and image analysis to assist in identifying safety hazards on construction sites. Two case studies were consucted to evaluate the capabilities of large language models (LLMs) and vision-language models (VLMs) for automated hazard identification.The first case study introduces a hybrid pipeline that utilizes GPT 4o and GPT 4o mini to extract structured insights from a dataset of 28,000 OSHA accident reports (2000-2025). The second case study extends this investigation using Molmo 7B and Qwen2 VL 2B, lightweight, open-source VLMs. Using the public ConstructionSite10k dataset, the performance of the two models was evaluated on rule-level safety violation detection using natural language prompts. This experiment served as a cost-aware benchmark against proprietary models and allowed testing at scale with ground-truth labels. Despite their smaller size, Molmo 7B and Quen2 VL 2B showed competitive performance in certain prompt configurations, reinforcing the feasibility of low-resource multimodal systems for rule-aware safety monitoring.

</details>


### [80] [Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods](https://arxiv.org/abs/2511.15722)
*Weichen Liu,Qiyao Xue,Haoming Wang,Xiangyu Yin,Boyuan Yang,Wei Gao*

Main category: cs.AI

TL;DR: 这篇论文是关于多模态大型语言模型（MLLMs）中空间推理的综述。它提出了一种基于认知方面的新分类法，并按推理复杂性划分任务，旨在弥合当前模型能力与类人推理之间的差距。


<details>
  <summary>Details</summary>
Motivation: 空间推理是人类智能的一个基本方面，但对于多模态大型语言模型（MLLMs）来说仍然是一个持续的挑战。现有的调查通常根据输入模态对最新进展进行分类，但本文认为空间能力并非完全由输入格式决定。

Method: 本文引入了一种新的分类法，从认知角度组织空间智能，并根据推理复杂性划分任务，将其与几种认知功能联系起来。本文将现有基准（包括纯文本、视觉语言和具身设置）映射到这个分类法上，并回顾了评估空间推理能力的评价指标和方法。此外，本文还分析了提高空间能力的方法，包括基于训练和基于推理的方法。

Result: 这种认知视角使得更具原则性的跨任务比较成为可能，并揭示了当前模型能力与类人推理之间的关键差距。这种双重视角分析阐明了它们的各自优势，并揭示了互补机制。

Conclusion: 通过调查任务、基准和最新进展，本文旨在为新研究人员提供对该领域的全面理解和未来研究的可行方向。

Abstract: Spatial reasoning, which requires ability to perceive and manipulate spatial relationships in the 3D world, is a fundamental aspect of human intelligence, yet remains a persistent challenge for Multimodal large language models (MLLMs). While existing surveys often categorize recent progress based on input modality (e.g., text, image, video, or 3D), we argue that spatial ability is not solely determined by the input format. Instead, our survey introduces a taxonomy that organizes spatial intelligence from cognitive aspect and divides tasks in terms of reasoning complexity, linking them to several cognitive functions. We map existing benchmarks across text only, vision language, and embodied settings onto this taxonomy, and review evaluation metrics and methodologies for assessing spatial reasoning ability. This cognitive perspective enables more principled cross-task comparisons and reveals critical gaps between current model capabilities and human-like reasoning. In addition, we analyze methods for improving spatial ability, spanning both training-based and reasoning-based approaches. This dual perspective analysis clarifies their respective strengths, uncovers complementary mechanisms. By surveying tasks, benchmarks, and recent advances, we aim to provide new researchers with a comprehensive understanding of the field and actionable directions for future research.

</details>


### [81] [Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer](https://arxiv.org/abs/2511.15741)
*Hyo-Jeong Jang*

Main category: cs.AI

TL;DR: 该论文通过探索不确定性弹性多模态学习和一致性引导的跨模态传输来解决多模态学习系统中数据不确定性、低质量标签和异构模态特性等挑战。该框架通过跨模态语义一致性实现鲁棒表示学习，从而减轻模态差异并发现结构关系，以支持不确定性估计和稳定的特征学习。


<details>
  <summary>Details</summary>
Motivation: 多模态学习系统通常面临数据不确定性、低质量标签和异构模态特性带来的巨大不确定性。在人机交互环境中，数据质量、语义可靠性和注释一致性因用户和记录条件而异，这些问题变得尤为关键。

Method: 该文提出了一种通过一致性引导的跨模态传输来探索不确定性弹性多模态学习的方法。其核心思想是利用跨模态语义一致性作为鲁棒表示学习的基础。通过将异构模态投影到共享的潜在空间中，该框架减轻了模态差距并揭示了支持不确定性估计和稳定特征学习的结构关系。该文还研究了增强语义鲁棒性、提高数据效率以及减少噪声和不完美监督影响的策略，而无需依赖大量高质量的标注。

Result: 在多模态情感识别基准上的实验表明，一致性引导的跨模态传输显著提高了模型的稳定性、判别能力以及对噪声或不完整监督的鲁棒性。潜在空间分析进一步表明，即使在挑战性条件下，该框架也能捕获可靠的跨模态结构。

Conclusion: 该论文通过整合不确定性建模、语义对齐和数据高效监督，为弹性多模态学习提供了一个统一的视角，为开发可靠和自适应的脑机接口系统提供了实践见解。

Abstract: Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.

</details>


### [82] [Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response](https://arxiv.org/abs/2511.15755)
*Philip Drammeh*

Main category: cs.AI

TL;DR: MyAntFarm.ai 框架通过多智能体编排，相较于单智能体方法，显著提升了LLM驱动的事件响应质量，实现了100%可操作的推荐率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在加速生产系统事件响应方面具有潜力，但单一智能体方法产生的建议过于模糊，无法使用。

Method: 本文提出了MyAntFarm.ai，一个可重现的容器化框架，旨在通过348次受控试验比较单智能体副驾驶与多智能体系统在相同事件场景下的表现。同时引入了决策质量（DQ）这一新指标，以评估操作部署所需的有效性、特异性和正确性。

Result: 多智能体编排实现了100%可操作的推荐率，而单智能体方法仅为1.7%，在行动特异性方面提高了80倍，解决方案正确性方面提高了140倍。多智能体系统在所有试验中质量方差为零，而两种架构的理解延迟相似（约40秒）。

Conclusion: 多智能体编排对于基于LLM的事件响应而言，是实现生产就绪的必要条件。

Abstract: Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.

</details>


### [83] [Identifying the Supply Chain of AI for Trustworthiness and Risk Management in Critical Applications](https://arxiv.org/abs/2511.15763)
*Raymond K. Sheh,Karen Geappen*

Main category: cs.AI

TL;DR: 本文讨论了人工智能供应链风险，并提出了一个分类框架。


<details>
  <summary>Details</summary>
Motivation: 目前对AI风险的研究主要集中在算法偏差和模型幻觉等方面，而对于AI供应链风险的系统性评估存在空白，特别是在关键应用领域，这一空白带来了严重问题。

Method: 本文首先调查了当前AI风险评估和管理现状，重点关注AI供应链及AI系统行为和输出相关风险。然后，提出了一个AI供应链实体分类法。

Result: 本文提出的分类法可以帮助利益相关者（尤其是那些缺乏AI专业知识的人）提出“正确的问题”，并系统地清点组织AI系统中的依赖关系。

Conclusion: 本文弥补了当前AI治理与关键应用中AI风险评估和管理需求之间的差距，提供了可行的风险评估和管理方法。

Abstract: Risks associated with the use of AI, ranging from algorithmic bias to model hallucinations, have received much attention and extensive research across the AI community, from researchers to end-users. However, a gap exists in the systematic assessment of supply chain risks associated with the complex web of data sources, pre-trained models, agents, services, and other systems that contribute to the output of modern AI systems. This gap is particularly problematic when AI systems are used in critical applications, such as the food supply, healthcare, utilities, law, insurance, and transport.
  We survey the current state of AI risk assessment and management, with a focus on the supply chain of AI and risks relating to the behavior and outputs of the AI system. We then present a proposed taxonomy specifically for categorizing AI supply chain entities. This taxonomy helps stakeholders, especially those without extensive AI expertise, to "consider the right questions" and systematically inventory dependencies across their organization's AI systems. Our contribution bridges a gap between the current state of AI governance and the urgent need for actionable risk assessment and management of AI use in critical applications.

</details>


### [84] [Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights](https://arxiv.org/abs/2511.15778)
*Paulina Tworek,Miłosz Bargieł,Yousef Khan,Tomasz Pełech-Pilichowski,Marek Mikołajczyk,Roman Lewandowski,Jose Sousa*

Main category: cs.AI

TL;DR: 该研究比较了低计算量、基于规则的自然语言处理（NLP）方法与大型语言模型（LLMs）在从波兰儿童康复医院的电子健康记录（EHR）中提取医疗信息方面的表现。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健领域，特别是非英语环境中，从非结构化临床文本中提取结构化医疗见解仍然是一个开放的挑战。

Method: 本研究通过提取患者人口统计学信息、临床发现和处方药物来评估两种方法，并检查了文本非标准化和翻译导致的信息丢失效应。

Result: 结果表明，基于规则的方法在信息检索任务中提供更高的准确性，尤其是在年龄和性别提取方面。然而，LLMs 提供更大的适应性和可扩展性，在药物名称识别方面表现出色。还通过比较波兰语原文和翻译成英语的文本来评估翻译的影响。

Conclusion: 研究强调了在医疗保健环境中部署自然语言处理时，准确性、标准化和计算成本之间的权衡。本研究建议采用混合方法，将基于规则的系统的精度与LLMs的适应性相结合，为现实世界医院中更可靠、资源高效的临床自然语言处理提供了一条实用路径。

Abstract: Extracting structured medical insights from unstructured clinical text using Natural Language Processing (NLP) remains an open challenge in healthcare, particularly in non-English contexts where resources are scarce. This study presents a comparative analysis of NLP low-compute rule-based methods and Large Language Models (LLMs) for information extraction from electronic health records (EHR) obtained from the Voivodeship Rehabilitation Hospital for Children in Ameryka, Poland. We evaluate both approaches by extracting patient demographics, clinical findings, and prescribed medications while examining the effects of lack of text normalisation and translation-induced information loss. Results demonstrate that rule-based methods provide higher accuracy in information retrieval tasks, particularly for age and sex extraction. However, LLMs offer greater adaptability and scalability, excelling in drug name recognition. The effectiveness of the LLMs was compared with texts originally in Polish and those translated into English, assessing the impact of translation. These findings highlight the trade-offs between accuracy, normalisation, and computational cost when deploying NLP in healthcare settings. We argue for hybrid approaches that combine the precision of rule-based systems with the adaptability of LLMs, offering a practical path toward more reliable and resource-efficient clinical NLP in real-world hospitals.

</details>


### [85] [IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation](https://arxiv.org/abs/2511.15825)
*Tuan-Anh Le,Anh Mai Vu,David Yang,Akash Awasthi,Hien Van Nguyen*

Main category: cs.AI

TL;DR: IMACT-CXR是一个交互式多智能体对话导师，它通过统一空间标注、凝视分析、知识检索和图像接地推理来帮助学员解释胸部X光片。


<details>
  <summary>Details</summary>
Motivation: 此研究的动机是创建一个交互式、多智能体的对话导师，旨在通过整合多种先进技术，如空间标注、凝视分析、知识检索和图像接地推理，来提升学员解读胸部X光片的能力。

Method: IMACT-CXR系统通过AutoGen工作流，同时摄取学习者的边界框、凝视样本和自由文本观察。专门的智能体负责评估定位质量、生成苏格拉底式指导、检索PubMed证据、推荐REFLACX中的相似病例，并在掌握程度低或学习者明确要求时触发NV-Reason-CXR-3B进行视觉语言推理。系统采用贝叶斯知识追踪（BKT）来维护技能掌握程度的估计，并以此驱动知识强化和病例相似性检索。一个源自TensorFlow U-Net的肺叶分割模块提供解剖学上的凝视反馈，同时安全提示可防止过早泄露真实标签。

Result: IMACT-CXR展示了具有有界延迟的响应式辅导流程、对答案泄露的精确控制以及面向实际住院医师部署的可扩展性。初步评估显示，与基线相比，该系统在定位和诊断推理方面有所改进。

Conclusion: IMACT-CXR成功地将多种先进技术集成到一个统一的框架中，为胸部X光片解读提供了一个高效、交互式的培训工具。该系统在提高学员的定位和诊断推理能力方面表现出色，并具有在实际临床环境中广泛应用的潜力。

Abstract: IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.

</details>


### [86] [Mini Amusement Parks (MAPs): A Testbed for Modelling Business Decisions](https://arxiv.org/abs/2511.15830)
*Stéphane Aroca-Ouellette,Ian Berlot-Attwell,Panagiotis Lymperopoulos,Abhiramon Rajasekharan,Tongqi Zhu,Herin Kang,Kaheer Suleman,Sam Pasupalak*

Main category: cs.AI

TL;DR: 该论文介绍了Mini Amusement Parks (MAPs)，这是一个游乐园模拟器，旨在评估智能体对环境建模、不确定性下的长期后果预测以及复杂业务战略运营的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的AI系统在应对现实世界决策的相互关联挑战方面存在困难，包括优化开放式、多方面的目标，从稀疏经验中主动学习环境动态，在随机设置中进行长期规划，以及对空间信息进行推理。

Method: 通过引入一个名为Mini Amusement Parks (MAPs)的游乐园模拟器，该模拟器旨在评估智能体对环境进行建模、在不确定性下预测长期后果以及战略性运营复杂业务的能力。作者提供了人类基线，并对最先进的LLM智能体进行了全面评估。

Result: 人类在简单模式下比LLM智能体表现好6.5倍，在a中等模式下表现好9.8倍。分析揭示了LLM智能体在长期优化、样本高效学习、空间推理和世界建模方面的持续弱点。

Conclusion: MAPs为基准测试能够适应性决策的智能体提供了一个新基础，因为它将现实世界决策中的多个挑战统一在一个环境中。

Abstract: Despite rapid progress in artificial intelligence, current systems struggle with the interconnected challenges that define real-world decision making. Practical domains, such as business management, require optimizing an open-ended and multi-faceted objective, actively learning environment dynamics from sparse experience, planning over long horizons in stochastic settings, and reasoning over spatial information. Yet existing human--AI benchmarks isolate subsets of these capabilities, limiting our ability to assess holistic decision-making competence. We introduce Mini Amusement Parks (MAPs), an amusement-park simulator designed to evaluate an agent's ability to model its environment, anticipate long-term consequences under uncertainty, and strategically operate a complex business. We provide human baselines and a comprehensive evaluation of state-of-the-art LLM agents, finding that humans outperform these systems by 6.5x on easy mode and 9.8x on medium mode. Our analysis reveals persistent weaknesses in long-horizon optimization, sample-efficient learning, spatial reasoning, and world modelling. By unifying these challenges within a single environment, MAPs offers a new foundation for benchmarking agents capable of adaptable decision making. Code: https://github.com/Skyfall-Research/MAPs

</details>


### [87] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: Step-Audio-R1模型通过模态接地推理蒸馏（MGRD）框架，首次成功地为音频语言模型带来了推理能力，并在音频理解和推理基准测试中表现出色，超越了Gemini 2.5 Pro，并达到了Gemini 3 Pro的水平。


<details>
  <summary>Details</summary>
Motivation: 传统的音频语言模型在推理方面表现不佳，甚至在没有推理的情况下表现更好，这引发了一个问题：音频智能是否能从深思熟虑中受益？

Method: 提出了Step-Audio-R1模型和模态接地推理蒸馏（MGRD）框架。Step-Audio-R1学习生成与音频相关的推理链，这些推理链真正基于声学特征，而不是脱节的推断。

Result: Step-Audio-R1在语音、环境声音和音乐等全面的音频理解和推理基准测试中展现出强大的音频推理能力，超过了Gemini 2.5 Pro，并取得了与Gemini 3 Pro相当的性能。

Conclusion: 推理是一种可跨模态转移的能力，只要适当锚定，深思熟虑就能成为音频智能的强大资产。Step-Audio-R1的成功为构建真正多模态的推理系统开辟了新的途径。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [88] [Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs](https://arxiv.org/abs/2511.15895)
*Ivan Chulo,Ananya Joshi*

Main category: cs.AI

TL;DR: 通过对比激活值，我们发现激活引导（activation steering）能够提升语言模型（LLM）的心理理论（ToM）能力，这种提升主要通过增强对情感内容的加工而非分析性推理来实现。


<details>
  <summary>Details</summary>
Motivation: 此前的研究表明激活引导能显著提升语言模型的心理理论能力，但其内部机制尚不明确，即内部激活如何变化导致不同的输出。

Method: 本研究提出通过比较引导后的LLM与基线LLM的激活值来分解LLM中的心理理论，使用在线性探针上训练的45种认知动作。具体来说，我们对Gemma-3-4B模型应用了对比激活添加（CAA）引导，并在1000个BigToM前向信念场景上进行了评估。

Result: 结果显示，信念归因任务的性能有所提高（准确率从32.5%提升到46.7%），这种提升是由处理情感内容的激活所介导的，包括情绪感知（+2.23）和情绪评估（+2.20），同时抑制了分析过程，如质疑（-0.78）和聚合思维（-1.59）。

Conclusion: 这表明大语言模型中成功的心理理论能力是由情感理解而非分析性推理介导的。

Abstract: Recent work shows activation steering substantially improves language models' Theory of Mind (ToM) (Bortoletto et al. 2024), yet the mechanisms of what changes occur internally that leads to different outputs remains unclear. We propose decomposing ToM in LLMs by comparing steered versus baseline LLMs' activations using linear probes trained on 45 cognitive actions. We applied Contrastive Activation Addition (CAA) steering to Gemma-3-4B and evaluated it on 1,000 BigToM forward belief scenarios (Gandhi et al. 2023), we find improved performance on belief attribution tasks (32.5\% to 46.7\% accuracy) is mediated by activations processing emotional content : emotion perception (+2.23), emotion valuing (+2.20), while suppressing analytical processes: questioning (-0.78), convergent thinking (-1.59). This suggests that successful ToM abilities in LLMs are mediated by emotional understanding, not analytical reasoning.

</details>


### [89] [Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921)
*Chelsea Zou,Yiheng Yao,Basant Khalil*

Main category: cs.AI

TL;DR: 该项目开发了一个大型语言模型（LLM）的自我校正框架，用于在多步推理过程中检测和缓解幻觉。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM在多步推理中仅依赖最终答案的正确性，忽略了推理过程中的幻觉。本文旨在解决这一问题，通过引入细粒度的不确定性信号来实时检测和缓解不可靠的推理。

Method: 设计了一个复合奖励函数，该函数惩罚不合理的过高自信和熵峰值，同时鼓励稳定和准确的推理轨迹。这些信号引导强化学习（RL）策略，使模型更具自省性，并通过置信度感知的奖励反馈来塑造模型的生成行为。方法主要利用两种细粒度不确定性信号：1) 自我评估的置信度对齐，2) 令牌级别的熵峰值。

Result: 实验结果表明，该方法不仅提高了最终答案的准确性，还改善了推理校准。

Conclusion: 本研究通过引入自我校正框架和细粒度不确定性信号，有效提高了大型语言模型在多步推理中的准确性和校准性，显著减少了幻觉现象，并提升了中间推理步骤的连贯性和忠实性。

Abstract: This project develops a self correcting framework for large language models (LLMs) that detects and mitigates hallucinations during multi-step reasoning. Rather than relying solely on final answer correctness, our approach leverages fine grained uncertainty signals: 1) self-assessed confidence alignment, and 2) token-level entropy spikes to detect unreliable and unfaithful reasoning in real time. We design a composite reward function that penalizes unjustified high confidence and entropy spikes, while encouraging stable and accurate reasoning trajectories. These signals guide a reinforcement learning (RL) policy that makes the model more introspective and shapes the model's generation behavior through confidence-aware reward feedback, improving not just outcome correctness but the coherence and faithfulness of their intermediate reasoning steps. Experiments show that our method improves both final answer accuracy and reasoning calibration, with ablations validating the individual contribution of each signal.

</details>


### [90] [JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation](https://arxiv.org/abs/2511.15958)
*Zhenyu Bi,Gaurav Srivastava,Yang Li,Meng Lu,Swastik Roy,Morteza Ziyadi,Xuan Wang*

Main category: cs.AI

TL;DR: 本文介绍了JudgeBoard，一个新颖的评估流程，旨在直接查询模型以评估候选答案的正确性，而无需额外的答案比较。为了提高轻量级模型的判断性能，我们提出了MAJ（多智能体判断），一个新颖的多智能体评估框架，它利用多个具有不同推理特征的交互式SLM，通过协作审议来逼近LLM级别的判断准确性。


<details>
  <summary>Details</summary>
Motivation: 以前的LLM作为判断框架的工作通常依赖于使用预定义指标（如蕴涵）将候选答案与真实标签或其他候选答案进行比较。然而，这种方法本质上是间接的，难以完全自动化，为推理输出的细粒度和可伸缩评估提供了有限支持。

Method: 我们提出了JudgeBoard，一个新的评估流程，直接查询模型以评估候选答案的正确性，而无需额外的答案比较。我们专注于两个核心推理领域：数学推理和科学/常识推理，并使用准确性排名和基于Elo的评分系统在五个基准数据集上构建了特定任务的评估排行榜。为了提高轻量级模型中的判断性能，我们提出了MAJ（多智能体判断），一个新颖的多智能体评估框架，它利用多个具有不同推理特征的交互式SLM，通过协作审议来逼近LLM级别的判断准确性。

Result: 实验结果显示，在独立的判断任务中，SLM和LLM之间存在显著的性能差距。然而，我们的MAJ框架显著提高了SLM的可靠性和一致性。在MATH数据集上，使用较小尺寸模型作为主干的MAJ表现出与较大尺寸模型相当甚至更好的性能。

Conclusion: 多智能体SLM系统有可能在判断任务中达到或超过LLM的性能，这对于可伸缩和高效的评估具有重要意义。

Abstract: While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.

</details>


### [91] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 这篇文章探讨了大型语言模型（LLM）在临床环境中，即使提供了相关证据，也可能无法正确推理的问题，并提出了一个评估框架来衡量其推理的准确性、一致性和忠实性。


<details>
  <summary>Details</summary>
Motivation: 作者旨在解决大型语言模型在临床应用中，即使能获取正确证据，也无法保证正确推理的问题，尤其关注输出需要符合结构化协议的临床场景。

Method: 作者使用书面暴露疗法（WET）指南作为测试平台，评估模型对临床医生审查过的问题的反应。他们提出了一种评估框架来衡量推理的准确性、一致性和忠实性。

Result: 研究结果表明，即使提供了权威性的段落，错误依然存在。检索增强生成（RAG）可以限制输出，但安全的部署需要像评估检索一样严格地评估推理，这突显了其潜力与风险。

Conclusion: 大型语言模型在临床推理方面存在差距，即使有证据支持也可能出错。因此，需要一个严格的评估框架来确保其在临床环境中的安全部署，该框架应同等重视推理与检索。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [92] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: 该论文提出了SpellForger，一个允许玩家通过自然语言提示创建自定义法术的游戏，旨在提供个性化和创造力的独特体验。


<details>
  <summary>Details</summary>
Motivation: 传统的游戏中AI在动态内容生成方面的应用已经很普遍，但是将其作为核心玩法协同创作工具的潜力尚未被充分发掘。

Method: SpellForger系统利用一个经过监督训练的BERT模型来解释玩家的自然语言提示，将文本描述映射到预设的法术模板，并平衡其参数（伤害、消耗、效果），以确保游戏的竞争完整性。游戏在Unity引擎中开发，AI后端使用Python。

Result: 预期结果是交付一个功能原型，展示实时法术生成，并应用于引人入胜的游戏循环。在这个循环中，玩家的创造力是体验的核心，从而验证AI作为直接游戏机制的有效性。

Conclusion: 本研究旨在通过开发SpellForger游戏，探索AI在游戏核心玩法协同创作中的应用，使玩家能够通过自然语言提示创造个性化法术，从而提升游戏的个性化和创造性体验。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [93] [An Aligned Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size](https://arxiv.org/abs/2511.16045)
*Jorge A. Huertas,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新颖的约束规划（CP）模型，用于解决具有最小批次大小要求的串行批处理调度问题。该模型通过直接关注机器上同家族作业序列的关键对齐参数，避免了现有CP模型对虚拟批次集的依赖。


<details>
  <summary>Details</summary>
Motivation: 在处理不同家族的连续作业时，串行批处理调度通过将相似家族的作业分组并顺序处理来避免重复设置。尽管这种方法在调度中取得了巨大成功，但目前只有三种约束规划（CP）模型考虑了最小批次大小，这在半导体制造的离子注入等许多实际应用中是一个常见需求。现有CP模型依赖于预定义的虚拟批次集，这带来了维度灾难并增加了问题复杂性。

Method: 本文提出了一种新颖的约束规划（CP）模型，它不依赖于虚拟批次集。取而代之的是，该模型利用关键对齐参数，直接对机器上同家族作业的序列进行推理，从而得到一个更紧凑的公式。通过利用问题的结构，采用定制的搜索阶段和增强的约束传播器推理级别，进一步改进了该模型。

Result: 通过对近五千个实例进行广泛的计算实验，将所提出的模型与现有方法进行了比较，包括混合整数规划公式、禁忌搜索元启发式算法和CP方法。结果表明，在作业数量高达100个的中小型实例上，所提出的模型表现出优越性；在作业数量高达500个、家族数量10个、机器数量10台的大规模实例上，所提出的模型能够找到比现有方法好25%的解决方案。

Conclusion: 所提出的新颖约束规划（CP）模型在串行批处理调度问题中，尤其是在处理中小型实例时，显示出显著的优越性，并且在大规模实例上也能找到显著改进的解决方案，这表明其在实际应用中具有强大的潜力。

Abstract: In serial batch (s-batch) scheduling, jobs from similar families are grouped into batches and processed sequentially to avoid repetitive setups that are required when processing consecutive jobs of different families. Despite its large success in scheduling, only three Constraint Programming (CP) models have been proposed for this problem considering minimum batch sizes, which is a common requirement in many practical settings, including the ion implantation area in semiconductor manufacturing. These existing CP models rely on a predefined virtual set of possible batches that suffers from the curse of dimensionality and adds complexity to the problem. This paper proposes a novel CP model that does not rely on this virtual set. Instead, it uses key alignment parameters that allow it to reason directly on the sequences of same-family jobs scheduled on the machines, resulting in a more compact formulation. This new model is further improved by exploiting the problem's structure with tailored search phases and strengthened inference levels of the constraint propagators. The extensive computational experiments on nearly five thousand instances compare the proposed models against existing methods in the literature, including mixed-integer programming formulations, tabu search meta-heuristics, and CP approaches. The results demonstrate the superiority of the proposed models on small-to-medium instances with up to 100 jobs, and their ability to find solutions up to 25\% better than the ones produces by existing methods on large-scale instances with up to 500 jobs, 10 families, and 10 machines.

</details>


### [94] [Artificial Intelligence and Accounting Research: A Framework and Agenda](https://arxiv.org/abs/2511.16055)
*Theophanis C. Stratopoulos,Victor Xiaoqi Wang*

Main category: cs.AI

TL;DR: 这篇论文分析了生成式AI和大型语言模型对会计研究的影响，并提出了一个分类框架，以识别研究机会和提高会计研究人员的竞争力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI和大型语言模型正在深刻改变会计研究，为学者带来机遇和挑战。

Method: 本研究提出了一个AI-会计研究的分类框架，该框架基于研究重点（以会计为中心与以AI为中心）和方法论（基于AI的方法与传统方法）两个维度。作者将此框架应用于IJAIS特刊和领先会计期刊上发表的AI-会计研究论文，以s识别现有研究并发现研究机会。

Result: 分析表明，生成式AI和大型语言模型正在改变研究过程本身。虽然生成式AI使某些研究能力普及化，但它也加剧了竞争，对人类判断、创造力和理论深度等高阶贡献提出了更高的要求。

Conclusion: 会计研究人员需要重新定位并与其他领域合作，利用自身优势，并通过改革博士教育来培养比较优势和AI素养，以适应这些变化，从而在AI时代保持竞争力。

Abstract: Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing studies and identify research opportunities. Using this same framework, we analyze how accounting researchers can leverage their expertise through strategic positioning and collaboration, revealing where accounting scholars' strengths create the most value. We further examine how GenAI and LLMs transform the research process itself, comparing the capabilities of human researchers and AI agents across the entire research workflow. This analysis reveals that while GenAI democratizes certain research capabilities, it simultaneously intensifies competition by raising expectations for higher-order contributions where human judgment, creativity, and theoretical depth remain valuable. These shifts call for reforming doctoral education to cultivate comparative advantages while building AI fluency.

</details>


### [95] [A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management](https://arxiv.org/abs/2511.16075)
*Hrikshesh Kumar,Anika Garg,Anshul Gupta,Yashika Agarwal*

Main category: cs.AI

TL;DR: 该论文介绍了一种主动式云-边缘工作负载资源管理框架，通过结合CNN-LSTM模型进行时间序列预测，并将预测结果嵌入到基于多智能体深度强化学习的编排器中，从而实现更智能的长期任务调度决策。


<details>
  <summary>Details</summary>
Motivation: 传统的云-边缘工作负载资源管理过于被动，依赖静态阈值会导致资源过度开销或性能下降。因此，需要开发一种主动式的解决方案。

Method: 设计了一种混合架构：结合CNN-LSTM模型进行时间序列预测，并将预测结果直接嵌入到基于多智能体深度强化学习的编排器（DRL agent）的状态空间中，使得DRL agent能够“预见未来”并做出更好的长期决策。

Result: 测试结果表明，该系统优于传统方法，能够有效解决复杂决策和多目标权衡（如成本、速度和可靠性）等难题。

Conclusion: 通过将CNN-LSTM预测与多智能体DRL相结合，实现了主动式的云-边缘工作负载资源管理，使得系统能够更好地平衡资源节约和系统性能，从而避免被动应对问题。

Abstract: Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable

</details>


### [96] [Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints](https://arxiv.org/abs/2511.16139)
*Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao*

Main category: cs.AI

TL;DR: 该论文介绍了一种名为MR-RML的新型对齐框架，旨在解决大型语言模型在医疗实践中应用的局限性，通过整合医疗标准和创新的奖励模型学习，显著提高了模型在医疗基准测试中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在医疗实践中具有巨大潜力，但其在现实世界中的临床效用受到关键对齐挑战的限制：静态评估基准与动态临床认知需求脱节；难以适应不断演变的多源医疗标准；以及传统奖励模型无法捕捉细致、多维的医疗质量标准。

Method: 本文提出MR-RML（多维量规导向奖励模型学习）通过GPRC（几何投影参考约束）框架，将医疗标准整合到结构化的“维度-场景-学科”矩阵中，以指导数据生成和模型优化。MR-RML引入了三项核心创新：1）一个将领域标准嵌入到完整训练流程中的“维度-场景-学科”医疗标准系统；2）一个分解评估标准的多维奖励模型，将实时量规评分转变为内化奖励建模；3）几何投影参考约束，将医疗认知逻辑转换为数学正则化，使评分梯度与临床推理对齐，并支持合成数据驱动的训练。

Result: 通过在权威医疗基准Healthbench上进行广泛评估，该方法在基础LLM Qwen-32B上取得了显著的性能提升（在完整子集上提升45%，在困难子集上提升85%）。它在开源LLM中取得了最先进的水平，分数分别为62.7（完整子集）和44.7（困难子集），同时超越了大多数闭源模型的表现。

Conclusion: MR-RML框架通过创新的医疗标准整合和奖励模型学习机制，有效解决了LLMs在医疗领域应用的对齐挑战，显著提升了模型性能，并在开源和闭源模型中均展现出卓越的竞争力。

Abstract: The integration of large language models (LLMs) into medical practice holds transformative potential, yet their real-world clinical utility remains limited by critical alignment challenges: (1) a disconnect between static evaluation benchmarks and dynamic clinical cognitive needs, (2) difficulties in adapting to evolving, multi-source medical standards, and (3) the inability of conventional reward models to capture nuanced, multi-dimensional medical quality criteria. To address these gaps, we propose MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC (Geometric Projection Reference Constraints), a novel alignment framework that integrates medical standards into a structured "Dimensions-Scenarios-Disciplines" matrix to guide data generation and model optimization. MR-RML introduces three core innovations: (1) a "Dimensions-Scenarios-Disciplines" medical standard system that embeds domain standards into the full training pipeline; (2) an independent multi-dimensional reward model that decomposes evaluation criteria, shifting from real-time rubric-based scoring to internalized reward modeling for improved consistency and cost-efficiency; (3) geometric projection reference constraints that transform medical cognitive logic into mathematical regularization, aligning scoring gradients with clinical reasoning and enabling synthetic data-driven training. Through extensive evaluations on the authoritative medical benchmark Healthbench, our method yields substantial performance gains over the base LLM Qwen-32B (45% on the full subset and 85% on Hard subset, respectively). It achieves a SOTA among open-source LLMs with scores of 62.7 (full subset) and 44.7 (hard subset), while also outperforming the majority of closed-source models.

</details>


### [97] [FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos](https://arxiv.org/abs/2511.16183)
*Jeremie Ochin,Raphael Chekroun,Bogdan Stanciulescu,Sotiris Manitsaris*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个名为FOOTPASS的新数据集，旨在通过结合计算机视觉技术和足球战术知识，提高足球比赛事件的自动化识别和分析的可靠性。


<details>
  <summary>Details</summary>
Motivation: 足球视频理解领域需要更可靠的方法来自动化生成比赛事件数据。现有的动作识别方法不足以构建可靠的逐格比赛数据，通常只能辅助而不是完全自动化注释。

Method: 本研究提出了Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS)数据集。该数据集是第一个用于在多模态、多智能体战术背景下，对整个足球比赛进行逐格动作定位的基准。它结合了计算机视觉任务（如跟踪、识别）的输出和足球的先验知识，包括其在长时间范围内的战术规律，以生成可靠的逐格比赛数据流。

Result: FOOTPASS数据集为以球员为中心的动作定位方法提供了可能，这些方法能够利用计算机视觉输出和足球的先验战术知识，生成可靠的逐格比赛数据流。

Conclusion: Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS)的引入为足球比赛分析提供了一个新的基准，通过集成计算机视觉和战术知识，提高了生成逐格比赛数据的自动化和可靠性，从而为数据驱动的体育分析奠定基础。

Abstract: Soccer video understanding has motivated the creation of datasets for tasks such as temporal action localization, spatiotemporal action detection (STAD), or multiobject tracking (MOT). The annotation of structured sequences of events (who does what, when, and where) used for soccer analytics requires a holistic approach that integrates both STAD and MOT. However, current action recognition methods remain insufficient for constructing reliable play-by-play data and are typically used to assist rather than fully automate annotation. Parallel research has advanced tactical modeling, trajectory forecasting, and performance analysis, all grounded in game-state and play-by-play data. This motivates leveraging tactical knowledge as a prior to support computer-vision-based predictions, enabling more automated and reliable extraction of play-by-play data. We introduce Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS), the first benchmark for play-by-play action spotting over entire soccer matches in a multi-modal, multi-agent tactical context. It enables the development of methods for player-centric action spotting that exploit both outputs from computer-vision tasks (e.g., tracking, identification) and prior knowledge of soccer, including its tactical regularities over long time horizons, to generate reliable play-by-play data streams. These streams form an essential input for data-driven sports analytics.

</details>


### [98] [From Performance to Understanding: A Vision for Explainable Automated Algorithm Design](https://arxiv.org/abs/2511.16201)
*Niki van Stein,Anna V. Kononova,Thomas Bäck*

Main category: cs.AI

TL;DR: 该文章认为，自动化算法设计领域在大型语言模型（LLM）的推动下进展迅速，但这种进展缺乏可解释性。作者提出，未来的突破将来自于将自动化与系统基准测试相结合，旨在实现可解释的自动化算法设计。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在自动化算法设计方面的进展过于注重性能，而忽视了算法工作原理、关键组成部分及其与问题结构的关系，导致过程不透明。

Method: 本文提出了可解释的自动化算法设计的三个支柱：1.大型语言模型驱动的算法变体发现；2.将性能归因于组件和超参数的可解释基准测试；3.连接算法行为和问题景观结构的“问题类别描述符”。

Result: 这些要素共同形成了一个闭合的知识循环，其中包含发现、解释和泛化，这些要素相互加强。

Conclusion: 通过整合这些方法，将使该领域从盲目搜索转向可解释的、特定于类别的算法设计，从而在加速进展的同时，为优化策略何时以及为何成功提供可重用的科学见解。

Abstract: Automated algorithm design is entering a new phase: Large Language Models can now generate full optimisation (meta)heuristics, explore vast design spaces and adapt through iterative feedback. Yet this rapid progress is largely performance-driven and opaque. Current LLM-based approaches rarely reveal why a generated algorithm works, which components matter or how design choices relate to underlying problem structures. This paper argues that the next breakthrough will come not from more automation, but from coupling automation with understanding from systematic benchmarking. We outline a vision for explainable automated algorithm design, built on three pillars: (i) LLM-driven discovery of algorithmic variants, (ii) explainable benchmarking that attributes performance to components and hyperparameters and (iii) problem-class descriptors that connect algorithm behaviour to landscape structure. Together, these elements form a closed knowledge loop in which discovery, explanation and generalisation reinforce each other. We argue that this integration will shift the field from blind search to interpretable, class-specific algorithm design, accelerating progress while producing reusable scientific insight into when and why optimisation strategies succeed.

</details>


### [99] [Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning](https://arxiv.org/abs/2511.16202)
*Pei Yang,Ke Zhang,Ji Wang,Xiao Chen,Yuxin Tang,Eric Yang,Lynn Ai,Bill Shi*

Main category: cs.AI

TL;DR: 该论文提出了CRM（多智能体协作奖励模型）框架，用一个由专业评估者组成的协调团队取代单一的黑盒奖励模型，以提高RLHF中的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的奖励模型难以联合优化多个（有时相互冲突的）偏好维度（例如，事实性、帮助性、安全性），并且对分数分配的原因提供的透明度有限。

Method: CRM将偏好评估任务分解为领域特定的智能体，每个智能体生成部分信号，并结合全局评估器（如基于排序器和嵌入相似度的奖励）。一个集中的聚合器在每个时间步融合这些信号，平衡逐步正确性、多智能体协议和重复惩罚等因素，生成与标准RL管道兼容的单一训练奖励。策略通过基于优势的更新进行优化，同时价值模型回归到聚合奖励，从而实现在不需要额外人类标注的情况下进行多视角奖励塑造。

Result: CRM和rewardBench提供了一种实用、模块化的路径，以实现更透明的奖励建模和更稳定的优化。

Conclusion: CRM（多智能体协作奖励模型）框架通过引入多智能体协作评估和集中的信号聚合，解决了传统奖励模型在优化多个偏好维度和透明度方面的局限性，提供了一种更鲁棒和可解释的RLHF奖励建模方法。

Abstract: We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.

</details>


### [100] [ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025](https://arxiv.org/abs/2511.16205)
*Xu Qiang,Shengyuan Bai,Leqing Chen,Zijing Liu,Yu Li*

Main category: cs.AI

TL;DR: ChemO是一个新的化学奥林匹克竞赛基准，旨在解决AI在化学领域多模态推理的挑战。它通过AER和SVE创新性地评估AI的化学问题解决能力，并引入了多智能体框架ChemLabs以模拟人类专家协作。


<details>
  <summary>Details</summary>
Motivation: 数学和物理领域的奥林匹克水平基准测试是评估高级AI推理能力的关键，但化学领域由于其独特的多模态符号语言，仍然是一个开放的挑战。

Method: 1. 建立了ChemO基准测试，该基准测试基于2025年国际化学奥林匹克竞赛（IChO）。
2. 引入了两种自动化评估的关键创新：评估等效重构（AER），将需要视觉输出（例如，绘制分子）的问题转换为计算上易于处理的格式；结构化视觉增强（SVE），一种诊断机制，用于将模型的视觉感知能力与其核心化学推理能力分离。
3. 提出了ChemLabs，一个分层的多智能体框架，通过专门的智能体（用于问题分解、感知、推理和审计）模拟人类专家的协作来解决此基准。

Result: 1. 结合SVE和多智能体系统在最先进的多模态模型上取得了显著的性能提升。
2. 最佳配置达到了93.6/100的分数，超过了人类金牌的估计门槛，并在自动化化学问题解决方面建立了新的SOTA。

Conclusion: ChemO基准和ChemLabs多智能体框架的引入，显著提升了AI在化学领域，特别是复杂多模态化学问题解决方面的能力，为AI在科学推理领域的发展开辟了新途径。

Abstract: Olympiad-level benchmarks in mathematics and physics are crucial testbeds for advanced AI reasoning, but chemistry, with its unique multimodal symbolic language, has remained an open challenge. We introduce ChemO, a new benchmark built from the International Chemistry Olympiad (IChO) 2025. ChemO features two key innovations for automated assessment: Assessment-Equivalent Reformulation (AER), which converts problems requiring visual outputs (e.g., drawing molecules) into computationally tractable formats, and Structured Visual Enhancement (SVE), a diagnostic mechanism to disentangle a model's visual perception capabilities from its core chemical reasoning. To tackle this benchmark, we propose ChemLabs, a hierarchical multi-agent framework that mimics human expert collaboration through specialized agents for problem decomposition, perception, reasoning, and auditing. Experiments on state-of-the-art multimodal models demonstrate that combining SVE with our multi-agent system yields dramatic performance gains. Our top configuration achieves a score of 93.6 out of 100, surpassing an estimated human gold medal threshold and establishing a new state-of-the-art in automated chemical problem-solving. ChemO Dataset: https://huggingface.co/datasets/IDEA-AI4SCI/ChemO

</details>


### [101] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: OpenMMReasoner是一个用于多模态推理的两阶段训练框架，包括SFT和RL。它通过高质量的数据集和训练设计，在多个基准测试中超越了现有基线。


<details>
  <summary>Details</summary>
Motivation: 尽管在视觉推理方面取得了显著进展，但透明和可复现的数据整理和训练策略的缺失仍然是可扩展研究的主要障碍。

Method: OpenMMReasoner采用两阶段训练方法：首先构建一个874K样本的冷启动数据集进行有监督微调（SFT），然后利用一个74K样本的跨域数据集进行强化学习（RL），以进一步提升和稳定模型的推理能力。

Result: OpenMMReasoner在九个多模态推理基准测试中，比Qwen2.5-VL-7B-Instruct基线提高了11.6%，证明了数据质量和训练设计在多模态推理性能中的关键作用。

Conclusion: OpenMMReasoner提供了一个透明且可复现的多模态推理训练框架，通过高质量的数据集和两阶段训练策略，显著提升了多模态推理模型的性能，为未来的大型多模态推理研究奠定了坚实的经验基础。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [102] [FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks](https://arxiv.org/abs/2511.16216)
*Zhen Hao Wong,Jingwen Deng,Hao Liang,Runming He,Chengyu Shen,Wentao Zhang*

Main category: cs.AI

TL;DR: 该论文提出了一种从教育文档中提取高质量问答对（QA）和视觉问答对（VQA）的自动化流程，以解决大型语言模型（LLMs）对高质量监督数据日益增长的需求。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的发展越来越依赖于高质量的监督数据，然而现有的指令调优和强化学习数据集构建成本高昂，且通常依赖于合成样本，这带来了幻觉和多样性限制。教科书和练习材料中蕴含丰富的、高质量的人工创作问答内容，但由于难以将原始PDF转换为AI可用的监督数据，这些资源未被充分利用。

Method: 本文提出了一种自动化流程，通过结合布局感知的OCR与基于LLM的语义解析，从教育文档中提取格式良好的问答对（QA）和视觉问答对（VQA）。

Result: 在不同类型的文档上的实验表明，该方法能够生成准确、对齐且低噪声的QA/VQA对。

Conclusion: 这种方法使得真实世界的教育内容可以规模化利用，并为改进面向推理的LLM训练提供了一种实用的替代方案，以应对合成数据生成的问题。所有代码和数据处理流程都已开源。

Abstract: The development of Large Language Models (LLMs) increasingly depends on high-quality supervised data, yet existing instruction-tuning and RL datasets remain costly to curate and often rely on synthetic samples that introduce hallucination and limited diversity. At the same time, textbooks and exercise materials contain abundant, high-quality human-authored Question-Answer(QA) content that remains underexploited due to the difficulty of transforming raw PDFs into AI-ready supervision. Although modern OCR and vision-language models can accurately parse document structure, their outputs lack the semantic alignment required for training. We propose an automated pipeline that extracts well-formed QA and visual-QA (VQA) pairs from educational documents by combining layout-aware OCR with LLM-based semantic parsing. Experiments across diverse document types show that the method produces accurate, aligned, and low-noise QA/VQA pairs. This approach enables scalable use of real-world educational content and provides a practical alternative to synthetic data generation for improving reasoning-oriented LLM training. All code and data-processing pipelines are open-sourced at https://github.com/OpenDCAI/DataFlow.

</details>


### [103] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为TOFA的训练无关单次联邦适应框架，用于在联邦学习设置下高效、轻量级地适应预训练的视觉-语言模型（VLMs），解决了现有方法通信成本高、易受攻击以及未充分利用多模态信息等问题。


<details>
  <summary>Details</summary>
Motivation: 开发一种轻量级的一次性联邦VLM适应方法，以解决现有迭代训练算法带来的高通信成本和易受攻击性，同时解决当前一次性方法在联邦设置下适应VLM时面临的挑战：未能充分利用VLM中丰富的多模态信息；缺乏专门的适应策略来系统地处理严重的数据异构性；以及需要额外的客户端或服务器训练资源。

Method: TOFA框架包含视觉和文本两条管道来提取与任务相关的表示。视觉管道使用分层贝叶斯模型学习个性化的、类别特定的原型分布。文本管道评估并全局对齐生成的局部文本提示以增强鲁棒性。此外，还引入了自适应权重校准机制来结合两种模态的预测，以平衡个性化和鲁棒性，从而处理数据异构性。该方法无需在客户端或服务器端进行额外训练。

Result: 在9个数据集上进行的广泛实验证明了所提出的TOFA方法的有效性。

Conclusion: TOFA提供了一种无需训练的一次性联邦适应框架，有效地解决了现有联邦VLM适应方法的局限性，特别是在处理数据异构性、利用多模态信息和降低通信及计算成本方面表现出色。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [104] [D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies](https://arxiv.org/abs/2511.16590)
*Sen Chen,Tong Zhao,Yi Bin,Fei Ma,Wenqi Shao,Zheng Wang*

Main category: cs.AI

TL;DR: 本文提出了D-GARA，一个动态基准框架，用于评估安卓图形用户界面（GUI）智能体在真实世界异常情况下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有用于训练和评估GUI智能体的大多数数据集和基准都是静态和理想化的，未能反映真实世界环境的复杂性和不可预测性，特别是异常情况的存在。

Method: 本文提出了一个动态基准测试框架D-GARA，用以评估安卓GUI智能体在真实世界异常下的鲁棒性。D-GARA引入了GUI智能体在实践中常面临的各类真实世界异常，包括权限弹窗、电量警告和更新提示等中断。基于D-GARA框架，本文构建并标注了一个包含常用安卓应用和嵌入式异常的基准，以支持更广泛的社区研究。

Result: 综合实验结果表明，在异常丰富的环境中，最先进的GUI智能体性能会大幅下降，这突出表明了鲁棒性感知学习的必要性。

Conclusion: D-GARA是模块化和可扩展的，支持无缝集成新任务、异常类型和交互场景，以满足特定的评估目标。

Abstract: Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a diverse set of real-world anomalies that GUI agents commonly face in practice, including interruptions such as permission dialogs, battery warnings, and update prompts. Based on D-GARA framework, we construct and annotate a benchmark featuring commonly used Android applications with embedded anomalies to support broader community research. Comprehensive experiments and results demonstrate substantial performance degradation in state-of-the-art GUI agents when exposed to anomaly-rich environments, highlighting the need for robustness-aware learning. D-GARA is modular and extensible, supporting the seamless integration of new tasks, anomaly types, and interaction scenarios to meet specific evaluation goals.

</details>


### [105] [MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering](https://arxiv.org/abs/2511.16283)
*Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang*

Main category: cs.AI

TL;DR: 介绍了MuISQA基准，用于评估RAG系统在子问题上的异构证据覆盖率，并提出了一种意图感知检索框架，以提高检索准确性和证据覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成（RAG）系统通常是单意图导向的，导致证据覆盖不完整，无法有效处理涉及多个意图的复杂科学问题。

Method: 提出了一种意图感知检索框架，该框架利用大型语言模型（LLMs）来假设潜在答案，将其分解为意图特定的查询，并为每个潜在意图检索支持性段落。检索到的片段通过倒数排序融合（RRF）进行聚合和重新排序，以平衡不同意图的覆盖范围，同时减少冗余。

Result: 在MuISQA基准测试和其他通用RAG数据集上的实验表明，该方法始终优于传统方法，尤其是在检索准确性和证据覆盖率方面。

Conclusion: 所提出的意图感知检索框架通过有效处理多意图科学问题，显著提高了RAG系统的检索准确性和证据覆盖率。

Abstract: Complex scientific questions often entail multiple intents, such as identifying gene mutations and linking them to related diseases. These tasks require evidence from diverse sources and multi-hop reasoning, while conventional retrieval-augmented generation (RAG) systems are usually single-intent oriented, leading to incomplete evidence coverage. To assess this limitation, we introduce the Multi-Intent Scientific Question Answering (MuISQA) benchmark, which is designed to evaluate RAG systems on heterogeneous evidence coverage across sub-questions. In addition, we propose an intent-aware retrieval framework that leverages large language models (LLMs) to hypothesize potential answers, decompose them into intent-specific queries, and retrieve supporting passages for each underlying intent. The retrieved fragments are then aggregated and re-ranked via Reciprocal Rank Fusion (RRF) to balance coverage across diverse intents while reducing redundancy. Experiments on both MuISQA benchmark and other general RAG datasets demonstrate that our method consistently outperforms conventional approaches, particularly in retrieval accuracy and evidence coverage.

</details>


### [106] [Reducing Instability in Synthetic Data Evaluation with a Super-Metric in MalDataGen](https://arxiv.org/abs/2511.16373)
*Anna Luiza Gomes da Silva,Diego Kreutz,Angelo Diniz,Rodrigo Mansilha,Celso Nobre da Fonseca*

Main category: cs.AI

TL;DR: 该论文介绍了一种评估Android恶意软件领域合成数据质量的Super-Metric，它整合了八个指标，解决了现有指标不稳定和缺乏标准化的挑战。


<details>
  <summary>Details</summary>
Motivation: 在Android恶意软件领域中，合成数据质量评估面临现有指标不稳定和缺乏标准化的挑战。

Method: 将八个指标整合到一个Super-Metric中，这些指标涵盖了四个保真度维度，生成一个单一的加权分数。

Result: 实验证明，Super-Metric比传统指标更稳定和一致，并且与分类器的实际性能有更强的相关性。

Conclusion: Super-Metric能够更有效地评估Android恶意软件合成数据的质量，为模型选择和性能提升提供了有价值的工具。

Abstract: Evaluating the quality of synthetic data remains a persistent challenge in the Android malware domain due to instability and the lack of standardization among existing metrics. This work integrates into MalDataGen a Super-Metric that aggregates eight metrics across four fidelity dimensions, producing a single weighted score. Experiments involving ten generative models and five balanced datasets demonstrate that the Super-Metric is more stable and consistent than traditional metrics, exhibiting stronger correlations with the actual performance of classifiers.

</details>


### [107] [Trustworthy AI in the Agentic Lakehouse: from Concurrency to Governance](https://arxiv.org/abs/2511.16402)
*Jacopo Tagliabue,Federico Bianchi,Ciro Greco*

Main category: cs.AI

TL;DR: 这篇论文提出了一种名为Bauplan的以Agent为中心的设计，旨在通过重新实现数据和计算隔离，解决传统数据湖不适用于Agent访问模式的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管AI能力不断提升，但大多数企业认为Agent在处理生产数据时不够值得信任。论文认为，要实现可信的Agent工作流，首先需要解决基础设施问题，即传统数据湖不适合Agent的访问模式。

Method: 论文将数据库中的MVCC操作类比到数据湖，并解释了直接移植在解耦、多语言环境中失败的原因。随后，提出了一种名为Bauplan的以Agent为中心（Agent-first）的设计，它在数据湖中重新实现了数据和计算隔离。

Result: 论文设计了一个名为Bauplan的Agent优先的数据湖架构，该架构通过重新实现数据和计算隔离来解决现有数据湖不适合Agent访问模式的问题。此外，文中还分享了一个在Bauplan中实现自我修复（self-healing）数据管道的参考实现。

Conclusion: Bauplan设计成功地将Agent推理与正确性和信任所需的所有保证无缝结合，为构建可信的Agent工作流奠定了基础。

Abstract: Even as AI capabilities improve, most enterprises do not consider agents trustworthy enough to work on production data. In this paper, we argue that the path to trustworthy agentic workflows begins with solving the infrastructure problem first: traditional lakehouses are not suited for agent access patterns, but if we design one around transactions, governance follows. In particular, we draw an operational analogy to MVCC in databases and show why a direct transplant fails in a decoupled, multi-language setting. We then propose an agent-first design, Bauplan, that reimplements data and compute isolation in the lakehouse. We conclude by sharing a reference implementation of a self-healing pipeline in Bauplan, which seamlessly couples agent reasoning with all the desired guarantees for correctness and trust.

</details>


### [108] [Pharos-ESG: A Framework for Multimodal Parsing, Contextual Narration, and Hierarchical Labeling of ESG Report](https://arxiv.org/abs/2511.16417)
*Yan Chen,Yu Zou,Jialei Zeng,Haoran You,Xiaorui Zhou,Aixi Zhong*

Main category: cs.AI

TL;DR: Pharos-ESG是一个统一框架，通过多模态解析、上下文叙述和分层标注，将ESG报告转化为结构化表示，以解决其在理解上的挑战。同时发布了Aurora-ESG数据集。


<details>
  <summary>Details</summary>
Motivation: ESG报告作为评估企业ESG表现的核心媒介，由于其混乱的阅读顺序、不规则的布局和冗长、结构薄弱的内容，给大规模理解带来了巨大挑战。

Method: Pharos-ESG集成了基于布局流的阅读顺序建模模块、目录锚点引导的分层分割以及将视觉元素上下文转换为连贯自然语言的多模态聚合管道。该框架通过ESG、GRI和情感标签进一步丰富其输出。

Result: Pharos-ESG在带注释的基准测试中始终优于专用文档解析系统和通用多模态模型。此外，还发布了Aurora-ESG，这是第一个大规模的ESG报告公共数据集。

Conclusion: Pharos-ESG框架有效地解决了ESG报告理解的挑战，并通过Aurora-ESG数据集为ESG在金融治理和决策中的整合提供了有力支持。

Abstract: Environmental, Social, and Governance (ESG) principles are reshaping the foundations of global financial gover- nance, transforming capital allocation architectures, regu- latory frameworks, and systemic risk coordination mecha- nisms. However, as the core medium for assessing corpo- rate ESG performance, the ESG reports present significant challenges for large-scale understanding, due to chaotic read- ing order from slide-like irregular layouts and implicit hier- archies arising from lengthy, weakly structured content. To address these challenges, we propose Pharos-ESG, a uni- fied framework that transforms ESG reports into structured representations through multimodal parsing, contextual nar- ration, and hierarchical labeling. It integrates a reading-order modeling module based on layout flow, hierarchy-aware seg- mentation guided by table-of-contents anchors, and a multi- modal aggregation pipeline that contextually transforms vi- sual elements into coherent natural language. The framework further enriches its outputs with ESG, GRI, and sentiment labels, yielding annotations aligned with the analytical de- mands of financial research. Extensive experiments on anno- tated benchmarks demonstrate that Pharos-ESG consistently outperforms both dedicated document parsing systems and general-purpose multimodal models. In addition, we release Aurora-ESG, the first large-scale public dataset of ESG re- ports, spanning Mainland China, Hong Kong, and U.S. mar- kets, featuring unified structured representations of multi- modal content, enriched with fine-grained layout and seman- tic annotations to better support ESG integration in financial governance and decision-making.

</details>


### [109] [From generative AI to the brain: five takeaways](https://arxiv.org/abs/2511.16432)
*Claudius Gros*

Main category: cs.AI

TL;DR: 生成式人工智能的巨大进步源于明确的生成原则。我们认为，有必要彻底调查哪些生成原则可能在大脑中起作用，并因此与认知神经科学相关。此外，机器学习研究还对神经信息处理系统进行了一系列有趣的表征。我们讨论了五个例子，包括世界建模的缺点、思维过程的生成、注意力、神经尺度定律和量化，这些例子说明了神经科学可以从机器学习研究中学到多少东西。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能的巨大进步是基于明确的生成原则，而不是晦涩难懂的算法。这些原则在大量应用中得到了验证。因此，有必要深入研究哪些生成原则可能在大脑中发挥作用，从而与认知神经科学相关。

Method: 本文通过讨论五个具体例子来阐述神经科学可以从机器学习研究中学到的内容，包括世界建模的缺点、思维过程的生成、注意力、神经尺度定律和量化。

Result: 机器学习研究提供了一系列有趣的神经信息处理系统表征。通过讨论五个例子，说明了神经科学可以从机器学习研究中获得启发。

Conclusion: 生成式人工智能的成功经验为认知神经科学研究大脑的生成原则提供了新的视角。机器学习研究对神经信息处理系统的理解，可以为神经科学带来重要的启示和借鉴。

Abstract: The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.

</details>


### [110] [PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring](https://arxiv.org/abs/2511.16445)
*Joy Lai,Alex Mihailidis*

Main category: cs.AI

TL;DR: PersonaDrift是一个用于评估机器学习和统计方法在检测痴呆症患者日常沟通中渐进性变化的合成基准。


<details>
  <summary>Details</summary>
Motivation: 开发PersonaDrift旨在跟踪痴呆症患者沟通行为随时间的变化，现有计算工具未专门用于此目的。

Method: PersonaDrift通过对真实痴呆症患者的模拟，创建了为期60天的交互日志。这些模拟基于对护理人员的访谈，并且在语气、模式和沟通习惯上具有多样性。基准侧重于两种主要的纵向变化：情感平淡（情感表达减少）和离题回复（语义漂移），并以不同的速率注入这些变化。研究者评估了多种异常检测方法，包括无监督统计方法（CUSUM, EWMA, One-Class SVM）、使用上下文嵌入的序列模型（GRU + BERT）以及通用和个性化设置下的监督分类器。

Result: 初步结果显示，情感平淡在基线变异性较低的用户中可以通过简单的统计模型检测。而语义漂移的检测则需要时间建模和个性化基线。在两项任务中，个性化分类器均优于通用分类器。

Conclusion: PersonaDrift基准能够有效评估自然语言处理模型在检测痴呆症患者沟通行为渐进性变化方面的能力，并强调了个性化模型在这一领域的优越性。这表明，针对个体行为背景的个性化方法对于准确检测痴呆症患者的沟通变化至关重要。

Abstract: People living with dementia (PLwD) often show gradual shifts in how they communicate, becoming less expressive, more repetitive, or drifting off-topic in subtle ways. While caregivers may notice these changes informally, most computational tools are not designed to track such behavioral drift over time. This paper introduces PersonaDrift, a synthetic benchmark designed to evaluate machine learning and statistical methods for detecting progressive changes in daily communication, focusing on user responses to a digital reminder system. PersonaDrift simulates 60-day interaction logs for synthetic users modeled after real PLwD, based on interviews with caregivers. These caregiver-informed personas vary in tone, modality, and communication habits, enabling realistic diversity in behavior. The benchmark focuses on two forms of longitudinal change that caregivers highlighted as particularly salient: flattened sentiment (reduced emotional tone and verbosity) and off-topic replies (semantic drift). These changes are injected progressively at different rates to emulate naturalistic cognitive trajectories, and the framework is designed to be extensible to additional behaviors in future use cases. To explore this novel application space, we evaluate several anomaly detection approaches, unsupervised statistical methods (CUSUM, EWMA, One-Class SVM), sequence models using contextual embeddings (GRU + BERT), and supervised classifiers in both generalized and personalized settings. Preliminary results show that flattened sentiment can often be detected with simple statistical models in users with low baseline variability, while detecting semantic drift requires temporal modeling and personalized baselines. Across both tasks, personalized classifiers consistently outperform generalized ones, highlighting the importance of individual behavioral context.

</details>


### [111] [Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes](https://arxiv.org/abs/2511.16548)
*Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang*

Main category: cs.AI

TL;DR: CLOZE是一个利用大型语言模型从临床笔记中提取和整合医学实体到分层医学本体的新框架，具有高准确性、可扩展性和保护隐私的特点，无需额外训练，零样本学习。


<details>
  <summary>Details</summary>
Motivation: 将新的医学概念和关系整合到现有本体中，可以显著增强其在生物医学研究和临床应用中的覆盖范围和实用性。临床笔记作为非结构化文档，富含详细的患者观察数据，提供了有价值的特定语境洞察力，是本体扩展的一个有前景但未充分利用的来源。然而，直接利用临床笔记进行本体扩展在很大程度上仍未被探索。

Method: CLOZE框架利用大型语言模型（LLMs）自动从临床笔记中提取医学实体，并将其整合到分层医学本体中。该框架利用预训练LLMs强大的语言理解能力和广泛的生物医学知识，有效识别疾病相关概念并捕获复杂的分层关系。它是一个零样本框架，不需要额外的训练或标记数据。此外，CLOZE通过自动移除受保护健康信息（PHI）来确保患者隐私。

Result: 实验结果表明，CLOZE提供了一个准确、可扩展且保护隐私的本体扩展框架。

Conclusion: CLOZE框架在支持生物医学研究和临床信息学中的广泛下游应用方面具有巨大潜力。

Abstract: Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.

</details>


### [112] [Consciousness in Artificial Intelligence? A Framework for Classifying Objections and Constraints](https://arxiv.org/abs/2511.16582)
*Andres Campero,Derek Shiller,Jaan Aru,Jonathan Simon*

Main category: cs.AI

TL;DR: 该框架旨在对数字人工智能系统中意识存在的挑战进行分类和辨别，并将其分为三个挑战等级：针对计算功能主义的挑战、针对数字意识的实践挑战以及断言数字意识严格上不可能的论点。


<details>
  <summary>Details</summary>
Motivation: 作者开发了一个分类框架，用于对数字人工智能系统意识可能面临的挑战进行分类。

Method: 我们将该框架应用于科学和哲学文献中的14个显著例子。

Result: 成功区分了计算功能主义的挑战和数字意识的挑战，以及解析这些挑战的不同方式。

Conclusion: 本文旨在提供结构和工具来消除对计算功能主义的挑战和对数字意识的挑战之间的歧义，以及解析这些挑战的不同方式。

Abstract: We develop a taxonomical framework for classifying challenges to the possibility of consciousness in digital artificial intelligence systems. This framework allows us to identify the level of granularity at which a given challenge is intended (the levels we propose correspond to Marr's levels) and to disambiguate its degree of force: is it a challenge to computational functionalism that leaves the possibility of digital consciousness open (degree 1), a practical challenge to digital consciousness that suggests improbability without claiming impossibility (degree 2), or an argument claiming that digital consciousness is strictly impossible (degree 3)? We apply this framework to 14 prominent examples from the scientific and philosophical literature. Our aim is not to take a side in the debate, but to provide structure and a tool for disambiguating between challenges to computational functionalism and challenges to digital consciousness, as well as between different ways of parsing such challenges.

</details>


### [113] [You Only Forward Once: An Efficient Compositional Judging Paradigm](https://arxiv.org/abs/2511.16600)
*Tianlong Zhang,Hongwei Xue,Shilin Yan,Di Wu,Chen Xu,Yunyun Yang*

Main category: cs.AI

TL;DR: YOFO是一种基于模板的方法，它通过单次前向传播，利用多模态大型语言模型（MLLMs）在推荐任务中进行快速、可解释的评估。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型（MLLMs）作为评估器时，存在输出单个分数与其生成特性不符的矛盾，且精细化理解受限；而自回归地生成评估分析又过于耗时。

Method: YOFO接受一个结构化的需求模板，并在单次推理步骤中，通过读取与每个需求相关的最终token的logits，对每个需求生成二元的“是/否”决定。该方法实现了数量级的速度提升，同时保持了解释性。

Result: 实验结果表明，YOFO在标准推荐数据集上取得了最先进的成果，支持依赖感知分析（后续判断以前续判断为条件），并受益于事后CoT（思维链）。

Conclusion: YOFO通过模板条件化的方法，解决了MLLMs作为评估器时速度和细粒度理解的权衡问题，实现了快速、可解释且高性能的评估。

Abstract: Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.

</details>


### [114] [Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](https://arxiv.org/abs/2511.16602)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Yingji Zhang,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Haozhe Shan,Junbo Qi,Yan Bai,Dengjie Li,Jiachen Luo,Yidong Wang,Yong Dai,Zenglin Xu,Bin Shen,Qifan Wang,Jian Tang,Xiaozhu Ju*

Main category: cs.AI

TL;DR: 该论文介绍了一种名为DPPO的元认知训练框架，旨在通过交替进行监督微调和强化学习来解决具身智能系统中的数据和算法效率问题，从而提高学习效率并超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 开发通用且多功能的具身智能系统面临两大挑战：具身数据稀缺且昂贵，以及现有算法的低效率和高资源消耗。

Method: 本文引入了Deliberate Practice Policy Optimization (DPPO)框架，这是一种元认知“Metaloop”训练框架。该框架动态地在监督微调（能力扩展）和强化学习（技能精炼）之间交替，从而实现自动弱点识别和有针对性的资源分配，旨在最大限度地提高从稀疏有限数据中学习的效率。理论上，DPPO可以被形式化为一个统一的偏好学习框架。

Result: 通过DPPO训练的视觉语言具身模型Pelican-VL 1.0，其性能比基础模型提高了20.3%，并且超越了100B参数规模的开源模型10.6%。

Conclusion: DPPO框架是第一个系统地缓解了数据和资源瓶颈的框架，能够有效地构建多功能具身智能体。该研究同时开源了模型和代码。

Abstract: Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.

</details>


### [115] [MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support](https://arxiv.org/abs/2511.16625)
*Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi*

Main category: cs.AI

TL;DR: MedBayes-Lite是一个轻量级的贝叶斯增强框架，用于改进Transformer在临床语言模型中的不确定性感知预测，在不牺牲性能的情况下提高校准性和可信度。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在临床决策支持方面潜力巨大，但它们容易过度自信，尤其是在需要校准不确定性的模糊医疗案例中。

Method: MedBayes-Lite将不确定性量化直接嵌入到现有的Transformer管道中，无需重新训练或更改架构，不增加新的可训练层，参数开销低于3％。该框架集成了三个组件：(i) 使用Monte Carlo dropout进行经验不确定性的贝叶斯嵌入校准，(ii) 对令牌可靠性进行边缘化的不确定性加权注意力，以及 (iii) 受临床风险最小化启发而形成的置信引导决策。

Result: 在生物医学问答和临床预测基准测试（MedQA，PubMedQA，MIMIC-III）中，MedBayes-Lite持续改进校准性和可信度，将过度自信降低32％到48％。在模拟临床环境中，它通过标记不确定的预测供人类审查，可以防止高达41％的诊断错误。

Conclusion: MedBayes-Lite在实现可靠的不确定性传播和提高医疗AI系统的可解释性方面非常有效。

Abstract: We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.

</details>


### [116] [Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems](https://arxiv.org/abs/2511.16657)
*Juan C. King,Jose M. Amigo*

Main category: cs.AI

TL;DR: 本文介绍了一种先进的基于人工智能的算法交易系统，专门用于外汇市场高频环境下的欧元兑美元交易。


<details>
  <summary>Details</summary>
Motivation: 探索基本面和技术面输入特征中哪一类能为生成有利可图的交易信号提供更大、更可靠的预测能力。

Method: 整合了一系列输入特征：来自欧元区和美国的关键宏观经济基本面变量（如GDP和失业率）以及全面的技术变量（如指标、振荡器、斐波那契水平和价格背离）。使用标准机器学习指标评估预测准确性，并通过历史数据回测模拟评估交易盈利能力和风险。

Result: 论文评估了所开发算法的性能。

Conclusion: 通过比较分析，确定基本面或技术面输入特征中哪一类对生成有利可图的交易信号具有更强且更可靠的预测能力。

Abstract: This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.

</details>


### [117] [Cognitive Foundations for Reasoning and Their Manifestation in LLMs](https://arxiv.org/abs/2511.16660)
*Priyanka Kargupta,Shuyue Stella Li,Haocheng Wang,Jinu Lee,Shan Chen,Orevaoghene Ahia,Dean Light,Thomas L. Griffiths,Max Kleiman-Weiner,Jiawei Han,Asli Celikyilmaz,Yulia Tsvetkov*

Main category: cs.AI

TL;DR: 该研究分析了大型语言模型与人类推理的差异，发现模型在认知机制上存在系统性差异，并通过认知评估框架和测试时推理指导提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决复杂问题时表现出色，但在处理简单问题时却出乎意料地失败，这表明它们的输出机制可能与人类推理的根本方式不同，该研究旨在探索这种差异。

Method: 1. 提出了一个包含28种认知元素的分类法，涵盖计算约束、元认知控制、知识表示和转换操作。2. 分析了17个模型（跨文本、视觉和音频模态）的17万条推理轨迹，以及54条人类有声思维轨迹。3. 对1598篇LLM推理论文进行了元分析。4. 基于分析结果，开发了测试时推理指导。

Result: 1. 人类推理表现出层次嵌套和元认知监控，而模型则依赖于浅层前向链接，在非结构化问题上差异最显著。2. LLM研究社区侧重于易于量化的行为（序列组织：55%，分解：60%），而忽视了与成功相关的元认知控制（自我意识：16%，评估：8%）。3. 模型拥有与成功相关的行为，但未能自发部署。4. 通过测试时推理指导，模型在复杂问题上的性能提升高达60%。

Conclusion: 大型语言模型与人类推理之间存在系统性认知机制差异，模型缺乏有效的元认知控制和分层推理。通过整合认知科学原理，并开发测试时推理指导，可以显著提升模型的推理能力，为构建更具原则性的认知机制模型奠定基础，并为大规模测试人类认知理论开辟新方向。

Abstract: Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [118] [Understanding the Complexities of Responsibly Sharing NSFW Content Online](https://arxiv.org/abs/2511.15726)
*Shalini Jangra,Zaid Almahmoud,Suparna De,Gareth Tyson,Ehsan Ul Haq,Nishanth Sastry*

Main category: cs.SI

TL;DR: 该研究分析了Reddit上NSFW内容的分享模式，发现在主流平台日益接受此类内容的情况下，用户会利用NSFW版块将受众引向私人或专业成人平台，并进行图像交易。文中还发现了非自愿内容分享的语言线索。


<details>
  <summary>Details</summary>
Motivation: 探索在确保道德、法律合规及盈利可能性的前提下，负责任地分享成人内容的复杂性。

Method: 本文分析了Reddit上15个NSFW限制的子版块，并训练了一个基于RoBERTa的分类模型来识别非自愿内容分享。

Result: 用户经常将NSFW子版块作为社交跳板，将读者引向Telegram、Kik或OnlyFans等私人或专业成人社交平台进行进一步互动。他们还通过信用卡或PayPal、比特币或Venmo等支付平台直接协商图片“交易”。研究人员还发现了与非自愿内容分享相关的语言线索。
训练的RoBERTa分类模型在识别非自愿内容分享方面优于GPT-4和传统分类器。

Conclusion: Reddit上的NSFW内容分享行为复杂，融合了社交引导、商业交易，并存在非自愿内容分享的风险。RoBERTa分类模型可以有效帮助平台进行内容审核。

Abstract: Reddit is in the minority of mainstream social platforms that permit posting content that may be considered to be at the edge of what is permissible, including so-called Not Safe For Work (NSFW) content. However, NSFW is becoming more common on mainstream platforms, with X now allowing such material. We examine the top 15 NSFW-restricted subreddits by size to explore the complexities of responsibly sharing adult content, aiming to balance ethical and legal considerations with monetization opportunities. We find that users often use NSFW subreddits as a social springboard, redirecting readers to private or specialized adult social platforms such as Telegram, Kik or OnlyFans for further interactions. They also directly negotiate image "trades" through credit cards or payment platforms such as PayPal, Bitcoin or Venmo. Disturbingly, we also find linguistic cues linked to non-consensual content sharing. To help platforms moderate such behavior, we trained a RoBERTa-based classification model, which outperforms GPT-4 and traditional classifiers such as logistic regression and random forest in identifying non-consensual content sharing, demonstrating superior performance in this specific task. The source code and trained model weights are publicly available at https://github.com/socsys/15NSFW Subreddits.

</details>


### [119] [Disagreement is Disappearing on U.S. Cable Debate Shows](https://arxiv.org/abs/2511.15774)
*S M Mehedi Zaman,Kiran Garimella*

Main category: cs.SI

TL;DR: 该研究分析了美国有线新闻节目中意见分歧的趋势，发现争议性内容呈下降趋势，且论证过程存在党派偏见。


<details>
  <summary>Details</summary>
Motivation: 探究美国有线新闻节目中，意见性节目是促进了真正的讨论，还是加深了社会分歧的党派回音室。

Method: 收集了2010-2024年间来自Fox News、MSNBC和CNN的24个旗舰节目的21,000多集节目。将节目分为主持人与嘉宾的对话，并使用大型语言模型分类器对213万对对话进行了标注，以量化节目中的同意与不同意。

Result: 1. 2017年至2024年间，黄金时段节目中不同意见/辩论的比例持续下降了约三分之一。2. 节目中的挑战性内容存在党派性和不对称性，福克斯新闻中保守派很少受到反驳，MSNBC中自由派也很少受到反驳，而CNN则趋于中间。3. 在堕胎、枪支权利和移民等两极分化问题上，节目中最少出现不同意见。

Conclusion: 电视辩论正在从真正的讨论转变为党派认同的平台，这侵蚀了多元社会中必要的跨领域分裂，从而加剧了情感上的两极分化。

Abstract: Prime-time cable news programs are a highly influential part of the American media landscape, with top-rated opinion shows attracting millions of politically attentive viewers each night. In an era of intense political polarization, a critical question is whether these widely-watched "debate" shows foster genuine discussion or have devolved into partisan echo chambers that deepen societal divides. While these programs claim to air competing viewpoints, no large-scale evidence exists to quantify how often hosts and guests actually disagree. Measuring these exchanges is a significant challenge, as live broadcasts contain overlapping speakers, sarcasm, and billions of words of text. To address this gap, we construct the first speaker-resolved map of agreement and disagreement across U.S. cable opinion programming. Our study assembles over 21,000 episodes from 24 flagship shows on Fox News, MSNBC, and CNN from 2010-2024, segmenting them into host-guest turns and labeling 2.13 million turn-pairs using a high-fidelity large-language-model classifier. We present three findings: (1) the proportion of disagreement/debate on prime time shows a consistent downward trend, dropping by roughly one-third between 2017 and 2024; (2) on-air challenge is partisan and asymmetric--conservatives seldom face push-back on Fox, liberals seldom on MSNBC, with CNN declining toward the midpoint; and (3) polarizing issues such as abortion, gun rights, and immigration attract the least disagreement. The work contributes a public corpus, an open-source stance pipeline, and the first longitudinal evidence that televised "debate" is retreating from genuine discussion. By transforming into platforms for partisan affirmation, these shows erode the cross-cutting cleavages essential for a pluralistic society, thereby intensifying affective polarization.

</details>


### [120] [Time-Critical Adversarial Influence Blocking Maximization](https://arxiv.org/abs/2511.16068)
*Jilong Shi,Qiuyan Yan,Xiaobin Rui,Zhixiao Wang*

Main category: cs.SI

TL;DR: 为了解决现有AIBM方法在时间紧迫场景下的局限性，本文提出了TC-IC模型和TC-AIBM问题，并设计了BIS算法，在提供理论近似保证的同时，实现了高效且稳定的负面影响对抗。


<details>
  <summary>Details</summary>
Motivation: 传统的对抗性影响阻断最大化（AIBM）研究主要基于忽略时间因素的独立级联（IC）模型。这限制了其在政治竞选和公共紧急事件等时间敏感场景的应用。此外，现有研究未能深入探讨目标函数的次模性，导致无法提供理论下界。

Method: 本文提出了时间临界独立级联（TC-IC）模型，将时间约束纳入经典IC模型。在此基础上，建立了时间临界对抗性影响阻断最大化（TC-AIBM）问题。给出了问题的详细公式，并从理论上证明了在三种不同的平局打破规则下目标函数的次模性。最后，提出了一种双向影响采样（BIS）算法来解决TC-AIBM问题。

Result: 目标函数的次模性保证了BIS算法能够提供接近最优解的近似保证。在四个真实世界数据集上的综合实验表明，所提出的BIS算法在各种负面种子、时间约束和平局打破规则下均表现出出色的稳定性，优于现有的最新基线算法。与贪婪算法相比，BIS算法的效率提高了三个数量级。

Conclusion: TC-AIBM模型和BIS算法提供了一种有效且高效的解决方案，用于在时间敏感场景中对抗负面影响，并具有坚实的理论基础和实验支持。

Abstract: Adversarial Influence Blocking Maximization (AIBM) aims to select a set of positive seed nodes that propagate synchronously with the known negative seed nodes on the graph to counteract their negative influence. Currently, most AIBM studies are based on the classical Independent Cascade (IC) model, which omits the time factor and thus hinders their applications to time-critical scenarios like political campaigns or public emergencies. More importantly, existing AIBM studies have not investigated in-depth the submodularity of the objective function, resulting in their failure to provide a theoretical lower bound for the problem. To address these challenges, firstly, this paper proposes the Time-Critical Independent Cascade (TC-IC) model, which incorporates time constraints into the classical IC model. Secondly, the Time-Critical Adversarial Influence Blocking Maximization (TC-AIBM) is established to better handle time-critical scenarios. A detailed formulation of the problem is then presented, along with a theoretical proof of its submodularity under three different tie-breaking rules. Finally, a Bidirectional Influence Sampling (BIS) algorithm is proposed to solve the TC-AIBM problem. The submodularity of the objective function guarantees that the BIS can provide an approximation guarantee of
  to the optimal solution. Comprehensive experiments on four real-world datasets demonstrated that the proposed BIS algorithm exhibits excellent stability with various negative seeds, time constraints, and tie-breaking rules, outperforming state-of-the-art baselines. In addition, BIS improves efficiency by up to three orders of magnitude compared to the Greedy algorithm.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [121] [Fluid Reconfigurable Intelligent Surface (FRIS) Enabling Secure Wireless Communications](https://arxiv.org/abs/2511.15860)
*Xusheng Zhu,Kai-Kit Wong,Boyi Tang,Wen Chen,Chan-Byoung Chae*

Main category: cs.IT

TL;DR: 本文提出了一种利用流体可重构智能表面（FRIS）增强物理层安全的新方法，通过联合优化接入点波束成形、FRIS激活元件选择和离散相移，以最大化保密速率。研究开发了一种基于交替优化（AO）框架的高效算法来解决这个复杂的混合整数非线性规划（MINLP）问题，并在仿真中证明了FRIS相比传统RIS的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 传统的RIS在物理层安全方面的能力受限于其固定位置的反射单元。而FRIS通过赋予反射单元定位可重构性，可以动态选择最优的反射单元子集，从而进一步提升物理层安全性。本文旨在探索FRIS在此场景下的应用潜力，解决其所面临的优化难题，并验证其性能优势。

Method: 本文将最大化保密速率的问题建模为一个NP-hard的混合整数非线性规划（MINLP）问题。为了解决这个问题，研究提出了一种基于交替优化（AO）框架的高效算法。在该框架内，波束成形子问题通过广义特征值法以闭合形式最优求解，而联合元件选择和离散相位设计的组合子问题则通过交叉熵优化（CEO）方法处理。

Result: 仿真结果表明，所提出的FRIS设计显著优于传统的RIS以及其他基线方案。这验证了通过引入元件定位这个新的自由度，可以获得显著的安全增益，极大地提升了物理层安全性能。

Conclusion: FRIS通过提供元件定位的可重构性，为物理层安全带来了新的可能性。本文提出的联合优化方法和高效算法能够有效利用FRIS的特性，显著提升系统的保密速率。研究结果证明了FRIS在未来安全通信系统中的巨大潜力，并为进一步的研究和应用奠定了基础。

Abstract: The concept of fluid reconfigurable intelligent surface (FRIS) upgrades the conventional reconfigurable intelligent surface (RIS) paradigm by empowering its reflecting elements with positioning reconfigurability. This letter aims to investigate the use of FRIS to enhance physical-layer security in a system, in which a multi-antenna access point (AP) communicates with a legitimate user device in the presence of an eavesdropper. Unlike RIS with fixed-position elements, FRIS can dynamically select an optimal subset of elements from a larger array of candidate locations. We aim to maximize the secrecy rate by jointly optimizing the AP's transmit beamforming, the selection of FRIS activated elements, and their discrete phase shifts. The resulting problem is a challenging mixed-integer nonlinear program (MINLP), which is NP-hard. To address this, we propose an efficient algorithm based on an alternating optimization (AO) framework. Within this framework, the beamforming subproblem is optimally solved in closed form using the generalized eigenvalue method, while the combinatorial subproblem of joint element selection and discrete phase design is handled via the cross-entropy optimization (CEO) method. Simulation results show that the proposed FRIS design significantly outperforms the conventional RIS counterpart and other baselines, demonstrating the substantial security gains by element positioning as the new degree of freedom (DoF).

</details>
