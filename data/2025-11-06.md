<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 41]
- [cs.IT](#cs.IT) [Total: 6]
- [stat.ML](#stat.ML) [Total: 4]
- [cs.GT](#cs.GT) [Total: 1]
- [cs.LG](#cs.LG) [Total: 47]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 13]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model](https://arxiv.org/abs/2511.02958)
*Cristian García-Romero,Miquel Esplà-Gomis,Felipe Sánchez-Martínez*

Main category: cs.CL

TL;DR: 该论文提出了一种新的方法，利用替代多语言机器翻译模型的内部表示来区分人工翻译和机器翻译的句子，以提高机器翻译系统的质量。


<details>
  <summary>Details</summary>
Motivation: 现代机器翻译系统依赖于大量的并行语料库，但其中很大一部分是机器生成的翻译，过度依赖这些合成内容会显著降低翻译质量。因此，在构建高质量机器翻译系统时，过滤掉非人工翻译是一个重要的预处理步骤。

Method: 本文提出了一种新颖的方法，直接利用替代多语言机器翻译模型的内部表示来区分人工翻译和机器翻译的句子。

Result: 实验结果表明，该方法优于目前最先进的技术，尤其是在非英语语言对方面，准确率至少提高了5个百分点。

Conclusion: 本文提出了一种有效的方法来区分人工翻译和机器翻译，该方法在提高机器翻译系统质量方面表现出色，特别是非英语语言对。

Abstract: Modern machine translation (MT) systems depend on large parallel corpora,
often collected from the Internet. However, recent evidence indicates that (i)
a substantial portion of these texts are machine-generated translations, and
(ii) an overreliance on such synthetic content in training data can
significantly degrade translation quality. As a result, filtering out non-human
translations is becoming an essential pre-processing step in building
high-quality MT systems. In this work, we propose a novel approach that
directly exploits the internal representations of a surrogate multilingual MT
model to distinguish between human and machine-translated sentences.
Experimental results show that our method outperforms current state-of-the-art
techniques, particularly for non-English language pairs, achieving gains of at
least 5 percentage points of accuracy.

</details>


### [2] [LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation](https://arxiv.org/abs/2511.03001)
*Gyeom Hwangbo,Hyungjoo Chae,Minseok Kang,Hyeonjong Ju,Soohyun Oh,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 尽管大型语言模型在生成3D场景方面取得了进展，但生成的场景缺乏真实感，原因在于指令不够详细。为了解决这个问题，本文提出了LEGO-Eval评估框架和LEGO-Bench基准，以实现对细粒度指令的准确评估，并揭示了当前生成方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLMs）生成的3D场景在空间布局和物体属性方面缺乏真实感，这是因为指令不够详细。在不真实的场景中训练具身智能体，会导致其学习到与现实世界物理和语义不符的先验知识，从而在部署时性能下降。因此，验证细粒度指令与生成场景之间的一致性对于有效学习至关重要。

Method: 本文提出了LEGO-Eval评估框架，该框架配备了多种工具，旨在明确地确定场景组件的基础，从而实现更准确的一致性评估。此外，本文还介绍了LEGO-Bench，这是一个详细指令的基准，用于指定真实世界环境中复杂的布局和属性。

Result: 实验表明，LEGO-Eval在评估场景指令一致性方面，F1分数比VLM-as-a-judge高出0.41。通过LEGO-Bench进行的基准测试显示，当前生成方法存在显著局限性，在所有评估方法中，完全符合细粒度指令的场景生成成功率最高仅为10%。

Conclusion: 为了解决大型语言模型生成3D场景不真实的问题，本文提出了LEGO-Eval评估框架和LEGO-Bench基准。实验证明了LEGO-Eval在评估细粒度指令与生成场景之间一致性方面的优越性，并揭示了当前生成方法在此类任务中的不足。

Abstract: Despite recent progress in using Large Language Models (LLMs) for
automatically generating 3D scenes, generated scenes often lack realistic
spatial layouts and object attributes found in real-world environments. As this
problem stems from insufficiently detailed, coarse-grained instructions,
advancing 3D scene synthesis guided by more detailed, fine-grained instructions
that reflect real-world environments becomes crucial. Without such realistic
scenes, training embodied agents in unrealistic environments can lead them to
learn priors that diverge significantly from real-world physics and semantics,
degrading their performance when deployed. Thus, verifying the alignment
between the fine-grained instruction and the generated scene is essential for
effective learning. However, current evaluation methods, such as CLIPScore and
vision-language models (VLMs), often fail to reliably assess such alignment.
This shortcoming arises primarily from their shallow understanding of 3D
scenes, which often leads to improperly grounded scene components. To address
this, we introduce LEGO-Eval, an evaluation framework equipped with diverse
tools designed to explicitly ground scene components, enabling more accurate
alignment assessments. We also present LEGO-Bench, a benchmark of detailed
instructions that specify complex layouts and attributes of real-world
environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge
by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with
LEGO-Bench reveals significant limitations in current generation methods.
Across all evaluated approaches, success rates reached at most 10% in
generating scenes that fully align with fine-grained instructions.

</details>


### [3] [Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT](https://arxiv.org/abs/2511.03005)
*Hee-Jin Lee,Zhen Guo,Luchao Jin,Morteza Moazami Goudarzi*

Main category: cs.CL

TL;DR: 该论文介绍了一种名为ARF的流水线，它能使小型开源语言模型在客户服务摘要任务中超越大型专有模型。


<details>
  <summary>Details</summary>
Motivation: 作者提出ARF流水线的动机是为了解决在客户服务摘要任务中，小型开源语言模型（LLMs）的性能不如大型专有模型的问题，并希望通过此流水线提高小型开源模型的性能、成本效益和数据隐私性。

Method: ARF流水线首先分析并归类教师模型（GPT-3.5）生成的摘要中的常见错误，然后使用紧凑的编辑模型（Llama 3.1 70B）进行有针对性的修改，生成高质量的、精炼的训练数据。最后，使用这些精炼数据对一个较小的学生模型（Llama 3.1 8B）进行微调。

Result: 通过ARF流水线对小型学生模型（Llama 3.1 8B）进行微调后，其摘要性能优于GPT-3.5，并在保持竞争性准确度的同时，提高了成本效益和数据隐私性。

Conclusion: ARF流水线为增强开源LLMs在各种下游应用中的性能提供了一个可推广的框架，证明了小型开源模型在特定任务上超越大型专有模型的潜力。

Abstract: We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller
open-source language models (LLMs) to surpass substantially larger proprietary
models in customer service summarization tasks. The pipeline first analyzes and
categorizes common errors in summaries produced by a teacher model (GPT-3.5),
then performs a targeted revision using a compact editor model (Llama 3.1 70B)
to generate high-quality, refined training data. Fine-tuning a smaller student
model (Llama 3.1 8B) on this refined data resulted in superior summarization
performance compared to GPT-3.5. The ARF pipeline improves cost efficiency and
data privacy while maintaining competitive accuracy, illustrating a
generalizable framework for enhancing open-source LLMs across diverse
downstream applications.

</details>


### [4] [Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2511.03034)
*Yan Cathy Hua,Paul Denny,Jörg Wicker,Katerina Taškova*

Main category: cs.CL

TL;DR: 该论文提出了FTS-OBP评估方法，研究了小型生成语言模型在教育领域ABSA中的应用，并发布了教育评论ABSA资源。


<details>
  <summary>Details</summary>
Motivation: 尽管ABSA发展迅速，但其研究和资源主要集中在商业领域，导致教育和医疗等高需求但资源匮乏领域的分析需求未得到满足。领域适应挑战和现有方法对资源密集型训练知识注入的依赖进一步阻碍了这些领域的进展。此外，传统的基于精确匹配的评估方法对于ABSA任务过于严格。

Method: 1. 提出了一种新颖的评估方法：灵活文本相似度匹配和最优二分图配对（FTS-OBP），该方法能够适应实际的提取边界变化，同时与传统指标保持强相关性并提供细粒度诊断。2. 对小型解码器生成语言模型（SLMs；<7B参数）进行了首次ABSA研究，并通过教育评论ABSA案例研究检验了资源下限。系统地探索了无数据（in-context learning和权重合并）和轻数据微调方法，并提出了一种多任务微调策略。3. 发布了第一个公共教育评论ABSA资源集。

Result: 1. FTS-OBP评估方法能够适应实际的提取边界变化，并与传统指标保持强相关性，提供细粒度诊断。2. 提出的多任务微调策略显著提升了SLM性能，使得1.5-3.8 B模型在仅有200-1,000个示例和一块GPU的情况下，超越了专有大型模型并接近基准测试结果。3. 发布了第一个公共教育评论ABSA资源集，以支持低资源领域的未来研究。

Conclusion: 该研究通过提出FTS-OBP评估方法、深入研究SLM在低资源ABSA领域的应用以及发布教育评论ABSA资源，有效解决了ABSA在低资源领域面临的挑战，并为未来的研究奠定了基础。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining
approach that identifies and classifies opinions associated with specific
entities (aspects) or their categories within a sentence. Despite its rapid
growth and broad potential, ABSA research and resources remain concentrated in
commercial domains, leaving analytical needs unmet in high-demand yet
low-resource areas such as education and healthcare. Domain adaptation
challenges and most existing methods' reliance on resource-intensive
in-training knowledge injection further hinder progress in these areas.
Moreover, traditional evaluation methods based on exact matches are overly
rigid for ABSA tasks, penalising any boundary variations which may misrepresent
the performance of generative models. This work addresses these gaps through
three contributions: 1) We propose a novel evaluation method, Flexible Text
Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates
realistic extraction boundary variations while maintaining strong correlation
with traditional metrics and offering fine-grained diagnostics. 2) We present
the first ABSA study of small decoder-only generative language models (SLMs;
<7B parameters), examining resource lower bounds via a case study in education
review ABSA. We systematically explore data-free (in-context learning and
weight merging) and data-light fine-tuning methods, and propose a multitask
fine-tuning strategy that significantly enhances SLM performance, enabling
1.5-3.8 B models to surpass proprietary large models and approach benchmark
results with only 200-1,000 examples on a single GPU. 3) We release the first
public set of education review ABSA resources to support future research in
low-resource domains.

</details>


### [5] [ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment](https://arxiv.org/abs/2511.03048)
*Anthony Hevia,Sanjana Chintalapati,Veronica Ka Wai Lai,Thanh Tam Nguyen,Wai-Tat Wong,Terry Klassen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: ROBOTO2 是一种基于 Web 的开源平台，它利用大型语言模型（LLM）协助对临床试验进行偏倚风险（ROB）评估。


<details>
  <summary>Details</summary>
Motivation: 传统的偏倚风险评估过程劳动密集，需要一个平台来简化这一过程，并提高效率和准确性。

Method: ROBOTO2 平台通过交互式界面，结合 PDF 解析、检索增强型 LLM 提示和人工审核，实现偏倚风险评估。用户可以上传临床试验报告，接收初步答案和支持证据，并提供反馈或更正。

Result: ROBOTO2 公开可用，代码和数据也已发布。研究人员构建并发布了一个包含 521 份儿科临床试验报告的数据集（8954 个信号问题，1202 个证据段落），这些报告使用了人工和 LLM 辅助方法进行标注。在此数据集上，研究人员对 4 种 LLM 的 ROB2 性能进行了基准测试。

Conclusion: ROBOTO2 平台和数据集的发布，为临床试验的偏倚风险评估提供了一个高效、可复现的工具，并为未来研究 LLM 在此领域的应用提供了基准和资源。当前模型在此关键方面的自动化仍面临挑战。

Abstract: We present ROBOTO2, an open-source, web-based platform for large language
model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2
streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process
via an interactive interface that combines PDF parsing, retrieval-augmented LLM
prompting, and human-in-the-loop review. Users can upload clinical trial
reports, receive preliminary answers and supporting evidence for ROB2 signaling
questions, and provide real-time feedback or corrections to system suggestions.
ROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and
data released to foster reproducibility and adoption. We construct and release
a dataset of 521 pediatric clinical trial reports (8954 signaling questions
with 1202 evidence passages), annotated using both manually and LLM-assisted
methods, serving as a benchmark and enabling future research. Using this
dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into
current model capabilities and ongoing challenges in automating this critical
aspect of systematic review.

</details>


### [6] [Reading Between the Lines: The One-Sided Conversation Problem](https://arxiv.org/abs/2511.03056)
*Victoria Ebert,Rishabh Singh,Tuochao Chen,Noah A. Smith,Shyamnath Gollakota*

Main category: cs.CL

TL;DR: 本文介绍了单边对话问题（1SC），即在只有对话一方可用的情况下进行推断和学习。研究了1）重建缺失说话者的对话，以及2）从单边记录中生成摘要。发现未来的一个回合和话语长度信息可以改善重建，并提出了解决幻觉和生成高质量摘要的方法。


<details>
  <summary>Details</summary>
Motivation: 会话式AI在许多现实世界环境中受到限制，例如远程医疗、呼叫中心和智能眼镜，这些环境只能记录对话的一方。

Method: 本文将此问题形式化为单边对话问题（1SC）：从对话的一侧进行推断和学习。研究了两个任务：（1）重建缺失说话者的对话，用于实时用例；（2）从单边记录中生成摘要。通过A/B测试和LLM-as-a-judge指标，在MultiWOZ、DailyDialog和Candor数据集上评估了提示和微调模型。

Result: 研究发现，访问未来一个回合和话语长度信息可以改善重建效果；占位符提示有助于减轻幻觉。大型模型通过提示生成了有前景的重建结果，而小型模型则需要进行微调。此外，无需重建缺失的对话回合即可生成高质量的摘要。

Conclusion: 本文提出了1SC作为一项新颖的挑战，并报告了有前景的结果，标志着在隐私保护会话式AI方面迈出了一步。

Abstract: Conversational AI is constrained in many real-world settings where only one
side of a dialogue can be recorded, such as telemedicine, call centers, and
smart glasses. We formalize this as the one-sided conversation problem (1SC):
inferring and learning from one side of a conversation. We study two tasks: (1)
reconstructing the missing speaker's turns for real-time use cases, and (2)
generating summaries from one-sided transcripts. Evaluating prompting and
finetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B
testing and LLM-as-a-judge metrics, we find that access to one future turn and
information about utterance length improves reconstruction, placeholder
prompting helps to mitigate hallucination, and while large models generate
promising reconstructions with prompting, smaller models require finetuning.
Further, high-quality summaries can be generated without reconstructing missing
turns. We present 1SC as a novel challenge and report promising results that
mark a step toward privacy-aware conversational AI.

</details>


### [7] [PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech](https://arxiv.org/abs/2511.03080)
*Michel Wong,Ali Alshehri,Sophia Kao,Haotian He*

Main category: cs.CL

TL;DR: 本文提出了一种名为 PolyNorm 的基于 LLM 的文本归一化方法，该方法通过自动数据整理和评估，减少了对人工规则的依赖，并在八种语言的实验中，展示出比现有系统更低的词错误率。


<details>
  <summary>Details</summary>
Motivation: 传统的文本归一化系统需要大量工程投入，难以扩展，并且在低资源环境下语言覆盖面临挑战。

Method: 本文提出了 PolyNorm，一种基于大型语言模型（LLM）的提示式文本归一化（TN）方法，旨在减少对人工规则的依赖，以最少的人工干预实现更广泛的语言适用性。此外，本文还提出了一种与语言无关的自动化数据整理和评估流程，旨在促进跨不同语言的可扩展实验。

Result: 实验结果表明，与基于生产级的系统相比，PolyNorm 在八种语言上的词错误率（WER）持续降低。

Conclusion: PolyNorm 方法通过利用大型语言模型和自动数据整理与评估，有效解决了传统文本归一化系统的痛点，在多语言环境下表现出优越的性能，并为该领域未来的研究提供了宝贵资源。

Abstract: Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)
systems, converting written forms into their canonical spoken equivalents.
Traditional TN systems can exhibit high accuracy, but involve substantial
engineering effort, are difficult to scale, and pose challenges to language
coverage, particularly in low-resource settings. We propose PolyNorm, a
prompt-based approach to TN using Large Language Models (LLMs), aiming to
reduce the reliance on manually crafted rules and enable broader linguistic
applicability with minimal human intervention. Additionally, we present a
language-agnostic pipeline for automatic data curation and evaluation, designed
to facilitate scalable experimentation across diverse languages. Experiments
across eight languages show consistent reductions in the word error rate (WER)
compared to a production-grade-based system. To support further research, we
release PolyNorm-Benchmark, a multilingual data set covering a diverse range of
text normalization phenomena.

</details>


### [8] [A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures](https://arxiv.org/abs/2511.03089)
*Gowtham Premananth,Carol Espy-Wilson*

Main category: cs.CL

TL;DR: 这篇文章探讨了精神分裂症患者语言障碍的计算语言学特征，特别是惊奇度和语义连贯性，以及这些特征与症状严重程度的关系。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症患者的语言障碍（如言语紊乱和语篇连贯性受损）可能是潜在认知障碍的体现，并有望成为症状严重程度和诊断的客观生物标志物。

Method: 本研究通过计算模型对精神分裂症患者和健康对照组的语言惊奇度和语义连贯性进行了计算和比较。此外，还探究了这些语言学指标如何随精神分裂症症状严重程度的变化而变化。

Result: 通过计算惊奇度和语义连贯性，可以区分精神分裂症患者和健康对照组，并且这些指标与精神分裂症症状的严重程度相关。

Conclusion: 惊奇度和语义连贯性这两种计算语言学指标可以作为精神分裂症的潜在客观生物标志物，有助于症状评估和诊断。

Abstract: Language disruptions are one of the well-known effects of schizophrenia
symptoms. They are often manifested as disorganized speech and impaired
discourse coherence. These abnormalities in spontaneous language production
reflect underlying cognitive disturbances and have the potential to serve as
objective markers for symptom severity and diagnosis of schizophrenia. This
study focuses on how these language disruptions can be characterized in terms
of two computational linguistic measures: surprisal and semantic coherence. By
computing surprisal and semantic coherence of language using computational
models, this study investigates how they differ between subjects with
schizophrenia and healthy controls. Furthermore, this study provides further
insight into how language disruptions in terms of these linguistic measures
change with varying degrees of schizophrenia symptom severity.

</details>


### [9] [CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic](https://arxiv.org/abs/2511.03102)
*Saad Mankarious,Ayah Zirikly*

Main category: cs.CL

TL;DR: 该Hugging Face论文介绍了一个名为CARMA的数据集，它是第一个自动标注的大规模阿拉伯语Reddit帖子数据集，用于检测六种精神疾病，旨在解决阿拉伯语精神健康检测资源稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语人群的精神健康问题早期发现面临挑战，现有研究主要集中在英语，阿拉伯语领域资源匮乏且受文化 stigmatization 影响。

Method: 作者们提出了CARMA，这是一个自动标注的大规模阿拉伯语Reddit帖子数据集。该数据集包含六种精神健康状况的内容（如焦虑、自闭症、抑郁症）和一个对照组。作者们对用户之间的词汇和语义差异进行了定性和定量分析，并且使用从浅层分类器到大型语言模型的多种模型进行了分类实验。

Result: CARMA数据集在规模和多样性上都超越了现有资源。研究结果揭示了特定精神健康状况的语言标记。分类实验展示了该数据集在推进阿拉伯语等代表性不足语言精神健康检测方面的潜力。

Conclusion: CARMA数据集的创建及其相关的分析和实验，为阿拉伯语人群的精神健康检测提供了一个有前景的工具和方向，对于解决该领域资源匮乏的问题具有重要意义。

Abstract: Mental health disorders affect millions worldwide, yet early detection
remains a major challenge, particularly for Arabic-speaking populations where
resources are limited and mental health discourse is often discouraged due to
cultural stigma. While substantial research has focused on English-language
mental health detection, Arabic remains significantly underexplored, partly due
to the scarcity of annotated datasets. We present CARMA, the first
automatically annotated large-scale dataset of Arabic Reddit posts. The dataset
encompasses six mental health conditions, such as Anxiety, Autism, and
Depression, and a control group. CARMA surpasses existing resources in both
scale and diversity. We conduct qualitative and quantitative analyses of
lexical and semantic differences between users, providing insights into the
linguistic markers of specific mental health conditions. To demonstrate the
dataset's potential for further mental health analysis, we perform
classification experiments using a range of models, from shallow classifiers to
large language models. Our results highlight the promise of advancing mental
health detection in underrepresented languages such as Arabic.

</details>


### [10] [Control Barrier Function for Aligning Large Language Models](https://arxiv.org/abs/2511.03121)
*Yuya Miyaoka,Masaki Inoue*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于控制理论的框架，利用控制障碍函数（CBF）来对大型语言模型（LLM）进行对齐，以确保生成符合用户期望的文本。


<details>
  <summary>Details</summary>
Motivation: 为了在不重新训练大型语言模型（LLM）的情况下，使其生成的内容符合用户期望。

Method: 该框架将CBF安全滤波器应用于基线LLM预测的token上，从而干预生成的文本。该安全滤波器是附加式的，无需微调基线LLM，并且可以直接利用现有的评估模型进行滤波器设计。

Result: 通过采用所提出的安全滤波器，模型能够生成符合用户期望的“正面”文本。

Conclusion: 所提出的基于控制的对齐框架，利用CBF安全滤波器，在不修改原有LLM的情况下，有效实现了文本生成的对齐。

Abstract: This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the CBF safety
filter to the predicted token generated from the baseline LLM, to intervene in
the generated text. The safety filter includes two significant advantages: this
safety filter is an add-on type, allowing it to be used for alignment purposes
without fine-tuning the baseline LLM, and if there is an evaluation model
regarding the desired alignment, it can be directly applied to the filter
design. The overall text-generation system is implemented with open-source
language models, aiming to generate positive text.

</details>


### [11] [MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity](https://arxiv.org/abs/2511.03146)
*Kaiyuan Zhang,Chenghao Yang,Zhoufutu Wen,Sihang Yuan,Qiuyue Wang,Chaoyi Huang,Guosheng Zhu,He Wang,Huawenyu Lu,Jianing Wen,Jianpeng Jiao,Lishu Luo,Longxiang Liu,Sijin Wu,Xiaolei Zhu,Xuanliang Zhang,Ge Zhang,Yi Lin,Guang Shi,Chaoyou Fu,Wenhao Huang*

Main category: cs.CL

TL;DR: 该文章介绍了MME-CC，一个用于评估多模态大模型（MLLMs）认知能力的视觉基准测试平台。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基准测试过度强调文本推理或未能系统性捕获以视觉为中心的认知行为，导致MLLMs的认知能力评估不足。

Method: 本文引入了MME-CC，一个视觉基准测试平台，将11个有代表性的推理任务组织成空间、几何和知识三大视觉信息基本类别，并对MLLMs的认知能力进行细粒度分析。

Result: 闭源模型（如Gemini-2.5-Pro）总体表现优于开源模型（如GLM-4.5V），但空间和几何推理能力普遍较弱（均≤30%）。文章还指出了常见的错误模式，例如方向错误、脆弱的跨视图身份持久性以及不遵循反事实指令等，并观察到思维链通常遵循“提取->推理->验证”三阶段过程，并严重依赖视觉提取。

Conclusion: 这项工作旨在将MLLMs的认知能力作为评估和模型设计的核心。

Abstract: As reasoning models scale rapidly, the essential role of multimodality in
human cognition has come into sharp relief, driving a growing need to probe
vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either
overemphasize textual reasoning or fall short of systematically capturing
vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs
insufficiently assessed. To address this limitation, we introduce MME-CC
(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded
benchmark that organizes 11 representative reasoning tasks into three
fundamental categories of visual information: spatial, geometric, and
knowledge-based reasoning, and provides fine-grained analyses of MLLMs'
cognitive capacity across these dimensions. Based on MME-CC, we conduct
extensive experiments over 16 representative MLLMs. Our study reveals that
closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.
30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak
(less than or equal to 30%). We further identify common error patterns,
including orientation mistakes, fragile cross-view identity persistence, and
poor adherence to counterfactual instructions, and observe that
Chain-of-Thought typically follows a three-stage process (extract -> reason ->
verify) with heavy reliance on visual extraction. We hope this work catalyzes a
shift toward treating the cognitive capacity of MLLMs as central to both
evaluation and model design.

</details>


### [12] [Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment](https://arxiv.org/abs/2511.03152)
*Srishti Yadav,Jasmina Gajcin,Erik Miehling,Elizabeth Daly*

Main category: cs.CL

TL;DR: 为了负责任地部署AI系统，了解不同利益相关者如何感知AI系统中的风险至关重要。本文提出了一个使用大型语言模型（LLM）作为判断者来预测和解释风险的框架，该框架能生成特定于利益相关者的、可解释的策略，从而揭示不同利益相关者对相同风险的认同或分歧。


<details>
  <summary>Details</summary>
Motivation: 理解不同利益相关者对AI系统风险的感知对于AI系统的负责任部署至关重要，因此需要一个能够评估和解释这些风险的框架。

Method: 本文提出了一个利益相关者基础的风险评估框架，利用大型语言模型（LLM）作为判断者来预测和解释风险。该框架结合了Risk Atlas Nexus和GloVE解释方法，生成具有利益相关者特定性的可解释策略，以展示不同利益相关者对相同风险的认同或分歧。此外，本文还提出了一种交互式可视化方法，用以揭示冲突产生的原因。并在医疗AI、自动驾驶和欺诈检测三个真实世界的AI用例中验证了该方法。

Result: 研究结果表明，利益相关者的观点显著影响风险感知和冲突模式。通过该框架，可以生成利益相关者特定的、可解释的策略，揭示不同利益相关者对相同风险的认同或分歧，并且交互式可视化能够增强冲突推理的透明度。

Conclusion: 本文强调了利益相关者感知对AI系统风险评估的重要性，并提出了一个基于LLM的评估框架，该框架能够提供利益相关者感知的解释，以使基于LLM的评估更加透明、可解释，并符合以人为中心的AI治理目标。

Abstract: Understanding how different stakeholders perceive risks in AI systems is
essential for their responsible deployment. This paper presents a framework for
stakeholder-grounded risk assessment by using LLMs, acting as judges to predict
and explain risks. Using the Risk Atlas Nexus and GloVE explanation method, our
framework generates stakeholder-specific, interpretable policies that shows how
different stakeholders agree or disagree about the same risks. We demonstrate
our method using three real-world AI use cases of medical AI, autonomous
vehicles, and fraud detection domain. We further propose an interactive
visualization that reveals how and why conflicts emerge across stakeholder
perspectives, enhancing transparency in conflict reasoning. Our results show
that stakeholder perspectives significantly influence risk perception and
conflict patterns. Our work emphasizes the importance of these
stakeholder-aware explanations needed to make LLM-based evaluations more
transparent, interpretable, and aligned with human-centered AI governance
goals.

</details>


### [13] [Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks](https://arxiv.org/abs/2511.03166)
*Kevin Wang,Subre Abdoul Moktar,Jia Li,Kangshuo Li,Feng Chen*

Main category: cs.CL

TL;DR: 本文对大型语言模型（LLMs）中的不确定性估计（UE）方法进行了全面的实证研究，评估了不同UE方法在回答问题任务中在同分布（ID）和异分布（OOD）数据集上的鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的应用日益广泛，确保其输出的可信度至关重要，而不确定性估计（UE）在其中扮演着关键角色。

Method: 本研究对十二种不同的UE方法和四种生成质量指标（包括来自LLM批评者的LLMScore）进行了评估，用于衡量LLM在问答（QA）任务中生成答案的不确定性，分别在同分布（ID）和异分布（OOD）数据集上进行。

Result: 基于信息的方法（利用token和序列概率）在ID设置中表现出色；基于密度的方法和P(True)指标在OOD环境中表现出卓越的性能；语义一致性方法在不同数据集和生成指标上表现出可靠的性能。

Conclusion: 不同类型的不确定性估计方法在LLM的同分布和异分布设置下表现各异。基于信息的方法在同分布数据上效果最佳，而基于密度的方法和P(True)指标在异分布数据上表现更优。语义一致性方法在不同数据集和指标上均表现可靠。

Abstract: Large Language Models (LLMs) have become increasingly pervasive, finding
applications across many industries and disciplines. Ensuring the
trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)
plays a key role. In this work, a comprehensive empirical study is conducted to
examine the robustness and effectiveness of diverse UE measures regarding
aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE
methods and four generation quality metrics including LLMScore from LLM
criticizers to evaluate the uncertainty of LLM-generated answers in
Question-Answering (QA) tasks on both in-distribution (ID) and
out-of-distribution (OOD) datasets. Our analysis reveals that information-based
methods, which leverage token and sequence probabilities, perform exceptionally
well in ID settings due to their alignment with the model's understanding of
the data. Conversely, density-based methods and the P(True) metric exhibit
superior performance in OOD contexts, highlighting their effectiveness in
capturing the model's epistemic uncertainty. Semantic consistency methods,
which assess variability in generated answers, show reliable performance across
different datasets and generation metrics. These methods generally perform well
but may not be optimal for every situation.

</details>


### [14] [BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture](https://arxiv.org/abs/2511.03180)
*Shahriyar Zaman Ridoy,Azmine Toushik Wasi,Koushik Ahamed Tonmoy*

Main category: cs.CL

TL;DR: 为孟加拉语和南亚文化开发的第一个大规模伦理基准，用于评估多语言大型语言模型的伦理对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的伦理基准主要是以英语为中心，而且是由西方框架形成的，忽略了对真实世界部署至关重要的文化细微差别。

Method: 本文介绍了BengaliMoralBench，这是第一个针对孟加拉语和社会文化背景的大规模伦理基准。它涵盖了日常活动、习惯、育儿、家庭关系和宗教活动五个道德领域，细分为50个与文化相关的子主题。每个场景都通过母语人士的共识，使用美德、常识和正义伦理这三种伦理视角进行标注。

Result: 在统一的提示协议和标准指标下，对Llama、Gemma、Qwen和DeepSeek等著名的多语言大型语言模型进行了系统的零样本评估。模型的性能差异很大（准确率为50-91%），定性分析揭示了在文化基础、常识推理和道德公平性方面存在一致的弱点。

Conclusion: BengaliMoralBench为负责任的本地化提供了基础，支持在孟加拉国等资源匮乏的B5多语言环境中部署符合道德规范、伦理上稳健的人工智能。

Abstract: As multilingual Large Language Models (LLMs) gain traction across South Asia,
their alignment with local ethical norms, particularly for Bengali, which is
spoken by over 285 million people and ranked 6th globally, remains
underexplored. Existing ethics benchmarks are largely English-centric and
shaped by Western frameworks, overlooking cultural nuances critical for
real-world deployment. To address this, we introduce BengaliMoralBench, the
first large-scale ethics benchmark for the Bengali language and socio-cultural
contexts. It covers five moral domains, Daily Activities, Habits, Parenting,
Family Relationships, and Religious Activities, subdivided into 50 culturally
relevant subtopics. Each scenario is annotated via native-speaker consensus
using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct
systematic zero-shot evaluation of prominent multilingual LLMs, including
Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and
standard metrics. Performance varies widely (50-91% accuracy), with qualitative
analysis revealing consistent weaknesses in cultural grounding, commonsense
reasoning, and moral fairness. BengaliMoralBench provides a foundation for
responsible localization, enabling culturally aligned evaluation and supporting
the deployment of ethically robust AI in diverse, low-resource multilingual
settings such as Bangladesh.

</details>


### [15] [LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval](https://arxiv.org/abs/2511.03214)
*Wenchang Lei,Ping Zou,Yue Wang,Feng Sun,Lei Zhao*

Main category: cs.CL

TL;DR: 为了增强LLMs对模糊或概念错位的术语的理解，我们提出了语言图模型（LGM）。该模型通过提取元关系（继承、别名和组成）并利用反射机制进行验证来提高概念清晰度。LGM将这些关系和描述动态地提供给LLMs，从而在不依赖扩展上下文窗口的情况下处理任意长度的文本。在标准基准测试中，LGM始终优于现有的RAG基线。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在语义理解方面表现出色，但在处理涉及模糊或概念错位术语的用户指令时存在困难。

Method: 本文提出了语言图模型（LGM），该模型通过从自然语言中提取元关系（继承、别名和组成）来增强概念清晰度。LGM利用反射机制来验证这些元关系。LGM通过概念迭代检索算法，动态地将这些关系和相关描述提供给LLM，提高了其解释概念和生成准确响应的能力。

Result: LGM在标准基准测试中的表现始终优于现有的检索增强生成（RAG）基线。

Conclusion: 语言图模型（LGM）通过提取和验证元关系，并利用概念迭代检索算法动态地为LLMs提供这些信息，有效地提高了LLMs对模糊概念的理解和生成准确响应的能力。与传统RAG方法不同，LGM能够处理任意长度的文本，且无需截断。

Abstract: Large language models (LLMs) exhibit strong semantic understanding, yet
struggle when user instructions involve ambiguous or conceptually misaligned
terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity
by extracting meta-relations-inheritance, alias, and composition-from natural
language. The model further employs a reflection mechanism to validate these
meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these
relations and related descriptions are dynamically supplied to the LLM,
improving its ability to interpret concepts and generate accurate responses.
Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely
on extended context windows, our method enables large language models to
process texts of any length without the need for truncation. Experiments on
standard benchmarks demonstrate that the LGM consistently outperforms existing
RAG baselines.

</details>


### [16] [Silenced Biases: The Dark Side LLMs Learned to Refuse](https://arxiv.org/abs/2511.03369)
*Rom Himelstein,Amit LeVi,Brit Youngmann,Yaniv Nemcovsky,Avi Mendelson*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为“沉默偏见”的概念，即大型语言模型在安全对齐后仍然存在的，但被拒绝回复所掩盖的潜在偏见。论文提出了“沉默偏见基准测试（SBB）”来评估这些偏见，该方法通过激活引导来减少模型拒绝，从而揭示模型深层隐藏的偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在敏感应用中日益普及，传统基于问答的公平性评估方法可能将模型拒绝回复解读为积极的公平性表现，从而掩盖了模型深层次的偏见，即“沉默偏见”。因此，需要一种新的方法来揭示这些被掩盖的潜在偏见。

Method: 本文提出“沉默偏见基准测试（SBB）”，通过对比直接回复和拒绝回复来评估模型的公平性。SBB利用激活引导技术减少模型拒绝回复，从而揭示模型潜在的偏见。SBB支持扩展到不同的人口统计学群体和主题。

Result: 研究结果表明，通过SBB评估多个大型语言模型，发现模型的直接回复与潜在的公平性问题之间存在显著差异，揭示了被安全对齐所掩盖的深层偏见。

Conclusion: 安全对齐的大型语言模型中存在“沉默偏见”，传统的公平性评估方法无法有效发现。SBB提供了一种新的评估框架，通过减少模型拒绝来揭示模型潜在的偏见，鼓励未来开发更公平的模型和工具，超越对齐训练的掩盖效应。

Abstract: Safety-aligned large language models (LLMs) are becoming increasingly
widespread, especially in sensitive applications where fairness is essential
and biased outputs can cause significant harm. However, evaluating the fairness
of models is a complex challenge, and approaches that do so typically utilize
standard question-answer (QA) styled schemes. Such methods often overlook
deeper issues by interpreting the model's refusal responses as positive
fairness measurements, which creates a false sense of fairness. In this work,
we introduce the concept of silenced biases, which are unfair preferences
encoded within models' latent space and are effectively concealed by
safety-alignment. Previous approaches that considered similar indirect biases
often relied on prompt manipulation or handcrafted implicit queries, which
present limited scalability and risk contaminating the evaluation process with
additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to
uncover these biases by employing activation steering to reduce model refusals
during QA. SBB supports easy expansion to new demographic groups and subjects,
presenting a fairness evaluation framework that encourages the future
development of fair models and tools beyond the masking effects of alignment
training. We demonstrate our approach over multiple LLMs, where our findings
expose an alarming distinction between models' direct responses and their
underlying fairness issues.

</details>


### [17] [Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval](https://arxiv.org/abs/2511.03228)
*Shantanu Agarwal,Joel Barry,Elizabeth Boschee,Scott Miller*

Main category: cs.CL

TL;DR: 该报告描述了SARAL团队在MATERIAL项目中的跨语言信息检索（CLIR）方法，该方法专注于检索与查询相关的文档集，在MATERIAL第三阶段评估中，SARAL在六分之五的评估条件下超越了其他团队。


<details>
  <summary>Details</summary>
Motivation: 处理跨语言信息检索（CLIR）

Method: SARAL团队开发了一种新颖的方法来处理CLIR，其重点是开发一种 Farsi, Kazakh, and Georgian)。

Result: 在MATERIAL第三阶段评估中，SARAL在涵盖三种不同语言（Farsi、Kazakh 和 Georgian）的六分之五评估条件下超越了其他团队的性能。

Conclusion: SARAL团队的CLIR方法在MATERIAL项目中表现出色，尤其在检索文档集方面，并在多语言评估中取得了领先的成绩。

Abstract: Machine Translation for English Retrieval of Information in Any Language
(MATERIAL) is an IARPA initiative targeted to advance the state of
cross-lingual information retrieval (CLIR). This report provides a detailed
description of Information Sciences Institute's (ISI's) Summarization and
domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.
Specifically, we outline our team's novel approach to handle CLIR with emphasis
in developing an approach amenable to retrieve a query-relevant document
\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3
evaluations, SARAL exceeded the performance of other teams in five out of six
evaluation conditions spanning three different languages (Farsi, Kazakh, and
Georgian).

</details>


### [18] [IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs](https://arxiv.org/abs/2511.03237)
*Souvik Rana,Arul Menezes,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 本文介绍了一种名为IndicSuperTokenizer的新型多语言分词器，专门用于大型语言模型（LLMs），它通过结合子词和多词分词以及语言特定的预分词，显著提高了多语言LLMs的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 分词器在大型语言模型（LLMs）的性能、训练效率和推理成本中起着关键作用。为多语言LLMs设计有效的分词器尤其具有挑战性，因为多语言存在不同的书写系统和丰富的形态变化。尽管BPE等子词方法被广泛采用，但它们在多语言环境中的有效性仍未被充分探索。

Method: 我们提出了IndicSuperTokenizer，这是一种用于印度多语言LLMs的分词器，它结合了子词和多词分词方法，并辅以语言特定的预分词。这种设计旨在生成更具语言对齐性的词元，以实现更高的生育分数。

Result: IndicSuperTokenizer在英语、22种印度语言和代码数据上的评估显示，与LLaMA4相比，平均生育分数提高了39.5%；与当前最佳的Sutra相比，平均生育分数提高了18%。这使得推理吞吐量比LLaMA4提高了44%，同时在英语和印度语基准测试中保持了可比的性能。

Conclusion: IndicSuperTokenizer通过其创新的子词和多词分词结合语言特定预分词的方法，显著提升了多语言LLMs的性能和效率，并在生育分数上达到了新的SOTA。我们的设计选择在分词器训练数据大小、词汇量、合并技术和预分词策略方面表现出鲁棒性。

Abstract: Tokenizers play a crucial role in determining the performance, training
efficiency, and the inference cost of Large Language Models (LLMs). Designing
effective tokenizers for multilingual LLMs is particularly challenging due to
diverse scripts and rich morphological variation. While subword methods such as
Byte Pair Encoding (BPE) are widely adopted, their effectiveness in
multilingual settings remains underexplored. We present IndicSuperTokenizer, a
tokenizer for Indic multilingual LLMs, that combines both subword and
multi-word tokenization, along with language-specific pre-tokenization, leading
to more linguistically aligned tokens and achieving a new state-of-the-art in
fertility score. Evaluated across English, 22 Indian languages and code data,
our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by
18% over Sutra (the current best). This translates to 44% improvement in
inference throughput over LLaMA4 while maintaining comparable performance on
English and Indic benchmarks. We also present detailed ablations across
tokenizer training data size, vocabulary size, merging techniques, and
pre-tokenization strategies, demonstrating the robustness of our design
choices.

</details>


### [19] [Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature](https://arxiv.org/abs/2511.03261)
*Ranul Dayarathne,Uvini Ranaweera,Upeksha Ganegoda*

Main category: cs.CL

TL;DR: 本文比较了RAG支持下，不同大型语言模型（LLMs）在计算机科学文献问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 比较不同大型语言模型（LLMs）在问答任务中的性能，特别是在检索增强生成（RAG）环境下的表现，以减少幻觉并提升生成式AI模型的能力。

Method: 本研究比较了四种开源大型语言模型（Mistral-7b-instruct, LLaMa2-7b-chat, Falcon-77b-instruct, 和 Orca-mini-v3-7b）以及OpenAI的GPT-3.5在计算机科学文献问答任务中的表现，并利用RAG支持。评估指标包括二元问题的准确率和精确度，以及人工专家、谷歌Gemini模型排名和长答案问题的余弦相似度。

Result: GPT-3.5与RAG结合在二元和长答案问题上表现出色。在开源模型中，Mistral-7b-instruct与RAG结合的表现优于其他开源模型。Orca-mini-v3-7b在生成响应方面平均延迟最短，而LLaMa2-7b-chat的平均延迟最高。

Conclusion: 开源大型语言模型在适当的基础设施支持下，可以与GPT-3.5等专有模型相媲美。

Abstract: Retrieval Augmented Generation (RAG) is emerging as a powerful technique to
enhance the capabilities of Generative AI models by reducing hallucination.
Thus, the increasing prominence of RAG alongside Large Language Models (LLMs)
has sparked interest in comparing the performance of different LLMs in
question-answering (QA) in diverse domains. This study compares the performance
of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,
Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA
tasks within the computer science literature leveraging RAG support. Evaluation
metrics employed in the study include accuracy and precision for binary
questions and ranking by a human expert, ranking by Google's AI model Gemini,
alongside cosine similarity for long-answer questions. GPT-3.5, when paired
with RAG, effectively answers binary and long-answer questions, reaffirming its
status as an advanced LLM. Regarding open-source LLMs, Mistral AI's
Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary
and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b
reports the shortest average latency in generating responses, whereas
LLaMa2-7b-chat by Meta reports the highest average latency. This research
underscores the fact that open-source LLMs, too, can go hand in hand with
proprietary models like GPT-3.5 with better infrastructure.

</details>


### [20] [SCALE: Upscaled Continual Learning of Large Language Models](https://arxiv.org/abs/2511.03270)
*Jin-woo Lee,Junhwa Choi,Bongkyu Hwang,Jinho Choo,Bogun Kim,JeongSeon Yi,Joonseok Lee,DongYoung Jung,Jaeseon Park,Kyoungwon Park,Suk-hoon Jung*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种名为SCALE的宽度扩展架构，用于大型语言模型的持续预训练，该架构在冻结预训练参数的同时，通过插入轻量级扩展来增加模型容量。SCALE旨在通过“持久保留”和“协同适应”原则，在获取新知识的同时，有效缓解遗忘问题并保持模型原有功能。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型的持续预训练进展，更多地取决于扩展正确的结构而非仅仅扩展参数量。

Method: SCALE架构通过在LMs中插入轻量级扩展到线性模块中，同时冻结所有预训练参数，从而增加了模型容量。该方法遵循“持久保留”和“协同适应”两个原则。具体实现了SCALE-Preserve、SCALE-Adapt以及可选的SCALE-Route。

Result: 在受控的合成传记基准测试中，SCALE有效缓解了深度扩展导致的严重遗忘问题，同时仍能获取新知识。在韩语语料库上的持续预训练中，SCALE变体在英语评估中展现出更少的遗忘，并在韩语基准测试中取得了有竞争力的提升，在稳定性和可塑性之间取得了最佳的权衡。

Conclusion: SCALE架构为大型语言模型的持续预训练提供了一种有效的解决方案，通过结构扩展而非简单参数扩展，在保留原有知识的同时获取新知识，有效缓解了遗忘问题，并在多语言场景下表现出色。研究还分析了保留性何时成立以及保留与适应之间的相互作用如何稳定优化。

Abstract: We revisit continual pre-training for large language models and argue that
progress now depends more on scaling the right structure than on scaling
parameters alone. We introduce SCALE, a width upscaling architecture that
inserts lightweight expansion into linear modules while freezing all
pre-trained parameters. This preserves the residual and attention topologies
and increases capacity without perturbing the base model's original
functionality. SCALE is guided by two principles: Persistent Preservation,
which maintains the base model's behavior via preservation-oriented
initialization and freezing of the pre-trained weights, and Collaborative
Adaptation, which selectively trains a subset of expansion components to
acquire new knowledge with minimal interference. We instantiate these ideas as
SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and
SCALE-Route, an optional routing extension that performs token-level routing
between preservation and adaptation heads. On a controlled synthetic biography
benchmark, SCALE mitigates the severe forgetting observed with depth expansion
while still acquiring new knowledge. In continual pre-training on a Korean
corpus, SCALE variants achieve less forgetting on English evaluations and
competitive gains on Korean benchmarks, with these variants offering the best
overall stability-plasticity trade-off. Accompanying analysis clarifies when
preservation provably holds and why the interplay between preservation and
adaptation stabilizes optimization compared to standard continual learning
setups.

</details>


### [21] [Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks](https://arxiv.org/abs/2511.03328)
*Jindong Hong,Tianjie Chen,Lingjie Luo,Chuanyang Zheng,Ting Xu,Haibao Yu,Jianing Qiu,Qianzhong Chen,Suning Huang,Yan Xu,Yong Gui,Yijun He,Jiankai Sun*

Main category: cs.CL

TL;DR: 本文评估了多模态大型语言模型（MLLMs）在医疗任务中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 评估“推理 MLLMs”在临床任务中增强的推理过程如何影响模型性能和可靠性。

Method: 本文评估了Seed1.5-VL和Gemini-2.5-Flash两种主流多模态大型语言模型在四项视觉医疗任务上的表现，使用了VQA-RAD和ROCOv2数据集。

Result: 激活思维模式带来的改进与标准非思维模式相比，在大多数任务中仍然微不足道。在开放式VQA和医学图像解释等复杂医疗任务上的表现仍不理想。

Conclusion: 需要特定领域的医疗数据和更先进的方法来整合医学知识，以提高MLLMs在医学任务中的表现。

Abstract: A recent advancement in Multimodal Large Language Models (MLLMs) research is
the emergence of "reasoning MLLMs" that offer explicit control over their
internal thinking processes (normally referred as the "thinking mode")
alongside the standard "non-thinking mode". This capability allows these models
to engage in a step-by-step process of internal deliberation before generating
a final response. With the rapid transition to and adoption of these
"dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning
processes of these MLLMs impact model performance and reliability in clinical
tasks. This paper evaluates the active "thinking mode" capabilities of two
leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We
assessed their performance on four visual medical tasks using VQA-RAD and
ROCOv2 datasets. Our findings reveal that the improvement from activating the
thinking mode remains marginal compared to the standard non-thinking mode for
the majority of the tasks. Their performance on complex medical tasks such as
open-ended VQA and medical image interpretation remains suboptimal,
highlighting the need for domain-specific medical data and more advanced
methods for medical knowledge integration.

</details>


### [22] [Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances](https://arxiv.org/abs/2511.03354)
*Riasad Alvi,Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Md Rafi Ur Rashid,Md Rafiqul Islam,Yakub Sebastian,Sami Azam*

Main category: cs.CL

TL;DR: 这篇综述系统地评估了生成式AI（GenAI）在生物信息学领域的应用和进展，涵盖了基因组学、蛋白质组学、转录组学、结构生物学和药物发现。


<details>
  <summary>Details</summary>
Motivation: 评估GenAI在生物信息学领域中的方法学进展、预测性能和专业化方面的有效策略，并识别有前景的建模、数据密集型发现和综合生物分析方法。

Method: 采用系统评价和荟萃分析的首选报告项目方法，提出了六个研究问题（RQs）来系统地识别和评估GenAI在生物信息学中的发展。

Result: RQ1: GenAI在多种生物信息学子领域（序列分析、分子设计、整合数据建模）中表现出色。 RQ2:  специализирован模型架构通过有针对性的预训练和上下文感知策略，优于通用模型。 RQ3: GenAI在分子分析和数据整合方面显著提升了准确性并减少了错误。 RQ4: 结构建模、功能预测和合成数据生成得到改进。 RQ5: 主要限制包括可扩展性不足和数据偏差，并提出了未来的研究方向。 RQ6: 分子数据集、细胞数据集和文本资源广泛支持GenAI模型的训练和泛化。

Conclusion: GenAI在生物信息学领域展现出巨大的潜力，特别是在提高预测性能和专业化方面。未来的研究应关注解决可扩展性、数据偏差和模型泛化能力等限制，以实现更稳健和生物学上更合理的模型。

Abstract: Generative artificial intelligence (GenAI) has become a transformative
approach in bioinformatics that often enables advancements in genomics,
proteomics, transcriptomics, structural biology, and drug discovery. To
systematically identify and evaluate these growing developments, this review
proposed six research questions (RQs), according to the preferred reporting
items for systematic reviews and meta-analysis methods. The objective is to
evaluate impactful GenAI strategies in methodological advancement, predictive
performance, and specialization, and to identify promising approaches for
advanced modeling, data-intensive discovery, and integrative biological
analysis. RQ1 highlights diverse applications across multiple bioinformatics
subfields (sequence analysis, molecular design, and integrative data modeling),
which demonstrate superior performance over traditional methods through pattern
recognition and output generation. RQ2 reveals that adapted specialized model
architectures outperformed general-purpose models, an advantage attributed to
targeted pretraining and context-aware strategies. RQ3 identifies significant
benefits in the bioinformatics domains, focusing on molecular analysis and data
integration, which improves accuracy and reduces errors in complex analysis.
RQ4 indicates improvements in structural modeling, functional prediction, and
synthetic data generation, validated by established benchmarks. RQ5 suggests
the main constraints, such as the lack of scalability and biases in data that
impact generalizability, and proposes future directions focused on robust
evaluation and biologically grounded modeling. RQ6 examines that molecular
datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as
CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly
support the training and generalization of GenAI models.

</details>


### [23] [EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation](https://arxiv.org/abs/2511.03370)
*Yunbo Long,Yuhan Liu,Alexandra Brintrup*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为EQ-Negotiator的新框架，它通过结合博弈论和隐马尔可夫模型来学习和跟踪债务人的情绪状态，从而弥补了小型语言模型（SLMs）在情感复杂的自动化协商中的性能差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自动化协商中表现出色，但其高计算成本和数据隐私要求使其不适用于许多隐私敏感的场景。小型语言模型（SLMs）虽然是替代方案，但在处理情感复杂的角色扮演上与LLMs存在显著差距，尤其是在信用协商中。

Method: EQ-Negotiator框架的核心是一个推理系统，该系统将博弈论与隐马尔可夫模型（HMM）相结合，以在线学习和跟踪债务人的情绪状态，而无需预训练。这使得SLMs能够具备战略智能，以对抗操纵，同时缓和冲突并维护道德标准。

Result: 通过广泛的智能体间模拟，在包括欺骗、威胁和扮演受害者等对抗性债务人策略的各种信用协商场景中，EQ-Negotiator使一个7B参数的语言模型，其债务回收率和协商效率优于比其大10倍以上的基线LLMs。

Conclusion: 这项工作将角色建模从描述性特征配置文件提升到在隐私限制内运行的动态情感架构。此外，本文认为，在自动化协商中，战略情感智能而非原始模型规模是成功的关键因素，这为在边缘设备上运行的有效、道德和保护隐私的AI协商者铺平了道路。

Abstract: The deployment of large language models (LLMs) in automated negotiation has
set a high performance benchmark, but their computational cost and data privacy
requirements render them unsuitable for many privacy-sensitive, on-device
applications such as mobile assistants, embodied AI agents or private client
interactions. While small language models (SLMs) offer a practical alternative,
they suffer from a significant performance gap compared to LLMs in playing
emotionally charged complex personas, especially for credit negotiation. This
paper introduces EQ-Negotiator, a novel framework that bridges this capability
gap using emotional personas. Its core is a reasoning system that integrates
game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional
states online, without pre-training. This allows EQ-Negotiator to equip SLMs
with the strategic intelligence to counter manipulation while de-escalating
conflict and upholding ethical standards. Through extensive agent-to-agent
simulations across diverse credit negotiation scenarios, including adversarial
debtor strategies like cheating, threatening, and playing the victim, we show
that a 7B parameter language model with EQ-Negotiator achieves better debt
recovery and negotiation efficiency than baseline LLMs more than 10 times its
size. This work advances persona modeling from descriptive character profiles
to dynamic emotional architectures that operate within privacy constraints.
Besides, this paper establishes that strategic emotional intelligence, not raw
model scale, is the critical factor for success in automated negotiation,
paving the way for effective, ethical, and privacy-preserving AI negotiators
that can operate on the edge.

</details>


### [24] [LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning](https://arxiv.org/abs/2511.03372)
*Shenghao Li*

Main category: cs.CL

TL;DR: LFC-DA是一种符号逻辑控制的流水线，用于解决复杂逻辑数据增强中人工标注成本高且直接生成缺乏可解释性的问题。它通过将逻辑文本映射到命题表达式，编译规则库，并通过有界状态空间搜索发现有效公式，最终将其转化为自然语言问题。实验证明LFC-DA能显著提高预训练模型的逻辑推理准确性。


<details>
  <summary>Details</summary>
Motivation: 在复杂逻辑数据增强中，人工标注成本高昂，而大型语言模型直接生成的数据缺乏可解释性且逻辑单一。

Method: LFC-DA首先将逻辑文本映射到命题表达式，然后编译一个紧凑的规则库。接着，通过有界状态空间搜索系统地发现有效的公式，并将这些公式具象化为自然语言问题。

Result: 在ReClor和LogiQA上的实验表明，LFC-DA显著提高了预训练模型的逻辑推理准确性。

Conclusion: LFC-DA通过符号逻辑控制的流水线，有效地解决了复杂逻辑数据增强的挑战，确保了数据的多样性和逻辑严谨性，并提升了预训练模型的逻辑推理能力。

Abstract: For complex logical data augmentation, heavy reliance on human annotation is
costly, whereas direct generation with large language models yields
uninterpretable and logically homogeneous examples. To address this, we present
LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to
propositional expressions, a compact rule library is compiled, and a bounded
state-space search systematically discovers valid formulas that are then
verbalized back into natural-language questions, ensuring both diversity and
logical rigor under propositional logic. Experiments on ReClor and LogiQA show
significant improvements in the logical-reasoning accuracy of pretrained
models, confirming the effectiveness of LFC-DA for LLM-guided logical data
augmentation.

</details>


### [25] [Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance](https://arxiv.org/abs/2511.03383)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: 该研究表明不对称BPE（源语言和目标语言采用不同数量的合并操作）在机器翻译中优于对称BPE，尤其是在低资源环境中。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译研究通常为词汇切分模型（BPE）建议单一且固定的超参数集，即对源语言和目标语言应用相同数量的合并操作。但这种统一方法并不能保证在不同语言对和数据量下都达到最佳的机器翻译性能。

Method: 通过调查不同数据量和语言对下的BPE切分策略，评估了机器翻译系统性能。

Result: 不对称BPE在机器翻译中显著优于对称方法，尤其是在低资源设置下（5万、10万和50万句对）。在低资源设置下的英语-印地语翻译中，不对称BPE带来了5.32、4.46和0.7的CHRF++平均增益。研究还在其他六种语言对上验证了这一趋势，在12个系统中观察到10个有显著改进。研究发现，源语言采用高NMO（4K到32K）而目标语言采用低NMO（0.5K到2K）能提供最优结果。

Conclusion: 不对称BPE，特别是源语言采用较高的合并操作数，目标语言采用较低的合并操作数，能显著提高机器翻译性能，尤其是在低资源环境下。

Abstract: Existing Machine Translation (MT) research often suggests a single, fixed set
of hyperparameters for word segmentation models, symmetric Byte Pair Encoding
(BPE), which applies the same number of merge operations (NMO) to train
tokenizers for both source and target languages. However, we demonstrate that
this uniform approach doesn't guarantee optimal MT performance across different
language pairs and data sizes. This work investigates BPE segmentation recipes
across various data volumes and language pairs to evaluate MT system
performance. We find that utilizing asymmetric BPE, where the source and target
languages have different NMOs, significantly improves results over the
symmetric approach, especially in low-resource settings (50K, 100K, and 500K
sentence pairs). Specifically, asymmetric BPE yield statistically significant
($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in
low-resource setups. We validated this trend across six additional language
pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),
observing statistically significant improvement in 10 out of 12 systems
compared to symmetric BPE. Our findings indicate a high NMO for the source (4K
to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,
particularly benefiting low-resource MT.

</details>


### [26] [Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties](https://arxiv.org/abs/2511.03407)
*Célian Ringwald,Fabien Gandon,Catherine Faron,Franck Michel,Hanna Abi Akl*

Main category: cs.CL

TL;DR: 这篇论文研究了小型语言模型（SLMs）在关系抽取（RE）中如何同时处理数据类型属性和对象属性，以实现完整的RDF图谱抽取。


<details>
  <summary>Details</summary>
Motivation: 以往的研究表明，小型语言模型在 SHACL Shapes 指导下，在关系抽取（RE）中提取 RDF 三元组方面表现出潜力，但主要集中在常见的数据类型属性。本文旨在探究 SLM 如何同时处理数据类型和对象属性，以实现完整的 RDF 图谱抽取。

Method: 本文评估了几种策略来解决稀有属性长尾分布带来的瓶颈问题：分层抽样、加权损失、数据集扩缩和基于模板的合成数据增强。研究发现，在不平衡目标属性上表现最佳的策略是构建一个训练集，使其中每个属性的出现次数超过给定阈值。

Result: 研究表明，处理稀有属性的长尾分布是 SLM 在完整 RDF 图谱抽取中的关键瓶颈。通过实验，发现构建一个每个属性出现次数都超过特定阈值的训练集，是解决不平衡目标属性问题的最佳策略。

Conclusion: 本文为训练形状感知的 SLM 提供了实用的指导，并为语义关系抽取的未来研究指明了方向。研究结果和代码已公开发布，以确保可复现性。

Abstract: Small language models (SLMs) have shown promises for relation extraction (RE)
when extracting RDF triples guided by SHACL shapes focused on common datatype
properties. This paper investigates how SLMs handle both datatype and object
properties for a complete RDF graph extraction. We show that the key bottleneck
is related to long-tail distribution of rare properties. To solve this issue,
we evaluate several strategies: stratified sampling, weighted loss, dataset
scaling, and template-based synthetic data augmentation. We show that the best
strategy to perform equally well over unbalanced target properties is to build
a training set where the number of occurrences of each property exceeds a given
threshold. To enable reproducibility, we publicly released our datasets,
experimental results and code. Our findings offer practical guidance for
training shape-aware SLMs and highlight promising directions for future work in
semantic RE.

</details>


### [27] [Efficient Reasoning via Thought-Training and Thought-Free Inference](https://arxiv.org/abs/2511.03408)
*Canhui Wu,Qiong Cao,Chao Xue,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 这篇文章介绍了一个名为3TF的新框架，该框架通过思想训练和思想无关推理，在不进行明确的逐步推理的情况下，提高了大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前，大型语言模型（LLMs）通过显式思维链（CoT）提示来提高推理准确性。然而，大多数现有方法主要压缩冗长的推理输出，旨在提高效率，但在推理过程中仍依赖于显式推理。

Method: 3TF框架采取“短到长”的视角，首先训练一个可以在推理和非推理模式下运行的混合模型。然后，在CoT注释数据上进一步训练该模型，使其内化结构化推理，同时在推理时使用非推理模式强制执行简洁、无思想的输出。

Result: 与基于压缩的方法不同，3TF提高了非推理输出的推理质量，使模型能够隐含地执行丰富的内部推理，同时保持外部输出简短。经验证明，经过3TF训练的模型在无思想推理下的推理基准上取得了显著改进。

Conclusion: 高L质量的推理可以被学习并在不明确的逐步生成的情况下隐式执行。3TF框架为LLMs的效率推理提供了一个新的视角。

Abstract: Recent advances in large language models (LLMs) have leveraged explicit
Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most
existing methods primarily compress verbose reasoning outputs. These
Long-to-Short transformations aim to improve efficiency, but still rely on
explicit reasoning during inference. In this work, we introduce \textbf{3TF}
(\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree
inference), a framework for efficient reasoning that takes a Short-to-Long
perspective. We first train a hybrid model that can operate in both reasoning
and non-reasoning modes, and then further train it on CoT-annotated data to
internalize structured reasoning, while enforcing concise, thought-free outputs
at inference time using the no-reasoning mode. Unlike compression-based
approaches, 3TF improves the reasoning quality of non-reasoning outputs,
enabling models to perform rich internal reasoning implicitly while keeping
external outputs short. Empirically, 3TF-trained models obtain large
improvements on reasoning benchmarks under thought-free inference,
demonstrating that high quality reasoning can be learned and executed
implicitly without explicit step-by-step generation.

</details>


### [28] [Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG](https://arxiv.org/abs/2511.03410)
*Longpeng Qiu,Ting Li,Shuai Mao,Nan Yang,Xiaohui Yan*

Main category: cs.CL

TL;DR: QuestionRAG是一个纠正问答系统中输入错误的框架，它通过外部知识增强和强化学习来解决误解和过度纠正问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理问答系统中的输入错误时，常常因为误解用户意图或过度修改问题结构而给出不正确的回答，因此需要一种方法来有效纠正这些错误。

Method: QuestionRAG框架通过两种策略解决了问题：1) 知识增强：利用外部知识（如搜索结果、相关实体）丰富输入，以解决误解问题；2) 强化学习（RL）：通过强化学习将模型的客观目标与精确纠正对齐，以防止过度纠正。

Result: 知识增强对于理解错误问题至关重要。基于强化学习的对齐比传统的监督微调（SFT）更有效，显著提升了模型遵循指令和泛化的能力。

Conclusion: QuestionRAG通过结合知识增强和强化学习，充分发挥了大型语言模型在问题纠正任务中的潜力。

Abstract: Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

</details>


### [29] [CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field](https://arxiv.org/abs/2511.03441)
*Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为CareMedEval的新数据集，用于评估大型语言模型在生物医学批判性评估和推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生物医学领域的科学文献批判性评估方面具有潜力，但其可靠性有限，尤其是在专业领域的批判性推理方面。

Method: 推出了CareMedEval数据集，该数据集包含534个问题，基于37篇科学文章，这些问题来源于法国医学生的真实考试。该数据集旨在评估LLMs的批判性阅读和基于科学论文的推理能力。作者还在不同上下文条件下，对最先进的通用和生物医学专业LLMs进行了基准测试。

Result: 基准测试结果显示，LLMs在该任务中表现不佳，即使是开放和商业模型，其精确匹配率也未能超过0.5。尽管生成中间推理 tokens 可以显著改善结果，但模型在研究局限性和统计分析问题上仍然面临挑战。

Conclusion: CareMedEval 为基础推理提供了一个具有挑战性的基准，揭示了当前LLM的局限性，并为未来自动化支持批判性评估的发展铺平了道路。

Abstract: Critical appraisal of scientific literature is an essential skill in the
biomedical field. While large language models (LLMs) can offer promising
support in this task, their reliability remains limited, particularly for
critical reasoning in specialized domains. We introduce CareMedEval, an
original dataset designed to evaluate LLMs on biomedical critical appraisal and
reasoning tasks. Derived from authentic exams taken by French medical students,
the dataset contains 534 questions based on 37 scientific articles. Unlike
existing benchmarks, CareMedEval explicitly evaluates critical reading and
reasoning grounded in scientific papers. Benchmarking state-of-the-art
generalist and biomedical-specialized LLMs under various context conditions
reveals the difficulty of the task: open and commercial models fail to exceed
an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens
considerably improves the results. Yet, models remain challenged especially on
questions about study limitations and statistical analysis. CareMedEval
provides a challenging benchmark for grounded reasoning, exposing current LLM
limitations and paving the way for future development of automated support for
critical appraisal.

</details>


### [30] [Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction](https://arxiv.org/abs/2511.03466)
*Ringwald Celian,Gandon Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: Kastor是一个框架，它通过重新构建验证任务并将迭代学习过程，来改进用于完善和优化知识库的RDF模式识别技术，从而显著增强了模型在有限文本和RDF数据上的泛化能力和性能。


<details>
  <summary>Details</summary>
Motivation: 作者引入Kastor框架，旨在通过重新构建验证任务和采用迭代学习过程来改进RDF模式识别，以满足专业领域中知识库的构建和完善需求。

Method: Kastor通过重新构建验证任务，不再局限于单一SHACL形状验证，而是评估所有可能的属性组合。通过为每个训练样本选择最佳组合，从而显著提高模型的泛化能力和性能。此外，Kastor采用迭代学习过程来优化噪声知识库，以创建能够发现新的相关事实的鲁棒模型。

Result: Kastor改进了模型在有限文本和RDF数据上的泛化能力和性能，并通过迭代学习过程使模型能够发现新的相关事实。

Conclusion: Kastor通过重新构建验证任务和迭代学习过程，成功地提升了模型在RDF模式识别方面的性能和泛化能力，使其能够有效地完善和扩展专业领域的知识库。

Abstract: RDF pattern-based extraction is a compelling approach for fine-tuning small
language models (SLMs) by focusing a relation extraction task on a specified
SHACL shape. This technique enables the development of efficient models trained
on limited text and RDF data. In this article, we introduce Kastor, a framework
that advances this approach to meet the demands for completing and refining
knowledge bases in specialized domains. Kastor reformulates the traditional
validation task, shifting from single SHACL shape validation to evaluating all
possible combinations of properties derived from the shape. By selecting the
optimal combination for each training example, the framework significantly
enhances model generalization and performance. Additionally, Kastor employs an
iterative learning process to refine noisy knowledge bases, enabling the
creation of robust models capable of uncovering new, relevant facts

</details>


### [31] [BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation](https://arxiv.org/abs/2511.03498)
*Kazi Reyazul Hasan,Mubasshira Musarrat,A. B. M. Alim Al Islam,Muhammad Abdullah Adnan*

Main category: cs.CL

TL;DR: 该论文介绍了BanglaSTEM，这是一个包含5,000对Bangla-英语技术领域句子的数据集，旨在提高大型语言模型在处理孟加拉语技术问题时的翻译准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在英语技术问题解决方面表现良好，但在孟加拉语中表现不佳，现有翻译系统在翻译技术术语时存在困难，导致问题含义改变和错误答案。

Method: 作者创建了一个包含5,000个精心挑选的Bangla-英语科技领域句子对的数据集，称为BanglaSTEM。他们使用语言模型生成了超过12,000个翻译，然后通过人工评估选择了高质量的翻译对。利用BanglaSTEM数据集训练了一个基于T5的翻译模型，并评估了其在代码生成和数学问题解决任务上的表现。

Result: 研究结果表明，BanglaSTEM显著提高了技术内容的翻译准确性，使孟加拉语使用者能够更有效地利用以英语为重点的语言模型。

Conclusion: BanglaSTEM数据集和训练有素的翻译模型为解决孟加拉语技术文本的翻译挑战提供了有效的解决方案，促进了大型语言模型在孟加拉语社区的应用。

Abstract: Large language models work well for technical problem solving in English but
perform poorly when the same questions are asked in Bangla. A simple solution
would be to translate Bangla questions into English first and then use these
models. However, existing Bangla-English translation systems struggle with
technical terms. They often mistranslate specialized vocabulary, which changes
the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a
dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM
fields including computer science, mathematics, physics, chemistry, and
biology. We generated over 12,000 translations using language models and then
used human evaluators to select the highest quality pairs that preserve
technical terminology correctly. We train a T5-based translation model on
BanglaSTEM and test it on two tasks: generating code and solving math problems.
Our results show significant improvements in translation accuracy for technical
content, making it easier for Bangla speakers to use English-focused language
models effectively. Both the BanglaSTEM dataset and the trained translation
model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.

</details>


### [32] [HaluMem: Evaluating Hallucinations in Memory Systems of Agents](https://arxiv.org/abs/2511.03506)
*Ding Chen,Simin Niu,Kehang Li,Peng Liu,Xiangping Zheng,Bo Tang,Xinchi Li,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: HaluMem：首个针对AI记忆系统操作级幻觉评估的基准。


<details>
  <summary>Details</summary>
Motivation: 现有记忆幻觉评估主要依赖端到端问答，难以定位幻觉产生的具体操作阶段。

Method: 推出HaluMem基准，包含记忆提取、记忆更新和记忆问答三项评估任务，并构建了用户中心多轮人机交互数据集HaluMem-Medium和HaluMem-Long，数据规模庞大，对话轮次和上下文长度均超过百万级别。

Result: 现有记忆系统在提取和更新阶段容易产生和积累幻觉，并传播到问答阶段。

Conclusion: 未来研究应专注于开发可解释和受约束的记忆操作机制，以系统地抑制幻觉并提高记忆可靠性。

Abstract: Memory systems are key components that enable AI systems such as LLMs and AI
agents to achieve long-term learning and sustained interaction. However, during
memory storage and retrieval, these systems frequently exhibit memory
hallucinations, including fabrication, errors, conflicts, and omissions.
Existing evaluations of memory hallucinations are primarily end-to-end question
answering, which makes it difficult to localize the operational stage within
the memory system where hallucinations arise. To address this, we introduce the
Hallucination in Memory Benchmark (HaluMem), the first operation level
hallucination evaluation benchmark tailored to memory systems. HaluMem defines
three evaluation tasks (memory extraction, memory updating, and memory question
answering) to comprehensively reveal hallucination behaviors across different
operational stages of interaction. To support evaluation, we construct
user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and
HaluMem-Long. Both include about 15k memory points and 3.5k multi-type
questions. The average dialogue length per user reaches 1.5k and 2.6k turns,
with context lengths exceeding 1M tokens, enabling evaluation of hallucinations
across different context scales and task complexities. Empirical studies based
on HaluMem show that existing memory systems tend to generate and accumulate
hallucinations during the extraction and updating stages, which subsequently
propagate errors to the question answering stage. Future research should focus
on developing interpretable and constrained memory operation mechanisms that
systematically suppress hallucinations and improve memory reliability.

</details>


### [33] [One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework](https://arxiv.org/abs/2511.03508)
*Qi Jia,Kaiwei Zhang,Xiujie Song,Ye Shen,Xiangyang Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的框架，用于评估大型语言模型在多轮对话中遵循指令的能力，并通过该框架构建了EvolIF基准。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估大型语言模型多轮指令遵循能力方面存在局限性，无法充分反映用户交互体验。

Method: 提出了一种多层机制框架，通过解耦语言表面形式和用户意图模拟，并跟踪约束、指令和主题，动态构建带有状态变化和回溯的基准。

Result: GPT-5在EvolIF基准上表现出卓越的指令遵循性能，平均对话轮次为18.54，鲁棒性达到70.31%，显著优于Gemini-2.5-Pro。

Conclusion: 所提出的框架和EvolIF基准能够有效评估大型语言模型的多轮指令遵循能力，并揭示了不同模型在此方面的性能差异，其中GPT-5表现最佳。

Abstract: Understanding how well large language models can follow users' instructions
throughout a dialogue spanning multiple topics is of great importance for
data-intensive conversational applications. Existing benchmarks are often
limited to a fixed number of turns, making them susceptible to saturation and
failing to account for the user's interactive experience. In this work, we
propose an extensible framework for assessing multi-turn instruction-following
ability. At its core, our framework decouples linguistic surface forms from
user intent simulation through a three-layer mechanism that tracks constraints,
instructions, and topics. This framework mimics User-LLM interaction by
enabling the dynamic construction of benchmarks with state changes and
tracebacks, terminating a conversation only when the model exhausts a simulated
user's patience. We define a suite of metrics capturing the quality of the
interaction process. Using this framework, we construct EvolIF, an evolving
instruction-following benchmark incorporating nine distinct constraint types.
Our results indicate that GPT-5 exhibits superior instruction-following
performance. It sustains an average of 18.54 conversational turns and
demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant
margin of 11.41%, while other models lag far behind. All of the data and code
will be made publicly available online.

</details>


### [34] [MultiZebraLogic: A Multilingual Logical Reasoning Benchmark](https://arxiv.org/abs/2511.03553)
*Sofie Helene Bruun,Dan Saattrup Smart*

Main category: cs.CL

TL;DR: 为了全面评估大型语言模型的逻辑推理能力，我们创建了一个多语言、高质量的数据集MultiZebraLogic，以及相应的生成代码，用于比较不同LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的能力评估需要涵盖多任务基准，特别是对跨多种语言的逻辑推理技能的比较，并且需要适合不同推理能力的LLM的难度。

Method: 我们通过生成多语言、多主题、不同规模的斑马谜题（Zebra Puzzles）并包含14种线索类型和8种冗余线索类型来增加难度，从而构建了大规模、高质量的数据集。

Result: 2x3和4x5的谜题规模分别对GPT-4o mini和o3-mini提出了足够的挑战。引入5条冗余线索使o3-mini在4x5谜题上的准确率下降了15±7%。o3-mini在4x5谜题上的得分不受语言（英语与丹麦语）和主题（常见房屋与特定国家美食）的影响。同时，我们发现难度与所选线索类型之间没有相关性。

Conclusion: 我们发布了包含128+1024个谜题的MultiZebraLogic数据集，涵盖了9种日耳曼语言的2x3和4x5两种规模的谜题，并开源了可扩展至更多语言和主题的谜题生成代码，以促进对LLMs逻辑推理能力的全面评估。

Abstract: Measuring the full abilities of large language models (LLMs) requires
benchmarks representing multiple tasks. We aim to create large, high-quality
datasets for comparison of logical reasoning skills across several languages
and of suitable difficulty for LLMs of various reasoning ability. We explore
multiple ways of increasing difficulty. We generate zebra puzzles in multiple
languages, themes, sizes and including 14 different clue types and 8 red
herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are
sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a
reasoning model), respectively. Including 5 red herrings decreases o3-mini
puzzle-level accuracy on 4x5 puzzles by 15$\pm$7 %. Scores of o3-mini on 4x5
puzzles are not significantly affected by use of English vs. Danish or the
common houses theme vs. the country-specific smoerrebroed theme. We find no
correlation between difficulty and the selected clue types. Datasets of
128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic
languages for sizes 2x3 and 4x5. We publish code for puzzle generation,
designed for adaptablity into more languages and themes.

</details>


### [35] [AILA--First Experiments with Localist Language Models](https://arxiv.org/abs/2511.03559)
*Joachim Diederich*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种可控局部性的Transformer语言模型，它允许在可解释的局部主义编码和高效的分布式表示之间进行连续控制，而无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型依赖于分布式表示，而本研究旨在探索一种新型架构，能在可解释的局部主义编码和高效的分布式表示之间进行动态插值，以平衡透明度和性能。

Method: 本文在WikiText语料库上使用一个两层Transformer架构进行实验，系统地改变局部性参数λ，范围从1.0（完全局部主义）到0.0（完全分布式）。通过测量注意力熵和指针保真度，以及进行预测实验来评估不同λ值的影响。

Result: 局部主义配置（λ = 1.0）实现了显著更低的注意力熵（5.36比特），而完全分布式配置（λ = 0.0）为7.18比特。同时，局部主义配置保持了更高的指针保真度。预测实验表明，中间局部性值（λ = 0.6）在可解释性和性能之间取得了最佳平衡，测试困惑度为4.65，准确率为84.7%。

Conclusion: 局部主义语言模型为需要在透明度和能力之间取得平衡的应用提供了一个实用框架。通过显式惩罚阈值和信息理论设计原则，该模型可以在可解释性-性能谱系上实现精确的数学控制。

Abstract: This paper presents the first empirical demonstration of controllable
locality in transformer language models, a novel architectural framework that
enables continuous control over the degree of representation localization
through a tunable locality dial parameter. Unlike traditional language models
that rely exclusively on distributed representations, our approach allows
dynamic interpolation between highly interpretable localist encodings and
efficient distributed representations without requiring model retraining. We
conducted experiments on the WikiText corpus using a two-layer transformer
architecture, systematically varying the locality parameter {\lambda} across
the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our
results demonstrate that localist configurations achieve dramatically lower
attention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18
bits at {\lambda} = 0.0, while maintaining substantially higher pointer
fidelity scores reflecting stronger alignment with rule-specified targets.
Prediction experiments reveal that intermediate locality values optimize the
tradeoff between interpretability and performance, with {\lambda} = 0.6
achieving test perplexity of 4.65 and accuracy of 84.7%. These findings
establish that localist language models provide a practical framework for
applications in regulated domains requiring both transparency and capability,
offering precise mathematical control over the interpretability-performance
spectrum through explicit penalty thresholds and information-theoretic design
principles.

</details>


### [36] [ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation](https://arxiv.org/abs/2511.03563)
*One Octadion,Bondan Sapta Prakoso,Nanang Yudi Setiawan,Novanto Yudistira*

Main category: cs.CL

TL;DR: 本文探讨了如何通过微调大型语言模型（LLMs）来辅助政策制定者理解、分析和起草法律法规。


<details>
  <summary>Details</summary>
Motivation: 政策制定者在理解、分析和起草法律法规方面面临挑战，需要更好的工具来支持其工作。

Method: 1. 建立了针对法律领域的监督训练数据集。2. 引入了检索增强生成（RAG）方法，使LLM能够获取并整合最新的外部法律知识。

Result: 微调与RAG相结合的方法显著增强了法律研究和法规制定的有效性。

Conclusion: 本研究提出了一种结合微调和检索增强生成（RAG）的LLM应用方法，为政策制定者提供了强大的工具，以提升其法律信息处理、法规解读和起草的能力。

Abstract: In this study, we explore the fine-tuning of Large Language Models (LLMs) to
better support policymakers in their crucial work of understanding, analyzing,
and crafting legal regulations. To equip the model with a deep understanding of
legal texts, we curated a supervised dataset tailored to the specific needs of
the legal domain. Additionally, we integrated the Retrieval-Augmented
Generation (RAG) method, enabling the LLM to access and incorporate up-to-date
legal knowledge from external sources. This combination of fine-tuning and
RAG-based augmentation results in a tool that not only processes legal
information but actively assists policymakers in interpreting regulations and
drafting new ones that align with current needs. The results demonstrate that
this approach can significantly enhance the effectiveness of legal research and
regulation development, offering a valuable resource in the ever-evolving field
of law.

</details>


### [37] [Step-Audio-EditX Technical Report](https://arxiv.org/abs/2511.03601)
*Chao Yan,Boyong Wu,Peng Yang,Pengfei Tan,Guoqiang Hu,Yuxin Zhang,Xiangyu,Zhang,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.CL

TL;DR: Step-Audio-EditX是首个开源的、基于LLM的音频模型，擅长富有表现力的迭代音频编辑，涵盖情感、说话风格和副语言，并具有强大的零样本文本到语音（TTS）功能。


<details>
  <summary>Details</summary>
Motivation: 此模型旨在通过仅利用大边距合成数据，避免使用基于嵌入的先验或辅助模块，从而在音频编辑方面实现迭代控制和高表现力。

Method: Step-Audio-EditX的核心创新在于仅利用大边距合成数据进行学习，这种方法与传统侧重于表示层面解耦的方法有所不同，实现了对声音的迭代控制和高表现力。

Result: 评估结果表明，在情感编辑和其他细粒度控制任务中，Step-Audio-EditX超越了MiniMax-2.6-hd和Doubao-Seed-TTS-2.0。

Conclusion: Step-Audio-EditX通过其独特的大边距学习方法，在音频编辑和零样本文本到语音方面取得了显著进展，提供了更优的控制和表现力。

Abstract: We present Step-Audio-EditX, the first open-source LLM-based audio model
excelling at expressive and iterative audio editing encompassing emotion,
speaking style, and paralinguistics alongside robust zero-shot text-to-speech
(TTS) capabilities.Our core innovation lies in leveraging only large-margin
synthetic data, which circumvents the need for embedding-based priors or
auxiliary modules. This large-margin learning approach enables both iterative
control and high expressivity across voices, and represents a fundamental pivot
from the conventional focus on representation-level disentanglement. Evaluation
results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and
Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.

</details>


### [38] [Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability](https://arxiv.org/abs/2511.03635)
*Apoorva Upadhyaya,Wolfgang Nejdl,Marco Fisichella*

Main category: cs.CL

TL;DR: 本文提出了IRIS，一种可解释的零样本立场检测框架，通过隐式和显式理由在零样本设置下提供可解释的立场预测，并在多个基准数据集上取得了出色的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本立场检测方法在泛化性、文本与目标连贯性方面存在问题，且大语言模型的方法过度依赖显式推理，解释粗略，难以理解模型预测。

Method: IRIS框架将立场检测视为信息检索排序任务，利用隐式理由（文本序列）和显式理由（语言学度量）进行可解释的立场预测。隐式理由通过相关性排序指导模型预测，无需理由真值；显式理由通过交际特征揭示情感和认知维度，提供作者态度解释。

Result: IRIS在VAST、EZ-STANCE、P-Stance和RFD等基准数据集上，仅使用50%、30%甚至10%的训练数据，证明了其出色的泛化能力。

Conclusion: IRIS框架通过其新颖的架构和可解释性设计，在零样本立场检测任务中实现了卓越的泛化性和固有的可解释性，有效解决了现有方法的局限性。

Abstract: Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward
unseen targets. Existing research using contrastive, meta-learning, or data
augmentation suffers from generalizability issues or lack of coherence between
text and target. Recent works leveraging large language models (LLMs) for ZSSD
focus either on improving unseen target-specific knowledge or generating
explanations for stance analysis. However, most of these works are limited by
their over-reliance on explicit reasoning, provide coarse explanations that
lack nuance, and do not explicitly model the reasoning process, making it
difficult to interpret the model's predictions. To address these issues, in our
study, we develop a novel interpretable ZSSD framework, IRIS. We provide an
interpretable understanding of the attitude of the input towards the target
implicitly based on sequences within the text (implicit rationales) and
explicitly based on linguistic measures (explicit rationales). IRIS considers
stance detection as an information retrieval ranking task, understanding the
relevance of implicit rationales for different stances to guide the model
towards correct predictions without requiring the ground-truth of rationales,
thus providing inherent interpretability. In addition, explicit rationales
based on communicative features help decode the emotional and cognitive
dimensions of stance, offering an interpretable understanding of the author's
attitude towards the given target. Extensive experiments on the benchmark
datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%
training data prove the generalizability of our model, benefiting from the
proposed architecture and interpretable design.

</details>


### [39] [ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation](https://arxiv.org/abs/2511.03656)
*Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng*

Main category: cs.CL

TL;DR: ChiMDQA 是一个高质量的中文多文档问答数据集，专注于学术、教育、金融、法律、医疗和新闻等领域的实际业务场景。


<details>
  <summary>Details</summary>
Motivation: NLP技术快速发展，高质量中文文档问答数据集需求不断增长。

Method: 通过严谨的文档筛选和系统的问题设计，构建了包含6个领域、6068个高质量问答对的ChiMDQA数据集，并进一步细分为十个细粒度类别。

Result: ChiMDQA数据集保证了多样性和高质量，适用于文档理解、知识提取和智能问答系统等NLP任务。

Conclusion: ChiMDQA 为中文问答领域的未来研究和实际应用提供了坚实的基础。

Abstract: With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.

</details>


### [40] [Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models](https://arxiv.org/abs/2511.03699)
*Francesco Corso,Francesco Pierri,Gianmarco De Francisci Morales*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）是否表现出阴谋论倾向，是否存在社会人口学偏见，以及模型在何种程度上容易被引导采纳阴谋论观点。


<details>
  <summary>Details</summary>
Motivation: 阴谋论信念在错误信息传播和对机构不信任的形成中起着核心作用，因此是评估LLMs社会忠实度的关键试验台。尽管LLMs被越来越多地用作研究人类行为的代表，但它们是否再现了高等心理结构（如阴谋论思维）却知之甚少。

Method: 本文通过向多个模型施测经过验证的心理测量调查（衡量阴谋论思维），并采用不同的提示和条件策略。

Result: 研究结果表明，LLMs在一定程度上认同阴谋论信念的要素；通过社会人口学属性进行条件设置会产生不均匀的影响，暴露出潜在的人口偏见。此外，有针对性的提示可以轻易地使模型响应转向阴谋论方向。

Conclusion: 本文强调了批判性评估LLMs内在心理维度的重要性，这不仅有助于推动计算社会科学的发展，也为防范有害使用提供了可能的缓解策略。

Abstract: In this paper, we investigate whether Large Language Models (LLMs) exhibit
conspiratorial tendencies, whether they display sociodemographic biases in this
domain, and how easily they can be conditioned into adopting conspiratorial
perspectives. Conspiracy beliefs play a central role in the spread of
misinformation and in shaping distrust toward institutions, making them a
critical testbed for evaluating the social fidelity of LLMs. LLMs are
increasingly used as proxies for studying human behavior, yet little is known
about whether they reproduce higher-order psychological constructs such as a
conspiratorial mindset. To bridge this research gap, we administer validated
psychometric surveys measuring conspiracy mindset to multiple models under
different prompting and conditioning strategies. Our findings reveal that LLMs
show partial agreement with elements of conspiracy belief, and conditioning
with socio-demographic attributes produces uneven effects, exposing latent
demographic biases. Moreover, targeted prompts can easily shift model responses
toward conspiratorial directions, underscoring both the susceptibility of LLMs
to manipulation and the potential risks of their deployment in sensitive
contexts. These results highlight the importance of critically evaluating the
psychological dimensions embedded in LLMs, both to advance computational social
science and to inform possible mitigation strategies against harmful uses.

</details>


### [41] [Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask](https://arxiv.org/abs/2511.03718)
*Nan Li,Albert Gatt,Massimo Poesio*

Main category: cs.CL

TL;DR: 本文介绍了一种用于HCRC MapTask语料库的透视主义标注方案，该方案单独捕获说话者和听话者对每个指称表达的扎根解释，从而能够追踪理解的出现、分歧和修复。研究发现，在统一词汇变体后，完全误解很少见，但多重性差异会系统地导致分歧，揭示了表面上的扎根如何掩盖指称错位。


<details>
  <summary>Details</summary>
Motivation: 在不对称的对话环境中，参与者可能会误以为他们达成了一致，但实际上指的是不同的实体，这促使作者探索在协作对话中理解是如何建立、分歧和修复的。

Method: 作者引入了一种透视主义标注方案，用于HCRC MapTask语料库，该方案通过一个受方案约束的LLM标注流程，获得了13k个带有可靠性估计的标注指称表达，并分析了由此产生的理解状态。

Result: 研究结果表明，统一词汇变体后，完全误解很少见，但多重性差异系统地导致分歧。这揭示了表面上的扎根如何掩盖了指称错位。

Conclusion: 本文提出的框架为研究扎根的误解以及评估(V)LLM模拟协作对话中依赖视角的扎根能力提供了一个资源和分析视角。

Abstract: Collaborative dialogue relies on participants incrementally establishing
common ground, yet in asymmetric settings they may believe they agree while
referring to different entities. We introduce a perspectivist annotation scheme
for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures
speaker and addressee grounded interpretations for each reference expression,
enabling us to trace how understanding emerges, diverges, and repairs over
time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k
annotated reference expressions with reliability estimates and analyze the
resulting understanding states. The results show that full misunderstandings
are rare once lexical variants are unified, but multiplicity discrepancies
systematically induce divergences, revealing how apparent grounding can mask
referential misalignment. Our framework provides both a resource and an
analytic lens for studying grounded misunderstanding and for evaluating
(V)LLMs' capacity to model perspective-dependent grounding in collaborative
dialogue.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [42] [List Decoding and New Bicycle Code Constructions for Quantum LDPC Codes](https://arxiv.org/abs/2511.02951)
*Sheida Rabeti,Hessam Mahdavifar*

Main category: cs.IT

TL;DR: 该文章提出了一种用于量子低密度奇偶校验（QLDPC）码的MBBP-LD译码器，它在保持线性时间复杂度的同时，显著提高了逻辑错误率性能。


<details>
  <summary>Details</summary>
Motivation: 针对量子低密度奇偶校验（QLDPC）码译码器在逻辑错误率和计算复杂度上的不足，旨在提出一种性能更优的新型译码器。

Method: 文章提出了多基信念传播列表译码器（MBBP-LD），它扩展了多基信念传播（MBBP）框架，并引入了一种新的判决规则用于后处理列表译码器，以进一步降低逻辑错误率。

Result: 与现有最先进的短QLDPC码译码器相比，MBBP-LD译码器在保持线性时间复杂度的前提下，逻辑错误率降低了40%。同时，文章还探索了一种新的UB码子类，并在各种BP译码器下验证了其良好性能。

Conclusion: MBBP-LD译码器在提高QLDPC码的译码性能方面取得了重大进展，为未来QLDPC码的应用提供了有力的支持。

Abstract: In this paper, we propose a new decoder, called the Multiple-Bases
Belief-Propagation List Decoder (MBBP-LD), for Quantum Low-Density Parity-Check
(QLDPC) codes. It extends the Multiple-Bases Belief-Propagation (MBBP)
framework, originally developed for classical cyclic LDPC codes. The proposed
method preserves the linear-time complexity of standard BP decoder while
improving the logical error rate. To further reduce the logical error rate, a
new decision rule is introduced for the post-processing list decoder,
outperforming the conventional least-metric selector (LMS) criterion. For the
recently developed and implemented bivariate bicycle (BB) code with parameters
\([[144,12,12]]\), our proposed MBBP-LD decoder achieves up to 40\% lower
logical error rate compared to the state-of-the-art decoder for short QLDPC
codes, i.e., BP with ordered-statistics decoding (BP-OSD), while retaining the
linear-time complexity of the plain BP decoder. In addition, we explore a new
subclass of BB codes, that we refer to as the univariate bicycle (UB) codes,
specifically with lower-weight parity checks (\(w=6,8\)). This reduces the
polynomial search space for the code compared to general BB codes, i.e., by
reducing the search space over two polynomial components in BB codes to just a
single polynomial component in UB codes. Simulations demonstrate the promising
performance of these codes under various types of BP decoders.

</details>


### [43] [A Tsallis-Entropy Lens on Genetic Variation](https://arxiv.org/abs/2511.03063)
*Margarita Geleta,Daniel Mas Montserrat,Alexander G. Ioannidis*

Main category: cs.IT

TL;DR: 本文介绍了一种信息论推广的固定统计量——Tsallis-order $q$ F-统计量$F_q$。它通过改变$q$值来调整对稀有等位基因或常见等位基因的侧重，从而提供比传统$F_{\textbf{ST}}$更细致的群体分化视图，并能有效揭示亚群驱动的区域结构、隔离-迁移事件和奠基者效应。


<details>
  <summary>Details</summary>
Motivation: 传统的群体遗传分化指标$F_{\textbf{ST}}$在等位基因频率分布偏斜时，可能无法提供足够细致的分化信息。因此，需要一种新的方法来更精细地分析群体分化，尤其是在稀有和常见等位基因的权重方面。

Method: 本文引入了Tsallis-order $q$ F-统计量$F_q$，它是固定统计量的信息论推广。$F_q$衡量的是亚群相对于混合群体损失的Tsallis $q$-熵的比例。当$q=2$时，$F_q$等同于经典的基于方差的固定指数$F_{\textbf{ST}}$；当$q=1$时，其绝对形式等于等位基因与群体标签之间的互信息。通过改变$q$值，$F_q$可以作为一个谱系鉴别器：低$q$值会增加稀有变异的权重，而$q>1$则会逐渐强调常见变异。研究人员在真实数据（865个大洋洲基因组，1,823,000个位点）和受控谱系模拟（来自HGDP和千人基因组项目的1,432个奠基者，322,216个位点）上评估了$F_q$在One-vs-Rest（OVR）和Leave-One-Out（LOO）模式下的表现。

Result: 实验结果表明，$F_q$在OVR和LOO模式下能够清晰地归因哪些亚群驱动了区域结构，并且能够敏感地标定隔离-迁移事件和奠基者效应。这意味着$F_q$可以比$F_{\textbf{ST}}$更精细地揭示群体分化，尤其是在等位基因频率谱偏斜的情况下。

Conclusion: $F_q$作为一种分辨率更高的补充工具，可以用于模拟审计和群体结构总结，为群体遗传学研究提供了更精细的分析视角。

Abstract: We introduce an information-theoretic generalization of the fixation
statistic, the Tsallis-order $q$ F-statistic, $F_q$, which measures the
fraction of Tsallis $q$-entropy lost within subpopulations relative to the
pooled population. The family nests the classical variance-based fixation index
$F_{\textbf{ST}}$ at $q{=}2$ and a Shannon-entropy analogue at $q{=}1$, whose
absolute form equals the mutual information between alleles and population
labels. By varying $q$, $F_q$ acts as a spectral differentiator that up-weights
rare variants at low $q$, while $q{>}1$ increasingly emphasizes common
variants, providing a more fine-grained view of differentiation than
$F_{\textbf{ST}}$ when allele-frequency spectra are skewed. On real data (865
Oceanian genomes with 1,823,000 sites) and controlled genealogical simulations
(seeded from 1,432 founders from HGDP and 1000 Genomes panels, with 322,216
sites), we show that $F_q$ in One-vs-Rest (OVR) and Leave-One-Out (LOO) modes
provides clear attribution of which subpopulations drive regional structure,
and sensitively timestamps isolation-migration events and founder effects.
$F_q$ serves as finer-resolution complement for simulation audits and
population-structure summaries.

</details>


### [44] [DRL-Based Robust Multi-Timescale Anti-Jamming Approaches under State Uncertainty](https://arxiv.org/abs/2511.03305)
*Haoqin Zhao,Zan Li,Jiangbo Si,Rui Huang,Hang Hu,Tony Q. S. Quek,Naofal Al-Dhahir*

Main category: cs.IT

TL;DR: 这篇论文提出了一种在存在感知误差和执行延迟的情况下，提高无线通信系统抗干扰鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的抗干扰方法忽略了异构动作之间的执行延迟不匹配和传感器缺陷引起的测量误差。

Method: 本文建立了包含状态不确定性的多时间尺度决策模型，并提出了两种鲁棒方案：PGD-DDQN算法和NQC-DDQN算法。PGD-DDQN通过在训练过程中应用PGD来寻找最坏情况扰动并优化；NQC-DDQN引入非线性压缩机制，自适应地收缩Q值范围，以消除动作混叠。

Result: 与理想感知基线相比，所提出的算法在抗干扰性能方面只有轻微的下降，并且在各种扰动下保持了鲁棒性。

Conclusion: 本文提出的PGD-DDQN和NQC-DDQN算法在存在感知误差的条件下，能够有效地提高无线通信系统的抗干扰鲁棒性，具有实用价值。

Abstract: Owing to the openness of wireless channels, wireless communication systems
are highly susceptible to malicious jamming. Most existing anti-jamming methods
rely on the assumption of accurate sensing and optimize parameters on a single
timescale. However, such methods overlook two practical issues: mismatched
execution latencies across heterogeneous actions and measurement errors caused
by sensor imperfections. Especially for deep reinforcement learning (DRL)-based
methods, the inherent sensitivity of neural networks implies that even minor
perturbations in the input can mislead the agent into choosing suboptimal
actions, with potentially severe consequences. To ensure reliable wireless
transmission, we establish a multi-timescale decision model that incorporates
state uncertainty. Subsequently, we propose two robust schemes that sustain
performance under bounded sensing errors. First, a Projected Gradient
Descent-assisted Double Deep Q-Network (PGD-DDQN) algorithm is designed, which
derives worst-case perturbations under a norm-bounded error model and applies
PGD during training for robust optimization. Second, a Nonlinear Q-Compression
DDQN (NQC-DDQN) algorithm introduces a nonlinear compression mechanism that
adaptively contracts Q-value ranges to eliminate action aliasing. Simulation
results indicate that, compared with the perfect-sensing baseline, the proposed
algorithms show only minor degradation in anti-jamming performance while
maintaining robustness under various perturbations, thereby validating their
practicality in imperfect sensing conditions.

</details>


### [45] [Constacyclic codes with best-known parameters](https://arxiv.org/abs/2511.03323)
*Zekai Chen,Min Sha*

Main category: cs.IT

TL;DR: 本文构建了$q$-ary常循环码的无限族，其长度为$n$，维度约为$n/2$，最小距离至少为$cn/	ext{log}_q n$，并包含了许多最优、接近最优或已知参数最佳的常循环码，且考虑了不同形式的长度$n$。


<details>
  <summary>Details</summary>
Motivation: 构建具有优良参数的$q$-ary常循环码。

Method: 通过构造无限家族的$q$-ary常循环码，并分析其长度、维度和最小距离。

Result: 构建的常循环码族具有长度$n$，维度约为$n/2$，最小距离至少为$cn/	ext{log}_q n$，并且包含许多具有最优、接近最优或已知参数最佳的常循环码。

Conclusion: 本文成功构建了一系列性能优异的$q$-ary常循环码，并考虑了不同形式的长度，为常循环码的研究提供了新的方向。

Abstract: In this paper, we construct several infinite families of $q$-ary constacyclic
codes over a finite field $\mathbb{F}_q$ with length $n$, dimension around
$n/2$, and minimum distance at least $cn/\log_q n$ for some positive constant
$c$. They contain many constacyclic codes with optimal, or almost-optimal, or
best-known parameters. We also consider various forms of the length $n$.

</details>


### [46] [The (+)-(L, P)-TGRS code](https://arxiv.org/abs/2511.03398)
*Zhonghao Liang,Chenlu Jia,Qunying Liao*

Main category: cs.IT

TL;DR: 本文主要研究了(+)-(L, P)-TGRS码C的性质，包括其奇偶校验矩阵、NMDS条件、非RS条件以及自对偶/自正交条件，并构建了两类自正交码。


<details>
  <summary>Details</summary>
Motivation: 研究非Reed-Solomon类型的线性码是近年的一个研究热点。Hu等人于2025年通过定义(L, P)-扭曲广义Reed-Solomon码(TGRS)构造了一些非RS MDS码。

Method: 本文首先给出了码C的奇偶校验矩阵。其次，给出了C为NMDS码的充要条件，部分回答了Hu等人在2025年提出的两个开放问题。同时，证明了当2k > n时C是非RS码，部分改进了Hu等人2025年的相关结果。再次，给出了C不是自对偶或自正交码的充分条件，并推广了Ding等人在2025年给出的相应结果，构造了两类自正交码。最后，通过例子进行了说明。

Result: 找到了(+)-(L, P)-TGRS码C的奇偶校验矩阵，给出了C是NMDS码的充要条件，证明了当2k > n时C是非RS码。此外，给出了C不是自对偶或自正交码的充分条件，并构造了两类自正交码。

Conclusion: 本文有效地分析了(+)-(L, P)-TGRS码C的多种重要性质，解决了前人提出的一些开放问题，并改进了部分现有成果，为非Reed-Solomon类型线性码的研究做出了贡献。

Abstract: The construction of the non-Reed-Solomon (in short, non-RS) type linear code
has been one of the research hotspots in recent years. In 2025, Hu et al.
constructed some non-RS MDS codes by defining the (L, P)-twisted generalized
Reed-Solomon code (in short, (L, P)-TGRS). In this paper, we focus on the
(+)-(L, P)-TGRS code C. We firstly present a parity-check matrix. Secondly, we
give a sufficient and necessary condition for C to be NMDS which partially
answers two open problems proposed by Hu et al. in 2025, and prove that C is
non-RS for 2k > n which partially improves the corresponding result given by Hu
et al. in 2025,. Thirdly, we give a sufficient condition for C not to be
self-dual or self-orthogonal, respectively, furthermore, we construct two
classes of self-orthogonal codes which is a promotion of the corresponding
result given by Ding et al. in 2025. Finally, some examples are given.

</details>


### [47] [On the Fundamental Scaling Laws of Fluid Antenna Systems](https://arxiv.org/abs/2511.03415)
*Xusheng Zhu,Farshad Rostami Ghadi,Tuo Wu,Kaitao Meng,Chao Wang,Gui Zhou*

Main category: cs.IT

TL;DR: 本文提出FAS的符号错误率（SER）的严格分析框架，揭示了其在空间相关信道中的基本比例定律，并通过增加天线移动空间来提高分集度，从而提高SER，而仅仅增加端口密度则效果不佳。


<details>
  <summary>Details</summary>
Motivation: 以往，FAS缺乏对其错误概率的严格分析框架，本研究旨在填补这一空白。

Method: 本文推导了适用于一般调制方案的SER的紧密的、封闭形式的渐近表达式，从而建立了SER与信道空间相关结构之间关系的基本比例定律。

Result: 本文全面描述了分集和编码增益，并得出结论：通过扩展天线的移动空间以增加分集度，可以从根本上改善SER，而仅仅增加受限空间内的端口密度会降低回报。

Conclusion: FAS的SER可以通过扩大天线移动空间来有效改善，而增加端口密度的效果有限。

Abstract: Fluid antenna systems (FAS) offer a promising paradigm for enhancing wireless
communication by exploiting spatial diversity, yet a rigorous analytical
framework for their error probability has been notably absent. To this end,
this paper addresses this critical gap by unveiling the \textbf{fundamental
scaling laws} that govern the symbol error rate (SER) of FAS in realistic,
spatially correlated channels. To establish these laws, we derive a tight,
closed-form asymptotic expression for the SER applicable to a general class of
modulation schemes. This result is pivotal as it establishes the fundamental
scaling law governing the relationship between SER and the channel's spatial
correlation structure. Based on this framework, we provide a complete
characterization of the diversity and coding gains. The analysis culminates in
a definitive design directive: SER can be fundamentally improved by expanding
the antenna's movement space to increase diversity, while merely increasing
port density within a constrained space yields diminishing returns.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [48] [Unifying Information-Theoretic and Pair-Counting Clustering Similarity](https://arxiv.org/abs/2511.03000)
*Alexander J. Gates*

Main category: stat.ML

TL;DR: 这篇论文提出了一个统一的框架，将现有的聚类相似性度量方法联系起来，并解释了它们之间的异同。


<details>
  <summary>Details</summary>
Motivation: 聚类是无监督模型评估的核心，但现有的相似性度量方法会导致评估结果的差异甚至矛盾。虽然之前的工作已经发现了这些方法之间的相似之处，但它们深层的分析联系仍未完全被理解。

Method: 本文提出了一个分析框架，通过两种互补的视角统一了这些方法。首先，将两类方法都表示为观察到的共现与预期共现的加权扩展，其中配对计数是二次低阶近似，信息论度量是高阶、频率加权扩展。其次，将配对计数推广到k元组一致性，并表明信息论度量可以看作是系统地积累了超出配对级别的高阶共分配结构。

Result: 作者通过对Rand指数和互信息进行分析，并展示了其他指数如何作为自然的扩展而出现。这些观点阐明了两种方法何时以及为何会产生差异，将其敏感性直接与加权和近似阶数联系起来。

Conclusion: 该研究为在不同应用中选择、解释和扩展聚类相似性度量提供了一个有原则的基础。

Abstract: Comparing clusterings is central to evaluating unsupervised models, yet the
many existing similarity measures can produce widely divergent, sometimes
contradictory, evaluations. Clustering similarity measures are typically
organized into two principal families, pair-counting and information-theoretic,
reflecting whether they quantify agreement through element pairs or aggregate
information across full cluster contingency tables. Prior work has uncovered
parallels between these families and applied empirical normalization or
chance-correction schemes, but their deeper analytical connection remains only
partially understood. Here, we develop an analytical framework that unifies
these families through two complementary perspectives. First, both families are
expressed as weighted expansions of observed versus expected co-occurrences,
with pair-counting arising as a quadratic, low-order approximation and
information-theoretic measures as higher-order, frequency-weighted extensions.
Second, we generalize pair-counting to $k$-tuple agreement and show that
information-theoretic measures can be viewed as systematically accumulating
higher-order co-assignment structure beyond the pairwise level. We illustrate
the approaches analytically for the Rand index and Mutual Information, and show
how other indices in each family emerge as natural extensions. Together, these
views clarify when and why the two regimes diverge, relating their
sensitivities directly to weighting and approximation order, and provide a
principled basis for selecting, interpreting, and extending clustering
similarity measures across applications.

</details>


### [49] [Provable Accelerated Bayesian Optimization with Knowledge Transfer](https://arxiv.org/abs/2511.03125)
*Haitao Lin,Boxin Zhao,Mladen Kolar,Chong Liu*

Main category: stat.ML

TL;DR: 本文提出了DeltaBO算法，通过引入源任务和目标任务之间的差异函数来加速贝叶斯优化的知识迁移。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯优化在知识迁移方面，现有方法的理论保证不足，或在非迁移设置下与BO的遗憾相同。

Method: DeltaBO算法基于源函数和目标函数之间的差异函数δ，构建了一种新颖的不确定性量化方法。

Result: DeltaBO的遗憾是$	ilde{\mathcal{O}}(\sqrt{T (T/N + \gamma_\delta)})$，通常情况下$N \gg T$，且$\gamma_\delta$可以远小于$\gamma_f$。

Conclusion: DeltaBO算法在理论和实践中都优于其他基线方法，支持了其理论主张。

Abstract: We study how Bayesian optimization (BO) can be accelerated on a target task
with historical knowledge transferred from related source tasks. Existing works
on BO with knowledge transfer either do not have theoretical guarantees or
achieve the same regret as BO in the non-transfer setting,
$\tilde{\mathcal{O}}(\sqrt{T \gamma_f})$, where $T$ is the number of
evaluations of the target function and $\gamma_f$ denotes its information gain.
In this paper, we propose the DeltaBO algorithm, in which a novel
uncertainty-quantification approach is built on the difference function
$\delta$ between the source and target functions, which are allowed to belong
to different reproducing kernel Hilbert spaces (RKHSs). Under mild assumptions,
we prove that the regret of DeltaBO is of order $\tilde{\mathcal{O}}(\sqrt{T
(T/N + \gamma_\delta)})$, where $N$ denotes the number of evaluations from
source tasks and typically $N \gg T$. In many applications, source and target
tasks are similar, which implies that $\gamma_\delta$ can be much smaller than
$\gamma_f$. Empirical studies on both real-world hyperparameter tuning tasks
and synthetic functions show that DeltaBO outperforms other baseline methods
and support our theoretical claims.

</details>


### [50] [RKUM: An R Package for Robust Kernel Unsupervised Methods](https://arxiv.org/abs/2511.03216)
*Md Ashad Alam*

Main category: stat.ML

TL;DR: RKUM是一个R语言软件包，用于实现鲁棒核方法，通过使用广义损失函数估计鲁棒核协方差算子和交叉协方差算子，以应对污染或噪声数据。它还包括鲁棒核典型相关分析和影响函数。


<details>
  <summary>Details</summary>
Motivation: 在污染或噪声数据条件下，需要可靠的分析方法。传统的核学习方法对异常值敏感，因此需要鲁棒的核方法。

Method: RKUM软件包通过使用广义损失函数代替传统的二次损失函数来估计鲁棒核协方差算子（CO）和鲁棒核交叉协方差算子（CCO）。该软件包还实现了鲁棒核典型相关分析（Kernel CCA）以及标准和多核CCA框架的影响函数（IF）。

Result: 在合成的两视角和多视角数据上的实验表明，标准核CCA的影响函数能有效识别异常值，而RKUM中实现的鲁棒核方法对污染的敏感性较低。

Conclusion: RKUM为高维数据应用中的鲁棒核分析提供了一个高效且可扩展的平台。

Abstract: RKUM is an R package developed for implementing robust kernel-based
unsupervised methods. It provides functions for estimating the robust kernel
covariance operator (CO) and the robust kernel cross-covariance operator (CCO)
using generalized loss functions instead of the conventional quadratic loss.
These operators form the foundation of robust kernel learning and enable
reliable analysis under contaminated or noisy data conditions. The package
includes implementations of robust kernel canonical correlation analysis
(Kernel CCA), as well as the influence function (IF) for both standard and
multiple kernel CCA frameworks. The influence function quantifies sensitivity
and helps detect influential or outlying observations across two-view and
multi-view datasets. Experiments using synthesized two-view and multi-view data
demonstrate that the IF of the standard kernel CCA effectively identifies
outliers, while the robust kernel methods implemented in RKUM exhibit reduced
sensitivity to contamination. Overall, RKUM provides an efficient and
extensible platform for robust kernel-based analysis in high-dimensional data
applications.

</details>


### [51] [Vector-valued self-normalized concentration inequalities beyond sub-Gaussianity](https://arxiv.org/abs/2511.03606)
*Diego Martinez-Taboada,Tomas Gonzalez,Aaditya Ramdas*

Main category: stat.ML

TL;DR: 自归一化过程在许多应用中都很重要，但向量值过程的自归一化集中度研究相对较少。本文为超越亚高斯分布（如Bennett或Bernstein界）的轻尾自归一化过程提供了集中度界限，并将其应用于在线线性回归和（核化）线性老虎机。


<details>
  <summary>Details</summary>
Motivation: 自归一化过程在许多应用中发挥着关键作用，但目前对向量值过程的自归一化集中度的研究相对较少，尤其是在亚高斯框架之外。

Method: 本文为超越亚高斯分布（如Bennett或Bernstein界）的轻尾自归一化过程提供了集中度界限。

Result: 推导出了超越亚高斯分布（如Bennett或Bernstein界）的轻尾自归一化过程的集中度界限。

Conclusion: 所提出的集中度界限在在线线性回归以及（核化）线性老虎机等应用中具有重要意义。

Abstract: The study of self-normalized processes plays a crucial role in a wide range
of applications, from sequential decision-making to econometrics. While the
behavior of self-normalized concentration has been widely investigated for
scalar-valued processes, vector-valued processes remain comparatively
underexplored, especially outside of the sub-Gaussian framework. In this
contribution, we provide concentration bounds for self-normalized processes
with light tails beyond sub-Gaussianity (such as Bennett or Bernstein bounds).
We illustrate the relevance of our results in the context of online linear
regression, with applications in (kernelized) linear bandits.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [52] [Branch-and-Cut for Computing Approximate Equilibria of Mixed-Integer Generalized Nash Games](https://arxiv.org/abs/2511.03340)
*Aloïs Duguet,Tobias Harks,Martin Schmidt,Julian Schwarz*

Main category: cs.GT

TL;DR: 本文提出了一种分支定界（B&C）算法，用于计算混合整数广义Nash均衡问题（GNEP）的近似均衡，或证明其不存在。


<details>
  <summary>Details</summary>
Motivation: 广义Nash均衡问题（GNEP）通常无法获得精确均衡，且玩家求解非凸问题的能力存疑，因此需要研究近似均衡。

Method: 本文提出了一种分支定界（B&C）方法，用于计算近似均衡或证明其不存在。该方法采用了截断割平面的思想，并在特定条件下证明了割平面的存在性。对于标准Nash均衡问题，引入了另一种割平面，并在特定条件下证明了方法的有限终止性。此外，本文还提出了一种基于B&C方法的单树二分搜索方法，用于计算最佳近似均衡。

Result: 本文将所提出的方法应用于混合整数流博弈，并提供了数值结果。

Conclusion: 本文提出了一种有效的方法来寻找广义纳什均衡（GNEP）的近似解，该方法在理论上具有收敛性保证，并通过数值实验证明了其有效性。

Abstract: Generalized Nash equilibrium problems with mixed-integer variables constitute
an important class of games in which each player solves a mixed-integer
optimization problem, where both the objective and the feasible set is
parameterized by the rivals' strategies. However, such games are known for
failing to admit exact equilibria and also the assumption of all players being
able to solve nonconvex problems to global optimality is questionable. This
motivates the study of approximate equilibria. In this work, we consider an
approximation concept that incorporates both multiplicative and additive
relaxations of optimality. We propose a branch-and-cut (B&C) method that
computes such approximate equilibria or proves its non-existence. For this, we
adopt the idea of intersection cuts and show the existence of such cuts under
the condition that the constraints are linear and each player's cost function
is either convex in the entire strategy profile, or, concave in the entire
strategy profile and linear in the rivals' strategies. For the special case of
standard Nash equilibrium problems, we introduce an alternative type of cut and
show that the method terminates finitely, provided that each player has only
finitely many distinct best-response sets. Finally, on the basis of the B&C
method, we introduce a single-tree binary-search method to compute
best-approximate equilibria under some simplifying assumptions. We implemented
these methods and present numerical results for a class of mixed-integer flow
games.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [53] [FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels](https://arxiv.org/abs/2511.02872)
*Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong*

Main category: cs.LG

TL;DR: 介绍了FATE基准，用于评估大型语言模型在形式代数定理证明方面的能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在竞赛式数学基准测试中表现出色，但这些竞赛不能反映现代数学研究的深度、广度和抽象性。需要弥合这一差距。

Method: 引入了FATE（形式代数定理评估）基准系列，包含FATE-H和FATE-X两个组件，每个组件有100个抽象代数和交换代数问题。FATE系列的难度涵盖从本科练习到超过博士资格考试的问题。

Result: 目前最先进的LLM证明器在FATE基准上的表现远低于竞赛数学：最佳模型在FATE-H上仅达到3%的准确率（pass@64），在FATE-X上为0%。两阶段评估显示，模型的自然语言推理能力明显优于其形式化推理能力。FATE-X是第一个超越博士级别考试难度和Mathlib库覆盖范围的形式基准。

Conclusion: FATE提供了一个强大而具有挑战性的基准，为研究级形式数学推理建立了重要的检查点。

Abstract: Recent advances in large language models (LLMs) have demonstrated impressive
capabilities in formal theorem proving, particularly on contest-based
mathematical benchmarks like the IMO. However, these contests do not reflect
the depth, breadth, and abstraction of modern mathematical research. To bridge
this gap, we introduce FATE (Formal Algebra Theorem Evaluation), a new
benchmark series in formal algebra designed to chart a course toward advanced
mathematical reasoning. We present two new components, FATE-H and FATE-X, each
with 100 problems in abstract and commutative algebra. The FATE series spans a
difficulty spectrum from undergraduate exercises to problems exceeding PhD
qualifying exams. Notably, FATE-X is the first formal benchmark to surpass both
PhD-level exam difficulty and the coverage of the Mathlib library. Our
evaluations of state-of-the-art LLM provers on this new benchmark reveal a
stark performance gap compared to contest math: the best model achieves only 3%
(pass@64) accuracy on FATE-H and 0% on FATE-X. Our two-stage evaluation reveals
that models' natural-language reasoning is notably more accurate than their
ability to formalize this reasoning. We systematically classify the common
errors that arise during this formalization process. Furthermore, a comparative
study shows that a specialized prover can exhibit less effective reflection
than general-purpose models, reducing its accuracy at the natural-language
stage. We believe FATE provides a robust and challenging benchmark that
establishes essential checkpoints on the path toward research-level formal
mathematical reasoning.

</details>


### [54] [Stochastic Deep Graph Clustering for Practical Group Formation](https://arxiv.org/abs/2511.02879)
*Junhyung Park,Hyungjin Kim,Seokho Ahn,Young-Duk Seo*

Main category: cs.LG

TL;DR: DeepForm是一个针对群组推荐系统（GRS）中群组形成的框架，它解决了现有方法在动态环境下的不足。


<details>
  <summary>Details</summary>
Motivation: 现有群组推荐系统（GRS）主要关注提高推荐准确性，但大多假设群组是静态或预定义的，不适用于动态、真实的场景。

Method: DeepForm提出了随机深度图聚类，采用轻量级GCN架构捕获高阶用户信息，通过随机聚类学习实现无需再训练的自适应群组重构，并利用对比学习在动态条件下优化群组。

Result: DeepForm在多个数据集上的实验表明，其在群组形成质量、效率和推荐准确性方面均优于各种基线方法。

Conclusion: DeepForm通过创新的方法解决了GRS中动态群组形成的核心挑战，提高了系统在真实世界场景中的适应性和性能。

Abstract: While prior work on group recommender systems (GRSs) has primarily focused on
improving recommendation accuracy, most approaches assume static or predefined
groups, making them unsuitable for dynamic, real-world scenarios. We reframe
group formation as a core challenge in GRSs and propose DeepForm (Stochastic
Deep Graph Clustering for Practical Group Formation), a framework designed to
meet three key operational requirements: (1) the incorporation of high-order
user information, (2) real-time group formation, and (3) dynamic adjustment of
the number of groups. DeepForm employs a lightweight GCN architecture that
effectively captures high-order structural signals. Stochastic cluster learning
enables adaptive group reconfiguration without retraining, while contrastive
learning refines groups under dynamic conditions. Experiments on multiple
datasets demonstrate that DeepForm achieves superior group formation quality,
efficiency, and recommendation accuracy compared with various baselines.

</details>


### [55] [Scaling Multi-Agent Environment Co-Design with Diffusion Models](https://arxiv.org/abs/2511.03100)
*Hao Xiang Li,Michael Amir,Amanda Prorok*

Main category: cs.LG

TL;DR: 该文章介绍了一种名为 DiCoDe 的新型协同设计框架，旨在解决现有智能体-环境协同设计方法的可扩展性和样本效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有的协同设计方法在处理高维环境设计空间时效率低下，并且在联合优化中存在样本效率问题，这限制了它们在实际应用中的推广。

Method: DiCoDe 框架包含两个核心创新：一是引入了 Projected Universal Guidance (PUG) 采样技术，用于探索奖励最大化环境的分布，同时满足硬性约束；二是设计了一种评论家蒸馏机制，通过强化学习评论家共享知识，确保引导扩散模型适应不断演进的智能体策略。

Result: DiCoDe 方法在具有挑战性的多智能体环境协同设计基准测试中，例如仓库自动化、多智能体路径规划和风电场优化，取得了超越现有技术的性能。例如，在仓库环境中，DiCoDe 在使用减少66%的模拟样本的情况下，奖励提高了39%。

Conclusion: DiCoDe 框架为智能体-环境协同设计领域树立了新标准，并为协同设计在现实世界应用中取得成功奠定了基础。

Abstract: The agent-environment co-design paradigm jointly optimises agent policies and
environment configurations in search of improved system performance. With
application domains ranging from warehouse logistics to windfarm management,
co-design promises to fundamentally change how we deploy multi-agent systems.
However, current co-design methods struggle to scale. They collapse under
high-dimensional environment design spaces and suffer from sample inefficiency
when addressing moving targets inherent to joint optimisation. We address these
challenges by developing Diffusion Co-Design (DiCoDe), a scalable and
sample-efficient co-design framework pushing co-design towards practically
relevant settings. DiCoDe incorporates two core innovations. First, we
introduce Projected Universal Guidance (PUG), a sampling technique that enables
DiCoDe to explore a distribution of reward-maximising environments while
satisfying hard constraints such as spatial separation between obstacles.
Second, we devise a critic distillation mechanism to share knowledge from the
reinforcement learning critic, ensuring that the guided diffusion model adapts
to evolving agent policies using a dense and up-to-date learning signal.
Together, these improvements lead to superior environment-policy pairs when
validated on challenging multi-agent environment co-design benchmarks including
warehouse automation, multi-agent pathfinding and wind farm optimisation. Our
method consistently exceeds the state-of-the-art, achieving, for example, 39%
higher rewards in the warehouse setting with 66% fewer simulation samples. This
sets a new standard in agent-environment co-design, and is a stepping stone
towards reaping the rewards of co-design in real world domains.

</details>


### [56] [Predicting Weekly Fishing Concentration Zones through Deep Learning Integration of Heterogeneous Environmental Spatial Datasets](https://arxiv.org/abs/2511.02887)
*Chaitanya Rele,Aditya Rathod,Kaustubh Natu,Saurabh Kulkarni,Ajay Koli,Swapnali Makdey*

Main category: cs.LG

TL;DR: 本文提出了一种利用AI技术预测北印度洋潜在渔区（PFZs）的框架，旨在提高渔业效率并促进可持续捕捞。


<details>
  <summary>Details</summary>
Motivation: 渔民在寻找高效渔区方面面临不确定性，这影响了他们的生计。

Method: 该框架利用AI技术，通过分析海表温度和叶绿素浓度等海洋参数来预测潜在渔区（PFZs）。

Result: 初步结果表明，该框架能有效减少渔民的搜索时间、降低燃料消耗，并促进资源的高效利用。

Conclusion: 该AI辅助框架能够显著提升北印度洋的渔业效率和可持续性。

Abstract: The North Indian Ocean, including the Arabian Sea and the Bay of Bengal,
represents a vital source of livelihood for coastal communities, yet fishermen
often face uncertainty in locating productive fishing grounds. To address this
challenge, we present an AI-assisted framework for predicting Potential Fishing
Zones (PFZs) using oceanographic parameters such as sea surface temperature and
chlorophyll concentration. The approach is designed to enhance the accuracy of
PFZ identification and provide region-specific insights for sustainable fishing
practices. Preliminary results indicate that the framework can support
fishermen by reducing search time, lowering fuel consumption, and promoting
efficient resource utilization.

</details>


### [57] [Adaptive and Robust Data Poisoning Detection and Sanitization in Wearable IoT Systems using Large Language Models](https://arxiv.org/abs/2511.02894)
*W. K. M Mithsara,Ning Yang,Ahmed Imteaj,Hussein Zangoti,Abdur R. Shahid*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新颖的框架，该框架利用大型语言模型（LLM）在人类活动识别（HAR）系统中进行投毒检测和净化。


<details>
  <summary>Details</summary>
Motivation: 目前机器学习模型在HAR方面取得了进展，但它们越来越容易受到数据投毒攻击，这会损害这些系统的数据完整性和可靠性。传统的防御方法需要对大型标记数据集进行广泛的任务特定训练，这限制了在动态物联网环境中的适应性。

Method: 本文提出了一种利用大型语言模型（LLM）进行投毒检测和净化的新颖框架，该框架采用零样本、单样本和少样本学习范式。该方法结合了“角色扮演”提示（LLM扮演专家角色以情境化和评估传感器异常）和“逐步思考”推理（引导LLM推断原始传感器数据中的投毒指标和合理的清洁替代方案）。

Result: 该框架最大限度地减少了对大量数据集整理的依赖，并实现了实时、强大且适应性强的防御机制。通过对检测准确性、净化质量、延迟和通信成本的广泛评估，证明了LLM在提高可穿戴物联网系统安全性和可靠性方面的实用性和有效性。

Conclusion: 所提出的基于LLM的框架为可穿戴物联网系统中的投毒攻击提供了一种新颖、适应性强且鲁棒的防御机制，克服了传统方法的局限性。

Abstract: The widespread integration of wearable sensing devices in Internet of Things
(IoT) ecosystems, particularly in healthcare, smart homes, and industrial
applications, has required robust human activity recognition (HAR) techniques
to improve functionality and user experience. Although machine learning models
have advanced HAR, they are increasingly susceptible to data poisoning attacks
that compromise the data integrity and reliability of these systems.
Conventional approaches to defending against such attacks often require
extensive task-specific training with large, labeled datasets, which limits
adaptability in dynamic IoT environments. This work proposes a novel framework
that uses large language models (LLMs) to perform poisoning detection and
sanitization in HAR systems, utilizing zero-shot, one-shot, and few-shot
learning paradigms. Our approach incorporates \textit{role play} prompting,
whereby the LLM assumes the role of expert to contextualize and evaluate sensor
anomalies, and \textit{think step-by-step} reasoning, guiding the LLM to infer
poisoning indicators in the raw sensor data and plausible clean alternatives.
These strategies minimize reliance on curation of extensive datasets and enable
robust, adaptable defense mechanisms in real-time. We perform an extensive
evaluation of the framework, quantifying detection accuracy, sanitization
quality, latency, and communication cost, thus demonstrating the practicality
and effectiveness of LLMs in improving the security and reliability of wearable
IoT systems.

</details>


### [58] [Zero-shot data citation function classification using transformer-based large language models (LLMs)](https://arxiv.org/abs/2511.02936)
*Neil Byers,Ali Zaidi,Valerie Skye,Chris Beecroft,Kjiersten Fagnan*

Main category: cs.LG

TL;DR: 这篇论文探讨了利用大型语言模型（LLMs）自动化识别科学文献中数据使用案例的方法，以Llama 3.1-405B模型为例，并在零样本数据引用分类任务上取得了F1分数为0.674的成果，同时也指出了现有挑战。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用预训练、基于Transformer的大型语言模型（LLMs）来大规模描述已发表文献中的数据使用案例，以避免昂贵的人工标注和经典机器学习系统训练数据集的开发。

Method: 本文应用开源LLM Llama 3.1-405B为已知包含特定基因组数据集的出版物生成结构化的数据使用案例标签，并引入了一种新颖的评估框架来确定方法的有效性。

Result: 结果表明，在没有预定义类别的零样本数据引用分类任务中，该模型可以达到0.674的F1分数。

Conclusion: 尽管结果Llama 3.1-405B在零样本数据引用分类任务中表现出潜力，但仍面临数据可用性、提示过拟合、计算基础设施以及负责任的性能评估所需开销等挑战。

Abstract: Efforts have increased in recent years to identify associations between
specific datasets and the scientific literature that incorporates them. Knowing
that a given publication cites a given dataset, the next logical step is to
explore how or why that data was used. Advances in recent years with
pretrained, transformer-based large language models (LLMs) offer potential
means for scaling the description of data use cases in the published
literature. This avoids expensive manual labeling and the development of
training datasets for classical machine-learning (ML) systems. In this work we
apply an open-source LLM, Llama 3.1-405B, to generate structured data use case
labels for publications known to incorporate specific genomic datasets. We also
introduce a novel evaluation framework for determining the efficacy of our
methods. Our results demonstrate that the stock model can achieve an F1 score
of .674 on a zero-shot data citation classification task with no previously
defined categories. While promising, our results are qualified by barriers
related to data availability, prompt overfitting, computational infrastructure,
and the expense required to conduct responsible performance evaluation.

</details>


### [59] [Power Constrained Nonstationary Bandits with Habituation and Recovery Dynamics](https://arxiv.org/abs/2511.02944)
*Fengxu Li,Stephanie M. Carpenter,Matthew P. Buman,Yonatan Mintz*

Main category: cs.LG

TL;DR: 该论文提出了ROGUE-TS算法，一个针对ROGUE框架的Thompson采样算法，用于在微随机试验(MRTs)中平衡个性化推荐和群体层面学习，以实现次线性遗憾并保持高统计功效。


<details>
  <summary>Details</summary>
Motivation: 决策者在选择奖励未知且随时间演变的行动时面临挑战，特别是在行为健康干预等领域，行动的有效性可能因重复使用而降低（习惯化）或因不活动而恢复（恢复）。现有的算法虽然能计算次线性遗憾策略，但可能过分强调利用而导致探索不足，限制了群体层面效应的估计能力。这在需要平衡个体化推荐和群体层面效应的微随机试验（MRTs）中尤为重要。

Method: 本研究首先提出了ROGUE-TS算法，这是一个专门为ROGUE（Reducing or Gaining Unknown Efficacy）强盗框架设计的Thompson采样算法，并提供了次线性遗憾的理论保证。其次，引入了一种概率剪切程序，以平衡个性化和群体层面的学习，并量化了该程序在遗憾和最小探索概率之间的权衡。

Result: 在两个关于身体活动促进和躁郁症治疗的MRTs数据集上的验证表明，ROGUE-TS方法不仅比现有方法实现了更低的遗憾，而且通过剪切程序在不显著增加遗憾的情况下保持了较高的统计功效。

Conclusion: 本研究提出的方法使得在考虑个体行为动态的同时，能够可靠地检测治疗效果。对于设计MRTs的研究人员，该框架为平衡个性化与统计有效性提供了实用的指导。

Abstract: A common challenge for decision makers is selecting actions whose rewards are
unknown and evolve over time based on prior policies. For instance, repeated
use may reduce an action's effectiveness (habituation), while inactivity may
restore it (recovery). These nonstationarities are captured by the Reducing or
Gaining Unknown Efficacy (ROGUE) bandit framework, which models real-world
settings such as behavioral health interventions. While existing algorithms can
compute sublinear regret policies to optimize these settings, they may not
provide sufficient exploration due to overemphasis on exploitation, limiting
the ability to estimate population-level effects. This is a challenge of
particular interest in micro-randomized trials (MRTs) that aid researchers in
developing just-in-time adaptive interventions that have population-level
effects while still providing personalized recommendations to individuals. In
this paper, we first develop ROGUE-TS, a Thompson Sampling algorithm tailored
to the ROGUE framework, and provide theoretical guarantees of sublinear regret.
We then introduce a probability clipping procedure to balance personalization
and population-level learning, with quantified trade-off that balances regret
and minimum exploration probability. Validation on two MRT datasets concerning
physical activity promotion and bipolar disorder treatment shows that our
methods both achieve lower regret than existing approaches and maintain high
statistical power through the clipping procedure without significantly
increasing regret. This enables reliable detection of treatment effects while
accounting for individual behavioral dynamics. For researchers designing MRTs,
our framework offers practical guidance on balancing personalization with
statistical validity.

</details>


### [60] [Discrete Bayesian Sample Inference for Graph Generation](https://arxiv.org/abs/2511.03015)
*Ole Petersen,Marcel Kollovieh,Marten Lienen,Stephan Günnemann*

Main category: cs.LG

TL;DR: GraphBSI是一种新颖的基于贝叶斯样本推理（BSI）的一次性图生成模型。


<details>
  <summary>Details</summary>
Motivation: 传统的生成模型难以处理图数据的离散、无序性质，促使离散扩散和流匹配模型兴起。

Method: GraphBSI通过在分布参数的连续空间中迭代细化图的信念来处理离散结构。该方法将BSI表述为随机微分方程（SDE），并导出了通过近似分数函数保持边际分布的噪声控制SDE族。

Result: GraphBSI在分子和合成图生成方面表现出最先进的性能，在标准基准测试Moses和GuacaMol上优于现有的一次性图生成模型。

Conclusion: GraphBSI作为一种新颖的一次性图生成模型，在生成图结构数据方面具有显著优势。

Abstract: Generating graph-structured data is crucial in applications such as molecular
generation, knowledge graphs, and network analysis. However, their discrete,
unordered nature makes them difficult for traditional generative models,
leading to the rise of discrete diffusion and flow matching models. In this
work, we introduce GraphBSI, a novel one-shot graph generative model based on
Bayesian Sample Inference (BSI). Instead of evolving samples directly, GraphBSI
iteratively refines a belief over graphs in the continuous space of
distribution parameters, naturally handling discrete structures. Further, we
state BSI as a stochastic differential equation (SDE) and derive a
noise-controlled family of SDEs that preserves the marginal distributions via
an approximation of the score function. Our theoretical analysis further
reveals the connection to Bayesian Flow Networks and Diffusion models. Finally,
in our empirical evaluation, we demonstrate state-of-the-art performance on
molecular and synthetic graph generation, outperforming existing one-shot graph
generative models on the standard benchmarks Moses and GuacaMol.

</details>


### [61] [Inference-Time Personalized Alignment with a Few User Preference Queries](https://arxiv.org/abs/2511.02966)
*Victor-Alexandru Pădurean,Parameswaran Kamalaruban,Nachiket Kotalwar,Alkis Gotovos,Adish Singla*

Main category: cs.LG

TL;DR: 本文提出了一种名为UserAlign的个性化对齐方法，它能通过少量查询和成对响应比较来推断用户偏好，并在理论框架和实验中展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化对齐方法要么需要大量用户偏好查询，要么要求偏好以文本形式明确指定。这两种方法都有局限性，因此需要一种更高效、灵活的个性化对齐方法。

Method: UserAlign方法基于逻辑赌博机的最佳臂识别理论框架，通过少量查询（成对响应比较）来推断用户偏好。它从模型生成响应的固定池中选择个性化响应。关键思想是将用户反馈视为一致且无噪声，并将其纳入理论框架以快速识别最佳响应。

Result: 在涉及个性化文本和图像生成的多个任务上进行的实验结果表明，UserAlign在实现个性化对齐方面是有效的。

Conclusion: UserAlign通过其新颖的推理时个性化对齐方法，解决了现有方法中用户偏好获取效率低或指定不明确的问题，并通过少量用户查询实现了高效的个性化对齐。

Abstract: We study the problem of aligning a generative model's response with a user's
preferences. Recent works have proposed several different formulations for
personalized alignment; however, they either require a large amount of user
preference queries or require that the preference be explicitly specified as a
text input. In this paper, we propose a novel inference-time personalized
alignment method, UserAlign, that elicits the user's preferences with a few
queries as pairwise response comparisons. In particular, UserAlign builds on
the theoretical framework of best-arm identification in logistic bandits and
selects a personalized response from a fixed pool of the model's generated
responses. The key idea is to consider the user's feedback consistent and
noise-free, and incorporate it into the theoretical framework to identify the
best response quickly. Experimental results across several tasks, involving
personalized text and image generation, showcase the effectiveness of UserAlign
in achieving personalized alignment.

</details>


### [62] [Cross-Modal Alignment via Variational Copula Modelling](https://arxiv.org/abs/2511.03196)
*Feng Wu,Tsai Hor Chan,Fuying Wang,Guosheng Yin,Lequan Yu*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的“copula驱动多模态学习框架”来捕获不同模态之间的复杂交互作用，通过将copula模型作为对齐模态边缘分布的工具，解决了现有方法简化交互结构和高阶交互不充分的问题。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的应用中，各种数据模态是很常见的，例如电子健康记录、医学图像和临床笔记。为了从多个模态聚合各种信息，开发多模态学习方法至关重要。主要挑战在于如何适当地对齐和融合不同模态的表示形成一个联合分布，因为现有方法主要依赖于连接或Kronecker积，这简化了模态之间的交互结构。此外，潜表示的联合分布与高阶交互作用尚未得到充分探索。

Method: 本文提出了一种新的copula驱动多模态学习框架。该框架将copula模型解释为有效对齐模态边缘分布的工具。通过为每个模态假设一个高斯混合分布，并在联合分布上假设一个copula模型，该模型可以生成缺失模态的准确表示。

Result: 在公共MIMIC数据集上进行了大量实验，结果表明该模型优于其他竞争模型。

Conclusion: copula驱动的多模态学习框架通过有效对齐模态的边缘分布并建模复杂的交互作用，显著提高了多模态学习的性能，尤其是在处理缺失模态的表示生成方面表现出色。

Abstract: Various data modalities are common in real-world applications (e.g.,
electronic health records, medical images and clinical notes in healthcare). It
is essential to develop multimodal learning methods to aggregate various
information from multiple modalities. The main challenge is how to
appropriately align and fuse the representations of different modalities into a
joint distribution. Existing methods mainly rely on concatenation or the
Kronecker product, oversimplifying the interaction structure between modalities
and indicating a need to model more complex interactions. Additionally, the
joint distribution of latent representations with higher-order interactions is
underexplored. Copula is a powerful statistical structure for modelling the
interactions among variables, as it naturally bridges the joint distribution
and marginal distributions of multiple variables. We propose a novel
copula-driven multimodal learning framework, which focuses on learning the
joint distribution of various modalities to capture the complex interactions
among them. The key idea is to interpret the copula model as a tool to align
the marginal distributions of the modalities efficiently. By assuming a
Gaussian mixture distribution for each modality and a copula model on the joint
distribution, our model can generate accurate representations for missing
modalities. Extensive experiments on public MIMIC datasets demonstrate the
superior performance of our model over other competitors. The code is available
at https://github.com/HKU-MedAI/CMCM.

</details>


### [63] [An Efficient Classification Model for Cyber Text](https://arxiv.org/abs/2511.03107)
*Md Sakhawat Hossen,Md. Zashid Iqbal Borshon,A. S. M. Badrudduza*

Main category: cs.LG

TL;DR: 深度学习带来高碳足迹，本文提出 CTF-IDF 与 IRLBA 结合的传统机器学习方法，旨在降低文本分析的计算成本和碳排放，同时保持较高准确性。


<details>
  <summary>Details</summary>
Motivation: 针对深度学习在文本分析领域算力需求大、碳足迹高的问题，探索更高效、低碳的替代方案。

Method: 1. 改进 TF-IDF 算法，提出 Clement Term Frequency-Inverse Document Frequency (CTF-IDF) 进行数据预处理。2. 引入更快的 IRLBA 算法进行降维。3. 将 CTF-IDF 和 IRLBA 应用于传统机器学习文本分析流程。

Result: 与深度学习方法相比，所提出的方法在碳足迹方面计算效率更高、速度更快、计算强度更低，且准确性损失较小。实验结果显示，该方法在时间复杂度上显著降低，模型准确性也得到提升。

Conclusion: 将 CTF-IDF 和 IRLBA 引入传统文本分析流程，能够有效降低计算成本和碳排放，同时保持较高的模型性能，为文本分析提供了一种更绿色、高效的替代方案。

Abstract: The uprising of deep learning methodology and practice in recent years has
brought about a severe consequence of increasing carbon footprint due to the
insatiable demand for computational resources and power. The field of text
analytics also experienced a massive transformation in this trend of
monopolizing methodology. In this paper, the original TF-IDF algorithm has been
modified, and Clement Term Frequency-Inverse Document Frequency (CTF-IDF) has
been proposed for data preprocessing. This paper primarily discusses the
effectiveness of classical machine learning techniques in text analytics with
CTF-IDF and a faster IRLBA algorithm for dimensionality reduction. The
introduction of both of these techniques in the conventional text analytics
pipeline ensures a more efficient, faster, and less computationally intensive
application when compared with deep learning methodology regarding carbon
footprint, with minor compromise in accuracy. The experimental results also
exhibit a manifold of reduction in time complexity and improvement of model
accuracy for the classical machine learning methods discussed further in this
paper.

</details>


### [64] [Decoupled Entropy Minimization](https://arxiv.org/abs/2511.03256)
*Jing Ma,Hanlin Li,Xiang Xiang*

Main category: cs.LG

TL;DR: 我们提出了自适应解耦熵最小化（AdaDEM）方法，通过解耦EM并解决其局限性，在各种不完全监督学习任务中取得了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 熵最小化（EM）在机器学习中具有减少类别重叠、弥合领域差距和限制不确定性的益处，但其潜力受到限制。

Method: 我们将经典的EM重构并解耦为两部分：集群聚合驱动因子（CADF）和梯度缓解校准器（GMC）。为了解决经典EM的局限性，我们提出了自适应解耦熵最小化（AdaDEM），它对CADF带来的奖励进行归一化，并采用边际熵校准器（MEC）取代GMC。

Result: AdaDEM在噪声和动态环境中的各种不完全监督学习任务中，其性能优于DEM*（经典EM的上限变体），并取得了卓越的性能。

Conclusion: 我们揭示了经典EM的局限性，并提出了AdaDEM来解决这些问题。AdaDEM在多个任务中表现出色，证明了其在不完全监督学习中的有效性。

Abstract: Entropy Minimization (EM) is beneficial to reducing class overlap, bridging
domain gap, and restricting uncertainty for various tasks in machine learning,
yet its potential is limited. To study the internal mechanism of EM, we
reformulate and decouple the classical EM into two parts with opposite effects:
cluster aggregation driving factor (CADF) rewards dominant classes and prompts
a peaked output distribution, while gradient mitigation calibrator (GMC)
penalizes high-confidence classes based on predicted probabilities.
Furthermore, we reveal the limitations of classical EM caused by its coupled
formulation: 1) reward collapse impedes the contribution of high-certainty
samples in the learning process, and 2) easy-class bias induces misalignment
between output distribution and label distribution. To address these issues, we
propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the
reward brought from CADF and employs a marginal entropy calibrator (MEC) to
replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM,
and achieves superior performance across various imperfectly supervised
learning tasks in noisy and dynamic environments.

</details>


### [65] [Adaptive-Sensorless Monitoring of Shipping Containers](https://arxiv.org/abs/2511.03022)
*Lingqing Shen,Chi Heem Wong,Misaki Mito,Arnab Chakrabarti*

Main category: cs.LG

TL;DR: 本文介绍了一种“自适应无传感器”监测模型，用于纠正无传感器集装箱监测模型中的系统偏差，在业内最大的数据集上，该模型在温度和相对湿度上均优于现有的无传感器模型。


<details>
  <summary>Details</summary>
Motivation: 在货运过程中，监测集装箱的内部温度和湿度对于防止货物质量下降至关重要。传统的无传感器监测方法在预测集装箱内部环境时存在系统误差，导致预测结果与实际数据之间存在显著差异，并可能误导用户。

Method: 本文提出了一种“残差校正法”，这是一种通用的框架，用于在观察实时遥测数据后纠正无传感器模型中的系统偏差。通过这种方法，构建了“自适应无传感器”监测模型。研究人员在一个包含348万个数据点的大型数据集上训练和评估了这些模型。

Result: 与基线无传感器模型相比，“自适应无传感器”模型取得了显著的改进。在模拟数据的保留集上进行评估时，温度的平均平均绝对误差（MAE）为2.24 $\sim$ 2.31°C（无传感器模型为2.43°C），相对湿度的平均绝对误差为5.72 $\sim$ 7.09%（无传感器模型为7.99%）。温度的平均均方根误差（RMSE）为3.19 $\sim$ 3.26°C（无传感器模型为3.38°C），相对湿度的平均均方根误差为7.70 $\sim$ 9.12%（无传感器模型为10.0%）。

Conclusion: 自适应无传感器模型能够实现更准确的货物监测、早期风险检测，并减少全球航运对完全连接的依赖。这的依赖，从而在集装箱运输过程中提供更好的质量保障。

Abstract: Monitoring the internal temperature and humidity of shipping containers is
essential to preventing quality degradation during cargo transportation.
Sensorless monitoring -- machine learning models that predict the internal
conditions of the containers using exogenous factors -- shows promise as an
alternative to monitoring using sensors. However, it does not incorporate
telemetry information and correct for systematic errors, causing the
predictions to differ significantly from the live data and confusing the users.
In this paper, we introduce the residual correction method, a general framework
for correcting for systematic biases in sensorless models after observing live
telemetry data. We call this class of models ``adaptive-sensorless''
monitoring. We train and evaluate adaptive-sensorless models on the 3.48
million data points -- the largest dataset of container sensor readings ever
used in academic research -- and show that they produce consistent improvements
over the baseline sensorless models. When evaluated on the holdout set of the
simulated data, they achieve average mean absolute errors (MAEs) of 2.24 $\sim$
2.31$^\circ$C (vs 2.43$^\circ$C by sensorless) for temperature and 5.72 $\sim$
7.09% for relative humidity (vs 7.99% by sensorless) and average root
mean-squared errors (RMSEs) of 3.19 $\sim$ 3.26$^\circ$C for temperature (vs
3.38$^\circ$C by sensorless) and 7.70 $\sim$ 9.12% for relative humidity (vs
10.0% by sensorless). Adaptive-sensorless models enable more accurate cargo
monitoring, early risk detection, and less dependence on full connectivity in
global shipping.

</details>


### [66] [Why Less is More (Sometimes): A Theory of Data Curation](https://arxiv.org/abs/2511.03492)
*Elvis Dohmatob,Mohammad Pezeshki,Reyhane Askari-Hemmat*

Main category: cs.LG

TL;DR: 该文章提出了一个理论框架，用于解决现代机器学习中的一个核心悖论：何时使用更少的数据会更好？


<details>
  <summary>Details</summary>
Motivation: 经典标度定律认为“越多越好”，但诸如 LIMO 和 S1 等方法在小型、精心策划的数据集上取得了卓越的性能，这挑战了经典标度定律，因此需要研究数据管理策略。

Method: 我们研究了数据管理策略，其中一个不完美的预言机根据训练样本的难度和正确性来选择训练样本。 我们在标签不可知和标签感知管理规则下，给出了测试误差的精确标度定律曲线。

Result: 在某些条件下，小型精选数据集的表现优于完整数据集。我们验证了这些理论，并通过 ImageNet 上的经验结果证实了我们的预测，即何时管理可以提高准确性，甚至可以减轻模型崩溃。

Conclusion: 精选的小数据集在特定条件下可以超越完整数据集，并且该框架为大型语言模型（LLM）数学推理中观察到的相互矛盾的管理策略提供了合理的解释。

Abstract: This paper introduces a theoretical framework to resolve a central paradox in
modern machine learning: When is it better to use less data? This question has
become critical as classical scaling laws suggesting ``more is more'' (Sun et
al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et
al., 2025; Muenighoff et al., 2025), which achieve superior performance with
small, aggressively curated datasets. Here, we study data curation strategies
where an imperfect oracle selects the training examples according to their
difficulty and correctness. Our results provide exact scaling law curves for
test error under both label-agnostic and label-aware curation rules, revealing
when and why keeping only a subset of data can improve generalization. In
contrast to classical scaling laws, we show that under certain conditions,
small curated datasets can outperform full datasets, and we provide analytical
conditions for this by deriving precise phase transition curves tied to data
size and quality. We validate these theoretical claims with empirical results
on ImageNet, confirming our predictions about when curation improves accuracy
and can even mitigate model collapse. Furthermore, our framework provides a
principled explanation for the contradictory curation strategies recently
observed in LLM mathematical reasoning.

</details>


### [67] [Leveraging Discrete Function Decomposability for Scientific Design](https://arxiv.org/abs/2511.03032)
*James C. Bowden,Sergey Levine,Jennifer Listgarten*

Main category: cs.LG

TL;DR: DADO是一种新的分布式优化算法，它能利用设计变量上的连接树所定义的任何可分解性，以提高优化效率。


<details>
  <summary>Details</summary>
Motivation: 目前AI驱动的科学和工程领域，通常需要在计算机中根据用户指定的属性设计离散对象。为了提高设计效率，需要一种新的分布式优化算法。

Method: DADO在设计变量上使用连接树来定义可分解性，从而提高优化效率。DADO采用软因子化的“搜索分布”（一种学习到的生成模型），以有效导航搜索空间，调用图消息传递来协调跨链接因素的优化。

Result: DADO算法可以利用设计变量上的连接树所定义的任何可分解性，以提高优化效率。

Conclusion: DADO算法通过利用设计变量的连接树分解性，能够更有效地优化离散对象设计。

Abstract: In the era of AI-driven science and engineering, we often want to design
discrete objects in silico according to user-specified properties. For example,
we may wish to design a protein to bind its target, arrange components within a
circuit to minimize latency, or find materials with certain properties. Given a
property predictive model, in silico design typically involves training a
generative model over the design space (e.g., protein sequence space) to
concentrate on designs with the desired properties. Distributional optimization
-- which can be formalized as an estimation of distribution algorithm or as
reinforcement learning policy optimization -- finds the generative model that
maximizes an objective function in expectation. Optimizing a distribution over
discrete-valued designs is in general challenging because of the combinatorial
nature of the design space. However, many property predictors in scientific
applications are decomposable in the sense that they can be factorized over
design variables in a way that could in principle enable more effective
optimization. For example, amino acids at a catalytic site of a protein may
only loosely interact with amino acids of the rest of the protein to achieve
maximal catalytic activity. Current distributional optimization algorithms are
unable to make use of such decomposability structure. Herein, we propose and
demonstrate use of a new distributional optimization algorithm,
Decomposition-Aware Distributional Optimization (DADO), that can leverage any
decomposability defined by a junction tree on the design variables, to make
optimization more efficient. At its core, DADO employs a soft-factorized
"search distribution" -- a learned generative model -- for efficient navigation
of the search space, invoking graph message-passing to coordinate optimization
across linked factors.

</details>


### [68] [Towards Formalizing Reinforcement Learning Theory](https://arxiv.org/abs/2511.03618)
*Shangtong Zhang*

Main category: cs.LG

TL;DR: 本文使用Lean 4定理证明器，基于Mathlib库，形式化验证了Q-learning和线性时序差分（TD）学习在马尔可夫样本下的几乎必然收敛性。


<details>
  <summary>Details</summary>
Motivation: Q-learning和线性TD学习是早期且极具影响力的强化学习算法。研究它们的收敛性不仅是RL领域早期发展的重要课题，在当下也受到越来越多的关注。

Method: 本文基于Robbins-Siegmund定理，在一个统一的框架下，形式化验证了Q-learning和线性TD学习的几乎必然收敛性。

Result: 成功形式化验证了Q-learning和线性TD学习在马尔可夫样本下的几乎必然收敛性，并开发了一个可扩展的框架。

Conclusion: 本文在完全形式化收敛性强化学习结果方面迈出了重要一步。

Abstract: In this paper, we formalize the almost sure convergence of $Q$-learning and
linear temporal difference (TD) learning with Markovian samples using the Lean
4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are
among the earliest and most influential reinforcement learning (RL) algorithms.
The investigation of their convergence properties is not only a major research
topic during the early development of the RL field but also receives increasing
attention nowadays. This paper formally verifies their almost sure convergence
in a unified framework based on the Robbins-Siegmund theorem. The framework
developed in this work can be easily extended to convergence rates and other
modes of convergence. This work thus makes an important step towards fully
formalizing convergent RL results. The code is available at
https://github.com/ShangtongZhang/rl-theory-in-lean.

</details>


### [69] [Data-Efficient Realized Volatility Forecasting with Vision Transformers](https://arxiv.org/abs/2511.03046)
*Emi Soroka,Artem Arzyn*

Main category: cs.LG

TL;DR: 这篇论文探讨了将Vision Transformer（ViT）模型应用于期权数据，以预测未来30天资产的已实现波动率，并取得了积极的初步结果。


<details>
  <summary>Details</summary>
Motivation: 传统的金融机器学习方法在预测金融数据时效果不佳，而深度学习方法（特别是transformer架构）在金融时间序列预测中展现出潜力，但鲜有应用于期权数据。

Method: 本研究将Vision Transformer (ViT) 架构用于期权数据，通过输入隐含波动率曲面（以及日期信息），训练模型预测资产在未来30天的已实现波动率。

Result: ViT模型能够从隐含波动率曲面中学习季节性模式和非线性特征，这表明ViT在期权数据建模方面具有潜力。

Conclusion: 将ViT模型应用于期权数据预测已实现波动率是一个有前景的方向，未来的研究可以进一步探索其在金融建模中的应用。

Abstract: Recent work in financial machine learning has shown the virtue of complexity:
the phenomenon by which deep learning methods capable of learning highly
nonlinear relationships outperform simpler approaches in financial forecasting.
While transformer architectures like Informer have shown promise for financial
time series forecasting, the application of transformer models for options data
remains largely unexplored. We conduct preliminary studies towards the
development of a transformer model for options data by training the Vision
Transformer (ViT) architecture, typically used in modern image recognition and
classification systems, to predict the realized volatility of an asset over the
next 30 days from its implied volatility surface (augmented with date
information) for a single day. We show that the ViT can learn seasonal patterns
and nonlinear features from the IV surface, suggesting a promising direction
for model development.

</details>


### [70] [The Curved Spacetime of Transformer Architectures](https://arxiv.org/abs/2511.03060)
*Riccardo Di Sipio,Jairo Diaz-Rodriguez,Luis Serrano*

Main category: cs.LG

TL;DR: 本文提出了一个理解Transformer语言模型的几何框架，将其与广义相对论进行了明确的类比。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer语言模型内部运作机制，特别是注意力机制如何影响表征空间中的信息处理，并引入几何视角（类比广义相对论）来解释这些复杂现象。

Method: 1. 提出几何框架：将Queries和Keys诱导的有效度量，以及注意力作为离散连接来实现价值向量在tokens间的平行传输。 2. 堆叠层作为离散时间切片，使token表征在弯曲流形上演化。 3. 反向传播作为最小作用量原理，塑造参数空间中最小化损失的轨迹。 4. 设计实验验证曲率的存在和影响： (i) 可视化一个完整段落的曲率景观，揭示局部转角如何随tokens和层变化。 (ii) 通过模拟表明，尖锐/平坦角度的过多计数以及更长的长弦比不能用维度或偶然性来解释。 (iii) 受爱因斯坦日食实验启发，在受控上下文编辑下探测偏转，证明了嵌入轨迹中可测量的、意义一致的弯曲，证实了注意力引起的曲率。

Result: 1. 证明Transformer模型中的token嵌入在特征空间中不沿直线路径行进，而是其层间步骤会因嵌入空间曲率引起的交互而弯曲和重新定向。 2. 发现局部转角在tokens和层之间变化。 3. 观察到尖锐/平坦角度过多和长弦比不能用维度或偶然性解释。 4. 通过受控上下文编辑实验，证实了注意力引起的曲率导致嵌入轨迹中出现可测量且有意义的弯曲。

Conclusion: Transformer中的自注意力机制会在表征空间中产生“曲率”，导致token嵌入在特征空间中以弯曲路径演进，这与广义相对论中质量导致时空弯曲有相似之处。这一几何框架可以帮助我们更好地理解Transformer的工作原理及其内部的信息处理方式。

Abstract: We present a geometric framework for understanding Transformer-based language
models, drawing an explicit analogy to General Relativity. Queries and keys
induce an effective metric on representation space, and attention acts as a
discrete connection that implements parallel transport of value vectors across
tokens. Stacked layers provide discrete time-slices through which token
representations evolve on this curved manifold, while backpropagation plays the
role of a least-action principle that shapes loss-minimizing trajectories in
parameter space. If this analogy is correct, token embeddings should not
traverse straight paths in feature space; instead, their layer-wise steps
should bend and reorient as interactions mediated by embedding space curvature.
To test this prediction, we design experiments that expose both the presence
and the consequences of curvature: (i) we visualize a curvature landscape for a
full paragraph, revealing how local turning angles vary across tokens and
layers; (ii) we show through simulations that excess counts of sharp/flat
angles and longer length-to-chord ratios are not explainable by dimensionality
or chance; and (iii) inspired by Einstein's eclipse experiment, we probe
deflection under controlled context edits, demonstrating measurable,
meaning-consistent bends in embedding trajectories that confirm
attention-induced curvature.

</details>


### [71] [Online Learning to Rank under Corruption: A Robust Cascading Bandits Approach](https://arxiv.org/abs/2511.03074)
*Fatemeh Ghaffari,Siddarth Sitaraman,Xutong Liu,Xuchuang Wang,Mohammad Hajiesmaili*

Main category: cs.LG

TL;DR: 这篇文章介绍了一种名为MSUCB的稳健算法，它可以抵御点击欺诈等恶意行为，并在在线学习排序中表现出色，在没有恶意行为时实现最优对数遗憾，在有恶意行为时也能保持良好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的在线学习排序（OLTR）系统容易受到点击欺诈和其他恶意操纵的影响，这些行为会误导学习过程并降低用户体验，因此需要一种能够抵御此类攻击的稳健算法。

Method: 本文提出了一种名为MSUCB的稳健算法，该算法结合了一种新颖的“中位数均值（mean-of-medians）”估计器，该估计器在没有腐败的情况下表现得像标准均值一样，并且在存在腐败时通过中位数步骤过滤掉异常值和被破坏的样本，从而使估计值接近真实值。

Result: MSUCB算法在没有腐败的情况下实现了最优对数遗憾，并在腐败情况下优雅地降低性能，遗憾值仅通过与总腐败相关的附加项增加。

Conclusion: MSUCB算法在真实世界数据集上的综合实验表明，它始终优于现有方法，并保持强大的鲁棒性，特别是比两种最先进的方法分别提高了97.35%和91.60%的遗憾改进。

Abstract: Online learning to rank (OLTR) studies how to recommend a short ranked list
of items from a large pool and improves future rankings based on user clicks.
This setting is commonly modeled as cascading bandits, where the objective is
to maximize the likelihood that the user clicks on at least one of the
presented items across as many timesteps as possible. However, such systems are
vulnerable to click fraud and other manipulations (i.e., corruption), where
bots or paid click farms inject corrupted feedback that misleads the learning
process and degrades user experience. In this paper, we propose MSUCB, a robust
algorithm that incorporates a novel mean-of-medians estimator, which to our
knowledge is applied to bandits with corruption setting for the first time.
This estimator behaves like a standard mean in the absence of corruption, so no
cost is paid for robustness. Under corruption, the median step filters out
outliers and corrupted samples, keeping the estimate close to its true value.
Updating this estimate at every round further accelerates empirical convergence
in experiments. Hence, MSUCB achieves optimal logarithmic regret in the absence
of corruption and degrades gracefully under corruptions, with regret increasing
only by an additive term tied to the total corruption. Comprehensive and
extensive experiments on real-world datasets further demonstrate that our
approach consistently outperforms prior methods while maintaining strong
robustness. In particular, it achieves a \(97.35\%\) and a \(91.60\%\) regret
improvement over two state-of-the-art methods.

</details>


### [72] [Sparse, self-organizing ensembles of local kernels detect rare statistical anomalies](https://arxiv.org/abs/2511.03095)
*Gaia Grosso,Sai Sumedh R. Hindupur,Thomas Fel,Samuel Bright-Thonney,Philip Harris,Demba Ba*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为SparKer的稀疏高斯核集成方法，用于解决现代人工智能在异常检测中表示统计特性控制不力的问题。SparKer通过强制稀疏性、保持局部性和促进竞争来适应性地划分表示空间，从而有效地检测和解释异常。


<details>
  <summary>Details</summary>
Motivation: 现代人工智能在提取数据表示方面取得了巨大进步，但这些表示的统计特性控制不佳，导致异常检测方法失效。弱小或稀有信号可能隐藏在正常数据的表象规律中，使得异常检测和解释面临挑战。

Method: 本文提出了一类自组织局部核，并以SparKer为例进行说明。SparKer是一个稀疏的高斯核集成，采用半监督Neyman-Pearson框架进行训练，用于局部建模包含异常样本与正常无异常参考之间的似然比。该方法强制稀疏性以保证简洁性，保持局部性以保留几何敏感性，并促进竞争以提高模型容量的有效分配。

Result: SparKer在科学发现、开放世界新颖性检测、入侵检测和生成模型验证等高维问题上表现出有效性。即使只包含少量核的集成，也能在数千维的表示空间中识别出统计显著的异常位置，突显了该方法的可解释性、效率和可扩展性。

Conclusion: SparKer通过自组织局部核的概念，在最少先验信息下，有效地解决了异常检测中表示统计特性控制不力的问题，为高维环境下的异常检测提供了一种可解释、高效且可扩展的解决方案。

Abstract: Modern artificial intelligence has revolutionized our ability to extract rich
and versatile data representations across scientific disciplines. Yet, the
statistical properties of these representations remain poorly controlled,
causing misspecified anomaly detection (AD) methods to falter. Weak or rare
signals can remain hidden within the apparent regularity of normal data,
creating a gap in our ability to detect and interpret anomalies. We examine
this gap and identify a set of structural desiderata for detection methods
operating under minimal prior information: sparsity, to enforce parsimony;
locality, to preserve geometric sensitivity; and competition, to promote
efficient allocation of model capacity. These principles define a class of
self-organizing local kernels that adaptively partition the representation
space around regions of statistical imbalance. As an instantiation of these
principles, we introduce SparKer, a sparse ensemble of Gaussian kernels trained
within a semi-supervised Neyman--Pearson framework to locally model the
likelihood ratio between a sample that may contain anomalies and a nominal,
anomaly-free reference. We provide theoretical insights into the mechanisms
that drive detection and self-organization in the proposed model, and
demonstrate the effectiveness of this approach on realistic high-dimensional
problems of scientific discovery, open-world novelty detection, intrusion
detection, and generative-model validation. Our applications span both the
natural- and computer-science domains. We demonstrate that ensembles containing
only a handful of kernels can identify statistically significant anomalous
locations within representation spaces of thousands of dimensions, underscoring
both the interpretability, efficiency and scalability of the proposed approach.

</details>


### [73] [FP-AbDiff: Improving Score-based Antibody Design by Capturing Nonequilibrium Dynamics through the Underlying Fokker-Planck Equation](https://arxiv.org/abs/2511.03113)
*Jiameng Chen,Yida Xiong,Kun Li,Hongzhi Zhang,Xiantao Cai,Wenbin Hu,Jia Wu*

Main category: cs.LG

TL;DR: FP-AbDiff是一个开创性的抗体生成器，它在生成过程中强制遵循Fokker-Planck方程（FPE）物理，能生成高精度的抗体结构，在CDR-H3设计和六CDR协同设计任务中均超越了现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在计算抗体设计中存在两个主要限制：缺乏动力学一致性导致物理上不合理的结构，以及由于数据稀缺和结构偏差导致的泛化能力差。

Method: FP-AbDiff通过在CDR几何的混合流形（R^3 x SO(3)）上最小化新颖的FPE残差损失，强制局部学习的去噪分数汇聚成全局连贯的概率流。这种物理信息正则化器与最先进的SE(3)等变扩散框架中的深度生物先验协同集成。

Result: 在de novo CDR-H3设计中，FP-AbDiff实现了0.99 Å的平均均方根偏差，比之前的最先进模型AbX提高了25%，报告的接触氨基酸恢复率最高达39.91%。在更具挑战性的六CDR协同设计任务中，该模型将平均全链均方根偏差降低了约15%，并在功能主导的CDR-H3环上实现了最高的氨基酸恢复率（45.67%）。

Conclusion: FP-AbDiff通过将生成动力学与物理定律对齐，增强了抗体设计的鲁棒性和泛化能力，为物理上忠实且功能可行的抗体设计建立了原则性方法。

Abstract: Computational antibody design holds immense promise for therapeutic
discovery, yet existing generative models are fundamentally limited by two core
challenges: (i) a lack of dynamical consistency, which yields physically
implausible structures, and (ii) poor generalization due to data scarcity and
structural bias. We introduce FP-AbDiff, the first antibody generator to
enforce Fokker-Planck Equation (FPE) physics along the entire generative
trajectory. Our method minimizes a novel FPE residual loss over the mixed
manifold of CDR geometries (R^3 x SO(3)), compelling locally-learned denoising
scores to assemble into a globally coherent probability flow. This
physics-informed regularizer is synergistically integrated with deep biological
priors within a state-of-the-art SE(3)-equivariant diffusion framework.
Rigorous evaluation on the RAbD benchmark confirms that FP-AbDiff establishes a
new state-of-the-art. In de novo CDR-H3 design, it achieves a mean Root Mean
Square Deviation of 0.99 {\AA} when superposing on the variable region, a 25%
improvement over the previous state-of-the-art model, AbX, and the highest
reported Contact Amino Acid Recovery of 39.91%. This superiority is underscored
in the more challenging six-CDR co-design task, where our model delivers
consistently superior geometric precision, cutting the average full-chain Root
Mean Square Deviation by ~15%, and crucially, achieves the highest full-chain
Amino Acid Recovery on the functionally dominant CDR-H3 loop (45.67%). By
aligning generative dynamics with physical laws, FP-AbDiff enhances robustness
and generalizability, establishing a principled approach for physically
faithful and functionally viable antibody design.

</details>


### [74] [An Augmentation Overlap Theory of Contrastive Learning](https://arxiv.org/abs/2511.03114)
*Qi Zhang,Yifei Wang,Yisen Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的数据增强重叠理论，以解释自监督对比学习的成功，并通过该理论开发了一种无监督的表示评估指标。


<details>
  <summary>Details</summary>
Motivation: 自监督对比学习在各种任务中取得了巨大成功，但其工作机制尚不清楚。

Method: 首先，在广泛采用的条件独立性假设下提供了最紧密的界限。然后，将条件独立性假设放宽到更实用的数据增强重叠假设，并推导出下游性能的渐近封闭界限。此外，从数据增强重叠的角度，开发了一种用于对比学习表示评估的无监督指标。

Result: 数据增强重叠理论揭示了在积极数据增强下，不同类别内样本的支持将变得更加重叠，从而通过对齐正样本（同一样本的增强视图）使对比学习将类别内样本聚类在一起。开发的无监督指标与下游性能良好对齐，几乎不依赖于额外模块。

Conclusion: 数据增强重叠理论可以很好地解释自监督对比学习的成功，并且基于该理论开发的无监督评估指标可以有效地评估表示性能。

Abstract: Recently, self-supervised contrastive learning has achieved great success on
various tasks. However, its underlying working mechanism is yet unclear. In
this paper, we first provide the tightest bounds based on the widely adopted
assumption of conditional independence. Further, we relax the conditional
independence assumption to a more practical assumption of augmentation overlap
and derive the asymptotically closed bounds for the downstream performance. Our
proposed augmentation overlap theory hinges on the insight that the support of
different intra-class samples will become more overlapped under aggressive data
augmentations, thus simply aligning the positive samples (augmented views of
the same sample) could make contrastive learning cluster intra-class samples
together. Moreover, from the newly derived augmentation overlap perspective, we
develop an unsupervised metric for the representation evaluation of contrastive
learning, which aligns well with the downstream performance almost without
relying on additional modules. Code is available at
https://github.com/PKU-ML/GARC.

</details>


### [75] [From Insight to Exploit: Leveraging LLM Collaboration for Adaptive Adversarial Text Generation](https://arxiv.org/abs/2511.03128)
*Najrin Sultana,Md Rafi Ur Rashid,Kang Gu,Shagufta Mehnaz*

Main category: cs.LG

TL;DR: 这篇论文介绍了 StaDec 和 DyDec 两种新的攻击框架，旨在利用对大型语言模型（LLMs）的理解，系统地生成动态和自适应的对抗性示例。这些示例在保留语义相似性的同时，能够有效地欺骗目标 LLM，并可用于评估 LLM 的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在不同任务上表现出色，但其在敏感任务上的鲁棒性尚未得到充分评估。

Method: 本文引入了 Static Deceptor (StaDec) 和 Dynamic Deceptor (DyDec) 两种攻击框架，它们通过利用对 LLM 的理解来生成动态和自适应的对抗性示例。攻击过程采用自动化的 LLM 驱动管道，生成微妙且自然的对抗性输入，这些输入与原始文本在语义上相似，但能有效欺骗目标 LLM。

Result: 攻击能够生成微妙且自然的对抗性输入，这些输入保留了与原始文本的语义相似性，同时有效地欺骗了目标 LLM。这些攻击可以在 LLM 的进步中演变，并对攻击者未知的模型表现出强大的可转移性。

Conclusion: 这项工作提供了一种系统性方法来评估 LLM 的鲁棒性，并通过引入 StaDec 和 DyDec 两种攻击框架，证明了在保留语义相似性的前提下生成有效欺骗 LLM 的对抗性示例的可行性。同时，该研究强调了 LLM 驱动的自动化攻击管道的优势以及攻击在未知模型上的可转移性，为 LLM 的自我评估提供了新途径。

Abstract: LLMs can provide substantial zero-shot performance on diverse tasks using a
simple task prompt, eliminating the need for training or fine-tuning. However,
when applying these models to sensitive tasks, it is crucial to thoroughly
assess their robustness against adversarial inputs. In this work, we introduce
Static Deceptor (StaDec) and Dynamic Deceptor (DyDec), two innovative attack
frameworks designed to systematically generate dynamic and adaptive adversarial
examples by leveraging the understanding of the LLMs. We produce subtle and
natural-looking adversarial inputs that preserve semantic similarity to the
original text while effectively deceiving the target LLM. By utilizing an
automated, LLM-driven pipeline, we eliminate the dependence on external
heuristics. Our attacks evolve with the advancements in LLMs and demonstrate
strong transferability across models unknown to the attacker. Overall, this
work provides a systematic approach for the self-assessment of an LLM's
robustness. We release our code and data at
https://github.com/Shukti042/AdversarialExample.

</details>


### [76] [Test Time Adaptation Using Adaptive Quantile Recalibration](https://arxiv.org/abs/2511.03148)
*Paria Mehrbod,Pedro Vianna,Geraldin Nanfack,Guy Wolf,Eugene Belilovsky*

Main category: cs.LG

TL;DR: AQR，一种新的测试时自适应方法，通过校准预激活分布的分位数来提高模型在域偏移时的泛化能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的域适应方法需要目标域的先验知识或模型再训练，限制了其在动态或资源受限环境中的实用性。现有的测试时自适应方法则无法捕捉复杂的激活分布或受限于特定的归一化层。

Method: 本文提出了自适应分位数重新校准（AQR）方法，这是一种在测试时进行调整的技术，它通过在通道级别对齐分位数来修改预激活分布。AQR能够捕捉激活分布的完整形状，并适用于使用BatchNorm、GroupNorm或LayerNorm的各种架构。为了解决在不同批量大小下估计分布尾部的挑战，AQR引入了一种鲁棒的尾部校准策略，提高了稳定性和精度。该方法利用在训练时计算的源域统计数据，实现了无需模型再训练的无监督适应。

Result: 在CIFAR-10-C、CIFAR-100-C和ImageNet-C数据集上，AQR在多种架构下实现了鲁棒的自适应性，并且优于现有的测试时自适应基线方法。

Conclusion: AQR在动态和不可预测的数据分布的真实场景中具有部署潜力。

Abstract: Domain adaptation is a key strategy for enhancing the generalizability of
deep learning models in real-world scenarios, where test distributions often
diverge significantly from the training domain. However, conventional
approaches typically rely on prior knowledge of the target domain or require
model retraining, limiting their practicality in dynamic or
resource-constrained environments. Recent test-time adaptation methods based on
batch normalization statistic updates allow for unsupervised adaptation, but
they often fail to capture complex activation distributions and are constrained
to specific normalization layers. We propose Adaptive Quantile Recalibration
(AQR), a test-time adaptation technique that modifies pre-activation
distributions by aligning quantiles on a channel-wise basis. AQR captures the
full shape of activation distributions and generalizes across architectures
employing BatchNorm, GroupNorm, or LayerNorm. To address the challenge of
estimating distribution tails under varying batch sizes, AQR incorporates a
robust tail calibration strategy that improves stability and precision. Our
method leverages source-domain statistics computed at training time, enabling
unsupervised adaptation without retraining models. Experiments on CIFAR-10-C,
CIFAR-100-C, and ImageNet-C across multiple architectures demonstrate that AQR
achieves robust adaptation across diverse settings, outperforming existing
test-time adaptation baselines. These results highlight AQR's potential for
deployment in real-world scenarios with dynamic and unpredictable data
distributions.

</details>


### [77] [Periodic Skill Discovery](https://arxiv.org/abs/2511.03187)
*Jonghae Park,Daesol Cho,Jusuk Lee,Dongseok Shim,Inkyu Jang,H. Jin Kim*

Main category: cs.LG

TL;DR: 该论文提出了周期性技能发现（PSD）框架，旨在无监督地学习具有周期性性质的机器人技能，并通过在循环潜在空间中编码周期性来有效捕获不同周期的技能，这些技能在下游任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 目前的无监督技能发现方法忽略了学习技能的周期性，而许多机器人任务需要不同时间尺度的周期性行为，因此发现多样化的周期性技能至关重要。

Method: PSD通过训练一个将状态映射到循环潜在空间的编码器来发现周期性行为，从而在潜在表示中自然地编码周期性。

Result: PSD能够有效地学习复杂机器人任务中具有不同周期的技能，即使是基于像素的观察，并且这些学习到的技能在跨栏等下游任务中表现出高性能。此外，将PSD与现有技能发现方法结合使用可以提供更多样化的行为。

Conclusion: PSD通过引入循环潜在空间，有效解决了无监督技能发现中周期性技能学习的问题，并为机器人学习多样化和高性能的周期性行为提供了新途径。

Abstract: Unsupervised skill discovery in reinforcement learning (RL) aims to learn
diverse behaviors without relying on external rewards. However, current methods
often overlook the periodic nature of learned skills, focusing instead on
increasing the mutual dependence between states and skills or maximizing the
distance traveled in latent space. Considering that many robotic tasks --
particularly those involving locomotion -- require periodic behaviors across
varying timescales, the ability to discover diverse periodic skills is
essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a
framework that discovers periodic behaviors in an unsupervised manner. The key
idea of PSD is to train an encoder that maps states to a circular latent space,
thereby naturally encoding periodicity in the latent representation. By
capturing temporal distance, PSD can effectively learn skills with diverse
periods in complex robotic tasks, even with pixel-based observations. We
further show that these learned skills achieve high performance on downstream
tasks such as hurdling. Moreover, integrating PSD with an existing skill
discovery method offers more diverse behaviors, thus broadening the agent's
repertoire. Our code and demos are available at
https://jonghaepark.github.io/psd/

</details>


### [78] [Efficient Linear Attention for Multivariate Time Series Modeling via Entropy Equality](https://arxiv.org/abs/2511.03190)
*Mingtao Zhang,Guoli Yang,Zhanxing Zhu,Mengzhu Wang,Xiaoying Bai*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的线性注意力机制，旨在解决传统注意力机制在处理长序列时面临的二次计算复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制在时间序列建模中非常有效，但其二次计算复杂度限制了其在长序列上的可扩展性。

Method: 本研究基于一个理论证明，即熵作为概率单纯形上的严格凹函数，意味着概率排序一致且熵值相似的分布表现出结构相似性。在此基础上，我们开发了一种高效的近似算法，该算法仅以线性复杂度计算点积派生分布的熵，从而实现了基于熵等式的线性注意力机制。

Result: 实验结果表明，该方法在四个时空数据集上取得了有竞争力的或更优的预测性能，同时显著降低了内存使用和计算时间。研究还揭示，注意力在时空时间序列建模中的有效性可能并非主要源于softmax的非线性，而是源于实现适度和均衡的权重分布。

Conclusion: 本文提出的线性注意力机制通过引入熵等式和近似算法，有效解决了传统注意力机制的复杂度问题，并在时空时间序列建模中展现出卓越的性能和效率。

Abstract: Attention mechanisms have been extensively employed in various applications,
including time series modeling, owing to their capacity to capture intricate
dependencies; however, their utility is often constrained by quadratic
computational complexity, which impedes scalability for long sequences. In this
work, we propose a novel linear attention mechanism designed to overcome these
limitations. Our approach is grounded in a theoretical demonstration that
entropy, as a strictly concave function on the probability simplex, implies
that distributions with aligned probability rankings and similar entropy values
exhibit structural resemblance. Building on this insight, we develop an
efficient approximation algorithm that computes the entropy of
dot-product-derived distributions with only linear complexity, enabling the
implementation of a linear attention mechanism based on entropy equality.
Through rigorous analysis, we reveal that the effectiveness of attention in
spatio-temporal time series modeling may not primarily stem from the
non-linearity of softmax but rather from the attainment of a moderate and
well-balanced weight distribution. Extensive experiments on four
spatio-temporal datasets validate our method, demonstrating competitive or
superior forecasting performance while achieving substantial reductions in both
memory usage and computational time.

</details>


### [79] [A Feedback-Control Framework for Efficient Dataset Collection from In-Vehicle Data Streams](https://arxiv.org/abs/2511.03239)
*Philipp Reis,Philipp Rigoll,Christian Steinhauser,Jacob Langner,Eric Sax*

Main category: cs.LG

TL;DR: 数据收集即闭环控制，通过在线概率模型和自适应样本保留，显著提高数据平衡性，减少存储。


<details>
  <summary>Details</summary>
Motivation: 目前AI系统受限于数据质量，传统开放式数据收集效率低下、冗余且泛化能力有限。

Method: 提出FCDC（Feedback Control for Data Collection）范式，将数据收集视为闭环控制问题。利用在线概率模型近似数据分布状态，并根据反馈信号（如似然和马哈拉诺比斯距离）自适应调节样本保留。

Result: 在合成数据集上展示了可控性。在真实数据流上，FCDC在减少39.8%数据存储的同时，将数据集平衡性提高了25.9%。

Conclusion: 数据收集可以被主动控制，从被动环节转变为自调节、反馈驱动的核心过程，赋能数据中心AI。

Abstract: Modern AI systems are increasingly constrained not by model capacity but by
the quality and diversity of their data. Despite growing emphasis on
data-centric AI, most datasets are still gathered in an open-loop manner which
accumulates redundant samples without feedback from the current coverage. This
results in inefficient storage, costly labeling, and limited generalization. To
address this, this paper introduces \ac{FCDC}, a paradigm that formulates data
collection as a closed-loop control problem. \ac{FCDC} continuously
approximates the state of the collected data distribution using an online
probabilistic model and adaptively regulates sample retention using based on
feedback signals such as likelihood and Mahalanobis distance. Through this
feedback mechanism, the system dynamically balances exploration and
exploitation, maintains dataset diversity, and prevents redundancy from
accumulating over time. Besides showcasing the controllability of \ac{FCDC} on
a synthetic dataset, experiments on a real data stream show that \ac{FCDC}
produces more balanced datasets by $\SI{25.9}{\percent}$ while reducing data
storage by $\SI{39.8}{\percent}$. These results demonstrate that data
collection itself can be actively controlled, transforming collection from a
passive pipeline stage into a self-regulating, feedback-driven process at the
core of data-centric AI.

</details>


### [80] [A unified physics-informed generative operator framework for general inverse problems](https://arxiv.org/abs/2511.03241)
*Gang Bao,Yaohua Zang*

Main category: cs.LG

TL;DR: IGNO是一个新颖的生成神经算子框架，它通过将高维系数场编码到低维潜在空间中，并通过神经算子解码器重建系数和PDE解，从而在没有标记训练数据的情况下解决由偏微分方程（PDE）控制的逆问题。


<details>
  <summary>Details</summary>
Motivation: 在测量稀疏、嘈杂，或底层系数是高维或不连续时，解决由偏微分方程（PDE）控制的逆问题仍然具有挑战性。现有深度学习方法需要大量标记数据集或仅限于特定测量类型，这限制了它们的实际应用。

Method: IGNO框架将高维、可能不连续的系数场编码到低维潜在空间中，并通过神经算子解码器重建系数和PDE解。训练纯粹依赖于通过PDE残差的物理约束，而反演通过潜在空间中高效的基于梯度的优化进行，并通过先验归一化流模型加速。

Result: 在各种具有挑战性的逆问题中，包括从基于解的测量中恢复不连续系数和基于算子测量的EIT问题，IGNO即使在严重噪声下也能始终实现准确、稳定和可扩展的反演。它在不同噪声水平下始终优于最先进的方法，并 C对分布外目标表现出强大的泛化能力。

Conclusion: IGNO被确立为一个统一而强大的框架，用于解决计算科学领域中具有挑战性的逆问题。

Abstract: Solving inverse problems governed by partial differential equations (PDEs) is
central to science and engineering, yet remains challenging when measurements
are sparse, noisy, or when the underlying coefficients are high-dimensional or
discontinuous. Existing deep learning approaches either require extensive
labeled datasets or are limited to specific measurement types, often leading to
failure in such regimes and restricting their practical applicability. Here, a
novel generative neural operator framework, IGNO, is introduced to overcome
these limitations. IGNO unifies the solution of inverse problems from both
point measurements and operator-valued data without labeled training pairs.
This framework encodes high-dimensional, potentially discontinuous coefficient
fields into a low-dimensional latent space, which drives neural operator
decoders to reconstruct both coefficients and PDE solutions. Training relies
purely on physics constraints through PDE residuals, while inversion proceeds
via efficient gradient-based optimization in latent space, accelerated by an a
priori normalizing flow model. Across a diverse set of challenging inverse
problems, including recovery of discontinuous coefficients from solution-based
measurements and the EIT problem with operator-based measurements, IGNO
consistently achieves accurate, stable, and scalable inversion even under
severe noise. It consistently outperforms the state-of-the-art method under
varying noise levels and demonstrates strong generalization to
out-of-distribution targets. These results establish IGNO as a unified and
powerful framework for tackling challenging inverse problems across
computational science domains.

</details>


### [81] [Extending Fair Null-Space Projections for Continuous Attributes to Kernel Methods](https://arxiv.org/abs/2511.03304)
*Felix Störck,Fabian Hinder,Barbara Hammer*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的核方法，用于解决机器学习系统中连续受保护属性的公平性问题。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习系统日益融入人们的日常生活，公平性在其开发中的重要性日益凸显。当前关于公平性的研究主要集中在离散属性上，而对于连续属性（尤其是与回归结合）的研究相对较少。

Method: 本研究通过将迭代零空间投影方法推广到核方法，极大地扩展了其适用范围。这使得该方法能够应用于连续受保护属性的核嵌入模型，并且与具体的模型和公平性评分无关。

Result: 实验结果表明，该新方法与支持向量回归（SVR）结合，在多个数据集上与现有方法相比，能够提供具有竞争力甚至更优的性能。

Conclusion: 本研究通过引入一种通用的核方法，有效应对了机器学习中连续公平性问题，为未来该领域的研究开辟了新的道路。

Abstract: With the on-going integration of machine learning systems into the everyday
social life of millions the notion of fairness becomes an ever increasing
priority in their development. Fairness notions commonly rely on protected
attributes to assess potential biases. Here, the majority of literature focuses
on discrete setups regarding both target and protected attributes. The
literature on continuous attributes especially in conjunction with regression
-- we refer to this as \emph{continuous fairness} -- is scarce. A common
strategy is iterative null-space projection which as of now has only been
explored for linear models or embeddings such as obtained by a non-linear
encoder. We improve on this by generalizing to kernel methods, significantly
extending the scope. This yields a model and fairness-score agnostic method for
kernel embeddings applicable to continuous protected attributes. We demonstrate
that our novel approach in conjunction with Support Vector Regression (SVR)
provides competitive or improved performance across multiple datasets in
comparisons to other contemporary methods.

</details>


### [82] [Diffusion Language Models are Super Data Learners](https://arxiv.org/abs/2511.03276)
*Jinjie Ni,Qian Liu,Longxu Dou,Chao Du,Zili Wang,Hang Yan,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 在数据有限的情况下，扩散语言模型（DLM）在训练更多epochs后始终优于自回归（AR）模型，这种现象被称为“Crossover”。DLM的优势归因于其无序建模、迭代双向去噪带来的超密集计算以及内置的蒙特卡洛增强。


<details>
  <summary>Details</summary>
Motivation: 探索扩散语言模型（DLM）在数据受限情况下的性能表现，并与自回归（AR）模型进行比较，分析DLM超越AR模型的原因。

Method: 在严格受控的预训练设置下，通过改变训练epoch数量、数据量、数据质量和模型大小，比较DLM和AR模型的性能。同时，分析DLM性能提升的三个因素：无序建模、迭代双向去噪和内置蒙特卡洛增强。

Result: 观察到“Crossover”现象：在独特数据有限时，DLM通过更多epochs的训练持续超越AR模型。Crossover现象会随着数据量或数据质量的增加而推迟，随着模型增大而提前，并在稠密和稀疏架构中普遍存在。一个1.7B的DLM在10B独特Python tokens上训练，使用约1.5T-token的计算预算，超越了设置严格匹配的AR编码器。一个1B参数的DLM仅使用1B tokens，在HellaSwag上达到>56%的准确率，在MMLU上达到>33%的准确率。

Conclusion: 拡散语言模型（DLM）在数据受限的预训练场景中表现出显著优势，并能在一定条件下超越自回归（AR）模型。DLM的优越性得益于其独特的架构和训练机制，特别是无序建模、高效率的迭代双向去噪以及内置的蒙特卡洛增强。研究结果表明，在某些情况下，验证交叉熵的升高并不一定意味着下游性能的下降。

Abstract: Under strictly controlled pre-training settings, we observe a Crossover: when
unique data is limited, diffusion language models (DLMs) consistently surpass
autoregressive (AR) models by training for more epochs. The crossover shifts
later with more or higher-quality data, earlier with larger models, and
persists across dense and sparse architectures. We attribute the gains to three
compounding factors: (1) any-order modeling, (2) super-dense compute from
iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation;
input or parameter noise improves AR under data constraint but cannot close the
gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B
unique Python tokens overtakes an AR coder trained with strictly matched
settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag
and > 33% on MMLU using only 1B tokens, without any special tricks, just by
repeating standard pre-training data. We also show that rising validation
cross-entropy does not imply degraded downstream performance in this regime.

</details>


### [83] [A Probabilistic Approach to Pose Synchronization for Multi-Reference Alignment with Applications to MIMO Wireless Communication Systems](https://arxiv.org/abs/2511.03280)
*Rob Romijnders,Gabriele Cesa,Christos Louizos,Kumar Pratik,Arash Behboodi*

Main category: cs.LG

TL;DR: 该文章提出了一种多参考对齐（MRA）问题的新算法，旨在解决信号重构中的对齐问题，该算法通过边缘化相对姿态作为干扰变量来消除全局对称性，从而在降低计算成本的同时提高重建精度。


<details>
  <summary>Details</summary>
Motivation: 在分子成像到无线通信等多个领域中，从多个未对齐的观测中对齐和重建信号对于系统性能至关重要，因此需要一种有效解决多参考对齐（MRA）问题的方法。

Method: 文章采用概率方法对MRA问题进行建模，并引入了一种新算法。该算法通过边缘化相对姿态作为干扰变量来消除问题的全局对称性。此外，文章还提出了一种去中心化的方法，通过循环一致性避免了中心化方法的三次计算复杂度，显著降低了计算成本。

Result: 所提出的两种算法在不同的实验设置下均实现了更低的重建误差，并且在计算效率上优于传统的中心化方法。

Conclusion: 通过消除全局对称性和采用去中心化方法，本文提出的MRA算法不仅提高了信号重建的精度，而且显著降低了计算成本，为多参考对齐问题提供了一种更有效和实用的解决方案。

Abstract: From molecular imaging to wireless communications, the ability to align and
reconstruct signals from multiple misaligned observations is crucial for system
performance. We study the problem of multi-reference alignment (MRA), which
arises in many real-world problems, such as cryo-EM, computer vision, and, in
particular, wireless communication systems. Using a probabilistic approach to
model MRA, we find a new algorithm that uses relative poses as nuisance
variables to marginalize out -- thereby removing the global symmetries of the
problem and allowing for more direct solutions and improved convergence. The
decentralization of this approach enables significant computational savings by
avoiding the cubic scaling of centralized methods through cycle consistency.
Both proposed algorithms achieve lower reconstruction error across experimental
settings.

</details>


### [84] [SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration](https://arxiv.org/abs/2511.03344)
*Elif Arslan,Jacobus G. M. van der Linden,Serge Hoogendoorn,Marco Rinaldi,Emir Demirović*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为SORTD的新框架，用于生成和探索稀疏决策树的Rashomon集。SORTD克服了现有方法的计算限制，并能以更快的速度生成更好的决策树。


<details>
  <summary>Details</summary>
Motivation: 稀疏决策树学习提供了准确和可解释的预测模型，但找到最优树是NP-难的。为了解决这个问题，需要一种方法来枚举 Rashomon 集，即性能相似但结构不同的树，以增强变量重要性分析、丰富解释，并允许用户选择更简单的树或满足利益相关者偏好的树。

Method: 本文提出了SORTD框架，它通过按目标值对 Rashomon 集中的树进行排序，提高了可扩展性。

Result: 实验结果表明，SORTD将运行时间缩短了两个数量级，并且能够为任何可分离和全序目标计算 Rashomon 集，支持使用其他可分离（和偏序）目标对集进行后评估。

Conclusion: SORTD框架可以使Rashomon集在实际应用中更易于探索，使得在实际应用中探索 Rashomon 集变得更加实用。

Abstract: Sparse decision tree learning provides accurate and interpretable predictive
models that are ideal for high-stakes applications by finding the single most
accurate tree within a (soft) size limit. Rather than relying on a single
"best" tree, Rashomon sets-trees with similar performance but varying
structures-can be used to enhance variable importance analysis, enrich
explanations, and enable users to choose simpler trees or those that satisfy
stakeholder preferences (e.g., fairness) without hard-coding such criteria into
the objective function. However, because finding the optimal tree is NP-hard,
enumerating the Rashomon set is inherently challenging. Therefore, we introduce
SORTD, a novel framework that improves scalability and enumerates trees in the
Rashomon set in order of the objective value, thus offering anytime behavior.
Our experiments show that SORTD reduces runtime by up to two orders of
magnitude compared with the state of the art. Moreover, SORTD can compute
Rashomon sets for any separable and totally ordered objective and supports
post-evaluating the set using other separable (and partially ordered)
objectives. Together, these advances make exploring Rashomon sets more
practical in real-world applications.

</details>


### [85] [TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled Markets](https://arxiv.org/abs/2511.03368)
*Hongrun Ren,Yun Xiong,Lei You,Yingying Wang,Haixu Xiong,Yangyong Zhu*

Main category: cs.LG

TL;DR: 本文提出了一个统一的数据-模型耦合市场，用于解决机器学习模型经济中训练数据集和预训练模型市场相互交织的问题，并证明了其均衡价格的存在性、唯一性和全局收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有的定价方法大多将数据和模型交易分开，或者依赖于偏向一方的中间人管道。此外，现有的数据市场研究虽然考虑了买方交互，但未能为数据卖家、模型生产者和模型买家提供同时对称的机制。

Method: 本文提出了一种统一的数据-模型耦合市场，将数据集和模型交易视为一个单一系统。通过供给侧映射将数据集支付转换为买方可见的模型报价，同时通过基于Shapley分配的需求侧映射将买方价格反馈给数据集。

Result: 通过实验证明，该方法与以中间人为中心和单边基线相比，具有更高的收敛效率和公平性，并且可以保证均衡价格的存在性、唯一性和全局收敛性。

Conclusion: 本文提出的数据-模型耦合市场为机器学习模型经济中的数据和模型交易提供了一个统一、公平且高效的解决方案，有效提升了市场效率和公平性。

Abstract: The rise of the machine learning (ML) model economy has intertwined markets
for training datasets and pre-trained models. However, most pricing approaches
still separate data and model transactions or rely on broker-centric pipelines
that favor one side. Recent studies of data markets with externalities capture
buyer interactions but do not yield a simultaneous and symmetric mechanism
across data sellers, model producers, and model buyers. We propose a unified
data-model coupled market that treats dataset and model trading as a single
system. A supply-side mapping transforms dataset payments into buyer-visible
model quotations, while a demand-side mapping propagates buyer prices back to
datasets through Shapley-based allocation. Together, they form a closed loop
that links four interactions: supply-demand propagation in both directions and
mutual coupling among buyers and among sellers. We prove that the joint
operator is a standard interference function (SIF), guaranteeing existence,
uniqueness, and global convergence of equilibrium prices. Experiments
demonstrate efficient convergence and improved fairness compared with
broker-centric and one-sided baselines. The code is available on
https://github.com/HongrunRen1109/Triple-Win-Pricing.

</details>


### [86] [Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent Advances](https://arxiv.org/abs/2511.03565)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 这篇综述探讨了模仿学习的最新进展及其在各个领域的应用，并提出了一种新的分类方法。


<details>
  <summary>Details</summary>
Motivation: 模仿学习使智能体能够通过观察和复制一个或多个专家的行为来获得技能，而深度学习的进步显著扩展了模仿学习的能力和可伸缩性。本文旨在综述模仿学习的最新进展。

Method: 本文回顾了模仿学习研究的最新进展，强调了最近的趋势、方法创新和实际应用。此外，本文提出了一种不同于现有分类的新分类法，以更好地反映模仿学习研究的现状和趋势。

Result: 本文详细考察了代表性工作的优缺点和评估实践，并概述了未来研究的关键挑战和开放方向。

Conclusion: 模仿学习在深度学习的推动下取得了显著发展，但也面临泛化、协变量偏移和示范质量等挑战。这篇综述提供了一个全面的视角来理解当前模仿学习的格局和未来发展方向。

Abstract: Imitation learning (IL) enables agents to acquire skills by observing and
replicating the behavior of one or multiple experts. In recent years, advances
in deep learning have significantly expanded the capabilities and scalability
of imitation learning across a range of domains, where expert data can range
from full state-action trajectories to partial observations or unlabeled
sequences. Alongside this growth, novel approaches have emerged, with new
methodologies being developed to address longstanding challenges such as
generalization, covariate shift, and demonstration quality. In this survey, we
review the latest advances in imitation learning research, highlighting recent
trends, methodological innovations, and practical applications. We propose a
novel taxonomy that is distinct from existing categorizations to better reflect
the current state of the IL research stratum and its trends. Throughout the
survey, we critically examine the strengths, limitations, and evaluation
practices of representative works, and we outline key challenges and open
directions for future research.

</details>


### [87] [Reinforcement Learning Using known Invariances](https://arxiv.org/abs/2511.03473)
*Alexandru Cioba,Aya Kayal,Laura Toni,Sattar Vakili,Alberto Bernacchia*

Main category: cs.LG

TL;DR: 这篇论文提出了一个将已知群对称性纳入基于核的强化学习的理论和算法框架，通过利用不变核来编码奖励和转换动力学中的不变性。


<details>
  <summary>Details</summary>
Motivation: 在许多现实世界的强化学习问题中，环境表现出固有的对称性，可以利用这些对称性来提高学习效率。

Method: 本文提出了一种对称感知的乐观最小二乘值迭代（LSVI）变体，其利用不变核来编码奖励和转换动力学中的不变性。

Result: 我们的分析建立了不变RKHS的最大信息增益和覆盖数的新界限，明确量化了对称性带来的样本效率增益。在定制的Frozen Lake环境和2D放置设计问题上的实证结果证实了理论上的改进，表明对称感知RL比标准核对应物取得了显著更好的性能。

Conclusion: 这些发现强调了结构先验在设计更样本高效的强化学习算法中的价值。

Abstract: In many real-world reinforcement learning (RL) problems, the environment
exhibits inherent symmetries that can be exploited to improve learning
efficiency. This paper develops a theoretical and algorithmic framework for
incorporating known group symmetries into kernel-based RL. We propose a
symmetry-aware variant of optimistic least-squares value iteration (LSVI),
which leverages invariant kernels to encode invariance in both rewards and
transition dynamics. Our analysis establishes new bounds on the maximum
information gain and covering numbers for invariant RKHSs, explicitly
quantifying the sample efficiency gains from symmetry. Empirical results on a
customized Frozen Lake environment and a 2D placement design problem confirm
the theoretical improvements, demonstrating that symmetry-aware RL achieves
significantly better performance than their standard kernel counterparts. These
findings highlight the value of structural priors in designing more
sample-efficient reinforcement learning algorithms.

</details>


### [88] [RAGBoost: Efficient Retrieval-Augmented Generation with Accuracy-Preserving Context Reuse](https://arxiv.org/abs/2511.03475)
*Yinsicheng Jiang,Yeqi Huang,Liang Cheng,Cheng Deng,Xuan Sun,Luo Mai*

Main category: cs.LG

TL;DR: RAGBoost通过准确性保持的上下文重用和高效的上下文管理，显著提升了检索增强生成（RAG）系统的预填充性能和推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统在处理长而复杂的输入时，预填充性能下降，并且缓存技术在准确性和缓存重用之间存在妥协。

Method: RAGBoost通过检测并发会话和多轮交互中重叠的检索项，利用高效的上下文索引、排序和去重技术来最大化缓存重用。同时，轻量级上下文提示确保了推理的准确性。

Result: RAGBoost将现有LLM推理引擎的预填充性能提高了1.5-3倍，同时在各种RAG和智能体AI工作负载中保持甚至提高了推理准确性。

Conclusion: RAGBoost有效解决了现有RAG系统在长输入下的预填充性能问题，并通过创新的上下文重用技术，在保持高准确性的同时显著提升了效率，为RAG和智能体AI应用提供了强大的支持。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs)
with retrieved context but often suffers from downgraded prefill performance as
modern applications demand longer and more complex inputs. Existing caching
techniques either preserve accuracy with low cache reuse or improve reuse at
the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG
system that achieves high cache reuse without sacrificing accuracy through
accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items
across concurrent sessions and multi-turn interactions, using efficient context
indexing, ordering, and de-duplication to maximize reuse, while lightweight
contextual hints maintain reasoning fidelity. It integrates seamlessly with
existing LLM inference engines and improves their prefill performance by 1.5-3X
over state-of-the-art methods, while preserving or even enhancing reasoning
accuracy across diverse RAG and agentic AI workloads. Our code is released at:
https://github.com/Edinburgh-AgenticAI/RAGBoost.

</details>


### [89] [NAP: Attention-Based Late Fusion for Automatic Sleep Staging](https://arxiv.org/abs/2511.03488)
*Alvise Dei Rossi,Julia van der Meer,Markus H. Schmidt,Claudio L. A. Bassetti,Luigi Fiorillo,Francesca Faraci*

Main category: cs.LG

TL;DR: 多导睡眠图信号异构，现有模型无法充分利用其多模态特性。本文提出NAP模型，通过三轴注意力机制结合多个预测流，提高了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多导睡眠图信号具有高度异构性，现有模型通常依赖固定的模态或通道子集，未能充分利用其固有多模态特性。

Method: 本文提出了一种名为NAP（Neural Aggregator of Predictions）的注意力模型。该模型使用三轴注意力机制（捕获时间、空间和预测器级别的依赖性），学习如何结合多个预测流。NAP通过聚合来自冻结的、预训练的单通道模型的输出，并能够适应不同的输入维度。

Result: NAP模型始终优于单个预测器和简单集成模型，在多个数据集上实现了最先进的零样本泛化。

Conclusion: NAP模型在自动睡眠分期任务中表现出色，并且该方法可以推广到其他多模态生理应用中。

Abstract: Polysomnography signals are highly heterogeneous, varying in modality
composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal,
occipital EEG), and acquisition protocols across datasets and clinical sites.
Most existing models that process polysomnography data rely on a fixed subset
of modalities or channels and therefore neglect to fully exploit its inherently
multimodal nature. We address this limitation by introducing NAP (Neural
Aggregator of Predictions), an attention-based model which learns to combine
multiple prediction streams using a tri-axial attention mechanism that captures
temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to
different input dimensions. By aggregating outputs from frozen, pretrained
single-channel models, NAP consistently outperforms individual predictors and
simple ensembles, achieving state-of-the-art zero-shot generalization across
multiple datasets. While demonstrated in the context of automated sleep staging
from polysomnography, the proposed approach could be extended to other
multimodal physiological applications.

</details>


### [90] [Structured Matrix Scaling for Multi-Class Calibration](https://arxiv.org/abs/2511.03685)
*Eugène Berta,David Holzmüller,Michael I. Jordan,Francis Bach*

Main category: cs.LG

TL;DR: 本文提出了一种新的事后校准方法，通过结构化正则化、鲁棒预处理和高效优化，有效地管理了多类校准中更复杂模型引入的参数数量增加所导致的偏差-方差权衡，从而在现有基于逻辑回归的校准技术上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 为了确保分类器提供可靠的概率估计，事后校准方法被广泛使用。然而，现有的多类校准方法在处理更复杂模型引入的参数数量增加时，往往会遇到过拟合问题，尤其是在校准数据有限的情况下，这促使作者寻求更有效的校准方法。

Method: 作者提出了一种基于逻辑回归的参数校准函数，并通过结构化正则化、鲁棒预处理和高效优化来管理偏差-方差权衡。

Result: 实验结果表明，该方法在现有基于逻辑回归的校准技术上取得了显著的改进。

Conclusion: 本文提出的校准方法通过有效管理复杂模型中的参数数量，在多类校准方面取得了显著进展，并提供了高效且易于使用的开源实现，为替代现有校准方法提供了有吸引力的选择。

Abstract: Post-hoc recalibration methods are widely used to ensure that classifiers
provide faithful probability estimates. We argue that parametric recalibration
functions based on logistic regression can be motivated from a simple
theoretical setting for both binary and multiclass classification. This insight
motivates the use of more expressive calibration methods beyond standard
temperature scaling. For multi-class calibration however, a key challenge lies
in the increasing number of parameters introduced by more complex models, often
coupled with limited calibration data, which can lead to overfitting. Through
extensive experiments, we demonstrate that the resulting bias-variance tradeoff
can be effectively managed by structured regularization, robust preprocessing
and efficient optimization. The resulting methods lead to substantial gains
over existing logistic-based calibration techniques. We provide efficient and
easy-to-use open-source implementations of our methods, making them an
attractive alternative to common temperature, vector, and matrix scaling
implementations.

</details>


### [91] [Learning Without Critics? Revisiting GRPO in Classical Reinforcement Learning Environments](https://arxiv.org/abs/2511.03527)
*Bryan L. M. de Oliveira,Felipe V. Frujeri,Marcos P. C. M. Queiroz,Luana G. B. Martins,Telma W. de L. Soares,Luckeciano C. Melo*

Main category: cs.LG

TL;DR: GRPO是一种可扩展的替代PPO的算法，它通过消除学习到的评论家并用轨迹的组间比较来估计优势。本文研究了GRPO的有效性，并通过实验证明了学习型评论家在长时任务中的必要性，GRPO在高折扣因子下的优势，以及小规模组在GRPO中的优越性。


<details>
  <summary>Details</summary>
Motivation: GRPO通过消除学习到的评论家并用轨迹的组间比较来估计优势，这引发了关于策略梯度方法中学习基线的必要性的基本问题。

Method: 本文对GRPO在经典的单任务强化学习环境中进行了首次系统研究，涵盖了离散和连续控制任务。通过分离基线、折扣和组采样的受控消融实验，揭示了三个关键发现。

Result: 1. 学习型评论家对于长时任务仍然至关重要。除了像CartPole这样的短时环境（其中 эпизодический 回报可能有效）外，所有无评论家的基线都劣于PPO。
2. GRPO受益于高折扣因子（gamma = 0.99），但在HalfCheetah中，由于缺乏提前终止，适度的折扣（gamma = 0.9）更为有利。
3. 较小规模的组优于较大规模的组，这表明基于批次的组合策略在混合不相关 эпизод 时存在局限性。

Conclusion: 这些结果揭示了无评论家方法在经典控制中的局限性，以及它们仍然是学习价值函数的有效替代方案的特定条件。

Abstract: Group Relative Policy Optimization (GRPO) has emerged as a scalable
alternative to Proximal Policy Optimization (PPO) by eliminating the learned
critic and instead estimating advantages through group-relative comparisons of
trajectories. This simplification raises fundamental questions about the
necessity of learned baselines in policy-gradient methods. We present the first
systematic study of GRPO in classical single-task reinforcement learning
environments, spanning discrete and continuous control tasks. Through
controlled ablations isolating baselines, discounting, and group sampling, we
reveal three key findings: (1) learned critics remain essential for
long-horizon tasks: all critic-free baselines underperform PPO except in
short-horizon environments like CartPole where episodic returns can be
effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except
in HalfCheetah, where lack of early termination favors moderate discounting
(gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting
limitations in batch-based grouping strategies that mix unrelated episodes.
These results reveal both the limitations of critic-free methods in classical
control and the specific conditions where they remain viable alternatives to
learned value functions.

</details>


### [92] [Byzantine-Robust Federated Learning with Learnable Aggregation Weights](https://arxiv.org/abs/2511.03529)
*Javad Parsa,Amir Hossein Daghestani,André M. H. Teixeira,Mikael Johansson*

Main category: cs.LG

TL;DR: 本文提出了一种针对联邦学习中拜占庭鲁棒性的新型自适应加权聚合算法，并在数据异构和恶意客户端比例较高的情况下超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）允许客户端在不共享私有数据的情况下协同训练全局模型，但恶意（拜占庭）客户端的存在对FL的鲁棒性构成了重大挑战，尤其是在客户端数据分布异构时。

Method: 本文提出了一种新颖的拜占庭鲁棒联邦学习优化问题，将自适应加权纳入聚合过程。我们不像传统方法那样，将聚合权重视为可学习参数，并与全局模型参数联合优化。为了解决这个优化问题，我们开发了一种交替最小化算法，在对抗性攻击下具有强大的收敛保证。

Result: 实验结果表明，我们的方法始终优于现有方法，特别是在数据高度异构和恶意客户端比例较大的设置中。

Conclusion: 所提出的算法在保持联邦学习的隐私优势的同时，显著提高了其在恶意客户端存在和非独立同分布数据环境下的鲁棒性。

Abstract: Federated Learning (FL) enables clients to collaboratively train a global
model without sharing their private data. However, the presence of malicious
(Byzantine) clients poses significant challenges to the robustness of FL,
particularly when data distributions across clients are heterogeneous. In this
paper, we propose a novel Byzantine-robust FL optimization problem that
incorporates adaptive weighting into the aggregation process. Unlike
conventional approaches, our formulation treats aggregation weights as
learnable parameters, jointly optimizing them alongside the global model
parameters. To solve this optimization problem, we develop an alternating
minimization algorithm with strong convergence guarantees under adversarial
attack. We analyze the Byzantine resilience of the proposed objective. We
evaluate the performance of our algorithm against state-of-the-art
Byzantine-robust FL approaches across various datasets and attack scenarios.
Experimental results demonstrate that our method consistently outperforms
existing approaches, particularly in settings with highly heterogeneous data
and a large proportion of malicious clients.

</details>


### [93] [Flat Minima and Generalization: Insights from Stochastic Convex Optimization](https://arxiv.org/abs/2511.03548)
*Matan Schliserman,Shira Vansover-Hager,Tomer Koren*

Main category: cs.LG

TL;DR: 本文研究了随机凸优化中平坦最小值与泛化之间的联系。结果表明，即使在该基本设置中，平坦经验最小值也可能导致平凡的 $\Omega(1)$ 总体风险，而尖锐最小值则能够实现最优泛化。


<details>
  <summary>Details</summary>
Motivation: 理解学习算法的泛化行为是学习理论的核心目标。最近出现的一种解释是，学习算法在实践中之所以成功，是因为它们收敛于平坦最小值，这与改进的泛化性能始终相关联。

Method: 本文在具有非负 $\beta$-光滑目标的随机凸优化的规范设置中研究了平坦最小值和泛化之间的联系。

Result: 1. 即使在基本且经过充分研究的随机凸优化设置中，平坦的经验最小值也可能导致平凡的 $\Omega(1)$ 总体风险，而尖锐的最小值则能实现最佳泛化。
2. 这种较差的泛化行为也延伸到两种自然的“尖锐度感知”算法：尖锐度感知梯度下降 (SA-GD) 和尖锐度感知最小化 (SAM)。
3. 对于 SA-GD，虽然它能以较快的速度成功收敛到平坦最小值，但解的总体风险仍然可以高达 $\Omega(1)$。
4. 对于 SAM，尽管它能最小化经验损失，但它可能收敛到尖锐最小值，并且也会导致 $\Omega(1)$ 的总体风险。

Conclusion: 平坦最小值与改进的泛化性能之间不总是存在关联，即使是专门设计用于寻找平坦 Minima 的算法也可能表现不佳。这表明在理解泛化方面，还需要更深入的研究，不能简单地将平坦度作为泛化性能的唯一指标。

Abstract: Understanding the generalization behavior of learning algorithms is a central
goal of learning theory. A recently emerging explanation is that learning
algorithms are successful in practice because they converge to flat minima,
which have been consistently associated with improved generalization
performance. In this work, we study the link between flat minima and
generalization in the canonical setting of stochastic convex optimization with
a non-negative, $\beta$-smooth objective. Our first finding is that, even in
this fundamental and well-studied setting, flat empirical minima may incur
trivial $\Omega(1)$ population risk while sharp minima generalizes optimally.
Then, we show that this poor generalization behavior extends to two natural
''sharpness-aware'' algorithms originally proposed by Foret et al. (2021),
designed to bias optimization toward flat solutions: Sharpness-Aware Gradient
Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which
performs gradient steps on the maximal loss in a predefined neighborhood, we
prove that while it successfully converges to a flat minimum at a fast rate,
the population risk of the solution can still be as large as $\Omega(1)$,
indicating that even flat minima found algorithmically using a sharpness-aware
gradient method might generalize poorly. For SAM, a computationally efficient
approximation of SA-GD based on normalized ascent steps, we show that although
it minimizes the empirical loss, it may converge to a sharp minimum and also
incur population risk $\Omega(1)$. Finally, we establish population risk upper
bounds for both SA-GD and SAM using algorithmic stability techniques.

</details>


### [94] [TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and Retrieval](https://arxiv.org/abs/2511.03570)
*Günther Schindler,Maximilian Schambach,Michael Medek,Sam Thelin*

Main category: cs.LG

TL;DR: 本文介绍了TabGemma，这是一种针对混合文本、数字和分类字段的表格预测模型，它通过改进数字表示和上下文检索来解决现有大型语言模型（LLMs）在表格预测中遇到的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在表格预测中面临数字标记化不稳定和上下文大小有限的问题。

Method: TabGemma通过使用有符号科学计数法对数字进行规范化，并使用大规模真实世界数据集对12B Gemma 3模型进行预训练，采用目标填充目标。在推理时，它利用基于n-gram的紧凑检索方法来选择信息丰富的示例，以适应128k的tokens窗口。

Result: 在语义丰富的基准测试中，TabGemma在低数据和高数据状态下的分类任务中均达到了新的最先进水平，并且随着上下文行的增加而单调提升。对于回归任务，在小样本量下具有竞争力，但随着数据量的增加，其表现落后于传统方法。

Conclusion: LLMs与专门的数字处理和上下文检索相结合，可以在高度语义化的任务中有效地进行表格上下文学习，但仍需在数字建模和长上下文扩展方面进一步发展。

Abstract: We study LLMs for tabular prediction with mixed text, numeric, and
categorical fields. We introduce TabGemma, a schema-agnostic in-context learner
that treats rows as sequences and tackles two practical hurdles when adapting
pretrained LLMs for tabular predictions: unstable numeric tokenization and
limited context size. We propose to canonicalize numbers via signed scientific
notation and continue pretraining of a 12B Gemma 3 model with a target
imputation objective using a large-scale real world dataset. For inference, we
use a compact n-gram-based retrieval to select informative exemplars that fit
within a 128k-token window.
  On semantically rich benchmarks, TabGemma establishes a new state of the art
on classification across low- and high-data regimes and improves monotonically
with more context rows. For regression, it is competitive at small sample sizes
but trails conventional approaches as data grows. Our results show that LLMs
can be effective tabular in-context learners on highly semantic tasks when
paired with dedicated numeric handling and context retrieval, while motivating
further advances in numeric modeling and long-context scaling.

</details>


### [95] [Tensor-Efficient High-Dimensional Q-learning](https://arxiv.org/abs/2511.03595)
*Junyi Wu,Dan Li*

Main category: cs.LG

TL;DR: TEQL通过改进的块坐标下降和新颖的探索与正则化机制，增强了低秩张量分解，以解决高维强化学习中的计算复杂性和样本效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 解决高维强化学习中由于状态-动作空间大导致的计算复杂和样本效率低的问题，特别是Q学习算法面临的维度诅咒。

Method: 提出TEQL算法，它在离散化的状态-动作空间上，通过改进的块坐标下降来增强低秩张量分解。算法结合了近似误差和基于访问计数的上置信区间来指导探索，并引入了基于频率的惩罚项来鼓励探索未被充分访问的状态-动作对。

Result: 在经典控制任务上的实验结果表明，TEQL在样本效率和总奖励方面均优于传统的基于矩阵的方法和深度强化学习方法。

Conclusion: TEQL是一种适用于资源受限应用（如航天和医疗保健）的高效强化学习方法，能够有效处理高维问题并提高样本效率。

Abstract: High-dimensional reinforcement learning faces challenges with complex
calculations and low sample efficiency in large state-action spaces. Q-learning
algorithms struggle particularly with the curse of dimensionality, where the
number of state-action pairs grows exponentially with problem size. While
neural network-based approaches like Deep Q-Networks have shown success, recent
tensor-based methods using low-rank decomposition offer more
parameter-efficient alternatives. Building upon existing tensor-based methods,
we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor
decomposition via improved block coordinate descent on discretized state-action
spaces, incorporating novel exploration and regularization mechanisms. The key
innovation is an exploration strategy that combines approximation error with
visit count-based upper confidence bound to prioritize actions with high
uncertainty, avoiding wasteful random exploration. Additionally, we incorporate
a frequency-based penalty term in the objective function to encourage
exploration of less-visited state-action pairs and reduce overfitting to
frequently visited regions. Empirical results on classic control tasks
demonstrate that TEQL outperforms conventional matrix-based methods and deep RL
approaches in both sample efficiency and total rewards, making it suitable for
resource-constrained applications, such as space and healthcare where sampling
costs are high.

</details>


### [96] [Going Beyond Expert Performance via Deep Implicit Imitation Reinforcement Learning](https://arxiv.org/abs/2511.03616)
*Iason Chrysomallis,Georgios Chalkiadakis*

Main category: cs.LG

TL;DR: 该论文介绍了一种深度隐式模仿强化学习框架，解决了传统模仿学习中专家演示的局限性，实现了在只有状态观测数据下学习，并能超越次优专家性能。


<details>
  <summary>Details</summary>
Motivation: 传统的模仿学习需要完整的专家状态-动作演示，且要求专家表现是最优或接近最优的。这限制了其在实际场景中的应用，因为在许多现实世界中只有状态观测数据而没有对应的动作，并且专家表现往往是次优的。

Method: 本文引入了深度隐式模仿强化学习框架，包含Deep Implicit Imitation Q-Network (DIIQN)和Heterogeneous Actions DIIQN (HA-DIIQN)算法。
DIIQN通过在线探索重建专家动作，并整合动态置信机制，平衡专家指导和自主学习，从而利用专家指导加速训练，同时保持超越次优专家性能的能力。
HA-DIIQN扩展了DIIQN，处理专家与智能体动作集不同的场景。它引入了不可行性检测机制和桥接程序，在无法直接复制动作时识别连接智能体能力与专家指导的替代路径。

Result: DIIQN相比标准DQN，其周期性回报高出130%，并且持续优于无法超越专家性能的现有隐式模仿方法。在异构动作设置下，HA-DIIQN的学习速度比基线快64%，并且能够利用传统方法无法使用的专家数据集。广泛的参数敏感性分析表明该框架在不同数据集大小和超参数配置下都具有鲁棒性。

Conclusion: 所提出的深度隐式模仿强化学习框架（DIIQN和HA-DIIQN）有效地解决了传统模仿学习的局限性，在仅有状态观测数据的次优专家环境中也能够进行有效学习，并能显著提升性能，甚至超越专家水平，并且在异构动作空间中表现出色。

Abstract: Imitation learning traditionally requires complete state-action
demonstrations from optimal or near-optimal experts. These requirements
severely limit practical applicability, as many real-world scenarios provide
only state observations without corresponding actions and expert performance is
often suboptimal. In this paper we introduce a deep implicit imitation
reinforcement learning framework that addresses both limitations by combining
deep reinforcement learning with implicit imitation learning from
observation-only datasets. Our main algorithm, Deep Implicit Imitation
Q-Network (DIIQN), employs an action inference mechanism that reconstructs
expert actions through online exploration and integrates a dynamic confidence
mechanism that adaptively balances expert-guided and self-directed learning.
This enables the agent to leverage expert guidance for accelerated training
while maintaining capacity to surpass suboptimal expert performance. We further
extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to
tackle scenarios where expert and agent possess different action sets, a
challenge previously unaddressed in the implicit imitation learning literature.
HA-DIIQN introduces an infeasibility detection mechanism and a bridging
procedure identifying alternative pathways connecting agent capabilities to
expert guidance when direct action replication is impossible. Our experimental
results demonstrate that DIIQN achieves up to 130% higher episodic returns
compared to standard DQN, while consistently outperforming existing implicit
imitation methods that cannot exceed expert performance. In heterogeneous
action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging
expert datasets unusable by conventional approaches. Extensive parameter
sensitivity analysis reveals the framework's robustness across varying dataset
sizes and hyperparameter configurations.

</details>


### [97] [nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN](https://arxiv.org/abs/2511.03634)
*Alexander Pfefferle,Johannes Hog,Lennart Purucker,Frank Hutter*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个名为nanoTabPFN的简化版TabPFN模型，旨在提高表格基础模型的可及性。


<details>
  <summary>Details</summary>
Motivation: 现有的表格基础模型（如TabPFN）实现复杂，文档和代码质量不佳，导致难以理解、不适合初学者且难以适应新实验。

Method: 作者引入了nanoTabPFN，这是一个简化且轻量级的TabPFN v2架构实现，并使用预生成的训练数据进行训练。

Result: nanoTabPFN在小数据设置下，预训练时间不到一分钟（比TabPFN v2快16万倍），性能与传统机器学习基线相当。

Conclusion: nanoTabPFN使表格基础模型的预训练在教育环境中变得可行，降低了对大量计算资源的需求。

Abstract: Tabular foundation models such as TabPFN have revolutionized predictive
machine learning for tabular data. At the same time, the driving factors of
this revolution are hard to understand. Existing open-source tabular foundation
models are implemented in complicated pipelines boasting over 10,000 lines of
code, lack architecture documentation or code quality. In short, the
implementations are hard to understand, not beginner-friendly, and complicated
to adapt for new experiments. We introduce nanoTabPFN, a simplified and
lightweight implementation of the TabPFN v2 architecture and a corresponding
training loop that uses pre-generated training data. nanoTabPFN makes tabular
foundation models more accessible to students and researchers alike. For
example, restricted to a small data setting it achieves a performance
comparable to traditional machine learning baselines within one minute of
pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This
eliminated requirement of large computational resources makes pre-training
tabular foundation models accessible for educational purposes. Our code is
available at https://github.com/automl/nanoTabPFN.

</details>


### [98] [Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online RL](https://arxiv.org/abs/2511.03695)
*Lipeng Zu,Hansong Zhou,Xiaonan Zhang*

Main category: cs.LG

TL;DR: BAQ通过结合隐式行为模型和双目标损失函数，在不确定性高时使在线策略与离线行为保持一致，并在积累更多在线经验后逐渐放松这一约束，从而实现了从离线到在线强化学习的平稳过渡。


<details>
  <summary>Details</summary>
Motivation: 解决离线强化学习在动态环境中部署时，由于分布偏移和对未见状态-动作对不可靠的价值估计导致策略表现不佳的问题。

Method: 引入行为自适应Q学习（BAQ）框架，该框架利用从离线数据中提取的隐式行为模型提供行为一致性信号。BAQ采用双目标损失函数，在不确定性高时使在线策略与离线行为保持一致，并在积累更多可靠的在线经验后逐渐放松这一约束。

Result: BAQ在标准基准测试中持续优于此前的离线到在线强化学习方法，实现了更快的恢复、更高的鲁棒性和整体性能。

Conclusion: 隐式行为适应是实现可靠的真实世界策略部署的原则性且实用的解决方案。

Abstract: Offline reinforcement learning (RL) enables training from fixed data without
online interaction, but policies learned offline often struggle when deployed
in dynamic environments due to distributional shift and unreliable value
estimates on unseen state-action pairs. We introduce Behavior-Adaptive
Q-Learning (BAQ), a framework designed to enable a smooth and reliable
transition from offline to online RL. The key idea is to leverage an implicit
behavioral model derived from offline data to provide a behavior-consistency
signal during online fine-tuning. BAQ incorporates a dual-objective loss that
(i) aligns the online policy toward the offline behavior when uncertainty is
high, and (ii) gradually relaxes this constraint as more confident online
experience is accumulated. This adaptive mechanism reduces error propagation
from out-of-distribution estimates, stabilizes early online updates, and
accelerates adaptation to new scenarios. Across standard benchmarks, BAQ
consistently outperforms prior offline-to-online RL approaches, achieving
faster recovery, improved robustness, and higher overall performance. Our
results demonstrate that implicit behavior adaptation is a principled and
practical solution for reliable real-world policy deployment.

</details>


### [99] [Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2511.03710)
*Guanning Zeng,Zhaoyi Zhou,Daman Arora,Andrea Zanette*

Main category: cs.LG

TL;DR: RLVR（Reinforcement Learning with Verifiable Rewards）使用策略梯度方法对大型推理模型（LRMs）进行后训练。为了稳定训练，这些方法通常通过减去每个提示的经验平均值来中心化轨迹奖励。本文提出了一种基于收缩（shrinkage）的基线，通过结合每个提示和跨提示的平均值来改进每个提示的平均估计精度，从而在低生成状态下降低策略梯度估计器的方差。该方法在理论上和经验上都被证明优于现有的经验平均基线，能够降低梯度更新的方差并提高训练稳定性。


<details>
  <summary>Details</summary>
Motivation: RLVR在后训练大型推理模型（LRMs）方面表现出色，但为了稳定训练，通常需要对轨迹奖励进行中心化处理，这涉及到每个提示的平均奖励估计。传统方法使用每个提示的经验平均值，但在低生成状态下估计精度不高，导致策略梯度估计器的方差较大，影响训练稳定性。

Method: 本文提出了一种基于收缩（shrinkage）的基线，灵感来源于Stein悖论。该方法通过结合每个提示的平均值和跨提示的平均值来估计每个提示的平均奖励，从而提高估计精度。这种收缩估计器可以在现有的每个提示的平均基线中即插即用，无需额外的超参数或计算。

Result: 在理论上，该方法能够降低策略梯度估计器的方差，从而提高训练稳定性。在经验上，收缩基线一致优于标准的经验平均基线，导致更低的梯度更新方差和更高的训练稳定性。

Conclusion: 本文提出了一种基于收缩的基线，可以有效改进RLVR中每个提示的平均奖励估计，从而降低策略梯度估计器的方差，提高大型推理模型的训练稳定性。该方法简单、高效，且无需额外调整。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for post-training large reasoning models (LRMs) using
policy-gradient methods such as GRPO. To stabilize training, these methods
typically center trajectory rewards by subtracting the empirical mean for each
prompt. Statistically, this centering acts as a control variate (or baseline),
reducing the variance of the policy-gradient estimator.
  Typically, the mean reward is estimated using per-prompt empirical averages
for each prompt in a batch. Drawing inspiration from Stein's paradox, we
propose using shrinkage estimators that combine per-prompt and across-prompt
means to improve the overall per-prompt mean estimation accuracy --
particularly in the low-generation regime typical of RLVR. Theoretically, we
construct a shrinkage-based baseline that provably yields lower-variance
policy-gradient estimators across algorithms. Our proposed baseline serves as a
drop-in replacement for existing per-prompt mean baselines, requiring no
additional hyper-parameters or computation. Empirically, shrinkage baselines
consistently outperform standard empirical-mean baselines, leading to
lower-variance gradient updates and improved training stability.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [100] [Establishing Trust in Crowdsourced Data](https://arxiv.org/abs/2511.03016)
*Iffat Gheyas,Muhammad Rizwan Asghar,Steve Schneider,Alan Woodward*

Main category: cs.SI

TL;DR: 该研究系统性地审查了众包平台中的信任管理实践，并提出了通过整合先进人工智能工具、透明声誉指标、去中心化审查、结构化社区参与和“软实力”策略来增强数据可靠性和公平分配决策权的解决方案。


<details>
  <summary>Details</summary>
Motivation: 众包数据在实时决策中发挥着重要作用，但面临错误信息、数据不准确和贡献者权力集中等挑战，因此本研究旨在探讨和改进众包平台中的信任管理实践，以提高数据可靠性和决策的公平性。

Method: 本研究系统性地审查了以下几类众包平台中的信任管理实践：志愿地理信息、维基生态系统、社交媒体、移动众包以及专业审查和环境众包。

Result: 识别出的优点包括自动化审核和社区验证，而局限性则涉及数据洪流、小众监督漏洞、不透明的信任指标以及精英主导。

Conclusion: 为了应对现有挑战，研究提出了整合先进人工智能工具、透明声誉指标、去中心化审核、结构化社区参与和“软实力”策略，旨在公平分配决策权并提升整体数据可靠性。

Abstract: Crowdsourced data supports real-time decision-making but faces challenges
like misinformation, errors, and contributor power concentration. This study
systematically examines trust management practices across platforms categorised
as Volunteered Geographic Information, Wiki Ecosystems, Social Media, Mobile
Crowdsensing, and Specialised Review and Environmental Crowdsourcing.
Identified strengths include automated moderation and community validation,
while limitations involve rapid data influx, niche oversight gaps, opaque trust
metrics, and elite dominance. Proposed solutions incorporate advanced AI tools,
transparent reputation metrics, decentralised moderation, structured community
engagement, and a ``soft power'' strategy, aiming to equitably distribute
decision-making authority and enhance overall data reliability.

</details>


### [101] [Beyond Citations: Measuring Idea-level Knowledge Diffusion from Research to Journalism and Policy-making](https://arxiv.org/abs/2511.03378)
*Yangliu Fan,Kilian Buehling,Volker Stocker*

Main category: cs.SI

TL;DR: 这篇论文提出了一种新的基于文本的方法来衡量社会科学知识在研究、新闻和政策制定领域中的思想层面传播，发现传播模式和动态在思想之间差异很大，而且研究和政策之间的距离通常大于研究和新闻之间的距离。


<details>
  <summary>Details</summary>
Motivation: 尽管社会科学知识对各种利益相关者很重要，但衡量其在不同领域传播仍然是一个挑战。

Method: 本研究使用了72,703份文档（2000-2019年），这些文档来自研究、新闻和政策制定三个领域。研究人员计算了这些思想在每个领域中被提及的次数，估计了它们特定于领域的上下文，并跟踪和比较了领域之间和时间上的差异。研究还使用了嵌入回归方法来比较跨领域的情境化意义。

Result: 社会科学知识的传播模式和动态在思想之间差异很大。研究发现，研究和政策之间的距离通常大于研究和新闻之间的距离。思想在跨领域中角色发生了很大转变，从研究中的理论到新闻中的意义构建，再到政策中的应用管理用途。随着时间的推移，主要针对实践导向的思想出现了语义趋同。

Conclusion: 本研究描述了社会科学知识在思想层面上的跨领域传播模式和动态，并讨论了超越引文衡量知识传播的意义。

Abstract: Despite the importance of social science knowledge for various stakeholders,
measuring its diffusion into different domains remains a challenge. This study
uses a novel text-based approach to measure the idea-level diffusion of social
science knowledge from the research domain to the journalism and policy-making
domains. By doing so, we expand the detection of knowledge diffusion beyond the
measurements of direct references. Our study focuses on media effects theories
as key research ideas in the field of communication science. Using 72,703
documents (2000-2019) from three domains (i.e., research, journalism, and
policy-making) that mention these ideas, we count the mentions of these ideas
in each domain, estimate their domain-specific contexts, and track and compare
differences across domains and over time. Overall, we find that diffusion
patterns and dynamics vary considerably between ideas, with some ideas
diffusing between other domains, while others do not. Based on the embedding
regression approach, we compare contextualized meanings across domains and find
that the distances between research and policy are typically larger than
between research and journalism. We also find that ideas largely shift roles
across domains - from being the theories themselves in research to sense-making
in news to applied, administrative use in policy. Over time, we observe
semantic convergence mainly for ideas that are practically oriented. Our
results characterize the cross-domain diffusion patterns and dynamics of social
science knowledge at the idea level, and we discuss the implications for
measuring knowledge diffusion beyond citations.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [102] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: ALAS是一个有状态、面向中断的框架，它将规划与非循环验证分开，记录版本化执行日志，并执行局部修复以保留正在进行的工作。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多智能体规划中表现出脆弱性，存在验证循环、状态变化未跟踪和全局重新计算成本高的问题。

Method: ALAS框架将规划与非循环验证分离，记录版本化执行日志以进行检查和还原，并通过局部修复保留进行中的工作。验证器独立于规划LLM运行，使用新鲜、有界上下文，避免自检循环。修复协议在明确策略下编辑最小受影响区域，这些策略在映射到Amazon States Language和Argo Workflows的规范工作流IR中定义。

Result: 在作业车间调度套件的五个经典基准测试中，ALAS的成功率达到83.7%，比强大的单一LLM和多智能体基线更高或相当，token使用量减少60%，运行速度快1.82倍。可靠性研究表明，验证器能以低开销检测结构故障，局部修复能有效控制运行时扰动。

Conclusion: 验证器隔离、版本化执行日志和局部修复的结合为多智能体LLM规划提供了可衡量的效率、可行性和可伸缩性。

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [103] [PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework](https://arxiv.org/abs/2511.03023)
*Sina Montazeri,Yunhe Feng,Kewei Sha*

Main category: cs.AI

TL;DR: PublicAgent是一个多智能体框架，通过将任务分解给专门的智能体，解决了大型语言模型在处理端到端分析工作流时的局限性。


<details>
  <summary>Details</summary>
Motivation: 开放数据存储库对非专家来说难以访问，因为他们缺乏数据集发现、模式映射和统计分析方面的专业知识。大型语言模型在处理端到端分析工作流时存在局限性，例如注意力分散、推理模式干扰和错误传播。

Method: PublicAgent是一个多智能体框架，它将任务分解为意图澄清、数据集发现、分析和报告等专门的智能体。这种架构在每个阶段都保持了智能体上下文的集中注意力并支持验证。

Result: 评估了五种模型和50个查询，导出了多智能体LLM系统的五个设计原则：1. 智能体专业化独立于模型强度提供价值；2. 智能体分为通用（发现、分析）和条件（报告、意图）类别；3. 智能体缓解了不同的故障模式；4. 架构优势在任务复杂性上保持稳定；5. 智能体在不同模型间的有效性存在很大差异，需要模型感知的架构设计。

Conclusion: 这些原则指导了在何时以及为何需要对复杂分析工作流进行专业化，同时通过自然语言接口实现了对公共数据的更广泛访问。

Abstract: Open data repositories hold potential for evidence-based decision-making, yet
are inaccessible to non-experts lacking expertise in dataset discovery, schema
mapping, and statistical analysis. Large language models show promise for
individual tasks, but end-to-end analytical workflows expose fundamental
limitations: attention dilutes across growing contexts, specialized reasoning
patterns interfere, and errors propagate undetected. We present PublicAgent, a
multi-agent framework that addresses these limitations through decomposition
into specialized agents for intent clarification, dataset discovery, analysis,
and reporting. This architecture maintains focused attention within agent
contexts and enables validation at each stage. Evaluation across five models
and 50 queries derives five design principles for multi-agent LLM systems.
First, specialization provides value independent of model strength--even the
strongest model shows 97.5% agent win rates, with benefits orthogonal to model
scale. Second, agents divide into universal (discovery, analysis) and
conditional (report, intent) categories. Universal agents show consistent
effectiveness (std dev 12.4%) while conditional agents vary by model (std dev
20.5%). Third, agents mitigate distinct failure modes--removing discovery or
analysis causes catastrophic failures (243-280 instances), while removing
report or intent causes quality degradation. Fourth, architectural benefits
persist across task complexity with stable win rates (86-92% analysis, 84-94%
discovery), indicating workflow management value rather than reasoning
enhancement. Fifth, wide variance in agent effectiveness across models (42-96%
for analysis) requires model-aware architecture design. These principles guide
when and why specialization is necessary for complex analytical workflows while
enabling broader access to public data through natural language interfaces.

</details>


### [104] [No-Human in the Loop: Agentic Evaluation at Scale for Recommendation](https://arxiv.org/abs/2511.03051)
*Tao Zhang,Kehui Yao,Luyi Ma,Jiao Chen,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: ScalingEval是一个大规模基准研究，系统地比较了36个LLM在多个产品类别中的表现，并提出了一套共识驱动的评估协议。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）作为评估者，对于构建可扩展和值得信赖的评估流程至关重要。

Method: 本文提出了ScalingEval，这是一个大规模基准研究，采用共识驱动的评估协议，系统地比较了36个LLMs（包括GPT、Gemini、Claude和Llama）。该研究使用多智能体框架，通过可扩展的多数投票将模式审计和问题代码聚合为基本事实标签，从而在无需人工标注的情况下实现LLM评估器的可重复比较。

Result: 应用于大规模互补项目推荐，该基准研究报告了四个关键发现：
(i) Anthropic Claude 3.5 Sonnet实现了最高的决策置信度；
(ii) Gemini 1.5 Pro在所有类别中提供了最佳的整体性能；
(iii) GPT-4o提供了最有利的延迟-准确性-成本权衡；
(iv) GPT-OSS 20B在开源模型中处于领先地位。
类别层面分析显示，在结构化领域（电子产品，体育）存在强烈共识，但在生活方式类别（服装，食品）中存在持续分歧。

Conclusion: 这些结果确立了ScalingEval作为一个可重复的LLM评估基准和评估协议，为扩展性、可靠性和模型系列权衡提供了可操作的指导。

Abstract: Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

</details>


### [105] [Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework](https://arxiv.org/abs/2511.03179)
*Varun Kumar,George Em Karniadakis*

Main category: cs.AI

TL;DR: 本文提出了一个多智能体AI框架，通过结构化设计和审查循环来形式化工程设计过程，并通过NACA翼型气动优化案例进行了演示。


<details>
  <summary>Details</summary>
Motivation: 传统的工程设计方法资源密集且效率低下，需要整合多领域专业知识并进行迭代改进，以解决复杂协作和效率低下的问题。

Method: 该框架通过一个多智能体AI框架形式化了工程设计过程，该框架集成了结构化设计和审查循环。该框架引入了专门的知识驱动智能体，这些智能体协同工作以生成和细化设计候选方案。该框架由三个关键AI智能体组成：图本体学家、设计工程师和系统工程师。图本体学家使用大型语言模型（LLM）从翼型设计文献中构建两个领域特定的知识图。系统工程师根据人类管理器的指导，制定技术要求，以指导设计生成和评估。设计工程师利用设计知识图和计算工具提出符合这些要求的候选翼型。系统工程师使用自己的知识图对设计进行定性和定量审查并提供反馈，形成迭代反馈循环，直到设计通过管理器验证。最终设计经过优化，以最大化升阻比等性能指标。

Result: 通过一个多智能体AI框架形式化了工程设计过程，并通过将知识图谱、大型语言模型与计算工具结合，实现了NACA翼型的气动优化。

Conclusion: 这项工作展示了配备结构化知识表示的协作AI智能体如何提高工程设计过程的效率、一致性和质量，解决了传统方法资源消耗大和效率低下的问题。

Abstract: The engineering design process often demands expertise from multiple domains,
leading to complex collaborations and iterative refinements. Traditional
methods can be resource-intensive and prone to inefficiencies. To address this,
we formalize the engineering design process through a multi-agent AI framework
that integrates structured design and review loops. The framework introduces
specialized knowledge-driven agents that collaborate to generate and refine
design candidates. As an exemplar, we demonstrate its application to the
aerodynamic optimization of 4-digit NACA airfoils. The framework consists of
three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems
Engineer. The Graph Ontologist employs a Large Language Model (LLM) to
construct two domain-specific knowledge graphs from airfoil design literature.
The Systems Engineer, informed by a human manager, formulates technical
requirements that guide design generation and evaluation. The Design Engineer
leverages the design knowledge graph and computational tools to propose
candidate airfoils meeting these requirements. The Systems Engineer reviews and
provides feedback both qualitative and quantitative using its own knowledge
graph, forming an iterative feedback loop until a design is validated by the
manager. The final design is then optimized to maximize performance metrics
such as the lift-to-drag ratio. Overall, this work demonstrates how
collaborative AI agents equipped with structured knowledge representations can
enhance efficiency, consistency, and quality in the engineering design process.

</details>


### [106] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: LLMs在现实世界概率分布知识方面表现不佳，这意味着它们在干预和反事实知识方面也受到限制。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理现实世界概率分布知识方面的能力，尤其是其是否能内化这些分布。

Method: 本文开发了首个基准来直接测试语言模型（LLMs）对描述现实世界人口的经验分布的访问能力，涵盖经济、健康、教育和社会行为等领域。

Result: LLMs的整体表现不佳，似乎没有自然地内化现实世界的统计数据。

Conclusion: LLMs似乎没有内化现实世界的统计数据，因此，它们在干预和反事实知识方面也受到限制。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [107] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: 本文介绍了SnapStream，一种用于大型语言模型（LLMs）KV缓存的压缩方法，它在减少内存使用的同时保持了高精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）参数量和上下文长度的增加，导致对片上内存中KV缓存的需求也随之增加。虽然存在StreamingLLM和SnapKV等技术来控制KV缓存大小和保持模型精度，但这些技术未能在vLLM或SGLang等工业部署框架中广泛应用。原因有二：这些框架采用的静态图和持续批处理方法使得修改标准多头注意力算法变得困难；此类技术对现代指令遵循和推理模型的精度影响尚不明确。

Method: 本文探讨了KV缓存压缩技术对Llama-3.1-8B-Instruct和DeepSeek-R1模型的精度影响，并开发了SnapStream。SnapStream是一种KV缓存压缩方法，其核心在于稀疏KV注意力技术。

Result: SnapStream在DeepSeek-671B的16路张量并行部署中展示了其有效性，实现了4倍的片上内存使用改进，并且在LongBench-v2、AIME24和LiveCodeBench上引入了最小的精度下降。SnapStream支持在128k上下文长度下，每秒高达1832个token的处理速度。

Conclusion: SnapStream首次将稀疏KV注意力技术应用于具有静态图和持续批处理的生产推理系统，有效解决了大型语言模型KV缓存对内存的巨大需求，同时保持了模型的精度。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [108] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的通用LLM监控方法，即基于能力的监控。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM监控方法是从传统机器学习继承而来的，它们是基于任务的，并假设数据集漂移会导致性能下降。然而，LLM并非针对特定任务进行训练，因此不能假设模型性能下降是由于人群变化造成的。

Method: 本文提出了一种新的基于能力的监控方法，该方法是可扩展的，并基于LLM的开发和使用方式。这种方法围绕共享的模型能力（如总结、推理、翻译或安全护栏）来组织监控，而不是独立评估每个下游任务。

Result: 通过这种方法，可以跨任务检测系统性弱点、长尾错误和新兴行为，而这些是基于任务的监控可能会遗漏的。

Conclusion: 基于能力的监控将为医疗保健领域LLM和未来通用人工智能模型的安全、适应性和协作监控提供可扩展的基础。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [109] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 本文分析了miniF2F数据集中形式化和非形式化陈述的差异，并提出了miniF2F-v2，以提高自动化形式化和定理证明的准确性。


<details>
  <summary>Details</summary>
Motivation: 在数学奥林匹克竞赛中，AI系统需要理解自然语言问题、将其形式化并证明。然而，现有方法在miniF2F基准测试上的表现远低于预期，作者旨在通过识别并修正形式化与非形式化陈述之间的差异来提高AI在此类任务中的表现。

Method: 1. 从AI系统角度分析miniF2F基准测试中的形式化和非形式化陈述。2. 识别并纠正miniF2F中形式化和非形式化陈述之间的错误、差异和简化。3. 提出miniF2F-v2，其中包含完全验证过的形式化和非形式化陈述及证明。4. 评估改进后的定理证明流程在miniF2F-v2上的表现。

Result: 1. 现有最佳模型的端到端准确率约为36%，远低于自动化形式化（97%）和定理证明（69%）的单独准确率。2. 准确率下降的主要原因是miniF2F中超过一半问题存在形式化和非形式化陈述之间的差异。3. 在miniF2F-v2上，定理证明的准确率可达70%，相比原始miniF2F的40%有显著提升。

Conclusion: 更高质量的基准测试（如miniF2F-v2）有助于社区更好地评估形式化推理领域的进展，并诊断自动化形式化和定理证明模型的失效和成功模式，揭示了自动化形式化模型与定理证明器之间存在显著的不一致性。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [110] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 该研究通过引入多模态大语言模型（MLLM）来改进烟花算法（FWA），从而解决了优化问题中的非凸、高维和黑盒特性。


<details>
  <summary>Details</summary>
Motivation: 传统的零阶或一阶优化方法在处理复杂优化问题时效率低下且无法有效利用优化信息。大语言模型在语言理解和代码生成方面的最新进展，为设计优化算法提供了新的机遇。

Method: 选择烟花算法（FWA）作为基础优化器，并提出一种新方法，通过融合多模态大语言模型（MLLM）来辅助FWA的设计。核心思想是引入“关键部分（CP）”概念，该概念扩展了FWA以处理复杂高维任务，并利用MLLM的多模态特性从优化过程中获取信息。

Result: 在旅行商问题（TSP）和电子设计自动化问题（EDA）上进行了实验。结果表明，在新框架下生成的FWA在许多问题实例上取得了与现有最优（SOTA）结果相当或超越SOTA的结果。

Conclusion: 通过结合多模态大语言模型，改进了烟花算法，使其能更有效地处理复杂的优化问题，并在特定任务上达到了SOTA表现。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [111] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 本文提出了一个新颖的安全响应框架，通过在输入端精细化风险分类和输出端结合RAG与微调解释模型，显著提升了大型语言模型的安全性，并在实验中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的广泛应用带来了日益突出的安全问题，这严重制约了它们在关键领域的可信部署。

Method: 该框架在输入层面采用基于监督微调的安全分类模型，通过四级分类法（安全、不安全、有条件安全、重点关注）对用户查询进行风险识别和分级处理。在输出层面，框架将检索增强生成（RAG）与专门微调的解释模型相结合，确保所有响应都基于实时、可信的知识库。

Result: 所提出的安全控制模型在公共安全评估基准上比基线模型TinyR1-Safety-8B取得了更高的安全分数。在专有的高风险测试集上，框架的组件达到了100%的安全分数。

Conclusion: 本研究提供了一条构建高安全性、高信任度大型语言模型应用的有效工程路径。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [112] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了一种验证形式化可解释器的新方法，并通过评估PyXAI证实了其重要性，发现PyXAI在大多数数据集中会生成不正确的解释。


<details>
  <summary>Details</summary>
Motivation: 正式可解释人工智能（XAI）提供了独特的理论严谨性保证，但其在实际应用中的验证却很少受到关注。

Method: 本文开发了一种新颖的方法来验证形式化可解释器，并评估了公开可用的形式化可解释器PyXAI。

Result: 实验发现PyXAI在大多数分析的数据集上都计算出了不正确的解释。

Conclusion: 本文提出的新方法对于验证形式化可解释器至关重要。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [113] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个名为Summit Concierge的领域特定AI助手，它在Adobe Summit中用于处理活动相关查询，并通过人机协作开发流程解决了数据稀疏、质量保证和快速部署等挑战。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在企业环境中提高生产力、简化信息访问和改善用户体验的生成式AI助手，尤其是在Adobe Summit这样的领域特定活动中处理各种查询。

Method: 采用人机协作开发流程，结合提示工程、检索基础和轻量级人工验证。

Result: 成功部署了Summit Concierge AI助手，它能处理各种活动相关查询，并解决了数据稀疏性、质量保证和快速部署等实际挑战。

Conclusion: 敏捷、反馈驱动的开发方法能够实现可扩展和可靠的AI助手，即使在冷启动场景下也能表现良好。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [114] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: 研究了大型语言模型（LLMs）如何模拟人类心理特质的相关结构，发现LLMs能从最少的量化输入中准确捕捉人类心理结构，其生成响应的量表间相关模式与人类数据高度一致。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）是否以及如何根据最少的量化输入，模拟人类心理特质的相关结构。

Method: 研究人员使用816名人类个体的大五人格量表回答来提示各种LLMs，使其扮演角色，对其他九个心理量表做出反应。通过比较LLMs生成响应的量表间相关模式与人类数据的相关模式来评估LLMs的准确性。还分析了LLMs的推理过程。

Result: LLMs在捕捉人类心理结构方面表现出卓越的准确性，LLM生成响应的量表间相关模式与人类数据高度吻合（R^2 > 0.89）。这种零样本性能远超基于语义相似性的预测，并接近直接在数据集上训练的机器学习算法的准确性。LLMs的推理过程是：首先将大五人格原始回答转化为自然语言人格摘要，然后根据这些摘要生成目标量表回答。

Conclusion: LLMs可以通过抽象和推理过程，从最少的数据中精确预测个体参与者的心理特质。这不仅为心理模拟提供了一个强大的工具，也为理解LLMs的 emergent 推理能力提供了宝贵的见解。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [115] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 这篇论文全面理论研究了各种机器学习模型中解释性问题的参数化复杂性。


<details>
  <summary>Details</summary>
Motivation: 尽管普遍认为机器学习模型是黑箱，但本文关注于内部机制透明的模型，旨在填补可解释人工智能（XAI）领域的空白。

Method: 本文分析了决策树、决策集、决策列表、布尔电路及其集成模型中的溯因和对比解释问题（包括局部和全局变体）。

Result: 这项研究为可解释人工智能（XAI）领域提供了基础性的理解，揭示了为这些模型生成解释的复杂性。

Conclusion: 本文为XAI领域的进一步研究提供了重要见解，并促进了关于AI系统透明度和可 F 责性的广泛讨论。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>
