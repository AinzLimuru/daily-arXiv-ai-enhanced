<div id=toc></div>

# Table of Contents

- [cs.GT](#cs.GT) [Total: 2]
- [cs.SI](#cs.SI) [Total: 4]
- [cs.IT](#cs.IT) [Total: 6]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [1] [BG-FlipIn: A Bayesian game framework for FlipIt-insider models in advanced persistent threats](https://arxiv.org/abs/2510.07430)
*Yang Jiao,Guanpu Chen,Yiguang Hong*

Main category: cs.GT

TL;DR: 本文提出一个名为BG-FlipIn的贝叶斯博弈框架，用于分析具有不同偏好的内部威胁。研究发现防守方行动率、成本和内部人员偏好对高级持续性威胁的影响，并为防守方提供决策指导。


<details>
  <summary>Details</summary>
Motivation: 解决内部人员偏好不确定性对高级持续性威胁（APT）带来的挑战。

Method: 提出BG-FlipIn贝叶斯博弈框架，用于FlipIt-内部人员模型，并研究恶意、无意或腐败的内部人员。计算了封闭形式的贝叶斯纳什均衡表达式，并得到了三种确定性内部人员的边缘情况下的纳什均衡表达式。

Result: 发现了防守方行动率和成本、以及内部人员偏好对APT的影响规律。研究发现BG-FlipIn框架能帮助防守方在不同参数条件下持续做出决策，避免频繁调整策略或检测内部人员具体偏好。

Conclusion: BG-FlipIn框架为应对具有不确定偏好的内部威胁APT提供了一种有效的贝叶斯博弈分析工具，并能为防守方提供实用的决策指导。

Abstract: In this paper, we study advanced persistent threats (APT) with an insider who
has different preferences. To address the uncertainty of the insider's
preference, we propose the BG-FlipIn: a Bayesian game framework for
FlipIt-insider models with an investigation on malicious, inadvertent, or
corrupt insiders. We calculate the closed-form Bayesian Nash Equilibrium
expression and further obtain three edge cases with deterministic insiders
corresponding to their Nash Equilibrium expressions. On this basis, we further
discover several phenomena in APT related to the defender's move rate and cost,
as well as the insider's preferences. We then provide decision-making guidance
for the defender, given different parametric conditions. Two applications
validate that our BG-FlipIn framework enables the defender to make decisions
consistently, avoiding detecting the insider's concrete preference or adjusting
its strategy frequently.

</details>


### [2] [Extending Games beyond the Finite Horizon](https://arxiv.org/abs/2510.08453)
*Kiri Sakahara,Takashi Sato*

Main category: cs.GT

TL;DR: 该文提出有限时间悖论源于标准数系在模拟认知感知无限性方面的限制。为解决此问题，作者提出了一个基于替代集合理论（AST）的新框架。


<details>
  <summary>Details</summary>
Motivation: 解决有限时间悖论，该悖论指博弈论与直觉相悖，源于标准数系在模拟无限性认知感知方面的局限性。

Method: 提出一种基于替代集合理论（AST）的新框架，该框架使用不同的拓扑结构来表示对长事件历史的不同认知视角。这些拓扑结构定义了一种不可辨别等价，将巨大、不可区分的数量形式化地视为等价，从而为 Selten 的连锁店悖论和 Rosenthal 的蜈蚣博弈等长期存在的悖论提供了依赖于标准的解决方案。

Result: 该框架揭示了新的直观子博弈完美均衡，其特征取决于所选择的时间视角和收益评估。

Conclusion: 通过将数学基础 H 植根于人类认知的不同模式，该工作扩展了博弈论在长周期情景下的解释力。

Abstract: This paper argues that the finite horizon paradox, where game theory
contradicts intuition, stems from the limitations of standard number systems in
modelling the cognitive perception of infinity. To address this issue, we
propose a new framework based on Alternative Set Theory (AST). This framework
represents different cognitive perspectives on a long history of events using
distinct topologies. These topologies define an indiscernibility equivalence
that formally treats huge, indistinguishable quantities as equivalent. This
offers criterion-dependent resolutions to long-standing paradoxes, such as
Selten's chain store paradox and Rosenthal's centipede game. Our framework
reveals new intuitive subgame perfect equilibria, the characteristics of which
depend on the chosen temporal perspective and payoff evaluation. Ultimately, by
grounding its mathematical foundation in different modes of human cognition,
our work expands the explanatory power of game theory for long-horizon
scenarios.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [3] [From Keywords to Clusters: AI-Driven Analysis of YouTube Comments to Reveal Election Issue Salience in 2024](https://arxiv.org/abs/2510.07821)
*Raisa M. Simoes,Timoteo Kelly,Eduardo J. Simoes,Praveen Rao*

Main category: cs.SI

TL;DR: 本文分析了YouTube评论，以找出2024年总统选举中影响选民选择的主要问题，发现移民和民主是关键因素。


<details>
  <summary>Details</summary>
Motivation: 探索不同的数据科学方法，以确定2024年总统选举中对选民选择影响最大的问题。

Method: 采用自然语言处理和聚类分析两种方法，挖掘了选举前一周来自右倾媒体（华尔街日报）和左倾媒体（纽约时报）YouTube视频下的8000多条用户评论，量化了评论中各议题的提及频率。

Result: 移民和民主是用户评论中最频繁且持续被提及的问题，其次是身份政治，而通货膨胀被提及的频率显著较低。

Conclusion: 在线用户数据的意见挖掘分析比民意调查更能揭示选举结果，移民和民主问题对选民选择的影响大于通货膨胀。

Abstract: This paper aims to explore two competing data science methodologies to
attempt answering the question, "Which issues contributed most to voters'
choice in the 2024 presidential election?" The methodologies involve novel
empirical evidence driven by artificial intelligence (AI) techniques. By using
two distinct methods based on natural language processing and clustering
analysis to mine over eight thousand user comments on election-related YouTube
videos from one right leaning journal, Wall Street Journal, and one left
leaning journal, New York Times, during pre-election week, we quantify the
frequency of selected issue areas among user comments to infer which issues
were most salient to potential voters in the seven days preceding the November
5th election. Empirically, we primarily demonstrate that immigration and
democracy were the most frequently and consistently invoked issues in user
comments on the analyzed YouTube videos, followed by the issue of identity
politics, while inflation was significantly less frequently referenced. These
results corroborate certain findings of post-election surveys but also refute
the supposed importance of inflation as an election issue. This indicates that
variations on opinion mining, with their analysis of raw user data online, can
be more revealing than polling and surveys for analyzing election outcomes.

</details>


### [4] [Do We Really Need SFT? Prompt-as-Policy over Knowledge Graphs for Cold-start Next POI Recommendation](https://arxiv.org/abs/2510.08012)
*Jinze Wang,Lu Zhang,Yiyang Cui,Zhishu Shen,Xingjun Ma,Jiong Jin,Tiehua Zhang*

Main category: cs.SI

TL;DR: 本文提出了一个名为“Prompt-as-Policy”的强化学习引导框架，通过上下文bandit优化动态构建提示，以解决冷启动条件下的下一兴趣点推荐问题，并在真实世界数据集中取得了显著优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 在旅游、餐饮和交通等智能城市服务中，下一兴趣点（POI）推荐至关重要。然而，大多数现有方法在用户-POI交互稀疏的冷启动条件下表现不佳。尽管最近利用大型语言模型（LLMs）的方法试图通过监督微调（SFT）或上下文学习（ICL）解决这一问题，但SFT需要高昂的标注成本且难以泛化到非活跃用户，而ICL中的静态提示无法适应多样的用户上下文。

Method: 我们提出了一个名为“Prompt-as-Policy over knowledge graphs”的强化学习引导的提示框架。该框架通过上下文bandit优化学习动态构建提示。具体而言，我们的方法将提示构建视为一个可学习的策略，该策略自适应地决定：（i）包含哪些关系证据，（ii）每个候选的证据数量，以及（iii）它们在提示中的组织和排序。我们构建了一个知识图谱（KG）来发现候选POI并挖掘关系路径，这些路径被转换为证据卡片，总结了每个候选POI的理由。然后，冻结的LLM作为推理引擎，根据策略优化的提示，从KG发现的候选集中生成推荐。

Result: 在三个真实世界数据集上的实验表明，“Prompt-as-Policy”方法始终优于最先进的基线方法，在非活跃用户的Acc@1指标上平均相对提高了7.7%，同时在活跃用户上保持了有竞争力的性能，且无需进行模型微调。

Conclusion: “Prompt-as-Policy”是一个有效的下一兴趣点推荐方法，尤其擅长处理冷启动问题。它通过动态提示构建和知识图谱集成，显著提高了推荐性能，并克服了传统LLM方法的局限性。

Abstract: Next point-of-interest (POI) recommendation is crucial for smart urban
services such as tourism, dining, and transportation, yet most approaches
struggle under cold-start conditions where user-POI interactions are sparse.
Recent efforts leveraging large language models (LLMs) address this challenge
through either supervised fine-tuning (SFT) or in-context learning (ICL).
However, SFT demands costly annotations and fails to generalize to inactive
users, while static prompts in ICL cannot adapt to diverse user contexts. To
overcome these limitations, we propose Prompt-as-Policy over knowledge graphs,
a reinforcement-guided prompting framework that learns to construct prompts
dynamically through contextual bandit optimization. Our method treats prompt
construction as a learnable policy that adaptively determines (i) which
relational evidences to include, (ii) the number of evidence per candidate, and
(iii) their organization and ordering within prompts. More specifically, we
construct a knowledge graph (KG) to discover candidates and mine relational
paths, which are transformed into evidence cards that summarize rationales for
each candidate POI. The frozen LLM then acts as a reasoning engine, generating
recommendations from the KG-discovered candidate set based on the
policy-optimized prompts. Experiments on three real-world datasets demonstrate
that Prompt-as-Policy consistently outperforms state-of-the-art baselines,
achieving average 7.7\% relative improvements in Acc@1 for inactive users,
while maintaining competitive performance on active users, without requiring
model fine-tuning.

</details>


### [5] [Geometric opinion exchange polarizes in every dimension](https://arxiv.org/abs/2510.08190)
*Abdou Majeed Alidou,Júlia Baligács,Jan Hązła*

Main category: cs.SI

TL;DR: 这篇论文研究了在d个主题上同时追踪智能体意见的意见交换模型。


<details>
  <summary>Details</summary>
Motivation: 以往的研究已经证明了d=2时的极化特性，但d≥3的一般情况仍未解决。

Method: 本研究使用了对模型动态和随机过程理论工具更详细的理解。

Result: 这项工作解决了d≥3的一般情况。

Conclusion: 该模型似乎会将意见极化为两个对立的群体。这与许多其他倾向于达成共识的已知模型形成对比。

Abstract: A recent line of work studies models of opinion exchange where agent opinions
about $d$ topics are tracked simultaneously. The opinions are represented as
vectors on the unit $(d-1)$-sphere, and the update rule is based on the overall
correlation between the relevant vectors. The update rule reflects the
assumption of biased assimilation, i.e., a pair of opinions is brought closer
together if their correlation is positive and further apart if the correlation
is negative.
  This model seems to induce the polarization of opinions into two antipodal
groups. This is in contrast to many other known models which tend to achieve
consensus. The polarization property has been recently proved for $d=2$, but
the general case of $d \ge 3$ remained open. In this work, we settle the
general case, using a more detailed understanding of the model dynamics and
tools from the theory of random processes.

</details>


### [6] [Forecasting the Buzz: Enriching Hashtag Popularity Prediction with LLM Reasoning](https://arxiv.org/abs/2510.08481)
*Yifei Xu,Jiaying Wu,Herun Wan,Yang Li,Zhen Hou,Min-Yen Kan*

Main category: cs.SI

TL;DR: BuzzProphet是一个结合了大型语言模型（LLM）和经典回归器的框架，用于预测社交媒体标签的流行度。它通过LLM的语义分析能力增强了预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管Hashtag趋势能显著影响公共舆论和广告支出，但预测其流行度仍面临挑战。传统回归模型忽视上下文，而LLMs在数值预测上表现不佳。

Method: BuzzProphet首先引导LLM分析标签的话题病毒性、受众范围和时间优势，然后利用这些分析结果丰富输入特征，最后通过回归模型进行预测。

Result: 在HashView数据集上，BuzzProphet将均方根误差（RMSE）降低了2.8%，并使相关性比基线提高了30%。同时，它还能生成人类可读的解释。

Conclusion: 将LLMs作为上下文推理器而非数值预测器，可以为表格模型注入领域洞察力，从而为社交媒体趋势预测提供一个可解释且可部署的解决方案。

Abstract: Hashtag trends ignite campaigns, shift public opinion, and steer millions of
dollars in advertising spend, yet forecasting which tag goes viral is elusive.
Classical regressors digest surface features but ignore context, while large
language models (LLMs) excel at contextual reasoning but misestimate numbers.
We present BuzzProphet, a reasoning-augmented hashtag popularity prediction
framework that (1) instructs an LLM to articulate a hashtag's topical virality,
audience reach, and timing advantage; (2) utilizes these popularity-oriented
rationales to enrich the input features; and (3) regresses on these inputs. To
facilitate evaluation, we release HashView, a 7,532-hashtag benchmark curated
from social media. Across diverse regressor-LLM combinations, BuzzProphet
reduces RMSE by up to 2.8% and boosts correlation by 30% over baselines, while
producing human-readable rationales. Results demonstrate that using LLMs as
context reasoners rather than numeric predictors injects domain insight into
tabular models, yielding an interpretable and deployable solution for social
media trend forecasting.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [7] [List Recoverable Codes: The Good, the Bad, and the Unknown (hopefully not Ugly)](https://arxiv.org/abs/2510.07597)
*Nicolas Resch,S. Venkitesh*

Main category: cs.IT

TL;DR: 这篇论文是对列表恢复码的综述，探讨了它的可能性、不可能性以及在理论计算机科学中的应用。


<details>
  <summary>Details</summary>
Motivation: 列表恢复是纠错码的一个基本任务，它推广了最坏情况误差的唯一解码和列表解码。

Method: 本文通过介绍列表恢复码的“好”（存在性结果）、“坏”（不可能性结果）和“未知”来综述列表恢复码的最新进展。

Result: 列表恢复码最初是作为列表解码级联码的一个组成部分引入的，但后来在理论计算机科学的其他主题中找到了广泛的应用和联系。

Conclusion: 列表恢复是纠错码和理论计算机科学中的一个重要且多功能的问题。

Abstract: List recovery is a fundamental task for error-correcting codes, vastly
generalizing unique decoding from worst-case errors and list decoding. Briefly,
one is given ''soft information'' in the form of input lists S_1,...,S_n of
bounded size, and one argues that there are not too many codewords that agree a
lot with this soft information. This general problem appears in many guises,
both within coding theory and in theoretical computer science more broadly.
  In this article we survey recent results on list recovery codes, introducing
both the ''good'' (i.e., possibility results, showing that codes with certain
list recoverability exist), the ''bad'' (impossibility results), and the
''unknown''. We additionally demonstrate that, while list recoverable codes
were initially introduced as a component in list decoding concatenated codes,
they have since found myriad applications to and connections with other topics
in theoretical computer science.

</details>


### [8] [Is star complexity a proxy for information based complexity of graphs?](https://arxiv.org/abs/2510.07722)
*Russell K. Standish*

Main category: cs.IT

TL;DR: 本文讨论了信息复杂度（IBC）以及图的复测方法，并提出了一个与星形复杂度强相关的IBC度量。


<details>
  <summary>Details</summary>
Motivation: 探索不同的信息复杂度度量方法，并验证它们之间的渐近等价性，特别是在图的复杂度测量方面。

Method: 本文首先介绍了信息复杂度（IBC）的概念及其在通用图灵机条件下的渐近独立性。然后，回顾了Standish提出的基于图链接编码和自同构识别的图IBC度量C。接着，引入了星形复杂度（star complexity）这一替代度量，它定义为生成原始图所需的基本星形图的并集和交集操作的数量。虽然星形复杂度本身不是一个IBC度量，但文章将其与一个强相关的IBC度量C*联系起来。为了进行实证比较，本文构建了星形复杂度高达8的10顶点和22顶点图，并将C*与C进行了比较。最后，本文还发现了一个易于计算的星形复杂度上限，并发现它与C密切相关。

Result: 通过构建10顶点和22顶点图并进行实证比较，发现与星形复杂度强相关的IBC度量C*与Standish提出的IBC度量C之间存在关联。同时，发现一个易于计算的星形复杂度上限与C密切相关。

Conclusion: 任何实用的信息复杂度度量在渐近上都与其他度量等价。文章通过比较C和C*验证了这一假设，并指出星形复杂度与IBC度量之间存在显著关系，并且可以找到其易于计算的上限。

Abstract: Information-based complexity (IBC) is a well-defined complexity measure of
any object given a description in a language and a classifier that identifies
those descriptions with the object. Of course, the exact numerical value will
vary according to the descriptive language and classifier, but under certain
universality conditions (eg the classifier identifies programs of a universal
Turning machine that halt and output the same value), asymptotically, the
complexity measure is independent of the classifier up to a constant of O(1).
The hypothesis being investigated in this work that any practical IBC measure
will similarly be asymptotically equivalent to any other practical IBC measure.
Standish presented an IBC measure for graphs ${\cal C}$ that encoded graphs by
their links, and identifies graphs as those that are automorphic to each other.
An interesting alternate graph measure is {\em star complexity}, which is
defined as the number of union and intersection operations of basic stars that
can generate the original graph. Whilst not an IBC itself, it can be related to
an IBC (called ${\cal C}^*$) that is strongly correlated with star complexity.
In this paper, 10 and 22 vertex graphs are constructed up to a star complexity
of 8, and the ${\cal C}^*$ compared emprically with ${\cal C}$. Finally, an
easily computable upper bound of star complexity is found to be strongly
related to ${\cal C}$.

</details>


### [9] [Integrated Localization, Mapping, and Communication through VCSEL-Based Light-emitting RIS (LeRIS)](https://arxiv.org/abs/2510.08071)
*Rashid Iqbal,Dimitrios Bozanis,Dimitrios Tyrovolas,Christos K. Liaskos,Muhammad Ali Imran,George K. Karagiannidis,Hanaa Abumarshoud*

Main category: cs.IT

TL;DR: 本文提出了一种基于VCSEL的LeRIS架构，可实现用户定位、障碍物感知绘图和毫米波通信，具有厘米级定位精度、鲁棒的障碍物检测、高频谱效率和显著的用户最小速率增益，是6G无线系统多功能PWEs的可扩展和实用集成使能器。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LED的LeRIS设计存在漫发射或需要笨重传感模块的LiDAR辅助方案。本文旨在提出一种更紧凑、低功耗且易于分析的LeRIS架构，以支持可编程无线环境（PWEs）中的用户定位、障碍物感知绘图和毫米波通信。

Method: 本文提出了一种集成垂直腔面发射激光器（VCSELs）的LeRIS架构。该方法利用窄高斯光束和多模分集，通过接收信号强度联合恢复用户位置和方向，并利用双模操作在特定几何条件下减少VCSELs需求。同时，引入了一种基于VCSEL的映射方法，利用反射信号到达时间测量来检测障碍物并引导抗阻塞RIS波束路由。

Result: 仿真结果表明，该系统具有毫米级定位精度、鲁棒的障碍物检测、高频谱效率和用户最小速率的显著增益。

Conclusion: VCSEL-based LeRIS可以作为一种可扩展和实用的使能技术，用于构建具有多功能PWEs的弹性6G无线系统。

Abstract: This paper presents a light-emitting reconfigurable intelligent surface
(LeRIS) architecture that integrates vertical cavity surface emitting lasers
(VCSELs) to jointly support user localization, obstacle-aware mapping, and
millimeter-wave (mmWave) communication in programmable wireless environments
(PWEs). Unlike prior light-emitting diode (LED)-based LeRIS designs with
diffuse emission or LiDAR-assisted schemes requiring bulky sensing modules, the
proposed VCSEL-based approach exploits narrow Gaussian beams and multimode
diversity to enable compact, low-power, and analytically tractable integration.
We derive closed-form expressions to jointly recover user position and
orientation from received signal strength using only five VCSELs, and reduce
this requirement to three under specific geometric conditions by leveraging
dual-mode operation. In parallel, we introduce a VCSEL-based mapping method
that uses reflected signal time-of-arrival measurements to detect obstructions
and guide blockage-resilient RIS beam routing. Simulation results demonstrate
millimeter-level localization accuracy, robust obstacle detection, high
spectral efficiency, and substantial gains in minimum user rate. These findings
establish VCSEL-based LeRIS as a scalable and practically integrable enabler
for resilient 6G wireless systems with multi-functional PWEs.

</details>


### [10] [Near-optimal Rank Adaptive Inference of High Dimensional Matrices](https://arxiv.org/abs/2510.08117)
*Frédéric Zheng,Yassir Jedra,Alexandre Proutiere*

Main category: cs.IT

TL;DR: 本文关注于设计最优的秩自适应算法，用于从线性测量中估计高维矩阵。


<details>
  <summary>Details</summary>
Motivation: 解决从线性测量中估计高维矩阵的问题，并设计最优的秩自适应算法。

Method: 提出了一种结合最小二乘估计器和通用奇异值阈值处理过程的算法，并通过增强的矩阵去噪方法分析来支持。

Result: 建立了此类算法样本复杂度的实例特定下限，揭示了选择有效秩的根本权衡；提出算法的有限样本误差界，并证明其性能接近于理论极限。

Conclusion: 所提出的算法在从线性测量中估计高维矩阵方面表现出色，其性能接近理论最优，并在多元回归和线性动力系统识别中得到验证。

Abstract: We address the problem of estimating a high-dimensional matrix from linear
measurements, with a focus on designing optimal rank-adaptive algorithms. These
algorithms infer the matrix by estimating its singular values and the
corresponding singular vectors up to an effective rank, adaptively determined
based on the data. We establish instance-specific lower bounds for the sample
complexity of such algorithms, uncovering fundamental trade-offs in selecting
the effective rank: balancing the precision of estimating a subset of singular
values against the approximation cost incurred for the remaining ones. Our
analysis identifies how the optimal effective rank depends on the matrix being
estimated, the sample size, and the noise level. We propose an algorithm that
combines a Least-Squares estimator with a universal singular value thresholding
procedure. We provide finite-sample error bounds for this algorithm and
demonstrate that its performance nearly matches the derived fundamental limits.
Our results rely on an enhanced analysis of matrix denoising methods based on
singular value thresholding. We validate our findings with applications to
multivariate regression and linear dynamical system identification.

</details>


### [11] [Exponential Error Bounds for Information Bottleneck Source Coding Problems](https://arxiv.org/abs/2510.08364)
*Han Wu,Hamdi Joudeh*

Main category: cs.IT

TL;DR: 本文研究了信息瓶颈（IB）源编码的过量失真概率，并建立了精确的误差指数和强逆指数。此外，本文还在编码层面建立了IB源编码与带有辅助器的源编码（WAK问题）之间的联系。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究信息瓶颈（IB）源编码问题，特别是其在对数损失下的过量失真概率。此外，研究还希望能将IB源编码与带有辅助器的源编码（WAK问题）联系起来。

Method: 本文通过推导匹配的上下指数界来建立IB源编码的精确误差指数和精确强逆指数。这些指数涉及对辅助随机变量的优化。匹配的逆界是通过对现有球封装和单字母化技术的非平凡扩展而得出的，这些技术经过调整以包含辅助随机变量。此外，本文通过证明WAK问题的每一个代码都是IB源编码的代码，从而建立了两者之间的代码层面联系。

Result: 本文为IB源编码建立了精确的误差指数和精确的强逆指数。此外，本文还通过将IB源编码与带有辅助器的源编码（WAK问题）联系起来，重新推导了WAK问题中已知的最佳球封装指数，并提供了操作性解释。

Conclusion: 本文成功地研究了信息瓶颈（IB）源编码的过量失真概率，并建立了相关的误差指数和强逆指数。通过将IB源编码与WAK问题联系起来，本文不仅深化了对这两种编码方式的理解，也为WAK问题提供了新的操作性解释。

Abstract: We study the information bottleneck (IB) source coding problem, also known as
remote lossy source coding under logarithmic loss. Based on a rate-limited
description of noisy observations, the receiver produces a soft estimate for
the remote source, i.e., a probability distribution, evaluated under the
logarithmic loss. We focus on the excess distortion probability of IB source
coding and investigate how fast it converges to 0 or 1, depending on whether
the rate is above or below the rate-distortion function. The latter case is
also known as the exponential strong converse. We establish both the exact
error exponent and the exact strong converse exponent for IB source coding by
deriving matching upper and lower exponential bounds. The obtained exponents
involve optimizations over auxiliary random variables. The matching converse
bounds are derived through non-trivial extensions of existing sphere packing
and single-letterization techniques, which we adapt to incorporate auxiliary
random variables.
  In the second part of this paper, we establish a code-level connection
between IB source coding and source coding with a helper, also known as the
Wyner-Ahlswede-K\"orner (WAK) problem. We show that every code for the WAK
problem is a code for IB source coding. This requires noticing that IB source
coding, under the excess distortion criterion, is equivalent to source coding
with a helper available at both the transmitter and the receiver; the latter in
turn relates to the WAK problem. Through this connection, we re-derive the best
known sphere packing exponent of the WAK problem, and provide it with an
operational interpretation.

</details>


### [12] [A Rate-Distortion Bound for ISAC](https://arxiv.org/abs/2510.08487)
*Mohammadreza Bakhshizadeh Mohajer,Alex Dytso,Daniela Tuninetti,Luca Barletta*

Main category: cs.IT

TL;DR: 本文介绍了一种基于率失真理论的新型逆界，用于解决集成传感与通信（ISAC）系统的基本性能限制。


<details>
  <summary>Details</summary>
Motivation: 解决现有估计理论（如贝叶斯克拉默-劳界限，BCRB）在ISAC系统性能限制分析中存在的局限性，特别是其严格的正则性条件。

Method: 引入了一种基于率失真理论的率失真界限（RDB）。该方法适用于任意参数分布和失真度量（包括均方误差和错误概率）。

Result: 所提出的RDB在1.高传感噪声条件下被证明是紧密的。2.在低传感噪声条件下，RDB可以比BCRB更紧密。3.在Nakagami衰落信道估计中，RDB在BCRB不适用时仍能提供有效界限。4.在二元占用检测任务中，RDB展示了其对离散传感问题的通用性。

Conclusion: 这项工作提供了一个强大而通用的工具，用于表征ISAC系统中最终的性能权衡。

Abstract: This paper addresses the fundamental performance limits of Integrated Sensing
and Communication (ISAC) systems by introducing a novel converse bound based on
rate-distortion theory. This rate-distortion bound (RDB) overcomes the
restrictive regularity conditions of classical estimation theory, such as the
Bayesian Cram\'er-Rao Bound (BCRB). The proposed framework is broadly
applicable, holding for arbitrary parameter distributions and distortion
measures, including mean-squared error and probability of error. The bound is
proved to be tight in the high sensing noise regime and can be strictly tighter
than the BCRB in the low sensing noise regime. The RDB's utility is
demonstrated on two challenging scenarios: Nakagami fading channel estimation,
where it provides a valid bound even when the BCRB is inapplicable, and a
binary occupancy detection task, showcasing its versatility for discrete
sensing problems. This work provides a powerful and general tool for
characterizing the ultimate performance tradeoffs in ISAC systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [13] [Network Topology and Information Efficiency of Multi-Agent Systems: Study based on MARL](https://arxiv.org/abs/2510.07888)
*Xinren Zhang,Sixi Cheng,Zixin Zhong,Jiadong Yu*

Main category: cs.MA

TL;DR: 本文探讨了多智能体系统中通信拓扑和信息效率对系统性能的影响，提出了通过优化通信拓扑和引入衡量信息效率的指标，可以提高多智能体系统的性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在解决复杂问题时面临非平稳性和部分可观测性挑战，而智能体间的通信可以提供解决方案，但最佳的通信结构和评估方法仍不清楚。

Method: 本文研究了有向和顺序通信拓扑，并提出了信息熵效率指数（IEI）和专业化效率指数（SEI）两个指标来评估消息的紧凑性和角色分化，并将这些指标纳入训练目标。

Result: 研究表明，有向和顺序拓扑结构可以提高同质和异质任务的性能，并减少通信开销。将提出的效率指标纳入训练目标可以提高成功率和收敛速度。

Conclusion: 设计具有信息高效消息传递的自适应通信拓扑对于复杂多智能体系统中的有效协调至关重要。

Abstract: Multi-agent systems (MAS) solve complex problems through coordinated
autonomous entities with individual decision-making capabilities. While
Multi-Agent Reinforcement Learning (MARL) enables these agents to learn
intelligent strategies, it faces challenges of non-stationarity and partial
observability. Communications among agents offer a solution, but questions
remain about its optimal structure and evaluation. This paper explores two
underexamined aspects: communication topology and information efficiency. We
demonstrate that directed and sequential topologies improve performance while
reducing communication overhead across both homogeneous and heterogeneous
tasks. Additionally, we introduce two metrics -- Information Entropy Efficiency
Index (IEI) and Specialization Efficiency Index (SEI) -- to evaluate message
compactness and role differentiation. Incorporating these metrics into training
objectives improves success rates and convergence speed. Our findings highlight
that designing adaptive communication topologies with information-efficient
messaging is essential for effective coordination in complex MAS.

</details>
