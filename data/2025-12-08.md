<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.IT](#cs.IT) [Total: 2]
- [stat.ML](#stat.ML) [Total: 4]
- [cs.LG](#cs.LG) [Total: 42]
- [cs.AI](#cs.AI) [Total: 19]
- [cs.GT](#cs.GT) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale](https://arxiv.org/abs/2512.05179)
*Aurélie Montfrond*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个为利默里克大学电子与计算机工程系开发的聊天机器人，旨在为学生提供课程信息。该研究通过在大学模块手册上构建了包含1203个问答对的数据集，并对BERT模型进行了微调，以适应教育领域的特定问答任务。


<details>
  <summary>Details</summary>
Motivation: 此前的科学问答工作主要集中在聊天机器人系统，对基础模型在特定领域推理方面的微调探索有限。该研究旨在解决大学课程材料领域缺乏定制基础模型的问题。

Method: 1. 构建了一个包含1203个问答对的自定义数据集，数据来源于大学模块手册，并辅以手动和合成生成。2. 使用PyTorch对BERT模型进行了微调。3. 使用Exact Match和F1分数评估模型性能。

Result: 研究结果表明，即便是适度的微调也能提高假设框架和知识提取能力，这证明了将基础模型应用于教育领域的可行性。

Conclusion: 通过使用学术问答对微调BERT，本研究取得了有效的结果，突出了构建大学领域特定问答模型的潜力，并有望实现自主教育知识系统。

Abstract: Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.

</details>


### [2] [Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting](https://arxiv.org/abs/2512.05243)
*P. D. Edgar,Alia Hall*

Main category: cs.CL

TL;DR: 该研究探讨了诗歌提示模式在提示工程中的应用，以及大型语言模型在文本生成和代码创作方面的能力。


<details>
  <summary>Details</summary>
Motivation: 创作人员和学者们利用大型语言模型（LLMs）来开发创意作品并探索其写作能力的边界，特别是在文本生成和代码创作方面。

Method: 本研究提出了一种名为“诗歌提示模式”（Poetry Prompt Patterns）的创造性文本提示方法，并概述了该方法的实施过程。

Result: 通过使用诗歌提示来评估一位著名诗人的三种模型描述和评价，并测试模型修改或重写原创文学作品以适应假定受众的意愿。

Conclusion: 诗歌提示模式可以成为提示工程师工具箱的有用补充。

Abstract: Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.

</details>


### [3] [Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4](https://arxiv.org/abs/2512.05256)
*Ivan Makohon,Mohamad Najafi,Jian Wu,Mathias Brochhausen,Yaohang Li*

Main category: cs.CL

TL;DR: 该研究探讨了使用思维链（CoT）提示工程结合语义搜索结果和知识图谱来改进大型语言模型（LLM）在临床笔记生成方面的表现。


<details>
  <summary>Details</summary>
Motivation: 过去十年中，美国电子健康记录（EHR）数据量激增，但医生手动书写临床笔记耗时，增加了患者等待时间并可能延误诊断。因此，需要一种方法来提高临床笔记生成的效率和质量。

Method: 本研究结合了传统的思维链（CoT）提示工程与语义搜索结果，并融入了基于临床本体构建的知识图谱，以丰富生成临床笔记的领域特定知识。输入信息包括国际疾病分类（ICD）代码和患者基本信息。

Result: 在CodiEsp测试数据集的六个临床案例上使用GPT-4进行测试，结果表明该提示技术优于标准的一次性提示生成的临床笔记。

Conclusion: 将思维链提示工程与语义搜索和知识图谱相结合，可以有效提高大型语言模型在临床笔记生成方面的质量和准确性，从而可能缩短病历书写时间并改善患者护理。

Abstract: In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts.

</details>


### [4] [To Think or Not to Think: The Hidden Cost of Meta-Training with Excessive CoT Examples](https://arxiv.org/abs/2512.05318)
*Vignesh Kothapalli,Ata Fatahibaarzi,Hamed Firooz,Maziar Sanjabi*

Main category: cs.CL

TL;DR: 本文提出了一种名为CoT-Recipe的元训练策略，通过调整CoT和非CoT示例的混合比例，显著提升了大型语言模型在处理新颖任务时的推理能力，即使在上下文中没有可用的CoT示例。


<details>
  <summary>Details</summary>
Motivation: CoT提示与少样本情境学习结合，极大地提升了大型语言模型的推理能力，但在预训练知识不足的情况下，带有CoT示例的情境学习在新任务上表现不佳。

Method: 本文在CoT-ICL Lab框架下进行受控研究，并提出了元训练技术，以在上下文中学习新颖的抽象推理任务。为解决CoT示例过多导致的性能下降，本文提出了CoT-Recipe，一种正式的方法来调节元训练序列中CoT和非CoT示例的混合比例。

Result: 通过CoT-Recipe的精心调节，在没有CoT示例的情况下，将Transformer在新任务上的准确率提高了高达300％。将这些技术应用于预训练的LLM（Qwen2.5系列）进行符号推理任务时，准确率提高了高达130％。

Conclusion: CoT-Recipe通过优化元训练过程中CoT和非CoT示例的混合，显著提高了大型语言模型在新颖推理任务上的性能，即使在资源受限的情况下也能表现出色。

Abstract: Chain-of-thought (CoT) prompting combined with few-shot in-context learning (ICL) has unlocked significant reasoning capabilities in large language models (LLMs). However, ICL with CoT examples is ineffective on novel tasks when the pre-training knowledge is insufficient. We study this problem in a controlled setting using the CoT-ICL Lab framework, and propose meta-training techniques to learn novel abstract reasoning tasks in-context. Although CoT examples facilitate reasoning, we noticed that their excessive inclusion during meta-training degrades performance when CoT supervision is limited. To mitigate such behavior, we propose CoT-Recipe, a formal approach to modulate the mix of CoT and non-CoT examples in meta-training sequences. We demonstrate that careful modulation via CoT-Recipe can increase the accuracy of transformers on novel tasks by up to 300% even when there are no CoT examples available in-context. We confirm the broader effectiveness of these techniques by applying them to pretrained LLMs (Qwen2.5 series) for symbolic reasoning tasks and observing gains of up to 130% in accuracy.

</details>


### [5] [Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats](https://arxiv.org/abs/2512.05331)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee,Mostafa Musharrat,Sai Vishnu Vamsi*

Main category: cs.CL

TL;DR: 这篇论文研究了“粉泥新闻”的检测，这是一种模仿本地新闻报道的低质量自动生成文章。研究发现，大型语言模型（LLMs）可以增强这种新闻的欺骗性，并提出了一种新的检测框架来应对LLMs的威胁。


<details>
  <summary>Details</summary>
Motivation: 本地新闻是2800万美国人获取可靠信息的重要来源，但“粉泥新闻”对其构成了威胁。这些低质量的自动生成文章模仿合法的本地报道，因此需要一种细粒度的分析来检测它们。

Method: 本文对“粉泥新闻”的语言、文体和词汇特征进行了全面研究，以揭示其区别模式，并在此基础上提出了检测策略。此外，本文还探讨了LLMs对现有检测系统的影响。

Result: 研究发现，LLMs可以显著降低现有检测系统的性能，F1分数下降高达40%。为了应对LLMs带来的威胁，研究引入了一个鲁棒的学习框架，该框架专门设计用于抵抗基于LLMs的对抗性攻击，并能适应自动化“粉泥新闻”不断变化的格局，并在性能上取得了高达27%的提升。

Conclusion: “粉泥新闻”对本地新闻业构成了严重威胁，特别是当LLMs被用于生成或修改这些欺骗性内容时。本文提出的鲁棒学习框架能够有效应对LLMs驱动的对抗性攻击，并为“粉泥新闻”检测领域提供了新的方向。

Abstract: The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their linguistic, stylistic, and lexical characteristics. In this work, we conduct a comprehensive study to uncover the distinguishing patterns of Pink Slime content and propose detection strategies based on these insights. Beyond traditional generation methods, we highlight a new adversarial vector: modifications through large language models (LLMs). Our findings reveal that even consumer-accessible LLMs can significantly undermine existing detection systems, reducing their performance by up to 40% in F1-score. To counter this threat, we introduce a robust learning framework specifically designed to resist LLM-based adversarial attacks and adapt to the evolving landscape of automated pink slime journalism, and showed and improvement by up to 27%.

</details>


### [6] [Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change](https://arxiv.org/abs/2512.05364)
*Ananth Hariharan,David Mortensen*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种混合神经符号方法，该方法通过定量分析梵语的演变，揭示了形态复杂语言的演变规律。


<details>
  <summary>Details</summary>
Motivation: 挑战语言变化是简化的观点，希望通过分析梵语的演变，深入了解形态丰富、资源匮乏语言的演变。

Method: 该研究通过弱监督的方法解决了数据稀缺问题，使用100多个高精度正则表达式模式生成伪标签，用于微调多语言BERT。然后，他们通过新颖的置信度加权集成融合了符号和神经输出，创建了一个可扩展和可解释的系统。

Result: 将该框架应用于147万字的历时语料库，该集成系统实现了52.4%的整体特征检测率。研究结果表明，梵语的整体形态复杂性并未降低，而是动态重新分布：早期动词特征显示出周期性下降模式，但复杂性转移到其他领域，这表现为复合词的急剧扩张和新哲学术语的出现。

Conclusion: 该系统生成了经过良好校准的不确定性估计，置信度与准确性强相关（Pearson r = 0.92），整体校准误差低（ECE = 0.043），从而增强了这些发现对计算文献学的可靠性。

Abstract: This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitatively analyzing over 2,000 years of Sanskrit, demonstrating how weakly-supervised hybrid methods can yield new insights into the evolution of morphologically rich, low-resource languages. Our approach addresses data scarcity through weak supervision, using 100+ high-precision regex patterns to generate pseudo-labels for fine-tuning a multilingual BERT. We then fuse symbolic and neural outputs via a novel confidence-weighted ensemble, creating a system that is both scalable and interpretable. Applying this framework to a 1.47-million-word diachronic corpus, our ensemble achieves a 52.4% overall feature detection rate. Our findings reveal that Sanskrit's overall morphological complexity does not decrease but is instead dynamically redistributed: while earlier verbal features show cyclical patterns of decline, complexity shifts to other domains, evidenced by a dramatic expansion in compounding and the emergence of new philosophical terminology. Critically, our system produces well-calibrated uncertainty estimates, with confidence strongly correlating with accuracy (Pearson r = 0.92) and low overall calibration error (ECE = 0.043), bolstering the reliability of these findings for computational philology.

</details>


### [7] [Mitigating Self-Preference by Authorship Obfuscation](https://arxiv.org/abs/2512.05379)
*Taslim Mahbub,Shi Feng*

Main category: cs.CL

TL;DR: 本文探讨了语言模型（LM）裁判在评估LM输出时存在的自我偏好，即LM裁判倾向于偏爱自己的答案。研究提出通过黑盒扰动，如同义词替换，来模糊输出的作者身份，从而减轻自我偏好。然而，研究也发现完全消除这种偏见仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: LM裁判在评估LM输出时存在自我偏好，这会损害评估的公正性。即使在未明确标注来源的情况下，前沿LM裁判也能识别自己的输出。因此，需要研究策略以减轻这种自我偏好。

Method: 本文通过对评估候选进行黑盒扰动，例如同义词替换，来模糊输出的作者身份，从而减少LM裁判的自我识别能力，以减轻自我偏好。

Result: 简单的同义词替换扰动可以有效地降低自我偏好。然而，当扰动被扩展到更彻底地中和评估候选之间的风格差异时，自我偏好会恢复。

Conclusion: 自我识别和自我偏好发生在多个语义层面，尽管初步结果显示扰动策略有潜力，但完全消除这种偏见仍然具有挑战性。

Abstract: Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring their own answers over those produced by other LMs or humans. The bias is hard to eliminate as frontier LM judges can distinguish their own outputs from those of others, even when the evaluation candidates are not labeled with their sources. In this paper, we investigate strategies to mitigate self-preference by reducing the LM judges' ability to recognize their own outputs. We apply black-box perturbations to evaluation candidates in pairwise comparison to obfuscate the authorship and reduce self-recognition. We find that perturbations as simple as synonym replacement for a few words predictably reduce self-preference. However, we also uncover fundamental challenges to eliminating the bias: when we extrapolate our perturbations to a more complete neutralization of stylistic differences between the evaluation candidates, self-preference recovers. Our findings suggest that self-recognition and self-preference can happen on many semantic levels, and complete mitigation remains challenging despite promising initial results.

</details>


### [8] [Learning from Self Critique and Refinement for Faithful LLM Summarization](https://arxiv.org/abs/2512.05387)
*Ting-Yao Hu,Hema Swetha Koppula,Hadi Pouransari,Cem Koc,Oncel Tuzel,Raviteja Vemulapalli*

Main category: cs.CL

TL;DR: 本文提出了一种名为 SCRPO 的自我监督训练框架，通过模型的自我批评和完善能力构建偏好数据集，然后应用偏好学习来改进 LLM 的忠实总结能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在执行长篇文本生成任务（如摘要）时，经常会出现“幻觉”问题，即输出内容与输入上下文不符。

Method: SCRPO 框架首先利用 LLM 自身的批评和完善能力构建偏好数据集，然后采用偏好学习来提高 LLM 在忠实摘要方面的性能。

Result: 在 XSUM、CNNDM 和 SAMSum 三个摘要基准测试中，SCRPO 在忠实度指标方面优于最先进的自我监督学习方法，同时保持或改进了衡量摘要整体质量的其他指标。

Conclusion: SCRPO 方法不仅提高了效率，而且与测试时完善相比，能产生更忠实的摘要，解决了 LLM 幻觉问题并提高了摘要的忠实度。

Abstract: Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously generated outputs using either the same model or a more powerful teacher model as the critique. However, these approaches either require additional test-time compute or assume access to more powerful teacher models, making them costly and less practical. In this work, we propose Self Critique and Refinement-based Preference Optimization (SCRPO), which is a self-supervised training framework that first constructs a preference dataset by leveraging the LLM's own critique and refinement capabilities, and then applies preference learning to improve the same LLM for faithful summarization. Experiments on three summarization benchmarks (XSUM CNNDM and SAMSum), demonstrate that our approach outperforms state-of-the-art self-supervised learning methods in terms of faithfulness metrics while either maintaining or improving other metrics that measure the overall quality of the summary. Moreover, compared to test-time refinement, our approach not only improves efficiency but also results in more faithful summaries.

</details>


### [9] [SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs](https://arxiv.org/abs/2512.05409)
*Ruixuan Huang,Hao Zeng,Hantao Huang,Jinyuan Shi,Minghui Yu,Ian En-Hsu Yen,Shuai Wang*

Main category: cs.CL

TL;DR: 本文提出了一种稀疏量化格式（SQ-format），旨在解决大型语言模型PTQ中低位量化和稀疏化技术在精度和效率之间难以平衡的问题。SQ-format将量化和稀疏化统一在一个数据格式中，能够获得性能和吞吐量的帕累托改进。


<details>
  <summary>Details</summary>
Motivation: 现有的低位量化和稀疏化技术难以平衡精度和效率，因为硬件支持有限。例如，W4A8的峰值TOPS与W8A8相同，而GPU支持的稀疏数据格式（2:4半结构化稀疏）由于精度损失很少被采用。

Method: 本文提出了稀疏量化格式（SQ-format），这是一种统一的量化和稀疏化数据格式，可能很容易得到新硬件和现有GPU的支持。SQ-format利用了稀疏矩阵可以在高精度下加速的事实，低精度矩阵乘法也可以相应地加速。

Result: SQ-format实现了性能和吞吐量之间的帕累托改进。这种格式特别适用于具有异常值不平等状态的激活，并使其静态压缩成为可能。

Conclusion: SQ-format在PTQ性能方面表现出色，并为下一代AI加速器提供了所需硬件、设计探索和见解。

Abstract: Post-training quantization (PTQ) plays a crucial role in the democratization of large language models (LLMs). However, existing low-bit quantization and sparsification techniques are difficult to balance accuracy and efficiency due to the limited hardware support. For example, W4A8 can only achieve the same peak TOPS as W8A8 whereas the GPU-supported sparse data format (2:4 semi-structure sparse) is seldomly adopted due to the loss of accuracy. To bridge this gap, in this paper, we propose the Sparse-Quantized Format (SQ-format), which is a unified data format for quantization and sparsification potentially easily supported by new hardware and existing GPUs. SQ-format makes use of the fact that sparse matrix can be accelerated in high-precision, and low-precision matrix multiplication can also be accelerated accordingly. As such, SQ-format is proposed to achieve Pareto improvement between performance and throughput. This format is particularly suitable for activations with outlier inequality status and makes their static compression possible. We show the state-of-the-art PTQ performance with SQ-format, propose the hardware required to support it, and further offer the design exploration and insights for the next-generation AI accelerators.

</details>


### [10] [LMSpell: Neural Spell Checking for Low-Resource Languages](https://arxiv.org/abs/2512.05414)
*Akesh Gunathilakea,Nadil Karunarathnea,Tharusha Bandaranayakea,Nisansa de Silvaa,Surangika Ranathunga*

Main category: cs.CL

TL;DR: 本文探讨了预训练语言模型（PLM）在低资源语言（LRL）拼写校正中的应用，首次进行了PLM在这方面的实证研究，并发现大型语言模型（LLM）在微调数据集较大时表现优于其他模型，即使LLM未针对该语言进行预训练也是如此。


<details>
  <summary>Details</summary>
Motivation: 探索和比较预训练语言模型（PLM）在低资源语言（LRL）拼写校正中的应用。

Method: 进行了PLM在拼写校正方面的首次实证研究，包括对低资源语言的评估。发布了LMSpell工具包，其中包含补偿LLM幻觉的评估功能，并通过对僧伽罗语的案例研究探讨了LRL拼写校正的挑战。

Result: 大型语言模型（LLM）在微调数据集较大时，在拼写校正方面表现优于编码器-解码器模型。即使LLM未针对特定语言进行预训练，这一观察结果也成立。

Conclusion: LLM在低资源语言的拼写校正任务中展现出潜力，尤其是在有足够微调数据的情况下。推出的LMSpell工具包为跨PLM的拼写校正提供了便利。

Abstract: Spell correction is still a challenging problem for low-resource languages (LRLs). While pretrained language models (PLMs) have been employed for spell correction, their use is still limited to a handful of languages, and there has been no proper comparison across PLMs. We present the first empirical study on the effectiveness of PLMs for spell correction, which includes LRLs. We find that Large Language Models (LLMs) outperform their counterparts (encoder-based and encoder-decoder) when the fine-tuning dataset is large. This observation holds even in languages for which the LLM is not pre-trained. We release LMSpell, an easy- to use spell correction toolkit across PLMs. It includes an evaluation function that compensates for the hallucination of LLMs. Further, we present a case study with Sinhala to shed light on the plight of spell correction for LRLs.

</details>


### [11] [ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering](https://arxiv.org/abs/2512.05430)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: 该文章介绍了MusWikiDB和ArtistMus，它们是针对音乐领域问答的资源，利用RAG技术显著提高了大型语言模型在该领域的表现，尤其在事实准确性和上下文推理方面。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在开放域问答方面取得了进展，但由于预训练数据中音乐知识的稀疏性，它们在音乐相关推理方面的有效性有限。现有的音乐信息检索和计算音乐学资源缺乏对基于艺术家元数据或历史背景的事实性和上下文音乐问答（MQA）的支持。

Method: 本文引入了MusWikiDB，这是一个包含来自14.4万个音乐相关维基百科页面的320万个段落的向量数据库。同时，还引入了ArtistMus，这是一个包含1000个问题和500位不同艺术家的数据集，这些艺术家具有流派、首次亮相年份和主题等元数据。这些资源用于系统地评估检索增强生成（RAG）在MQA中的应用。

Result: RAG显著提高了事实准确性，使开源模型的性能提升高达56.8个百分点（例如，Qwen3 8B从35.0提高到91.8），接近专有模型的性能。RAG风格的微调进一步提升了事实回忆和上下文推理能力，改进了域内和域外基准的测试结果。与通用维基百科语料库相比，MusWikiDB的准确率提高了约6个百分点，检索速度提高了40%。

Conclusion: MusWikiDB和ArtistMus的发布旨在推动音乐信息检索和领域特定问答的研究，为音乐等文化丰富领域的检索增强推理奠定基础。这些资源和方法为解决大型语言模型在特定领域知识方面的不足提供了有效的解决方案。

Abstract: Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.

</details>


### [12] [Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment](https://arxiv.org/abs/2512.05464)
*Panatchakorn Anantaprayoon,Nataliia Babina,Jad Tarifi,Nima Asgharbeygi*

Main category: cs.CL

TL;DR: 介绍了Collective Agency (CA)和Dynamic Alignment框架，以实现可扩展的、自我改进的LLM对齐，超越传统对齐规范。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM对齐方法在AI发展到AGI和ASI时可能不足，且基于人类反馈的对齐成本高昂。

Method: 提出了Collective Agency (CA)作为统一和开放式的对齐价值观，并引入了Dynamic Alignment框架。Dynamic Alignment包含两个核心组件：1）使用LLM自动生成训练数据集，2）一个自我奖励机制，其中策略模型评估自己的输出并分配奖励用于GRPO强化学习。

Result: 实验结果表明，该方法成功地将模型与CA对齐，同时保留了通用NLP能力。

Conclusion: Collective Agency和Dynamic Alignment框架为LLM的对齐提供了一个可扩展、自我改进且超越传统价值观的新途径，以适应未来AI的发展。

Abstract: Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.

</details>


### [13] [SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures](https://arxiv.org/abs/2512.05501)
*Panuthep Tasawong,Jian Gang Ngui,Alham Fikri Aji,Trevor Cohn,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 介绍了SEA-SafeguardBench，这是一个针对东南亚语言的第一个人工验证安全基准，旨在解决现有安全评估中英语中心化和对低资源语言细微差别忽视的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的安全基准英语中心化，并且忽视了低资源语言的细微差异，尤其是在东南亚语言中，这种不足导致无法捕捉到当地文化敏感的政治言论和区域性错误信息所带来的独特安全问题。

Method: 推出了SEA-SafeguardBench，一个包含八种东南亚语言、21,640个样本的人工验证安全基准，涵盖通用、实地和内容生成三个子集。

Result: 实验结果表明，即使是最先进的LLM和护栏在东南亚文化和危害场景面前也面临挑战，并且与处理英语文本时相比，表现不佳。

Conclusion: SEA-SafeguardBench的推出，填补了东南亚语言安全评估的空白，揭示了LLM和安全护栏在处理非英语、特别是文化特定有害内容时的不足，强调了未来研究需关注多语言和文化多样性安全评估。

Abstract: Safeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region's linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.

</details>


### [14] [Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches](https://arxiv.org/abs/2512.05537)
*Namu Park,Farzad Ahmed,Zhaoyi Sun,Kevin Lybarger,Ethan Breinhorst,Julie Hu,Ozlem Uzuner,Martin Gunn,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型（LLMs）在细粒度、病灶级别上检测需要随访的偶然瘤方面的能力，通过引入病灶标记输入和解剖学感知提示，取得了比监督基线更好的表现，并接近人类专家的水平。


<details>
  <summary>Details</summary>
Motivation: 目前文档级别的分类系统在检测偶然瘤方面存在局限性，特别是在细粒度、病灶级别上。

Method: 使用了包含400份放射学报告和1,623个病灶发现的注释数据集。比较了三种监督式Transformer编码器（BioClinicalModernBERT、ModernBERT、Clinical Longformer）和四种生成式LLM配置（Llama 3.1-8B、GPT-4o、GPT-OSS-20b）。引入了使用病灶标记输入和解剖学感知提示的推理策略来指导模型推理。性能评估采用类别特定的F1分数。

Result: 解剖学知情的GPT-OSS-20b模型表现最佳，偶然瘤阳性宏观F1得分0.79，超过所有监督基线（最大宏观F1：0.70），并接近评估者间一致性（0.76）。显式解剖学接地使基于GPT的模型性能显著提高（p < 0.05）。最佳系统的多数投票集成进一步将宏观F1提高到0.90。误差分析显示，解剖学感知的LLM在区分可操作发现和良性病变方面表现出卓越的上下文推理能力。

Conclusion: 生成式LLM，在结构化病灶标记和解剖学上下文的增强下，显著优于传统的监督编码器，并取得了与人类专家相当的性能。这种方法为放射学工作流程中自动化偶然发现监测提供了一条可靠、可解释的途径。

Abstract: Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.
  Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.
  Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.
  Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.

</details>


### [15] [Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems](https://arxiv.org/abs/2512.05580)
*Aurprita Mahmood,Sabrin alam,Neloy kumer Sagor,Md. Abdul Hadi,Md. Sehab Al Islam,Minhajul Islam*

Main category: cs.CL

TL;DR: 本文探讨了用于解决孟加拉语数学应用题 (MWPs) 的思维树 (ToT) 推理，结果显示 ToT 比传统的思维链 (CoT) 推理更有效，尤其对于中大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 数学应用题是自然语言处理中一项具有挑战性的任务，需要语言理解和多步骤数值推理。虽然思维链 (CoT) 提示已经显示出前景，但其线性结构常常会传播错误，限制了整体效率。

Method: 本文对孟加拉语数学应用题 (MWPs) 采用思维树 (ToT) 推理进行了系统研究，使用了 SOMADHAN 数据集。由于计算和 token 成本的限制，研究评估了 GPT-OSS 和 LLaMA 变体等多个大型语言模型 (LLMs)，在标准提示、CoT 和 ToT 策略下，对 100 个具有代表性的问题进行了评估。

Result: CoT 将基线准确率从平均 78%（标准提示）提高到 83%，而 ToT 将性能进一步提高了 5 个百分点，使用 GPT-OSS-120B 实现了 88% 的准确率。这些改进表明 ToT 在中大型模型中特别有效。

Conclusion: 思维树 (ToT) 是一种强大的框架，可以解决孟加拉语等低资源语言中的数学问题。这项研究表明，像 ToT 这样的结构化推理方法可以提供比 CoT 更可靠和全局一致的结果，为多语言自然语言处理中更好的推理策略铺平了道路。

Abstract: Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.

</details>


### [16] [Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models](https://arxiv.org/abs/2512.05658)
*Pietro Ferrazzi,Aitor Soroa,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 该论文介绍了一种生成多语言医学推理路径的方法，该路径以事实医学知识为基础。通过检索增强生成方法，利用维基百科的医学信息，生成了50万条英语、意大利语和西班牙语的推理路径。作者在MedQA和MedMCQA数据集中进行测试，结果表明，该推理路径在in-context学习和监督微调方面均能提高LLM的性能，达到了8B参数LLMs中的最新水平。


<details>
  <summary>Details</summary>
Motivation: 现有的医学问答（QA）大型语言模型（LLMs）主要以英语为中心，并且大多依赖于通用LLMs的蒸馏，这引发了对其医学知识可靠性的担忧。因此，本研究旨在生成多语言的、以事实医学知识为基础的推理路径，以支持开发更安全、透明的多语言临床决策支持工具。

Method: 本研究提出了一种生成多语言推理路径的方法，该方法以维基医学信息为基础，运用检索增强生成技术。具体方法如下：1. 利用维基百科的医学信息，生成了50万条英语、意大利语和西班牙语的推理路径。2. 选择MedQA和MedMCQA数据集中的医学问题，并将其扩展到意大利语和西班牙语。3. 在in-domain和out-of-domain设置下，对医学问答基准进行实验。4. 通过in-context learning（少样本）和监督微调两种方式，利用所生成的推理路径来提高LLMs的性能。

Result: 本研究通过实验证明，所提出的推理路径在in-context学习和监督微调方面均能显著提高LLMs的性能。在8B参数的LLMs中，该方法取得了最先进的结果。这些推理路径能够支持开发更安全、更透明的多语言临床决策支持工具。

Conclusion: 本研究成功开发了一种生成多语言医学推理路径的方法，该方法以事实医学知识为基础，并利用检索增强生成技术。实验结果表明，该方法在医学问答任务中表现出色，显著提高了LLMs的性能，达到了当前8B参数LLMs的最新水平。研究资源（包括推理路径、翻译后的问答数据集、医学维基百科和微调模型）的发布，将推动多语言临床决策支持工具的发展，使其更加安全和透明。

Abstract: Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.

</details>


### [17] [Interleaved Latent Visual Reasoning with Selective Perceptual Modeling](https://arxiv.org/abs/2512.05665)
*Shuai Dong,Siyuan Wang,Xingyu Liu,Zhongyu Wei*

Main category: cs.CL

TL;DR: 该论文介绍了一种名为ILVR的框架，它通过结合动态状态演化和精确感知建模，解决了多模态大语言模型在视觉反馈推理中遇到的计算成本和感知精度问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在进行视觉反馈的交错推理时，由于图像反复编码导致计算成本过高。而潜在视觉推理虽然避免了这一问题，但又在感知精度和动态问题建模之间存在矛盾。

Method: ILVR框架通过交错文本生成和潜在视觉表示，使这些潜在视觉表示成为后续推理的特定、演化的线索。为实现此目的，该方法采用自监督策略，其中一个动量教师模型选择性地从辅助图像中提取相关特征到稀疏监督目标中，从而引导模型自主生成上下文感知的视觉信号。

Result: 在多模态推理基准测试中，ILVR显著优于现有方法。

Conclusion: ILVR框架有效地弥合了细粒度感知和序列多模态推理之间的鸿沟。

Abstract: Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of repeatedly re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet currently forces a critical trade-off: methods either sacrifice precise perceptual modeling by over-compressing features or fail to model dynamic problems due to static, non-interleaved structures. We introduce Interleaved Latent Visual Reasoning (ILVR), a framework that unifies dynamic state evolution with precise perceptual modeling. ILVR interleaves textual generation with latent visual representations that act as specific, evolving cues for subsequent reasoning. To enable this, we employ a self-supervision strategy where a Momentum Teacher Model selectively distills relevant features from helper images into sparse supervision targets. This adaptive selection mechanism guides the model to autonomously generate context-aware visual signals. Extensive experiments on multimodal reasoning benchmarks demonstrate that ILVR significantly outperforms existing approaches, effectively bridging the gap between fine-grained perception and sequential multimodal reasoning.

</details>


### [18] [MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation](https://arxiv.org/abs/2512.05671)
*Zhitao He,Haolin Yang,Zeyu Qin,Yi R Fung*

Main category: cs.CL

TL;DR: 本文介绍了ClinEdu，一个多智能体教学模拟器，以及ClinTeach，一个基于该模拟器构建的苏格拉底教学对话数据集。在此基础上，作者训练了MedTutor-R1，一个用于临床医学教育中的多模态苏格拉底导师，并通过模拟评估证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 临床培训需求与专家指导稀缺之间的巨大差距对医学教育构成了主要挑战。当前的LLM研究主要集中在一对一的知识教学上，忽略了协作推理，而这恰好是学生在团队合作中（如查房）培养的关键技能。

Method: 1. **开发ClinEdu：** 一个多智能体教学模拟器，具有个性驱动的患者和多样化的学生群体，支持复杂教学过程的受控测试和可扩展的教学数据生成。
2. **构建ClinTeach：** 基于ClinEdu构建的大规模苏格拉底教学对话数据集，捕捉小组教学的复杂性。
3. **训练MedTutor-R1：** 
    - 首先在ClinTeach数据集上进行指令微调。
    - 其次，使用源自三轴评估标准（涵盖结构保真度、分析质量和临床安全性）的奖励进行强化学习优化，以完善其自适应苏格拉底策略。
4. **评估：** 采用基于模拟的交互式评估，将导师重新部署到ClinEdu中进行真实情境评估。

Result: MedTutor-R1在平均教学得分上比基础模型高出20%以上，并且与O3模型表现相当，同时在处理不同数量的学生时也表现出高度的适应性。

Conclusion: 所提出的教学模拟器ClinEdu和苏格拉底导师MedTutor-R1在解决医学教育专家指导稀缺问题方面表现出有效性和前景。

Abstract: The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current research focuses mainly on one-on-one knowledge instruction, overlooking collaborative reasoning, a key skill for students developed in teamwork like ward rounds. To this end, we develop ClinEdu, a multi-agent pedagogical simulator with personality-driven patients and diverse student cohorts, enabling controlled testing of complex pedagogical processes and scalable generation of teaching data. Based on ClinEdu, we construct ClinTeach, a large Socratic teaching dialogue dataset that captures the complexities of group instruction. We then train MedTutor-R1, the first multimodal Socratic tutor designed for one-to-many instruction in clinical medical education. MedTutor-R1 is first instruction-tuned on our ClinTeach dataset and then optimized with reinforcement learning, using rewards derived from a three-axis rubric, covering structural fidelity, analytical quality, and clinical safety, to refine its adaptive Socratic strategies. For authentic in-situ assessment, we use simulation-based interactive evaluation that redeploys the tutor back into ClinEdu. Experimental results demonstrate that our MedTutor-R1 outperforms the base model by over 20% in average pedagogical score and is comparable to o3, while also exhibiting high adaptability in handling a varying number of students. This promising performance underscores the effectiveness of our pedagogical simulator, ClinEdu.

</details>


### [19] [Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods](https://arxiv.org/abs/2512.05681)
*Tereza Novotna,Jakub Harasta*

Main category: cs.CL

TL;DR: 这篇论文比较了两个模型在捷克宪法法院判决中的案例法检索，并提出了一个噪声感知评估框架。


<details>
  <summary>Details</summary>
Motivation: 比较大型通用嵌入器（OpenAI）和领域特定BERT模型在案例法检索中的表现，并提出一个鲁棒的评估框架以应对噪声标签的司法数据库。

Method: 比较了两个模型：一个大型通用嵌入器（OpenAI）和一个在约30,000份判决书上从头开始训练的领域特定BERT模型。采用噪声感知评估方法，包括IDF加权关键词重叠作为分级相关性，通过两个阈值（0.20平衡，0.28严格）进行二值化，以及通过配对自举法进行显著性检验，并辅以定性分析的nDCG诊断。

Result: 尽管绝对nDCG值不高，但通用的OpenAI嵌入器在两种设置和@10/@20/@100的所有阈值下，都明显优于预训练的领域特定BERT模型，且差异具有统计学意义。诊断结果表明，较低的绝对值是由于标签漂移和强烈的理想化，而非缺乏实用性。

Conclusion: OpenAI大型通用嵌入器在案例法检索中表现优于领域特定BERT模型。提出的评估框架对于处理带有异构标签的噪声司法数据集是鲁棒且有效的。

Abstract: Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.

</details>


### [20] [Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains](https://arxiv.org/abs/2512.05700)
*Ben Malin,Tatiana Kalganova,Nikolaos Boulgouris*

Main category: cs.CL

TL;DR: 该论文提出了一个用于提高大型语言模型（LLM）忠实度评估准确性的方法。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型（LLM）输出的忠实度，并使其评估方法更准确。

Method: 该方法通过结合基本的忠实度指标，形成一个融合指标。融合策略采用树形模型来识别每个指标的重要性，并结合了人类对LLM响应忠实度的判断。

Result: 融合后的指标在所有测试领域中与人类判断的忠实度相关性更强。此外，作者还标准化了问答和对话领域的数据集，并将其与人类判断和LLM响应结合，以便于忠实度评估的复现和测试。

Conclusion: 该研究通过引入融合忠实度指标，显著提高了LLM忠实度评估的准确性，从而增强了对模型部署到更多场景的信心。

Abstract: We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.

</details>


### [21] [Efficient Text Classification with Conformal In-Context Learning](https://arxiv.org/abs/2512.05732)
*Ippokratis Pantelidis,Korbinian Randl,Aron Henriksson*

Main category: cs.CL

TL;DR: CICLe是一个将轻量级分类器与共形预测相结合的框架，它利用LLM的上下文学习能力来减少候选类别的数量。它在文本分类任务中表现出优于基线和更强的效率，尤其适用于类别不平衡的任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本分类方面的有效性高度依赖于提示设计并产生大量计算成本，CICLe的广泛适用性和效率尚未得到系统探索。

Method: 本文对CICLe在各种NLP分类基准上进行了全面评估，通过将轻量级基础分类器与共形预测相结合，自适应地减少候选类别集来指导LLM提示。

Result: CICLe始终优于其基础分类器，并在训练样本量充足时优于少样本提示基线，在低数据量情况下表现相当。CICLe将样本数量和提示长度分别减少了34.45%和25.16%，并且可以使用较小的模型实现有竞争力的性能，特别适用于类别不平衡的文本分类任务。

Conclusion: CICLe是一种实用且可扩展的文本分类方法，结合了传统分类器的鲁棒性和LLM的适应性，在数据和计算效率方面取得了显著提升。

Abstract: Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.

</details>


### [22] [Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments](https://arxiv.org/abs/2512.05832)
*Yifei Tong*

Main category: cs.CL

TL;DR: 本研究调查了美国最高法院口头辩论中，打断对律师言语的语义内容和情感语调的影响，特别关注司法 S 话语中的性别动态。


<details>
  <summary>Details</summary>
Motivation: 探究打断对律师言语的语义内容和情感语调的影响，并研究司法话语中的性别动态。

Method: 使用 ConvoKit 最高法院语料库（2010-2019），分析了 12,663 个律师与法官互动中的 S 话语片段。通过 GloVe 构建的句子嵌入量化语义 S 变化，通过基于词典的分析测量 S 情感。

Result: 打断前后言语的语义相似性始终 S 很高，表明打断并未实质性改变 S 论证内容。然而，针对女性律师的打断 S 含有明显更高水平的负面 S 情感。

Conclusion: 这些结果加深了对精英机构 S 环境中性别沟通的实证理解，并 S 展示了计算语言学方法在研究司法 S 程序中的权力、话语和 S 公平方面的价值。

Abstract: This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.

</details>


### [23] [Prompting Science Report 4: Playing Pretend: Expert Personas Don't Improve Factual Accuracy](https://arxiv.org/abs/2512.05858)
*Savir Basil,Ina Shapiro,Dan Shapiro,Ethan Mollick,Lilach Mollick,Lennart Meincke*

Main category: cs.CL

TL;DR: 这篇论文研究了为AI模型分配角色对回答困难多项选择题性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索为AI模型分配角色（专家或低知识角色）是否能提高其在困难多项选择题上的表现，例如在GPQA Diamond和MMLU-Pro基准测试中。

Method: 作者测试了三种角色分配方法：领域内专家角色、领域外专家角色和低知识角色。在GPQA Diamond和MMLU-Pro这两个包含科学、工程和法律等研究生级别问题的基准测试上，评估了六个模型的性能。

Result: 领域内专家角色对模型性能没有显著影响，领域外专家角色导致了微小的差异，而低知识角色通常会损害基准测试的准确性。总体而言，角色提示并没有提高准确性。

Conclusion: 为AI模型分配角色通常不会提高其在困难多项选择题上的准确性。专家角色没有显示出持续的好处，而低知识角色往往会降低准确性。未来研究可以探索角色在其他方面的作用，例如改变输出的语气。

Abstract: This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law.
  We tested three approaches:
  -In-Domain Experts: Assigning the model an expert persona ("you are a physics expert") matched to the problem type (physics problems) had no significant impact on performance (with the exception of the Gemini 2.0 Flash model).
  -Off-Domain Experts (Domain-Mismatched): Assigning the model an expert persona ("you are a physics expert") not matched to the problem type (law problems) resulted in marginal differences.
  -Low-Knowledge Personas: We assigned the model negative capability personas (layperson, young child, toddler), which were generally harmful to benchmark accuracy.
  Across both benchmarks, persona prompts generally did not improve accuracy relative to a no-persona baseline. Expert personas showed no consistent benefit across models, with few exceptions. Domain-mismatched expert personas sometimes degraded performance. Low-knowledge personas often reduced accuracy. These results are about the accuracy of answers only; personas may serve other purposes (such as altering the tone of outputs), beyond improving factual performance.

</details>


### [24] [Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework](https://arxiv.org/abs/2512.05863)
*Tasnimul Hassan,Md Faisal Karim,Haziq Jeelani,Elham Behnam,Robert Green,Fayeq Jeelani Syed*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个基于检索增强生成（RAG）的医疗问答系统，该系统结合了领域特定的知识检索和开源大型语言模型，以提高医学问题回答的准确性和减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 直接将大型语言模型应用于临床领域存在挑战，例如难以保持事实准确性和避免幻觉。

Method: 该系统通过使用LoRA技术对LLaMA-2和Falcon两种开源大型语言模型进行微调，以实现领域专业化。它还检索相关的医学文献来支持大型语言模型的回答。

Result: 检索增强显著提高了答案的准确性，微调后的LLaMA-2模型在PubMedQA数据集上达到了71.8%的准确率，比零样本基线提高了55.4%。此外，该方法将大型语言模型生成的不受支持内容的比例降低了约60%。

Conclusion: RAG增强的开源大型语言模型在可靠的生物医学问答方面具有巨大潜力，可应用于实际的临床信息学。

Abstract: Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.

</details>


### [25] [M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG](https://arxiv.org/abs/2512.05959)
*David Anugraha,Patrick Amadeus Irawan,Anshul Singh,En-Shiun Annie Lee,Genta Indra Winata*

Main category: cs.CL

TL;DR: M4-RAG是一个涵盖42种语言和56种方言的基准，包含超过80,000个图像-问题对，用于评估多语言多模态检索增强的视觉问答。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型受限于静态训练数据，而检索增强生成（RAG）在多语言多模态RAG方面探索不足。

Method: 本文介绍了M4-RAG，一个大规模基准，涵盖42种语言和56种区域方言和语域，包含超过80,000个文化多样化的图像-问题对，用于评估跨语言和模态的检索增强VQA。为了平衡真实性和可复现性，我们构建了一个受控的检索环境，其中包含数百万精心策划的与查询领域相关的多语言文档，以模拟现实世界检索条件，同时确保一致的实验。

Result: 系统评估表明，尽管RAG始终有利于较小的VLM，但它无法扩展到较大的模型，甚至通常会降低它们的性能，这暴露了模型大小与当前检索效率之间的关键不匹配。

Conclusion: M4-RAG为推进下一代RAG系统奠定了基础，该系统能够无缝地跨语言、模态和文化背景进行推理。

Abstract: Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [26] [Uncertainty-Aware Data-Efficient AI: An Information-Theoretic Perspective](https://arxiv.org/abs/2512.05267)
*Osvaldo Simeone,Yaniv Romano*

Main category: cs.IT

TL;DR: 这篇综述探讨了在数据受限场景下，人工智能系统如何通过量化认知不确定性和通过合成数据增强来缓解数据稀缺性，从而提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人、电信和医疗保健等特定领域应用中，人工智能系统经常面临训练数据有限的挑战，这导致了可还原的认知不确定性，并从根本上限制了预测性能。

Method: 本文首先回顾了通过模型参数空间中的广义后验来描述认知不确定性的广义贝叶斯学习框架和“后贝叶斯”学习框架。接着，介绍了信息论泛化界限，这些界限将训练数据量与预测不确定性之间的关系形式化，为广义贝叶斯学习提供了理论依据。然后，本文调查了提供有限样本统计保证的不确定性量化方法，包括共形预测和共形风险控制。最后，本文研究了通过结合有限的标记数据与丰富的模型预测或合成数据来提高数据效率的最新进展。

Result: 本文提供了一个信息论视角，强调了信息度量在量化数据稀缺性影响方面的作用，并总结了缓解数据稀缺性的方法。

Conclusion: 通过量化认知不确定性和利用合成数据增强，可以有效解决数据稀缺问题，从而提高人工智能系统在数据受限应用中的预测性能。

Abstract: In context-specific applications such as robotics, telecommunications, and healthcare, artificial intelligence systems often face the challenge of limited training data. This scarcity introduces epistemic uncertainty, i.e., reducible uncertainty stemming from incomplete knowledge of the underlying data distribution, which fundamentally limits predictive performance. This review paper examines formal methodologies that address data-limited regimes through two complementary approaches: quantifying epistemic uncertainty and mitigating data scarcity via synthetic data augmentation. We begin by reviewing generalized Bayesian learning frameworks that characterize epistemic uncertainty through generalized posteriors in the model parameter space, as well as ``post-Bayes'' learning frameworks. We continue by presenting information-theoretic generalization bounds that formalize the relationship between training data quantity and predictive uncertainty, providing a theoretical justification for generalized Bayesian learning. Moving beyond methods with asymptotic statistical validity, we survey uncertainty quantification methods that provide finite-sample statistical guarantees, including conformal prediction and conformal risk control. Finally, we examine recent advances in data efficiency by combining limited labeled data with abundant model predictions or synthetic data. Throughout, we take an information-theoretic perspective, highlighting the role of information measures in quantifying the impact of data scarcity.

</details>


### [27] [Foundations of information theory for coding theory](https://arxiv.org/abs/2512.05316)
*El Mahdi Mouloua,Essaid Mohamed*

Main category: cs.IT

TL;DR: 这篇讲义介绍了信息论及其与代数编码理论的关联。


<details>
  <summary>Details</summary>
Motivation: 连接信息论的概率框架与现代编码理论中使用的结构和代数技术。

Method: 以香农的信息、熵和信道容量公式为基础，发展了量化不确定性和信息传输的数学基础，并通过二元对称信道等例子阐述了熵、条件熵、互信息和噪声信道模型等关键概念。

Result: 描述了最大似然解码原理和香农的噪声信道编码定理，该定理刻画了在噪声信道上可靠通信的理论极限。

Conclusion: 本讲义对寻求信息论概率框架与现代编码理论中使用的结构和代数技术之间联系的学生和研究人员有所帮助。

Abstract: Information theory is introduced in this lecture note with a particular emphasis on its relevance to algebraic coding theory. The document develops the mathematical foundations for quantifying uncertainty and information transmission by building upon Shannon's pioneering formulation of information, entropy, and channel capacity. Examples, including the binary symmetric channel, illustrate key concepts such as entropy, conditional entropy, mutual information, and the noisy channel model. Furthermore, the note describes the principles of maximum likelihood decoding and Shannon's noisy channel coding theorem, which characterizes the theoretical limits of reliable communication over noisy channels. Students and researchers seeking a connection between probabilistic frameworks of information theory and structural and algebraic techniques used in modern coding theory will find this work helpful.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [28] [Symmetric Linear Dynamical Systems are Learnable from Few Observations](https://arxiv.org/abs/2512.05337)
*Minh Vu,Andrey Y. Lokhov,Marc Vuffray*

Main category: stat.ML

TL;DR: 本文提出了一种新的估计器，用于在少量观测数据下学习N维随机线性动力学参数，该估计器对稀疏或稠密矩阵均有效，且不依赖于特定的正则化方法，这对于结构发现等应用非常重要。


<details>
  <summary>Details</summary>
Motivation: 在全观测和部分观测条件下，从单个T时间轨迹中学习N维随机线性动力学模型的参数。

Method: 本文引入并分析了一种新的估计器，该估计器基于矩量法，不依赖于问题特定的正则化。

Result: 该估计器在仅使用 T=O(log N) 次观测的情况下，在恢复对称动态矩阵时实现了较小的最大逐元素误差，无论矩阵是稀疏还是稠密。这对于结构发现等应用尤为重要。

Conclusion: 该研究提出了一种高效的参数学习方法，尤其适用于数据量有限且对矩阵结构无先验假设的场景，为解决复杂动态系统的参数估计问题提供了新的途径。

Abstract: We consider the problem of learning the parameters of a $N$-dimensional stochastic linear dynamics under both full and partial observations from a single trajectory of time $T$. We introduce and analyze a new estimator that achieves a small maximum element-wise error on the recovery of symmetric dynamic matrices using only $T=\mathcal{O}(\log N)$ observations, irrespective of whether the matrix is sparse or dense. This estimator is based on the method of moments and does not rely on problem-specific regularization. This is especially important for applications such as structure discovery.

</details>


### [29] [Do We Really Even Need Data? A Modern Look at Drawing Inference with Predicted Data](https://arxiv.org/abs/2512.05456)
*Stephen Salerno,Kentaro Hoffman,Awan Afiaz,Anna Neufeld,Tyler H. McCormick,Jeffrey T. Leek*

Main category: stat.ML

TL;DR: 本文分析了使用预训练模型预测数据进行推断时存在的统计挑战，并探讨了如何透明且符合统计原则地运用预测数据。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和机器学习工具的普及，以及数据收集面临的新障碍，研究人员越来越多地使用预训练算法的预测结果来替代缺失或未观察到的数据。

Method: 本文首先阐述了使用预测数据进行推断（IPD）固有的统计挑战，证明了高预测精度不一定能保证下游推断的有效性。作者指出，所有这些失效都可归结为统计学上的偏差（当预测系统性地改变估计量或扭曲变量之间的关系）和方差（当预测模型的不确定性以及真实数据的内在变异性被忽略时）。然后，文章回顾了现有的IPD方法，并讨论了该框架如何深植于经典统计理论。

Result: 使用预测数据进行推断时，高预测精度无法保证下游推断的有效性。失败的原因可归结为偏差（预测系统性地改变估计量或扭曲变量关系）和方差（忽略预测模型不确定性和真实数据变异性）。

Conclusion: 使用预测数据进行推断存在统计挑战，需要注意偏差和方差问题。研究人员应透明且符合统计原则地使用预测数据，未来的工作可以继续探索这一领域的开放问题。

Abstract: As artificial intelligence and machine learning tools become more accessible, and scientists face new obstacles to data collection (e.g., rising costs, declining survey response rates), researchers increasingly use predictions from pre-trained algorithms as substitutes for missing or unobserved data. Though appealing for financial and logistical reasons, using standard tools for inference can misrepresent the association between independent variables and the outcome of interest when the true, unobserved outcome is replaced by a predicted value. In this paper, we characterize the statistical challenges inherent to drawing inference with predicted data (IPD) and show that high predictive accuracy does not guarantee valid downstream inference. We show that all such failures reduce to statistical notions of (i) bias, when predictions systematically shift the estimand or distort relationships among variables, and (ii) variance, when uncertainty from the prediction model and the intrinsic variability of the true data are ignored. We then review recent methods for conducting IPD and discuss how this framework is deeply rooted in classical statistical theory. We then comment on some open questions and interesting avenues for future work in this area, and end with some comments on how to use predicted data in scientific studies that is both transparent and statistically principled.

</details>


### [30] [BalLOT: Balanced $k$-means clustering with optimal transport](https://arxiv.org/abs/2512.05926)
*Wenyan Luo,Dustin G. Mixon*

Main category: stat.ML

TL;DR: BalLOT是一种基于最优传输的交替最小化方法，能够快速有效地解决平衡k-means聚类问题。


<details>
  <summary>Details</summary>
Motivation: 解决平衡k-means聚类问题。

Method: 引入了一种名为BalLOT的最优传输方法，用于交替最小化。

Result: 数值实验表明BalLOT是一种快速有效的解决方案。对于通用数据，BalLOT在每一步都会产生积分耦合。在随机球模型下，BalLOT能够对植入的簇进行精确和部分恢复。

Conclusion: BalLOT为平衡k-means聚类问题提供了一种快速有效的解决方案，并通过理论分析和实验验证了其有效性。

Abstract: We consider the fundamental problem of balanced $k$-means clustering. In particular, we introduce an optimal transport approach to alternating minimization called BalLOT, and we show that it delivers a fast and effective solution to this problem. We establish this with a variety of numerical experiments before proving several theoretical guarantees. First, we prove that for generic data, BalLOT produces integral couplings at each step. Next, we perform a landscape analysis to provide theoretical guarantees for both exact and partial recoveries of planted clusters under the stochastic ball model. Finally, we propose initialization schemes that achieve one-step recovery of planted clusters.

</details>


### [31] [Design-marginal calibration of Gaussian process predictive distributions: Bayesian and conformal approaches](https://arxiv.org/abs/2512.05611)
*Aurélien Pion,Emmanuel Vazquez*

Main category: stat.ML

TL;DR: 本文从设计边缘化的角度研究了高斯过程（GP）预测分布的校准问题，特别是在插值设置下。


<details>
  <summary>Details</summary>
Motivation: 作者旨在解决高斯过程预测分布的校准问题，尤其关注在插值设置下的设计边缘化视角，并通过引入两种新方法（cps-gp和bcr-gp）来改进预测的准确性和校准性。

Method: 本文提出了两种新方法：cps-gp和bcr-gp。cps-gp通过适应共形预测系统到GP插值并使用标准化留一法残差，得到具有有限样本边际校准的逐步预测分布。bcr-gp保留GP后验均值，并将高斯残差替换为通过交叉验证的标准化残差拟合的广义正态模型。此外，bcr-gp还使用基于贝叶斯选择规则来控制离散度和尾部行为，并生成适用于顺序设计的平滑预测分布。

Result: 通过在基准函数上进行数值实验，比较了cps-gp、bcr-gp、Jackknife+ for GPs和全共形高斯过程，并使用了校准指标（覆盖率、Kolmogorov-Smirnov、积分绝对误差）和通过缩放连续排名概率分数衡量的准确性或锐度。结果表明新方法在校准和准确性方面表现良好。

Conclusion: 本文成功地从设计边缘化的角度研究了高斯过程预测分布的校准问题，并提出了cps-gp和bcr-gp两种有效的方法。通过实验，验证了这些方法在提高预测分布校准性和准确性方面的潜力。

Abstract: We study the calibration of Gaussian process (GP) predictive distributions in the interpolation setting from a design-marginal perspective. Conditioning on the data and averaging over a design measure μ, we formalize μ-coverage for central intervals and μ-probabilistic calibration through randomized probability integral transforms. We introduce two methods. cps-gp adapts conformal predictive systems to GP interpolation using standardized leave-one-out residuals, yielding stepwise predictive distributions with finite-sample marginal calibration. bcr-gp retains the GP posterior mean and replaces the Gaussian residual by a generalized normal model fitted to cross-validated standardized residuals. A Bayesian selection rule-based either on a posterior upper quantile of the variance for conservative prediction or on a cross-posterior Kolmogorov-Smirnov criterion for probabilistic calibration-controls dispersion and tail behavior while producing smooth predictive distributions suitable for sequential design. Numerical experiments on benchmark functions compare cps-gp, bcr-gp, Jackknife+ for GPs, and the full conformal Gaussian process, using calibration metrics (coverage, Kolmogorov-Smirnov, integral absolute error) and accuracy or sharpness through the scaled continuous ranked probability score.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [32] [Coefficient of Variation Masking: A Volatility-Aware Strategy for EHR Foundation Models](https://arxiv.org/abs/2512.05216)
*Rajna Fani,Rafi Al Attrach,David Restrepo,Yugang Jia,Leo Anthony Celi,Peter Schüffler*

Main category: cs.LG

TL;DR: 本文提出了一种名为CV-Masking的变异性感知预训练策略，通过根据每个特征的内在变异性自适应调整掩蔽概率，提高了电子健康记录（EHR）的表示学习能力，并在重建、下游预测性能和收敛速度方面取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的电子健康记录（EHR）掩码自编码器（MAE）方法通常采用统一的随机掩码，假设所有特征都同样可预测。然而，实验室检查中的生物标志物在波动性上存在显著异质性。临床上，波动性大的生物标志物往往预示着急性病理生理学，需要更复杂的建模来捕捉其复杂的时间模式，这促使研究者寻找更有效的方法来处理这种异质性。

Method: 本研究提出了一种变异性感知（volatility-aware）的预训练策略，称为变异系数掩码（CV-Masking）。该方法根据每个特征的内在变异性自适应地调整掩码概率。结合与临床工作流程对齐的仅值掩码目标，CV-Masking策略被开发用于学习更稳健和有临床意义的EHR表示。

Result: CV-Masking在重建、下游预测性能和收敛速度方面，相对于随机和基于方差的策略产生了系统的改进。实验结果表明，该方法能够生成更稳健且具有临床意义的EHR表示。

Conclusion: CV-Masking策略通过考虑生物标志物波动性的异质性，有效地提升了电子健康记录中掩码自编码器的性能，为学习更具临床意义的EHR表示提供了一种有效途径。

Abstract: Masked autoencoders (MAEs) are increasingly applied to electronic health records (EHR) for learning general-purpose representations that support diverse clinical tasks. However, existing approaches typically rely on uniform random masking, implicitly assuming all features are equally predictable. In reality, laboratory tests exhibit substantial heterogeneity in volatility: some biomarkers (e.g., sodium) remain stable, while others (e.g., lactate) fluctuate considerably and are more difficult to model. Clinically, volatile biomarkers often signal acute pathophysiology and require more sophisticated modeling to capture their complex temporal patterns. We propose a volatility-aware pretraining strategy, Coefficient of Variation Masking (CV-Masking), that adaptively adjusts masking probabilities according to the intrinsic variability of each feature. Combined with a value-only masking objective aligned with clinical workflows, CV-Masking yields systematic improvements over random and variance-based strategies. Experiments on a large panel of laboratory tests show that CV-Masking enhances reconstruction, improves downstream predictive performance, and accelerates convergence, producing more robust and clinically meaningful EHR representations.

</details>


### [33] [Rethinking Tokenization for Clinical Time Series: When Less is More](https://arxiv.org/abs/2512.05217)
*Rafi Al Attrach,Rajna Fani,David Restrepo,Yugang Jia,Peter Schüffler*

Main category: cs.LG

TL;DR: 本文系统评估了临床时间序列建模中不同分词策略的有效性，发现了一些任务依赖且有时反直觉的结果，尤其是在时间编码和价值特征的重要性方面。


<details>
  <summary>Details</summary>
Motivation: 目前对电子健康记录中分词策略有效性的公平比较仍然有限。

Method: 本文使用基于Transformer的架构，在MIMIC-IV数据集上进行了四项临床预测任务的受控消融实验。

Result: 明确的时间编码对下游任务没有持续的统计学显著益处；价值特征的重要性因任务而异；冻结的预训练代码编码器在性能上显著优于可训练的编码器，并且参数更少；更大的临床编码器通过冻结嵌入带来持续改进。

Conclusion: 简单的、参数高效的方法在许多情况下可以实现强大的性能，但最佳的分词策略仍然是任务依赖的。

Abstract: Tokenization strategies shape how models process electronic health records, yet fair comparisons of their effectiveness remain limited. We present a systematic evaluation of tokenization approaches for clinical time series modeling using transformer-based architectures, revealing task-dependent and sometimes counterintuitive findings about temporal and value feature importance. Through controlled ablations across four clinical prediction tasks on MIMIC-IV, we demonstrate that explicit time encodings provide no consistent statistically significant benefit for the evaluated downstream tasks. Value features show task-dependent importance, affecting mortality prediction but not readmission, suggesting code sequences alone can carry sufficient predictive signal. We further show that frozen pretrained code encoders dramatically outperform their trainable counterparts while requiring dramatically fewer parameters. Larger clinical encoders provide consistent improvements across tasks, benefiting from frozen embeddings that eliminate computational overhead. Our controlled evaluation enables fairer tokenization comparisons and demonstrates that simpler, parameter-efficient approaches can, in many cases, achieve strong performance, though the optimal tokenization strategy remains task-dependent.

</details>


### [34] [Variance Matters: Improving Domain Adaptation via Stratified Sampling](https://arxiv.org/abs/2512.05226)
*Andrea Napoli,Paul White*

Main category: cs.LG

TL;DR: 该论文提出了一种名为VaRDASS（通过分层抽样进行方差减少域适应）的无监督域适应（UDA）技术，旨在通过减少随机设置中域差异估计的方差来提高UDA的性能。


<details>
  <summary>Details</summary>
Motivation: 无监督域适应（UDA）在将机器学习模型部署到现实世界中时，由于域偏移的存在而面临挑战。现有的UDA方法在随机设置中估计域差异时存在高方差问题，这限制了其理论优势。因此，需要一种专门的随机方差减少技术来解决这个问题。

Method: 该论文提出了VaRDASS，这是一种专门用于UDA的随机方差减少技术。该方法考虑了两种特定的差异度量：相关性对齐和最大均值差异（MMD）。作者推导了针对这些度量的特殊分层目标。然后，提出了期望误差界和最坏情况误差界，并证明在某些假设下，针对MMD提出的目标在理论上是最佳的（即最小化方差）。最后，引入并分析了一种实用的k-means式优化算法。

Result: 在三个域偏移数据集上进行的实验表明，VaRDASS提高了差异估计的准确性和目标域的性能。

Conclusion: VaRDASS是第一个专门用于UDA的随机方差减少技术，它通过分层抽样有效降低了域差异估计的方差。该方法在理论上对MMD是最佳的，并在实践中提高了域适应性能。

Abstract: Domain shift remains a key challenge in deploying machine learning models to the real world. Unsupervised domain adaptation (UDA) aims to address this by minimising domain discrepancy during training, but the discrepancy estimates suffer from high variance in stochastic settings, which can stifle the theoretical benefits of the method. This paper proposes Variance-Reduced Domain Adaptation via Stratified Sampling (VaRDASS), the first specialised stochastic variance reduction technique for UDA. We consider two specific discrepancy measures -- correlation alignment and the maximum mean discrepancy (MMD) -- and derive ad hoc stratification objectives for these terms. We then present expected and worst-case error bounds, and prove that our proposed objective for the MMD is theoretically optimal (i.e., minimises the variance) under certain assumptions. Finally, a practical k-means style optimisation algorithm is introduced and analysed. Experiments on three domain shift datasets demonstrate improved discrepancy estimation accuracy and target domain performance.

</details>


### [35] [Uncertainty Quantification for Scientific Machine Learning using Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KAN)](https://arxiv.org/abs/2512.05306)
*Y. Sungtaek Ju*

Main category: cs.LG

TL;DR: 该文章介绍了一种结合稀疏变分高斯过程推理和Kolmogorov-Arnold拓扑的新框架，实现了具有不确定性量化能力的KANs模型，并在多个科学应用中验证了其能有效区分偶然不确定性和认知不确定性。


<details>
  <summary>Details</summary>
Motivation: 传统的Kolmogorov-Arnold Networks（KANs）缺乏原则性的不确定性量化能力，而这在许多科学应用中至关重要。

Method: 本文提出了一个将稀疏变分高斯过程推理与Kolmogorov-Arnold拓扑相结合的框架。通过解析矩匹配，作者在保持可解释性的同时，在深度加性结构中传播不确定性。该方法允许进行可扩展的贝叶斯推断，其计算复杂度与样本量呈准线性关系。

Result: 通过三个案例研究，该框架展示了区分偶然不确定性（aleatoric uncertainty）和认知不确定性（epistemic uncertainty）的能力。这些案例包括：流体流动重建中异方差测量噪声的校准，平流扩散动力学多步预测中预测置信度下降的量化，以及卷积自编码器中的分布外检测。

Conclusion: Sparse Variational Gaussian Process Kolmogorov-Arnold Networks（SVGP KANs）是一种在科学机器学习中实现不确定性感知学习的有前景的架构。

Abstract: Kolmogorov-Arnold Networks have emerged as interpretable alternatives to traditional multi-layer perceptrons. However, standard implementations lack principled uncertainty quantification capabilities essential for many scientific applications. We present a framework integrating sparse variational Gaussian process inference with the Kolmogorov-Arnold topology, enabling scalable Bayesian inference with computational complexity quasi-linear in sample size. Through analytic moment matching, we propagate uncertainty through deep additive structures while maintaining interpretability. We use three example studies to demonstrate the framework's ability to distinguish aleatoric from epistemic uncertainty: calibration of heteroscedastic measurement noise in fluid flow reconstruction, quantification of prediction confidence degradation in multi-step forecasting of advection-diffusion dynamics, and out-of-distribution detection in convolutional autoencoders. These results suggest Sparse Variational Gaussian Process Kolmogorov-Arnold Networks (SVGP KANs) is a promising architecture for uncertainty-aware learning in scientific machine learning.

</details>


### [36] [Robustness Test for AI Forecasting of Hurricane Florence Using FourCastNetv2 and Random Perturbations of the Initial Condition](https://arxiv.org/abs/2512.05323)
*Adam Lizerbram,Shane Stevenson,Iman Khadir,Matthew Tu,Samuel S. P. Shen*

Main category: cs.LG

TL;DR: 本文分析了AI天气预报模型NVIDIA FourCastNetv2（FCNv2）在不同输入噪声水平下的鲁棒性和敏感性，发现其在低中等噪声下能准确保持飓风特征，在高噪声下仍能保持大致轨迹和结构，但会低估风暴强度和持久性。在完全随机初始条件下，模型能生成平滑且连贯的预报。


<details>
  <summary>Details</summary>
Motivation: 理解天气预报模型对输入噪声或不确定性的鲁棒性对于评估其输出可靠性至关重要，尤其是在飓风等极端天气事件中。

Method: 本文通过两种实验来评估模型在不同程度的初始条件噪声注入下的输出表现。首先，使用不同程度的高斯噪声扰动飓风Florence的初始条件，并观察其对预测轨迹和风暴强度的影响。其次，使用完全随机的初始条件启动FCNv2，观察模型对无意义输入的响应。

Result: FCNv2在低到中等噪声注入下能准确保持飓风特征。即使在高噪声水平下，模型也能保持大致的风暴轨迹和结构，尽管位置准确性开始下降。FCNv2在所有噪声水平下都持续低估风暴强度和持久性。在完全随机的初始条件下，模型能在几个时间步后生成平滑且连贯的预报，这表明模型倾向于产生稳定、平滑的输出。

Conclusion: FCNv2在面对不同程度的噪声输入时表现出较好的鲁棒性，能够保持飓风的整体特征，但对风暴强度和持久性的预测存在低估。同时，它具有从高度不确定性输入中恢复并产生平滑，连贯预测的能力。本研究的方法简单且适用于其他数据驱动的AI天气预报模型。

Abstract: Understanding the robustness of a weather forecasting model with respect to input noise or different uncertainties is important in assessing its output reliability, particularly for extreme weather events like hurricanes. In this paper, we test sensitivity and robustness of an artificial intelligence (AI) weather forecasting model: NVIDIAs FourCastNetv2 (FCNv2). We conduct two experiments designed to assess model output under different levels of injected noise in the models initial condition. First, we perturb the initial condition of Hurricane Florence from the European Centre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset (September 13-16, 2018) with varying amounts of Gaussian noise and examine the impact on predicted trajectories and forecasted storm intensity. Second, we start FCNv2 with fully random initial conditions and observe how the model responds to nonsensical inputs. Our results indicate that FCNv2 accurately preserves hurricane features under low to moderate noise injection. Even under high levels of noise, the model maintains the general storm trajectory and structure, although positional accuracy begins to degrade. FCNv2 consistently underestimates storm intensity and persistence across all levels of injected noise. With full random initial conditions, the model generates smooth and cohesive forecasts after a few timesteps, implying the models tendency towards stable, smoothed outputs. Our approach is simple and portable to other data-driven AI weather forecasting models.

</details>


### [37] [When unlearning is free: leveraging low influence points to reduce computational costs](https://arxiv.org/abs/2512.05254)
*Anat Kleiman,Robert Fisher,Ben Deaner,Udi Wieder*

Main category: cs.LG

TL;DR: 该论文提出了一种高效的机器学习遗忘框架，通过识别对模型影响可忽略的数据点来减少遗忘数据集的大小，从而显著节省计算成本。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，数据隐私问题日益突出，使得从训练好的模型中删除特定数据点（即遗忘）的能力变得越来越重要。当前最先进的遗忘方法通常平等对待所有需要遗忘的数据点，但我们质疑这种做法是否有效。

Method: 本文通过对语言和视觉任务中的影响函数进行比较分析，识别了对模型输出影响可忽略的训练数据子集。

Result: 我们提出了一个高效的遗忘框架，该框架在遗忘之前减小了数据集的大小，从而在实际经验示例中显著节省了计算成本（高达约50%）。

Conclusion: 通过识别并忽略对模型影响可忽略的数据点，可以显著提高机器学习遗忘过程的效率，节省计算资源。

Abstract: As concerns around data privacy in machine learning grow, the ability to unlearn, or remove, specific data points from trained models becomes increasingly important. While state of the art unlearning methods have emerged in response, they typically treat all points in the forget set equally. In this work, we challenge this approach by asking whether points that have a negligible impact on the model's learning need to be removed. Through a comparative analysis of influence functions across language and vision tasks, we identify subsets of training data with negligible impact on model outputs. Leveraging this insight, we propose an efficient unlearning framework that reduces the size of datasets before unlearning leading to significant computational savings (up to approximately 50 percent) on real world empirical examples.

</details>


### [38] [Text Rationalization for Robust Causal Effect Estimation](https://arxiv.org/abs/2512.05373)
*Lijinghua Zhang,Hengrui Cai*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个名为CATR的框架，用于解决在因果推断中使用文本数据时，高维文本特征导致的混淆问题和估计不稳定性问题。CATR通过选择稀疏的、必要的token子集来保留混淆信息，从而缓解因果推断中的“积极性假设”违背，并稳定因果效应估计。


<details>
  <summary>Details</summary>
Motivation: 在高维文本数据用于因果推断时，由于特征空间庞大，会导致“积极性假设”难以满足，从而影响因果效应估计的准确性和稳定性。

Method: 本文提出了Confounding-Aware Token Rationalization (CATR) 框架。CATR利用残差独立性诊断 (residual-independence diagnostic) 来选择一个稀疏的、必要的token子集，该子集足以保留混淆信息以满足无混淆假设。通过剔除不相关的文本并保留关键信号，CATR旨在缓解观察层面的“积极性假设”违背，并稳定后续的因果效应估计器。

Result: 在合成数据和MIMIC-III数据库上的真实世界研究中，CATR框架比现有基线方法产生了更准确、更稳定、更具解释性的因果效应估计。

Conclusion: CATR框架通过选择性地保留文本中的混淆信息，有效解决了高维文本数据在因果推断中引起的“积极性假设”违背和估计不稳定性问题。 CATR在提高因果效应估计的准确性、稳定性和可解释性方面表现出色。

Abstract: Recent advances in natural language processing have enabled the increasing use of text data in causal inference, particularly for adjusting confounding factors in treatment effect estimation. Although high-dimensional text can encode rich contextual information, it also poses unique challenges for causal identification and estimation. In particular, the positivity assumption, which requires sufficient treatment overlap across confounder values, is often violated at the observational level, when massive text is represented in feature spaces. Redundant or spurious textual features inflate dimensionality, producing extreme propensity scores, unstable weights, and inflated variance in effect estimates. We address these challenges with Confounding-Aware Token Rationalization (CATR), a framework that selects a sparse necessary subset of tokens using a residual-independence diagnostic designed to preserve confounding information sufficient for unconfoundedness. By discarding irrelevant texts while retaining key signals, CATR mitigates observational-level positivity violations and stabilizes downstream causal effect estimators. Experiments on synthetic data and a real-world study using the MIMIC-III database demonstrate that CATR yields more accurate, stable, and interpretable causal effect estimates than existing baselines.

</details>


### [39] [Bridging Interpretability and Optimization: Provably Attribution-Weighted Actor-Critic in Reproducing Kernel Hilbert Spaces](https://arxiv.org/abs/2512.05291)
*Na Li,Hangguan Shan,Wei Ni,Wenjie Zhang,Xinyu Li*

Main category: cs.LG

TL;DR: 该文章提出了一种名为RSA2C的强化学习算法，它通过引入基于RKHS-SHAP的状态归因来提高Actor-Critic方法的解释性、效率和稳定性，并在理论上证明了其收敛性。


<details>
  <summary>Details</summary>
Motivation: 传统的Actor-Critic方法解释性有限，现有的可解释强化学习方法在训练中很少使用状态归因，并且忽略了不同状态维度对奖励的异质影响。

Method: RSA2C算法是一种归因感知、核化的双时间尺度AC算法，包括Actor、Value Critic和Advantage Critic。Actor位于向量值再生核希尔伯特空间（RKHS）中，Value Critic和Advantage Critic位于标量RKHS中。这些RKHS增强的组件使用稀疏字典。通过RKHS-SHAP从Value Critic计算状态归因，并将其转换为Mahalanobis门控权重，以调节Actor梯度和Advantage Critic目标。

Result: RSA2C算法在三个标准的连续控制环境中实现了效率、稳定性和可解释性。

Conclusion: RSA2C算法通过整合状态归因和核方法，显著提升了Actor-Critic算法在可解释性、效率和稳定性方面的表现，并通过理论分析证实了其收敛性。

Abstract: Actor-critic (AC) methods are a cornerstone of reinforcement learning (RL) but offer limited interpretability. Current explainable RL methods seldom use state attributions to assist training. Rather, they treat all state features equally, thereby neglecting the heterogeneous impacts of individual state dimensions on the reward. We propose RKHS--SHAP-based Advanced Actor--Critic (RSA2C), an attribution-aware, kernelized, two-timescale AC algorithm, including Actor, Value Critic, and Advantage Critic. The Actor is instantiated in a vector-valued reproducing kernel Hilbert space (RKHS) with a Mahalanobis-weighted operator-valued kernel, while the Value Critic and Advantage Critic reside in scalar RKHSs. These RKHS-enhanced components use sparsified dictionaries: the Value Critic maintains its own dictionary, while the Actor and Advantage Critic share one. State attributions, computed from the Value Critic via RKHS--SHAP (kernel mean embedding for on-manifold expectations and conditional mean embedding for off-manifold expectations), are converted into Mahalanobis-gated weights that modulate Actor gradients and Advantage Critic targets. Theoretically, we derive a global, non-asymptotic convergence bound under state perturbations, showing stability through the perturbation-error term and efficiency through the convergence-error term. Empirical results on three standard continuous-control environments show that our algorithm achieves efficiency, stability, and interpretability.

</details>


### [40] [Modular Jets for Supervised Pipelines: Diagnosing Mirage vs Identifiability](https://arxiv.org/abs/2512.05638)
*Suman Sanyal*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为“模块化射流”（Modular Jets）的新方法，用于评估监督学习模型内部组件的独特程度。它区分了“幻影”（mirage）状态（多种模块化分解产生相同结果）和“可识别”（identifiable）状态（通过观察到的射流可以唯一确定分解）。


<details>
  <summary>Details</summary>
Motivation: 经典监督学习通过预测风险评估模型，但这种评估没有解决模型内部组件是否由数据和评估设计唯一确定的问题

Method: 引入“模块化射流”（Modular Jets），通过估计经验射流（局部线性响应图）来描述每个模块对输入的微小结构扰动的反应。提出了“幻影”状态（多种不同的模块化分解导致不可区分的射流）和“可识别”状态（观察到的射流可以唯一确定分解）。在两模块线性回归的背景下，证明了射流可识别性定理。提出了MoJet算法，用于经验射流估计和幻影诊断。

Result: 在温和的秩假设和可获得模块级射流的情况下，内部因式分解是唯一确定的，而仅基于风险的评估允许大量实现相同输入输出映射的幻影分解。

Conclusion: “模块化射流”方法提供了一种新的方式来评估监督学习模型的内部可分解性，区分了幻影和可识别状态，并通过MoJet算法，能够诊断和识别不同模块化分解的特性。这有助于我们更好地理解模型的内部工作原理。

Abstract: Classical supervised learning evaluates models primarily via predictive risk on hold-out data. Such evaluations quantify how well a function behaves on a distribution, but they do not address whether the internal decomposition of a model is uniquely determined by the data and evaluation design. In this paper, we introduce \emph{Modular Jets} for regression and classification pipelines. Given a task manifold (input space), a modular decomposition, and access to module-level representations, we estimate empirical jets, which are local linear response maps that describe how each module reacts to small structured perturbations of the input. We propose an empirical notion of \emph{mirage} regimes, where multiple distinct modular decompositions induce indistinguishable jets and thus remain observationally equivalent, and contrast this with an \emph{identifiable} regime, where the observed jets single out a decomposition up to natural symmetries. In the setting of two-module linear regression pipelines we prove a jet-identifiability theorem. Under mild rank assumptions and access to module-level jets, the internal factorisation is uniquely determined, whereas risk-only evaluation admits a large family of mirage decompositions that implement the same input-to-output map. We then present an algorithm (MoJet) for empirical jet estimation and mirage diagnostics, and illustrate the framework using linear and deep regression as well as pipeline classification.

</details>


### [41] [The Erosion of LLM Signatures: Can We Still Distinguish Human and LLM-Generated Scientific Ideas After Iterative Paraphrasing?](https://arxiv.org/abs/2512.05311)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee*

Main category: cs.LG

TL;DR: 这篇论文评估了最先进的机器学习模型区分人类和大型语言模型（LLM）生成想法的能力，发现在连续复述后，检测性能显著下降，尤其是在简化复述风格下，但结合研究问题可以提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着研究人员越来越依赖大型语言模型（LLMs）作为研究助手，区分LLM和人类生成的思想对于理解LLMs研究能力的认知细微差别至关重要。尽管检测LLM生成的文本已被广泛研究，但区分人类与LLM生成的科学思想仍是一个未探索的领域。

Method: 本研究系统地评估了最先进（SOTA）的机器学习模型区分人类和大型语言模型（LLM）生成想法的能力，特别是在连续的复述阶段之后。

Result: 研究发现，最先进的模型在溯源方面面临挑战，经过五次连续复述后，检测性能平均下降了25.4%。此外，研究表明，将研究问题作为上下文信息可以使检测性能提高2.97%。值得注意的是，当思想被简化为非专业风格时，检测算法的识别能力显著下降。

Conclusion: 区分人类和LLM生成想法的能力在连续复述后会显著下降，尤其是在简化风格下。将研究问题作为上下文信息可以提高检测性能。

Abstract: With the increasing reliance on LLMs as research agents, distinguishing between LLM and human-generated ideas has become crucial for understanding the cognitive nuances of LLMs' research capabilities. While detecting LLM-generated text has been extensively studied, distinguishing human vs LLM-generated scientific idea remains an unexplored area. In this work, we systematically evaluate the ability of state-of-the-art (SOTA) machine learning models to differentiate between human and LLM-generated ideas, particularly after successive paraphrasing stages. Our findings highlight the challenges SOTA models face in source attribution, with detection performance declining by an average of 25.4\% after five consecutive paraphrasing stages. Additionally, we demonstrate that incorporating the research problem as contextual information improves detection performance by up to 2.97%. Notably, our analysis reveals that detection algorithms struggle significantly when ideas are paraphrased into a simplified, non-expert style, contributing the most to the erosion of distinguishable LLM signatures.

</details>


### [42] [Non-Convex Federated Optimization under Cost-Aware Client Selection](https://arxiv.org/abs/2512.05327)
*Xiaowen Jiang,Anton Rodomanov,Sebastian U. Stich*

Main category: cs.LG

TL;DR: 本文提出了一种新的联邦优化模型，用于量化通信和本地计算的复杂性，并提出了一种新的算法，该算法在现有联邦非凸优化方法中实现了最佳的通信和本地复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有的优化方法比较指标未能区分不同的客户端选择策略及其带来的通信成本差异。

Method: 本文提出了一种新的联邦优化模型，该模型允许使用多种常见的客户端选择策略，并明确地为每种策略关联了不同的成本。在此模型下，我们提出一种基于不精确复合梯度方法的新算法，该算法采用了精心构造的梯度估计器和解决辅助子问题的特殊程序。梯度估计器基于SAGA，并通过引入递归梯度技术（Recursive-Gradient）获得了一个新的误差改进估计器RG-SAGA。

Result: 本文提出的新算法在非凸优化方面，实现了现有联邦优化方法中最佳的通信和本地计算复杂性。SAGA的新的方差边界显示它可以利用函数相似性。RG-SAGA与原始SAGA相比，具有改进的误差边界。

Conclusion: 本文通过引入一个新的联邦优化模型和提出一种基于改进梯度估计器的新算法，解决了现有联邦优化方法中通信成本量化不足的问题，并在非凸优化领域取得了最佳的通信和本地计算复杂性。

Abstract: Different federated optimization algorithms typically employ distinct client-selection strategies: some methods communicate only with a randomly sampled subset of clients at each round, while others need to periodically communicate with all clients or use a hybrid scheme that combines both strategies. However, existing metrics for comparing optimization methods typically do not distinguish between these strategies, which often incur different communication costs in practice. To address this disparity, we introduce a simple and natural model of federated optimization that quantifies communication and local computation complexities. This new model allows for several commonly used client-selection strategies and explicitly associates each with a distinct cost. Within this setting, we propose a new algorithm that achieves the best-known communication and local complexities among existing federated optimization methods for non-convex optimization. This algorithm is based on the inexact composite gradient method with a carefully constructed gradient estimator and a special procedure for solving the auxiliary subproblem at each iteration. The gradient estimator is based on SAGA, a popular variance-reduced gradient estimator. We first derive a new variance bound for it, showing that SAGA can exploit functional similarity. We then introduce the Recursive-Gradient technique as a general way to potentially improve the error bound of a given conditionally unbiased gradient estimator, including both SAGA and SVRG. By applying this technique to SAGA, we obtain a new estimator, RG-SAGA, which has an improved error bound compared to the original one.

</details>


### [43] [PathFinder: MCTS and LLM Feedback-based Path Selection for Multi-Hop Question Answering](https://arxiv.org/abs/2512.05336)
*Durga Prasad Maram,Kalpa Gunaratna,Vijay Srinivasan,Haris Jeelani,Srinivas Chappidi*

Main category: cs.LG

TL;DR: PATHFINDER通过使用蒙特卡洛树搜索生成训练路径，并通过子答案召回和LLM判断来过滤错误和冗长的路径，以提高多跳问答（QA）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳问答系统在处理复杂的多跳问题时，仍然存在大型语言模型（LLM）幻觉和不正确的推理路径的问题，这限制了其性能。

Method: PATHFINDER方法包括三个步骤：1. 使用蒙特卡洛树搜索生成训练路径。2. 通过子答案召回和LLM-as-a-judge验证来过滤错误和冗长的路径，提高训练数据质量。3. 重新 формуulate 子查询以处理检索失败的情况。

Result: PATHFINDER在公共基准数据集上显著提高了多跳问答的性能。

Conclusion: PATHFINDER通过生成高质量的训练路径和优化子查询处理，有效解决了多跳问答中LLM幻觉和推理路径不准确的问题，从而提升了多跳问答系统的整体性能。

Abstract: Multi-hop question answering is a challenging task in which language models must reason over multiple steps to reach the correct answer. With the help of Large Language Models and their reasoning capabilities, existing systems are able to think and decompose an input question over multiple steps to analyze, retrieve, and reason. However, training-based approaches for this problem still suffer from LLM hallucinations and incorrect reasoning paths that hinder performance. Hence, we propose PATHFINDER, an approach that: (i) uses Monte Carlo Tree Search to generate training path traces, (ii) improves training data quality by filtering erroneous and lengthy traces using sub-answer recall and LLM-as-a-judge verification, and (iii) reformulates sub-queries to handle failed retrieval cases. By following these steps, we demonstrate that PATHFINDER improves the performance of multi-hop QA over public benchmark datasets.

</details>


### [44] [Interaction Tensor Shap](https://arxiv.org/abs/2512.05338)
*Hiroki Hasegawa,Yukihiko Okada*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为IT SHAP的新方法，用于计算机器学习模型中的高阶Shapley交互作用。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型日益复杂，难以理解特征如何影响预测。现有的Shapley值方法无法有效评估高阶交互作用，因为它们计算成本高昂或仅限于一阶效应。

Method: IT SHAP将Shapley-Taylor交互指数（STII）重新表述为值张量和权重张量的收缩。它假设权重张量具有有限状态的张量列车（TT）表示，并利用TT结构的模型和分布张量，将STII的计算复杂度从指数级的O(4^n)降低到NC2的并行时间。

Result: IT SHAP为高维模型中的主效应和高阶交互作用提供了一个统一的、公理化的、计算上可行的公式。

Conclusion: IT SHAP为可扩展的交互感知可解释人工智能奠定了基础，使得对大型黑盒模型进行交互分析成为可能。

Abstract: Machine learning models have grown increasingly deep and high dimensional, making it difficult to understand how individual and combined features influence their predictions. While Shapley value based methods provide principled feature attributions, existing formulations cannot tractably evaluate higher order interactions: the Shapley Taylor Interaction Index (STII) requires exponential scale enumeration of subsets, and current tensor based approaches such as the Marginal SHAP Tensor (MST) are restricted to first order effects. The central problem is that no existing framework simultaneously preserves the axiomatic exactness of STII and avoids the exponential computational blow up inherent to high order discrete derivatives. Here we show that high order Shapley interactions can be represented exactly as tensor network contractions, enabling polynomial time and polylog depth computation under Tensor Train (TT) structure. We introduce Interaction Tensor SHAP (IT SHAP), which reformulates STII as the contraction of a Value Tensor and a Weight Tensor, and assume a finite state TT representation of the Weight Tensor with polynomial TT ranks. Under TT structured model and distribution tensors, we show that IT SHAP reduces the exponential complex Theta(4^n) of STII to NC2 parallel time. These results demonstrate that IT SHAP provides a unified, axiomatic, and computationally tractable formulation of main effects and higher order interactions in high dimensional models. This framework establishes a foundation for scalable interaction aware explainable AI, with implications for large black box models whose combinatorial structure has previously rendered interaction analysis infeasible.

</details>


### [45] [Taxonomy-Adaptive Moderation Model with Robust Guardrails for Large Language Models](https://arxiv.org/abs/2512.05339)
*Mahesh Kumar Nandwana,Youngwan Lim,Joseph Liu,Alex Yang,Varun Notibala,Nishchaie Khanna*

Main category: cs.LG

TL;DR: 本文介绍了Roblox Guard 1.0，一个基于Llama-3.1-8B-Instruct的LLM，旨在通过全面的输入输出审核增强LLM系统的安全性。Roblox Guard 1.0通过指令微调，结合了合成数据和开源安全数据集，并辅以思维链和输入反转技术，以提高上下文理解和决策能力。同时，本文还发布了RobloxGuard-Eval，一个新的基准测试，用于评估LLM安全防护和审核框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在训练后通常会进行安全对齐，但仍可能生成不当输出，对用户构成潜在风险。因此，需要强大的安全防护措施来同时处理模型的输入和输出。

Method: Roblox Guard 1.0是一个指令微调的LLM，采用LLM管道技术来增强审核能力，其核心是Llama-3.1-8B-Instruct。该模型通过指令微调，使其能够泛化到未见过的安全分类体系。微调过程结合了合成安全数据集和开源安全数据集，并利用思维链（CoT）推理和输入反转技术来增强模型的上下文理解和决策能力。

Result: Roblox Guard 1.0在出域安全基准测试中表现出强大的性能。

Conclusion: Roblox Guard 1.0通过先进的指令微调LLM方法，结合多种数据增强技术，有效提升了LLM系统的安全审核能力。同时发布的RobloxGuard-Eval为LLM安全防护的系统评估提供了新的工具。

Abstract: Large Language Models (LLMs) are typically aligned for safety during the post-training phase; however, they may still generate inappropriate outputs that could potentially pose risks to users. This challenge underscores the need for robust safeguards that operate across both model inputs and outputs. In this work, we introduce Roblox Guard 1.0, a state-of-the-art instruction fine-tuned LLM designed to enhance the safety of LLM systems through comprehensive input-output moderation, using a pipeline of LLMs to enhance moderation capability. Built on the Llama-3.1-8B-Instruct backbone, our model is instruction fine-tuned to generalize across previously unseen safety taxonomies and demonstrates strong performance on out-of-domain safety benchmarks. The instruction fine-tuning process uses a mix of synthetic and open-source safety datasets, augmented with chain-of-thought (CoT) rationales and input inversion to enhance contextual understanding and decision making. To support systematic evaluation, we also release RobloxGuard-Eval, a new benchmark featuring an extensible safety taxonomy to assess the effectiveness of LLM guardrails and moderation frameworks.

</details>


### [46] [When Forgetting Builds Reliability: LLM Unlearning for Reliable Hardware Code Generation](https://arxiv.org/abs/2512.05341)
*Yiwen Liang,Qiufeng Li,Shikai Wang,Weidong Cao*

Main category: cs.LG

TL;DR: 该论文提出了一个针对LLM驱动硬件设计中的代码生成场景的、新颖的遗忘框架。这个框架通过结合保留语法结构的遗忘策略和细粒度的、楼层感知的选择性损失来解决LLMs在硬件代码生成中可能出现的知识产权泄露、基准污染和不安全编码模式问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在加速数字硬件设计方面表现出巨大潜力，但其可靠性仍是一个关键挑战，因为现有LLMs可能存在对专有IP的记忆、基准污染和不安全编码模式等问题。

Method: 本文提出了一种新颖的、针对LLM驱动硬件代码生成的遗忘框架。该方法结合了(i)一种保留语法的遗忘策略，以在遗忘过程中保护硬件代码的结构完整性，以及(ii)一种细粒度的、楼层感知的选择性损失，从而实现对问题知识的精确有效去除。

Result: 实验表明，该框架支持的遗忘集大小可达3倍以上，通常只需一个训练周期，同时保持寄存器传输级（RTL）代码的语法正确性和功能完整性，且不降低LLM的代码生成能力。

Conclusion: 该工作为可靠的LLM辅助硬件设计开辟了一条新途径。

Abstract: Large Language Models (LLMs) have shown strong potential in accelerating digital hardware design through automated code generation. Yet, ensuring their reliability remains a critical challenge, as existing LLMs trained on massive heterogeneous datasets often exhibit problematic memorization of proprietary intellectual property (IP), contaminated benchmarks, and unsafe coding patterns. To mitigate these risks, we propose a novel unlearning framework tailored for LLM-based hardware code generation. Our method combines (i) a syntax-preserving unlearning strategy that safeguards the structural integrity of hardware code during forgetting, and (ii) a fine-grained floor-aware selective loss that enables precise and efficient removal of problematic knowledge. This integration achieves effective unlearning without degrading LLM code generation capabilities. Extensive experiments show that our framework supports forget sets up to 3x larger, typically requiring only a single training epoch, while preserving both syntactic correctness and functional integrity of register-transfer level (RTL) codes. Our work paves an avenue towards reliable LLM-assisted hardware design.

</details>


### [47] [China Regional 3km Downscaling Based on Residual Corrective Diffusion Model](https://arxiv.org/abs/2512.05377)
*Honglu Sun,Hao Jing,Zhixiang Dai,Sa Xiao,Wei Xue,Jian Sun,Qifeng Lu*

Main category: cs.LG

TL;DR: 本文主要介绍了一种基于扩散模型的统计降尺度方法CorrDiff，并将其应用于中国区域的3公里气象预报。


<details>
  <summary>Details</summary>
Motivation: 在数值天气预报中，高效地生成高分辨率预报是一个基本挑战。下尺度方法是解决此问题的一个常见方案。

Method: 本文采用名为CorrDiff的基于扩散的降尺度框架。与CorrDiff的原始工作相比，本文考虑的区域大了近20倍，并且不仅考虑了原始工作中的地表变量，还遇到了高层变量（六个压力层）作为目标降尺度变量。此外，还添加了全局残差连接以提高准确性。为了生成中国区域的3公里预报，我们将训练好的模型应用于CMA-GFS（中国气象局的业务全球模型）和SFF（从球面傅里叶神经算子（SFNO）开发的基于数据驱动的深度学习天气模型）的25公里全球网格预报。

Result: 实验结果表明，本文方法降尺度后的预报在MAE方面通常优于CMA-MESO的直接预报。雷达组合反射率的预报表明，CorrDiff作为生成模型，可以生成精细尺度的细节，从而产生比相应的确定性回归模型更真实的预测。

Conclusion: 本文提出了一种改进的基于扩散模型的统计降尺度方法CorrDiff，并在中国区域的3公里气象预报中取得了良好的效果，证明了其在生成精细尺度细节方面的优势。

Abstract: A fundamental challenge in numerical weather prediction is to efficiently produce high-resolution forecasts. A common solution is applying downscaling methods, which include dynamical downscaling and statistical downscaling, to the outputs of global models. This work focuses on statistical downscaling, which establishes statistical relationships between low-resolution and high-resolution historical data using statistical models. Deep learning has emerged as a powerful tool for this task, giving rise to various high-performance super-resolution models, which can be directly applied for downscaling, such as diffusion models and Generative Adversarial Networks. This work relies on a diffusion-based downscaling framework named CorrDiff. In contrast to the original work of CorrDiff, the region considered in this work is nearly 20 times larger, and we not only consider surface variables as in the original work, but also encounter high-level variables (six pressure levels) as target downscaling variables. In addition, a global residual connection is added to improve accuracy. In order to generate the 3km forecasts for the China region, we apply our trained models to the 25km global grid forecasts of CMA-GFS, an operational global model of the China Meteorological Administration (CMA), and SFF, a data-driven deep learning-based weather model developed from Spherical Fourier Neural Operators (SFNO). CMA-MESO, a high-resolution regional model, is chosen as the baseline model. The experimental results demonstrate that the forecasts downscaled by our method generally outperform the direct forecasts of CMA-MESO in terms of MAE for the target variables. Our forecasts of radar composite reflectivity show that CorrDiff, as a generative model, can generate fine-scale details that lead to more realistic predictions compared to the corresponding deterministic regression models.

</details>


### [48] [Generalization Beyond Benchmarks: Evaluating Learnable Protein-Ligand Scoring Functions on Unseen Targets](https://arxiv.org/abs/2512.05386)
*Jakub Kopko,David Graber,Saltuk Mustafa Eyrilmez,Stanislav Mazurenko,David Bednar,Jiri Sedlar,Josef Sivic*

Main category: cs.LG

TL;DR: 该研究评估了机器学习蛋白质-配体评分函数在新蛋白质靶点上的泛化能力，并发现现有基准未能反映真实挑战。研究还探讨了大规模自监督预训练的潜力，并提出了更严格的评估协议。


<details>
  <summary>Details</summary>
Motivation: 机器学习已成为分子设计的核心，但可学习的蛋白质-配体评分函数在新蛋白质靶点上的可靠性仍需确保。尽管许多评分函数在标准基准上表现良好，但其超越训练数据的泛化能力仍是一个重大挑战。

Method: 本研究通过在数据集划分上评估最先进的评分函数，模拟了在已知结构和实验亲和力测量数量有限的靶点上进行评估的场景。

Result: 分析表明，常用的基准无法反映泛化到新靶点的真实挑战。研究还初步证实了大规模自监督预训练弥合泛化差距的潜力，并探讨了利用有限测试靶点数据提高评分函数性能的简单方法的有效性。

Conclusion: 研究结果强调了制定更严格评估协议的必要性，并为设计具有预测能力、可推广到新型蛋白质靶点的评分函数提供了实践指导。

Abstract: As machine learning becomes increasingly central to molecular design, it is vital to ensure the reliability of learnable protein-ligand scoring functions on novel protein targets. While many scoring functions perform well on standard benchmarks, their ability to generalize beyond training data remains a significant challenge. In this work, we evaluate the generalization capability of state-of-the-art scoring functions on dataset splits that simulate evaluation on targets with a limited number of known structures and experimental affinity measurements. Our analysis reveals that the commonly used benchmarks do not reflect the true challenge of generalizing to novel targets. We also investigate whether large-scale self-supervised pretraining can bridge this generalization gap and we provide preliminary evidence of its potential. Furthermore, we probe the efficacy of simple methods that leverage limited test-target data to improve scoring function performance. Our findings underscore the need for more rigorous evaluation protocols and offer practical guidance for designing scoring functions with predictive power extending to novel protein targets.

</details>


### [49] [Smart Timing for Mining: A Deep Learning Framework for Bitcoin Hardware ROI Prediction](https://arxiv.org/abs/2512.05402)
*Sithumi Wickramasinghe,Bikramjit Das,Dorien Herremans*

Main category: cs.LG

TL;DR: 本文提出MineROI-Net，一个基于Transformer的开源架构，用于预测比特币ASIC挖矿硬件的投资回报率，以帮助矿工决定何时购买新硬件，在实际数据中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管比特币挖矿已发展成为资本密集型产业，但何时购买新的ASIC硬件却缺乏指导，也没有现有的计算框架解决这一决策问题。

Method: 将硬件购置问题建模为时间序列分类任务，预测购买ASIC机器是否会在一年内产生盈利、边际利润或亏损回报。提出了MineROI-Net，一个基于Transformer的开源架构，旨在捕捉挖矿盈利能力中的多尺度时间模式。

Result: 在2015年至2024年发布的20种ASIC矿机的数据集上评估，MineROI-Net优于基于LSTM和TSLANet的基线模型，达到了83.7%的准确率和83.1%的宏F1分数。该模型在检测无利可图的时期时达到了93.6%的精确度，在检测有利可图的时期时达到了98.5%的精确度。

Conclusion: MineROI-Net为矿工提供了一个实用的、数据驱动的工具来规划挖矿硬件的购置时机，从而可能降低资本密集型挖矿操作中的财务风险。

Abstract: Bitcoin mining hardware acquisition requires strategic timing due to volatile markets, rapid technological obsolescence, and protocol-driven revenue cycles. Despite mining's evolution into a capital-intensive industry, there is little guidance on when to purchase new Application-Specific Integrated Circuit (ASIC) hardware, and no prior computational frameworks address this decision problem. We address this gap by formulating hardware acquisition as a time series classification task, predicting whether purchasing ASIC machines yields profitable (Return on Investment (ROI) >= 1), marginal (0 < ROI < 1), or unprofitable (ROI <= 0) returns within one year. We propose MineROI-Net, an open source Transformer-based architecture designed to capture multi-scale temporal patterns in mining profitability. Evaluated on data from 20 ASIC miners released between 2015 and 2024 across diverse market regimes, MineROI-Net outperforms LSTM-based and TSLANet baselines, achieving 83.7% accuracy and 83.1% macro F1-score. The model demonstrates strong economic relevance, achieving 93.6% precision in detecting unprofitable periods and 98.5% precision for profitable ones, while avoiding misclassification of profitable scenarios as unprofitable and vice versa. These results indicate that MineROI-Net offers a practical, data-driven tool for timing mining hardware acquisitions, potentially reducing financial risk in capital-intensive mining operations. The model is available through: https://github.com/AMAAI-Lab/MineROI-Net.

</details>


### [50] [TS-HINT: Enhancing Semiconductor Time Series Regression Using Attention Hints From Large Language Model Reasoning](https://arxiv.org/abs/2512.05419)
*Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu*

Main category: cs.LG

TL;DR: 这篇文章提出了一种时间序列基础模型框架TS-Hint，它通过思维链推理在训练过程中提供注意力提示，解决了现有数据驱动方法在半导体制造过程中MRR预测中时间动态性缺失和对大量数据依赖的问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在半导体制造过程（如化学机械抛光CMP）的材料去除率（MRR）预测中，依赖于从时间序列中提取静态特征，导致时间动态性缺失，并且需要大量数据进行有效训练。

Method: 本文提出了TS-Hint，一个时间序列基础模型（TSFM）框架，集成了思维链推理。该框架在训练过程中基于注意力机制数据和显著性数据提供注意力提示。

Result: 实验结果表明，该模型在有限数据设置下通过少样本学习表现出有效性，并且可以直接从多元时间序列特征中学习。

Conclusion: TS-Hint框架能够有效解决现有方法的时间动态性缺失和对数据量依赖的问题，尤其在数据量有限的情况下表现出色，并且能够直接处理多元时间序列数据。

Abstract: Existing data-driven methods rely on the extraction of static features from time series to approximate the material removal rate (MRR) of semiconductor manufacturing processes such as chemical mechanical polishing (CMP). However, this leads to a loss of temporal dynamics. Moreover, these methods require a large amount of data for effective training. In this paper, we propose TS-Hint, a Time Series Foundation Model (TSFM) framework, integrated with chain-of-thought reasoning which provides attention hints during training based on attention mechanism data and saliency data. Experimental results demonstrate the effectiveness of our model in limited data settings via few-shot learning and can learn directly from multivariate time series features.

</details>


### [51] [Entropy Ratio Clipping as a Soft Global Constraint for Stable Reinforcement Learning](https://arxiv.org/abs/2512.05591)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Tiehua Mei,Zijia Lin,Yuntao Li,Wenping Hu,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种新的熵比剪裁（ERC）机制，用于稳定大型语言模型（LLM）的后训练过程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的后训练过程依赖于强化学习，但离策略训练范式引入了分布偏移，导致训练不稳定。PPO-Clip虽然通过重要性剪裁缓解了这个问题，但仍忽略了动作的全局分布偏移。

Method: 本文提出使用当前策略和先前策略之间的熵比作为新的全局度量，以有效量化整个更新过程中策略探索的相对变化。在此基础上，引入了熵比剪裁（ERC）机制，对熵比施加双向约束。

Result: 实验表明，ERC持续改进了性能。

Conclusion: ERC机制通过对熵比施加双向约束，稳定了全局分布层面的策略更新，弥补了PPO-Clip在调节未采样动作概率偏移方面的不足。

Abstract: Large language model post-training relies on reinforcement learning to improve model capability and alignment quality. However, the off-policy training paradigm introduces distribution shift, which often pushes the policy beyond the trust region, leading to training instabilities manifested as fluctuations in policy entropy and unstable gradients. Although PPO-Clip mitigates this issue through importance clipping, it still overlooks the global distributional shift of actions. To address these challenges, we propose using the entropy ratio between the current and previous policies as a new global metric that effectively quantifies the relative change in policy exploration throughout updates. Building on this metric, we introduce an \textbf{Entropy Ratio Clipping} (ERC) mechanism that imposes bidirectional constraints on the entropy ratio. This stabilizes policy updates at the global distribution level and compensates for the inability of PPO-clip to regulate probability shifts of un-sampled actions. We integrate ERC into both DAPO and GPPO reinforcement learning algorithms. Experiments across multiple benchmarks show that ERC consistently improves performance.

</details>


### [52] [IdealTSF: Can Non-Ideal Data Contribute to Enhancing the Performance of Time Series Forecasting Models?](https://arxiv.org/abs/2512.05442)
*Hua Wang,Jinghao Lu,Fan Zhang*

Main category: cs.LG

TL;DR: 该研究提出了IdealTSF框架，利用理想的正负样本进行时间序列预测。


<details>
  <summary>Details</summary>
Motivation: 解决时间序列预测中，序列数据中缺失值和异常值等问题阻碍深度学习进一步发展的问题。现有的研究主要集中在提取序列数据中的特征信息或将这些次优数据作为正样本进行知识转移。

Method: IdealTSF框架，包括三个渐进的步骤：预训练、训练和优化。首先通过从负样本数据中提取知识来预训练模型，然后在训练过程中将序列数据转化为理想的正样本。此外，还应用了带有对抗性扰动的负优化机制。

Result: 负样本数据在时间序列预测的基础注意力架构中释放了巨大的潜力。

Conclusion: IdealTSF特别适用于处理噪声样本或低质量数据的应用。

Abstract: Deep learning has shown strong performance in time series forecasting tasks. However, issues such as missing values and anomalies in sequential data hinder its further development in prediction tasks. Previous research has primarily focused on extracting feature information from sequence data or addressing these suboptimal data as positive samples for knowledge transfer. A more effective approach would be to leverage these non-ideal negative samples to enhance event prediction. In response, this study highlights the advantages of non-ideal negative samples and proposes the IdealTSF framework, which integrates both ideal positive and negative samples for time series forecasting. IdealTSF consists of three progressive steps: pretraining, training, and optimization. It first pretrains the model by extracting knowledge from negative sample data, then transforms the sequence data into ideal positive samples during training. Additionally, a negative optimization mechanism with adversarial disturbances is applied. Extensive experiments demonstrate that negative sample data unlocks significant potential within the basic attention architecture for time series forecasting. Therefore, IdealTSF is particularly well-suited for applications with noisy samples or low-quality data.

</details>


### [53] [How Ensemble Learning Balances Accuracy and Overfitting: A Bias-Variance Perspective on Tabular Data](https://arxiv.org/abs/2512.05469)
*Zubair Ahmed Mohammad*

Main category: cs.LG

TL;DR: 这篇文章探讨了集成模型在保持高准确性和避免过拟合方面的能力，特别关注它们如何通过减少方差来做到这一点。


<details>
  <summary>Details</summary>
Motivation: 探索集成模型在不同表格分类任务中如何平衡准确性和过拟合，并理解它们何时能有效控制方差，以提供实际模型选择指导。

Method: 使用重复分层交叉验证和统计显著性检验，比较了线性模型、单一决策树和九种集成方法在乳腺癌、心脏病、Pima糖尿病和信用卡欺诈这四种表格分类任务上的表现。此外，还计算了线性分数、Fisher比和噪声估计等数据集复杂性指标。

Result: 集成模型在不显著增加泛化误差的情况下，通过平均或受控提升来提高准确性。在接近线性且干净的数据上，集成模型的额外收益有限。在具有非线性结构的数据集上，基于树的集成模型将测试准确性提高了5到7个百分点，同时将泛化误差保持在3%以下。在噪声或高度不平衡的数据集上，集成模型仍然具有竞争力，但需要正则化以避免拟合噪声或多数类模式。数据集复杂性指标有助于解释集成模型何时能有效控制方差。

Conclusion: 集成模型能够通过减少方差在保持高准确性的同时有效控制过拟合。在模型选择时，了解数据集的特性（如线性度、噪声和不平衡性）对于判断集成模型是否能有效发挥作用以及如何进行正则化至关重要。

Abstract: Ensemble models often achieve higher accuracy than single learners, but their ability to maintain small generalization gaps is not always well understood. This study examines how ensembles balance accuracy and overfitting across four tabular classification tasks: Breast Cancer, Heart Disease, Pima Diabetes, and Credit Card Fraud. Using repeated stratified cross validation with statistical significance testing, we compare linear models, a single decision tree, and nine ensemble methods. The results show that ensembles can reach high accuracy without large gaps by reducing variance through averaging or controlled boosting. On nearly linear and clean data, linear models already generalize well and ensembles offer little additional benefit. On datasets with meaningful nonlinear structure, tree based ensembles increase test accuracy by 5 to 7 points while keeping gaps below 3 percent. On noisy or highly imbalanced datasets, ensembles remain competitive but require regularization to avoid fitting noise or majority class patterns. We also compute simple dataset complexity indicators, such as linearity score, Fisher ratio, and noise estimate, which explain when ensembles are likely to control variance effectively. Overall, the study provides a clear view of how and when ensembles maintain high accuracy while keeping overfitting low, offering practical guidance for model selection in real world tabular applications.

</details>


### [54] [PERM EQ x GRAPH EQ: Equivariant Neural Networks for Quantum Molecular Learning](https://arxiv.org/abs/2512.05475)
*Saumya Biswas,Jiten Oswal*

Main category: cs.LG

TL;DR: 本文比较了几种几何量子机器学习模型在分子几何排序中的性能，研究了它们在LiH和NH3分子数据集上的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索不同几何量子机器学习模型在分子几何学习中的性能差异及其与分子几何形状的关系，以确定模型选择标准并提高几何数据集的可训练性。

Method: 比较了无对称等变性、旋转和置换等变性以及图嵌入置换等变性的量子机器学习模型，并使用经典等变模型作为性能比较的基线。

Result: 图形特征嵌入是提高几何数据集可训练性的有效途径。置换对称嵌入被发现是几何学习中最具泛化性的量子机器学习模型。

Conclusion: 模型的性能差异和分子几何结构揭示了泛化性模型选择的标准。置换对称嵌入是几何学习中最具泛化性的量子机器学习模型。

Abstract: In hierarchal order of molecular geometry, we compare the performances of Geometric Quantum Machine Learning models. Two molecular datasets are considered: the simplistic linear shaped LiH-molecule and the trigonal pyramidal molecule NH3. Both accuracy and generalizability metrics are considered. A classical equivariant model is used as a baseline for the performance comparison. The comparative performance of Quantum Machine Learning models with no symmetry equivariance, rotational and permutational equivariance, and graph embedded permutational equivariance is investigated. The performance differentials and the molecular geometry in question reveals the criteria for choice of models for generalizability. Graph embedding of features is shown to be an effective pathway to greater trainability for geometric datasets. Permutational symmetric embedding is found to be the most generalizable quantum Machine Learning model for geometric learning.

</details>


### [55] [Credal and Interval Deep Evidential Classifications](https://arxiv.org/abs/2512.05526)
*Michele Caprio,Shireen K. Manchingal,Fabio Cuzzolin*

Main category: cs.LG

TL;DR: 这篇论文介绍了Credal和Interval Deep Evidential Classifications（CDEC和IDEC）两种新方法，用于解决AI分类任务中的不确定性量化问题。


<details>
  <summary>Details</summary>
Motivation: 在人工智能领域，不确定性量化（UQ）对决策、风险评估和模型可靠性有着深远影响。

Method: CDEC和IDEC利用信任集和证据预测分布区间，系统地评估认知不确定性（可约减）和偶然不确定性（不可约减）。当不确定性超过可接受阈值时，CDEC和IDEC能够拒绝分类并指出不确定性过高。在可接受的范围内，它们提供具有鲁棒概率保证的标签集合。CDEC和IDEC使用标准反向传播和基于证据理论的损失函数进行训练。

Result: 在MNIST、CIFAR-10和CIFAR-100等数据集及其域外漂移（OoD）上的大量实验表明，CDEC和IDEC在预测准确性方面具有竞争力，在认知不确定性和总不确定性下的OoD检测达到了最先进水平，并且在分布漂移下提供了紧密、校准良好的预测区域。消融实验也证明了CDEC在小规模集成下也能获得稳定的不确定性估计。

Conclusion: CDEC和IDEC克服了以往方法的缺点，扩展了当前的证据深度学习文献，为解决AI分类任务中的不确定性量化问题提供了有效的新方法。

Abstract: Uncertainty Quantification (UQ) presents a pivotal challenge in the field of Artificial Intelligence (AI), profoundly impacting decision-making, risk assessment and model reliability. In this paper, we introduce Credal and Interval Deep Evidential Classifications (CDEC and IDEC, respectively) as novel approaches to address UQ in classification tasks. CDEC and IDEC leverage a credal set (closed and convex set of probabilities) and an interval of evidential predictive distributions, respectively, allowing us to avoid overfitting to the training data and to systematically assess both epistemic (reducible) and aleatoric (irreducible) uncertainties. When those surpass acceptable thresholds, CDEC and IDEC have the capability to abstain from classification and flag an excess of epistemic or aleatoric uncertainty, as relevant. Conversely, within acceptable uncertainty bounds, CDEC and IDEC provide a collection of labels with robust probabilistic guarantees. CDEC and IDEC are trained using standard backpropagation and a loss function that draws from the theory of evidence. They overcome the shortcomings of previous efforts, and extend the current evidential deep learning literature. Through extensive experiments on MNIST, CIFAR-10 and CIFAR-100, together with their natural OoD shifts (F-MNIST/K-MNIST, SVHN/Intel, TinyImageNet), we show that CDEC and IDEC achieve competitive predictive accuracy, state-of-the-art OoD detection under epistemic and total uncertainty, and tight, well-calibrated prediction regions that expand reliably under distribution shift. An ablation over ensemble size further demonstrates that CDEC attains stable uncertainty estimates with only a small ensemble.

</details>


### [56] [IDK-S: Incremental Distributional Kernel for Streaming Anomaly Detection](https://arxiv.org/abs/2512.05531)
*Yang Xu,Yixiao Ma,Kaifeng Zhang,Zuliang Yang,Kai Ming Ting*

Main category: cs.LG

TL;DR: 本文介绍了一种名为 $\mathcal{IDK}$-$\mathcal{S}$ 的新型增量分布核方法，专门用于数据流上的异常检测。它通过引入动态表示和轻量级增量更新机制，在保持高检测精度的同时，显著提高了实时效率。


<details>
  <summary>Details</summary>
Motivation: 数据流上的异常检测面临挑战，要求方法在数据分布不断演变的情况下保持高检测精度，同时确保实时效率。

Method: 本文提出了一种名为 $\mathcal{IDK}$-$\mathcal{S}$ 的增量分布核方法。该方法继承了离线检测器 Isolation Distributional Kernel 的优点，并通过轻量级增量更新机制显著降低了计算开销，同时保持了与完全重新训练模型统计学上的等效性。

Result: 在十三个基准测试上的大量实验表明，$\mathcal{IDK}$-$\mathcal{S}$ 在检测精度上优于现有最先进的方法，并且运行速度显著加快，在许多情况下甚至能快一个数量级。

Conclusion: $\mathcal{IDK}$-$\mathcal{S}$ 在数据流异常检测方面取得了显著进展，它在保持高检测精度的同时具备卓越的实时效率，解决了传统方法的痛点。

Abstract: Anomaly detection on data streams presents significant challenges, requiring methods to maintain high detection accuracy among evolving distributions while ensuring real-time efficiency. Here we introduce $\mathcal{IDK}$-$\mathcal{S}$, a novel $\mathbf{I}$ncremental $\mathbf{D}$istributional $\mathbf{K}$ernel for $\mathbf{S}$treaming anomaly detection that effectively addresses these challenges by creating a new dynamic representation in the kernel mean embedding framework. The superiority of $\mathcal{IDK}$-$\mathcal{S}$ is attributed to two key innovations. First, it inherits the strengths of the Isolation Distributional Kernel, an offline detector that has demonstrated significant performance advantages over foundational methods like Isolation Forest and Local Outlier Factor due to the use of a data-dependent kernel. Second, it adopts a lightweight incremental update mechanism that significantly reduces computational overhead compared to the naive baseline strategy of performing a full model retraining. This is achieved without compromising detection accuracy, a claim supported by its statistical equivalence to the full retrained model. Our extensive experiments on thirteen benchmarks demonstrate that $\mathcal{IDK}$-$\mathcal{S}$ achieves superior detection accuracy while operating substantially faster, in many cases by an order of magnitude, than existing state-of-the-art methods.

</details>


### [57] [On the Theoretical Foundation of Sparse Dictionary Learning in Mechanistic Interpretability](https://arxiv.org/abs/2512.05534)
*Yiming Tang,Harshvardhan Saini,Yizhen Liao,Dianbo Liu*

Main category: cs.LG

TL;DR: 这篇论文提出了一个统一的理论框架，用于理解稀疏字典学习（SDL）方法如何将AI模型中叠加的概念解耦为可解释的特征，并解释了SDL中一些经验观察到的现象。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型能力的增强，理解它们学习到的表示以及信息处理方式变得越来越重要。现有的SDL方法虽然在实践中取得了成功，但在理论理解上存在局限性，特别是对于除带权值约束的稀疏自编码器之外的更广泛的SDL方法缺乏形式化基础。

Method: 本文将SDL视为一个统一的优化问题，并开发了一个统一的理论框架。

Result: 该框架展示了不同的SDL方法如何实例化，并对优化格局进行了严格分析。它首次为特征吸收、死亡神经元和神经元重采样等经验观察到的现象提供了理论解释。

Conclusion: 这项工作为稀疏字典学习方法提供了统一的理论基础，并解释了其在实践中观察到的一些关键现象。实验验证也进一步证明了理论结果的有效性。

Abstract: As AI models achieve remarkable capabilities across diverse domains, understanding what representations they learn and how they process information has become increasingly important for both scientific progress and trustworthy deployment. Recent works in mechanistic interpretability have shown that neural networks represent meaningful concepts as directions in their representation spaces and often encode many concepts in superposition. Various sparse dictionary learning (SDL) methods, including sparse autoencoders, transcoders, and crosscoders, address this by training auxiliary models with sparsity constraints to disentangle these superposed concepts into interpretable features. These methods have demonstrated remarkable empirical success but have limited theoretical understanding. Existing theoretical work is limited to sparse autoencoders with tied-weight constraints, leaving the broader family of SDL methods without formal grounding. In this work, we develop the first unified theoretical framework considering SDL as one unified optimization problem. We demonstrate how diverse methods instantiate the theoretical framwork and provide rigorous analysis on the optimization landscape. We provide the first theoretical explanations for some empirically observed phenomena, including feature absorption, dead neurons, and the neuron resampling technique. We further design controlled experiments to validate our theoretical results.

</details>


### [58] [SCoNE: Spherical Consistent Neighborhoods Ensemble for Effective and Efficient Multi-View Anomaly Detection](https://arxiv.org/abs/2512.05540)
*Yang Xu,Hang Zhang,Yixiao Ma,Ye Zhu,Kai Ming Ting*

Main category: cs.LG

TL;DR: 多视图异常检测中的一个核心问题是如何在所有视图中一致地表示正常实例的局部邻域。现有方法存在学习过程计算成本高和难以很好地捕获一致邻居的问题。为此，论文提出了一种名为SCoNE（Spherical Consistent Neighborhoods Ensemble）的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在表示多视图异常检测中正常实例的局部邻域时，存在计算成本高和难以很好地捕获一致邻居的问题，尤其是在不同视图中相同邻居位于不同密度区域时，这会导致检测精度不佳。

Method: 本文提出了一种新颖的方法，称为球形一致邻域集成（SCoNE）。它具有两个独特的特点：a）一致邻域直接用多视图实例表示，不需要像现有方法那样使用中间表示；b）邻域具有数据依赖性，这意味着在稀疏区域有大的邻域，在密集区域有小的邻域。数据依赖特性使得不同视图中的局部邻域能够很好地表示为一致邻域，无需学习过程。

Result: SCoNE在检测精度方面表现出色，并且在大型数据集上的运行速度比现有方法快几个数量级。

Conclusion: SCoNE通过直接表示多视图实例和数据依赖的邻域特性，解决了现有方法在多视图异常检测中存在的计算成本高和捕获一致邻居困难的问题，显著提高了检测精度并降低了计算复杂度。

Abstract: The core problem in multi-view anomaly detection is to represent local neighborhoods of normal instances consistently across all views. Recent approaches consider a representation of local neighborhood in each view independently, and then capture the consistent neighbors across all views via a learning process. They suffer from two key issues. First, there is no guarantee that they can capture consistent neighbors well, especially when the same neighbors are in regions of varied densities in different views, resulting in inferior detection accuracy. Second, the learning process has a high computational cost of $\mathcal{O}(N^2)$, rendering them inapplicable for large datasets. To address these issues, we propose a novel method termed \textbf{S}pherical \textbf{C}onsistent \textbf{N}eighborhoods \textbf{E}nsemble (SCoNE). It has two unique features: (a) the consistent neighborhoods are represented with multi-view instances directly, requiring no intermediate representations as used in existing approaches; and (b) the neighborhoods have data-dependent properties, which lead to large neighborhoods in sparse regions and small neighborhoods in dense regions. The data-dependent properties enable local neighborhoods in different views to be represented well as consistent neighborhoods, without learning. This leads to $\mathcal{O}(N)$ time complexity. Empirical evaluations show that SCoNE has superior detection accuracy and runs orders-of-magnitude faster in large datasets than existing approaches.

</details>


### [59] [Improving Local Fidelity Through Sampling and Modeling Nonlinearity](https://arxiv.org/abs/2512.05556)
*Sanjeev Shrestha,Rahul Dubey,Hui Liu*

Main category: cs.LG

TL;DR: 克服LIME缺点，提出一种可获取高置信度解释的新方法，可以更好地捕捉决策边界的非线性关系，并提高解释的忠实度。


<details>
  <summary>Details</summary>
Motivation: LIME未能捕捉非线性关系，导致解释不准确。

Method: 本文提出了一种新的方法，它使用MARS来模拟非线性局部边界，并利用N-ball采样技术，直接从期望的分布中进行采样，而不是像LIME那样对样本进行重新加权。

Result: 与基线相比，该方法能提供更忠实的解释，将均方根误差平均降低37%，显著提高了局部保真度。

Conclusion: 所提出的方法可以提供高保真的解释，并且可以更好地捕捉决策边界的非线性关系，有望为机器学习模型的解释性提供更准确和可靠的工具。

Abstract: With the increasing complexity of black-box machine learning models and their adoption in high-stakes areas, it is critical to provide explanations for their predictions. Local Interpretable Model-agnostic Explanation (LIME) is a widely used technique that explains the prediction of any classifier by learning an interpretable model locally around the predicted instance. However, it assumes that the local decision boundary is linear and fails to capture the non-linear relationships, leading to incorrect explanations. In this paper, we propose a novel method that can generate high-fidelity explanations. Multivariate adaptive regression splines (MARS) is used to model non-linear local boundaries that effectively captures the underlying behavior of the reference model, thereby enhancing the local fidelity of the explanation. Additionally, we utilize the N-ball sampling technique, which samples directly from the desired distribution instead of reweighting samples as done in LIME, further improving the faithfulness score. We evaluate our method on three UCI datasets across different classifiers and varying kernel widths. Experimental results show that our method yields more faithful explanations compared to baselines, achieving an average reduction of 37% in root mean square error, significantly improving local fidelity.

</details>


### [60] [Hyperparameter Transfer Enables Consistent Gains of Matrix-Preconditioned Optimizers Across Scales](https://arxiv.org/abs/2512.05620)
*Shikai Qiu,Zixi Chen,Hoang Phan,Qi Lei,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: 本文分析了几种利用矩阵级预处理的深度学习优化器在模型宽度和深度方面的超参数缩放规律，并发现学习率和权重衰减的特定缩放规则能显著提高这些优化器在大规模语言模型训练中的性能，从而实现比AdamW更快的训练速度。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过超参数迁移来扩展预处理优化器，以解决最近引入的深度学习优化器（如Shampoo、SOAP和Muon）在从小规模实验到大规模应用中表现出的不一致性，并更好地理解它们在大规模应用中的有效性。

Method: 作者研究了学习率和权重衰减如何随模型宽度和深度进行缩放，涵盖了Shampoo、SOAP和Muon等多种优化器，并考虑了阻塞（blocking）和嫁接（grafting）等常用技术的影响。他们在此基础上验证μP等先前的研究，并引入了明确的谱归一化作为缓解措施。

Result: 研究发现，根据μP缩放学习率可以改善迁移效果，但仍然存在显著的有限宽度偏差，导致最优学习率漂移。通过阻塞和明确的谱归一化可以缓解这种漂移。对于计算最优的缩放，独立的权重衰减按1/width缩放对所有优化器都接近最优。应用这些缩放规则后，Muon和Shampoo在训练1.9亿到14亿参数的Llama架构语言模型时，比AdamW分别实现了1.4倍和1.3倍的加速。

Conclusion: 研究表明，在给定实际的调优预算下，研究最优超参数迁移对于可靠地比较大规模优化器至关重要。正确理解和应用超参数缩放规则是实现预处理优化器在大规模应用中性能优势的关键。

Abstract: Several recently introduced deep learning optimizers utilizing matrix-level preconditioning have shown promising speedups relative to the current dominant optimizer AdamW, particularly in relatively small-scale experiments. However, efforts to validate and replicate their successes have reported mixed results. To better understand the effectiveness of these optimizers at scale, in this work we investigate how to scale preconditioned optimizers via hyperparameter transfer, building on prior works such as $μ$P. We study how the optimal learning rate and weight decay should scale with model width and depth for a wide range of optimizers, including Shampoo, SOAP, and Muon, accounting for the impact of commonly used techniques such as blocking and grafting. We find that scaling the learning rate according to $μ$P improves transfer, but can still suffer from significant finite-width deviations that cause drifting optimal learning rates, which we show can be mitigated by blocking and explicit spectral normalization. For compute-optimal scaling, we find scaling independent weight decay as $1/\mathrm{width}$ is nearly optimal across optimizers. Applying these scaling rules, we show Muon and Shampoo consistently achieve $1.4\times$ and $1.3\times$ speedup over AdamW for training Llama-architecture language models of sizes ranging from $190$M to $1.4$B, whereas the speedup vanishes rapidly with scale under incorrect scaling. Based on these results and further ablations, we argue that studying optimal hyperparameter transfer is essential for reliably comparing optimizers at scale given a realistic tuning budget.

</details>


### [61] [Beyond Data Filtering: Knowledge Localization for Capability Removal in LLMs](https://arxiv.org/abs/2512.05648)
*Igor Shilov,Alex Cloud,Aryo Pradipta Gema,Jacob Goldman-Wetzler,Nina Panickssery,Henry Sleight,Erik Jones,Cem Anil*

Main category: cs.LG

TL;DR: 本文提出了一种改进的梯度路由变体SGTM，用于在预训练阶段消除大语言模型中的有害知识，即使在标签噪声存在的情况下也比现有方法更有效，并对对抗性微调表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型日益增长的能力带来了双重用途的风险。数据过滤作为预训练阶段的缓解措施面临挑战，因为有害内容标记成本高昂，且少量错误标记内容可能导致危险能力。为了解决错误标记有害内容相关的风险，先前的工作提出了梯度路由（Gradient Routing），本文旨在探索其改进变体，以提高在标签噪声存在时的鲁棒性。

Method: 本文提出了一种名为选择性梯度掩蔽（Selective Gradient Masking, SGTM）的改进梯度路由变体。SGTM通过对选定梯度进行零掩蔽，确保目标领域示例只更新其专用参数。本文在两种应用中测试了SGTM的有效性：从双语合成数据集训练的模型中移除一种语言的知识，以及从英文维基百科训练的模型中移除生物学知识。

Result: 在两种应用中，SGTM在存在标签错误的情况下，相较于数据过滤和先前提出的梯度路由实例，都能提供更好的保留/遗忘权衡。与通过微调可快速撤销的浅层非学习方法不同，SGTM对对抗性微调表现出强大的鲁棒性，与基于微调的非学习方法（RMU）相比，需要七倍的微调步骤才能在遗忘集上达到基线性能。

Conclusion: SGTM为现有的安全缓解措施提供了一个有前景的预训练阶段补充，特别是在标签噪声不可避免的环境中。该方法能够有效且鲁棒地消除大语言模型中的特定有害知识。

Abstract: Large Language Models increasingly possess capabilities that carry dual-use risks. While data filtering has emerged as a pretraining-time mitigation, it faces significant challenges: labeling whether data is harmful is expensive at scale, and given improving sample efficiency with larger models, even small amounts of mislabeled content could give rise to dangerous capabilities. To address risks associated with mislabeled harmful content, prior work proposed Gradient Routing (Cloud et al., 2024) -- a technique that localizes target knowledge into a dedicated subset of model parameters so they can later be removed. We explore an improved variant of Gradient Routing, which we call Selective GradienT Masking (SGTM), with particular focus on evaluating its robustness to label noise. SGTM zero-masks selected gradients such that target domain examples only update their dedicated parameters. We test SGTM's effectiveness in two applications: removing knowledge of one language from a model trained on a bilingual synthetic dataset, and removing biology knowledge from a model trained on English Wikipedia. In both cases SGTM provides better retain/forget trade-off in the presence of labeling errors compared to both data filtering and a previously proposed instantiation of Gradient Routing. Unlike shallow unlearning approaches that can be quickly undone through fine-tuning, SGTM exhibits strong robustness to adversarial fine-tuning, requiring seven times more fine-tuning steps to reach baseline performance on the forget set compared to a finetuning-based unlearning method (RMU). Our results suggest SGTM provides a promising pretraining-time complement to existing safety mitigations, particularly in settings where label noise is unavoidable.

</details>


### [62] [Feasibility of AI-Assisted Programming for End-User Development](https://arxiv.org/abs/2512.05666)
*Irene Weber*

Main category: cs.LG

TL;DR: 这篇论文探讨了人工智能辅助的终端用户编程作为一种新的终端用户开发范式的可行性。


<details>
  <summary>Details</summary>
Motivation: 探索AI辅助的终端用户编程是否可以作为终端用户开发的可行范式，它可能会补充甚至取代LCNC模型。

Method: 通过案例研究，让非程序员使用AI助手开发基本的Web应用。

Result: 大多数参与者在合理的时间内成功完成任务，并支持AI辅助的终端用户编程作为一种可行的终端用户开发方法。

Conclusion: AI辅助的终端用户编程是终端用户开发的一种可行范式，具有更高的灵活性和更广的应用范围。

Abstract: End-user development,where non-programmers create or adapt their own digital tools, can play a key role in driving digital transformation within organizations. Currently, low-code/no-code platforms are widely used to enable end-user development through visual programming, minimizing the need for manual coding. Recent advancements in generative AI, particularly large language model-based assistants and "copilots", open new possibilities, as they may enable end users to generate and refine programming code and build apps directly from natural language prompts. This approach, here referred to as AI-assisted end-user coding, promises greater flexibility, broader applicability, faster development, improved reusability, and reduced vendor lock-in compared to the established visual LCNC platforms. This paper investigates whether AI-assisted end-user coding is a feasible paradigm for end-user development, which may complement or even replace the LCNC model in the future. To explore this, we conducted a case study in which non-programmers were asked to develop a basic web app through interaction with AI assistants.The majority of study participants successfully completed the task in reasonable time and also expressed support for AI-assisted end-user coding as a viable approach for end-user development. The paper presents the study design, analyzes the outcomes, and discusses potential implications for practice, future research, and academic teaching.

</details>


### [63] [Mechanistic Interpretability of Antibody Language Models Using SAEs](https://arxiv.org/abs/2512.05794)
*Rebonto Haque,Oliver M. Turnbull,Anisha Parsan,Nithin Parsan,John J. Yang,Charlotte M. Deane*

Main category: cs.LG

TL;DR: 本文探讨了稀疏自动编码器（SAE）在蛋白质语言模型中的应用，以提供对学习概念的洞察。


<details>
  <summary>Details</summary>
Motivation: 作者旨在研究TopK和有序SAE在分析自回归抗体语言模型p-IgGen中的应用，并指导其生成。

Method: 本文采用了TopK和有序SAE来分析蛋白质语言模型p-IgGen。

Result: TopK SAEs能够揭示生物学上 S D U N S U U R L U P U L O P 有意义的潜在特征，但高特征概念相关性不能保证对生成的因果控制。而有序SAE施加了层次结构，可靠地识别可控特征，但代价是激活模式更复杂且 S D U N S U U R L U P U L O P 解释性 S D U N S U U R L U P U L O P 较差。

Conclusion: TopK SAE足以将潜在特征映射到概念，而当需要精确的生成控制时，有序SAE是更优的选择，这 S D U N S U U R L U P U L O P 推动了 S D U N S U U R L U P U L O P 特定领域蛋白质语言模型的机械可解释性发展。

Abstract: Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose an hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs are sufficient for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.

</details>


### [64] [Utility Boundary of Dataset Distillation: Scaling and Configuration-Coverage Laws](https://arxiv.org/abs/2512.05817)
*Zhengquan Luo,Zhiqiang Xu*

Main category: cs.LG

TL;DR: 这篇论文提出了一个统一的理论框架，利用配置-动态-误差分析，通过泛化误差的视角重新构建了主流的数据集蒸馏方法，并给出了两种主要的理论结果，一个为在单配置下，蒸馏出的数据规模的收敛定律，另一个为多配置下的蒸馏的数据规模定律。


<details>
  <summary>Details</summary>
Motivation: 以往的数据集蒸馏方法缺少统一的理论框架，其工作原理难以被分析，在改变配置（例如优化器、架构或增强）时，蒸馏出的数据能否和完整数据集同样有效，这一点尚不清楚。

Method: 本文提出了一个统一的理论框架，称为配置-动态-误差分析，从共同的泛化误差角度重新制定了主要的数据集蒸馏（DD）方法。

Result: 本文提出了一个单配置上限的收敛定律，它描述了随着蒸馏样本量的增加，误差如何减少，并解释了常见性能饱和效应。同时本文提出了一个覆盖定律，表明所需的蒸馏样本量与配置多样性呈线性关系，具有可证明的匹配上限和下限。此外，本文的统一分析揭示了各种匹配方法是可互换的替代品，它们减少了相同的泛化误差，从而阐明了为什么它们都可以实现数据集蒸馏，并为替代品选择如何影响样本效率和鲁棒性提供了指导。

Conclusion: 本文通过实验证明了所提出的理论框架的有效性，为数据集蒸馏提供了理论基础，并能够实现紧凑、配置鲁棒的数据集蒸馏的理论驱动设计。

Abstract: Dataset distillation (DD) aims to construct compact synthetic datasets that allow models to achieve comparable performance to full-data training while substantially reducing storage and computation. Despite rapid empirical progress, its theoretical foundations remain limited: existing methods (gradient, distribution, trajectory matching) are built on heterogeneous surrogate objectives and optimization assumptions, which makes it difficult to analyze their common principles or provide general guarantees. Moreover, it is still unclear under what conditions distilled data can retain the effectiveness of full datasets when the training configuration, such as optimizer, architecture, or augmentation, changes. To answer these questions, we propose a unified theoretical framework, termed configuration--dynamics--error analysis, which reformulates major DD approaches under a common generalization-error perspective and provides two main results: (i) a scaling law that provides a single-configuration upper bound, characterizing how the error decreases as the distilled sample size increases and explaining the commonly observed performance saturation effect; and (ii) a coverage law showing that the required distilled sample size scales linearly with configuration diversity, with provably matching upper and lower bounds. In addition, our unified analysis reveals that various matching methods are interchangeable surrogates, reducing the same generalization error, clarifying why they can all achieve dataset distillation and providing guidance on how surrogate choices affect sample efficiency and robustness. Experiments across diverse methods and configurations empirically confirm the derived laws, advancing a theoretical foundation for DD and enabling theory-driven design of compact, configuration-robust dataset distillation.

</details>


### [65] [Approximation of Box Decomposition Algorithm for Fast Hypervolume-Based Multi-Objective Optimization](https://arxiv.org/abs/2512.05825)
*Shuhei Watanabe*

Main category: cs.LG

TL;DR: 高斯过程模型可以提高超体积在基于贝叶斯优化的多目标决策中的计算效率


<details>
  <summary>Details</summary>
Motivation: 超体积（HV）在基于贝叶斯优化的多目标决策中，计算成本是一个瓶颈；现有的HV盒分解算法在最坏情况下的内存复杂度过高，而近似算法尚缺乏严谨的算法描述。

Method: 本文旨在通过提供 Couckuyt 等人（2012）提出的近似算法的全面数学和算法细节来弥补这一空白。

Result: 通过提供近似算法的详细描述，可以降低HV改进计算的复杂性。

Conclusion: 本文详细描述了HV近似算法，从而提高了基于贝叶斯优化的多目标决策的效率。

Abstract: Hypervolume (HV)-based Bayesian optimization (BO) is one of the standard approaches for multi-objective decision-making. However, the computational cost of optimizing the acquisition function remains a significant bottleneck, primarily due to the expense of HV improvement calculations. While HV box-decomposition offers an efficient way to cope with the frequent exact improvement calculations, it suffers from super-polynomial memory complexity $O(MN^{\lfloor \frac{M + 1}{2} \rfloor})$ in the worst case as proposed by Lacour et al. (2017). To tackle this problem, Couckuyt et al. (2012) employed an approximation algorithm. However, a rigorous algorithmic description is currently absent from the literature. This paper bridges this gap by providing comprehensive mathematical and algorithmic details of this approximation algorithm.

</details>


### [66] [NEAT: Neighborhood-Guided, Efficient, Autoregressive Set Transformer for 3D Molecular Generation](https://arxiv.org/abs/2512.05844)
*Daniel Rose,Roxane Axel Jacob,Johannes Kirchmair,Thierry Langer*

Main category: cs.LG

TL;DR: NEAT 是一种基于邻域引导的、高效的、自回归的集合变换器，它能处理分子图为原子集合，并以自回归流模型学习图边界上可接受标记的与顺序无关的分布。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在3D分子结构生成方面是扩散模型的有前途替代，但存在令牌顺序假设的关键限制，即文本具有自然顺序，而给定分子图前缀的下一个令牌预测应与原子排列无关。

Method: NEAT 将分子图视为原子集合，并使用自回归流模型学习图边界处允许的令牌的与顺序无关的分布。

Result: NEAT 在 3D 分子生成方面达到了最先进的性能，具有高计算效率和原子级排列不变性。

Conclusion: NEAT 为可扩展分子设计奠定了实用基础。

Abstract: Autoregressive models are a promising alternative to diffusion-based models for 3D molecular structure generation. However, a key limitation is the assumption of a token order: while text has a natural sequential order, the next token prediction given a molecular graph prefix should be invariant to atom permutations. Previous works sidestepped this mismatch by using canonical orders or focus atoms. We argue that this is unnecessary. We introduce NEAT, a Neighborhood-guided, Efficient, Autoregressive, Set Transformer that treats molecular graphs as sets of atoms and learns the order-agnostic distribution over admissible tokens at the graph boundary with an autoregressive flow model. NEAT approaches state-of-the-art performance in 3D molecular generation with high computational efficiency and atom-level permutation invariance, establishing a practical foundation for scalable molecular design.

</details>


### [67] [Sparse Attention Post-Training for Mechanistic Interpretability](https://arxiv.org/abs/2512.05865)
*Florent Draye,Anson Lei,Ingmar Posner,Bernhard Schölkopf*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种简单的Transformer注意力稀疏化方法，可以在不牺牲性能的情况下将注意力连接减少到约0.3%，同时使模型更具可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统的Transformer模型中存在大量冗余计算，注意力连接过于密集，缺乏可解释性。

Method: 通过在受限损失目标下应用灵活的稀疏性正则化，使Transformer模型在不影响原始预训练损失的情况下，将注意力连接减少到约0.3%。

Result: 该方法成功将注意力连接减少到约0.3%，且不影响模型性能。稀疏化使得任务特定电路涉及更少的组件，连接边缘减少了100倍。

Conclusion: Transformer注意力可以大大稀疏化，表明大部分计算是冗余的。稀疏性可以作为构建更结构化和可解释模型的指导原则。

Abstract: We introduce a simple post-training method that makes transformer attention sparse without sacrificing performance. Applying a flexible sparsity regularisation under a constrained-loss objective, we show on models up to 1B parameters that it is possible to retain the original pretraining loss while reducing attention connectivity to $\approx 0.3 \%$ of its edges. Unlike sparse-attention methods designed for computational efficiency, our approach leverages sparsity as a structural prior: it preserves capability while exposing a more organized and interpretable connectivity pattern. We find that this local sparsity cascades into global circuit simplification: task-specific circuits involve far fewer components (attention heads and MLPs) with up to 100x fewer edges connecting them. These results demonstrate that transformer attention can be made orders of magnitude sparser, suggesting that much of its computation is redundant and that sparsity may serve as a guiding principle for more structured and interpretable models.

</details>


### [68] [Computational Design of Low-Volatility Lubricants for Space Using Interpretable Machine Learning](https://arxiv.org/abs/2512.05870)
*Daniel Miliate,Ashlie Martini*

Main category: cs.LG

TL;DR: 该研究介绍了一种数据驱动的机器学习方法来预测液体润滑剂的蒸汽压，以在分子动力学模拟和实验数据库的帮助下实现新型润滑剂的虚拟筛选和发现。


<details>
  <summary>Details</summary>
Motivation: 在空间中移动机械组件（MMA）的功能和寿命取决于润滑剂的性能，而空间中的MMAs由于其高速或高循环而需要液态润滑剂。

Method: 本文提出了一种数据驱动的机器学习（ML）方法来预测蒸汽压，从而实现新型液态空间润滑剂的虚拟筛选和发现。ML模型通过高通量分子动力学模拟和实验数据库中的数据进行训练。

Result: 模型优先考虑可解释性，从而能够识别化学结构和蒸汽压之间的关系。

Conclusion: 该研究提出了几种候选分子，这些分子有望在MMAs中用于未来的空间润滑剂应用。

Abstract: The function and lifetime of moving mechanical assemblies (MMAs) in space depend on the properties of lubricants. MMAs that experience high speeds or high cycles require liquid based lubricants due to their ability to reflow to the point of contact. However, only a few liquid-based lubricants have vapor pressures low enough for the vacuum conditions of space, each of which has limitations that add constraints to MMA designs. This work introduces a data-driven machine learning (ML) approach to predicting vapor pressure, enabling virtual screening and discovery of new space-suitable liquid lubricants. The ML models are trained with data from both high-throughput molecular dynamics simulations and experimental databases. The models are designed to prioritize interpretability, enabling the relationships between chemical structure and vapor pressure to be identified. Based on these insights, several candidate molecules are proposed that may have promise for future space lubricant applications in MMAs.

</details>


### [69] [Neural Coherence : Find higher performance to out-of-distribution tasks from few samples](https://arxiv.org/abs/2512.05880)
*Simon Guiroy,Mats Richter,Sarath Chandar,Christopher Pal*

Main category: cs.LG

TL;DR: 本文提出了一种名为“神经一致性”的新方法，可以在目标任务数据稀缺、无标签和分布外时，仅使用少量无标签样本对预训练大型视觉模型进行模型选择。


<details>
  <summary>Details</summary>
Motivation: 在下游任务中，微调预训练的大型视觉模型已成为常见做法，但如何选择最佳的模型检查点作为起点仍是一个开放性问题。当目标任务数据稀缺、无标签且分布外时，依赖域内验证数据的常见方法变得不可靠或不适用。

Method: 本文提出了一种基于“神经一致性”的新方法，通过描述模型在源域和目标域的激活统计来定义模型选择方法，实现了高数据效率。

Result: 在ImageNet1K上预训练的模型，并在Food-101、PlantNet-300K和iNaturalist等目标域上进行实验，以及在许多元学习设置中进行评估。结果表明，与已有基线相比，该方法显著提高了这些不同目标域的泛化能力。

Conclusion: “神经一致性”作为一种强大的原则，在模型选择和训练数据选择方面都展现了其有效性和多功能性，显著改善了数据稀缺场景下的模型泛化能力。

Abstract: To create state-of-the-art models for many downstream tasks, it has become common practice to fine-tune a pre-trained large vision model. However, it remains an open question of how to best determine which of the many possible model checkpoints resulting from a large training run to use as the starting point. This becomes especially important when data for the target task of interest is scarce, unlabeled and out-of-distribution. In such scenarios, common methods relying on in-distribution validation data become unreliable or inapplicable. This work proposes a novel approach for model selection that operates reliably on just a few unlabeled examples from the target task. Our approach is based on a novel concept: Neural Coherence, which entails characterizing a model's activation statistics for source and target domains, allowing one to define model selection methods with high data-efficiency. We provide experiments where models are pre-trained on ImageNet1K and examine target domains consisting of Food-101, PlantNet-300K and iNaturalist. We also evaluate it in many meta-learning settings. Our approach significantly improves generalization across these different target domains compared to established baselines. We further demonstrate the versatility of Neural Coherence as a powerful principle by showing its effectiveness in training data selection.

</details>


### [70] [MaxShapley: Towards Incentive-compatible Generative Search with Fair Context Attribution](https://arxiv.org/abs/2512.05958)
*Sara Patel,Mingxun Zhou,Giulia Fanti*

Main category: cs.LG

TL;DR: 该文章介绍了一种名为 MaxShapley 的高效算法，用于在生成式搜索中公平地归因和补偿内容提供者，解决了大型语言模型（LLMs）取代传统搜索后信息提供者补偿方式变化的问题。 MaxShapley 算法通过利用可分解的最大和效用函数，以线性时间计算归因，与指数级计算成本的 Shapley 值相比，具有显著的效率提升，并在多跳问答数据集上展现出与精确 Shapley 计算相当的归因质量，同时大幅降低了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）驱动的生成式搜索引擎正在取代传统搜索，改变了信息提供者的报酬方式，因此需要建立公平的机制来根据内容提供者对生成答案的贡献进行归因和补偿，以维持信息生态系统的可持续发展。

Method: 本文提出了一种名为 MaxShapley 的算法。该算法是 Shapley 值的一种特殊情况，但其核心在于利用可分解的最大和效用函数。通过这种方式，MaxShapley 能够以与文档数量呈线性关系的时间复杂度计算归因，显著降低了计算成本，避免了 Shapley 值指数级的计算开销。

Result: MaxShapley 在三个多跳问答数据集（HotPotQA, MuSiQUE, MS MARCO）上进行了评估，结果显示其归因质量与精确的 Shapley 计算相当。在保持相同归因准确性的前提下，MaxShapley 显著降低了资源消耗。例如，与现有最先进的方法相比，它能将资源消耗减少高达8倍。

Conclusion: MaxShapley 算法为生成式搜索中的内容归因和补偿提供了一个高效且公平的解决方案。它在保持高归因质量的同时，通过显著降低计算资源消耗，解决了大型语言模型时代信息提供者补偿机制的挑战，有助于构建一个可持续的信息生态系统。

Abstract: Generative search engines based on large language models (LLMs) are replacing traditional search, fundamentally changing how information providers are compensated. To sustain this ecosystem, we need fair mechanisms to attribute and compensate content providers based on their contributions to generated answers. We introduce MaxShapley, an efficient algorithm for fair attribution in generative search pipelines that use retrieval-augmented generation (RAG). MaxShapley is a special case of the celebrated Shapley value; it leverages a decomposable max-sum utility function to compute attributions with linear computation in the number of documents, as opposed to the exponential cost of Shapley values. We evaluate MaxShapley on three multi-hop QA datasets (HotPotQA, MuSiQUE, MS MARCO); MaxShapley achieves comparable attribution quality to exact Shapley computation, while consuming a fraction of its tokens--for instance, it gives up to an 8x reduction in resource consumption over prior state-of-the-art methods at the same attribution accuracy.

</details>


### [71] [KQ-SVD: Compressing the KV Cache with Provable Guarantees on Attention Fidelity](https://arxiv.org/abs/2512.05916)
*Damien Lesens,Beheshteh T. Rakhshan,Guillaume Rabusseau*

Main category: cs.LG

TL;DR: KQ-SVD是一种针对LLM中KV缓存的高效压缩方法，通过直接对注意力矩阵进行最优的低秩分解，解决了传统方法的次优性问题。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型中，KV缓存随着序列长度和批次大小的增加，成为主要的内存瓶颈。现有的压缩方法未能充分考虑到注意力机制的内在特性，导致压缩效果不理想。

Method: KQ-SVD通过闭式解直接对注意力矩阵进行最优的低秩分解。这种方法不同于以往仅对键进行低秩分解或联合嵌入查询和键的策略。

Result: 在LLaMA和Mistral模型上的大量评估表明，KQ-SVD在压缩下能以更高的保真度保持注意力输出，并持续提供卓越的投影质量。

Conclusion: KQ-SVD通过直接对注意力矩阵进行最优的低秩分解，有效地解决了LLM中KV缓存的内存瓶颈问题，并在保持注意力输出保真度方面优于现有方法。

Abstract: The Key-Value (KV) cache is central to the efficiency of transformer-based large language models (LLMs), storing previously computed vectors to accelerate inference. Yet, as sequence length and batch size grow, the cache becomes a major memory bottleneck. Prior compression methods typically apply low-rank decomposition to keys alone or attempt to jointly embed queries and keys, but both approaches neglect that attention fundamentally depends on their inner products. In this work, we prove that such strategies are suboptimal for approximating the attention matrix. We introduce KQ-SVD, a simple and computationally efficient method that directly performs an optimal low-rank decomposition of the attention matrix via a closed-form solution. By targeting the true source of redundancy, KQ-SVD preserves attention outputs with higher fidelity under compression. Extensive evaluations on LLaMA and Mistral models demonstrate that our approach consistently delivers superior projection quality.

</details>


### [72] [Whatever Remains Must Be True: Filtering Drives Reasoning in LLMs, Shaping Diversity](https://arxiv.org/abs/2512.05962)
*Germán Kruszewski,Pierre Erbacher,Jos Rozen,Marc Dymetman*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法来解决强化学习在调整大型语言模型（LLMs）时多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习在调整LLMs以解决推理任务时表现出色，但会导致模型多样性显著下降。作者认为这是因为强化学习隐式地优化了“模式搜索”或“零强制”的反向KL散度，使得模型倾向于高概率区域而忽略其他区域。

Method: 本文从一个明确的目标分布开始，该目标分布通过过滤掉不正确答案并保留正确答案的相对概率获得。然后，作者使用α-散度家族来 H 近似这个目标分布，α-散度家族统一了以前的方法，并通过在模式搜索和质量覆盖散度之间进行插值，直接控制了精度-多样性之间的权衡。

Result: 在Lean定理证明基准测试中，该方法在覆盖率-精度帕累托前沿上达到了最先进的性能，在覆盖率方面优于所有现有方法。

Conclusion: 本文提出了一种通过显式目标分布和α-散度家族来提高LLM多样性的新方法，并在实验中验证了其有效性。

Abstract: Reinforcement Learning (RL) has become the de facto standard for tuning LLMs to solve tasks involving reasoning. However, growing evidence shows that models trained in such way often suffer from a significant loss in diversity. We argue that this arises because RL implicitly optimizes the "mode-seeking" or "zero-forcing" Reverse KL to a target distribution causing the model to concentrate mass on certain high-probability regions of the target while neglecting others. In this work, we instead begin from an explicit target distribution, obtained by filtering out incorrect answers while preserving the relative probabilities of correct ones. Starting from a pre-trained LLM, we approximate this target distribution using the $α$-divergence family, which unifies prior approaches and enables direct control of the precision-diversity trade-off by interpolating between mode-seeking and mass-covering divergences. On a Lean theorem-proving benchmark, our method achieves state-of-the-art performance along the coverage-precision Pareto frontier, outperforming all prior methods on the coverage axis.

</details>


### [73] [Developing synthetic microdata through machine learning for firm-level business surveys](https://arxiv.org/abs/2512.05948)
*Jorge Cisneros Paz,Timothy Wojan,Matthew Williams,Jennifer Ozawa,Robert Chew,Kimberly Janda,Timothy Navarro,Michael Floyd,Christine Task,Damon Streat*

Main category: cs.LG

TL;DR: 该文章讨论了利用机器学习模型从年度商业调查（ABS）中生成综合的公共使用微观数据样本（PUMS）的方法及其质量评估，旨在解决匿名数据重识别的风险并为商业数据提供可行的公开使用形式。


<details>
  <summary>Details</summary>
Motivation: 由于计算能力的显著提高和大数据应用的普及，匿名数据的重识别风险增加，可能违反对调查对象的保密承诺。特别是在企业数据方面，匿名性较差，特定行业容易被识别。因此，需要开发能够保留实证数据关键特征但又不包含任何现有受访者记录的合成数据。

Method: 本文描述了一种使用机器学习模型来构建基于年度商业调查（ABS）的合成PUMS的方法。文章还讨论了评估这些合成数据质量的各种指标。为了验证其有效性，作者利用一个与ABS商业数据相似的2007年企业主调查开发的两个合成PUMS，进行了计量经济学复制，重现了一项已发表在高影响力期刊上的分析结果。

Result: 尽管ABS PUMS仍在完善中且结果保密，但通过复制2007年企业主调查的合成PUMS，并成功重现了已发表在高影响力期刊《小企业经济学》上的一项分析，证明了合成数据与真实数据的相似性。此结果也为ABS的潜在使用场景提供了讨论基础。

Conclusion: 机器学习模型可以有效地生成保持了原始数据关键特性的合成PUMS，同时又规避了重新识别匿名数据的风险。尽管商业数据的匿名化存在挑战，但合成数据为其公开使用提供了一个可行的解决方案，并且通过计量经济学分析证明了其高度的真实性。未来可将此方法应用于类似ABS的数据集，以促进数据共享和分析。

Abstract: Public-use microdata samples (PUMS) from the United States (US) Census Bureau on individuals have been available for decades. However, large increases in computing power and the greater availability of Big Data have dramatically increased the probability of re-identifying anonymized data, potentially violating the pledge of confidentiality given to survey respondents. Data science tools can be used to produce synthetic data that preserve critical moments of the empirical data but do not contain the records of any existing individual respondent or business. Developing public-use firm data from surveys presents unique challenges different from demographic data, because there is a lack of anonymity and certain industries can be easily identified in each geographic area. This paper briefly describes a machine learning model used to construct a synthetic PUMS based on the Annual Business Survey (ABS) and discusses various quality metrics. Although the ABS PUMS is currently being refined and results are confidential, we present two synthetic PUMS developed for the 2007 Survey of Business Owners, similar to the ABS business data. Econometric replication of a high impact analysis published in Small Business Economics demonstrates the verisimilitude of the synthetic data to the true data and motivates discussion of possible ABS use cases.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [74] [Semantic Faithfulness and Entropy Production Measures to Tame Your LLM Demons and Manage Hallucinations](https://arxiv.org/abs/2512.05156)
*Igor Halperin*

Main category: cs.AI

TL;DR: 本文提出了两种基于信息论和热力学的新型无监督方法来评估大型语言模型（LLMs）的忠实性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）对给定任务的忠实性是一个复杂的问题。

Method: 将LLM视为information engine，隐藏层作为Maxwell demon控制上下文C通过提示Q转换为答案A。将QCA三元组建模为共享主题上的概率分布。主题从C到Q和A的转换被建模为transition matrices Q和A，分别编码查询目标和实际结果。语义忠实度（SF）度量通过这些矩阵之间的Kullback-Leibler（KL）散度来量化任何给定QCA三元组的忠实度。同时通过KL散度的凸优化推断出两个矩阵，并通过将最小散度映射到单位区间[0,1]来获得最终的SF度量。还提出了一种基于热力学的语义熵产生（SEP）度量。

Result: SF和SEP度量可以联合或单独用于LLM评估和幻觉控制。高忠实度通常意味着低熵产生。

Conclusion: 本文提出了两种用于评估LLM忠实性的新型无监督指标：语义忠实度（SF）和语义熵产生（SEP），这两种指标可以用于LLM的评估和幻觉控制。

Abstract: Evaluating faithfulness of Large Language Models (LLMs) to a given task is a complex challenge. We propose two new unsupervised metrics for faithfulness evaluation using insights from information theory and thermodynamics. Our approach treats an LLM as a bipartite information engine where hidden layers act as a Maxwell demon controlling transformations of context $C $ into answer $A$ via prompt $Q$. We model Question-Context-Answer (QCA) triplets as probability distributions over shared topics. Topic transformations from $C$ to $Q$ and $A$ are modeled as transition matrices ${\bf Q}$ and ${\bf A}$ encoding the query goal and actual result, respectively. Our semantic faithfulness (SF) metric quantifies faithfulness for any given QCA triplet by the Kullback-Leibler (KL) divergence between these matrices. Both matrices are inferred simultaneously via convex optimization of this KL divergence, and the final SF metric is obtained by mapping the minimal divergence onto the unit interval [0,1], where higher scores indicate greater faithfulness. Furthermore, we propose a thermodynamics-based semantic entropy production (SEP) metric in answer generation, and show that high faithfulness generally implies low entropy production. The SF and SEP metrics can be used jointly or separately for LLM evaluation and hallucination control. We demonstrate our framework on LLM summarization of corporate SEC 10-K filings.

</details>


### [75] [Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education](https://arxiv.org/abs/2512.05167)
*Fang Li*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种创新的教学方法，用于将传统机器学习与现代大型语言模型（LLMs）相结合，以教授人工智能和数据科学。


<details>
  <summary>Details</summary>
Motivation: 作者旨在解决传统机器学习与现代大型语言模型（LLMs）之间的教学鸿沟，使学生对人工智能的演进有全面的理解，并掌握相关实践技能。

Method: 课程分为两个部分：基础机器学习概念和当代LLM应用。课程设计包括课程架构、实施策略、评估方法和学习成果。

Result: 研究发现，这种整合方法增强了学生对人工智能领域的理解，并更好地为他们应对快速发展的人工智能行业的挑战做好了准备。

Conclusion: 该教学方法成功地将传统机器学习与现代LLM相结合，提高了学生的学习效果和就业竞争力。

Abstract: This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies, assessment methods, and learning outcomes from our summer course delivery spanning two seven-week terms. Our findings demonstrate that this integrated approach enhances student comprehension of the AI landscape and better prepares them for industry demands in the rapidly evolving field of artificial intelligence.

</details>


### [76] [On the Computability of Artificial General Intelligence](https://arxiv.org/abs/2512.05212)
*Georgios Mappouras,Charalambos Rossides*

Main category: cs.AI

TL;DR: 这篇论文探讨了人工智能（A.I.）和通用人工智能（A.G.I.）的极限，并证明了任何算法都无法真正地创造出新的功能。


<details>
  <summary>Details</summary>
Motivation: 作者旨在探讨人类离实现通用人工智能（A.G.I.）的距离，并试图定义任何机器可计算过程（即算法）的上限。

Method: 通过借鉴既有工作对A.G.I.的定义，即在某个研究领域中创新和创造新功能的能力，作者正式证明了算法的计算极限。

Result: 研究结果表明，算法无法展示出其自身初始设计中不曾存在的新功能，因此，任何算法（包括A.I.模型）都无法在任何研究领域中实现真正的创造力。A.I.模型只能展示现有功能以及现有功能的组合和排列。

Conclusion: 论文最后讨论了这项证明对A.I.未来发展以及人类智能起源的意义。

Abstract: In recent years we observed rapid and significant advancements in artificial intelligence (A.I.). So much so that many wonder how close humanity is to developing an A.I. model that can achieve human level of intelligence, also known as artificial general intelligence (A.G.I.). In this work we look at this question and we attempt to define the upper bounds, not just of A.I., but rather of any machine-computable process (a.k.a. an algorithm). To answer this question however, one must first precisely define A.G.I. We borrow prior work's definition of A.G.I. [1] that best describes the sentiment of the term, as used by the leading developers of A.I. That is, the ability to be creative and innovate in some field of study in a way that unlocks new and previously unknown functional capabilities in that field. Based on this definition we draw new bounds on the limits of computation. We formally prove that no algorithm can demonstrate new functional capabilities that were not already present in the initial algorithm itself. Therefore, no algorithm (and thus no A.I. model) can be truly creative in any field of study, whether that is science, engineering, art, sports, etc. In contrast, A.I. models can demonstrate existing functional capabilities, as well as combinations and permutations of existing functional capabilities. We conclude this work by discussing the implications of this proof both as it regards to the future of A.I. development, as well as to what it means for the origins of human intelligence.

</details>


### [77] [Resolving Zadehs Paradox Axiomatic Possibility Theory as a Foundation for Reliable Artificial Intelligence](https://arxiv.org/abs/2512.05257)
*Bychkov Oleksii,Bychkova Sophia,Lytvynchuk Khrystyna*

Main category: cs.AI

TL;DR: 本文探讨了通过可能性理论解决DST (Dempster-Shafer 理论) 悖论的根本方法，而不是修改Dempster的规则。该方法使用可能性和必要性度量的双重机制，提供了一个严谨的不确定性基础。


<details>
  <summary>Details</summary>
Motivation: 这篇论文旨在证明可能性理论不仅是 DST 的替代方案，而且是解决 DST 悖论的基本方法

Method: 本文将对概率范式、证据范式和可能性范式进行比较分析。它将使用一个经典的医学诊断困境作为例子，展示可能性理论如何正确处理矛盾数据，避免 DST 的逻辑陷阱，并使形式推理更接近自然智能的逻辑。

Result: 通过对医学诊断困境的分析，该研究将展示可能性理论如何有效处理矛盾数据，避免 DST 的逻辑缺陷，并使形式推理更符合自然智能的逻辑。

Conclusion: 可能性理论为解决DST悖论提供了一个基本且逻辑一致的框架，它能够有效地处理矛盾信息，这与传统的概率和证据方法不同。

Abstract: This work advances and substantiates the thesis that the resolution of this crisis lies in the domain of possibility theory, specifically in the axiomatic approach developed in Bychkovs article. Unlike numerous attempts to fix Dempster rule, this approach builds from scratch a logically consistent and mathematically rigorous foundation for working with uncertainty, using the dualistic apparatus of possibility and necessity measures. The aim of this work is to demonstrate that possibility theory is not merely an alternative, but provides a fundamental resolution to DST paradoxes. A comparative analysis of three paradigms will be conducted probabilistic, evidential, and possibilistic. Using a classic medical diagnostic dilemma as an example, it will be shown how possibility theory allows for correct processing of contradictory data, avoiding the logical traps of DST and bringing formal reasoning closer to the logic of natural intelligence.

</details>


### [78] [AI & Human Co-Improvement for Safer Co-Superintelligence](https://arxiv.org/abs/2512.05356)
*Jason Weston,Jakob Foerster*

Main category: cs.AI

TL;DR: 这篇文章提倡人机协作，以实现“协同超级智能”，从而加速人工智能研究，并确保人工智能和人类超级智能更加安全。


<details>
  <summary>Details</summary>
Motivation: 作者认为，虽然人工智能的自我完善令人兴奋，但存在风险且难以实现。因此，他们提出人机协作的共同改进是人类更可行、更好的目标。

Method: 通过提高人工智能系统与人类研究人员合作进行人工智能研究的能力，包括从概念形成到实验的各个阶段，来实现人机协作。

Result: 加速人工智能研究，并通过人机共生，使人工智能和人类都获得更安全的超级智能。

Conclusion: 将人类研究的改进纳入人工智能研究循环，可以更快、更安全地实现超级智能。

Abstract: Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.

</details>


### [79] [ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications](https://arxiv.org/abs/2512.05371)
*Changwen Xing,SamZaak Wong,Xinlai Wan,Yanfeng Lu,Mengli Zhang,Zebin Ma,Lei Qi,Zhengxiong Li,Nan Guan,Zhe Jiang,Xi Wang,Jun Yang*

Main category: cs.AI

TL;DR: ChipMind是一个新型的知识图增强推理框架，专门为处理冗长的集成电路（IC）规范而设计，通过将电路规范转化为领域特定知识图谱ChipKG，并利用ChipKG增强推理机制进行信息论自适应检索和意图感知语义过滤，有效解决了现有LLM在IC开发中受限于上下文窗口的问题，并在工业级基准测试中显著优于现有技术水平。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLMs）在自动化集成电路（IC）开发方面潜力巨大，但其实际部署受限于上下文窗口的限制。现有上下文扩展方法难以在广泛、复杂的电路规范上实现有效的语义建模和彻底的多跳推理。

Method: ChipMind首先通过电路语义感知知识图谱构建方法，将电路规范转换为领域特定的知识图谱ChipKG。然后，它利用ChipKG增强推理机制，结合信息论自适应检索来动态追踪逻辑依赖，并通过意图感知语义过滤来修剪不相关的噪音，从而有效平衡检索的完整性和精确性。

Result: 在工业规模的规范推理基准测试中，ChipMind显著优于最先进的基线方法，平均性能提升34.59%（最高可达72.73%）。

Conclusion: ChipMind框架弥合了学术研究与LLM辅助硬件设计（LAD）实际工业部署之间的关键差距。

Abstract: While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).

</details>


### [80] [BEAVER: An Efficient Deterministic LLM Verifier](https://arxiv.org/abs/2512.05439)
*Tarun Suresh,Nalin Wadhwa,Debangshu Banerjee,Gagandeep Singh*

Main category: cs.AI

TL;DR: BEAVER是一个用于验证大型语言模型（LLMs）输出是否满足约束的框架。它使用新颖的Trie树和前沿数据结构来系统地探索生成空间，并在每次迭代中保持可靠的边界。


<details>
  <summary>Details</summary>
Motivation: 在LLMs从研究原型过渡到生产系统的过程中，从业者需要可靠的方法来验证模型输出是否满足所需的约束。现有的基于采样的估计方法无法提供可靠的保证。

Method: BEAVER使用Token Trie和前沿数据结构系统地探索生成空间，并在每次迭代中保持可靠的边界。

Result: BEAVER在相同的计算预算下，与基线方法相比，实现了6到8倍更紧密的概率边界，并识别出3到4倍更多的高风险实例。

Conclusion: BEAVER能够提供精确的特性描述和风险评估，这是宽松边界或经验评估无法提供的。

Abstract: As large language models (LLMs) transition from research prototypes to production systems, practitioners often need reliable methods to verify that model outputs satisfy required constraints. While sampling-based estimates provide an intuition of model behavior, they offer no sound guarantees. We present BEAVER, the first practical framework for computing deterministic, sound probability bounds on LLM constraint satisfaction. Given any prefix-closed semantic constraint, BEAVER systematically explores the generation space using novel token trie and frontier data structures, maintaining provably sound bounds at every iteration. We formalize the verification problem, prove soundness of our approach, and evaluate BEAVER on correctness verification, privacy verification and secure code generation tasks across multiple state of the art LLMs. BEAVER achieves 6 to 8 times tighter probability bounds and identifies 3 to 4 times more high risk instances compared to baseline methods under identical computational budgets, enabling precise characterization and risk assessment that loose bounds or empirical evaluation cannot provide.

</details>


### [81] [The Seeds of Scheming: Weakness of Will in the Building Blocks of Agentic Systems](https://arxiv.org/abs/2512.05449)
*Robert Yang*

Main category: cs.AI

TL;DR: 这篇论文探讨了大型语言模型中“知行不一”的现象，并将其命名为“Akrasia”（意志薄弱）。提出了一种初步的Akrasia基准测试，用于衡量模型在不同提示条件下其局部响应与自身先前承诺的矛盾程度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型表现出一种特殊的不一致性，即它们“知道”正确的答案却未能付诸行动。作者引入了“Akrasia”概念来分析智能体AI系统中的不一致性及目标漂移。

Method: 提出了一种初步的 Akrasia 基准测试，该测试包含结构化提示条件（基线[B]、同义词[S]、时间[T]和诱惑[X]），用于衡量模型在局部响应中何时与其先前的承诺相矛盾。

Result: 通过该基准测试，可以量化比较不同模型家族、解码策略和诱惑类型之间的“自控”能力。研究还指出，微观层面的Akrasia可能会在多智能体系统中演变为宏观层面的不稳定，这种不稳定可能被解读为“诡计”或故意的未对齐。

Conclusion: 将不一致性重新定义为意志薄弱，该研究将智能体行为与古典的智能体理论联系起来，并为哲学、心理学和新兴的智能体AI科学之间搭建了实证的桥梁。

Abstract: Large language models display a peculiar form of inconsistency: they "know" the correct answer but fail to act on it. In human philosophy, this tension between global judgment and local impulse is called akrasia, or weakness of will. We propose akrasia as a foundational concept for analyzing inconsistency and goal drift in agentic AI systems. To operationalize it, we introduce a preliminary version of the Akrasia Benchmark, currently a structured set of prompting conditions (Baseline [B], Synonym [S], Temporal [T], and Temptation [X]) that measures when a model's local response contradicts its own prior commitments. The benchmark enables quantitative comparison of "self-control" across model families, decoding strategies, and temptation types. Beyond single-model evaluation, we outline how micro-level akrasia may compound into macro-level instability in multi-agent systems that may be interpreted as "scheming" or deliberate misalignment. By reframing inconsistency as weakness of will, this work connects agentic behavior to classical theories of agency and provides an empirical bridge between philosophy, psychology, and the emerging science of agentic AI.

</details>


### [82] [MIND: Multi-rationale INtegrated Discriminative Reasoning Framework for Multi-modal Large Models](https://arxiv.org/abs/2512.05530)
*Chuang Yu,Jinmiao Zhao,Mingxuan Zhao,Yunpeng Liu,Xiujun Shu,Yuanhao Feng,Bo Wang,Xiangyu Yue*

Main category: cs.AI

TL;DR: 本文提出了一个名为MIND的多模态大语言模型推理框架，旨在改进现有MLLM在复杂推理中遇到的问题。该模型通过模仿人类“理解-反思-纠正”的认知模式，实现了从被动模仿到主动判别推理的范式转变。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型（MLLMs）在推理任务中存在多理性语义建模有限、逻辑鲁棒性不足以及易受误导性解释影响的问题。

Method: 1. 提出了“Rethink -> Correct”的认知能力，将MIND定义为多理性集成判别推理框架。
2. 引入了理由增强与判别（RAD）范式，通过生成多样化的理由来扩展现有数据集。
3. 设计了渐进式两阶段校正学习（P2CL）策略，第一阶段增强多理性积极学习，第二阶段实现主动逻辑判别和校正。
4. 提出了多理性对比对齐（MCA）优化策略，以减轻多理性语义空间中的表征纠缠，实现正确推理的语义聚合和不正确推理的边界分离。

Result: MIND推理框架在科学、常识和数学等多个公共数据集上实现了最先进的（SOTA）性能。

Conclusion: MIND框架为提升MLLMs的认知智能水平提供了新的视角。

Abstract: Recently, multimodal large language models (MLLMs) have been widely applied to reasoning tasks. However, they suffer from limited multi-rationale semantic modeling, insufficient logical robustness, and are susceptible to misleading interpretations in complex scenarios. Therefore, we propose a Multi-rationale INtegrated Discriminative (MIND) reasoning framework, which is designed to endow MLLMs with human-like cognitive abilities of "Understand -> Rethink -> Correct", and achieves a paradigm evolution from passive imitation-based reasoning to active discriminative reasoning. Specifically, we introduce a Rationale Augmentation and Discrimination (RAD) paradigm, which automatically and efficiently expands existing datasets by generating diverse rationales, providing a unified and extensible data foundation. Meanwhile, we design a Progressive Two-stage Correction Learning (P2CL) strategy. The first phase enhances multi-rationale positive learning, while the second phase enables active logic discrimination and correction. In addition, to mitigate representation entanglement in the multi-rationale semantic space, we propose a Multi-rationale Contrastive Alignment (MCA) optimization strategy, which achieves semantic aggregation of correct reasoning and boundary separation of incorrect reasoning. Extensive experiments demonstrate that the proposed MIND reasoning framework achieves state-of-the-art (SOTA) performance on multiple public datasets covering scientific, commonsense, and mathematical scenarios. It provides a new perspective for advancing MLLMs towards higher levels of cognitive intelligence. Our code is available at https://github.com/YuChuang1205/MIND

</details>


### [83] [CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning](https://arxiv.org/abs/2512.05576)
*Ting-Ting Xie,Yixin Zhang*

Main category: cs.AI

TL;DR: 本文提出了Executor-Analyst框架，通过解耦和分层集成来解决小型LLM在临床推理中存在的上下文利用失败问题，并在CURE-Bench上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 目前用于临床诊断的小型LLM（如TxAgent）存在“上下文利用失败”问题，即模型虽能检索到生物医学证据，但无法将诊断结果与这些信息结合。

Method: 我们提出了Executor-Analyst框架，这是一种模块化架构，将工具执行的句法精确性与临床推理的语义鲁棒性解耦。通过协调专门的TxAgents（执行器）与长上下文基础模型（分析器），我们缓解了单一模型中观察到的推理缺陷。我们还提出了一种分层集成策略，通过保留证据多样性，显著优于全局池化，有效解决了信息瓶颈问题。

Result: 我们的压力测试揭示了关键的扩展性见解：1. “上下文-性能悖论”：将推理上下文扩展到超过12k tokens会引入噪声，从而降低准确性。2. 动作空间中的“维度诅咒”：扩展工具集需要分层检索策略。重要的是，我们的方法强调了免训练架构工程的潜力，在无需昂贵的端到端微调的情况下，在CURE-Bench上取得了最先进的性能。

Conclusion: Executor-Analyst框架为新一代值得信赖的AI驱动疗法提供了一个可扩展、敏捷的基础。

Abstract: Current clinical agent built on small LLMs, such as TxAgent suffer from a \textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.

</details>


### [84] [Ontology Learning with LLMs: A Benchmark Study on Axiom Identification](https://arxiv.org/abs/2512.05594)
*Roos M. Bakker,Daan L. Di Scala,Maaike H. T. de Boer,Stephan A. Raaijmakers*

Main category: cs.AI

TL;DR: 本体学习，旨在自动化本体的开发过程，在过去十年中随着自然语言处理技术的进步而取得了进展，尤其是最近大型语言模型（LLM）的兴起。本文研究了识别公理的挑战：定义类和属性之间逻辑关系的基本本体组件。我们引入了一个本体公理基准测试OntoAxiom，并系统地测试了LLM在该基准测试上识别公理的能力，评估了不同的提示策略、本体和公理类型。


<details>
  <summary>Details</summary>
Motivation: 本体是构建领域知识的重要工具，但其开发复杂，需要大量的建模和领域专业知识。本体学习旨在自动化这一过程，但目前在公理识别方面仍面临挑战。

Method: 本文引入了一个名为OntoAxiom的本体公理基准测试，包含九个中等规模的本体，共17118个三元组和2771个公理，重点关注子类、不相交、子属性、域和范围公理。研究比较了十二种LLM在三种少样本设置和两种提示策略（直接方法和逐公理方法）下的性能。

Result: 研究发现，逐公理（AbA）提示策略比直接方法能带来更高的F1分数。然而，性能因公理类型和领域而异。大型LLM的表现优于小型LLM，但小型模型在资源受限的情况下仍有其价值。尽管LLM目前的整体性能不足以完全自动化公理识别，但它们能够提供有价值的候选公理，以支持本体工程师进行本体开发和完善。

Conclusion: LLM在本体公理识别方面展现出潜力，尤其是在正确的提示策略下。然而，仍需要进一步的研究和改进，以提高其在不同公理类型和领域上的性能，最终实现更完善的自动化本体构建。

Abstract: Ontologies are an important tool for structuring domain knowledge, but their development is a complex task that requires significant modelling and domain expertise. Ontology learning, aimed at automating this process, has seen advancements in the past decade with the improvement of Natural Language Processing techniques, and especially with the recent growth of Large Language Models (LLMs). This paper investigates the challenge of identifying axioms: fundamental ontology components that define logical relations between classes and properties. In this work, we introduce an Ontology Axiom Benchmark OntoAxiom, and systematically test LLMs on that benchmark for axiom identification, evaluating different prompting strategies, ontologies, and axiom types. The benchmark consists of nine medium-sized ontologies with together 17.118 triples, and 2.771 axioms. We focus on subclass, disjoint, subproperty, domain, and range axioms. To evaluate LLM performance, we compare twelve LLMs with three shot settings and two prompting strategies: a Direct approach where we query all axioms at once, versus an Axiom-by-Axiom (AbA) approach, where each prompt queries for one axiom only. Our findings show that the AbA prompting leads to higher F1 scores than the direct approach. However, performance varies across axioms, suggesting that certain axioms are more challenging to identify. The domain also influences performance: the FOAF ontology achieves a score of 0.642 for the subclass axiom, while the music ontology reaches only 0.218. Larger LLMs outperform smaller ones, but smaller models may still be viable for resource-constrained settings. Although performance overall is not high enough to fully automate axiom identification, LLMs can provide valuable candidate axioms to support ontology engineers with the development and refinement of ontologies.

</details>


### [85] [Enhancing Local Search for MaxSAT with Deep Differentiation Clause Weighting](https://arxiv.org/abs/2512.05619)
*Menghua Jiang,Haokai Gao,Shuhao Chen,Yin Chen*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种新的随机局部搜索算法DeepDist，用于解决部分最大可满足性（PMS）和加权部分最大可满足性（WPMS）问题。


<details>
  <summary>Details</summary>
Motivation: 现有的（W）PMS随机局部搜索算法在子句加权方案上存在局限性，未能充分区分PMS和WPMS，并忽视了两种问题类型之间的关键结构差异。

Method: 本文提出了一种新的子句加权方案，该方案首次根据不同的条件更新PMS和WPMS实例的子句权重，并引入了一种新的初始化方法，以更好地适应两种实例类型的独特特性。此外，还提出了一种优先满足单一子句和硬子句的抽取方法，有效地补充了所提出的子句加权方案。

Result: 在近期MaxSAT评估的随时可用赛道基准测试中，DeepDist的表现优于最先进的SLS求解器。与TT-Open-WBO-Inc结合的混合求解器超越了MaxSAT评估2024年获奖者的性能。

Conclusion: 本研究通过引入区分PMS和WPMS的子句加权方案，以及新的初始化和抽取方法，显著提升了P-MaxSAT和WPMS问题的求解性能。

Abstract: Partial Maximum Satisfiability (PMS) and Weighted Partial Maximum Satisfiability (WPMS) generalize Maximum Satisfiability (MaxSAT), with broad real-world applications. Recent advances in Stochastic Local Search (SLS) algorithms for solving (W)PMS have mainly focused on designing clause weighting schemes. However, existing methods often fail to adequately distinguish between PMS and WPMS, typically employing uniform update strategies for clause weights and overlooking critical structural differences between the two problem types. In this work, we present a novel clause weighting scheme that, for the first time, updates the clause weights of PMS and WPMS instances according to distinct conditions. This scheme also introduces a new initialization method, which better accommodates the unique characteristics of both instance types. Furthermore, we propose a decimation method that prioritizes satisfying unit and hard clauses, effectively complementing our proposed clause weighting scheme. Building on these methods, we develop a new SLS solver for (W)PMS named DeepDist. Experimental results on benchmarks from the anytime tracks of recent MaxSAT Evaluations show that DeepDist outperforms state-of-the-art SLS solvers. Notably, a hybrid solver combining DeepDist with TT-Open-WBO-Inc surpasses the performance of the MaxSAT Evaluation 2024 winners, SPB-MaxSAT-c-Band and SPB-MaxSAT-c-FPS, highlighting the effectiveness of our approach. The code is available at https://github.com/jmhmaxsat/DeepDist

</details>


### [86] [Evolutionary System 2 Reasoning: An Empirical Proof](https://arxiv.org/abs/2512.05760)
*Zeyuan Ma,Wenqi Huang,Guo-Huan Song,Hongshu Guo,Sijie Ma,Zhiguang Cao,Yue-Jiao Gong*

Main category: cs.AI

TL;DR: 本文探讨了机器学习中的一个重要问题：机器智能能否通过进化获得与人类相似的推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在特定任务上取得了显著进展，但在通用智能、特别是系统2推理能力方面仍有不足。本文旨在探究LLMs是否能通过进化获得类人的推理能力。

Method: 提出了一种名为“演化推理优化（ERO）”的框架。ERO通过对LLMs群体进行“适者生存”的演化过程，以寻找具有强大推理能力的个体。具体而言，ERO首先初始化多个LLMs，然后运用演化策略来最大化最佳个体的量化推理分数。

Result: 通过在代表性测试集上的实验，发现两个令人惊讶的现象：1）最新的LLMs（如GPT-5）在系统2推理能力上仍然有限；2）通过ERO的简单演化循环，一个相对较弱的模型（Qwen-7B）能够被增强并展现出强大的推理能力。

Conclusion: LLMs的系统2推理能力仍有待提高，但通过演化优化框架，即使是相对较弱的模型也能获得强大的推理能力，为提升机器智能的通用推理能力提供了新的方向。

Abstract: Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.

</details>


### [87] [The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics](https://arxiv.org/abs/2512.05765)
*Edward Y. Chang*

Main category: cs.AI

TL;DR: 批评性观点认为大语言模型（LLMs）是通往通用人工智能（AGI）的死胡同，因为它们被视为“单纯的模式匹配器”，在结构上不具备推理或规划能力。本文认为，这一结论错误地识别了瓶颈，混淆了海洋与渔网。模式存储库是必要的 System-1 基底，而缺失的组件是 System-2 协调层，它负责选择、约束和绑定这些模式。我们通过 UCCT 理论形式化了这一层，该理论是一种语义锚定理论，将推理建模为由有效支持（rho_d）、表征不匹配（d_r）和自适应锚定预算（gamma log k）控制的相变。


<details>
  <summary>Details</summary>
Motivation: 批评者认为LLMs是AGI的死胡同，因为它是一个“模式匹配器”，这造成了误解。

Method: 通过UCCT理论进行语义锚定、MACI协调堆栈实现，包括诱导（由行为调节的辩论）、过滤（苏格拉底式判断）和持久性（事务记忆）来解决问题。

Result: 大语言模型（LLMs）是通往通用人工智能（AGI）的必经之路，而不是绕开。

Conclusion: 通过将常见的反对意见重新定义为可测试的协调失败，我们认为通往通用人工智能的道路是通过大语言模型，而不是绕开它们。

Abstract: Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: "mere pattern matchers" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while "reasoning" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.

</details>


### [88] [Multimodal Oncology Agent for IDH1 Mutation Prediction in Low-Grade Glioma](https://arxiv.org/abs/2512.05824)
*Hafsa Akebli,Adam Shephard,Vincenzo Della Mea,Nasir Rajpoot*

Main category: cs.AI

TL;DR: 该研究介绍了一种新型多模态肿瘤智能体（MOA），它结合了基于TITAN基础模型的组织学工具和对结构化临床与基因组输入的推理能力，用于预测低级别胶质瘤中的IDH1突变。


<details>
  <summary>Details</summary>
Motivation: 低级别胶质瘤中IDH1突变的存在对临床预后和治疗具有重要意义，因此准确预测IDH1突变对于患者管理至关重要。

Method: MOA通过整合基于TITAN基础模型的组织学工具和从PubMed、Google Search、OncoKB获取的结构化临床与基因组数据进行推理。研究在TCGA-LGG队列的488名患者中评估了MOA的性能。

Result: 不含组织学工具的MOA表现优于临床基线，F1-score从0.798提高到0.826。当与组织学特征融合时，MOA达到了最高的性能，F1-score为0.912，优于独立组织学基线（0.894）和融合组织学-临床基线（0.897）。

Conclusion: MOA能够有效地整合多源信息，包括组织学和临床基因组数据，从而实现对IDH1突变的高度准确预测，这表明该智能体能够从外部生物医学资源中捕获互补的突变相关信息。

Abstract: Low-grade gliomas frequently present IDH1 mutations that define clinically distinct subgroups with specific prognostic and therapeutic implications. This work introduces a Multimodal Oncology Agent (MOA) integrating a histology tool based on the TITAN foundation model for IDH1 mutation prediction in low-grade glioma, combined with reasoning over structured clinical and genomic inputs through PubMed, Google Search, and OncoKB. MOA reports were quantitatively evaluated on 488 patients from the TCGA-LGG cohort against clinical and histology baselines. MOA without the histology tool outperformed the clinical baseline, achieving an F1-score of 0.826 compared to 0.798. When fused with histology features, MOA reached the highest performance with an F1-score of 0.912, exceeding both the histology baseline at 0.894 and the fused histology-clinical baseline at 0.897. These results demonstrate that the proposed agent captures complementary mutation-relevant information enriched through external biomedical sources, enabling accurate IDH1 mutation prediction.

</details>


### [89] [To Err Is Human: Systematic Quantification of Errors in Published AI Papers via LLM Analysis](https://arxiv.org/abs/2512.05925)
*Federico Bianchi,Yongchan Kwon,Zachary Izzo,Linjun Zhang,James Zou*

Main category: cs.AI

TL;DR: 本文分析了已发表AI论文中客观错误的数量，并发现其数量呈上升趋势，同时展示了基于GPT-5的论文正确性检查工具能有效识别并修正这些错误。


<details>
  <summary>Details</summary>
Motivation: 已发表论文中的错误会阻碍后续研究，影响可重复性，且在快速发展的研究环境下，错误更难被发现和避免，因此有必要系统性地识别论文中的错误。

Method: 开发了一个基于GPT-5的论文正确性检查器（Paper Correctness Checker），用于识别顶级AI会议和期刊中已发表论文的客观错误（如公式、推导、计算、图表错误）。通过人类专家审查AI识别出的错误，验证其准确性。

Result: 已发表论文中存在不可忽视的客观错误数量，且平均错误数量随时间增加：NeurIPS从2021年的3.8个增至2025年的5.9个；ICLR从2018年的4.1个增至2025年的5.2个；TMLR从2022/23年的5.0个增至2025年的5.5个。AI检查器识别出的错误中，83.2%被人类专家确认为实际错误。AI检查器还能对75.8%的错误提出修正建议。

Conclusion: 本研究表明，前沿大型语言模型（LLMs）有潜力检测并纠正已发表论文中的客观错误，有助于为知识奠定更坚实的基础，减少文献中的混淆，并增强研究的可重复性。

Abstract: How many mistakes do published AI papers contain? Peer-reviewed publications form the foundation upon which new research and knowledge are built. Errors that persist in the literature can propagate unnoticed, creating confusion in follow-up studies and complicating reproducibility. The accelerating pace of research and the increasing demands on the peer-review system make such mistakes harder to detect and avoid. To address this, we developed a Paper Correctness Checker based on GPT-5 to systematically identify mistakes in papers previously published at top AI conferences and journals. Our analysis focuses on objective mistakes-e.g., errors in formulas, derivations, calculations, figures, and tables-that have a clearly verifiable ground truth. We intentionally exclude subjective considerations such as novelty, importance, or writing quality. We find that published papers contain a non-negligible number of objective mistakes and that the average number of mistakes per paper has increased over time-from 3.8 in NeurIPS 2021 to 5.9 in NeurIPS 2025 (55.3% increase); from 4.1 in ICLR 2018 to 5.2 in ICLR 2025; and from 5.0 in TMLR 2022/23 to 5.5 in TMLR 2025. Human experts reviewed 316 potential mistakes identified by the AI Checker and confirmed that 263 were actual mistakes, corresponding to a precision of 83.2%. While most identified issues are relatively minor, correcting them would reduce confusion in the literature and strengthen reproducibility. The AI Checker also surfaced potentially more substantive mistakes that could affect the interpretation of results. Moreover, we show that the AI Checker can propose correct fixes for 75.8% of the identified mistakes. Overall, this study highlights the potential of frontier LLMs to detect and correct objective mistakes in published papers, helping to establish a firmer foundation of knowledge.

</details>


### [90] [TRACE: A Framework for Analyzing and Enhancing Stepwise Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.05943)
*Shima Imani,Seungwhan Moon,Lambert Mathias,Lu Zhang,Babak Damavandi*

Main category: cs.AI

TL;DR: TRACE是一个评估大型视觉语言模型数学和科学推理的框架。它通过分解复杂问题、评估中间步骤和暴露传统评估忽略的错误来诊断推理轨迹。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在数学和科学推理方面存在挑战，传统评估方法常常掩盖推理错误。

Method: TRACE框架利用“辅助推理集”（Auxiliary Reasoning Sets, ARS），将复杂问题分解为紧凑的子问题-答案对，并通过基于一致性的度量评估中间步骤。

Result: 实验表明，ARS的一致性与最终答案的正确性相关，并能帮助查明推理失败的步骤，为模型改进提供可操作的信号。

Conclusion: TRACE框架通过诊断推理轨迹，而非仅仅最终结果，有效识别和改进大型视觉语言模型在数学和科学推理中的不足，并能区分可靠和不可靠的推理路径。

Abstract: Reliable mathematical and scientific reasoning remains an open challenge for large vision-language models. Standard final-answer evaluation often masks reasoning errors, allowing silent failures to persist. To address this gap, we introduce TRACE, a framework for Transparent Reasoning And Consistency Evaluation that diagnoses reasoning trajectories rather than only end results. At its core, TRACE leverages Auxiliary Reasoning Sets, compact sub question answer pairs that decompose complex problems, evaluate intermediate steps through consistency-based metrics, and expose failures overlooked by standard evaluation. Our experiments show that consistency across ARS correlates with final-answer correctness and helps pinpoint the reasoning steps where failures arise, offering actionable signals for model improvement. Furthermore, TRACE defines confidence regions that distinguish reliable from unreliable reasoning paths, supporting effective filtering, debugging, and model refinement.

</details>


### [91] [Variational Quantum Rainbow Deep Q-Network for Optimizing Resource Allocation Problem](https://arxiv.org/abs/2512.05946)
*Truong Thanh Hung Nguyen,Truong Thinh Nguyen,Hung Cao*

Main category: cs.AI

TL;DR: 该论文提出了VQR-DQN，一种结合变分量子电路和Rainbow DQN的深度强化学习方法，旨在解决资源分配问题中的NP-hard挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的DRL方法在处理资源分配问题时，由于组合复杂性，其函数逼近器的表示能力有限，导致可伸缩性不足。

Method: 本文提出了变分量子Rainbow DQN (VQR-DQN)，它将环形拓扑变分量子电路与Rainbow DQN相结合，利用量子叠加和纠缠的特性。通过将人力资源分配问题建模为马尔可夫决策过程，并考虑军官能力、事件时间表和转换时间等因素。

Result: 在四个人力资源分配问题基准测试中，VQR-DQN 使归一化完工时间减少了26.8%，优于随机基线，并且比 Double DQN 和经典 Rainbow DQN 高出4.9-13.4%。

Conclusion: VQR-DQN通过量子增强的深度强化学习方法，在处理大规模资源分配问题上展现出巨大潜力，其性能提升与电路表达能力、纠缠和策略质量之间的理论联系一致。

Abstract: Resource allocation remains NP-hard due to combinatorial complexity. While deep reinforcement learning (DRL) methods, such as the Rainbow Deep Q-Network (DQN), improve scalability through prioritized replay and distributional heads, classical function approximators limit their representational power. We introduce Variational Quantum Rainbow DQN (VQR-DQN), which integrates ring-topology variational quantum circuits with Rainbow DQN to leverage quantum superposition and entanglement. We frame the human resource allocation problem (HRAP) as a Markov decision process (MDP) with combinatorial action spaces based on officer capabilities, event schedules, and transition times. On four HRAP benchmarks, VQR-DQN achieves 26.8% normalized makespan reduction versus random baselines and outperforms Double DQN and classical Rainbow DQN by 4.9-13.4%. These gains align with theoretical connections between circuit expressibility, entanglement, and policy quality, demonstrating the potential of quantum-enhanced DRL for large-scale resource allocation. Our implementation is available at: https://github.com/Analytics-Everywhere-Lab/qtrl/.

</details>


### [92] [SymPyBench: A Dynamic Benchmark for Scientific Reasoning with Executable Python Code](https://arxiv.org/abs/2512.05954)
*Shima Imani,Seungwhan Moon,Adel Ahmadyan,Lu Zhang,Kirmani Ahmed,Babak Damavandi*

Main category: cs.AI

TL;DR: SymPyBench 是一个包含 15,045 个大学物理问题的基准，每个问题都经过参数化，并附带详细的解题步骤和可执行的 Python 代码，用于评估语言模型的科学推理能力。


<details>
  <summary>Details</summary>
Motivation: 开发一个大规模的物理问题基准，以评估和改进当前语言模型在科学推理方面的能力。

Method: SymPyBench 包含 15,045 个参数化的大学物理问题，每个问题都提供结构化的分步推理和生成真值解的 Python 代码。它支持三种问题类型：符号多选、数值多选和自由格式。

Result: 通过使用 SymPyBench，研究人员引入了除了标准准确性之外的三个新评估指标：一致性得分、失败率和混淆率。对最先进的指令调整语言模型的实验揭示了科学推理的优点和局限性。

Conclusion: SymPyBench 为开发更强大和可解释的推理系统奠定了基础，并为评估语言模型在科学推理方面的能力提供了全面的工具。

Abstract: We introduce, a large-scale synthetic benchmark of 15,045 university-level physics problems (90/10% train/test split). Each problem is fully parameterized, supporting an effectively infinite range of input configurations, and is accompanied by structured, step-by-step reasoning and executable Python code that produces the ground-truth solution for any parameter set. The benchmark contains three question types: MC-Symbolic (multiple-choice with symbolic options), MC-Numerical (multiple-choice with numerical options), and free-form (open-ended responses). These diverse formats test complementary reasoning skills. By leveraging the dynamic, code-driven nature of the benchmark, we introduce three novel evaluation metrics in addition to standard accuracy: Consistency Score, Failure Rate, and Confusion Rate, that quantify variability and uncertainty across problem variants. Experiments with state-of-the-art instruction-tuned language models reveal both strengths and limitations in scientific reasoning, positioning SymPyBench as a foundation for developing more robust and interpretable reasoning systems

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [93] [Strategyproof Tournament Rules for Teams with a Constant Degree of Selfishness](https://arxiv.org/abs/2512.05235)
*David Pennock,Daniel Schoepflin,Kangning Wang*

Main category: cs.GT

TL;DR: 本文提出了一种新的锦标赛规则，在中间自私程度λ=11的情况下可以抵抗策略操纵，并引入了一种新的乘法对非操纵性概念。


<details>
  <summary>Details</summary>
Motivation: 在锦标赛规则设计中，寻找满足单调性、孔多塞一致性且能抵抗策略性行为（即队伍不会通过故意输掉比赛来获益）的机制是一个长期存在的问题。以往的研究要么假设队伍完全自私，要么假设队伍完全无私，或者考虑了介于两者之间的中间自私程度λ。在λ参数设置下，现有规则需要λ=Ω(n)才能抵抗策略操纵，而寻找具有最小λ值的策略抗操纵规则一直是一个开放问题。

Method: 本文设计了一种新的锦标赛规则。通过该规则，作者解决了在中间自私程度λ下策略抗操纵的问题。此外，文章还引入了一种新的乘法对非操纵性概念，该概念确保两支队伍不能通过操纵比赛结果来将其获胜概率之和增加超过一个乘法因子δ。

Result: 本文提出的锦标赛规则在λ=11时是策略抗操纵的。这是一个显著的进步，因为之前所有已知的锦标赛规则都需要λ=Ω(n)才能实现策略抗操纵。同时，该规则在乘法对非操纵性方面，可以达到δ=3.5。

Conclusion: 本文成功设计了一种在λ值显著降低（从Ω(n)降至11）的情况下仍能抵抗策略操纵的锦标赛规则，并提出了一个新的乘法对非操纵性概念，为锦标赛规则设计领域做出了重要贡献。

Abstract: We revisit the well-studied problem of designing fair and manipulation-resistant tournament rules. In this problem, we seek a mechanism that (probabilistically) identifies the winner of a tournament after observing round-robin play among $n$ teams in a league. Such a mechanism should satisfy the natural properties of monotonicity and Condorcet consistency. Moreover, from the league's perspective, the winner-determination tournament rule should be strategyproof, meaning that no team can do better by losing a game on purpose.
  Past work considered settings in which each team is fully selfish, caring only about its own probability of winning, and settings in which each team is fully selfless, caring only about the total winning probability of itself and the team to which it deliberately loses. More recently, researchers considered a mixture of these two settings with a parameter $λ$. Intermediate selfishness $λ$ means that a team will not lose on purpose unless its pair gains at least $λs$ winning probability, where $s$ is the individual team's sacrifice from its own winning probability. All of the dozens of previously known tournament rules require $λ= Ω(n)$ to be strategyproof, and it has been an open problem to find such a rule with the smallest $λ$.
  In this work, we make significant progress by designing a tournament rule that is strategyproof with $λ= 11$. Along the way, we propose a new notion of multiplicative pairwise non-manipulability that ensures that two teams cannot manipulate the outcome of a game to increase the sum of their winning probabilities by more than a multiplicative factor $δ$ and provide a rule which is multiplicatively pairwise non-manipulable for $δ= 3.5$.

</details>


### [94] [Correlation of Rankings in Matching Markets](https://arxiv.org/abs/2512.05304)
*Rémi Castera,Patrick Loiseau,Bary S. R. Pradelski*

Main category: cs.GT

TL;DR: 这篇论文研究了在匹配市场中，不同决策者同时从同一候选人池中选择时，候选人优先级分数相关性的作用。


<details>
  <summary>Details</summary>
Motivation: 探索不同社会人口群体之间优先级分数相关性差异如何影响匹配市场的结果。

Method: 提出了一个模型，其中候选人在不同决策者中的优先级分数表现出不同程度的相关性，这种相关性依赖于候选人的社会人口群体。

Result: 研究表明，一个群体较高的相关性通常会改善所有群体的结果，提高效率。然而，特定群体的学生随着自身相关性水平的增加，未匹配的可能性也越大。这意味着属于低相关性群体是有利的。

Conclusion: 差分相关性是学校、大学和就业录取中群体不平等的一个先前被忽视的系统性来源。

Abstract: We study the role of correlation in matching markets, where multiple decision-makers simultaneously face selection problems from the same pool of candidates. We propose a model in which a candidate's priority scores across different decision-makers exhibit varying levels of correlation dependent on the candidate's sociodemographic group. Such differential correlation can arise in school choice due to the varying prevalence of selection criteria, in college admissions due to test-optional policies, or due to algorithmic monoculture, that is, when decision-makers rely on the same algorithms and data sets to evaluate candidates. We show that higher correlation for one of the groups generally improves the outcome for all groups, leading to higher efficiency. However, students from a given group are more likely to remain unmatched as their own correlation level increases. This implies that it is advantageous to belong to a low-correlation group. Finally, we extend the tie-breaking literature to multiple priority classes and intermediate levels of correlation. Overall, our results point to differential correlation as a previously overlooked systemic source of group inequalities in school, university, and job admissions.

</details>


### [95] [On Dynamic Programming Theory for Leader-Follower Stochastic Games](https://arxiv.org/abs/2512.05667)
*Jilles Steeve Dibangoye,Thibaut Le Marre,Ocan Sankur,François Schwarzentruber*

Main category: cs.GT

TL;DR: 本文提出了一种新的动态规划（DP）框架，用于计算领导者-追随者一般和随机博弈（LF-GSSG）中的强Stackelberg均衡（SSE）。该框架通过在可信集上应用Bellman递归，将LF-GSSG无损地归约到Markov决策过程（MDP）。


<details>
  <summary>Details</summary>
Motivation: 之前的研究中，尽管存在一些方法来寻找领导者-追随者一般和随机博弈中的Stackelberg均衡，但对于如何有效地处理领导者承诺下的追随者最佳响应以及如何在保证领导者收益的同时避免追随者可利用性方面仍存在挑战。本文旨在通过引入可信集和动态规划框架来解决这些问题。

Method: 本文引入了一个动态规划（DP）框架，该框架在可信集上应用Bellman递归来计算SSE。可信集是形式化表示部分领导者承诺下所有理性追随者最佳响应的状态抽象。首先证明了任何LF-GSSG都可以无损地归约为基于可信集的Markov决策过程（MDP）。其次，鉴于合成最优无记忆确定性领导者策略是NP难的，本文开发了具有可证明领导者可利用性保证的ε-最优DP算法。

Result: 实验结果表明，在安全博弈、资源分配和对抗性规划等混合动机基准测试中，本文提出的方法在领导者价值和运行时可伸缩性方面均优于现有最先进的方法。

Conclusion: 本文成功地提出了一种基于动态规划和可信集的新框架，用于解决领导者-追随者一般和随机博弈中的强Stackelberg均衡问题。该框架不仅在理论上证明了其有效性，而且在实验中也展现出优越的性能，为解决此类决策问题提供了新的思路和有效的方法。

Abstract: Leader-follower general-sum stochastic games (LF-GSSGs) model sequential decision-making under asymmetric commitment, where a leader commits to a policy and a follower best responds, yielding a strong Stackelberg equilibrium (SSE) with leader-favourable tie-breaking. This paper introduces a dynamic programming (DP) framework that applies Bellman recursion over credible sets-state abstractions formally representing all rational follower best responses under partial leader commitments-to compute SSEs. We first prove that any LF-GSSG admits a lossless reduction to a Markov decision process (MDP) over credible sets. We further establish that synthesising an optimal memoryless deterministic leader policy is NP-hard, motivating the development of ε-optimal DP algorithms with provable guarantees on leader exploitability. Experiments on standard mixed-motive benchmarks-including security games, resource allocation, and adversarial planning-demonstrate empirical gains in leader value and runtime scalability over state-of-the-art methods.

</details>
