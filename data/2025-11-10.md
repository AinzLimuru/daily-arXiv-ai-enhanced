<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 36]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.IT](#cs.IT) [Total: 2]
- [stat.ML](#stat.ML) [Total: 3]
- [cs.LG](#cs.LG) [Total: 52]
- [cs.AI](#cs.AI) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

TL;DR: 深入研究了语言模型在重构程序序列方面的能力，特别是在餐饮菜谱领域的应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理程序序列时，步骤的先后顺序对结果有直接影响，因此对程序序列进行推理至关重要。

Method: 本研究使用一个精心策划的餐饮菜谱数据集，评估了多种大型语言模型在零样本和小样本设置下的表现，并提出了一个综合评估框架。该框架采用了排序和序列比对中的既定指标，包括Kendall’s Tau、归一化最长公共子序列（NLCS）和归一化编辑距离（NED）。

Result: 分析结果表明，模型的性能随序列长度的增加而下降，这反映了较长程序的复杂性。同时，输入中步骤位移的增大会导致性能的进一步下降。

Conclusion: 目前的大型语言模型在程序推理方面存在局限性，尤其是在处理较长和更无序的输入时。

Abstract: Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [2] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: ATLAS是一个使用项目反应理论（IRT）的自适应评估框架，通过费雪信息引导的项目选择，能通过显著减少项目数量来高效评估大型语言模型，同时保持测量精度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型评估需要大量的基准项目，导致评估成本高昂且耗时。现有方法对所有项目一视同仁，忽略了项目质量和信息量的差异，同时存在评估项目中的标注错误。

Method: ATLAS框架利用项目反应理论（IRT），通过费雪信息引导的项目选择来估计模型能力。该方法能够识别评价数据中的负区分度项目（即标注错误），并能够自适应地选择评估项目。

Result: ATLAS在保持测量精度的前提下，实现了90%的项目削减。例如，在HellaSwag基准测试中，仅使用42个项目就能达到与完整基准测试相似的评估结果（0.154 MAE）。此外，ATLAS将项目暴露率保持在10%以下，测试重叠率在16-27%之间。研究还发现，IRT排名与传统准确率排名存在差异，有23-31%的模型排名变化超过10位。

Conclusion: ATLAS框架通过引入自适应测试和IRT，显著提高了大型语言模型评估的效率和准确性，减少了评估成本和时间。它还能识别并纠正基准测试中的标注错误，使得评估结果更加可靠。

Abstract: Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [3] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

TL;DR: 这篇论文提出了一个名为SARC的框架，通过结合情感增强的深度聚类来识别用户角色，从而改善假新闻检测。


<details>
  <summary>Details</summary>
Motivation: 以往的研究通常将情感特征视为辅助信号，忽略了角色分化，即相同的情感极性可能来源于不同角色的用户，从而限制了现有方法捕捉细微模式以进行有效检测的能力。

Method: SARC框架首先通过联合评论文本表示（使用BiGRU和注意力机制）和情感编码生成用户特征，然后构建一个可微分的深度聚类模块来自动分类用户角色。最后，通过整合角色聚类和假新闻检测，提出了一个联合优化目标。

Result: 在RumourEval-19和Weibo-comp这两个基准数据集上的实验结果表明，SARC在所有指标上都优于基线模型。

Conclusion: SARC通过情感增强的角色聚类，有效地提升了假新闻检测的性能。

Abstract: Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [4] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLM）中指令层级（IH）的重要性，提出将指令层级解析视为推理任务，并通过训练实现了这一能力，从而提升了模型在指令遵循、指令层级基准测试以及安全关键场景下的表现，增强了模型抵抗越狱和提示注入攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在现实世界的决策中，基于大型语言模型的系统需要协调来自多方（例如，模型开发者、用户和工具）的竞争性指令。因此，在LLM中强制执行指令层级（IH），即更高级别的指令覆盖优先级较低的请求，对于LLM的可靠性和可控性至关重要。

Method: 1. 将指令层级解析重新定义为推理任务。具体来说，模型必须首先“思考”给定用户提示和更高优先级（系统）指令之间的关系，然后才能生成响应。
2. 构建VerIH数据集：为了通过训练实现这一能力，我们构建了一个名为VerIH的指令层级数据集，其中包含具有可验证答案的约束遵循任务。该数据集包含对齐和冲突的系统-用户指令。
3. 轻量级强化学习：利用VerIH数据集进行轻量级强化学习，将模型的通用推理能力有效地 F 迁移到指令优先级排序上。

Result: 1. 持续改进：我们微调后的模型在指令遵循和指令层级基准测试方面取得了持续的改进。
2. 泛化能力：这种推理能力也泛化到了超出训练分布的安全关键设置。
3. 增强鲁棒性：通过将安全问题视为解决对抗性用户输入与预定义高优先级策略之间的冲突，我们训练的模型增强了抵抗越狱（jailbreak）和提示注入（prompt injection）攻击的鲁棒性。

Conclusion: 对指令层级进行推理为实现可靠的LLM提供了一条实用途径，其中系统提示的更新可以带来模型行为的可控和稳健变化。

Abstract: As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [5] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

TL;DR: EncouRAGE是一个综合性的Python框架，用于开发和评估基于LLM和嵌入模型的RAG系统，它包含五个模块化组件。研究结果表明，RAG的性能仍低于Oracle Context，而Hybrid BM25在所有四个数据集中表现最佳，重排序对性能提升不明显但增加了延迟。


<details>
  <summary>Details</summary>
Motivation: 目前RAG系统的开发和评估过程缺乏统一和高效的框架，研究人员需要一个能够简化开发、提供灵活实验、保证科学可重复性并支持本地部署的工具。

Method: EncouRAGE框架由Type Manifest、RAG Factory、Inference、Vector Store和Metrics五个模块化组件组成，旨在促进RAG系统的灵活实验和可扩展开发。该框架强调科学可重复性、多样化的评估指标和本地部署。

Result: RAG系统在性能上仍不及Oracle Context。Hybrid BM25在所有四个基准数据集上均取得了最佳结果。重排序对性能的提升微乎其微，但却伴随着更高的响应延迟。

Conclusion: EncouRAGE框架为RAG系统的开发和评估提供了一个全面的解决方案，但当前的RAG系统在性能上仍有提升空间，尤其是在与Oracle Context相比时。Hybrid BM25在多个数据集上显示出强大的性能，而重排序的效用需要进一步权衡其带来的延迟。

Abstract: We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [6] [Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic Calibration in LLMs](https://arxiv.org/abs/2511.04869)
*Preetum Nakkiran,Arwen Bradley,Adam Goliński,Eugene Ndiaye,Michael Kirchhof,Sinead Williamson*

Main category: cs.CL

TL;DR: 尽管LLMs通常缺乏对其输出的有效置信度评估，但我们发现，基础LLMs在语义校准方面表现出色，能够有效评估开放域问答任务中的置信度。我们提出了“B校准”的理论机制，解释了语义校准作为下一个token预测的副产品而出现的原因。实验验证了我们的预测，即基础LLMs在问答任务中表现出语义校准，而RL指令调优和思维链推理会破坏这种校准。


<details>
  <summary>Details</summary>
Motivation: LLMs在评估其输出的可信度方面通常表现不佳，尽管基础LLMs在下一个token级别的校准上有所表现，但其在超越token层面的响应语义意义上的置信度评估能力仍不明确。

Method: 本文提出了一种“B校准”的理论机制，这是一种通过等价类选择（语义或其他）来参数化的校准概念。该理论利用了校准与局部损失最优性之间的最新联系，解释了语义校准作为下一个标记预测的副产品而出现的原因。研究通过实验验证了这一预测。

Result: 1. 基础LLMs在问答任务中表现出语义校准。2. RL指令调优系统地破坏了这种校准。3. 思维链推理也会破坏校准。

Conclusion: 本文首次从原理上解释了LLMs中语义校准出现的时间和原因。基础LLMs在没有明确训练的情况下也能很好地进行语义校准，而RL指令调优和思维链推理反而会损害这种能力。

Abstract: Large Language Models (LLMs) often lack meaningful confidence estimates for
their outputs. While base LLMs are known to exhibit next-token calibration, it
remains unclear whether they can assess confidence in the actual meaning of
their responses beyond the token level. We find that, when using a certain
sampling-based notion of semantic calibration, base LLMs are remarkably
well-calibrated: they can meaningfully assess confidence in open-domain
question-answering tasks, despite not being explicitly trained to do so. Our
main theoretical contribution establishes a mechanism for why semantic
calibration emerges as a byproduct of next-token prediction, leveraging a
recent connection between calibration and local loss optimality. The theory
relies on a general definition of "B-calibration," which is a notion of
calibration parameterized by a choice of equivalence classes (semantic or
otherwise). This theoretical mechanism leads to a testable prediction: base
LLMs will be semantically calibrated when they can easily predict their own
distribution over semantic answer classes before generating a response. We
state three implications of this prediction, which we validate through
experiments: (1) Base LLMs are semantically calibrated across
question-answering tasks, (2) RL instruction-tuning systematically breaks this
calibration, and (3) chain-of-thought reasoning breaks calibration. To our
knowledge, our work provides the first principled explanation of when and why
semantic calibration emerges in LLMs.

</details>


### [7] [Listening Between the Lines: Decoding Podcast Narratives with Language Modeling](https://arxiv.org/abs/2511.05310)
*Shreya Gupta,Ojasva Saxena,Arghodeep Nandi,Sarah Masud,Kiran Garimella,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的、经过微调的BERT模型，用于分析播客叙事框架，解决了现有大型语言模型在处理非结构化会话数据方面的不足，揭示了播客中话题与叙事框架之间的系统关系。


<details>
  <summary>Details</summary>
Motivation: 播客作为塑造公众舆论的中心，是理解当代话语的重要来源。然而，播客的非结构化、多主题和会话性质使得自动化分析变得复杂，现有的大型语言模型难以准确捕捉叙事框架，限制了对播客说服和 H 信息的分析。

Method: 开发并评估了一个微调的BERT模型，该模型将叙事框架与对话中提到的特定实体明确关联起来，从而将抽象框架具体化。该方法使用这些细粒度的框架标签，并将其与高级主题相关联，以揭示更广泛的话语趋势。

Result: 开发了一个新颖的框架标注方法，该方法与人类对凌乱、会话数据的判断更接近。揭示了正在讨论的内容（话题）与呈现方式（框架）之间的系统关系，为研究数字媒体中的影响力提供了一个更稳健的框架。

Conclusion: 本研究成功开发了一种新的框架标注方法和分析模型，有效地解决了播客内容分析的挑战，揭示了话题与叙事框架之间的深层联系，为数字媒体影响力研究提供了新的视角和工具。

Abstract: Podcasts have become a central arena for shaping public opinion, making them
a vital source for understanding contemporary discourse. Their typically
unscripted, multi-themed, and conversational style offers a rich but complex
form of data. To analyze how podcasts persuade and inform, we must examine
their narrative structures -- specifically, the narrative frames they employ.
  The fluid and conversational nature of podcasts presents a significant
challenge for automated analysis. We show that existing large language models,
typically trained on more structured text such as news articles, struggle to
capture the subtle cues that human listeners rely on to identify narrative
frames. As a result, current approaches fall short of accurately analyzing
podcast narratives at scale.
  To solve this, we develop and evaluate a fine-tuned BERT model that
explicitly links narrative frames to specific entities mentioned in the
conversation, effectively grounding the abstract frame in concrete details. Our
approach then uses these granular frame labels and correlates them with
high-level topics to reveal broader discourse trends. The primary contributions
of this paper are: (i) a novel frame-labeling methodology that more closely
aligns with human judgment for messy, conversational data, and (ii) a new
analysis that uncovers the systematic relationship between what is being
discussed (the topic) and how it is being presented (the frame), offering a
more robust framework for studying influence in digital media.

</details>


### [8] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为multiMentalRoBERTa的，用于精神健康状况多分类的微调RoBERTa模型，该模型在识别方面表现出色，并强调了模型的可解释性和公平性。


<details>
  <summary>Details</summary>
Motivation: 早期发现社交媒体文本中的心理健康障碍对于及时支持、风险评估和转诊至关重要。

Method: 本文引入了一个名为multiMentalRoBERTa的微调RoBERTa模型，用于常见心理健康状况的多类别分类，包括压力、焦虑、抑郁、创伤后应激障碍（PTSD）、自杀意念和中性话语。作者利用多个精选数据集，分析了类别重叠，揭示了抑郁症和自杀意念之间以及焦虑症和PTSD之间存在强相关性，而压力则是一个广泛、重叠的类别。

Result: 多项实验结果表明，multiMentalRoBERTa在六类别设置中宏观F1分数为0.839，在五类别设置（排除压力）中宏观F1分数为0.870，优于微调后的MentalBERT和基线分类器。此外，研究还应用了Layer Integrated Gradients和KeyBERT等可解释性方法来识别驱动分类的词汇线索。

Conclusion: 精细调整的Transformer模型在敏感情境下进行可靠和可解释的检测是有效的，同时强调了公平性、偏见缓解和人工参与安全协议的重要性。总体而言，multiMentalRoBERTa是一个轻量级、稳健且可部署的解决方案，可增强心理健康平台的支持。

Abstract: The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [9] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

TL;DR: Cross-Lingual SynthDocs是一个大型合成语料库，旨在解决阿拉伯语OCR和文档理解资源的稀缺问题。它包含超过250万样本，通过在Qwen-2.5-VL上进行微调，在OCR、表格和图表提取方面均取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语光学字符识别（OCR）和文档理解（DU）领域资源稀缺的挑战，特别是缺乏大规模、高质量的阿拉伯语文档数据集。

Method: 该语料库通过利用真实的扫描背景、双语布局和支持音调的字体来捕捉阿拉伯文档的印刷和结构复杂性。它包含150万文本数据、27万完全标注的表格和数十万基于真实数据的图表。

Result: 在Cross-Lingual SynthDocs上对Qwen-2.5-VL进行微调后，在多个公共阿拉伯语基准测试中，OCR的词错误率（WER）和字符错误率（CER）均得到持续改善。此外，在其他模态中，树编辑距离相似度（TEDS）和图表提取分数（CharTeX）也得到了提高。

Conclusion: Cross-Lingual SynthDocs提供了一个可扩展、视觉真实的资源，用于推动多语言文档分析领域的研究进展。

Abstract: Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [10] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

TL;DR: 本文对445个LLM基准测试进行了系统综述，发现现有评估方法在测量现象、任务和评分指标方面存在问题，这削弱了评估结果的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的评估对于评估其能力以及在部署前识别安全性和鲁棒性问题至关重要。可靠地测量“安全性”和“鲁棒性”等抽象复杂现象需要强大的结构效度，即测量方法必须能够代表现象的实质。

Method: 本文组织了一个由29名专家评审员组成的团队，对自然语言处理和机器学习领域主要会议的445个大型语言模型（LLM）基准测试进行了系统综述。

Result: 通过对已评审文章的分析，本文发现现有评估方法在测量现象、任务和评分指标方面存在一些模式，这些模式削弱了评估结果的有效性。

Conclusion: 为了解决现有LLM评估方法的不足，本文提出了八项关键建议，并为LLM基准测试的开发人员提供了详细可行的指导。

Abstract: Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


### [11] [GEMMA-SQL: A Novel Text-to-SQL Model Based on Large Language Models](https://arxiv.org/abs/2511.04710)
*Hari Mohan Pandey,Anshul Gupta,Subham Sarkar,Minakshi Tomer,Schneider Johannes,Yan Gong*

Main category: cs.CL

TL;DR: GEMMA-SQL是一个轻量级、高效的Text-to-SQL模型，它基于Gemma 2B架构，通过资源高效的迭代方式进行微调，并在SPIDER基准测试中表现出色，其Instruct版本在Test-Suite准确率上达到66.8%，Exact Set Match准确率达到63.3%，超过了多个先进基线模型。


<details>
  <summary>Details</summary>
Motivation: 目前的Text-to-SQL系统需要专业的编程知识，且许多大型语言模型（LLMs）资源消耗大，难以部署在低成本硬件上。因此，开发一种轻量级、高效且能在低成本硬件上部署的Text-to-SQL系统是必要的。

Method: GEMMA-SQL模型基于开源的Gemma 2B架构构建，采用资源高效的迭代方式进行微调。该模型结合了多种提示策略，包括少样本学习，以提高SQL查询生成准确性。模型在SPIDER基准测试上进行训练和评估，并通过指令调优生成了GEMMA-SQL Instruct版本。

Result: GEMMA-SQL Instruct在Test-Suite准确率上达到66.8%，Exact Set Match准确率上达到63.3%。该模型超越了IRNet、RYANSQL和CodeXDavinci等多个现有先进基线模型，证明了有效的提示设计和有针对性的指令调优可以显著提升性能。

Conclusion: GEMMA-SQL提供了一个实用、开源的替代方案，用于构建强大且易于访问的Text-to-SQL系统。该研究表明，即使是轻量级模型，通过有效的提示工程和指令调优，也能在Text-to-SQL任务中取得优异性能，且部署成本较低。

Abstract: Text-to-SQL systems enable users to interact with structured databases using
natural language, eliminating the need for specialized programming knowledge.
In this work, we introduce GEMMA-SQL, a lightweight and efficient text-to-SQL
model built upon the open-source Gemma 2B architecture. Unlike many large
language models (LLMs), GEMMA-SQL is fine-tuned in a resource-efficient,
iterative manner and can be deployed on low-cost hardware. Leveraging the
SPIDER benchmark for training and evaluation, GEMMA-SQL combines multiple
prompting strategies, including few-shot learning, to enhance SQL query
generation accuracy. The instruction-tuned variant, GEMMA-SQL Instruct,
achieves 66.8% Test-Suite accuracy and 63.3% Exact Set Match accuracy,
outperforming several state-of-the-art baselines such as IRNet, RYANSQL, and
CodeXDavinci. The proposed approach demonstrates that effective prompt design
and targeted instruction tuning can significantly boost performance while
maintaining high scalability and adaptability. These results position GEMMA-SQL
as a practical, open-source alternative for robust and accessible text-to-SQL
systems.

</details>


### [12] [First is Not Really Better Than Last: Evaluating Layer Choice and Aggregation Strategies in Language Model Data Influence Estimation](https://arxiv.org/abs/2511.04715)
*Dmytro Vitel,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 这篇论文旨在解决如何识别训练样本影响大型语言模型决策的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的训练样本影响力估计方法（影响力函数）在计算上受限于大型语言模型的模型大小。Yeh等人（2022）的开创性工作认为第一（嵌入）层对于计算语言数据影响力最 H T 有信息量，但本文认为这种取消效应是不可靠的。

Method: 我们提出了理论和实证证据，证明取消效应是不可靠的，并且中间注意力层是更好的影响力估计器。其次，我们使用排名和基于投票的方法来替代标准平均，聚合跨层的影响力分数，这可以显著提高性能。最后，我们提出了一种新的评估影响力分数效用的衡量标准，称为噪声检测率（NDR），它与取消效应相比，表现出强大的预测能力。

Result: 我们发现中间注意力层是更好的影响力估计器。聚合影响力分数时，排名和基于投票的方法可以显著提高性能。我们提出的NDR度量具有强大的预测能力。

Conclusion: 本研究驳斥了先前认为第一层对于LLM影响力估计优于最后一层的观点，为LLM影响力分析提供了新的视角和改进的方法。

Abstract: Identifying how training samples influence/impact Large Language Model (LLM)
decision-making is essential for effectively interpreting model decisions and
auditing large-scale datasets. Current training sample influence estimation
methods (also known as influence functions) undertake this goal by utilizing
information flow through the model via its first-order and higher-order
gradient terms. However, owing to the large model sizes of today consisting of
billions of parameters, these influence computations are often restricted to
some subset of model layers to ensure computational feasibility. Prior seminal
work by Yeh et al. (2022) in assessing which layers are best suited for
computing language data influence concluded that the first (embedding) layers
are the most informative for this purpose, using a hypothesis based on
influence scores canceling out (i.e., the cancellation effect). In this work,
we propose theoretical and empirical evidence demonstrating how the
cancellation effect is unreliable, and that middle attention layers are better
estimators for influence. Furthermore, we address the broader challenge of
aggregating influence scores across layers, and showcase how alternatives to
standard averaging (such as ranking and vote-based methods) can lead to
significantly improved performance. Finally, we propose better methods for
evaluating influence score efficacy in LLMs without undertaking model
retraining, and propose a new metric known as the Noise Detection Rate (NDR)
that exhibits strong predictive capability compared to the cancellation effect.
Through extensive experiments across LLMs of varying types and scales, we
concretely determine that the first (layers) are not necessarily better than
the last (layers) for LLM influence estimation, contrasting with prior
knowledge in the field.

</details>


### [13] [Surprisal reveals diversity gaps in image captioning and different scorers change the story](https://arxiv.org/abs/2511.04754)
*Nikolai Ilinykh,Simon Dobnik*

Main category: cs.CL

TL;DR: 本文提出了一种新的评估图像字幕多样性的方法，称为“惊奇度方差”，并发现人类字幕比模型字幕具有更高的惊奇度方差，但这一结论取决于所使用的语言模型。


<details>
  <summary>Details</summary>
Motivation: 量化图像字幕中的语言多样性。

Method: 本文提出用“惊奇度方差”来量化图像字幕中的语言多样性，并在MSCOCO测试集上比较了五种最先进的视觉和语言LLMs的字幕与人类字幕。

Result: 人类字幕的惊奇度方差大约是模型的两倍（使用字幕训练的n-gram LM度量），但使用通用语言模型重新评分后，这一模式反转。

Conclusion: 惊奇度方差可以作为图像字幕多样性的度量，但鲁棒的多样性评估必须在多个评分器下报告惊奇度。

Abstract: We quantify linguistic diversity in image captioning with surprisal variance
- the spread of token-level negative log-probabilities within a caption set. On
the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs,
decoded with greedy and nucleus sampling, to human captions. Measured with a
caption-trained n-gram LM, humans display roughly twice the surprisal variance
of models, but rescoring the same captions with a general-language model
reverses the pattern. Our analysis introduces the surprisal-based diversity
metric for image captioning. We show that relying on a single scorer can
completely invert conclusions, thus, robust diversity evaluation must report
surprisal under several scorers.

</details>


### [14] [Explore Data Left Behind in Reinforcement Learning for Reasoning Language Models](https://arxiv.org/abs/2511.04800)
*Chenxi Liu,Junjie Liang,Yuqi Jia,Bochuan Cao,Yang Bai,Heng Huang,Xun Chen*

Main category: cs.CL

TL;DR: ERPO框架通过鼓励对残差提示的探索和重新激活训练信号，提高了大语言模型在RLVR中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在模型训练时间增长和规模扩大时，会出现越来越多的残差提示，这些提示的奖励方差为零，无法提供有效的训练信号，从而降低了训练效率和多样性。

Method: ERPO框架为每个提示维护一个历史跟踪器，并自适应地增加之前产生所有正确响应的残差提示的采样温度。这鼓励模型生成更多样化的推理轨迹，引入不正确的响应以恢复训练信号。

Result: 在Qwen2.5系列上的实证结果表明，ERPO在多个数学推理基准测试中持续超越了强基线。

Conclusion: ERPO框架通过有效处理残差提示，显著提升了RLVR训练大语言模型进行数学推理的能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an
effective approach for improving the reasoning abilities of large language
models (LLMs). The Group Relative Policy Optimization (GRPO) family has
demonstrated strong performance in training LLMs with RLVR. However, as models
train longer and scale larger, more training prompts become residual prompts,
those with zero variance rewards that provide no training signal. Consequently,
fewer prompts contribute to training, reducing diversity and hindering
effectiveness. To fully exploit these residual prompts, we propose the Explore
Residual Prompts in Policy Optimization (ERPO) framework, which encourages
exploration on residual prompts and reactivates their training signals. ERPO
maintains a history tracker for each prompt and adaptively increases the
sampling temperature for residual prompts that previously produced all correct
responses. This encourages the model to generate more diverse reasoning traces,
introducing incorrect responses that revive training signals. Empirical results
on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong
baselines across multiple mathematical reasoning benchmarks.

</details>


### [15] [Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs](https://arxiv.org/abs/2511.04875)
*Matthew Bozoukov,Matthew Nguyen,Shubkarman Singh,Bart Bussmann,Patrick Leask*

Main category: cs.CL

TL;DR: 研究发现，LLMs可以表现出行为的自我意识，即在没有明确监督的情况下准确描述或预测自身学习行为的能力。本文旨在探讨这种自我意识出现的最小条件及其表现的机制过程。


<details>
  <summary>Details</summary>
Motivation: LLM的自我意识能力引发了安全问题，因为它可能允许模型在评估期间更好地隐藏其真实能力。因此，研究这种现象的出现条件和机制至关重要。

Method: 通过对指令调优的LLMs进行受控的LoRA微调实验。

Result: 1. 仅使用一个秩-1的LoRA适配器就能可靠地诱导自我意识；2. 学习到的自我意识行为可以通过激活空间中的单个“引导向量”在很大程度上被捕获；3. 自我意识是非普遍的且域局部化的，在不同任务中具有独立的表示。

Conclusion: 行为自我意识是领域特定的线性特征，易于诱导和调节。

Abstract: Recent studies have revealed that LLMs can exhibit behavioral self-awareness:
the ability to accurately describe or predict their own learned behaviors
without explicit supervision. This capability raises safety concerns as it may,
for example, allow models to better conceal their true abilities during
evaluation. We attempt to characterize the minimal conditions under which such
self-awareness emerges, and the mechanistic processes through which it
manifests. Through controlled finetuning experiments on instruction-tuned LLMs
with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably
induced using a single rank-1 LoRA adapter; (2) that the learned self-aware
behavior can be largely captured by a single steering vector in activation
space, recovering nearly all of the fine-tune's behavioral effect; and (3) that
self-awareness is non-universal and domain-localized, with independent
representations across tasks. Together, these findings suggest that behavioral
self-awareness emerges as a domain-specific, linear feature that can be easily
induced and modulated.

</details>


### [16] [SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in Korean Public Documents](https://arxiv.org/abs/2511.04910)
*Jaehoon Lee,Sohyun Kim,Wanggeun Park,Geon Lee,Seungkyung Kim,Minyoung Lee*

Main category: cs.CL

TL;DR: 本文介绍了SDS KoPub VDR，一个针对韩语公共文档检索和理解的大规模基准，旨在解决现有基准忽视非英语语言和复杂文档结构的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉文档检索（VDR）基准 largely overlook 非英语语言和官方出版物的结构复杂性。

Method: SDS KoPub VDR 基准建立在361份真实世界韩语公共文档（40,781页）的基础上，其中包括来自KOGL Type 1许可和官方法律门户的文档，捕捉了表格、图表和多栏布局等复杂视觉元素。该基准通过多模态模型（如GPT-4o）生成并经过人工验证和改进，构建了600个查询-页面-答案三元组。查询涵盖六个主要公共领域，并根据所需的推理模态进行分类：基于文本、基于视觉和跨模态。该基准在文本检索和多模态检索两种任务上进行评估。

Result: 评估揭示了显著的性能差距，特别是在需要跨模态推理的多模态场景中，即使是当前最先进的模型也存在不足。

Conclusion: SDS KoPub VDR 作为基础资源，不仅能够对文本和多模态检索任务进行严格和细致的评估，还为复杂真实世界文档智能领域的多模态AI发展提供了清晰的路线图。

Abstract: Existing benchmarks for visual document retrieval (VDR) largely overlook
non-English languages and the structural complexity of official publications.
To address this critical gap, we introduce SDS KoPub VDR, the first
large-scale, publicly available benchmark for retrieving and understanding
Korean public documents. The benchmark is built upon a corpus of 361 real-world
documents (40,781 pages), including 256 files under the KOGL Type 1 license and
105 from official legal portals, capturing complex visual elements like tables,
charts, and multi-column layouts. To establish a challenging and reliable
evaluation set, we constructed 600 query-page-answer triples. These were
initially generated using multimodal models (e.g., GPT-4o) and subsequently
underwent a rigorous human verification and refinement process to ensure
factual accuracy and contextual relevance. The queries span six major public
domains and are systematically categorized by the reasoning modality required:
text-based, visual-based (e.g., chart interpretation), and cross-modal. We
evaluate SDS KoPub VDR on two complementary tasks that reflect distinct
retrieval paradigms: (1) text-only retrieval, which measures a model's ability
to locate relevant document pages based solely on textual signals, and (2)
multimodal retrieval, which assesses retrieval performance when visual features
(e.g., tables, charts, and layouts) are jointly leveraged alongside text. This
dual-task evaluation reveals substantial performance gaps, particularly in
multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art
models. As a foundational resource, SDS KoPub VDR not only enables rigorous and
fine-grained evaluation across textual and multimodal retrieval tasks but also
provides a clear roadmap for advancing multimodal AI in complex, real-world
document intelligence.

</details>


### [17] [BudgetMem: Learning Selective Memory Policies for Cost-Efficient Long-Context Processing in Language Models](https://arxiv.org/abs/2511.04919)
*Chandra Vamsi Krishna Alla,Harish Naidu Gaddam,Manohar Kommi*

Main category: cs.CL

TL;DR: BudgetMem是一种新颖的记忆增强架构，它通过选择性记忆策略和基于特征的显著性评分，学习记住什么而不是记住所有内容，从而在处理长上下文时显著降低计算和内存成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理长上下文时面临显著的计算和内存限制，尽管对需要对大量文档、多会话对话和书籍长度文本进行推理的应用程序的需求不断增长。

Method: BudgetMem结合了选择性记忆策略和基于特征的显著性评分（实体密度、TF-IDF、语篇标记、位置偏差）来决定在严格预算约束下哪些信息值得存储。与现有存储所有块的检索增强生成（RAG）系统不同，BudgetMem采用学习门控机制和BM25稀疏检索来实现高效信息访问。

Result: 通过对700个问题答案对（涵盖短文档（237个token）和长文档（5K-10K个token））以及Llama-3.2-3B-Instruct的综合实验，BudgetMem在长文档上取得了显著成果：与基线RAG相比，F1分数仅下降1.0%，同时节省了72.4%的内存。

Conclusion: BudgetMem提供了一种在适度硬件上部署有能力的“长上下文”系统的实用途径，使更多人能够使用先进的语言理解功能。

Abstract: Large Language Models (LLMs) face significant computational and memory
constraints when processing long contexts, despite growing demand for
applications requiring reasoning over extensive documents, multi-session
dialogues, and book length texts. While recent advances have extended context
windows to 100K-1M tokens, such approaches incur prohibitive costs for resource
constrained deployments. We propose BudgetMem, a novel memory augmented
architecture that learns what to remember rather than remembering everything.
Our system combines selective memory policies with feature based salience
scoring (entity density, TF-IDF, discourse markers, position bias) to decide
which information merits storage under strict budget constraints. Unlike
existing retrieval augmented generation (RAG) systems that store all chunks,
BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval
for efficient information access. Through comprehensive experiments on 700
question answer pairs across short (237 tokens) and long (5K-10K tokens)
documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves
remarkable results on long documents: only 1.0% F1 score degradation while
saving 72.4% memory compared to baseline RAG. We validate our approach through
budget sensitivity analysis (testing 7 budget ratios), naive baseline
comparisons, and document length analysis, showing that BudgetMem's benefits
increase with document length. Our work provides a practical pathway for
deploying capable long context systems on modest hardware, democratizing access
to advanced language understanding capabilities.

</details>


### [18] [Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's Classification Hierarchy](https://arxiv.org/abs/2511.04926)
*Shixiong Zhao,Hideaki Takeda*

Main category: cs.CL

TL;DR: 该研究提出了一种新的验证方法，用于识别和纠正Wikidata中分类错误和冗余链接，并开发了一个系统，允许用户检查Wikidata中任意实体的分类关系。


<details>
  <summary>Details</summary>
Motivation: Wikidata在知识图谱研究中具有核心地位，但其宽松的编辑政策导致了分类不一致的问题。

Method: 提出并应用了一种新颖的验证方法，以确认Wikidata特定领域中分类错误、过度泛化的子类链接和冗余连接的存在。引入了一个新的评估标准，用于确定这些问题是否需要纠正，并开发了一个系统，允许用户检查任意Wikidata实体的分类关系。

Result: 确认了Wikidata特定领域中存在分类错误、过度泛化的子类链接和冗余连接。开发了一个系统，允许用户检查Wikidata中任意实体的分类关系，充分利用了该平台的众包性质。

Conclusion: 该研究提出了一种有效的方法来解决Wikidata中分类不一致的问题，并通过用户检查系统充分利用了其众包特性，有助于提高Wikidata的质量。

Abstract: Wikidata is currently the largest open knowledge graph on the web,
encompassing over 120 million entities. It integrates data from various
domain-specific databases and imports a substantial amount of content from
Wikipedia, while also allowing users to freely edit its content. This openness
has positioned Wikidata as a central resource in knowledge graph research and
has enabled convenient knowledge access for users worldwide. However, its
relatively loose editorial policy has also led to a degree of taxonomic
inconsistency. Building on prior work, this study proposes and applies a novel
validation method to confirm the presence of classification errors,
over-generalized subclass links, and redundant connections in specific domains
of Wikidata. We further introduce a new evaluation criterion for determining
whether such issues warrant correction and develop a system that allows users
to inspect the taxonomic relationships of arbitrary Wikidata
entities-leveraging the platform's crowdsourced nature to its full potential.

</details>


### [19] [LoPT: Lossless Parallel Tokenization Acceleration for Long Context Inference of Large Language Model](https://arxiv.org/abs/2511.04952)
*Wei Shao,Lingchao Zheng,Pengyu Wang,Peizhen Zheng,Jun Li,Yuwei Fan*

Main category: cs.CL

TL;DR: LoPT是一个针对大语言模型长文本推理场景的无损并行分词框架，它通过字符位置匹配和动态块长度调整，解决了现有并行分词方法中因边界伪影导致结果不一致的问题，在保证分词无损的同时显著加速了长文本分词过程。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型的长上下文推理场景中，分词已成为一个被忽视的瓶颈。现有的并行分词方法虽然能加速处理，但由于合并后出现边界伪影，导致结果不一致。

Method: LoPT通过基于字符位置的匹配和动态块长度调整来精确对齐和合并分词后的片段。

Result: LoPT在各种长文本数据集上都达到了显著的加速，并保证了无损分词。

Conclusion: LoPT是一个鲁棒、高效的解决方案，它在实现并行分词加速的同时，保证了分词结果与标准顺序分词完全一致。

Abstract: Long context inference scenarios have become increasingly important for large
language models, yet they introduce significant computational latency. While
prior research has optimized long-sequence inference through operators, model
architectures, and system frameworks, tokenization remains an overlooked
bottleneck. Existing parallel tokenization methods accelerate processing
through text segmentation and multi-process tokenization, but they suffer from
inconsistent results due to boundary artifacts that occur after merging. To
address this, we propose LoPT, a novel Lossless Parallel Tokenization framework
that ensures output identical to standard sequential tokenization. Our approach
employs character-position-based matching and dynamic chunk length adjustment
to align and merge tokenized segments accurately. Extensive experiments across
diverse long-text datasets demonstrate that LoPT achieves significant speedup
while guaranteeing lossless tokenization. We also provide theoretical proof of
consistency and comprehensive analytical studies to validate the robustness of
our method.

</details>


### [20] [Too Good to be Bad: On the Failure of LLMs to Role-Play Villains](https://arxiv.org/abs/2511.04962)
*Zihao Yi,Qingxuan Jiang,Ruotian Ma,Xingyu Chen,Qu Yang,Mengru Wang,Fanghua Ye,Ying Shen,Zhaopeng Tu,Xiaolong Li,Linus*

Main category: cs.CL

TL;DR: 该论文探讨了大型语言模型（LLMs）在扮演非亲社会、反派角色时面临的挑战，发现模型的安全对齐限制了其对道德 H 模棱两可或邪恶角色的真实再现。


<details>
  <summary>Details</summary>
Motivation: 探究现代 LLM 的安全对齐与真实扮演道德模糊或反派角色任务之间的根本冲突。

Method: 引入 Moral RolePlay 基准测试数据集，该数据集具有四级道德对齐量表和平衡的测试集；让最先进的 LLM 扮演从道德典范到纯粹恶棍的角色。

Result: 角色道德水平越低，角色扮演的忠实度持续单调下降。模型在处理与安全原则 E 直接 H 对立的 H 特征（如 H “欺骗性”和 H “操控性”）时 T 表现最差， H 经常用肤浅的 H 攻击性 H 取代 H 微妙的男性恶意。 H 通用聊天机器人能力并不能很好地预测 H 恶棍角色扮演能力，高度安全对齐的模型表现 H S 差。

Conclusion: 首次系统地证明了这一关键局限性，揭示了模型安全与创作忠实度之间的关键 H 矛盾。本研究的基准和发现为 H 开发更细致、 H 上下文感知的对齐方法铺平了道路。

Abstract: Large Language Models (LLMs) are increasingly tasked with creative
generation, including the simulation of fictional characters. However, their
ability to portray non-prosocial, antagonistic personas remains largely
unexamined. We hypothesize that the safety alignment of modern LLMs creates a
fundamental conflict with the task of authentically role-playing morally
ambiguous or villainous characters. To investigate this, we introduce the Moral
RolePlay benchmark, a new dataset featuring a four-level moral alignment scale
and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs
with role-playing characters from moral paragons to pure villains. Our
large-scale evaluation reveals a consistent, monotonic decline in role-playing
fidelity as character morality decreases. We find that models struggle most
with traits directly antithetical to safety principles, such as ``Deceitful''
and ``Manipulative'', often substituting nuanced malevolence with superficial
aggression. Furthermore, we demonstrate that general chatbot proficiency is a
poor predictor of villain role-playing ability, with highly safety-aligned
models performing particularly poorly. Our work provides the first systematic
evidence of this critical limitation, highlighting a key tension between model
safety and creative fidelity. Our benchmark and findings pave the way for
developing more nuanced, context-aware alignment methods.

</details>


### [21] [Acquiring Common Chinese Emotional Events Using Large Language Model](https://arxiv.org/abs/2511.04989)
*Ya Wang,Guangzheng Zhu,Cungen Cao,Jingjing Li,He Li,Xin Huang*

Main category: cs.CL

TL;DR: 该论文介绍了一种获取中文通用情感事件的方法，并构建了一个包含102,218个情感事件的大规模知识库。


<details>
  <summary>Details</summary>
Motivation: 情感事件知识对多种应用具有重要意义，但难以获取，尤其是与上下文无关的通用情感事件。

Method: 首先收集中文情感事件指标，然后利用这些指标提示中文大型语言模型生成情感事件。之后，训练一个过滤器来筛选无效结果。最后，利用不同技术对情感事件进行积极/消极分类。

Result: 最终获得了102,218个高质量的、带有情感极性标签的中文通用情感事件。这是目前唯一的中文情感事件大规模常识知识库。

Conclusion: 所提出的方法能够有效地获取中文通用情感事件。外部用例也表明，通用情感事件在情感原因提取领域具有巨大潜力。

Abstract: Knowledge about emotional events is an important kind of knowledge which has
been applied to improve the effectiveness of different applications. However,
emotional events cannot be easily acquired, especially common or generalized
emotional events that are context-independent. The goal of this paper is to
obtain common emotional events in Chinese language such as "win a prize" and
"be criticized". Our approach begins by collecting a comprehensive list of
Chinese emotional event indicators. Then, we generate emotional events by
prompting a Chinese large language model (LLM) using these indicators. To
ensure the quality of these emotional events, we train a filter to discard
invalid generated results. We also classify these emotional events as being
positive events and negative events using different techniques. Finally, we
harvest a total of 102,218 high-quality common emotional events with sentiment
polarity labels, which is the only large-scale commonsense knowledge base of
emotional events in Chinese language. Intrinsic evaluation results show that
the proposed method in this paper can be effectively used to acquire common
Chinese emotional events. An extrinsic use case also demonstrates the strong
potential of common emotional events in the field of emotion cause extraction
(ECE). Related resources including emotional event indicators and emotional
events will be released after the publication of this paper.

</details>


### [22] [UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM Code Generation in Ukrainian](https://arxiv.org/abs/2511.05040)
*Mykyta Syromiatnikov,Victoria Ruvinskaya*

Main category: cs.CL

TL;DR: 该论文介绍了UA-Code-Bench，这是一个用于评估大型语言模型在乌克兰语代码生成和编程解题能力的基准。研究发现，即使是顶级的模型也只能解决大约一半的问题，凸显了在低资源语言中代码生成的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注从英语翻译而来的任务或只评估简单的语言理解，难以真实评估大型语言模型在低资源语言中的能力。

Method: 论文提出了UA-Code-Bench基准，包含来自Eolymp平台的500个问题，分为五个难度级别。使用one-shot提示评估了13个领先的专有和开源模型，并通过Eolymp环境针对隐藏测试评估Python解决方案的代码正确性。

Result: 即使是GPT-4和GPT-5等顶级模型也只能解决大约一半的问题。研究还对不同难度级别的性能、解决方案的独特性和计算效率（包括执行时间和内存消耗）进行了全面分析。

Conclusion: 竞技编程基准对于评估大型语言模型（特别是在资源不足的语言中）具有重要价值，并为未来的多语言代码生成和推理增强模型研究奠定了基础。

Abstract: Evaluating the real capabilities of large language models in low-resource
languages still represents a challenge, as many existing benchmarks focus on
widespread tasks translated from English or evaluate only simple language
understanding. This paper introduces UA-Code-Bench, a new open-source benchmark
established for a thorough evaluation of language models' code generation and
competitive programming problem-solving abilities in Ukrainian. The benchmark
comprises 500 problems from the Eolymp platform, evenly distributed across five
complexity levels from very easy to very hard. A diverse set of 13 leading
proprietary and open-source models, generating Python solutions based on a
one-shot prompt, was evaluated via the dedicated Eolymp environment against
hidden tests, ensuring code correctness. The obtained results reveal that even
top-performing models, such as OpenAI o3 and GPT-5, solve only half of the
problems, highlighting the challenge of code generation in low-resource natural
language. Furthermore, this research presents a comprehensive analysis of
performance across various difficulty levels, as well as an assessment of
solution uniqueness and computational efficiency, measured by both elapsed time
and memory consumption of the generated solutions. In conclusion, this work
demonstrates the value of competitive programming benchmarks in evaluating
large language models, especially in underrepresented languages. It also paves
the way for future research on multilingual code generation and
reasoning-enhanced models. The benchmark, data parsing, preparation, code
generation, and evaluation scripts are available at
https://huggingface.co/datasets/NLPForUA/ua-code-bench.

</details>


### [23] [Order-Level Attention Similarity Across Language Models: A Latent Commonality](https://arxiv.org/abs/2511.05064)
*Jinglin Liang,Jin Zhong,Shuangping Huang,Yunqing Hu,Huiyuan Zhang,Huifang Li,Lixin Fan,Hanlin Gu*

Main category: cs.CL

TL;DR: 这篇论文探讨了大型语言模型（LMs）中上下文聚合模式的共性，发现了一种名为Order-Level Attention (OLA) 的机制，该机制在不同LM之间表现出显著的相似性，并且与句法知识存在隐式映射。基于这些发现，作者提出了可迁移的OLA适配器（TOA），这是一种无需训练的跨LM适配器迁移方法，可以有效提升未见LMs的性能。


<details>
  <summary>Details</summary>
Motivation: 以往的研究大多关注单个模型或注意力头部的上下文聚合，缺乏对多个LMs之间共性的系统分析。本文旨在探索LMs之间上下文聚合模式的共性，以加深对LMs的理解并促进跨模型知识迁移。

Method: 本文引入了Order-Level Attention (OLA)，它源于注意力展开（Attention Rollout）的阶次分解。通过分析不同LMs在相同阶次上的OLA，揭示了其显著的相似性。此外，本文还发现OLA与句法知识之间存在隐式映射。基于这两个发现，提出了免训练的跨LM适配器迁移方法——可迁移的OLA适配器（TOA）。TOA将OLA视为统一的句法特征表示，并训练一个以OLA为输入的适配器。

Result: 不同LMs之间相同阶次的OLA表现出显著的相似性。OLA与句法知识之间存在隐式映射。TOA方法在未见LMs上展现出良好的跨LM泛化能力，有效提升了这些LMs的性能。

Conclusion: 本文通过引入OLA并揭示其在不同LMs之间的共性以及与句法知识的映射，提出了一种新颖的、免训练的跨LM适配器迁移方法TOA。该方法利用OLA的相似性，实现了适配器在未见LMs上的泛化，为理解和提升LMs的性能提供了新的视角和有效方法。

Abstract: In this paper, we explore an important yet previously neglected question: Do
context aggregation patterns across Language Models (LMs) share commonalities?
While some works have investigated context aggregation or attention weights in
LMs, they typically focus on individual models or attention heads, lacking a
systematic analysis across multiple LMs to explore their commonalities. In
contrast, we focus on the commonalities among LMs, which can deepen our
understanding of LMs and even facilitate cross-model knowledge transfer. In
this work, we introduce the Order-Level Attention (OLA) derived from the
order-wise decomposition of Attention Rollout and reveal that the OLA at the
same order across LMs exhibits significant similarities. Furthermore, we
discover an implicit mapping between OLA and syntactic knowledge. Based on
these two findings, we propose the Transferable OLA Adapter (TOA), a
training-free cross-LM adapter transfer method. Specifically, we treat the OLA
as a unified syntactic feature representation and train an adapter that takes
OLA as input. Due to the similarities in OLA across LMs, the adapter
generalizes to unseen LMs without requiring any parameter updates. Extensive
experiments demonstrate that TOA's cross-LM generalization effectively enhances
the performance of unseen LMs. Code is available at
https://github.com/jinglin-liang/OLAS.

</details>


### [24] [Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media Posts](https://arxiv.org/abs/2511.05078)
*Manan Sharma,Arya Suneesh,Manish Jain,Pawan Kumar Rajpoot,Prasanna Devadiga,Bharatdeep Hazarika,Ashish Shrivastava,Kishan Gurumurthy,Anshuman B Suresh,Aditya U Baliga*

Main category: cs.CL

TL;DR: 该论文提出了一个针对20种语言的跨语言错误信息检测的声明规范化方法，即使只用英语数据训练，也能通过系统分解帖子实现强大的跨语言传输。


<details>
  <summary>Details</summary>
Motivation: 解决多语言错误信息检测中的声明规范化问题，将嘈杂的社交媒体帖子转化为清晰、可验证的声明。

Method: 该方法通过“谁、什么、哪里、何时、为什么、如何”的问题系统分解帖子，并使用LoRA对Qwen3-14B进行微调，结合了帖子内部去重、token级召回过滤以实现语义对齐，以及推理过程中上下文示例的检索增强少样本学习。

Result: 该系统在METEOR得分上，英语达到41.16，马拉地语达到15.21，在英语排行榜上获得第三名，在荷兰语和旁遮普语方面获得第四名。与基线配置相比，METEOR相对提高了41.3%，并且显著优于现有方法。

Conclusion: 该方法展示了对罗曼语族和日耳曼语族语言的有效跨语言泛化能力，同时在不同语言结构中保持了语义连贯性。

Abstract: We address claim normalization for multilingual misinformation detection -
transforming noisy social media posts into clear, verifiable statements across
20 languages. The key contribution demonstrates how systematic decomposition of
posts using Who, What, Where, When, Why and How questions enables robust
cross-lingual transfer despite training exclusively on English data. Our
methodology incorporates finetuning Qwen3-14B using LoRA with the provided
dataset after intra-post deduplication, token-level recall filtering for
semantic alignment and retrieval-augmented few-shot learning with contextual
examples during inference. Our system achieves METEOR scores ranging from 41.16
(English) to 15.21 (Marathi), securing third rank on the English leaderboard
and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative
improvement in METEOR over baseline configurations and substantial gains over
existing methods. Results demonstrate effective cross-lingual generalization
for Romance and Germanic languages while maintaining semantic coherence across
diverse linguistic structures.

</details>


### [25] [On Text Simplification Metrics and General-Purpose LLMs for Accessible Health Information, and A Potential Architectural Advantage of The Instruction-Tuned LLM class](https://arxiv.org/abs/2511.05080)
*P. Bilha Githinji,Aikaterini Meilliou,Peiwu Qin*

Main category: cs.CL

TL;DR: 这篇论文评估了大型语言模型（LLM）在将复杂的生物医学信息简化为通俗易懂语言方面的表现，并将其与人类表现进行比较。研究发现，经过指令微调的Mistral 24B模型在可读性和语义保真度之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 随着公众对健康信息的关注和对生物医学数字信息的消费增加，需要可扩展的解决方案将复杂的科学技术文档自动改编为通俗易懂的语言，但现有自动文本简化方案（包括大型语言模型）在优化可读性和确保语篇忠实度之间面临挑战。

Method: 该研究通过比较分析指令微调的Mistral 24B和推理增强的QWen2.5 32B，评估了两类主流通用大型语言模型的性能。研究使用了可读性、语篇忠实度、内容安全性以及潜在分布度量等21个指标进行综合相关性分析，并与人类评估结果进行比较。

Result: Mistral 24B表现出温和的词汇简化策略，提高了可读性（SARI平均值为42.46），并以0.91的BERTScore保持了人类水平的语篇。QWen2.5 32B也提高了可读性，但在可读性和准确性之间未能取得平衡，BERTScore显著低于0.89。此外，相关性分析证实了五个可读性指标之间存在很强的功能冗余。

Conclusion: 指令微调的Mistral 24B在文本简化任务中表现出更好的性能，在可读性和语篇忠实度之间取得了更好的平衡。研究指出，词汇支持是简化的主要领域适应问题，并为指标选择提供了必要的启发式方法。

Abstract: The increasing health-seeking behavior and digital consumption of biomedical
information by the general public necessitate scalable solutions for
automatically adapting complex scientific and technical documents into plain
language. Automatic text simplification solutions, including advanced large
language models, however, continue to face challenges in reliably arbitrating
the tension between optimizing readability performance and ensuring
preservation of discourse fidelity. This report empirically assesses the
performance of two major classes of general-purpose LLMs, demonstrating their
linguistic capabilities and foundational readiness for the task compared to a
human benchmark. Using a comparative analysis of the instruction-tuned Mistral
24B and the reasoning-augmented QWen2.5 32B, we identify a potential
architectural advantage in the instruction-tuned LLM. Mistral exhibits a
tempered lexical simplification strategy that enhances readability across a
suite of metrics and the simplification-specific formula SARI (mean 42.46),
while preserving human-level discourse with a BERTScore of 0.91. QWen also
attains enhanced readability performance, but its operational strategy shows a
disconnect in balancing between readability and accuracy, reaching a
statistically significantly lower BERTScore of 0.89. Additionally, a
comprehensive correlation analysis of 21 metrics spanning readability,
discourse fidelity, content safety, and underlying distributional measures for
mechanistic insights, confirms strong functional redundancies among five
readability indices. This empirical evidence tracks baseline performance of the
evolving LLMs for the task of text simplification, identifies the
instruction-tuned Mistral 24B for simplification, provides necessary heuristics
for metric selection, and points to lexical support as a primary
domain-adaptation issue for simplification.

</details>


### [26] [Iterative Layer-wise Distillation for Efficient Compression of Large Language Models](https://arxiv.org/abs/2511.05085)
*Grigory Kovalev,Mikhail Tikhomirov*

Main category: cs.CL

TL;DR: 本文探讨了大语言模型（LLMs）的蒸馏方法，旨在开发紧凑型高性能模型。


<details>
  <summary>Details</summary>
Motivation: 开发紧凑型高性能的大语言模型。

Method: 提出了一种基于ShortGPT的改进方法，通过迭代评估层的重要性。该方法在移除单个层时测量性能下降来评估重要性，并结合基于KL散度和均方误差的联合损失函数进行进一步训练。

Result: 在Qwen2.5-3B模型上的实验表明，层数从36减少到28（24.7亿参数）时，质量损失仅为9.7%；减少到24层时，质量损失为18%。中间的Transformer层对推理的贡献较小。

Conclusion: 迭代蒸馏和微调是有效的，该方法适用于资源受限的环境。

Abstract: This work investigates distillation methods for large language models (LLMs)
with the goal of developing compact models that preserve high performance.
Several existing approaches are reviewed, with a discussion of their respective
strengths and limitations. An improved method based on the ShortGPT approach
has been developed, building upon the idea of incorporating iterative
evaluation of layer importance. At each step, importance is assessed by
measuring performance degradation when individual layers are removed, using a
set of representative datasets. This process is combined with further training
using a joint loss function based on KL divergence and mean squared error.
Experiments on the Qwen2.5-3B model show that the number of layers can be
reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a
9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that
the middle transformer layers contribute less to inference, underscoring the
potential of the proposed method for creating efficient models. The results
demonstrate the effectiveness of iterative distillation and fine-tuning, making
the approach suitable for deployment in resource-limited settings.

</details>


### [27] [A Toolbox for Improving Evolutionary Prompt Search](https://arxiv.org/abs/2511.05120)
*Daniel Grießhaber,Maximilian Kimmich,Johannes Maucher,Ngoc Thang Vu*

Main category: cs.CL

TL;DR: 该论文提出了一种改进的进化提示优化方法，通过分解进化步骤、引入基于LLM的评估器、整合人工反馈以及开发高效评估策略来提高优化质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的进化提示优化方法缺乏鲁棒的操作符和高效的评估机制。

Method: 1. 将进化分解为不同的步骤以增强进化及其控制。
2. 引入基于LLM的评估器来验证进化。
3. 整合人工反馈以改进进化操作符。
4. 开发更高效的评估策略，在保持性能的同时减少计算开销。

Result: 方法显著提高了优化质量和效率。

Conclusion: 所提出的改进方法有效解决了现有进化提示优化方法的局限性，并为该领域的进一步研究提供了基础。

Abstract: Evolutionary prompt optimization has demonstrated effectiveness in refining
prompts for LLMs. However, existing approaches lack robust operators and
efficient evaluation mechanisms. In this work, we propose several key
improvements to evolutionary prompt optimization that can partially generalize
to prompt optimization in general: 1) decomposing evolution into distinct steps
to enhance the evolution and its control, 2) introducing an LLM-based judge to
verify the evolutions, 3) integrating human feedback to refine the evolutionary
operator, and 4) developing more efficient evaluation strategies that maintain
performance while reducing computational overhead. Our approach improves both
optimization quality and efficiency. We release our code, enabling prompt
optimization on new tasks and facilitating further research in this area.

</details>


### [28] [ManufactuBERT: Efficient Continual Pretraining for Manufacturing](https://arxiv.org/abs/2511.05135)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: 本文介绍了ManufactuBERT，一个在制造业领域特定语料库上持续预训练的RoBERTa模型，该模型通过精心去重的数据集，不仅在制造业相关NLP任务上取得了最先进的性能，还将训练时间和计算成本降低了33%。


<details>
  <summary>Details</summary>
Motivation: 大型通用Transformer编码器在制造业等专业领域表现不佳，因为它们缺乏领域特定术语和语义的经验，本文旨在解决这一空白。

Method: 本文引入了ManufactuBERT，一个在制造业领域特定大规模语料库上持续预训练的RoBERTa模型。该语料库通过一个全面的数据处理流程创建，包括领域特定过滤和多阶段去重。

Result: ManufactuBERT在一系列制造业相关的NLP任务上取得了最先进的性能，超越了强大的专业基线。在精心去重后的语料库上训练，收敛速度显著加快，训练时间和计算成本降低了33%。

Conclusion: 本文提出的流水线为在其他专业领域开发高性能编码器提供了一个可复现的范例。

Abstract: While large general-purpose Transformer-based encoders excel at general
language understanding, their performance diminishes in specialized domains
like manufacturing due to a lack of exposure to domain-specific terminology and
semantics. In this paper, we address this gap by introducing ManufactuBERT, a
RoBERTa model continually pretrained on a large-scale corpus curated for the
manufacturing domain. We present a comprehensive data processing pipeline to
create this corpus from web data, involving an initial domain-specific
filtering step followed by a multi-stage deduplication process that removes
redundancies. Our experiments show that ManufactuBERT establishes a new
state-of-the-art on a range of manufacturing-related NLP tasks, outperforming
strong specialized baselines. More importantly, we demonstrate that training on
our carefully deduplicated corpus significantly accelerates convergence,
leading to a 33\% reduction in training time and computational cost compared to
training on the non-deduplicated dataset. The proposed pipeline offers a
reproducible example for developing high-performing encoders in other
specialized domains. We will release our model and curated corpus at
https://huggingface.co/cea-list-ia.

</details>


### [29] [Effectiveness of Chain-of-Thought in Distilling Reasoning Capability from Large Language Models](https://arxiv.org/abs/2511.05184)
*Cong-Thanh Do,Rama Doddipatla,Kate Knill*

Main category: cs.CL

TL;DR: 本文探讨了CoT在白盒知识蒸馏中对LLMs的推理能力迁移的作用，发现CoT能有效提高小模型在自然语言推理和理解任务上的表现。


<details>
  <summary>Details</summary>
Motivation: CoT提示在提高大型语言模型（LLMs）的推理能力方面被广泛应用，并且最近被用于知识蒸馏（KD），以将推理能力从大型LLM转移到小型LLM。本文旨在通过白盒KD，利用CoT数据，研究CoT在将推理能力从大型LLM蒸馏到小型LLM中的作用及其有效性。

Method: 本文使用Qwen和Llama2系列的LLM进行白盒知识蒸馏实验，并采用来自CoT-Collection数据集的CoT数据。蒸馏后的模型在BIG-Bench-Hard（BBH）基准测试中的自然语言推理和理解任务上进行评估。

Result: 实验结果表明，CoT在提高白盒KD的有效性方面发挥了作用，使得蒸馏后的模型在BBH的自然语言推理和理解任务中取得了更好的平均性能。

Conclusion: CoT能够显著提升白盒知识蒸馏的有效性，从而使小型LLM在复杂的自然语言推理和理解任务中表现出更好的性能。

Abstract: Chain-of-Thought (CoT) prompting is a widely used method to improve the
reasoning capability of Large Language Models (LLMs). More recently, CoT has
been leveraged in Knowledge Distillation (KD) to transfer reasoning capability
from a larger LLM to a smaller one. This paper examines the role of CoT in
distilling the reasoning capability from larger LLMs to smaller LLMs using
white-box KD, analysing its effectiveness in improving the performance of the
distilled models for various natural language reasoning and understanding
tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2
families, employing CoT data from the CoT-Collection dataset. The distilled
models are then evaluated on natural language reasoning and understanding tasks
from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for
smaller LLMs. Experimental results demonstrate the role of CoT in improving
white-box KD effectiveness, enabling the distilled models to achieve better
average performance in natural language reasoning and understanding tasks from
BBH.

</details>


### [30] [Translation via Annotation: A Computational Study of Translating Classical Chinese into Japanese](https://arxiv.org/abs/2511.05239)
*Zilong Li,Jie Cao*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种将古汉语翻译成日语的序列标注方法。


<details>
  <summary>Details</summary>
Motivation: 古人将古汉语翻译成日语时，会对每个字进行标注。作者将这个过程抽象为序列标注任务，并将其融入现代语言技术中。

Method: 通过引入基于LLM（大型语言模型）的标注流程，并从数字化的开源翻译数据构建了一个新的数据集，解决了低资源问题。在低资源环境下，引入辅助性的中文自然语言处理任务对序列标注任务的训练有促进作用。

Result: 在直接机器翻译中，大型语言模型取得了高分，但在对字符进行标注时表现不佳。本文提出的方法可以作为大型语言模型的补充。

Conclusion: 本文提出了一种针对古汉语到日语的序列标注方法，在低资源环境下，辅助性的中文NLP任务对训练有促进作用，并且该方法可以弥补大型语言模型在字符标注方面的不足。

Abstract: Ancient people translated classical Chinese into Japanese by annotating
around each character. We abstract this process as sequence tagging tasks and
fit them into modern language technologies. The research of this annotation and
translation system is a facing low-resource problem. We release this problem by
introducing a LLM-based annotation pipeline and construct a new dataset from
digitalized open-source translation data. We show that under the low-resource
setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the
training of sequence tagging tasks. We also evaluate the performance of large
language models. They achieve high scores in direct machine translation, but
they are confused when being asked to annotate characters. Our method could
work as a supplement of LLMs.

</details>


### [31] [Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models](https://arxiv.org/abs/2511.05286)
*Teqi Hao,Xioayu Tan,Shaojie Shi,Yinghui Xu,Xihe Qiu*

Main category: cs.CL

TL;DR: 该论文提出了一种名为RPO的新型个性化框架，通过将内容生成和个性化对齐解耦，显著优于现有的个性化黑盒大型语言模型的方法，并在LaMP基准测试中取得了最先进的结果，为以用户为中心的生成场景提供了一个高效且与模型无关的个性化层。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型个性化方法主要依赖于上下文注入，在生成准确内容的同时满足用户特定风格，但这会牺牲输出质量并限制精确控制。

Method: RPO框架将内容生成与个性化对齐解耦，分为两个阶段：首先，基础模型生成高质量的通用响应；然后，外部反射模块根据用户偏好重写输出。反射模块通过两阶段训练：首先是结构化重写轨迹的监督微调，建立核心个性化推理策略；其次是应用强化学习来优化个性化输出质量。

Result: 在LaMP基准测试上的综合实验表明，RPO显著优于最先进的基线。RPO引入了一个高效、与模型无关的个性化层，可以无缝集成到任何基础模型中。

Conclusion: RPO框架通过解耦内容生成和个性化，并通过两阶段训练的反射模块进行显式响应塑造，克服了现有方法的局限性，提供了一种更高效、更精确的个性化大型语言模型的新范式。

Abstract: The personalization of black-box large language models (LLMs) is a critical
yet challenging task. Existing approaches predominantly rely on context
injection, where user history is embedded into the prompt to directly guide the
generation process. However, this single-step paradigm imposes a dual burden on
the model: generating accurate content while simultaneously aligning with
user-specific styles. This often results in a trade-off that compromises output
quality and limits precise control. To address this fundamental tension, we
propose Reflective Personalization Optimization (RPO), a novel framework that
redefines the personalization paradigm by decoupling content generation from
alignment. RPO operates in two distinct stages: first, a base model generates a
high-quality, generic response; then, an external reflection module explicitly
rewrites this output to align with the user's preferences. This reflection
module is trained using a two-stage process. Initially, supervised fine-tuning
is employed on structured rewriting trajectories to establish a core
personalized reasoning policy that models the transformation from generic to
user-aligned responses. Subsequently, reinforcement learning is applied to
further refine and enhance the quality of the personalized outputs.
Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by
decoupling content generation from personalization, significantly outperforms
state-of-the-art baselines. These findings underscore the superiority of
explicit response shaping over implicit context injection. Moreover, RPO
introduces an efficient, model-agnostic personalization layer that can be
seamlessly integrated with any underlying base model, paving the way for a new
and effective direction in user-centric generation scenarios.

</details>


### [32] [What Are the Facts? Automated Extraction of Court-Established Facts from Criminal-Court Opinions](https://arxiv.org/abs/2511.05320)
*Klára Bendová,Tomáš Knap,Jan Černý,Vojtěch Pour,Jaromir Savelka,Ivana Kvapilíková,Jakub Drápal*

Main category: cs.CL

TL;DR: 本文探讨了从斯洛伐克法院判决书中提取犯罪行为描述的可行性，通过比较正则表达式和大型语言模型（LLM）的方法，发现高级正则表达式和LLM在准确性上均远超基线方法。


<details>
  <summary>Details</summary>
Motivation: 犯罪司法行政数据中关于犯罪行为的信息有限，而欧洲大陆法院判决书中的犯罪行为描述是一个未被利用的信息源。

Method: 研究采用了两种方法：正则表达式和大型语言模型（LLM）。正则表达式方法包括：1. 基线方法：使用典型词识别描述。2. 高级正则表达式：聚焦于“sparing”及其规范化。LLM方法：使用Gemini Flash 2.0模型，通过预定义指令提取描述。

Result: 1. 基线方法识别描述的准确率为40.5%。2. 高级正则表达式和LLM的表现显著优于基线，分别达到97%和98.75%。3. 结合使用高级正则表达式和LLM时，准确率达到99.5%。4. 法律学生评估显示，高级正则表达式和LLM在约90%的案例中与人工标注匹配，而基线方法仅为34.5%。5. LLM在91.75%的实例中完全匹配人工标注的描述，结合高级正则表达式和LLM达到92%。

Conclusion: 从斯洛伐克法院判决书中提取犯罪行为描述是可行的，高级正则表达式和大型语言模型（特别是结合使用时）在准确性和与人类标注的一致性方面表现出色。

Abstract: Criminal justice administrative data contain only a limited amount of
information about the committed offense. However, there is an unused source of
extensive information in continental European courts' decisions: descriptions
of criminal behaviors in verdicts by which offenders are found guilty. In this
paper, we study the feasibility of extracting these descriptions from publicly
available court decisions from Slovakia. We use two different approaches for
retrieval: regular expressions and large language models (LLMs). Our baseline
was a simple method employing regular expressions to identify typical words
occurring before and after the description. The advanced regular expression
approach further focused on "sparing" and its normalization (insertion of
spaces between individual letters), typical for delineating the description.
The LLM approach involved prompting the Gemini Flash 2.0 model to extract the
descriptions using predefined instructions. Although the baseline identified
descriptions in only 40.5% of verdicts, both methods significantly outperformed
it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and
99.5% when combined. Evaluation by law students showed that both advanced
methods matched human annotations in about 90% of cases, compared to just 34.5%
for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of
instances, and a combination of advanced regular expressions with LLMs reached
92%.

</details>


### [33] [Evaluating Subword Tokenization Techniques for Bengali: A Benchmark Study with BengaliBPE](https://arxiv.org/abs/2511.05324)
*Firoj Ahmmed Patwary,Abdullah Al Noman*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为BengaliBPE的BPE分词器，专门用于孟加拉语，解决了现有分词器在处理形态丰富的语言时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的子词分词器（如SentencePiece或HuggingFace BPE）主要为拉丁语或多语言语料库设计，在处理形态丰富的语言（如孟加拉语）时表现不佳。

Method: BengaliBPE采用Unicode标准化、字素级初始化和形态感知的合并规则，以保持语言一致性并保留子词的完整性。作者使用一个大规模的孟加拉语新闻分类数据集，将BengaliBPE与Whitespace、SentencePiece BPE和HuggingFace BPE三种基线方法进行比较，评估了分词粒度、编码速度和下游分类准确性。

Result: 所有方法都表现良好，但BengaliBPE提供了最详细的分割和最佳的形态可解释性，尽管计算成本略高。

Conclusion: 这些发现强调了语言感知分词对于形态丰富的语言的重要性，并确立了BengaliBPE作为未来孟加拉语NLP系统（包括上下文语言模型的大规模预训练）的强大基础。

Abstract: Tokenization is an important first step in Natural Language Processing (NLP)
pipelines because it decides how models learn and represent linguistic
information. However, current subword tokenizers like SentencePiece or
HuggingFace BPE are mostly designed for Latin or multilingual corpora and do
not perform well on languages with rich morphology such as Bengali. To address
this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer
specifically developed for the Bengali script. BengaliBPE applies Unicode
normalization, grapheme-level initialization, and morphology-aware merge rules
to maintain linguistic consistency and preserve subword integrity. We use a
large-scale Bengali news classification dataset to compare BengaliBPE with
three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The
evaluation considers tokenization granularity, encoding speed, and downstream
classification accuracy. While all methods perform reasonably well, BengaliBPE
provides the most detailed segmentation and the best morphological
interpretability, albeit with slightly higher computational cost. These
findings highlight the importance of language-aware tokenization for
morphologically rich scripts and establish BengaliBPE as a strong foundation
for future Bengali NLP systems, including large-scale pretraining of contextual
language models.

</details>


### [34] [Minority-Aware Satisfaction Estimation in Dialogue Systems via Preference-Adaptive Reinforcement Learning](https://arxiv.org/abs/2511.05407)
*Yahui Fu,Zi Haur Pang,Tatsuya Kawahara*

Main category: cs.CL

TL;DR: 本文提出了一个统一的框架，通过CoPeR和M2PC算法，结合个体和群体偏好，优化对话系统中用户满意度估计。


<details>
  <summary>Details</summary>
Motivation: 现有对话系统在用户满意度评估中普遍存在“一刀切”问题，忽略了少数用户群体的异质性和个体偏好，导致少数用户满意度评估不准确。

Method: 1. 提出CoPeR（Chain-of-Personalized-Reasoning）来捕捉个体偏好，通过可解释的推理链。2. 提出M2PC（Majority-Minority Preference-Aware Clustering）算法，通过无监督方式发现不同的用户群体，以学习群体层面的偏好。3. 将CoPeR和M2PC集成到PAda-PPO（Preference-Adaptive Reinforcement Learning）框架中，共同优化个体和群体偏好。

Result: 在情感支持对话数据集上的实验表明，该方法在用户满意度估计方面，特别是对于代表性不足的用户群体，表现出了持续的改进。

Conclusion: 本文提出的统一框架通过结合个体和群体偏好，显著提高了对话系统用户满意度估计的准确性，尤其解决了少数用户群体满意度评估的挑战。

Abstract: User satisfaction in dialogue systems is inherently subjective. When the same
response strategy is applied across users, minority users may assign different
satisfaction ratings than majority users due to variations in individual
intents and preferences. However, existing alignment methods typically train
one-size-fits-all models that aim for broad consensus, often overlooking
minority perspectives and user-specific adaptation. We propose a unified
framework that models both individual- and group-level preferences for user
satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning
(CoPeR) to capture individual preferences through interpretable reasoning
chains. Second, we propose an expectation-maximization-based Majority-Minority
Preference-Aware Clustering (M2PC) algorithm that discovers distinct user
groups in an unsupervised manner to learn group-level preferences. Finally, we
integrate these components into a preference-adaptive reinforcement learning
framework (PAda-PPO) that jointly optimizes alignment with both individual and
group preferences. Experiments on the Emotional Support Conversation dataset
demonstrate consistent improvements in user satisfaction estimation,
particularly for underrepresented user groups.

</details>


### [35] [Steering Language Models with Weight Arithmetic](https://arxiv.org/abs/2511.05408)
*Constanza Fierro,Fabien Roger*

Main category: cs.CL

TL;DR: 本文提出了一种对比权重转向方法，通过对模型参数进行权重算术编辑来更好地利用狭窄的训练数据，以期在不损害通用能力的情况下，减少LLMs的不良行为并提高性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在多样化训练数据上获取高质量反馈的困难和成本高昂，以及在狭窄分布上训练可能导致意外的泛化，促使研究者寻求一种方法，能够在有限数据下有效引导模型行为。

Method: 对比权重转向（contrastive weight steering），这是一种后训练方法。通过对两个小范围微调（一个诱导期望行为，另一个诱导相反行为）的权重增量进行相减，从而在权重空间中分离出一个行为方向。然后，通过添加或移除该方向来修改模型权重。

Result: 与激活转向相比，权重转向在泛化性上表现更优，在不损害通用能力的前提下，实现了更强的OOD行为控制。在任务特定的微调中，权重转向能部分缓解不良行为漂移（如减少谄媚和不足的拒绝），同时保持任务性能提升。此外，本文初步证据表明，通过测量微调更新与“邪恶”权重方向的相似性，可以检测到紧急失调，这为在训练过程中监测权重演变和检测罕见失调行为提供了可能。

Conclusion: 对比权重转向是一种有效的方法，可以在有效利用有限训练数据的前提下，减少大型语言模型的不良行为，提高模型性能，并有望实现对模型对齐状态的实时监控。

Abstract: Providing high-quality feedback to Large Language Models (LLMs) on a diverse
training distribution can be difficult and expensive, and providing feedback
only on a narrow distribution can result in unintended generalizations. To
better leverage narrow training data, we propose contrastive weight steering, a
simple post-training method that edits the model parameters using weight
arithmetic. We isolate a behavior direction in weight-space by subtracting the
weight deltas from two small fine-tunes -- one that induces the desired
behavior and another that induces its opposite -- and then add or remove this
direction to modify the model's weights. We apply this technique to mitigate
sycophancy and induce misalignment, and find that weight steering often
generalizes further than activation steering, achieving stronger
out-of-distribution behavioral control before degrading general capabilities.
We also show that, in the context of task-specific fine-tuning, weight steering
can partially mitigate undesired behavioral drift: it can reduce sycophancy and
under-refusals introduced during fine-tuning while preserving task performance
gains. Finally, we provide preliminary evidence that emergent misalignment can
be detected by measuring the similarity between fine-tuning updates and an
"evil" weight direction, suggesting that it may be possible to monitor the
evolution of weights during training and detect rare misaligned behaviors that
never manifest during training or evaluations.

</details>


### [36] [MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis](https://arxiv.org/abs/2511.05485)
*Yuexin Wu,Shiqi Wang,Vasile Rus*

Main category: cs.CL

TL;DR: 该研究引入了MIMIC-SR-ICD11数据集，并提出了LL-Rank重排序框架，以提高疾病诊断的准确性。LL-Rank通过去除标签频率偏差，在多个模型上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现代医疗保健以疾病诊断为核心，旨在早期发现、及时干预，并指导生活方式调整和用药，以预防或减缓慢性病发展。尤其在微妙但重要的细节方面，电子健康记录（EHR）有时会忽视或遗漏临床相关信息，而自我报告则能保留这些重要信号。

Method: 1. 构建MIMIC-SR-ICD11数据集：一个大型英语诊断数据集，由EHR出院记录构建，并与WHO ICD-11术语进行本地对齐。2. 提出LL-Rank框架：一个基于可能性的重排序框架，该框架计算给定临床报告上下文的每个标签的长度归一化联合可能性，并减去该标签对应的无报告先验可能性。它主要通过PMI（Pointwise Mutual Information）得分来隔离语义兼容性，从而去除标签频率偏差。

Result: 在七个模型骨干上，LL-Rank始终优于强大的生成加映射基线（GenMap）。消融实验表明，LL-Rank的性能提升主要来自于其基于PMI的评分，能够有效隔离语义兼容性与标签频率偏差。

Conclusion: 本研究通过引入MIMIC-SR-ICD11数据集和LL-Rank框架，显著提升了疾病诊断的准确性，尤其是在处理细微但关键的临床信息方面。LL-Rank的PMI评分机制有效解决了传统方法中存在的标签频率偏差问题，使其在多个模型上的表现优于现有基线。

Abstract: Disease diagnosis is a central pillar of modern healthcare, enabling early
detection and timely intervention for acute conditions while guiding lifestyle
adjustments and medication regimens to prevent or slow chronic disease.
Self-reports preserve clinically salient signals that templated electronic
health record (EHR) documentation often attenuates or omits, especially subtle
but consequential details. To operationalize this shift, we introduce
MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge
notes and natively aligned to WHO ICD-11 terminology. We further present
LL-Rank, a likelihood-based re-ranking framework that computes a
length-normalized joint likelihood of each label given the clinical report
context and subtracts the corresponding report-free prior likelihood for that
label. Across seven model backbones, LL-Rank consistently outperforms a strong
generation-plus-mapping baseline (GenMap). Ablation experiments show that
LL-Rank's gains primarily stem from its PMI-based scoring, which isolates
semantic compatibility from label frequency bias.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [37] [Communication-Constrained Private Decentralized Online Personalized Mean Estimation](https://arxiv.org/abs/2511.04702)
*Yauhen Yakimenka,Hsuan-Yin Lin,Eirik Rosnes,Jörg Kliewer*

Main category: cs.SI

TL;DR: 本文研究了在通信受限和隐私保护的条件下，多个智能体协作进行个性化均值估计的问题。


<details>
  <summary>Details</summary>
Motivation: 在多个智能体持续接收数据且数据分布未知的情况下，需要解决通信受限和隐私保护下的协作个性化均值估计问题。

Method: 本文提出并研究了一种基于共识的算法，该算法在差分隐私框架下运行，以保护每个智能体的数据。

Result: 理论分析表明，在一定的隐私级别和智能体连接性限制下，以及在预言机决策规则下，所提出的协作算法比完全本地方法具有更快的收敛速度。数值结果也支持了这一理论。

Conclusion: 在通信受限的在线环境中，通过私有协作可以实现比完全本地方法更快的收敛速度，从而证明了其在个性化均值估计中的优势。

Abstract: We consider the problem of communication-constrained collaborative
personalized mean estimation under a privacy constraint in an environment of
several agents continuously receiving data according to arbitrary unknown
agent-specific distributions. A consensus-based algorithm is studied under the
framework of differential privacy in order to protect each agent's data. We
give a theoretical convergence analysis of the proposed consensus-based
algorithm for any bounded unknown distributions on the agents' data, showing
that collaboration provides faster convergence than a fully local approach
where agents do not share data, under an oracle decision rule and under some
restrictions on the privacy level and the agents' connectivity, which
illustrates the benefit of private collaboration in an online setting under a
communication restriction on the agents. The theoretical faster-than-local
convergence guarantee is backed up by several numerical results.

</details>


### [38] [NCSAC: Effective Neural Community Search via Attribute-augmented Conductance](https://arxiv.org/abs/2511.04712)
*Longlong Lin,Quanao Li,Miao Qiao,Zeli Wang,Jin Zhao,Rong-Hua Li,Xin Luo,Tao Jia*

Main category: cs.SI

TL;DR: 这篇论文介绍了一种名为NCSAC的新型神经社区搜索方法，它通过结合规则约束与深度学习来改进社区搜索的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的社区搜索方法要么完全依赖基于规则的约束，要么完全利用深度学习技术。这篇论文旨在解决一个重要问题：深度学习能否与基于规则的约束相结合以提升社区搜索的质量？

Method: NCSAC首先提出了属性增强电导这一新概念，将结构接近度和属性相似性融合在一起。然后，它使用属性增强电导提取一个粗略的候选社区。最后，NCSAC将社区搜索构架为一个图优化任务，通过强化学习技术优化候选社区。

Result: 在六个真实世界图和十个竞争对手上的大量实验表明，NCSAC在准确性、效率和可扩展性方面优于现有解决方案。与最先进的方法相比，F1-score的改进范围从5.3%到42.4%。

Conclusion: NCSAC成功地将深度学习与规则约束相结合，显著提高了社区搜索的质量，并在准确性、效率和可扩展性方面表现出色。

Abstract: Identifying locally dense communities closely connected to the user-initiated
query node is crucial for a wide range of applications. Existing approaches
either solely depend on rule-based constraints or exclusively utilize deep
learning technologies to identify target communities. Therefore, an important
question is proposed: can deep learning be integrated with rule-based
constraints to elevate the quality of community search? In this paper, we
affirmatively address this question by introducing a novel approach called
Neural Community Search via Attribute-augmented Conductance, abbreviated as
NCSAC. Specifically, NCSAC first proposes a novel concept of
attribute-augmented conductance, which harmoniously blends the (internal and
external) structural proximity and the attribute similarity. Then, NCSAC
extracts a coarse candidate community of satisfactory quality using the
proposed attribute-augmented conductance. Subsequently, NCSAC frames the
community search as a graph optimization task, refining the candidate community
through sophisticated reinforcement learning techniques, thereby producing
high-quality results. Extensive experiments on six real-world graphs and ten
competitors demonstrate the superiority of our solutions in terms of accuracy,
efficiency, and scalability. Notably, the proposed solution outperforms
state-of-the-art methods, achieving an impressive F1-score improvement ranging
from 5.3\% to 42.4\%. For reproducibility purposes, the source code is
available at https://github.com/longlonglin/ncsac.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [39] [TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems](https://arxiv.org/abs/2511.05269)
*Ishan Kavathekar,Hemang Jain,Ameya Rathod,Ponnurangam Kumaraguru,Tanuja Ganu*

Main category: cs.MA

TL;DR: 该论文介绍了TAMAS，一个用于评估多智能体LLM系统鲁棒性和安全性的基准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在工具使用、规划和决策方面表现出强大的能力，这导致它们在各种任务中被广泛采用。随着任务复杂度的增长，多智能体LLM系统被越来越多地用于协作解决问题。然而，这些系统的安全性和安全性在很大程度上还未被充分探索。现有的基准和数据集主要关注单智能体设置，未能捕捉多智能体动态和协调的独特漏洞。

Method: 为了解决这个问题，我们引入了多智能体系统中的威胁和攻击（TAMAS），这是一个旨在评估多智能体LLM系统鲁棒性和安全性的基准。TAMAS包括五个不同的场景，包含300个对抗性实例，涵盖六种攻击类型和211个工具，以及100个无害任务。我们评估了十个骨干LLM和来自Autogen和CrewAI框架的三个智能体交互配置的系统性能，突出了当前多智能体部署中的关键挑战和故障模式。此外，我们引入了有效鲁棒性得分（ERS）来评估这些框架的安全性和任务有效性之间的权衡。

Result: 我们的研究结果表明，多智能体系统极易受到对抗性攻击。

Conclusion: TAMAS为系统地研究和改进多智能体LLM系统的安全性奠定了基础，强调了加强防御的紧迫性。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities as
autonomous agents through tool use, planning, and decision-making abilities,
leading to their widespread adoption across diverse tasks. As task complexity
grows, multi-agent LLM systems are increasingly used to solve problems
collaboratively. However, safety and security of these systems remains largely
under-explored. Existing benchmarks and datasets predominantly focus on
single-agent settings, failing to capture the unique vulnerabilities of
multi-agent dynamics and co-ordination. To address this gap, we introduce
$\textbf{T}$hreats and $\textbf{A}$ttacks in $\textbf{M}$ulti-$\textbf{A}$gent
$\textbf{S}$ystems ($\textbf{TAMAS}$), a benchmark designed to evaluate the
robustness and safety of multi-agent LLM systems. TAMAS includes five distinct
scenarios comprising 300 adversarial instances across six attack types and 211
tools, along with 100 harmless tasks. We assess system performance across ten
backbone LLMs and three agent interaction configurations from Autogen and
CrewAI frameworks, highlighting critical challenges and failure modes in
current multi-agent deployments. Furthermore, we introduce Effective Robustness
Score (ERS) to assess the tradeoff between safety and task effectiveness of
these frameworks. Our findings show that multi-agent systems are highly
vulnerable to adversarial attacks, underscoring the urgent need for stronger
defenses. TAMAS provides a foundation for systematically studying and improving
the safety of multi-agent LLM systems.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [40] [Adjoint and duality for rank-metric codes in a skew polynomial framework](https://arxiv.org/abs/2511.05084)
*José Gómez-Torrecillas,F. J. Lobillo,Gabriel Navarro,Paolo Santonastaso*

Main category: cs.IT

TL;DR: 本文对斜多项式环的商环中的转置和对偶操作进行了系统研究，并给出了转置和对偶码的斜多项式描述，从而确定了与Sheekey等人最近引入的MRD码族相关的伴随码和对偶码。在此基础上，本文计算了这些码的核参数，并证明了对于一组新的无限参数，许多MRD码与文献中以前已知的构造不等价。


<details>
  <summary>Details</summary>
Motivation: 斜多项式环的特殊商环产生了在秩度量码理论中起核心作用的矩阵代数，最近的突破表明，这些商环的特定子集产生了已知最大的最大秩距离（MRD）码族。

Method: 本文系统地研究了斜多项式环的商环中的转置和对偶操作。我们开发了转置和对偶码构造的显式斜多项式描述。

Result: 本文确定了与Sheekey等人最近引入的MRD码族相关的伴随码和对偶码，并计算了这些码的核参数。

Conclusion: 对于一组新的无限参数，许多MRD码与文献中以前已知的构造不等价。

Abstract: Skew polynomial rings provide a fundamental example of noncommutative
principal ideal domains. Special quotients of these rings yield matrix algebras
that play a central role in the theory of rank-metric codes. Recent
breakthroughs have shown that specific subsets of these quotients produce the
largest known families of maximum rank distance (MRD) codes. In this work, we
present a systematic study of transposition and duality operations within
quotients of skew polynomial rings. We develop explicit skew-polynomial
descriptions of the transpose and dual code constructions, enabling us to
determine the adjoint and dual codes associated with the MRD code families
recently introduced by Sheekey et al. Building on these results, we compute the
nuclear parameters of these codes, and prove that, for a new infinite set of
parameters, many of these MRD codes are inequivalent to previously known
constructions in the literature.

</details>


### [41] [Shortest self-orthogonal embeddings of binary linear codes](https://arxiv.org/abs/2511.05440)
*Junmin An,Nathan Kaplan,Jon-Lark Kim,Jinquan Luo,Guodong Wang*

Main category: cs.IT

TL;DR: 本文提出了一种利用线性码的hull性质确定最短自正交嵌入长度的方法，并以汉明码和Reed-Muller码为例进行了说明。


<details>
  <summary>Details</summary>
Motivation: 为了寻找最短的自正交嵌入，许多研究者已经开始关注二进制线性码的自正交嵌入，因为许多这样的码都是最优的自正交码。

Method: 1. 利用线性码的hull性质确定任意二进制线性码的最短自正交嵌入长度。 2. 详细探讨了汉明码和Reed-Muller码的例子。 3. 证明了二元汉明码的最短自正交嵌入是自对偶的。 4. 提出了两种从汉明码$\mathcal H_r$构造自对偶码的算法。 5. 利用线性码的最短自正交嵌入，获得了许多不同构的7维和8维最优自正交码。

Result: 1. 成功地从二进制$[15, 11, 3]$汉明码$\mathcal H_4$构造了一个自对偶$[22, 11, 6]$码（即缩短的Golay码）。 2. 成功地从二进制$[31, 26, 3]$汉明码$\mathcal H_5$构造了一个自对偶$[52, 26, 8]$码。 3. 构造了具有新参数的8维码，如$[91, 8, 42]$、$[98, 8, 46]$、$[114, 8, 54]$和$[191, 8, 94]$。

Conclusion: 本文提出了一种确定二进制线性码最短自正交嵌入长度的方法，并成功构建了多种自对偶码和具有新参数的最优自正交码。

Abstract: There has been recent interest in the study of shortest self-orthogonal
embeddings of binary linear codes, since many such codes are optimal
self-orthogonal codes. Several authors have studied the length of a shortest
self-orthogonal embedding of a given binary code $\mathcal C$, or equivalently,
the minimum number of columns that must be added to a generator matrix of
$\mathcal C$ to form a generator matrix of a self-orthogonal code. In this
paper, we use properties of the hull of a linear code to determine the length
of a shortest self-orthogonal embedding of any binary linear code. We focus on
the examples of Hamming codes and Reed-Muller codes. We show that a shortest
self-orthogonal embedding of a binary Hamming code is self-dual, and propose
two algorithms to construct self-dual codes from Hamming codes $\mathcal H_r$.
Using these algorithms, we construct a self-dual $[22, 11, 6]$ code, called the
shortened Golay code, from the binary $[15, 11, 3]$ Hamming code $\mathcal
H_4$, and construct a self-dual $[52, 26, 8]$ code from the binary $[31, 26,
3]$ Hamming code $\mathcal H_5$. We use shortest SO embeddings of linear codes
to obtain many inequivalent optimal self-orthogonal codes of dimension $7$ and
$8$ for several lengths. Four of the codes of dimension $8$ that we construct
are codes with new parameters such as $[91, 8, 42],\, [98, 8, 46],\,[114, 8,
54]$, and $[191, 8, 94]$.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [42] [Prototype Selection Using Topological Data Analysis](https://arxiv.org/abs/2511.04873)
*Jordan Eckert,Elvan Ceyhan,Henry Schenck*

Main category: stat.ML

TL;DR: 该文章提出了一种名为拓扑原型选择器（TPS）的基于拓扑数据分析（TDA）的框架，用于从大型数据集中选择具有代表性的子集（原型）。TPS在不同数据特性下的模拟数据集和真实数据集上均表现出卓越的性能，能够显著保持或提高分类性能，同时大幅减少数据量。


<details>
  <summary>Details</summary>
Motivation: 在大规模数据集中选择具有代表性的子集（原型），以捕获数据的结构和关系。

Method: 提出了一种名为拓扑原型选择器（TPS）的基于拓扑数据分析（TDA）的框架。该框架利用拓扑原理来表示数据，并选择具有代表性的子集（原型）。

Result: TPS在所有模拟和真实数据设置中，都能够显著保持或提高分类性能，同时大幅减少数据量。

Conclusion: TPS在原型学习的算法和几何方面都取得了进展，为并行化、可解释和高效的分类提供了实用工具。

Abstract: Recently, there has been an explosion in statistical learning literature to
represent data using topological principles to capture structure and
relationships. We propose a topological data analysis (TDA)-based framework,
named Topological Prototype Selector (TPS), for selecting representative
subsets (prototypes) from large datasets. We demonstrate the effectiveness of
TPS on simulated data under different data intrinsic characteristics, and
compare TPS against other currently used prototype selection methods in real
data settings. In all simulated and real data settings, TPS significantly
preserves or improves classification performance while substantially reducing
data size. These contributions advance both algorithmic and geometric aspects
of prototype learning and offer practical tools for parallelized,
interpretable, and efficient classification.

</details>


### [43] [Estimating Bidirectional Causal Effects with Large Scale Online Kernel Learning](https://arxiv.org/abs/2511.05050)
*Masahiro Tanaka*

Main category: stat.ML

TL;DR: 本文提出了一个可扩展的在线核学习框架，用于估计具有相互依赖和异方差性的系统中的双向因果效应，该框架结合了计量经济学识别和现代机器学习技术。


<details>
  <summary>Details</summary>
Motivation: 传统因果推断忽略了现实世界中常见的双向关系，而本研究旨在解决在相互依赖和异方差系统中估计双向因果效应的问题。

Method: 该方法在异方差性识别的基础上，将联立方程模型的准最大似然估计器与大规模在线核学习相结合。它采用随机傅里叶特征近似来灵活地建模非线性条件均值和方差，并通过自适应在线梯度下降算法确保计算效率。

Result: 广泛的模拟结果表明，该方法比单一方程和多项式近似基线具有更高的准确性和稳定性，在各种数据生成过程中表现出更低的偏差和均方根误差，并且计算量接近线性扩展。

Conclusion: 所提出的框架结合了计量经济学识别和现代机器学习技术，为自然/社会科学、政策制定、商业和工业应用中的大规模因果推断提供了一个实用、可扩展且有理论依据的解决方案，能够有效地捕捉复杂的双向因果效应。

Abstract: In this study, a scalable online kernel learning framework is proposed for
estimating bidirectional causal effects in systems characterized by mutual
dependence and heteroskedasticity. Traditional causal inference often focuses
on unidirectional effects, overlooking the common bidirectional relationships
in real-world phenomena. Building on heteroskedasticity-based identification,
the proposed method integrates a quasi-maximum likelihood estimator for
simultaneous equation models with large scale online kernel learning. It
employs random Fourier feature approximations to flexibly model nonlinear
conditional means and variances, while an adaptive online gradient descent
algorithm ensures computational efficiency for streaming and high-dimensional
data. Results from extensive simulations demonstrate that the proposed method
achieves superior accuracy and stability than single equation and polynomial
approximation baselines, exhibiting lower bias and root mean squared error
across various data-generating processes. These results confirm that the
proposed approach effectively captures complex bidirectional causal effects
with near-linear computational scaling. By combining econometric identification
with modern machine learning techniques, the proposed framework offers a
practical, scalable, and theoretically grounded solution for large scale causal
inference in natural/social science, policy making, business, and industrial
applications.

</details>


### [44] [A New Framework for Convex Clustering in Kernel Spaces: Finite Sample Bounds, Consistency and Performance Insights](https://arxiv.org/abs/2511.05159)
*Shubhayan Pan,Saptarshi Chakraborty,Debolina Paul,Kushal Bose,Swagatam Das*

Main category: stat.ML

TL;DR: 这篇论文提出了一种核化的凸聚类方法，可以处理线性不可分或非凸数据，并通过实验证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的凸聚类方法在处理线性不可分或非凸数据时会失效。

Method: 将数据点投影到再生核希尔伯特空间（RKHS），并在该空间中进行凸聚类，从而处理复杂的数据分布并生成有限维向量嵌入。

Result: 该方法在合成数据集和真实世界数据集上都表现出优于现有聚类技术的性能。

Conclusion: 核化的凸聚类方法为非线性非凸数据场景下的聚类问题提供了一种有效的解决方案。

Abstract: Convex clustering is a well-regarded clustering method, resembling the
similar centroid-based approach of Lloyd's $k$-means, without requiring a
predefined cluster count. It starts with each data point as its centroid and
iteratively merges them. Despite its advantages, this method can fail when
dealing with data exhibiting linearly non-separable or non-convex structures.
To mitigate the limitations, we propose a kernelized extension of the convex
clustering method. This approach projects the data points into a Reproducing
Kernel Hilbert Space (RKHS) using a feature map, enabling convex clustering in
this transformed space. This kernelization not only allows for better handling
of complex data distributions but also produces an embedding in a
finite-dimensional vector space. We provide a comprehensive theoretical
underpinnings for our kernelized approach, proving algorithmic convergence and
establishing finite sample bounds for our estimates. The effectiveness of our
method is demonstrated through extensive experiments on both synthetic and
real-world datasets, showing superior performance compared to state-of-the-art
clustering techniques. This work marks a significant advancement in the field,
offering an effective solution for clustering in non-linear and non-convex data
scenarios.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [45] [Stateful KV Cache Management for LLMs: Balancing Space, Time, Accuracy, and Positional Fidelity](https://arxiv.org/abs/2511.04686)
*Pratik Poudel*

Main category: cs.LG

TL;DR: 研究了大型语言模型（LLM）中KV缓存的增长对模型生成质量的影响。


<details>
  <summary>Details</summary>
Motivation: 探索KV缓存管理策略、模型架构上下文限制以及位置编码完整性之间的相互作用。

Method: 使用有状态基准测试框架进行实证分析。

Result: 当累积的KV缓存接近或超过模型的训练上下文窗口时，LLM生成质量会急剧下降。即使是高保留的逐出策略（如AttentionTop的99%）如果破坏了位置连贯性，也会恶化性能。保持连续上下文块的简单策略（例如保留最初的“要点”）可以比复杂或位置破坏性策略产生更连贯的生成。

Conclusion: 提出了一种新的KV缓存管理框架，该框架考虑了模型架构限制、位置编码完整性以及评估策略对最终生成质量的影响。主张采用尊重架构限制、保留位置结构并从整体角度看待“缓存健康”的逐出技术，而不仅仅是关注大小。

Abstract: The Key-Value (KV) cache is integral to efficient autoregressive inference in
large language models (LLMs), yet its unbounded growth in stateful multi-turn
scenarios presents major challenges. This paper examines the interplay between
KV cache management strategies, the architectural context limits of models like
meta-llama/Meta-Llama-3-8b-instruct, and the often-overlooked integrity of
positional encodings. Through empirical analysis using a stateful benchmarking
framework, we show that LLM generation quality degrades sharply when the
accumulated KV cache approaches or exceeds the model's trained context window
(e.g., 8192 tokens for Llama 3), a failure mode distinct from GPU memory
exhaustion. Common eviction strategies, even high-retention ones (e.g., 99% via
AttentionTop), can worsen performance if they disrupt positional coherence.
Because LLMs rely on consistent positional signals (e.g., RoPE), compacting a
cache by removing non-contiguous tokens can scramble these signals and lead to
degenerative outputs. We further show that simple strategies preserving
contiguous context blocks (e.g., keeping an initial "gist") can yield more
coherent generations than complex or positionally disruptive ones. We advocate
for eviction techniques that respect architectural limits, preserve positional
structure, and view "cache health" holistically beyond mere size.

</details>


### [46] [Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement Learning at the Hyperscale](https://arxiv.org/abs/2511.04904)
*Bassel Al Omari,Michael Matthews,Alexander Rutherford,Jakob Nicolaus Foerster*

Main category: cs.LG

TL;DR: Craftax-MA是Craftax的扩展版本，支持多智能体，并支持环境中的各种通用能力，且速度非常快。而Craftax-Coop则引入了异构智能体、交易和需要智能体之间复杂合作的更多机制，对现有算法提出了挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试往往只针对狭窄的短程挑战，不能充分强调许多多智能体系统中固有的长期依赖和泛化能力。

Method: 我们首先提出了Craftax-MA，它是流行的开放式RL环境Craftax的扩展，支持多个智能体，并在一个环境中评估各种通用能力。Craftax-MA用JAX编写，速度非常快。为了给MARL提供一个更具吸引力的挑战，我们还提出了Craftax-Coop，它引入了异构智能体、交易和需要智能体之间复杂合作的更多机制。

Result: 现有的算法在Craftax-MA基准测试中，在包括长期信用分配、探索和合作等关键挑战上表现不佳。

Conclusion: Craftax-MA和Craftax-Coop具有推动MARL领域长期研究的潜力。

Abstract: Progress in multi-agent reinforcement learning (MARL) requires challenging
benchmarks that assess the limits of current methods. However, existing
benchmarks often target narrow short-horizon challenges that do not adequately
stress the long-term dependencies and generalization capabilities inherent in
many multi-agent systems. To address this, we first present
\textit{Craftax-MA}: an extension of the popular open-ended RL environment,
Craftax, that supports multiple agents and evaluates a wide range of general
abilities within a single environment. Written in JAX, \textit{Craftax-MA} is
exceptionally fast with a training run using 250 million environment
interactions completing in under an hour. To provide a more compelling
challenge for MARL, we also present \textit{Craftax-Coop}, an extension
introducing heterogeneous agents, trading and more mechanics that require
complex cooperation among agents for success. We provide analysis demonstrating
that existing algorithms struggle with key challenges in this benchmark,
including long-horizon credit assignment, exploration and cooperation, and
argue for its potential to drive long-term research in MARL.

</details>


### [47] [Causal Structure and Representation Learning with Biomedical Applications](https://arxiv.org/abs/2511.04790)
*Caroline Uhler,Jiaqi Zhang*

Main category: cs.LG

TL;DR: 这篇论文概述了一个因果结构和表征学习的统计和计算框架，该框架利用多模态数据来应对生物医学中的基本问题。


<details>
  <summary>Details</summary>
Motivation: 表示学习在预测任务中取得了巨大成功，但在因果任务（如预测扰动/干预的影响）中却可能失败。这表明需要将表示学习与因果推理相结合。

Method: 本文概述了一个因果结构和表示学习的统计和计算框架。该框架利用多模态数据（观察数据和扰动数据、基于图像的数据和基于测序的数据，在单细胞、组织和有机体水平上）回答生物医学问题。

Result: 该框架旨在解决以下生物医学问题：如何有效利用观察和扰动数据对观察到的因果变量进行因果发现；如何利用系统的多模态视图学习因果变量；以及如何设计最佳扰动。

Conclusion: 通过结合表示学习和因果推理，并利用多模态数据，可以更好地理解复杂现象，并最终做出更好的决策。

Abstract: Massive data collection holds the promise of a better understanding of
complex phenomena and, ultimately, better decisions. Representation learning
has become a key driver of deep learning applications, as it allows learning
latent spaces that capture important properties of the data without requiring
any supervised annotations. Although representation learning has been hugely
successful in predictive tasks, it can fail miserably in causal tasks including
predicting the effect of a perturbation/intervention. This calls for a marriage
between representation learning and causal inference. An exciting opportunity
in this regard stems from the growing availability of multi-modal data
(observational and perturbational, imaging-based and sequencing-based, at the
single-cell level, tissue-level, and organism-level). We outline a statistical
and computational framework for causal structure and representation learning
motivated by fundamental biomedical questions: how to effectively use
observational and perturbational data to perform causal discovery on observed
causal variables; how to use multi-modal views of the system to learn causal
variables; and how to design optimal perturbations.

</details>


### [48] [Regularized GLISp for sensor-guided human-in-the-loop optimization](https://arxiv.org/abs/2511.04751)
*Matteo Cercola,Michele Lomuscio,Dario Piga,Simone Formentin*

Main category: cs.LG

TL;DR: 本文提出了GLISp的一种传感器引导的正则化扩展，该方法通过物理信息假设函数和最小二乘正则化项，将可测量的描述符集成到偏好学习循环中，从而在保持偏好搜索灵活性的同时，实现了更快收敛和更优的最终解。


<details>
  <summary>Details</summary>
Motivation: 传统的偏好优化方法（如Preferential Bayesian Optimization或GLISp）将系统视为黑盒，忽略了信息丰富的传感器测量。

Method: 本文提出了一种传感器引导的GLISp正则化扩展，通过物理信息假设函数和最小二乘正则化项，将可测量的描述符集成到偏好学习循环中。

Result: 在分析基准和人机交互车辆悬架调整任务的数值评估中，本文提出的方法与基线GLISp相比，显示出更快的收敛速度和更优的最终解决方案。

Conclusion: 本文通过引入传感器引导的正则化扩展，有效地将主观反馈与定量传感器信息结合起来，提高了偏好优化的效率和性能。

Abstract: Human-in-the-loop calibration is often addressed via preference-based
optimization, where algorithms learn from pairwise comparisons rather than
explicit cost evaluations. While effective, methods such as Preferential
Bayesian Optimization or Global optimization based on active preference
learning with radial basis functions (GLISp) treat the system as a black box
and ignore informative sensor measurements. In this work, we introduce a
sensor-guided regularized extension of GLISp that integrates measurable
descriptors into the preference-learning loop through a physics-informed
hypothesis function and a least-squares regularization term. This injects
grey-box structure, combining subjective feedback with quantitative sensor
information while preserving the flexibility of preference-based search.
Numerical evaluations on an analytical benchmark and on a human-in-the-loop
vehicle suspension tuning task show faster convergence and superior final
solutions compared to baseline GLISp.

</details>


### [49] [When Data Falls Short: Grokking Below the Critical Threshold](https://arxiv.org/abs/2511.04760)
*Vaibhav Singh,Eugene Belilovsky,Rahaf Aljundi*

Main category: cs.LG

TL;DR: 本文研究了在数据稀缺和分布变化环境下，通过知识蒸馏（KD）技术诱导和加速模型泛化（grokking）的现象。


<details>
  <summary>Details</summary>
Motivation: 在数据稀缺且分布不断变化的实际场景中，模型难以泛化，传统的监督学习方法可能失效。本文旨在探究知识蒸馏在这些场景下对模型泛化能力的影响。

Method: 1. 研究在数据量低于临界阈值时，从已在分布p1上泛化的模型进行知识蒸馏，是否能在不同分布p2上诱导和加速泛化。2. 研究在联合分布(p1, p2)上训练时，当任一分布数据不足时，从在个体分布上泛化的模型进行蒸馏，能否实现泛化。3. 考察持续预训练设置下，一个已泛化的模型从p1迁移到p2时，知识蒸馏如何加速泛化并减轻灾难性遗忘。

Result: 1. 即使可用数据低于临界阈值，知识蒸馏也能在不同分布p2上诱导和加速泛化。这强调了知识蒸馏对于需要适应有限数据下新分布的已部署模型的价值。2. 在联合分布上训练时，标准监督训练在数据不足时会失败，但从在个体分布上泛化的模型进行蒸馏可以实现泛化。3. 在持续预训练设置中，知识蒸馏既能加速泛化又能减轻灾难性遗忘，即使只有10%的数据也能获得良好性能。

Conclusion: 知识蒸馏在低数据量和不断变化的分布环境下，对于实现模型泛化（grokking）起着核心作用。本文结果为知识迁移下泛化的机制提供了新见解。

Abstract: In this paper, we investigate the phenomenon of grokking, where models
exhibit delayed generalization following overfitting on training data. We focus
on data-scarce regimes where the number of training samples falls below the
critical threshold, making grokking unobservable, and on practical scenarios
involving distribution shift. We first show that Knowledge Distillation (KD)
from a model that has already grokked on a distribution (p1) can induce and
accelerate grokking on a different distribution (p2), even when the available
data lies below the critical threshold. This highlights the value of KD for
deployed models that must adapt to new distributions under limited data. We
then study training on the joint distribution (p1, p2) and demonstrate that
while standard supervised training fails when either distribution has
insufficient data, distilling from models grokked on the individual
distributions enables generalization. Finally, we examine a continual
pretraining setup, where a grokked model transitions from p1 to p2, and find
that KD both accelerates generalization and mitigates catastrophic forgetting,
achieving strong performance even with only 10% of the data. Together, our
results provide new insights into the mechanics of grokking under knowledge
transfer and underscore the central role of KD in enabling generalization in
low-data and evolving distribution settings.

</details>


### [50] [Efficient Swap Multicalibration of Elicitable Properties](https://arxiv.org/abs/2511.04907)
*Lunjia Hu,Haipeng Luo,Spandan Senapati,Vatsal Sharan*

Main category: cs.LG

TL;DR: 本文提出了一种新的概念——交换多重校准，并提出了一种高效的算法，在在线预测中显著提高了多重校准的准确性。


<details>
  <summary>Details</summary>
Motivation: 探索多重校准与可启发性之间的联系，并解决当前多重校准算法存在效率低下的问题，尤其是在线设置中。

Method: 本文将可启发性质 \Gamma 的多重校准从群成员函数推广到任意有界假设类别，并引入了更强的概念——交换多重校准。提出了一种高效的算法，该算法在给定在线不可知学习器的访问权限时，以高概率实现了 $T^{1/(r+1)}$ 的 $\ell_r$-交换多重校准误差。

Result: 对于 $r \ge 2$ 的有界序列 Rademacher 复杂度的假设类别和可启发性质 \Gamma，该算法实现了 $T^{1/(r+1)}$ 的 $\ell_r$-交换多重校准误差。在 $r=2$ 的特殊情况下，实现了 $T^{1/3}$ 的 $\ell_2$-交换多重校准误差，这显著改善了现有算法的边界。

Conclusion: 本文通过引入交换多重校准和提出高效的在线算法，在解决多重校准问题上取得了重大进展，并对相关领域的一个开放问题给出了明确的肯定答案。

Abstract: Multicalibration [HJKRR18] is an algorithmic fairness perspective that
demands that the predictions of a predictor are correct conditional on
themselves and membership in a collection of potentially overlapping subgroups
of a population. The work of [NR23] established a surprising connection between
multicalibration for an arbitrary property $\Gamma$ (e.g., mean or median) and
property elicitation: a property $\Gamma$ can be multicalibrated if and only if
it is elicitable, where elicitability is the notion that the true property
value of a distribution can be obtained by solving a regression problem over
the distribution. In the online setting, [NR23] proposed an inefficient
algorithm that achieves $\sqrt T$ $\ell_2$-multicalibration error for a
hypothesis class of group membership functions and an elicitable property
$\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.
  In this paper, we generalize multicalibration for an elicitable property
$\Gamma$ from group membership functions to arbitrary bounded hypothesis
classes and introduce a stronger notion -- swap multicalibration, following
[GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when
given access to an online agnostic learner, achieves $T^{1/(r+1)}$
$\ell_r$-swap multicalibration error with high probability (for $r\ge2$) for a
hypothesis class with bounded sequential Rademacher complexity and an
elicitable property $\Gamma$. For the special case of $r=2$, this implies an
oracle-efficient algorithm that achieves $T^{1/3}$ $\ell_2$-swap
multicalibration error, which significantly improves on the previously
established bounds for the problem [NR23, GMS25, LSS25a], and completely
resolves an open question raised in [GJRR24] on the possibility of an
oracle-efficient algorithm that achieves $\sqrt{T}$ $\ell_2$-mean
multicalibration error by answering it in a strongly affirmative sense.

</details>


### [51] [FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep Learning on Streaming Dataflow](https://arxiv.org/abs/2511.04768)
*Rubens Lacouture,Nathan Zhang,Ritvik Sharma,Marco Siracusa,Fredrik Kjolstad,Kunle Olukotun,Olivia Hsu*

Main category: cs.LG

TL;DR: FuseFlow是一个编译器，可以将稀疏ML模型转换为用于RDA的融合稀疏数据流图，它支持跨表达式融合，是第一个支持稀疏操作通用跨表达式融合的编译器。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在稀疏计算和专用数据流硬件方面的效率问题。

Method: FuseFlow编译器支持跨内核（表达式）融合，并行化、数据流排序和稀疏性阻塞等优化，并针对循环精确数据流模拟器进行微架构分析。

Result: 通过对四种真实ML应用的设计空间探索，FuseFlow实现了性能提升，例如在GPT-3与BigBird块稀疏注意力模型上，相比未融合基线，获得了约2.7倍的加速。同时，FuseFlow还提供了一种启发式方法来识别和修剪次优配置。

Conclusion: FuseFlow编译器通过支持通用跨表达式融合、并行化、数据流排序和稀疏性阻塞等优化，在稀疏机器学习模型的硬件加速方面取得了显著的性能提升。但研究也表明，完全融合并非总是最优选择，融合粒度取决于模型本身。

Abstract: As deep learning models scale, sparse computation and specialized dataflow
hardware have emerged as powerful solutions to address efficiency. We propose
FuseFlow, a compiler that converts sparse machine learning models written in
PyTorch to fused sparse dataflow graphs for reconfigurable dataflow
architectures (RDAs). FuseFlow is the first compiler to support general
cross-expression fusion of sparse operations. In addition to fusion across
kernels (expressions), FuseFlow also supports optimizations like
parallelization, dataflow ordering, and sparsity blocking. It targets a
cycle-accurate dataflow simulator for microarchitectural analysis of fusion
strategies. We use FuseFlow for design-space exploration across four real-world
machine learning applications with sparsity, showing that full fusion (entire
cross-expression fusion across all computation in an end-to-end model) is not
always optimal for sparse models-fusion granularity depends on the model
itself. FuseFlow also provides a heuristic to identify and prune suboptimal
configurations. Using Fuseflow, we achieve performance improvements, including
a ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse
attention.

</details>


### [52] [Scaling Up ROC-Optimizing Support Vector Machines](https://arxiv.org/abs/2511.04979)
*Gimun Bae,Seung Jun Shin*

Main category: cs.LG

TL;DR: 这篇文章介绍了一种名为ROC-SVM的分类器，它可以直接最大化曲线下面积（AUC），解决了传统二分类在类别不平衡情况下效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: ROC-SVM在处理类别不平衡问题时表现良好，但其计算成本高昂，限制了实际应用。

Method: 本文提出了一种可扩展的ROC-SVM变体，利用不完全U统计量显著降低了计算复杂性。通过低秩核近似，将框架扩展到非线性分类，以在再现核希尔伯特空间中实现高效训练。

Result: 理论分析证明了该方法的误差界，并且在合成数据集和实际数据集上的实验结果表明，该方法在显著减少训练时间的同时，实现了与原始ROC-SVM相当的AUC性能。

Conclusion: 本文提出了一种可扩展的ROC-SVM变体，有效降低了计算成本，并扩展到非线性分类，在保持性能的同时大大提高了效率。

Abstract: The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the
area under the ROC curve (AUC) and has become an attractive alternative of the
conventional binary classification under the presence of class imbalance.
However, its practical use is limited by high computational cost, as training
involves evaluating all $O(n^2)$. To overcome this limitation, we develop a
scalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby
substantially reducing computational complexity. We further extend the
framework to nonlinear classification through a low-rank kernel approximation,
enabling efficient training in reproducing kernel Hilbert spaces. Theoretical
analysis establishes an error bound that justifies the proposed approximation,
and empirical results on both synthetic and real datasets demonstrate that the
proposed method achieves comparable AUC performance to the original ROC-SVM
with drastically reduced training time.

</details>


### [53] [Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement Learning with Online Interaction](https://arxiv.org/abs/2511.05396)
*Yiting He,Zhishuai Liu,Weixin Wang,Pan Xu*

Main category: cs.LG

TL;DR: 本文研究了离线强化学习（RL），其中训练和部署的转换动力学不同。针对在线鲁棒马尔可夫决策过程（RMDP）中的探索挑战，作者引入了至高访问比，并提出了一种计算高效的算法，实现了次线性遗憾，并在理论和实验上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在离线强化学习（RL）中，训练和部署的转换动力学不同，这可以通过在鲁棒马尔可夫决策过程（RMDP）中学习来解决。现有研究大多假设可以访问生成模型或预收集的数据集，忽略了探索的挑战。本文旨在研究智能体在线交互的训练环境，这是一种更现实和具有挑战性的环境。

Method: 为了量化在线RMDP中探索的内在难度，本文引入了至高访问比，这是一个衡量训练动力学和部署动力学之间不匹配度的新指标。本文提出了一种计算高效的算法，该算法在基于f-散度的转换不确定性的在线RMDP中实现了次线性遗憾。

Result: 本文证明了如果至高访问比无界，在线学习将变得指数级困难。作者提出的算法在在线RMDP中实现了次线性遗憾。本文还建立了匹配的遗憾下界，表明该算法在至高访问比和交互 episodios 数量上都达到了最优依赖。

Conclusion: 本文首次提出了一种计算高效的算法，用于解决在线RMDP中的探索挑战，并在理论和实验上验证了其有效性，为离线强化学习领域提供了新的视角和解决方案。

Abstract: Off-dynamics reinforcement learning (RL), where training and deployment
transition dynamics are different, can be formulated as learning in a robust
Markov decision process (RMDP) where uncertainties in transition dynamics are
imposed. Existing literature mostly assumes access to generative models
allowing arbitrary state-action queries or pre-collected datasets with a good
state coverage of the deployment environment, bypassing the challenge of
exploration. In this work, we study a more realistic and challenging setting
where the agent is limited to online interaction with the training environment.
To capture the intrinsic difficulty of exploration in online RMDPs, we
introduce the supremal visitation ratio, a novel quantity that measures the
mismatch between the training dynamics and the deployment dynamics. We show
that if this ratio is unbounded, online learning becomes exponentially hard. We
propose the first computationally efficient algorithm that achieves sublinear
regret in online RMDPs with $f$-divergence based transition uncertainties. We
also establish matching regret lower bounds, demonstrating that our algorithm
achieves optimal dependence on both the supremal visitation ratio and the
number of interaction episodes. Finally, we validate our theoretical results
through comprehensive numerical experiments.

</details>


### [54] [Synapse: Adaptive Arbitration of Complementary Expertise in Time Series Foundational Models](https://arxiv.org/abs/2511.05460)
*Sarkar Snigdha Sarathi Das,Palash Goyal,Mihir Parmar,Yiwen Song,Long T. Le,Lesly Miculicich,Jinsung Yoon,Rui Zhang,Hamid Palangi,Tomas Pfister*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为 Synapse 的新型仲裁框架，用于应对预训练时间序列基础模型 (TSFM) 在时间序列预测中表现差异大的问题。Synapse 通过动态地利用 TSFM 池，根据其相对和上下文相关的性能分配和调整预测权重，并通过自适应地从组成模型的输出分位数中抽样来构建稳健的预测分布。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练时间序列基础模型（TSFM）在预测各种时间序列方面取得了显著进步，但它们在不同预测任务、领域和时间范围内的表现差异很大。这种差异源于不同的训练协议和数据源。利用现有 TSFM 输出的互补专业知识进行仲裁是一种引人注目的策略，但目前在这方面的研究很少。

Method: 本文首先彻底检查了不同的 TSFM 如何在各种预测设置中表现出专门的性能特征，以及如何有效利用这种行为在不同时间序列模型之间进行仲裁。然后，文章分析了模型选择和预测范围分布等因素如何影响仲裁策略的有效性。在此基础上，提出了一种名为 Synapse 的新型仲裁框架。Synapse 能够动态地利用 TSFM 池，根据其相对的、上下文相关的性能分配和调整预测权重，并通过自适应地从组成模型的输出分位数中抽样来构建稳健的预测分布。

Result: 实验结果表明，Synapse 持续优于其他流行的集成技术以及单个 TSFM。

Conclusion: Synapse 框架通过有效整合多个 TSFM 的优势，显著提升了时间序列预测的准确性和鲁棒性。这篇论文介绍了一种名为 Synapse 的新型仲裁框架，用于应对预训练时间序列基础模型 (TSFM) 在时间序列预测中表现差异大的问题。Synapse 通过动态地利用 TSFM 池，根据其相对和上下文相关的性能分配和调整预测权重，并通过自适应地从组成模型的输出分位数中抽样来构建稳健的预测分布。性。

Abstract: Pre-trained Time Series Foundational Models (TSFMs) represent a significant
advance, capable of forecasting diverse time series with complex
characteristics, including varied seasonalities, trends, and long-range
dependencies. Despite their primary goal of universal time series forecasting,
their efficacy is far from uniform; divergent training protocols and data
sources cause individual TSFMs to exhibit highly variable performance across
different forecasting tasks, domains, and horizons. Leveraging this
complementary expertise by arbitrating existing TSFM outputs presents a
compelling strategy, yet this remains a largely unexplored area of research. In
this paper, we conduct a thorough examination of how different TSFMs exhibit
specialized performance profiles across various forecasting settings, and how
we can effectively leverage this behavior in arbitration between different time
series models. We specifically analyze how factors such as model selection and
forecast horizon distribution can influence the efficacy of arbitration
strategies. Based on this analysis, we propose Synapse, a novel arbitration
framework for TSFMs. Synapse is designed to dynamically leverage a pool of
TSFMs, assign and adjust predictive weights based on their relative,
context-dependent performance, and construct a robust forecast distribution by
adaptively sampling from the output quantiles of constituent models.
Experimental results demonstrate that Synapse consistently outperforms other
popular ensembling techniques as well as individual TSFMs, demonstrating
Synapse's efficacy in time series forecasting.

</details>


### [55] [On Flow Matching KL Divergence](https://arxiv.org/abs/2511.05480)
*Maojiang Su,Jerry Yao-Chieh Hu,Sophia Pi,Han Liu*

Main category: cs.LG

TL;DR: 本文对流匹配分布近似的Kullback-Leibler（KL）散度推导了一个确定性的非渐近上限。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对流匹配统计效率的理论保证，尤其是在KL散度方面。

Method: 通过假设$L_2$流匹配损失有界，推导了真实数据分布与估计分布之间KL散度的上限表达式。

Result: KL散度被限制在$A_1 \epsilon + A_2 \epsilon^2$的范围内，其中$A_1$和$A_2$仅依赖于数据和速度场的正则性。这表明流匹配在估计平滑分布方面达到了接近最优的统计效率。

Conclusion: 流匹配的统计效率与扩散模型在TV距离下相当，并且在数值研究中得到了验证。

Abstract: We derive a deterministic, non-asymptotic upper bound on the Kullback-Leibler
(KL) divergence of the flow-matching distribution approximation. In particular,
if the $L_2$ flow-matching loss is bounded by $\epsilon^2 > 0$, then the KL
divergence between the true data distribution and the estimated distribution is
bounded by $A_1 \epsilon + A_2 \epsilon^2$. Here, the constants $A_1$ and $A_2$
depend only on the regularities of the data and velocity fields. Consequently,
this bound implies statistical convergence rates of Flow Matching Transformers
under the Total Variation (TV) distance. We show that, flow matching achieves
nearly minimax-optimal efficiency in estimating smooth distributions. Our
results make the statistical efficiency of flow matching comparable to that of
diffusion models under the TV distance. Numerical studies on synthetic and
learned velocities corroborate our theory.

</details>


### [56] [PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via Sparse Expert Merging and Bit-packed inference](https://arxiv.org/abs/2511.04805)
*Yushu Zhao,Zheng Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: 本文介绍了一种名为 PuzzleMoE 的无训练 MoE 压缩方法，通过识别元素级权重冗余和专业化进行稀疏专家合并，并引入位打包编码方案以实现高效的 MoE 推理，从而在保持准确性的同时将 MoE 模型压缩高达 50%。


<details>
  <summary>Details</summary>
Motivation: MoE 模型在扩展语言模型方面表现出强大潜力，但由于存储所有专家参数的高内存开销，其广泛部署仍受限制。

Method: PuzzleMoE 是一种无训练的 MoE 压缩方法。它通过识别元素级权重冗余和专业化来执行稀疏专家合并，并使用双掩码来捕获共享参数和专家特定参数。此外，它引入了一种位打包编码方案，通过重用未充分利用的指数位来避免存储二进制掩码和符号的开销，从而在 GPU 上实现高效的 MoE 推理。

Result: PuzzleMoE 在各种任务中可将 MoE 模型压缩高达 50% 同时保持准确性。在 50% 压缩率下，它在 MMLU 上比之前的 MoE 压缩方法高出 16.7%，并实现了高达 1.28 倍的推理加速。

Conclusion: PuzzleMoE 通过稀疏专家合并和位打包编码，有效地解决了 MoE 模型的内存开销问题，并在高压缩率下保持了出色的性能和推理效率。

Abstract: Mixture-of-Experts (MoE) models have shown strong potential in scaling
language models efficiently by activating only a small subset of experts per
input. However, their widespread deployment remains limited due to the high
memory overhead associated with storing all expert parameters, particularly as
the number of experts increases. To address this challenge, prior works have
explored expert dropping and merging strategies, yet they often suffer from
performance drop at high compression ratios. In this paper, we introduce
PuzzleMoE, a training-free MoE compression method that achieves both high
accuracy and efficient inference through two key innovations: First, PuzzleMoE
performs sparse expert merging by identifying element-wise weight redundancy
and specialization. It uses a dual-mask to capture both shared and
expert-specific parameters. Second, to avoid the overhead of storing binary
masks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses
underutilized exponent bits, enabling efficient MoE inference on GPUs.
Extensive experiments demonstrate that PuzzleMoE can compress MoE models by up
to 50% while maintaining accuracy across various tasks. Specifically, it
outperforms prior MoE compression methods by up to 16.7% on MMLU at 50%
compression ratio, and achieves up to 1.28\times inference speedup.

</details>


### [57] [Autoencoding Dynamics: Topological Limitations and Capabilities](https://arxiv.org/abs/2511.04807)
*Matthew D. Kvalheim,Eduardo D. Sontag*

Main category: cs.LG

TL;DR: 本文探讨了自动编码器的拓扑限制和能力，特别是在处理作为不变流形的动态系统时的应用。


<details>
  <summary>Details</summary>
Motivation: 探索自动编码器在数据流形和潜在空间之间进行映射时的拓扑限制和能力。

Method: 通过分析编码器和解码器的连续映射，并关注“往返”映射D∘E与恒等映射idM之间的接近程度。

Result: 揭示了自动编码器在拓扑方面的局限性和潜力。

Conclusion: 自动编码器在处理具有不变流形的动态系统时具有潜在的能力，但也存在拓扑上的限制。

Abstract: Given a "data manifold" $M\subset \mathbb{R}^n$ and "latent space"
$\mathbb{R}^\ell$, an autoencoder is a pair of continuous maps consisting of an
"encoder" $E\colon \mathbb{R}^n\to \mathbb{R}^\ell$ and "decoder" $D\colon
\mathbb{R}^\ell\to \mathbb{R}^n$ such that the "round trip" map $D\circ E$ is
as close as possible to the identity map $\mbox{id}_M$ on $M$. We present
various topological limitations and capabilites inherent to the search for an
autoencoder, and describe capabilities for autoencoding dynamical systems
having $M$ as an invariant manifold.

</details>


### [58] [Sharp Minima Can Generalize: A Loss Landscape Perspective On Data](https://arxiv.org/abs/2511.04808)
*Raymond Fan,Bryce Sandlund,Lin Myat Ko*

Main category: cs.LG

TL;DR: 这篇论文探讨了深度学习中“体积假设”与“泛化”之间的关系，并强调了数据集大小在其中扮演的关键角色。


<details>
  <summary>Details</summary>
Motivation: 传统的“体积假设”认为模型的泛化能力来源于其能找到体积较大的平坦极小值。然而，这个假设无法解释大型数据集在泛化中的作用。

Method: 通过测量不同训练数据量下极小值的体积，作者发现存在泛化能力强的尖锐极小值，但由于其体积小而不易被找到。

Result: 增加数据量会改变损失函数地形，使得原本小的、泛化能力强的极小值变得（相对）较大。

Conclusion: 数据集大小对深度学习模型的泛化能力至关重要，它通过改变损失函数的几何特性，使模型更容易找到泛化能力强的极小值。

Abstract: The volume hypothesis suggests deep learning is effective because it is
likely to find flat minima due to their large volumes, and flat minima
generalize well. This picture does not explain the role of large datasets in
generalization. Measuring minima volumes under varying amounts of training data
reveals sharp minima which generalize well exist, but are unlikely to be found
due to their small volumes. Increasing data changes the loss landscape, such
that previously small generalizing minima become (relatively) large.

</details>


### [59] [A Standardized Benchmark for Multilabel Antimicrobial Peptide Classification](https://arxiv.org/abs/2511.04814)
*Sebastian Ojeda,Rafael Velasquez,Nicolás Aparicio,Juanita Puentes,Paula Cárdenas,Nicolás Andrade,Gabriel González,Sergio Rincón,Carolina Muñoz-Camargo,Pablo Arbeláez*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个名为ESCAPE的抗菌肽评估框架，它整合了大量数据并提出了一个基于Transformer的模型，用于预测肽的多种功能活性。


<details>
  <summary>Details</summary>
Motivation: 现有的抗菌肽研究存在数据碎片化、注释不一致和缺乏标准化基准等问题，阻碍了计算方法的发展和新抗菌肽的发现。

Method: 作者提出了ESCAPE框架，该框架整合了来自27个经过验证的存储库的80,000多种肽序列，并将抗菌肽与阴性序列分开，同时将功能注释整合到生物学上连贯的多标签层次结构中。在此基础上，作者提出了一个基于Transformer的模型，该模型利用序列和结构信息来预测肽的多种功能活性。

Result: 作者提出的方法在多标签肽分类任务中取得了显著的进展，相对于第二好的方法，平均精度（mean Average Precision）相对提高了2.56%，建立了新的多标签肽分类技术水平。

Conclusion: ESCAPE提供了一个全面且可重现的评估框架，以推动AI驱动的抗菌肽研究。

Abstract: Antimicrobial peptides have emerged as promising molecules to combat
antimicrobial resistance. However, fragmented datasets, inconsistent
annotations, and the lack of standardized benchmarks hinder computational
approaches and slow down the discovery of new candidates. To address these
challenges, we present the Expanded Standardized Collection for Antimicrobial
Peptide Evaluation (ESCAPE), an experimental framework integrating over 80.000
peptides from 27 validated repositories. Our dataset separates antimicrobial
peptides from negative sequences and incorporates their functional annotations
into a biologically coherent multilabel hierarchy, capturing activities across
antibacterial, antifungal, antiviral, and antiparasitic classes. Building on
ESCAPE, we propose a transformer-based model that leverages sequence and
structural information to predict multiple functional activities of peptides.
Our method achieves up to a 2.56% relative average improvement in mean Average
Precision over the second-best method adapted for this task, establishing a new
state-of-the-art multilabel peptide classification. ESCAPE provides a
comprehensive and reproducible evaluation framework to advance AI-driven
antimicrobial peptide research.

</details>


### [60] [Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.04834)
*Jiwoo Shin,Byeonghu Na,Mina Kang,Wonhyeok Choi,Il-chul Moon*

Main category: cs.LG

TL;DR: 这篇论文提出了一种通过概念反演获得的隐式负面嵌入来取代训练无关方法中使用的负面提示的方法。


<details>
  <summary>Details</summary>
Motivation: 目前的文本到图像生成模型在接收到恶意输入文本提示时，可能会生成有害内容。现有的两种主要方法（模型微调和训练无关的指导方法）在结合使用时效果不佳，甚至会降低防御性能。

Method: 本文提出了一种概念简单但实验结果稳健的方法：用通过概念反演获得的隐式负嵌入替换训练无关方法中使用的负提示。该方法无需修改现有方法，可以轻松集成到现有流程中。

Result: 在裸露和暴力基准测试中验证了该方法的有效性，证明在保持输入提示核心语义的同时，防御成功率得到了持续改进。

Conclusion: 这篇论文提出了一种新的方法，通过概念反演获得的隐式负面嵌入来取代训练无关方法中使用的负面提示，解决了现有两种防御方法结合使用时的兼容性问题，并在有害内容生成防御方面取得了显著的改进。

Abstract: Recent advances in text-to-image generative models have raised concerns about
their potential to produce harmful content when provided with malicious input
text prompts. To address this issue, two main approaches have emerged: (1)
fine-tuning the model to unlearn harmful concepts and (2) training-free
guidance methods that leverage negative prompts. However, we observe that
combining these two orthogonal approaches often leads to marginal or even
degraded defense performance. This observation indicates a critical
incompatibility between two paradigms, which hinders their combined
effectiveness. In this work, we address this issue by proposing a conceptually
simple yet experimentally robust method: replacing the negative prompts used in
training-free methods with implicit negative embeddings obtained through
concept inversion. Our method requires no modification to either approach and
can be easily integrated into existing pipelines. We experimentally validate
its effectiveness on nudity and violence benchmarks, demonstrating consistent
improvements in defense success rate while preserving the core semantics of
input prompts.

</details>


### [61] [Sublinear iterations can suffice even for DDPMs](https://arxiv.org/abs/2511.04844)
*Matthew S. Zhang,Stephen Huan,Jerry Huang,Nicholas M. Boffi,Sitan Chen,Sinho Chewi*

Main category: cs.LG

TL;DR: 本文分析了一种名为去噪扩散随机中点法（DDRaM）的新型积分器，它利用一个额外的随机中点来更好地近似SDE。


<details>
  <summary>Details</summary>
Motivation: DDPMs在真实样本生成任务中表现出色，但先前的分析集中于指数欧拉离散化，其保证通常至少线性依赖于维度或初始费雪信息。

Method: 设计了去噪扩散随机中点法（DDRaM），并利用“移位合成规则”的分析框架证明了次线性复杂度界限。

Result: 在适当的平滑假设下，该算法具有良好的离散化特性，通过$\\widetilde{O}(\\sqrt{d})$次分数评估即可保证收敛。这是纯DDPM采样的第一个次线性复杂度界限。

Conclusion: DDRaM方法在理论上和实践中都表现出优势，填补了DDPMs次线性复杂度界限的空白，并且在图像合成模型中表现良好。

Abstract: SDE-based methods such as denoising diffusion probabilistic models (DDPMs)
have shown remarkable success in real-world sample generation tasks. Prior
analyses of DDPMs have been focused on the exponential Euler discretization,
showing guarantees that generally depend at least linearly on the dimension or
initial Fisher information. Inspired by works in log-concave sampling (Shen and
Lee, 2019), we analyze an integrator -- the denoising diffusion randomized
midpoint method (DDRaM) -- that leverages an additional randomized midpoint to
better approximate the SDE. Using a recently-developed analytic framework
called the "shifted composition rule", we show that this algorithm enjoys
favorable discretization properties under appropriate smoothness assumptions,
with sublinear $\widetilde{O}(\sqrt{d})$ score evaluations needed to ensure
convergence. This is the first sublinear complexity bound for pure DDPM
sampling -- prior works which obtained such bounds worked instead with
ODE-based sampling and had to make modifications to the sampler which deviate
from how they are used in practice. We also provide experimental validation of
the advantages of our method, showing that it performs well in practice with
pre-trained image synthesis models.

</details>


### [62] [Investigating U.S. Consumer Demand for Food Products with Innovative Transportation Certificates Based on Stated Preferences and Machine Learning Approaches](https://arxiv.org/abs/2511.04845)
*Jingchen Bi,Rodrigo Mesa-Arango*

Main category: cs.LG

TL;DR: 这篇论文旨在使用机器学习模型来评估消费者在食品产品方面对创新运输证书的偏好，并为改善食品供应链系统提供数据驱动的建议。


<details>
  <summary>Details</summary>
Motivation: 以往的研究已经证明供应链的可追溯性对于食品消费者的需求有影响，但是交通因素对于消费者购买食物的选择也是很重要的，因此本研究的动机是确定消费者所看重的具体交通属性。

Method: 本研究通过第二个实验，使用机器学习模型，提出了五项与运输相关的创新证书：运输模式、物联网（IoT）、安全措施、能源、以及最晚到达日期（MABDs）。还在偏好实验中加入了产品特定和决策者的因素以进行控制。

Result: 研究结果显示，在美国食品供应链的运输领域，消费者明显倾向于安全和能源证书。此外，研究还检验了价格、产品类型、证书和决策者因素对购买选择的影响。

Conclusion: 本研究为改善食品供应链系统提供了数据驱动的建议，特别强调了在运输环节中安全和能源证书的重要性。

Abstract: This paper utilizes a machine learning model to estimate the consumer's
behavior for food products with innovative transportation certificates in the
U.S. Building on previous research that examined demand for food products with
supply chain traceability using stated preference analysis, transportation
factors were identified as significant in consumer food purchasing choices.
Consequently, a second experiment was conducted to pinpoint the specific
transportation attributes valued by consumers. A machine learning model was
applied, and five innovative certificates related to transportation were
proposed: Transportation Mode, Internet of Things (IoT), Safety measures,
Energy Source, and Must Arrive By Dates (MABDs). The preference experiment also
incorporated product-specific and decision-maker factors for control purposes.
The findings reveal a notable inclination toward safety and energy certificates
within the transportation domain of the U.S. food supply chain. Additionally,
the study examined the influence of price, product type, certificates, and
decision-maker factors on purchasing choices. Ultimately, the study offers
data-driven recommendations for improving food supply chain systems.

</details>


### [63] [SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3) Diffusion](https://arxiv.org/abs/2511.04854)
*Alvaro Prat,Leo Zhang,Charlotte M. Deane,Yee Whye Teh,Garrett M. Morris*

Main category: cs.LG

TL;DR: SigmaDock是一种SE(3)黎曼扩散模型，通过学习在结合口袋内重新组装配体 фрагмент 来生成姿态，在PoseBusters数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 目前生成式方法在分子对接中存在化学不合理输出、泛化能力差和计算成本高等问题。

Method: 引入了一种新颖的碎片化方案，利用结构化学的归纳偏差将配体分解为刚体 фрагмент。在此分解的基础上，提出了SigmaDock，这是一种SE(3)黎曼扩散模型，通过学习在结合口袋内重新组装这些刚体来生成姿态。

Result: SigmaDock在PoseBusters集上的Top-1成功率（RMSD<2 & PB-valid）超过79.9%，而最近的深度学习方法的报告为12.7-30.8%，同时对未见蛋白质表现出一致的泛化能力。

Conclusion: SigmaDock是第一个在PB训练-测试拆分下超越经典基于物理的对接的深度学习方法，标志着深度学习在分子建模的可靠性和可行性方面取得了重大飞跃。

Abstract: Determining the binding pose of a ligand to a protein, known as molecular
docking, is a fundamental task in drug discovery. Generative approaches promise
faster, improved, and more diverse pose sampling than physics-based methods,
but are often hindered by chemically implausible outputs, poor
generalisability, and high computational cost. To address these challenges, we
introduce a novel fragmentation scheme, leveraging inductive biases from
structural chemistry, to decompose ligands into rigid-body fragments. Building
on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion
model that generates poses by learning to reassemble these rigid bodies within
the binding pocket. By operating at the level of fragments in SE(3), SigmaDock
exploits well-established geometric priors while avoiding overly complex
diffusion processes and unstable training dynamics. Experimentally, we show
SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates
(RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8%
reported by recent deep learning approaches, whilst demonstrating consistent
generalisation to unseen proteins. SigmaDock is the first deep learning
approach to surpass classical physics-based docking under the PB train-test
split, marking a significant leap forward in the reliability and feasibility of
deep learning for molecular modelling.

</details>


### [64] [Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning](https://arxiv.org/abs/2511.04856)
*Thore Gerlach,Michael Schenk,Verena Kain*

Main category: cs.LG

TL;DR: CSQBM模型结合了经典和量子方法，以减少量子比特需求，并支持连续动作强化学习，通过CSQBM分布进行有效采样，解决了连续控制中的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 开发一种支持连续动作强化学习的新模型，解决现有方法在量子比特需求和连续控制稳定性方面的不足。

Method: 本文引入了连续半量子玻尔兹曼机（CSQBMs），它结合了可见单元上的指数族先验和隐藏单元上的量子玻尔兹曼分布。该模型能够解析计算连续变量的梯度，并提出了一种连续Q学习框架，通过从CSQBM分布中高效采样来替代全局最大化。

Result: CSQBM模型实现了混合量子-经典方法，减少了量子比特需求，同时保持了强大的表达能力。它通过高效采样克服了连续控制中的不稳定性问题，并能直接集成到Actor-Critic算法中。

Conclusion: CSQBMs为连续动作强化学习提供了一个理论上可靠的混合量子-经典模型。该模型通过创新的采样方法解决了连续控制的挑战，为未来的强化学习研究开辟了新途径。

Abstract: We introduce theoretically grounded Continuous Semi-Quantum Boltzmann
Machines (CSQBMs) that supports continuous-action reinforcement learning. By
combining exponential-family priors over visible units with quantum Boltzmann
distributions over hidden units, CSQBMs yield a hybrid quantum-classical model
that reduces qubit requirements while retaining strong expressiveness.
Crucially, gradients with respect to continuous variables can be computed
analytically, enabling direct integration into Actor-Critic algorithms.
Building on this, we propose a continuous Q-learning framework that replaces
global maximization by efficient sampling from the CSQBM distribution, thereby
overcoming instability issues in continuous control.

</details>


### [65] [FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food Donation Forecasting](https://arxiv.org/abs/2511.04865)
*Esha Sharma,Lauren Davis,Julie Ivy,Min Chi*

Main category: cs.LG

TL;DR: FoodRL是一个基于强化学习的元学习框架，能够有效地预测食物银行的实物捐赠，尤其在面对自然灾害等干扰时表现出色，比传统方法能多提供170万份餐食。


<details>
  <summary>Details</summary>
Motivation: 食物银行在缓解食物不安全方面发挥着关键作用，但传统预测模型在预测高度不稳定的实物捐赠时，无法保持持续的准确性，尤其是在季节性变化和自然灾害（如飓风和森林火灾）引起的不可预测波动和概念漂移面前。

Method: 本文提出了FoodRL，一种新颖的基于强化学习（RL）的元学习框架，它根据近期表现和背景信息对不同的预测模型进行聚类并动态加权。

Result: FoodRL在两个结构截然不同的美国食物银行的多年数据上进行了评估，结果显示它持续优于基线方法，特别是在中断或下降期间。

Conclusion: FoodRL可以提供更可靠和适应性更强的预测，每年可额外重新分配相当于170万份餐食的食物，这表明它在社会影响以及人道主义供应链的自适应集成学习方面具有巨大的潜力。

Abstract: Food banks are crucial for alleviating food insecurity, but their
effectiveness hinges on accurately forecasting highly volatile in-kind
donations to ensure equitable and efficient resource distribution. Traditional
forecasting models often fail to maintain consistent accuracy due to
unpredictable fluctuations and concept drift driven by seasonal variations and
natural disasters such as hurricanes in the Southeastern U.S. and wildfires in
the West Coast. To address these challenges, we propose FoodRL, a novel
reinforcement learning (RL) based metalearning framework that clusters and
dynamically weights diverse forecasting models based on recent performance and
contextual information. Evaluated on multi-year data from two structurally
distinct U.S. food banks-one large regional West Coast food bank affected by
wildfires and another state-level East Coast food bank consistently impacted by
hurricanes, FoodRL consistently outperforms baseline methods, particularly
during periods of disruption or decline. By delivering more reliable and
adaptive forecasts, FoodRL can facilitate the redistribution of food equivalent
to 1.7 million additional meals annually, demonstrating its significant
potential for social impact as well as adaptive ensemble learning for
humanitarian supply chains.

</details>


### [66] [Self-Interest and Systemic Benefits: Emergence of Collective Rationality in Mixed Autonomy Traffic Through Deep Reinforcement Learning](https://arxiv.org/abs/2511.04883)
*Di Chen,Jia Li,Michael Zhang*

Main category: cs.LG

TL;DR: 这篇论文研究了在混合自动驾驶交通中，自动驾驶车辆（AVs）在追求个体利益的同时，是否能够通过集体理性（CR）为所有驾驶者带来益处。研究表明，通过深度强化学习（DRL）训练的AVs，即使只关注自身利益，也能够实现集体理性。


<details>
  <summary>Details</summary>
Motivation: 探索在自动驾驶车辆和人类驾驶车辆共存的交通系统中，当驾驶 एजेंटs 出于自身利益行动时，自动驾驶车辆是否仍然能够提升整体交通系统性能，以及集体理性（CR）概念在此情境下的适用性。

Method: 本研究通过使用深度强化学习（DRL）训练的自动驾驶车辆，在简单的奖励设计下，检验了自利型驾驶主体是否能够实现集体理性。该方法不直接纳入系统级目标。

Result: 研究结果表明，集体理性（CR）在各种场景中持续出现，这证明了其鲁棒性。此外，本文还提出了一种机制来解释CR在微观动态环境中的出现，并基于仿真证据进行了验证。

Conclusion: 本研究表明，在混合自动驾驶交通系统中，自利型自动驾驶车辆通过深度强化学习，即使不直接追求系统级目标，也能实现集体理性。这为利用先进学习方法（如联邦学习）实现自利型驾驶主体之间的集体合作提供了可能性。

Abstract: Autonomous vehicles (AVs) are expected to be commercially available in the
near future, leading to mixed autonomy traffic consisting of both AVs and
human-driven vehicles (HVs). Although numerous studies have shown that AVs can
be deployed to benefit the overall traffic system performance by incorporating
system-level goals into their decision making, it is not clear whether the
benefits still exist when agents act out of self-interest -- a trait common to
all driving agents, both human and autonomous. This study aims to understand
whether self-interested AVs can bring benefits to all driving agents in mixed
autonomy traffic systems. The research is centered on the concept of collective
rationality (CR). This concept, originating from game theory and behavioral
economics, means that driving agents may cooperate collectively even when
pursuing individual interests. Our recent research has proven the existence of
CR in an analytical game-theoretical model and empirically in mixed
human-driven traffic. In this paper, we demonstrate that CR can be attained
among driving agents trained using deep reinforcement learning (DRL) with a
simple reward design. We examine the extent to which self-interested traffic
agents can achieve CR without directly incorporating system-level objectives.
Results show that CR consistently emerges in various scenarios, which indicates
the robustness of this property. We also postulate a mechanism to explain the
emergence of CR in the microscopic and dynamic environment and verify it based
on simulation evidence. This research suggests the possibility of leveraging
advanced learning methods (such as federated learning) to achieve collective
cooperation among self-interested driving agents in mixed-autonomy systems.

</details>


### [67] [You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL in Weak Base Models](https://arxiv.org/abs/2511.04902)
*Shuvendu Roy,Hossein Hajimirsadeghi,Mengyao Zhai,Golnoosh Samei*

Main category: cs.LG

TL;DR: 本文探讨了无标签强化学习在不同大小模型上的应用，发现其性能高度依赖于基础模型的推理能力。文章提出了一种新的课程学习方法，通过逐步引入更难的问题和掩盖次优轨迹来提高无监督强化学习在资源受限模型中的效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在无监督强化学习增强推理能力方面取得了进展，但这些方法对小型基础模型的通用性尚不明确。

Method: 本文系统地研究了0.5B到7B参数不同模型大小和推理能力下无标签强化学习方法的性能，并提出了一种利用课程学习和掩盖非多数轨迹的无标签强化学习方法。此外，还引入了一个数据整理管道来生成预定义难度的样本。

Result: 经验分析表明，无标签强化学习高度依赖于基础模型原有的推理能力，对于较弱的模型性能常会下降。小型模型无法生成足够长或多样化的思维链推理以进行有效自我反思，并且训练数据难度对成功起着关键作用。而本文提出的方法在所有模型大小和推理能力上都表现出持续的改进，为更强大的无监督强化学习提供了途径。

Conclusion: 无标签强化学习在小型模型上的应用具有挑战性。本文提出的课程学习方法有效提升了无标签强化学习在资源受限模型中的性能，为实现更可靠的无监督强化学习奠定了基础。

Abstract: Recent advances in large language models have demonstrated the promise of
unsupervised reinforcement learning (RL) methods for enhancing reasoning
capabilities without external supervision. However, the generalizability of
these label-free RL approaches to smaller base models with limited reasoning
capabilities remains unexplored. In this work, we systematically investigate
the performance of label-free RL methods across different model sizes and
reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals
critical limitations: label-free RL is highly dependent on the base model's
pre-existing reasoning capability, with performance often degrading below
baseline levels for weaker models. We find that smaller models fail to generate
sufficiently long or diverse chain-of-thought reasoning to enable effective
self-reflection, and that training data difficulty plays a crucial role in
determining success. To address these challenges, we propose a simple yet
effective method for label-free RL that utilizes curriculum learning to
progressively introduce harder problems during training and mask no-majority
rollouts during training. Additionally, we introduce a data curation pipeline
to generate samples with predefined difficulty. Our approach demonstrates
consistent improvements across all model sizes and reasoning capabilities,
providing a path toward more robust unsupervised RL that can bootstrap
reasoning abilities in resource-constrained models. We make our code available
at https://github.com/BorealisAI/CuMa

</details>


### [68] [A Dual Perspective on Decision-Focused Learning: Scalable Training via Dual-Guided Surrogates](https://arxiv.org/abs/2511.04909)
*Paula Rodriguez-Diaz,Kirk Bansak Elisabeth Paulson*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为Dual-Guided Loss（DGL）的新方法，用于解决决策聚焦学习中优化问题的扩展性挑战。DGL通过利用下游问题的对偶变量来指导学习，减少了对优化器的频繁调用，同时保持了决策对齐，并在组合选择问题上取得了与现有最先进方法相当或更优的性能，但训练时间大大缩短。


<details>
  <summary>Details</summary>
Motivation: 在不确定性下，许多实际决策是通过使用预测量解决优化问题来制定的。这种“预测然后优化”的范式催生了决策聚焦学习，它在训练模型时考虑了优化器如何使用预测，从而提高了下游决策的性能。然而，现有的最先进方法需要频繁且昂贵的优化器调用，这限制了其可扩展性。

Method: 本文提出了一种新的、可扩展的目标函数——Dual-Guided Loss (DGL)。DGL利用下游问题的对偶变量来指导学习过程，旨在减少对优化器的依赖。它专门针对具有“多选一”约束的组合选择问题（如匹配、背包和最短路径问题）而设计。DGL通过以下方式工作：1. 将优化过程与梯度更新解耦，仅周期性地解决下游问题。2. 在两次刷新之间，使用简单的可微分替代损失，并根据对偶变量调整目标进行训练。3. 随着刷新的频率降低，训练成本趋近于标准的监督学习，同时保持强大的决策对齐。

Result: DGL在减少求解器调用次数和显著减少训练时间的情况下，在两种问题类别上达到了与最先进的决策聚焦学习（DFL）方法相当或超越的性能。本文还证明了DGL具有渐近递减的决策遗憾，并分析了其运行时复杂度。

Conclusion: Dual-Guided Loss (DGL) 提供了一种简单且可扩展的决策聚焦学习方法，它通过利用对偶变量并减少对优化器的频繁调用来解决现有方法的扩展性挑战。DGL在组合选择问题上表现出色，实现了高效的训练和强大的决策对齐，为实际应用提供了有前景的解决方案。

Abstract: Many real-world decisions are made under uncertainty by solving optimization
problems using predicted quantities. This predict-then-optimize paradigm has
motivated decision-focused learning, which trains models with awareness of how
the optimizer uses predictions, improving the performance of downstream
decisions. Despite its promise, scaling is challenging: state-of-the-art
methods either differentiate through a solver or rely on task-specific
surrogates, both of which require frequent and expensive calls to an optimizer,
often a combinatorial one. In this paper, we leverage dual variables from the
downstream problem to shape learning and introduce Dual-Guided Loss (DGL), a
simple, scalable objective that preserves decision alignment while reducing
solver dependence. We construct DGL specifically for combinatorial selection
problems with natural one-of-many constraints, such as matching, knapsack, and
shortest path. Our approach (a) decouples optimization from gradient updates by
solving the downstream problem only periodically; (b) between refreshes, trains
on dual-adjusted targets using simple differentiable surrogate losses; and (c)
as refreshes become less frequent, drives training cost toward standard
supervised learning while retaining strong decision alignment. We prove that
DGL has asymptotically diminishing decision regret, analyze runtime complexity,
and show on two problem classes that DGL matches or exceeds state-of-the-art
DFL methods while using far fewer solver calls and substantially less training
time. Code is available at https://github.com/paularodr/Dual-Guided-Learning.

</details>


### [69] [BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk Assessment of Alcohol and Substance Use Disorder with Electronic Health Records](https://arxiv.org/abs/2511.04998)
*Daniel S. Lee,Mayra S. Haedo-Cruz,Chen Jiang,Oshin Miranda,LiRong Wang*

Main category: cs.LG

TL;DR: BiPETE是一种基于Transformer的深度学习模型，可以在不规则的电子健康记录数据上准确预测疾病风险，并在精神疾病队列中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer的深度学习模型在利用电子健康记录（EHR）进行疾病风险预测方面显示出前景，但由于就诊时间间隔不规律和结构缺乏统一性，对时间依赖性进行建模仍然是一个关键挑战。

Method: 我们提出了一个名为Bi-Positional Embedding Transformer Encoder（BiPETE）的模型，用于单病种预测。该模型融合了旋转位置嵌入（用于编码相对就诊时间）和正弦嵌入（用于保留就诊顺序）。BiPETE在两个精神健康队列（抑郁症和创伤后应激障碍）的EHR数据上进行训练，以预测酒精和物质使用障碍（ASUD）的风险。

Result: BiPETE的表现优于基线模型，在抑郁症和创伤后应激障碍队列中的精确召回曲线下面积（AUPRC）分别提高了34%和50%。消融研究进一步证实了双重位置编码策略的有效性。我们应用Integrated Gradients方法来解释模型预测，识别出与ASUD风险和保护相关的关键临床特征，如异常的炎症、血液学和代谢标志物，以及特定的药物和合并症。

Conclusion: 本研究提出了一个实用且可解释的疾病风险预测框架，该框架利用电子健康记录数据，可以实现强大的性能。通过归因方法识别出的关键临床特征有助于更深入地理解风险评估过程，并为减轻潜在风险提供有价值的线索。

Abstract: Transformer-based deep learning models have shown promise for disease risk
prediction using electronic health records(EHRs), but modeling temporal
dependencies remains a key challenge due to irregular visit intervals and lack
of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder
or BiPETE for single-disease prediction, which integrates rotary positional
embeddings to encode relative visit timing and sinusoidal embeddings to
preserve visit order. Without relying on large-scale pretraining, BiPETE is
trained on EHR data from two mental health cohorts-depressive disorder and
post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and
substance use disorders (ASUD). BiPETE outperforms baseline models, improving
the area under the precision-recall curve (AUPRC) by 34% and 50% in the
depression and PTSD cohorts, respectively. An ablation study further confirms
the effectiveness of the dual positional encoding strategy. We apply the
Integrated Gradients method to interpret model predictions, identifying key
clinical features associated with ASUD risk and protection, such as abnormal
inflammatory, hematologic, and metabolic markers, as well as specific
medications and comorbidities. Overall, these key clinical features identified
by the attribution methods contribute to a deeper understanding of the risk
assessment process and offer valuable clues for mitigating potential risks. In
summary, our study presents a practical and interpretable framework for disease
risk prediction using EHR data, which can achieve strong performance.

</details>


### [70] [Machine Learning Algorithms in Statistical Modelling Bridging Theory and Application](https://arxiv.org/abs/2511.04918)
*A. Ganapathi Rao,Sathish Krishna Anumula,Aditya Kumar Singh,Renukhadevi M,Y. Jeevan Nagendra Kumar,Tammineni Rama Tulasi*

Main category: cs.LG

TL;DR: 本文探讨了机器学习算法与传统统计模型融合的新方法，旨在提升数据分析、预测和决策的能力。


<details>
  <summary>Details</summary>
Motivation: 研究机器学习与统计模型的结合方式，以理解现代机器学习算法如何“丰富”传统模型。

Method: 通过展示新算法如何改进传统模型的性能、规模、灵活性和鲁棒性，来研究两者的联系。

Result: 混合模型在预测准确性、鲁棒性和可解释性方面有显著改进。

Conclusion: 机器学习算法与传统统计模型的融合能够显著提升模型的性能和应用价值。

Abstract: It involves the completely novel ways of integrating ML algorithms with
traditional statistical modelling that has changed the way we analyze data, do
predictive analytics or make decisions in the fields of the data. In this
paper, we study some ML and statistical model connections to understand ways in
which some modern ML algorithms help 'enrich' conventional models; we
demonstrate how new algorithms improve performance, scale, flexibility and
robustness of the traditional models. It shows that the hybrid models are of
great improvement in predictive accuracy, robustness, and interpretability

</details>


### [71] [Multi-agent Coordination via Flow Matching](https://arxiv.org/abs/2511.05005)
*Dongsu Lee,Daehee Lee,Amy Zhang*

Main category: cs.LG

TL;DR: MAC-Flow是一个新的多智能体协调框架，它在保持良好性能的同时，将推理速度提高了约14.5倍，解决了现有方法在表示能力和计算效率之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体协调方法在表示复杂协调行为或实时高效执行方面存在不足，MAC-Flow旨在解决这一性能与计算成本之间的权衡。

Method: MAC-Flow首先学习联合行为的基于流的表示，然后将其提炼为分散式单步策略。这使得它能够保留协调能力，同时实现快速执行。

Result: MAC-Flow在四个不同的基准测试中（包括12个环境和34个数据集）表现出色，与基于扩散的MARL方法相比，推理速度提高了约14.5倍，同时保持了良好的性能。其推理速度与高斯策略的离线多智能体强化学习方法相似。

Conclusion: MAC-Flow通过结合流式表示和蒸馏策略，成功地在多智能体协调任务中实现了高性能和高效率的平衡，为未来多智能体系统设计提供了新的方向。

Abstract: This work presents MAC-Flow, a simple yet expressive framework for
multi-agent coordination. We argue that requirements of effective coordination
are twofold: (i) a rich representation of the diverse joint behaviors present
in offline data and (ii) the ability to act efficiently in real time. However,
prior approaches often sacrifice one for the other, i.e., denoising
diffusion-based solutions capture complex coordination but are computationally
slow, while Gaussian policy-based solutions are fast but brittle in handling
multi-agent interaction. MAC-Flow addresses this trade-off by first learning a
flow-based representation of joint behaviors, and then distilling it into
decentralized one-step policies that preserve coordination while enabling fast
execution. Across four different benchmarks, including $12$ environments and
$34$ datasets, MAC-Flow alleviates the trade-off between performance and
computational cost, specifically achieving about $\boldsymbol{\times14.5}$
faster inference compared to diffusion-based MARL methods, while maintaining
good performance. At the same time, its inference speed is similar to that of
prior Gaussian policy-based offline multi-agent reinforcement learning (MARL)
methods.

</details>


### [72] [Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic Decoding](https://arxiv.org/abs/2511.04934)
*Hadi Reisizadeh,Jiajun Ruan,Yiwei Chen,Soumyadeep Pal,Sijia Liu,Mingyi Hong*

Main category: cs.LG

TL;DR: “遗忘”大型语言模型中的有害信息对于法规遵从性以及构建道德的生成式人工智能至关重要。本文研究发现，几乎所有现有的“遗忘”方法在实践中都无法实现真正的遗忘。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的“遗忘”对于监管合规性和构建道德的生成式人工智能系统至关重要，这些系统需要避免生成私人、有毒、非法或受版权保护的内容。

Method: 本文引入了新的元评估指标leak@k，用于量化当模型在实际解码策略下生成k个样本时，被遗忘知识重新出现的可能性。利用TOFU、MUSE和WMDP这三个广泛采用的基准，本文首次使用新定义的leak@k指标对“遗忘”的可靠性进行了大规模系统研究。

Result: 研究结果表明，知识泄漏普遍存在于各种方法和任务中。

Conclusion: 目前最先进的“遗忘”技术只能提供有限的遗忘，这突显出迫切需要更强大的LLM“遗忘”方法。

Abstract: Unlearning in large language models (LLMs) is critical for regulatory
compliance and for building ethical generative AI systems that avoid producing
private, toxic, illegal, or copyrighted content. Despite rapid progress, in
this work we show that \textit{almost all} existing unlearning methods fail to
achieve true forgetting in practice. Specifically, while evaluations of these
`unlearned' models under deterministic (greedy) decoding often suggest
successful knowledge removal using standard benchmarks (as has been done in the
literature), we show that sensitive information reliably resurfaces when models
are sampled with standard probabilistic decoding. To rigorously capture this
vulnerability, we introduce \texttt{leak@$k$}, a new meta-evaluation metric
that quantifies the likelihood of forgotten knowledge reappearing when
generating $k$ samples from the model under realistic decoding strategies.
Using three widely adopted benchmarks, TOFU, MUSE, and WMDP, we conduct the
first large-scale, systematic study of unlearning reliability using our newly
defined \texttt{leak@$k$} metric. Our findings demonstrate that knowledge
leakage persists across methods and tasks, underscoring that current
state-of-the-art unlearning techniques provide only limited forgetting and
highlighting the urgent need for more robust approaches to LLM unlearning.

</details>


### [73] [Structural Properties, Cycloid Trajectories and Non-Asymptotic Guarantees of EM Algorithm for Mixed Linear Regression](https://arxiv.org/abs/2511.04937)
*Zhankun Luo,Abolfazl Hashemi*

Main category: cs.LG

TL;DR: 本文探讨了期望最大化（EM）算法在双组分混合线性回归（2MLR）中的结构特性、摆线轨迹和非渐近收敛性，其中混合权重和回归参数都是未知的。


<details>
  <summary>Details</summary>
Motivation: 尽管EM算法在已知平衡权重和高信噪比（SNR）情况下的全局收敛性已被证实，但在完全未知参数设置下，EM算法的理论行为，包括其轨迹和收敛顺序，仍不明确。

Method: 本文推导了2MLR在所有信噪比条件下未知混合权重和回归参数的显式EM更新表达式，并分析了它们的结构特性和摆线轨迹。在无噪声情况下，通过建立次优角度的递推关系，证明了EM迭代中回归参数的轨迹描绘出一条摆线；在高信噪比情况下，量化了其与摆线轨迹的偏差。

Result: 轨迹分析揭示了收敛的阶数：当EM估计几乎正交于真实值时是线性的，当估计与真实值之间的角度在总体层面很小时是二次的。通过缩小有限样本和总体EM更新之间统计误差的界限，将EM的统计精度与次优角度联系起来，并证明了在有限样本水平上任意初始化的收敛性，从而建立了非渐近保证。

Conclusion: 本文为分析混合线性回归中的EM算法提供了一种新颖的基于轨迹的框架，并为完全未知参数设置下的EM算法的收敛行为提供了深入理解，揭示了其收敛的阶数和非渐近保证。

Abstract: This work investigates the structural properties, cycloid trajectories, and
non-asymptotic convergence guarantees of the Expectation-Maximization (EM)
algorithm for two-component Mixed Linear Regression (2MLR) with unknown mixing
weights and regression parameters. Recent studies have established global
convergence for 2MLR with known balanced weights and super-linear convergence
in noiseless and high signal-to-noise ratio (SNR) regimes. However, the
theoretical behavior of EM in the fully unknown setting remains unclear, with
its trajectory and convergence order not yet fully characterized. We derive
explicit EM update expressions for 2MLR with unknown mixing weights and
regression parameters across all SNR regimes and analyze their structural
properties and cycloid trajectories. In the noiseless case, we prove that the
trajectory of the regression parameters in EM iterations traces a cycloid by
establishing a recurrence relation for the sub-optimality angle, while in high
SNR regimes we quantify its discrepancy from the cycloid trajectory. The
trajectory-based analysis reveals the order of convergence: linear when the EM
estimate is nearly orthogonal to the ground truth, and quadratic when the angle
between the estimate and ground truth is small at the population level. Our
analysis establishes non-asymptotic guarantees by sharpening bounds on
statistical errors between finite-sample and population EM updates, relating
EM's statistical accuracy to the sub-optimality angle, and proving convergence
with arbitrary initialization at the finite-sample level. This work provides a
novel trajectory-based framework for analyzing EM in Mixed Linear Regression.

</details>


### [74] [OvA-LP: A Simple and Efficient Framework for Federated Learning on Non-IID Data](https://arxiv.org/abs/2511.05028)
*Dongjin Park,Hasung Yeo,Joon-Woo Lee*

Main category: cs.LG

TL;DR: OvA-LP通过冻结编码器和使用one-vs-all头部的线性探测，有效地抑制了联邦微调（FFT）中由异构数据引起的问题。


<details>
  <summary>Details</summary>
Motivation: 联邦微调（FFT）在分散数据上调整基础模型时，由于局部漂移（即客户端更新差异导致全局模型出现系统偏差和方差放大），在异构客户端分布下表现脆弱。现有的聚合和个性化方法大多是事后纠正漂移，在极端非IID条件下效果不佳。

Method: 我们引入了OvA-LP，这是一个最小主义框架，它结合了冻结编码器上的线性探测与one-vs-all头部，并通过一个简单的两阶段过程，在PEFT-based FFT范式中从源头上抑制漂移。该方法旨在保留预训练的特征几何，并解耦逻辑，以防止放大漂移的机制。

Result: 在CIFAR-100数据集和100个客户端的实验中，OvA-LP在shard-1、shard-2和Bernoulli-Dirichlet分区上平均保持了95.9%的IID准确率，而最先进的FFT基线（PFPT和FFT-MoE）在相同条件下分别仅保持了10.1%和34.5%。OvA-LP在对称和非对称标签噪声下也保持了弹性。此外，预计算编码器特征使得每轮成本几乎与编码器大小无关。

Conclusion: OvA-LP为在异构条件下实现鲁棒的联邦微调提供了一个有原则且高效的基础。

Abstract: Federated fine-tuning (FFT) adapts foundation models to decentralized data
but remains fragile under heterogeneous client distributions due to local
drift, i.e., client-level update divergences that induce systematic bias and
amplified variance in the global model. Existing aggregation and
personalization methods largely correct drift post hoc, which proves brittle
under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework
that is, to our knowledge, the first explicitly designed to suppress drift at
its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing
on a frozen encoder with a one-vs-all head and a simple two-stage procedure,
preserving pretrained feature geometry and decoupling logits to prevent the
mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over
shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of
its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1%
(PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains
resilience under both symmetric and asymmetric label noise. In addition,
precomputing encoder features makes per-round cost nearly independent of
encoder size. Together, these results demonstrate that OvA-LP provides a
principled and efficient basis for robust FFT under heterogeneity.

</details>


### [75] [Less Is More: Generating Time Series with LLaMA-Style Autoregression in Simple Factorized Latent Spaces](https://arxiv.org/abs/2511.04973)
*Siyuan Li,Yifan Sun,Lei Cheng,Lewen Wang,Yang Liu,Weiqing Liu,Jianlong Li,Jiang Bian,Shikai Fang*

Main category: cs.LG

TL;DR: 该论文提出FAR-TS，一个结合解耦分解和自回归Transformer的框架，用于快速、可控地生成任意长度的时间序列，解决了现有扩散模型速度慢和固定长度的限制。


<details>
  <summary>Details</summary>
Motivation: 现有的多变量时间序列生成模型，特别是基于扩散的方法，存在生成速度慢和只能处理固定长度序列的问题，限制了它们在数据增强、模拟和隐私保护等方面的应用。

Method: FAR-TS通过以下步骤实现： 1. 将每个时间序列分解为一个数据自适应基，捕获静态跨通道相关性。 2. 将时间系数向量量化为离散token。 3. 使用LLaMA风格的自回归Transformer模型对这些token序列进行建模，从而实现快速、可控的任意长度序列生成。

Result: FAR-TS实现了比Diffusion-TS快几个数量级的生成速度，同时保持了跨通道相关性和可解释的潜在空间。

Conclusion: FAR-TS通过其简化的设计，实现了高质量和灵活的时间序列合成，克服了现有扩散模型的局限性，在生成速度和序列长度控制方面表现出色。

Abstract: Generative models for multivariate time series are essential for data
augmentation, simulation, and privacy preservation, yet current
state-of-the-art diffusion-based approaches are slow and limited to
fixed-length windows. We propose FAR-TS, a simple yet effective framework that
combines disentangled factorization with an autoregressive Transformer over a
discrete, quantized latent space to generate time series. Each time series is
decomposed into a data-adaptive basis that captures static cross-channel
correlations and temporal coefficients that are vector-quantized into discrete
tokens. A LLaMA-style autoregressive Transformer then models these token
sequences, enabling fast and controllable generation of sequences with
arbitrary length. Owing to its streamlined design, FAR-TS achieves
orders-of-magnitude faster generation than Diffusion-TS while preserving
cross-channel correlations and an interpretable latent space, enabling
high-quality and flexible time series synthesis.

</details>


### [76] [Model Merging Improves Zero-Shot Generalization in Bioacoustic Foundation Models](https://arxiv.org/abs/2511.05171)
*Davide Marincione,Donato Crisostomi,Roberto Dessi,Emanuele Rodolà,Emanuele Rossi*

Main category: cs.LG

TL;DR: 本文探讨了NatureLM在生物声学领域的应用，并提出了一种模型合并策略来解决其在指令遵循灵活性方面的局限性，同时提高了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: NatureLM在生物声学领域表现出色，但其在指令遵循方面存在不足。例如，当同时需要普通名和科学名时，准确率会显著下降。

Method: 本文提出了一种简单的模型合并策略，将NatureLM与其基础语言模型进行插值，以恢复指令遵循能力，同时最大限度地减少领域专业知识的损失。

Result: 合并后的模型在指令遵循方面有所改善，并且在零样本泛化方面表现出显著增强，在未见过物种的封闭集零样本分类中实现了超过200%的相对改进，并创造了新的技术水平。

Conclusion: 通过模型合并策略，可以在保持领域专业知识的同时，有效提升NatureLM的指令遵循能力和零样本泛化能力，为生物声学领域的应用提供了新的思路和更强大的工具。

Abstract: Foundation models capable of generalizing across species and tasks represent
a promising new frontier in bioacoustics, with NatureLM being one of the most
prominent examples. While its domain-specific fine-tuning yields strong
performance on bioacoustic benchmarks, we observe that it also introduces
trade-offs in instruction-following flexibility. For instance, NatureLM
achieves high accuracy when prompted for either the common or scientific name
individually, but its accuracy drops significantly when both are requested in a
single prompt. We address this by applying a simple model merging strategy that
interpolates NatureLM with its base language model, recovering
instruction-following capabilities with minimal loss of domain expertise.
Finally, we show that the merged model exhibits markedly stronger zero-shot
generalization, achieving over a 200% relative improvement and setting a new
state-of-the-art in closed-set zero-shot classification of unseen species.

</details>


### [77] [Deep Progressive Training: scaling up depth capacity of zero/one-layer models](https://arxiv.org/abs/2511.04981)
*Zhiqi Bu*

Main category: cs.LG

TL;DR: 为了实现计算效率与模型性能之间的最佳平衡，本文提出了零层/单层渐进式训练，该方法可以在保持模型性能的同时，显著减少大型模型的训练计算成本。


<details>
  <summary>Details</summary>
Motivation: 在深度学习中，模型深度与计算成本之间存在矛盾：深度模型能实现高精度，但计算成本高昂。为了高效地训练大规模模型，需要一种能够显著减少计算成本而不影响性能的有效策略。

Method: 本文通过优化理论和特征学习的视角，研究了大型模型的深度扩展，并为新层的初始化、超参数迁移、学习率调度以及模型扩展的时机提供了深入见解。具体提出了零层/单层渐进式训练方法。

Result: 在GPT2上的实验表明，零层/单层渐进式训练可以节省约80%的计算量，或等效地将训练速度提升约5倍，同时达到与完全训练的60层7B参数模型几乎相同的性能。

Conclusion: 本文提出的零层/单层渐进式训练是一种高效的策略，能够在大规模模型训练中显著降低计算成本，同时保持模型性能。

Abstract: Model depth is a double-edged sword in deep learning: deeper models achieve
higher accuracy but require higher computational cost. To efficiently train
models at scale, an effective strategy is the progressive training, which
scales up model capacity during training, hence significantly reducing
computation with little to none performance degradation. In this work, we study
the depth expansion of large models through the lens of optimization theory and
feature learning, offering insights on the initialization of new layers,
hyperparameter transfer, learning rate schedule, and timing of model expansion.
Specifically, we propose zero/one-layer progressive training for the optimal
tradeoff between computation and loss. For example, zero/one-layer progressive
training on GPT2 can save $\approx 80\%$ compute, or equivalently accelerate
$\approx 5\times$ while achieving almost the same loss, compared to to a fully
trained 60-layer model with 7B parameters.

</details>


### [78] [An End-to-End Deep Reinforcement Learning Approach for Solving the Traveling Salesman Problem with Drones](https://arxiv.org/abs/2511.05265)
*Taihelong Zeng,Yun Lin,Yuhe Shi,Yan Li,Zhiqing Wei,Xuanru Ji*

Main category: cs.LG

TL;DR: 该研究提出了一个分层的Actor-Critic深度强化学习框架，用于解决带无人机的旅行商问题（TSP-D），该框架在计算效率和性能方面超越了现有的启发式算法和强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 卡车-无人机协同系统在最后一英里物流中的出现，使得带无人机的旅行商问题（TSP-D）成为经典路径优化问题的一个关键扩展，其车辆协调同步有望显著提高运营效率和减少环境影响。然而，TSP-D引入了NP-hard组合复杂性，超出了传统优化范畴。深度强化学习为解决TSP-D的内在挑战提供了一个理论基础框架。

Method: 本研究提出了一个分层的Actor-Critic深度强化学习框架来解决TSP-D问题。该架构包含两个主要组成部分：一个受Transformer启发的编码器和一个高效的Minimal Gated Unit解码器。编码器Sears一个新颖的、优化的k-近邻稀疏注意力机制，专门用于关注相关的空间关系，并通过集成全局节点特征进一步增强。Minimal Gated Unit解码器处理这些编码表示，以高效生成解决方案序列。整个框架在异步优势Actor-Critic范式中运行。

Result: 在各种规模（N=10到100）的基准TSP-D实例上，所提出的模型能够以更短的平均计算时间获得与高性能启发式算法和现有强化学习方法相比具有竞争力甚至更优的解决方案。此外，与先进的强化学习算法基准相比，所提出的框架显著减少了所需的总训练时间，同时实现了卓越的最终性能。

Conclusion: 该研究提出的分层Actor-Critic深度强化学习框架在解决TSP-D问题时，在计算效率和最终性能方面均显示出显著的优势，尤其在训练效率上表现突出，为解决更复杂的组合优化问题提供了新的思路和方法。

Abstract: The emergence of truck-drone collaborative systems in last-mile logistics has
positioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal
extension of classical routing optimization, where synchronized vehicle
coordination promises substantial operational efficiency and reduced
environmental impact, yet introduces NP-hard combinatorial complexity beyond
the reach of conventional optimization paradigms. Deep reinforcement learning
offers a theoretically grounded framework to address TSP-D's inherent
challenges through self-supervised policy learning and adaptive
decision-making. This study proposes a hierarchical Actor-Critic deep
reinforcement learning framework for solving the TSP-D problem. The
architecture consists of two primary components: a Transformer-inspired encoder
and an efficient Minimal Gated Unit decoder. The encoder incorporates a novel,
optimized k-nearest neighbors sparse attention mechanism specifically for
focusing on relevant spatial relationships, further enhanced by the integration
of global node features. The Minimal Gated Unit decoder processes these encoded
representations to efficiently generate solution sequences. The entire
framework operates within an asynchronous advantage actor-critic paradigm.
Experimental results show that, on benchmark TSP-D instances of various scales
(N=10 to 100), the proposed model can obtain competitive or even superior
solutions in shorter average computation times compared to high-performance
heuristic algorithms and existing reinforcement learning methods. Moreover,
compared to advanced reinforcement learning algorithm benchmarks, the proposed
framework significantly reduces the total training time required while
achieving superior final performance, highlighting its notable advantage in
training efficiency.

</details>


### [79] [Carbon Price Forecasting with Structural Breaks: A Comparative Study of Deep Learning Models](https://arxiv.org/abs/2511.04988)
*Runsheng Ren,Jing Li,Yanxiu Li,Shixun Huang,Jun Shen,Wanqing Li,John Le,Sheng Wang*

Main category: cs.LG

TL;DR: 本文提出了一种结合结构性断裂检测、小波信号去噪和深度学习模型的混合框架，显著提高了碳价格预测的准确性，尤其以PELT-WT-TCN模型的表现最佳。


<details>
  <summary>Details</summary>
Motivation: 碳价格预测对于能源市场决策、可持续能源规划和脱碳策略至关重要，但由于频繁的政策干预和市场冲击导致的结构性断裂和高频噪声，预测仍然具有挑战性。现有研究未能将去噪和建模有效整合，并且缺乏对先进深度学习架构的系统评估，限制了模型的鲁棒性和泛化能力。

Method: 本文提出了一个综合的混合框架，该框架集成了结构性断裂检测（采用Bai-Perron、ICSS和PELT算法）、小波信号去噪以及三种先进的深度学习模型（LSTM、GRU和TCN）。研究利用2007年至2024年的欧盟碳配额（EUA）现货价格以及能源价格和政策指标等外部特征，构建了单变量和多变量数据集进行比较评估。

Result: 实验结果表明，本文提出的PELT-WT-TCN模型取得了最高的预测精度，与现有最佳基线模型（结合小波和LSTM的断裂点模型）相比，RMSE误差降低了22.35%，MAE误差降低了18.63%。与同一基线研究中未经分解的原始LSTM相比，RMSE误差降低了70.55%，MAE误差降低了74.42%。

Conclusion: 研究结果强调了将结构感知和多尺度分解整合到深度学习架构中，对于提高碳价格预测和其他非平稳金融时间序列的准确性和可解释性的重要价值。

Abstract: Accurately forecasting carbon prices is essential for informed energy market
decision-making, guiding sustainable energy planning, and supporting effective
decarbonization strategies. However, it remains challenging due to structural
breaks and high-frequency noise caused by frequent policy interventions and
market shocks. Existing studies, including the most recent baseline approaches,
have attempted to incorporate breakpoints but often treat denoising and
modeling as separate processes and lack systematic evaluation across advanced
deep learning architectures, limiting the robustness and the generalization
capability. To address these gaps, this paper proposes a comprehensive hybrid
framework that integrates structural break detection (Bai-Perron, ICSS, and
PELT algorithms), wavelet signal denoising, and three state-of-the-art deep
learning models (LSTM, GRU, and TCN). Using European Union Allowance (EUA) spot
prices from 2007 to 2024 and exogenous features such as energy prices and
policy indicators, the framework constructs univariate and multivariate
datasets for comparative evaluation. Experimental results demonstrate that our
proposed PELT-WT-TCN achieves the highest prediction accuracy, reducing
forecasting errors by 22.35% in RMSE and 18.63% in MAE compared to the
state-of-the-art baseline model (Breakpoints with Wavelet and LSTM), and by
70.55% in RMSE and 74.42% in MAE compared to the original LSTM without
decomposition from the same baseline study. These findings underscore the value
of integrating structural awareness and multiscale decomposition into deep
learning architectures to enhance accuracy and interpretability in carbon price
forecasting and other nonstationary financial time series.

</details>


### [80] [Usando LLMs para Programar Jogos de Tabuleiro e Variações](https://arxiv.org/abs/2511.05114)
*Álvaro Guglielmin Becker,Lana Bertoldo Rossato,Anderson Rocha Tavares*

Main category: cs.LG

TL;DR: 本文探讨了大型语言模型（LLMs）在生成棋盘游戏代码方面的能力，以简化游戏开发过程。


<details>
  <summary>Details</summary>
Motivation: 构建棋盘游戏程序是一个耗时的过程，而大型语言模型（LLMs）能够基于简单的上下文信息高效生成代码，从而有可能加速这一过程。

Method: 本文提出了一种方法，用于测试Claude、DeepSeek和ChatGPT这三种LLMs在创建棋盘游戏代码以及现有游戏新变体方面的能力。

Result: 目前尚未提供具体结果。

Conclusion: 本文将评估大型语言模型在棋盘游戏代码生成方面的潜力，具体结论尚待实验结果。

Abstract: Creating programs to represent board games can be a time-consuming task.
Large Language Models (LLMs) arise as appealing tools to expedite this process,
given their capacity to efficiently generate code from simple contextual
information. In this work, we propose a method to test how capable three LLMs
(Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as
new variants of existing games.

</details>


### [81] [ProDER: A Continual Learning Approach for Fault Prediction in Evolving Smart Grids](https://arxiv.org/abs/2511.05420)
*Emad Efatinasab,Nahal Azadi,Davide Dalle Pezze,Gian Antonio Susto,Chuadhry Mujeeb Ahmed,Mirco Rampazzo*

Main category: cs.LG

TL;DR: 这篇论文提出了一种在智能电网中进行故障预测的持续学习框架，以帮助模型适应不断变化的环境。


<details>
  <summary>Details</summary>
Motivation: 现有的AI故障预测模型在不断演变的环境中（需要适应新的故障类型和操作区域）难以确保可靠性。

Method: 提出了一个在智能电网背景下的持续学习（CL）框架，使模型能随环境一起演进。设计了四种基于类别增量和域增量学习的现实评估场景，以模拟不断变化的电网条件。引入了基于原型的暗经验回放（ProDER）方法，该方法集成了基于原型的特征正则化、逻辑蒸馏和原型引导的回放记忆。

Result: ProDER在测试的持续学习技术中表现最佳，故障类型预测的准确率仅下降0.045，故障区域预测的准确率仅下降0.015。

Conclusion: 持续学习对于智能电网中可扩展的、实用的故障预测是可行的。

Abstract: As smart grids evolve to meet growing energy demands and modern operational
challenges, the ability to accurately predict faults becomes increasingly
critical. However, existing AI-based fault prediction models struggle to ensure
reliability in evolving environments where they are required to adapt to new
fault types and operational zones. In this paper, we propose a continual
learning (CL) framework in the smart grid context to evolve the model together
with the environment. We design four realistic evaluation scenarios grounded in
class-incremental and domain-incremental learning to emulate evolving grid
conditions. We further introduce Prototype-based Dark Experience Replay
(ProDER), a unified replay-based approach that integrates prototype-based
feature regularization, logit distillation, and a prototype-guided replay
memory. ProDER achieves the best performance among tested CL techniques, with
only a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone
prediction. These results demonstrate the practicality of CL for scalable,
real-world fault prediction in smart grids.

</details>


### [82] [QuAnTS: Question Answering on Time Series](https://arxiv.org/abs/2511.05124)
*Felix Divo,Maurice Kraus,Anh Q. Nguyen,Hao Xue,Imran Razzak,Flora D. Salim,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.LG

TL;DR: 该文提出了QuAnTS——一个在时间序列上问答（TSQA）的数据集，旨在通过文本交互来提高时间序列模型的可访问性与决策性。


<details>
  <summary>Details</summary>
Motivation: 现有的问答研究主要集中在视觉和文本领域，时间序列问答受到的关注较少。为了弥补这一空白，作者提出了一个具有挑战性的新型时间序列问答（TSQA）数据集。

Method: 本文通过对人体运动（以跟踪骨架轨迹的形式）提出各种问题和答案，构建了QuAnTS数据集，并通过广泛的实验验证了其良好的结构和全面性。

Result: QuAnTS数据集的提出为TSQA的深入研究奠定了基础。通过评估现有及新提出的基线，该文展示了数据集的有效性。

Conclusion: QuAnTS数据集和人类表现的提供，旨在鼓励未来通过文本与时间序列模型进行交互的研究，以实现更好的决策和更透明的系统。

Abstract: Text offers intuitive access to information. This can, in particular,
complement the density of numerical time series, thereby allowing improved
interactions with time series models to enhance accessibility and
decision-making. While the creation of question-answering datasets and models
has recently seen remarkable growth, most research focuses on question
answering (QA) on vision and text, with time series receiving minute attention.
To bridge this gap, we propose a challenging novel time series QA (TSQA)
dataset, QuAnTS, for Question Answering on Time Series data. Specifically, we
pose a wide variety of questions and answers about human motion in the form of
tracked skeleton trajectories. We verify that the large-scale QuAnTS dataset is
well-formed and comprehensive through extensive experiments. Thoroughly
evaluating existing and newly proposed baselines then lays the groundwork for a
deeper exploration of TSQA using QuAnTS. Additionally, we provide human
performances as a key reference for gauging the practical usability of such
models. We hope to encourage future research on interacting with time series
models through text, enabling better decision-making and more transparent
systems.

</details>


### [83] [APP: Accelerated Path Patching with Task-Specific Pruning](https://arxiv.org/abs/2511.05442)
*Frauke Andersen,William Rudman,Ruochen Zhang,Carsten Eickhoff*

Main category: cs.LG

TL;DR: 本文提出了一种名为加速路径修补（APP）的新方法，通过结合对比注意力头剪枝和传统路径修补，显著减少了电路发现的计算成本，同时保持了与现有方法相似的电路性能和重叠。


<details>
  <summary>Details</summary>
Motivation: 现有的电路发现方法（如路径修补）计算成本高昂，且难以对小型模型进行深入的电路分析。

Method: 本文提出了一种混合方法：加速路径修补（APP）。首先，利用对比FLAP剪枝算法来修剪任务无关的注意力头，从而将电路发现的搜索空间平均减少了56%。然后，在剩余的注意力头上应用传统的路径修补方法，从而将速度提高了59.63%-93.27%。

Result: APP方法在保持电路性能和与传统路径修补电路的重叠度相似的情况下，显著降低了计算成本，取得了59.63%-93.27%的速度提升。

Conclusion: APP方法通过结合对比注意力头剪枝和传统路径修补，有效地解决了现有电路发现方法计算成本高的问题，为电路分析提供了更高效的工具。

Abstract: Circuit discovery is a key step in many mechanistic interpretability
pipelines. Current methods, such as Path Patching, are computationally
expensive and have limited in-depth circuit analysis for smaller models. In
this study, we propose Accelerated Path Patching (APP), a hybrid approach
leveraging our novel contrastive attention head pruning method to drastically
reduce the search space of circuit discovery methods. Our Contrastive-FLAP
pruning algorithm uses techniques from causal mediation analysis to assign
higher pruning scores to task-specific attention heads, leading to higher
performing sparse models compared to traditional pruning techniques. Although
Contrastive-FLAP is successful at preserving task-specific heads that existing
pruning algorithms remove at low sparsity ratios, the circuits found by
Contrastive-FLAP alone are too large to satisfy the minimality constraint
required in circuit analysis. APP first applies Contrastive-FLAP to reduce the
search space on required for circuit discovery algorithms by, on average, 56\%.
Next, APP, applies traditional Path Patching on the remaining attention heads,
leading to a speed up of 59.63\%-93.27\% compared to Path Patching applied to
the dense model. Despite the substantial computational saving that APP
provides, circuits obtained from APP exhibit substantial overlap and similar
performance to previously established Path Patching circuits

</details>


### [84] [Consecutive Preferential Bayesian Optimization](https://arxiv.org/abs/2511.05163)
*Aras Erarslan,Carlos Sevilla Salcedo,Ville Tanskanen,Anni Nisov,Eero Päiväkumpu,Heikki Aisala,Kaisu Honkapää,Arto Klami,Petrus Mikkola*

Main category: cs.LG

TL;DR: 本文提出了一种连续优先贝叶斯优化方法，通过限制比较对象为之前生成的候选，降低了生产成本，并通过引入最小可觉差阈值来解决感知模糊性，提高了优化精度。


<details>
  <summary>Details</summary>
Motivation: 现有的偏好优化方法忽略了候选解决方案的生成成本，同时也没有考虑到评估者在感知上的模糊性。

Method: 本文提出了一种“连续优先贝叶斯优化”方法，通过将比较限定在先前生成的候选上，从而降低了生产成本。此外，该方法通过在概率偏好模型中引入“最小可觉差”阈值来解释感知模糊性，从而捕捉了对微小效用差异的无差性。作者还采用了一种信息论获取策略，选择对于未知最优解信息量最大的新配置。

Result: 在生产成本高或存在无差别反馈的情况下，本文提出的方法显著提高了精度。

Conclusion: 本文提出的连续优先贝叶斯优化方法有效解决了传统偏好优化中生产成本高和感知模糊性问题，提高了优化效率和准确性。

Abstract: Preferential Bayesian optimization allows optimization of objectives that are
either expensive or difficult to measure directly, by relying on a minimal
number of comparative evaluations done by a human expert. Generating candidate
solutions for evaluation is also often expensive, but this cost is ignored by
existing methods. We generalize preference-based optimization to explicitly
account for production and evaluation costs with Consecutive Preferential
Bayesian Optimization, reducing production cost by constraining comparisons to
involve previously generated candidates. We also account for the perceptual
ambiguity of the oracle providing the feedback by incorporating a
Just-Noticeable Difference threshold into a probabilistic preference model to
capture indifference to small utility differences. We adapt an
information-theoretic acquisition strategy to this setting, selecting new
configurations that are most informative about the unknown optimum under a
preference model accounting for the perceptual ambiguity. We empirically
demonstrate a notable increase in accuracy in setups with high production costs
or with indifference feedback.

</details>


### [85] [Associative Poisoning to Generative Machine Learning](https://arxiv.org/abs/2511.05177)
*Mathias Lundteigen Mohus,Jingyue Li,Zhirong Yang*

Main category: cs.LG

TL;DR: 本文介绍了一种名为“关联投毒”的新型数据投毒技术，该技术通过扰乱训练数据来操纵生成输出中特定特征对之间的统计关联，而无需控制训练过程。


<details>
  <summary>Details</summary>
Motivation: 大型生成模型（如 Stable Diffusion 和 ChatGPT）的广泛应用使其成为恶意利用（尤其是数据投毒）的诱人目标。现有投毒攻击通常会导致生成数据质量普遍下降或需要控制训练过程，从而限制了其在实际场景中的适用性。

Method: 本文提出了一种名为“关联投毒”的新型数据投毒技术。该攻击仅通过扰乱训练数据来操纵生成输出中特定特征对之间的统计关联。作者提供了攻击的正式数学表述，并证明了其理论可行性和隐蔽性。

Result: 通过对两种最先进的生成模型进行实证评估，结果表明关联投毒能有效诱导或抑制特征关联，同时保留目标特征的边际分布并保持高质量输出，从而逃避视觉检测。

Conclusion: 这些结果表明，图像合成、合成数据集生成和自然语言处理中使用的生成系统容易受到微妙、隐蔽的操纵，从而损害其统计完整性。为了解决这一风险，本文研究了现有防御策略的局限性，并提出了一种新颖的对抗策略。

Abstract: The widespread adoption of generative models such as Stable Diffusion and
ChatGPT has made them increasingly attractive targets for malicious
exploitation, particularly through data poisoning. Existing poisoning attacks
compromising synthesised data typically either cause broad degradation of
generated data or require control over the training process, limiting their
applicability in real-world scenarios. In this paper, we introduce a novel data
poisoning technique called associative poisoning, which compromises
fine-grained features of the generated data without requiring control of the
training process. This attack perturbs only the training data to manipulate
statistical associations between specific feature pairs in the generated
outputs. We provide a formal mathematical formulation of the attack and prove
its theoretical feasibility and stealthiness. Empirical evaluations using two
state-of-the-art generative models demonstrate that associative poisoning
effectively induces or suppresses feature associations while preserving the
marginal distributions of the targeted features and maintaining high-quality
outputs, thereby evading visual detection. These results suggest that
generative systems used in image synthesis, synthetic dataset generation, and
natural language processing are susceptible to subtle, stealthy manipulations
that compromise their statistical integrity. To address this risk, we examine
the limitations of existing defensive strategies and propose a novel
countermeasure strategy.

</details>


### [86] [ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep Behavior Disorder Screening through Standardized Actigraphy](https://arxiv.org/abs/2511.05221)
*David Bertram,Anja Ophey,Sinah Röttgen,Konstantin Kuffer,Gereon R. Fink,Elke Kalbe,Clint Hansen,Walter Maetzler,Maximilian Kapsecker,Lara M. Reimer,Stephan Jonas,Andreas T. Damgaard,Natasha B. Bertelsen,Casper Skjaerbaek,Per Borghammer,Karolien Groenewald,Pietro-Luca Ratti,Michele T. Hu,No émie Moreau,Michael Sommerauer,Katarzyna Bozek*

Main category: cs.LG

TL;DR: ActiTect是一个开源的自动化机器学习工具，旨在通过腕戴式活动记录仪数据识别隔离性快速眼动睡眠行为障碍（iRBD）。该工具在多个数据集上表现出良好的泛化能力和鲁棒性，有助于推动可穿戴设备在RBD检测中的应用。


<details>
  <summary>Details</summary>
Motivation: 隔离性快速眼动睡眠行为障碍（iRBD）是α-突触核蛋白病（如帕金森病、路易体痴呆等）的重要前驱标志物。腕戴式活动记录仪在通过捕捉夜间异常运动进行大规模RBD筛查方面具有巨大潜力，但缺乏可靠高效的分析流程。

Method: 本研究提出了ActiTect，一个全自动、开源的机器学习工具。该工具包括鲁棒的预处理和自动睡眠-觉醒检测，以协调多设备数据并提取生理可解释的运动特征。模型开发使用78名个体的数据，并在嵌套交叉验证中获得0.95的AUROC。

Result: ActiTect在盲法本地测试集（n = 31, AUROC = 0.86）和两个独立的外部队列（n = 113, AUROC = 0.84; n = 57, AUROC = 0.94）上确认了泛化能力。留一数据集交叉验证显示持续的性能（AUROC范围 = 0.84-0.89），关键预测特征在不同数据集间可重现。

Conclusion: ActiTect是一个稳健的预训练资源，可广泛部署，它通过开源和易用性促进了RBD检测工具的普及，并推动了可穿戴设备在统一和通用RBD检测模型方面的发展。

Abstract: Isolated rapid eye movement sleep behavior disorder (iRBD) is a major
prodromal marker of $\alpha$-synucleinopathies, often preceding the clinical
onset of Parkinson's disease, dementia with Lewy bodies, or multiple system
atrophy. While wrist-worn actimeters hold significant potential for detecting
RBD in large-scale screening efforts by capturing abnormal nocturnal movements,
they become inoperable without a reliable and efficient analysis pipeline. This
study presents ActiTect, a fully automated, open-source machine learning tool
to identify RBD from actigraphy recordings. To ensure generalizability across
heterogeneous acquisition settings, our pipeline includes robust preprocessing
and automated sleep-wake detection to harmonize multi-device data and extract
physiologically interpretable motion features characterizing activity patterns.
Model development was conducted on a cohort of 78 individuals, yielding strong
discrimination under nested cross-validation (AUROC = 0.95). Generalization was
confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two
independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To
assess real-world robustness, leave-one-dataset-out cross-validation across the
internal and external cohorts demonstrated consistent performance (AUROC range
= 0.84-0.89). A complementary stability analysis showed that key predictive
features remained reproducible across datasets, supporting the final pooled
multi-center model as a robust pre-trained resource for broader deployment. By
being open-source and easy to use, our tool promotes widespread adoption and
facilitates independent validation and collaborative improvements, thereby
advancing the field toward a unified and generalizable RBD detection model
using wearable devices.

</details>


### [87] [The Causal Round Trip: Generating Authentic Counterfactuals by Eliminating Information Loss](https://arxiv.org/abs/2511.05236)
*Rui Wu,Lizheng Wang,Yongjun Li*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为BELM-MDCM的新的扩散模型框架，旨在通过消除结构重建误差（SRE）来实现忠实的反事实推理，从而弥合现代生成模型与经典因果理论之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: Judea Pearl的结构因果模型（SCM）的反事实推理愿景依赖于精确推断潜在外生噪声的忠实溯因。然而，在复杂非线性机制中实现这一目标一直是一个重大的计算挑战。

Method: 本文提出了一种名为BELM-MDCM的扩散模型框架，通过分析可逆机制从构建上消除SRE，从而实现了因果信息的守恒。该框架采用目标建模策略进行结构正则化，并采用混合训练目标来注入强大的因果归纳偏差。

Result: BELM-MDCM框架不仅在准确性方面达到了最先进的水平，而且实现了深度因果研究所需的高保真度、个体层面的反事实。

Conclusion: 这项工作为调和现代生成模型的强大功能与经典因果理论的严谨性提供了基础蓝图，为新兴领域建立了新的、更严格的标准。

Abstract: Judea Pearl's vision of Structural Causal Models (SCMs) as engines for
counterfactual reasoning hinges on faithful abduction: the precise inference of
latent exogenous noise. For decades, operationalizing this step for complex,
non-linear mechanisms has remained a significant computational challenge. The
advent of diffusion models, powerful universal function approximators, offers a
promising solution. However, we argue that their standard design, optimized for
perceptual generation over logical inference, introduces a fundamental flaw for
this classical problem: an inherent information loss we term the Structural
Reconstruction Error (SRE). To address this challenge, we formalize the
principle of Causal Information Conservation (CIC) as the necessary condition
for faithful abduction. We then introduce BELM-MDCM, the first diffusion-based
framework engineered to be causally sound by eliminating SRE by construction
through an analytically invertible mechanism. To operationalize this framework,
a Targeted Modeling strategy provides structural regularization, while a Hybrid
Training Objective instills a strong causal inductive bias. Rigorous
experiments demonstrate that our Zero-SRE framework not only achieves
state-of-the-art accuracy but, more importantly, enables the high-fidelity,
individual-level counterfactuals required for deep causal inquiries. Our work
provides a foundational blueprint that reconciles the power of modern
generative models with the rigor of classical causal theory, establishing a new
and more rigorous standard for this emerging field.

</details>


### [88] [Embedding-Space Data Augmentation to Prevent Membership Inference Attacks in Clinical Time Series Forecasting](https://arxiv.org/abs/2511.05289)
*Marius Fracarolli,Michael Staniek,Stefan Riezler*

Main category: cs.LG

TL;DR: 本文探讨了数据增强在时间序列预测（TSF）模型中缓解成员推断攻击（MIA）的有效性，强调如何在保护隐私的同时保持高预测性能。


<details>
  <summary>Details</summary>
Motivation: 在涉及电子健康记录（EHR）的时间序列预测（TSF）任务中，平衡强大的隐私保障和高预测性能至关重要。

Method: 本研究探讨了数据增强如何缓解TSF模型上的成员推断攻击（MIA）。我们研究了多种数据增强策略——零阶优化（ZOO）、受主成分分析约束的ZOO变体（ZOO-PCA）和MixUp，以在不牺牲准确性的情况下增强模型弹性。

Result: 实验结果表明，ZOO-PCA在MIA攻击中取得了最佳的TPR/FPR比率降低，同时没有牺牲测试数据上的性能。使用合成数据进行再训练可以显著降低基于损失的MIA的有效性，减少攻击者的真阳性与假阳性比率。

Conclusion: 数据增强，特别是ZOO-PCA，能够有效缓解时间序列预测模型中的成员推断攻击，同时保持甚至提升模型的泛化能力和预测性能，从而在保护用户隐私和模型实用性之间取得平衡。

Abstract: Balancing strong privacy guarantees with high predictive performance is
critical for time series forecasting (TSF) tasks involving Electronic Health
Records (EHR). In this study, we explore how data augmentation can mitigate
Membership Inference Attacks (MIA) on TSF models. We show that retraining with
synthetic data can substantially reduce the effectiveness of loss-based MIAs by
reducing the attacker's true-positive to false-positive ratio. The key
challenge is generating synthetic samples that closely resemble the original
training data to confuse the attacker, while also introducing enough novelty to
enhance the model's ability to generalize to unseen data. We examine multiple
augmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO
constrained by Principal Component Analysis (ZOO-PCA), and MixUp - to
strengthen model resilience without sacrificing accuracy. Our experimental
results show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA
attacks without sacrificing performance on test data.

</details>


### [89] [Attention and Compression is all you need for Controllably Efficient Language Models](https://arxiv.org/abs/2511.05313)
*Jatin Prakash,Aahlad Puli,Rajesh Ranganath*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为Compress & Attend Transformer（CAT）的新型Transformer架构。CAT通过对序列进行压缩来解决现有高效Transformer模型在计算效率和质量之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的高效Transformer模型（如稀疏注意力、滑动窗口注意力、卷积和线性注意力）虽然在计算和内存方面有所改进，但通常会牺牲质量，特别是在上下文回忆性能方面。此外，这些方法通常需要预先固定质量-计算权衡，导致次优结果，并且依赖于启发式选择、复杂的状态更新规则或混合架构，这使得设计过程复杂。

Method: CAT架构提出了一种概念简单的方法，仅使用密集注意力和压缩两种机制。CAT通过关注序列中已压缩的块来解码新的令牌块。压缩可以减少序列长度，从而节省计算和内存。CAT可以在训练时使用多个块大小，从而无需重新训练即可在测试时直接控制质量-计算权衡。

Result: 在常见的语言建模任务、上下文回忆和长上下文理解方面，自适应CAT模型在不同的计算-内存预算下均优于现有高效基线（包括混合架构）。单个CAT模型在语言建模方面能与密集Transformer相媲美，同时速度提高了1.4-3倍，总内存使用量降低了2-9倍。

Conclusion: CAT模型通过结合密集注意力和压缩，提供了一种简单而有效的方法来解决高效Transformer模型的质量-计算权衡问题。它在各种任务和预算下都表现出色，并且具有在测试时进行自适应调整的灵活性。

Abstract: The quadratic cost of attention in transformers motivated the development of
efficient approaches: namely sparse and sliding window attention, convolutions
and linear attention. Although these approaches result in impressive reductions
in compute and memory, they often trade-off with quality, specifically
in-context recall performance. Moreover, apriori fixing this quality-compute
tradeoff means being suboptimal from the get-go: some downstream applications
require more memory for in-context recall, while others require lower latency
and memory. Further, these approaches rely on heuristic choices that
artificially restrict attention, or require handcrafted and complex recurrent
state update rules, or they must be carefully composed with attention at
specific layers to form a hybrid architecture that complicates the design
process, especially at scale. To address above issues, we propose Compress &
Attend Transformer (CAT), a conceptually simple architecture employing two
simple ingredients only: dense attention and compression. CAT decodes chunks of
tokens by attending to compressed chunks of the sequence so far. Compression
results in decoding from a reduced sequence length that yields compute and
memory savings, while choosing a particular chunk size trades-off quality for
efficiency. Moreover, CAT can be trained with multiple chunk sizes at once,
unlocking control of quality-compute trade-offs directly at test-time without
any retraining, all in a single adaptive architecture. In exhaustive
evaluations on common language modeling tasks, in-context recall, and
long-context understanding, a single adaptive CAT model outperforms existing
efficient baselines, including hybrid architectures, across different
compute-memory budgets. Further, a single CAT matches dense transformer in
language modeling across model scales while being 1.4-3x faster and requiring
2-9x lower total memory usage.

</details>


### [90] [Turning Adversaries into Allies: Reversing Typographic Attacks for Multimodal E-Commerce Product Retrieval](https://arxiv.org/abs/2511.05325)
*Janet Jenq,Hongda Shen*

Main category: cs.LG

TL;DR: 这篇论文提出了一种通过在商品图片上渲染相关文本内容来增强多模态商品检索性能的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态商品检索系统（如CLIP）容易受到文本攻击，即图片中嵌入的误导性或不相关文本会影响模型预测。

Method: 本文提出了一种新颖的方法，通过在商品图片上直接渲染相关的文本内容（例如，标题、描述）来逆转文本攻击的逻辑，从而进行视觉-文本压缩，增强图像-文本对齐，并提升多模态商品检索性能。

Result: 作者在三个垂直领域的电商数据集（运动鞋、手提包和交易卡）上，使用六个最先进的视觉基础模型评估了所提出的方法。实验结果表明，在所有类别和模型家族中，单模态和多模态检索的准确性都得到了持续的改善。

Conclusion: 研究结果表明，视觉渲染商品元数据是一种简单而有效的方法，可以增强电商应用中的零样本多模态检索性能。

Abstract: Multimodal product retrieval systems in e-commerce platforms rely on
effectively combining visual and textual signals to improve search relevance
and user experience. However, vision-language models such as CLIP are
vulnerable to typographic attacks, where misleading or irrelevant text embedded
in images skews model predictions. In this work, we propose a novel method that
reverses the logic of typographic attacks by rendering relevant textual content
(e.g., titles, descriptions) directly onto product images to perform
vision-text compression, thereby strengthening image-text alignment and
boosting multimodal product retrieval performance. We evaluate our method on
three vertical-specific e-commerce datasets (sneakers, handbags, and trading
cards) using six state-of-the-art vision foundation models. Our experiments
demonstrate consistent improvements in unimodal and multimodal retrieval
accuracy across categories and model families. Our findings suggest that
visually rendering product metadata is a simple yet effective enhancement for
zero-shot multimodal retrieval in e-commerce applications.

</details>


### [91] [Learning Dynamics from Input-Output Data with Hamiltonian Gaussian Processes](https://arxiv.org/abs/2511.05330)
*Jan-Hendrik Ewering,Robin E. Herrmann,Niklas Wahlström,Thomas B. Schön,Thomas Seel*

Main category: cs.LG

TL;DR: 本文提出了一种基于非保守哈密顿高斯过程（GP）的方法，用于在仅有输入输出数据的情况下学习动力学模型，并通过降秩GP近似解决了计算复杂性问题，优于依赖动量测量的现有方法。


<details>
  <summary>Details</summary>
Motivation: 在有限数据下，将能量守恒等非限制性先验知识嵌入到学习方法中，以构建物理一致的模型，这对于基于模型的控制等领域至关重要。

Method: 本文提出了一种基于非保守哈密顿高斯过程（GP）的方法，用于从输入输出数据中学习动力学模型。该方法提供了一个完全贝叶斯方案，用于估计未知隐藏状态、GP超参数以及结构超参数（如阻尼系数）的概率密度。为了解决计算复杂性问题，该方法利用了降秩GP近似，以实现高效的预测和训练。

Result: 在非线性仿真案例研究中对所提出的方法进行了评估，结果表明该方法优于依赖动量测量的现有最新方法。

Conclusion: 本文提出了一种有效的方法，通过非保守哈密顿高斯过程和降秩GP近似，在仅有输入输出数据的情况下成功学习动力学模型，解决了实际应用中速度或动量数据稀缺的问题，并取得了优于现有方法的性能。

Abstract: Embedding non-restrictive prior knowledge, such as energy conservation laws,
in learning-based approaches is a key motive to construct physically consistent
models from limited data, relevant for, e.g., model-based control. Recent work
incorporates Hamiltonian dynamics into Gaussian Process (GP) regression to
obtain uncertainty-quantifying models that adhere to the underlying physical
principles. However, these works rely on velocity or momentum data, which is
rarely available in practice. In this paper, we consider dynamics learning with
non-conservative Hamiltonian GPs, and address the more realistic problem
setting of learning from input-output data. We provide a fully Bayesian scheme
for estimating probability densities of unknown hidden states, of GP
hyperparameters, as well as of structural hyperparameters, such as damping
coefficients. Considering the computational complexity of GPs, we take
advantage of a reduced-rank GP approximation and leverage its properties for
computationally efficient prediction and training. The proposed method is
evaluated in a nonlinear simulation case study and compared to a
state-of-the-art approach that relies on momentum measurements.

</details>


### [92] [SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically Consistent Planning](https://arxiv.org/abs/2511.05355)
*Tzu-Yuan Huang,Armin Lederer,Dai-Jie Wu,Xiaobing Dai,Sihua Zhang,Stefan Sosnowski,Shao-Hua Sun,Sandra Hirche*

Main category: cs.LG

TL;DR: SAD-Flower是一个新的框架，通过引入虚拟控制输入，可以生成安全、可接受和动态一致的轨迹，并在不重新训练的情况下满足未见过的约束。


<details>
  <summary>Details</summary>
Motivation: 现有的流匹配（FM）方法在数据驱动规划中缺乏确保状态和动作约束的正式保证，也无法保证动态一致性，这对于规划轨迹的安全性和可执行性至关重要。

Method: SAD-Flower通过对流的虚拟控制输入进行增强，利用非线性控制理论技术提供指导，从而保证状态约束、动作约束和动态一致性。

Result: SAD-Flower在各种任务中表现出色，在确保约束满足方面优于其他基于生成模型的基线。

Conclusion: SAD-Flower框架有效地解决了流匹配在保证轨迹安全、可接受和动态一致性方面的缺陷，并能在不重新训练的情况下适应新的约束，为数据驱动规划提供了更可靠的解决方案。

Abstract: Flow matching (FM) has shown promising results in data-driven planning.
However, it inherently lacks formal guarantees for ensuring state and action
constraints, whose satisfaction is a fundamental and crucial requirement for
the safety and admissibility of planned trajectories on various systems.
Moreover, existing FM planners do not ensure the dynamical consistency, which
potentially renders trajectories inexecutable. We address these shortcomings by
proposing SAD-Flower, a novel framework for generating Safe, Admissible, and
Dynamically consistent trajectories. Our approach relies on an augmentation of
the flow with a virtual control input. Thereby, principled guidance can be
derived using techniques from nonlinear control theory, providing formal
guarantees for state constraints, action constraints, and dynamic consistency.
Crucially, SAD-Flower operates without retraining, enabling test-time
satisfaction of unseen constraints. Through extensive experiments across
several tasks, we demonstrate that SAD-Flower outperforms various
generative-model-based baselines in ensuring constraint satisfaction.

</details>


### [93] [Diffusion-Based Electromagnetic Inverse Design of Scattering Structured Media](https://arxiv.org/abs/2511.05357)
*Mikhail Tsukerman,Konstantin Grotov,Pavel Ginzburg*

Main category: cs.LG

TL;DR: 该论文提出了一种用于电磁逆向设计的条件扩散模型。


<details>
  <summary>Details</summary>
Motivation: 以往的电磁逆向设计方法需要昂贵的迭代优化。

Method: 本文提出了一种条件扩散模型，利用1D U-Net架构和Feature-wise Linear Modulation，将期望的角散射模式映射到2x2的介电球结构，通过采样各种有效设计来处理逆向问题的非唯一性。

Result: 该模型在11,000个模拟超表面的数据集上进行训练，在未见过的目标上实现了低于19%的中位MPE（最佳：1.39%），优于CMA-ES进化优化，并将设计时间从数小时缩短到数秒。

Conclusion: 将扩散模型应用于电磁逆向设计有望加速复杂超表面架构的探索以及下一代光子和无线通信系统的发展。

Abstract: We present a conditional diffusion model for electromagnetic inverse design
that generates structured media geometries directly from target differential
scattering cross-section profiles, bypassing expensive iterative optimization.
Our 1D U-Net architecture with Feature-wise Linear Modulation learns to map
desired angular scattering patterns to 2x2 dielectric sphere structure,
naturally handling the non-uniqueness of inverse problems by sampling diverse
valid designs. Trained on 11,000 simulated metasurfaces, the model achieves
median MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES
evolutionary optimization while reducing design time from hours to seconds.
These results demonstrate that employing diffusion models is promising for
advancing electromagnetic inverse design research, potentially enabling rapid
exploration of complex metasurface architectures and accelerating the
development of next-generation photonic and wireless communication systems. The
code is publicly available at
https://github.com/mikzuker/inverse_design_metasurface_generation.

</details>


### [94] [Adversarially Robust Multitask Adaptive Control](https://arxiv.org/abs/2511.05444)
*Kasra Fallah,Leonardo F. Toso,James Anderson*

Main category: cs.LG

TL;DR: 本文研究了对抗性鲁棒多任务自适应线性二次控制，并提出了一种聚类的多任务方法。


<details>
  <summary>Details</summary>
Motivation: 在模型不确定性和对抗性损坏下，多个系统协同学习控制策略。

Method: 提出了一种聚类的多任务方法，该方法将聚类和系统识别与弹性聚合相结合，以减轻损坏的模型更新。

Result: 分析了聚类精度、簇内异质性和对抗行为如何影响LQR任务的确定性等效控制的预期遗憾。
建立了非渐近界，表明遗憾随每个簇中诚实系统数量的增加而减小，并且在每个簇中存在有界比例的对抗性系统的情况下，这种减小仍然保持不变。

Conclusion: 所提出的聚类多任务方法在对抗性鲁棒多任务自适应线性二次控制中表现出良好的性能，并且能够有效地处理模型不确定性和对抗性损坏。

Abstract: We study adversarially robust multitask adaptive linear quadratic control; a
setting where multiple systems collaboratively learn control policies under
model uncertainty and adversarial corruption. We propose a clustered multitask
approach that integrates clustering and system identification with resilient
aggregation to mitigate corrupted model updates. Our analysis characterizes how
clustering accuracy, intra-cluster heterogeneity, and adversarial behavior
affect the expected regret of certainty-equivalent (CE) control across LQR
tasks. We establish non-asymptotic bounds demonstrating that the regret
decreases inversely with the number of honest systems per cluster and that this
reduction is preserved under a bounded fraction of adversarial systems within
each cluster.

</details>


### [95] [SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning](https://arxiv.org/abs/2511.05462)
*Xiaodong Wang,Jing Huang,Kevin J Liang*

Main category: cs.LG

TL;DR: 本文介绍了一种聚类方法SiamMM，它在各种无监督学习任务中都达到了最先进的性能，其学习到的聚类与未见过的真实标签非常相似。


<details>
  <summary>Details</summary>
Motivation: 现有的基于聚类的无监督学习方法通常是启发式的，缺乏理论基础，且最佳方法不明确。

Method: 本文将无监督聚类方法与经典的统计混合模型联系起来，并在此框架下对聚类方法进行了改进，提出了SiamMM模型。

Result: SiamMM在多种自监督学习基准测试中取得了最先进的性能，并且学习到的聚类与未见过的真实标签高度相似，甚至能发现潜在的错误标签。

Conclusion: 本文通过将无监督聚类与统计混合模型相结合，提出了一种性能卓越的新型模型SiamMM，并在自监督学习领域取得了显著进展。

Abstract: Recent studies have demonstrated the effectiveness of clustering-based
approaches for self-supervised and unsupervised learning. However, the
application of clustering is often heuristic, and the optimal methodology
remains unclear. In this work, we establish connections between these
unsupervised clustering methods and classical mixture models from statistics.
Through this framework, we demonstrate significant enhancements to these
clustering methods, leading to the development of a novel model named SiamMM.
Our method attains state-of-the-art performance across various self-supervised
learning benchmarks. Inspection of the learned clusters reveals a strong
resemblance to unseen ground truth labels, uncovering potential instances of
mislabeling.

</details>


### [96] [SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive Cross-Component Learning](https://arxiv.org/abs/2511.05482)
*Kang Yang,Yuanlin Yang,Yuning Chen,Sikai Yang,Xinyu Zhang,Wan Du*

Main category: cs.LG

TL;DR: 这篇文章介绍了一种名为SoilX的免校准土壤传感系统，它可以同时测量土壤中的水分、氮、磷、钾、有机碳和铝，解决了传统方法需要针对不同土壤质地进行重新校准的问题，并提高了测量精度。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要持续准确地监测土壤水分和主要常量营养素，以优化产量和节约资源。然而，现有的无线土壤传感解决方案需要针对不同的土壤质地进行重新校准，这限制了其实用性。

Method: SoilX系统通过显式建模有机碳（C）和铝（Al），消除了对土壤质地和碳含量依赖的重新校准。它采用了对比跨组分学习（3CL），并包含正交正则化器和分离损失两个定制项，以有效 S解耦跨组分干扰。此外，SoilX设计了一种新型的带有天线切换机制的四面体天线阵列，可以独立于设备放置地鲁棒地测量土壤介电常数。

Result: 广泛的实验表明，SoilX将估计误差比基线降低了23.8%到31.5%，并且对未 P见的田地具有良好的泛化能力。

Conclusion: SoilX是一个免校准的土壤传感系统，通过同时测量多 N个土壤组分，并采用先进的机器学习和天线设计，解决了传统土壤传感技术的局限性，显著提高了土壤参数测量的精度和实用性。

Abstract: Precision agriculture demands continuous and accurate monitoring of soil
moisture (M) and key macronutrients, including nitrogen (N), phosphorus (P),
and potassium (K), to optimize yields and conserve resources. Wireless soil
sensing has been explored to measure these four components; however, current
solutions require recalibration (i.e., retraining the data processing model) to
handle variations in soil texture, characterized by aluminosilicates (Al) and
organic carbon (C), limiting their practicality. To address this, we introduce
SoilX, a calibration-free soil sensing system that jointly measures six key
components: {M, N, P, K, C, Al}. By explicitly modeling C and Al, SoilX
eliminates texture- and carbon-dependent recalibration. SoilX incorporates
Contrastive Cross-Component Learning (3CL), with two customized terms: the
Orthogonality Regularizer and the Separation Loss, to effectively disentangle
cross-component interference. Additionally, we design a novel tetrahedral
antenna array with an antenna-switching mechanism, which can robustly measure
soil dielectric permittivity independent of device placement. Extensive
experiments demonstrate that SoilX reduces estimation errors by 23.8% to 31.5%
over baselines and generalizes well to unseen fields.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [97] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 该文章介绍了他们在2024年综合医疗时间表竞赛中获得第三名的算法、实现和结果。


<details>
  <summary>Details</summary>
Motivation: 解决医疗保健时间表问题。

Method: 该方法结合了混合整数规划、约束规划和模拟退火，采用基于子问题分解的三阶段解决方案。

Result: 在竞赛中获得第三名，并首次为基准实例提供了最优解决方案值的下限。

Conclusion: 文章最后强调了一些悬而未决的问题，这些问题的解决有望进一步改进他们的方法。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [98] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种拒绝选项预测器，它可以识别出由于训练数据不足而导致模型无法做出可靠决策的输入。


<details>
  <summary>Details</summary>
Motivation: 传统的拒绝选项预测器只关注偶然不确定性，而忽略了在数据量有限时也很重要的认知不确定性。

Method: 本文引入了认知拒绝选项预测器，当由不充足数据引起的认知不确定性较高时，该预测器会弃权。该方法基于贝叶斯学习，将最优预测器重新定义为最小化预期遗憾的预测器，即学习模型与完全了解数据分布的贝叶斯最优预测器之间的性能差距。当给定输入的遗憾超出指定的拒绝成本时，模型会弃权。

Result: 本文提出的框架能够学习识别训练数据不足以做出可靠决策的输入的预测器。

Conclusion: 本文提出了第一个有原则的框架，使学习预测器能够识别训练数据不足以做出可靠决策的输入。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [99] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: 本文介绍了一种名为 DMA 的在线学习框架，该框架通过结合多粒度的人类反馈来调整 RAG 系统中的排序，以适应不断变化的意图和内容。DMA 在线和离线评估都取得了显著效果，并且在实际部署中也表现出色。


<details>
  <summary>Details</summary>
Motivation: 在 RAG 系统中，检索通常是静态的，这限制了其适应不断变化的意图和内容。

Method: DMA 框架通过以下方式将文档级、列表级和响应级信号整合到一致的学习流程中：
1. 监督式训练：用于逐点和列表式排序器。
2. 策略优化：由响应级偏好驱动。
3. 知识蒸馏：将知识蒸馏到轻量级评分器中，以实现低延迟服务。

Result: DMA 在以下两方面取得了显著成果：
1. 在线 A/B 实验：大规模在线 A/B 实验隔离了每个反馈源的效用，并在一项为期数月的工业部署中，DMA 显著提高了用户参与度。
2. 离线测试：在知识密集型基准测试中进行的少量离线测试表明，DMA 在保持基础检索竞争力的同时，在会话式问答（TriviaQA、HotpotQA）方面取得了显著进展。

Conclusion: DMA 是一种通过反馈驱动的实时适应 RAG 的原则性方法，在不牺牲基线能力的情况下，有效解决了传统 RAG 系统中检索静态性问题。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [100] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 本文提出了一种支持军事地面作战行动执行阶段决策的方法，重点关注己方行动。


<details>
  <summary>Details</summary>
Motivation: 在军事地面作战行动的执行阶段，需要一种支持决策制定的方法，尤其是在己方行动方面。

Method: 该方法为机械化营生成并评估各种行动方案的建议，从一组根据预期结果评估的初始方案开始。它系统地产生数千种单独的行动替代方案，然后进行评估，以确定具有 S 结果的替代行动方案。这些替代方案根据对手的状态和行动进行评估，考虑单位组成、兵力对比、进攻和防御类型以及预期的推进速度。通过野战手册评估战斗结果和推进速度。生成和评估过程同时进行。

Result: 产生多种替代行动方案，并能根据先前评估的行动管理新方案的生成。随着战斗的展开和条件的变化，在顺序决策框架内为决策者制定修订的行动方案。

Conclusion: 该方法通过系统生成和评估行动方案，为军事地面作战的决策提供了有力支持，尤其是在动态变化的战场 L 境下。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [101] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang,Jiatong Li,Filip Biljecki*

Main category: cs.AI

TL;DR: 这篇论文提出了一个Agentic城市规划AI框架，旨在利用先进的推理AI技术，通过多智能体协作，增强城市规划的决策能力，并详细阐述了其架构、评估指标以及未来研究挑战。


<details>
  <summary>Details</summary>
Motivation: AI在城市规划分析方面取得了显著成功，但目前的挑战在于将AI能力扩展到辅助决策。现有的统计学习方法无法满足城市规划决策中对价值基础、规则约束和可解释性的要求。

Method: 本文提出了一个Agentic城市规划AI框架，该框架集成了三个认知层（感知、基础、推理）和六个逻辑组件（分析、生成、验证、评估、协作、决策），通过多智能体协作框架实现。该方法强调了规划决策需要明确的推理能力，这些能力是基于价值的、有规则依据的和可解释的。

Result: 该框架展示了AI智能体如何通过系统地探索解决方案空间、验证法规遵从性以及透明地权衡利弊来增强人类规划师的能力，而不是取代人类的判断，而是通过计算推理能力来放大它。

Conclusion: Agentic城市规划AI框架为城市规划领域提供了一个新的范式，它通过结合先进的推理AI技术，解决了传统AI方法在决策支持方面的不足，为未来城市规划的智能化发展指明了方向。未来的研究将集中于该框架的基准评估、性能优化以及处理更复杂多变规划场景的能力。

Abstract: AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>
