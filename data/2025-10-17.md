<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 102]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.LG](#cs.LG) [Total: 65]
- [cs.IT](#cs.IT) [Total: 8]
- [stat.ML](#stat.ML) [Total: 8]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Bridging the Semantic Gap: Contrastive Rewards for Multilingual Text-to-SQL](https://arxiv.org/abs/2510.13827)
*Ashish Kattamuri,Ishita Prasad,Meetu Malhotra,Arpita Vats,Rahul Raja,Albert Lie*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架，将GRPO与多语言对比奖励信号相结合，以提高跨语言Text-to-SQL系统的任务效率和语义准确性。


<details>
  <summary>Details</summary>
Motivation: 目前的Text-to-SQL方法忽略了语义对齐挑战，并且在从英语到其他语言时执行准确性显著下降。

Method: 本文提出了一种新的框架，该框架将组相对策略优化（GRPO）与多语言对比奖励信号相结合，以增强跨语言场景中Text-to-SQL系统的任务效率和语义准确性。该方法通过结合基于语义相似度的奖励信号，教导模型在SQL生成和用户意图之间获得更好的对应关系。

Result: 在七语言MultiSpider数据集上，使用GRPO对LLaMA-3-3B模型进行微调，将执行准确性提高到87.4%（比零样本高出26个百分点），语义准确性提高到52.29%（高出32.86个百分点）。在GRPO框架中添加对比奖励信号，将平均语义准确性进一步提高到59.14%（高出6.85个百分点，越南语最高提高10个百分点）。

Conclusion: 本文证明了如何通过对比奖励进行定向语义对齐来提高Text-to-SQL系统的性能，而无需大规模训练数据集。

Abstract: Current Text-to-SQL methods are evaluated and only focused on executable
queries, overlooking the semantic alignment challenge -- both in terms of the
semantic meaning of the query and the correctness of the execution results.
Even execution accuracy itself shows significant drops when moving from English
to other languages, with an average decline of 6 percentage points across
non-English languages. We address these challenges by presenting a new
framework that combines Group Relative Policy Optimization (GRPO) within a
multilingual contrastive reward signal to enhance both task efficiency and
semantic accuracy in Text-to-SQL systems in cross-lingual scenarios. Our method
teaches models to obtain better correspondence between SQL generation and user
intent by combining a reward signal based on semantic similarity. On the
seven-language MultiSpider dataset, fine-tuning the LLaMA-3-3B model with GRPO
improved the execution accuracy up to 87.4 percent (+26 pp over zero-shot) and
semantic accuracy up to 52.29 percent (+32.86 pp). Adding our contrastive
reward signal in the GRPO framework further improved the average semantic
accuracy to 59.14 percent (+6.85 pp, up to +10 pp for Vietnamese). Our
experiments showcase that a smaller, parameter-efficient 3B LLaMA model
fine-tuned with our contrastive reward signal outperforms a much larger
zero-shot 8B LLaMA model, with an uplift of 7.43 pp in execution accuracy (from
81.43 percent on the 8B model to 88.86 percent on the 3B model), and nearly
matches its semantic accuracy (59.14 percent vs. 68.57 percent) -- all using
just 3,000 reinforcement learning training examples. These results demonstrate
how we can improve the performance of Text-to-SQL systems with contrastive
rewards for directed semantic alignment, without requiring large-scale training
datasets.

</details>


### [2] [From Explainability to Action: A Generative Operational Framework for Integrating XAI in Clinical Mental Health Screening](https://arxiv.org/abs/2510.13828)
*Ratna Kandala,Akshata Kishore Moharir,Divya Arvinda Nayak*

Main category: cs.CL

TL;DR: 这篇论文提出了一个生成式操作框架，旨在利用大型语言模型（LLM）弥合心理健康筛查（MHS）中可解释人工智能（XAI）的“实验室到临床”鸿沟，将XAI的原始技术输出转化为临床医生和患者可理解的、具有临床相关性的叙述。


<details>
  <summary>Details</summary>
Motivation: 目前的XAI技术（如SHAP和LIME）能够产生技术上准确的特征重要性得分，但未能提供临床医生可用或患者可理解的、具有临床相关性的可操作见解，导致技术透明度与人类实用性之间脱节，阻碍了XAI在现实世界中的应用。

Method: 本文提出了一个名为“生成式操作框架”的新颖系统架构。该框架利用大型语言模型（LLMs）作为核心翻译引擎，将来自不同XAI工具的原始技术输出与临床指南（通过RAG）相结合，自动生成人类可读、有证据支持的临床叙述。

Result: 通过这种方法，该框架直接解决了关键的操作障碍，包括工作流程整合、偏见缓解和针对不同利益相关者的沟通。

Conclusion: 该论文为推动该领域发展提供了一个战略路线图，旨在将孤立数据点的生成转向在临床实践中交付集成、可操作和值得信赖的AI。

Abstract: Explainable Artificial Intelligence (XAI) has been presented as the critical
component for unlocking the potential of machine learning in mental health
screening (MHS). However, a persistent lab-to-clinic gap remains. Current XAI
techniques, such as SHAP and LIME, excel at producing technically faithful
outputs such as feature importance scores, but fail to deliver clinically
relevant, actionable insights that can be used by clinicians or understood by
patients. This disconnect between technical transparency and human utility is
the primary barrier to real-world adoption. This paper argues that this gap is
a translation problem and proposes the Generative Operational Framework, a
novel system architecture that leverages Large Language Models (LLMs) as a
central translation engine. This framework is designed to ingest the raw,
technical outputs from diverse XAI tools and synthesize them with clinical
guidelines (via RAG) to automatically generate human-readable, evidence-backed
clinical narratives. To justify our solution, we provide a systematic analysis
of the components it integrates, tracing the evolution from intrinsic models to
generative XAI. We demonstrate how this framework directly addresses key
operational barriers, including workflow integration, bias mitigation, and
stakeholder-specific communication. This paper also provides a strategic
roadmap for moving the field beyond the generation of isolated data points
toward the delivery of integrated, actionable, and trustworthy AI in clinical
practice.

</details>


### [3] [A Linguistics-Aware LLM Watermarking via Syntactic Predictability](https://arxiv.org/abs/2510.13829)
*Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han*

Main category: cs.CL

TL;DR: 该论文介绍了一种名为STELA的新型框架，它通过利用语言固有的自由度来调整水印强度，解决了大型语言模型（LLMs）中文本质量与检测鲁棒性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展需要可靠的治理工具，其中公开可验证的水印对于构建值得信赖的AI生态系统至关重要。当前挑战在于平衡文本质量和检测鲁棒性。现有方法依赖模型特定信号，使得公开验证困难。

Method: STELA框架利用词性（POS）n-gram建模的语言不确定性，动态调整水印信号强度。在语法受限的上下文中减弱信号以保持质量，在语言灵活性较大的上下文中增强信号以提高可检测性。该检测器无需访问模型 logits，支持公开可验证的检测。

Result: 通过对英语、汉语和韩语进行广泛实验，STELA在检测鲁棒性方面超越了现有方法。

Conclusion: STELA通过动态调整水印强度，在不牺牲文本质量的前提下，显著提高了大型语言模型水印的检测鲁棒性，并且支持公开验证，为构建可信赖的AI生态系统提供了重要工具。

Abstract: As large language models (LLMs) continue to advance rapidly, reliable
governance tools have become critical. Publicly verifiable watermarking is
particularly essential for fostering a trustworthy AI ecosystem. A central
challenge persists: balancing text quality against detection robustness. Recent
studies have sought to navigate this trade-off by leveraging signals from model
output distributions (e.g., token-level entropy); however, their reliance on
these model-specific signals presents a significant barrier to public
verification, as the detection process requires access to the logits of the
underlying model. We introduce STELA, a novel framework that aligns watermark
strength with the linguistic degrees of freedom inherent in language. STELA
dynamically modulates the signal using part-of-speech (POS) n-gram-modeled
linguistic indeterminacy, weakening it in grammatically constrained contexts to
preserve quality and strengthen it in contexts with greater linguistic
flexibility to enhance detectability. Our detector operates without access to
any model logits, thus facilitating publicly verifiable detection. Through
extensive experiments on typologically diverse languages-analytic English,
isolating Chinese, and agglutinative Korean-we show that STELA surpasses prior
methods in detection robustness. Our code is available at
https://github.com/Shinwoo-Park/stela_watermark.

</details>


### [4] [Users as Annotators: LLM Preference Learning from Comparison Mode](https://arxiv.org/abs/2510.13830)
*Zhongze Cai,Xiaocheng Li*

Main category: cs.CL

TL;DR: 本文探讨了一种从用户生成内容中收集成对偏好数据的新方法，特别关注通过用户行为模型进行质量控制，以有效校准大型语言模型（LLMs）。


<details>
  <summary>Details</summary>
Motivation: 通过考虑让用户注释LLM的回答，而不是传统的由专业人员进行回复，来尝试解决LLM中的对齐问题。这个方法的优点是用户是评价他们自己查询结果的最佳专家，但缺点是这些标签的质量控制不佳。

Method: 通过生成来自两个不同模型或同一模型的两个不同版本的响应来引入不对称性，从而能够通过提出的用户行为模型推断用户数据的质量。文章开发了一个期望最大化算法来估计用户的潜在质量因素，并相应地筛选用户的注释数据。

Result: 下游任务显示，该方法在用户行为捕捉和LLM对齐的数据过滤方面都表现出有效性。

Conclusion: 通过引入不对称响应和用户行为模型，可以有效地从未经专业人员审查的用户注释中估计用户的潜在质量，并过滤数据，从而提高了LLM对齐的效率和准确性。

Abstract: Pairwise preference data have played an important role in the alignment of
large language models (LLMs). Each sample of such data consists of a prompt,
two different responses to the prompt, and a binary label indicating which of
the two responses is better. The labels are usually annotated by professional
human annotators. In this paper, we consider an alternative approach to collect
pairwise preference data -- user annotation from comparison mode. With the
increasingly wider adoption of LLMs among the population, users are
contributing more and more of their preference labels through their daily
interactions with the LLMs. The upside of such labels is that users are the
best experts in judging the responses to their own queries/prompts, but the
downside is the lack of quality control in these labels. In this paper, we
consider a new idea of generating two responses from two different models or
two different versions of the same model. The asymmetry allows us to make an
inference of the user's data quality through our proposed user behavior model.
We develop an expectation-maximization algorithm to estimate a latent quality
factor of the user, and filter users' annotation data accordingly. The
downstream task shows the effectiveness of our approach in both capturing the
user behavior and data filtering for LLM alignment.

</details>


### [5] [Informed Routing in LLMs: Smarter Token-Level Computation for Faster Inference](https://arxiv.org/abs/2510.13831)
*Chao Han,Yijuan Liang,Zihao Xuan,Daokuan Wu,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种名为“informed routing”的新范式，旨在通过评估令牌的即时重要性和可恢复性来解决大型语言模型部署中存在的推断成本高昂的问题。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型在实际应用中受限于其高昂的推理成本，现有方法依赖贪婪路由，这常导致信息丢失和次优的令牌选择。

Method: 本文提出了“informed routing”范式。它引入了轻量级特征预测器（LFF）来评估令牌的即时重要性和可恢复性，从而在路由决策前预测单元输出，实现灵活的执行或近似策略。

Result: Informed routing 在语言建模和推理任务上实现了最先进的效率-性能权衡。即使没有最终的LoRA微调，该方法也能达到或超越需要完全微调的强大基线，同时将训练时间减少50%以上。

Conclusion: Informed routing 通过在保持模型保真度的同时大幅降低计算成本，有效解决了大型语言模型推理成本高的问题。

Abstract: The deployment of large language models (LLMs) in real-world applications is
increasingly limited by their high inference cost. While recent advances in
dynamic token-level computation allocation attempt to improve efficiency by
selectively activating model components per token, existing methods rely on
greedy routing--a myopic execute-or-skip mechanism that often leads to
irreversible information loss and suboptimal token selection. This paper
introduces informed routing, a new paradigm that proactively addresses these
issues. The key insight is to assess not only a token's immediate importance
but also its recoverability, i.e., how well its transformation can be
approximated. To this end, we propose the Lightweight Feature Forecaster (LFF),
a small predictive module that estimates a unit's output before routing
decisions are made. This enables a flexible execute-or-approximate policy that
preserves model fidelity while drastically reducing computation. Extensive
experiments on both language modeling and reasoning tasks show that informed
routing achieves state-of-the-art efficiency-performance trade-offs across
multiple sparsity levels. Notably, even without final LoRA fine-tuning, our
method matches or surpasses strong baselines that require full fine-tuning, all
while reducing training time by over 50%. The code is available at:
https://github.com/EIT-NLP/informed-routing

</details>


### [6] [Entropy Meets Importance: A Unified Head Importance-Entropy Score for Stable and Efficient Transformer Pruning](https://arxiv.org/abs/2510.13832)
*Minsik Choi,Hyegang Son,Changhoon Kim,Young Geun Kim*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为HIES（Head Importance-Entropy Score）的注意力头剪枝新方法，旨在解决Transformer模型在推理和部署中的效率和稳定性挑战。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在自然语言处理任务中表现出色，但其多层和多头注意力结构导致推理和部署效率低下。现有的基于梯度（HIS）的剪枝方法只关注梯度贡献，忽略了注意力模式的多样性，存在局限性。

Method: 本文提出HIES剪枝标准，该标准将注意力头重要性分数与注意力熵相结合，为每个注意力头的贡献提供了互补的证据。

Result: 与单独使用HIS的方法相比，基于HIES的剪枝方法在模型质量上提升了15.2%，稳定性提升了2.04倍。

Conclusion: HIES剪枝方法可以在不牺牲准确性或稳定性的前提下，实现显著的模型压缩。

Abstract: Transformer-based models have achieved remarkable performance in NLP tasks.
However, their structural characteristics-multiple layers and attention
heads-introduce efficiency challenges in inference and deployment. To address
these challenges, various pruning methods have recently been proposed. Notably,
gradient-based methods using Head Importance Scores (HIS) have gained traction
for interpretability, efficiency, and ability to identify redundant heads.
However, HIS alone has limitations as it captures only the gradient-driven
contribution, overlooking the diversity of attention patterns. To overcome
these limitations, we introduce a novel pruning criterion, HIES (Head
Importance-Entropy Score), which integrates head importance scores with
attention entropy, providing complementary evidence on per-head contribution.
Empirically, HIES-based pruning yields up to 15.2% improvement in model quality
and 2.04x improvement in stability over HIS-only methods, enabling substantial
model compression without sacrificing either accuracy or stability. Code will
be released upon publication.

</details>


### [7] [Seeing Hate Differently: Hate Subspace Modeling for Culture-Aware Hate Speech Detection](https://arxiv.org/abs/2510.13837)
*Weibin Cai,Reza Zafarani*

Main category: cs.CL

TL;DR: 该文章提出了一种文化感知框架来克服仇恨言论检测中现有方法面对的挑战，例如数据稀疏性、文化纠缠和模糊标签。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测方法忽略了训练标签有偏差以及不同文化背景个体对仇恨定义解释不同的现实复杂性。

Method: 提出了一种文化感知框架，该框架构建了个体的仇恨子空间。通过对文化属性组合进行建模以减轻数据稀疏性。利用标签传播来捕获每种组合的独特特征，以解决文化纠缠和模糊标签问题。

Result: 实验表明，该方法在所有指标上的表现平均优于最先进水平1.05%。

Conclusion: 该文章提出的文化感知框架能有效解决仇恨言论检测中存在的文化差异和标签模糊问题，并提升了检测性能。

Abstract: Hate speech detection has been extensively studied, yet existing methods
often overlook a real-world complexity: training labels are biased, and
interpretations of what is considered hate vary across individuals with
different cultural backgrounds. We first analyze these challenges, including
data sparsity, cultural entanglement, and ambiguous labeling. To address them,
we propose a culture-aware framework that constructs individuals' hate
subspaces. To alleviate data sparsity, we model combinations of cultural
attributes. For cultural entanglement and ambiguous labels, we use label
propagation to capture distinctive features of each combination. Finally,
individual hate subspaces, which in turn can further enhance classification
performance. Experiments show our method outperforms state-of-the-art by 1.05\%
on average across all metrics.

</details>


### [8] [ConDABench: Interactive Evaluation of Language Models for Data Analysis](https://arxiv.org/abs/2510.13835)
*Avik Dutta,Priyanshu Gupta,Hosein Hasanbeig,Rahul Pratap Singh,Harshit Nigam,Sumit Gulwani,Arjun Radhakrishna,Gustavo Soares,Ashish Tiwari*

Main category: cs.CL

TL;DR: 介绍了ConDABench，一个用于生成对话式数据分析（ConDA）基准和评估外部工具的框架。


<details>
  <summary>Details</summary>
Motivation: 现有的用于评估大型语言模型（LLMs）在数据分析任务上的基准未能捕捉到用户交互的复杂性，也未能提供对交互性的一流支持。

Method: ConDABench包含一个多智能体工作流程，用于从描述从公共数据集中获得见解的文章中生成真实的基准；1,420个通过此工作流程生成的ConDA问题；以及一个评估工具，首次使得系统地评估对话式数据分析工具在生成的ConDA问题上成为可能。

Result: 对基准上最先进的LLMs的评估表明，新一代模型在解决更多实例方面表现更好，但在解决需要持续、长期参与的任务方面不一定更优。

Conclusion: ConDABench为模型构建者提供了一条途径，以衡量在实现能够完成复杂交互任务的真正协作模型方面的进展。

Abstract: Real-world data analysis tasks often come with under-specified goals and
unclean data. User interaction is necessary to understand and disambiguate a
user's intent, and hence, essential to solving these complex tasks. Existing
benchmarks for evaluating LLMs on data analysis tasks do not capture these
complexities or provide first-class support for interactivity. We introduce
ConDABench, a framework for generating conversational data analysis (ConDA)
benchmarks and evaluating external tools on the generated benchmarks. \bench
consists of (a) a multi-agent workflow for generating realistic benchmarks from
articles describing insights gained from public datasets, (b) 1,420 ConDA
problems generated using this workflow, and (c) an evaluation harness that, for
the first time, makes it possible to systematically evaluate conversational
data analysis tools on the generated ConDA problems. Evaluation of
state-of-the-art LLMs on the benchmarks reveals that while the new generation
of models are better at solving more instances, they are not necessarily better
at solving tasks that require sustained, long-form engagement. ConDABench is an
avenue for model builders to measure progress towards truly collaborative
models that can complete complex interactive tasks.

</details>


### [9] [SIMBA UQ: Similarity-Based Aggregation for Uncertainty Quantification in Large Language Models](https://arxiv.org/abs/2510.13836)
*Debarun Bhattacharjya,Balaji Ganesan,Junkyu Lee,Radu Marinescu,Katsiaryna Mirylenka,Michael Glass,Xiao Shou*

Main category: cs.CL

TL;DR: 大语言模型（LLM）的“知其不知”能力至关重要，本文研究了主要但不完全是黑盒的不确定性量化（UQ）方法，并提出了一个基于相似性的聚合框架，通过实证研究证明了其在多任务上的有效性。


<details>
  <summary>Details</summary>
Motivation: 不确定性量化（UQ）能够评估大型语言模型（LLM）生成输出的置信度，并且正日益被认为是可信AI系统的关键组成部分。

Method: 本文调查了主要但不完全是黑盒的UQ技术，这些技术通过生成输出与其他采样生成之间的一致性来衡量置信度。作者提出了一个高层级的、非语言化的、基于相似性的聚合框架，该框架涵盖了适用于复杂生成任务的UQ方法，并引入了该框架中用于训练置信度估计模型的特定新颖技术。

Result: 通过对问答、摘要和Text-to-SQL等任务数据集进行的实证研究表明，本文提出的基于相似性的方法能够产生比基线更好的校准置信度。

Conclusion: 本文研究了大型语言模型中不确定性量化的问题，提出了一种基于相似性的聚合框架，并在多种任务上验证了其有效性，为提升LLM的可信度提供了新的途径。

Abstract: When does a large language model (LLM) know what it does not know?
Uncertainty quantification (UQ) provides measures of uncertainty, such as an
estimate of the confidence in an LLM's generated output, and is therefore
increasingly recognized as a crucial component of trusted AI systems. Black-box
UQ methods do not require access to internal model information from the
generating LLM and therefore have numerous real-world advantages, such as
robustness to system changes, adaptability to choice of LLM, reduced costs, and
computational tractability. In this paper, we investigate the effectiveness of
UQ techniques that are primarily but not necessarily entirely black-box, where
the consistency between a generated output and other sampled generations is
used as a proxy for confidence in its correctness. We propose a high-level
non-verbalized similarity-based aggregation framework that subsumes a broad
swath of UQ approaches suitable for complex generative tasks, as well as
introduce specific novel techniques from the framework that train confidence
estimation models using small training sets. Through an empirical study with
datasets spanning the diverse tasks of question answering, summarization, and
text-to-SQL, we demonstrate that our proposed similarity-based methods can
yield better calibrated confidences than baselines.

</details>


### [10] [Meronymic Ontology Extraction via Large Language Models](https://arxiv.org/abs/2510.13839)
*Dekai Zhang,Simone Conia,Antonio Rago*

Main category: cs.CL

TL;DR: 本体在数字化时代对于组织大量非结构化文本至关重要。传统的本体构建方法耗时费力。本文提出了一种利用大型语言模型（LLMs）从原始评论文本中全自动提取本体（以部分-整体关系形式）的方法。实验证明，该方法生成的本体优于现有的基于BERT的基线方法。


<details>
  <summary>Details</summary>
Motivation: 本体在电子商务等领域具有重要价值，但手动构建本体耗时且成本高昂。

Method: 利用大型语言模型（LLMs）从原始评论文本中全自动提取产品本体，本体形式为部分-整体关系（meronymies）。

Result: 本文方法生成的本体在LLM作为评估者的评估中，超越了现有的基于BERT的基线方法。

Conclusion: 本研究为LLMs在本体提取（无论是产品本体还是其他类型本体）中的更广泛应用奠定了基础。

Abstract: Ontologies have become essential in today's digital age as a way of
organising the vast amount of readily available unstructured text. In providing
formal structure to this information, ontologies have immense value and
application across various domains, e.g., e-commerce, where countless product
listings necessitate proper product organisation. However, the manual
construction of these ontologies is a time-consuming, expensive and laborious
process. In this paper, we harness the recent advancements in large language
models (LLMs) to develop a fully-automated method of extracting product
ontologies, in the form of meronymies, from raw review texts. We demonstrate
that the ontologies produced by our method surpass an existing, BERT-based
baseline when evaluating using an LLM-as-a-judge. Our investigation provides
the groundwork for LLMs to be used more generally in (product or otherwise)
ontology extraction.

</details>


### [11] [ADMIT: Few-shot Knowledge Poisoning Attacks on RAG-based Fact Checking](https://arxiv.org/abs/2510.13842)
*Yutao Wu,Xiao Liu,Yinghui Li,Yifeng Gao,Yifan Ding,Jiale Ding,Xiang Zheng,Xingjun Ma*

Main category: cs.CL

TL;DR: ADMIT是一种针对RAG系统事实核查设置的知识中毒攻击，它通过注入少量语义对齐的对抗性内容，有效地操纵大型语言模型产生攻击者控制的输出，具有很高的攻击成功率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 以往的工作强调LLM易受误导或恶意检索内容的影响。然而，在真实世界的事实核查场景中，可信证据通常在检索池中占主导地位，这使得问题更具挑战性。该研究旨在探究在这种复杂情况下知识中毒的有效性。

Method: 本文提出了一种名为ADMIT（ADversarial Multi-Injection Technique）的少样本、语义对齐的知识中毒攻击方法。ADMIT无需访问目标LLM、检索器或进行token级别的控制，即可翻转事实核查决策并诱导欺骗性解释。

Result: ADMIT在4种检索器、11种LLM和4个跨领域基准测试中表现出良好的泛化性，平均攻击成功率（ASR）高达86%，而中毒率极低，仅为0.93 × 10^-6。即使存在强有力的反证据，ADMIT仍然保持稳健。

Conclusion: ADMIT攻击相较于以往最先进的攻击方法，在所有设置下A SR提高了11.2%，揭示了RAG事实核查系统在现实世界中的显著漏洞。这表明当前的RAG系统在面对精细的知识中毒攻击时存在严重缺陷，需要加强防御机制。

Abstract: Knowledge poisoning poses a critical threat to Retrieval-Augmented Generation
(RAG) systems by injecting adversarial content into knowledge bases, tricking
Large Language Models (LLMs) into producing attacker-controlled outputs
grounded in manipulated context. Prior work highlights LLMs' susceptibility to
misleading or malicious retrieved content. However, real-world fact-checking
scenarios are more challenging, as credible evidence typically dominates the
retrieval pool. To investigate this problem, we extend knowledge poisoning to
the fact-checking setting, where retrieved context includes authentic
supporting or refuting evidence. We propose \textbf{ADMIT}
(\textbf{AD}versarial \textbf{M}ulti-\textbf{I}njection \textbf{T}echnique), a
few-shot, semantically aligned poisoning attack that flips fact-checking
decisions and induces deceptive justifications, all without access to the
target LLMs, retrievers, or token-level control. Extensive experiments show
that ADMIT transfers effectively across 4 retrievers, 11 LLMs, and 4
cross-domain benchmarks, achieving an average attack success rate (ASR) of 86\%
at an extremely low poisoning rate of $0.93 \times 10^{-6}$, and remaining
robust even in the presence of strong counter-evidence. Compared with prior
state-of-the-art attacks, ADMIT improves ASR by 11.2\% across all settings,
exposing significant vulnerabilities in real-world RAG-based fact-checking
systems.

</details>


### [12] [Serialized EHR make for good text representations](https://arxiv.org/abs/2510.13843)
*Zhirong Chou,Quan Qin,Shi Li*

Main category: cs.CL

TL;DR: SerialBEHRT通过在结构化EHR序列上对SciBERT进行额外预训练，解决了现有医学基础模型在处理EHRs时面临的表格和事件特性的结构不匹配问题。它在抗生素敏感性预测任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗领域基础模型在处理电子健康记录（EHRs）的表格和事件特性时，与自然语言模型的序列先验之间存在结构不匹配，这限制了它们捕捉患者就诊之间的纵向依赖关系的能力。

Method: 本文引入了一个名为SerialBEHRT的领域对齐基础模型。该模型通过在结构化EHR序列上进行额外的预训练来扩展SciBERT，旨在编码临床事件之间的时间和上下文关系，从而生成更丰富的患者表征。

Result: 通过与最先进的EHR表征策略进行广泛基准测试，SerialBEHRT在抗生素敏感性预测任务上取得了卓越且更稳定一致的性能。

Conclusion: SerialBEHRT的优异表现强调了在医疗领域基础模型预训练中时间序列化的重要性，它有效解决了现有模型在处理EHR数据时的结构不匹配问题并提高了表征能力。

Abstract: The emergence of foundation models in healthcare has opened new avenues for
learning generalizable representations from large scale clinical data. Yet,
existing approaches often struggle to reconcile the tabular and event based
nature of Electronic Health Records (EHRs) with the sequential priors of
natural language models. This structural mismatch limits their ability to
capture longitudinal dependencies across patient encounters. We introduce
SerialBEHRT, a domain aligned foundation model that extends SciBERT through
additional pretraining on structured EHR sequences. SerialBEHRT is designed to
encode temporal and contextual relationships among clinical events, thereby
producing richer patient representations. We evaluate its effectiveness on the
task of antibiotic susceptibility prediction, a clinically meaningful problem
in antibiotic stewardship. Through extensive benchmarking against state of the
art EHR representation strategies, we demonstrate that SerialBEHRT achieves
superior and more consistent performance, highlighting the importance of
temporal serialization in foundation model pretraining for healthcare.

</details>


### [13] [DynaSpec: Context-aware Dynamic Speculative Sampling for Large-Vocabulary Language Models](https://arxiv.org/abs/2510.13847)
*Jinbin Zhang,Nasib Ullah,Erik Schultheis,Rohit Babbar*

Main category: cs.CL

TL;DR: 本文提出DynaSpec，一种上下文相关的动态短列表机制，用于加速LLM推理中的推测解码，解决了现有方法在处理大型词汇表时的瓶颈，并在提高效率的同时保持了准确性。


<details>
  <summary>Details</summary>
Motivation: 推测解码在加速大型语言模型（LLM）推理方面表现出色，但随着LLM词汇量增加，draft模型输出头部的参数量成为延迟瓶颈。现有方法限制draft模型的词汇表，但这导致语料库依赖性和对不常见或特定领域词元的抑制。

Method: DynaSpec引入轻量级、粗粒度的元分类器，将上下文路由到少量词元簇。这些簇的并集形成draft模型的短列表，而验证阶段保留完整的词汇表。元分类器利用并行执行在draft模型隐藏状态生成之前完成计算。

Result: 在标准推测解码基准测试中，DynaSpec相对于固定短列表基线，在平均接受长度方面取得了一致的提升。上下文相关的选择允许使用更小的短列表，同时不降低接受率，且在不影响模型准确性（exactness）的前提下加速了draft模型的推理。

Conclusion: DynaSpec通过其上下文相关的动态短列表机制，有效解决了LLM推测解码中大型词汇表的效率问题。它提供了一种鲁棒且通用的方法，可以在提高draft模型推理速度的同时，保持验证的准确性，并具有更好的短列表灵活性。

Abstract: Speculative decoding (a.k.a. speculative sampling) has become a standard way
to accelerate LLM inference: a small drafter proposes multiple tokens and a
large target model verifies them once per speculation length. Recently, scaling
of the LLM vocabulary has pushed the number of tokens to grow substantially.
While verification over the full vocabulary leaves the target model largely
unaffected, the O(|V|d) parameters in the drafter's output head become a
latency bottleneck, slowing the entire pipeline. Contemporary methods (e.g.,
FR-Spec, VocabTrim) restrict the drafter's vocabulary to a fixed subset of the
target model's vocabulary, ranked in descending order of token frequency.
Although this reduces draft-time compute, it is brittle, since: (i) frequency
lists are corpus-dependent and require retuning to generalize, and (ii) static
shortlists suppress rare or domain-specific tokens, lowering the expected
number of tokens per verification step. We propose DynaSpec, a
context-dependent dynamic shortlisting mechanism that is robust, speeds up
drafting, and generalizes across diverse tasks. Concretely, we introduce
lightweight, coarse-grained meta-classifiers that route contexts to a small
number of token clusters; the union of the top-k selected clusters forms the
drafter's shortlist, while verification retains the full vocabulary and
exactness. The meta-classifier finishes its computation earlier than the
drafter's hidden state generation by exploiting parallel execution of draft
encoding and meta shortlisting on separate streams. On standard
speculative-decoding benchmarks, we observe consistent gains in mean accepted
length over fixed-shortlist baselines, while context-dependent selection
enables smaller shortlists without degrading acceptance.

</details>


### [14] [On-device System of Compositional Multi-tasking in Large Language Models](https://arxiv.org/abs/2510.13848)
*Ondrej Bohdal,Konstantinos Theodosiadis,Asterios Mpatziakas,Dimitris Filippidis,Iro Spyrou,Christos Zonios,Anastasios Drosou,Dimosthenis Ioannidis,Kyeng-Hun Lee,Jijoong Moon,Hyeonmok Ko,Mete Ozay,Umberto Michieli*

Main category: cs.CL

TL;DR: 本文提出了一种结合LoRA适配器和可学习投影层的新方法，用以解决大语言模型在组合式多任务处理（如翻译和摘要）中的挑战，并在设备端环境中实现了高效且快速的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调（如LoRA）技术在处理大语言模型同时执行复杂组合任务（例如从长对话中生成翻译摘要）时表现不佳。

Method: 通过在组合的摘要和翻译适配器之上添加一个可学习的投影层。这种设计在有效整合任务的同时，通过减少计算开销保持了效率，避免了对替代策略中广泛再训练或顺序处理的需求。

Result: 我们的解决方案在云端和设备端实现中都表现良好且快速，并在我们开发的Android应用中展示了实际可行性。

Conclusion: 本文提出的方法为需要高速运行和资源约束的实际应用场景提供了潜在的益处，在组合式多任务处理方面展现了强大的潜力。

Abstract: Large language models (LLMs) are commonly adapted for diverse downstream
tasks via parameter-efficient fine-tuning techniques such as Low-Rank Adapters
(LoRA). While adapters can be combined to handle multiple tasks separately,
standard approaches struggle when targeting the simultaneous execution of
complex tasks, such as generating a translated summary from a long
conversation. To address this challenge, we propose a novel approach tailored
specifically for compositional multi-tasking scenarios involving summarization
and translation. Our technique involves adding a learnable projection layer on
top of the combined summarization and translation adapters. This design enables
effective integration while maintaining efficiency through reduced
computational overhead compared to alternative strategies requiring extensive
retraining or sequential processing. We demonstrate the practical viability of
our method within an on-device environment by developing an Android app capable
of executing compositional tasks seamlessly. Experimental results indicate our
solution performs well and is fast in both cloud-based and on-device
implementations, highlighting the potential benefits of adopting our framework
in real-world applications demanding high-speed operation alongside resource
constraints.

</details>


### [15] [Language steering in latent space to mitigate unintended code-switching](https://arxiv.org/abs/2510.13849)
*Andrey Goncharov,Nikolai Kondusov,Alexey Zaytsev*

Main category: cs.CL

TL;DR: 该论文提出了一种名为“潜在空间语言引导”的轻量级推理时方法，旨在解决多语言大型语言模型（LLMs）中出现的意外语码转换问题。


<details>
  <summary>Details</summary>
Motivation: 多语言大型语言模型（LLMs）经常出现意外的语码转换，从而降低了下游任务的可靠性。

Method: 该方法通过在并行翻译上使用主成分分析（PCA）来识别语言方向，并沿着这些轴引导token嵌入，以控制语言身份。

Result: 在Qwen2.5和Llama-3.2模型上，该方法使用单个主成分实现了95-99%的语言分类准确率，并将跨多个语言对的下一个token分布差异减少了高达42%。此外，研究发现语言身份集中在最终层，并且具有近乎完美的线性可分离性。

Conclusion: 潜在空间语言引导是一种有效且计算开销可忽略不计的轻量级方法，它可以在保持语义的同时，减轻代码转换问题。

Abstract: Multilingual Large Language Models (LLMs) often exhibit unintended
code-switching, reducing reliability in downstream tasks. We propose
latent-space language steering, a lightweight inference-time method that
identifies language directions via PCA on parallel translations and steers
token embeddings along these axes to control language identity. Our approach
mitigates code-switching while preserving semantics with negligible
computational overhead and requires only minimal parallel data for calibration.
Empirically, we achieve 95-99\% language classification accuracy using a single
principal component and reduce next-token distributional divergence by up to
42% across multiple language pairs on Qwen2.5 and Llama-3.2 models. We further
analyze the layer-wise evolution of language representations, revealing that
language identity concentrates in final layers with near-perfect linear
separability.

</details>


### [16] [Revisiting the UID Hypothesis in LLM Reasoning Traces](https://arxiv.org/abs/2510.13850)
*Minju Gwak,Guijin Son,Jaehyung Kim*

Main category: cs.CL

TL;DR: LLMs在解决问题时，其思维链（CoT）推理的中间步骤往往不可靠或难以解释。成功推理的特点是信息密度波动不均，这与人类交流模式形成鲜明对比，挑战了对机器推理的假设，并为设计可解释和自适应推理模型提供了新方向。


<details>
  <summary>Details</summary>
Motivation: LLMs在解决问题时，其采取的链式思考（`Chain-of-Thought`， `CoT`)推理的中间步骤常常不可靠或者难以解释。这促使我们思考LLMs在推理过程中信息是如何流动的，与人类有何不同。

Method: 本文引入了基于熵的度量来分析推理轨迹中的信息流，并通过人类心理语言学中的统一信息密度（`Uniform Information Density`，`UID`)假设，即人类通过保持信息稳定流进行交流，来对LLMs数学问题推理过程中的信息流进行分析。

Result: 通过在三个具有挑战性的数学基准测试中进行评估，研究发现LLMs的成功推理是全局不均匀的，正确解决方案的特点是信息密度的不均衡波动。这与人类交流模式形成鲜明对比。

Conclusion: 这一结果挑战了关于机器推理的假设，并为设计可解释和自适应推理模型提供了新的方向。

Abstract: Large language models (LLMs) often solve problems using step-by-step
Chain-of-Thought (CoT) reasoning, yet these intermediate steps are frequently
unfaithful or hard to interpret. Inspired by the Uniform Information Density
(UID) hypothesis in psycholinguistics -- which posits that humans communicate
by maintaining a stable flow of information -- we introduce entropy-based
metrics to analyze the information flow within reasoning traces. Surprisingly,
across three challenging mathematical benchmarks, we find that successful
reasoning in LLMs is globally non-uniform: correct solutions are characterized
by uneven swings in information density, in stark contrast to human
communication patterns. This result challenges assumptions about machine
reasoning and suggests new directions for designing interpretable and adaptive
reasoning models.

</details>


### [17] [LLM Prompt Duel Optimizer: Efficient Label-Free Prompt Optimization](https://arxiv.org/abs/2510.13907)
*Yuanchen Wu,Saurabh Verma,Justin Lee,Fangzhou Xiong,Poppy Zhang,Amel Awadelkarim,Xu Chen,Yubai Yuan,Shawndra Hill*

Main category: cs.CL

TL;DR: 本文提出了一种名为Prompt Duel Optimizer（PDO）的样本高效无标签提示优化框架，通过模拟双方博弈场景，利用大型语言模型（LLM）作为评判者提供成对偏好反馈，以优化提示设计。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）对输入提示高度敏感，导致提示设计成为核心挑战。然而，现有的自动化提示优化（APO）方法大多需要依赖于带有真实标签的验证数据，而收集高质量的标签成本高昂且耗时。

Method: PDO框架将提示优化问题建模为“对决赌博机”设置，其监督信号来源于LLM评判者提供的成对偏好反馈。该框架结合了双重汤普森抽样（D-TS）来优先处理信息量丰富的提示比较，并辅以“顶尖表现者引导突变”机制，通过变异高性能提示来 H 扩展候选池。PDO天然地适用于无标签环境，并且能够通过整合部分标签来缓解评判者引入的噪声。

Result: 在BIG-bench Hard (BBH) 和 MS MARCO 数据集上的实验结果表明，PDO始终优于基线方法。

Conclusion: 本文提出的PDO框架在无标签设置下，通过创新的对决赌博机模型和结合D-TS与提示突变机制，有效解决了LLM提示优化中标签数据稀缺的挑战，并在多项任务上展现出卓越性能，为LLM提示设计提供了一种新的高效解决方案。

Abstract: Large language models (LLMs) are highly sensitive to their input prompts,
making prompt design a central challenge. While automatic prompt optimization
(APO) reduces manual engineering, most approaches assume access to ground-truth
references such as labeled validation data. In practice, however, collecting
high-quality labels is costly and slow. We propose the Prompt Duel Optimizer
(PDO), a sample-efficient framework for label-free prompt optimization. PDO
formulates the problem as a dueling-bandit setting, where supervision signal
comes from pairwise preference feedback provided by an LLM judge. The framework
combines Double Thompson Sampling (D-TS), which prioritizes informative prompt
comparisons, with Top-Performer Guided Mutation, which expands the candidate
pool by mutating high-performing prompts. PDO naturally operates in label-free
settings and can also incorporate partial labels to mitigate judge noise.
Experiments on BIG-bench Hard (BBH) and MS MARCO show that PDO consistently
outperforms baseline methods. Ablation studies further demonstrate the
effectiveness of both D-TS and prompt mutation.

</details>


### [18] [EvoEdit: Evolving Null-space Alignment for Robust and Efficient Knowledge Editing](https://arxiv.org/abs/2510.13851)
*Sicheng Lyu,Yu Gu,Xinyu Wang,Jerry Huang,Sitao Luan,Yufei Cui,Xiao-Wen Chang,Peng Lu*

Main category: cs.CL

TL;DR: EvoEdit通过顺序零空间对齐来缓解灾难性干扰，从而实现稳定高效的模型编辑。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）需要持续更新以纠正过时或错误的知识，而现有的模型编辑方法在连续编辑时存在灾难性干扰问题。

Method: EvoEdit通过对每个传入的编辑执行顺序零空间对齐来保留原始和先前修改的知识表示，并保持在长编辑序列中对保留知识的输出不变性，有效减轻了干扰。

Result: 在真实世界的连续知识编辑基准测试中，EvoEdit取得了与现有最先进的定位-编辑技术相当或更好的性能，并且速度提高了3.53倍。

Conclusion: EvoEdit为动态演进的信息设置中LLM的设计提供了一个 F。

Abstract: Large language models (LLMs) require continual updates to rectify outdated or
erroneous knowledge. Model editing has emerged as a compelling paradigm for
introducing targeted modifications without the computational burden of full
retraining. Existing approaches are mainly based on a locate-then-edit
framework. However, in sequential editing contexts, where multiple updates are
applied over time, they exhibit significant limitations and suffer from
catastrophic interference, i.e., new edits compromise previously integrated
updates and degrade preserved knowledge. To address these challenges, we
introduce EvoEdit, a novel editing strategy that mitigates catastrophic
interference through sequential null-space alignment, enabling stable and
efficient model editing. By performing sequential null-space alignment for each
incoming edit, EvoEdit preserves both original and previously modified
knowledge representations and maintains output invariance on preserved
knowledge even across long edit sequences, effectively mitigating interference.
Evaluations on real-world sequential knowledge-editing benchmarks show that
EvoEdit achieves better or comparable performance than prior state-of-the-art
locate-then-edit techniques, with up to 3.53 times speedup. Overall, these
results underscore the necessity of developing more principled approaches for
designing LLMs in dynamically evolving information settings, while providing a
simple yet effective solution with strong theoretical guarantees.

</details>


### [19] [ConsistencyAI: A Benchmark to Assess LLMs' Factual Consistency When Responding to Different Demographic Groups](https://arxiv.org/abs/2510.13852)
*Peter Banyas,Shristi Sharma,Alistair Simmons,Atharva Vispute*

Main category: cs.CL

TL;DR: 本文介绍了ConsistencyAI，一个用于衡量大型语言模型（LLM）在不同用户画像下事实一致性的独立基准。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏衡量LLM在不同用户画像下事实一致性的独立基准。

Method: ConsistencyAI通过让不同用户画像的用户询问相同问题，并评估模型是否给出事实不一致的答案来测试LLM。实验中，对19个LLM进行了100次查询，每次使用不同的用户画像提示上下文，并分析响应的事实一致性。

Result: 在100个人物角色实验中，分数介于0.9065到0.7896之间，平均值为0.8656。xAI的Grok-3表现出最高的一致性，而一些轻量级模型排名最低。一致性因主题而异，就业市场一致性最低，G7世界领导人一致性最高，疫苗或巴以冲突等问题则因提供商而异。

Conclusion: LLM的事实一致性受提供商和主题的影响。本文的代码和交互式演示已发布，以支持可重现的评估并鼓励用户画像不变的提示策略。

Abstract: Is an LLM telling you different facts than it's telling me? This paper
introduces ConsistencyAI, an independent benchmark for measuring the factual
consistency of large language models (LLMs) for different personas.
ConsistencyAI tests whether, when users of different demographics ask identical
questions, the model responds with factually inconsistent answers. Designed
without involvement from LLM providers, this benchmark offers impartial
evaluation and accountability. In our experiment, we queried 19 LLMs with
prompts that requested 5 facts for each of 15 topics. We repeated this query
100 times for each LLM, each time adding prompt context from a different
persona selected from a subset of personas modeling the general population. We
processed the responses into sentence embeddings, computed cross-persona cosine
similarity, and computed the weighted average of cross-persona cosine
similarity to calculate factual consistency scores. In 100-persona experiments,
scores ranged from 0.9065 to 0.7896, and the mean was 0.8656, which we adopt as
a benchmark threshold. xAI's Grok-3 is most consistent, while several
lightweight models rank lowest. Consistency varies by topic: the job market is
least consistent, G7 world leaders most consistent, and issues like vaccines or
the Israeli-Palestinian conflict diverge by provider. These results show that
both the provider and the topic shape the factual consistency. We release our
code and interactive demo to support reproducible evaluation and encourage
persona-invariant prompting strategies.

</details>


### [20] [BenchPress: A Human-in-the-Loop Annotation System for Rapid Text-to-SQL Benchmark Curation](https://arxiv.org/abs/2510.13853)
*Fabian Wenz,Omar Bouattour,Devin Yang,Justin Choi,Cecil Gregg,Nesime Tatbul,Çağatay Demiralp*

Main category: cs.CL

TL;DR: BenchPress是一个人机协作系统，旨在加速创建特定领域的text-to-SQL基准。BenchPress结合了RAG和LLM来提出多种自然语言描述，然后由人类专家进行选择、排名或编辑，以确保准确性和领域对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的text-to-SQL研究主要集中在公共数据集上，但在查询大型私有企业数据仓库时效果较差。手动注释SQL日志以识别其对应的自然语言问题是一项艰巨且昂贵的任务，因此需要一种更高效的方式来创建特定领域的text-to-SQL基准。

Method: BenchPress利用检索增强生成（RAG）和大型语言模型（LLM）根据给定的SQL查询生成多个自然语言描述草稿。随后，人类专家对这些草稿进行选择、排序或编辑，以确保其准确性和与领域的一致性。

Result: BenchPress在带有注释的企业SQL日志上进行了评估，结果表明，LLM辅助的注释显著减少了创建高质量基准所需的时间和精力。结合人工验证和LLM生成的建议可以提高注释准确性、基准可靠性和模型评估的鲁棒性。

Conclusion: BenchPress通过简化自定义基准的创建，为研究人员和实践者提供了一种在给定领域特定工作负载上评估text-to-SQL模型的机制。

Abstract: Large language models (LLMs) have been successfully applied to many tasks,
including text-to-SQL generation. However, much of this work has focused on
publicly available datasets, such as Fiben, Spider, and Bird. Our earlier work
showed that LLMs are much less effective in querying large private enterprise
data warehouses and released Beaver, the first private enterprise text-to-SQL
benchmark. To create Beaver, we leveraged SQL logs, which are often readily
available. However, manually annotating these logs to identify which natural
language questions they answer is a daunting task. Asking database
administrators, who are highly trained experts, to take on additional work to
construct and validate corresponding natural language utterances is not only
challenging but also quite costly. To address this challenge, we introduce
BenchPress, a human-in-the-loop system designed to accelerate the creation of
domain-specific text-to-SQL benchmarks. Given a SQL query, BenchPress uses
retrieval-augmented generation (RAG) and LLMs to propose multiple natural
language descriptions. Human experts then select, rank, or edit these drafts to
ensure accuracy and domain alignment. We evaluated BenchPress on annotated
enterprise SQL logs, demonstrating that LLM-assisted annotation drastically
reduces the time and effort required to create high-quality benchmarks. Our
results show that combining human verification with LLM-generated suggestions
enhances annotation accuracy, benchmark reliability, and model evaluation
robustness. By streamlining the creation of custom benchmarks, BenchPress
offers researchers and practitioners a mechanism for assessing text-to-SQL
models on a given domain-specific workload. BenchPress is freely available via
our public GitHub repository at
https://github.com/fabian-wenz/enterprise-txt2sql and is also accessible on our
website at http://dsg-mcgraw.csail.mit.edu:5000.

</details>


### [21] [Harnessing Consistency for Robust Test-Time LLM Ensemble](https://arxiv.org/abs/2510.13855)
*Zhichen Zeng,Qi Yu,Xiao Lin,Ruizhong Qiu,Xuying Ning,Tianxin Wei,Yuchen Yan,Jingrui He,Hanghang Tong*

Main category: cs.CL

TL;DR: 本文提出了CoRE，这是一种即插即用技术，它利用模型一致性来实现强大的LLM集成，从而提高集成性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的集成提供了一种结合它们互补能力的方法。然而，在现有研究中，LLM集成的鲁棒性问题（即如何处理潜在的错误信号，如异构标记化方案和不同的模型专业知识）尚未得到充分关注。

Method: 本文提出CoRE，它通过在两种粒度上利用模型一致性来解决LLM集成的鲁棒性问题。具体来说，CoRE在标记级别和模型级别上捕捉一致性。在标记级别上，CoRE通过应用低通滤波器来降低不确定标记的权重，以处理标记预测中的严重分歧。在模型级别上，CoRE通过提升具有高置信度并与其它模型输出差异最小的模型输出来增强全局一致性。

Result: CoRE持续改进了集成性能和鲁棒性。

Conclusion: CoRE通过利用模型一致性，在不同粒度（即标记级别和模型级别）上增强了LLM集成的鲁棒性，从而提高了集成性能。

Abstract: Different large language models (LLMs) exhibit diverse strengths and
weaknesses, and LLM ensemble serves as a promising approach to integrate their
complementary capabilities. Despite substantial progress in improving ensemble
quality, limited attention has been paid to the robustness of ensembles against
potential erroneous signals, which often arise from heterogeneous tokenization
schemes and varying model expertise. Our analysis shows that ensemble failures
typically arise from both the token level and the model level: the former
reflects severe disagreement in token predictions, while the latter involves
low confidence and pronounced disparities among models. In light of this, we
propose CoRE, a plug-and-play technique that harnesses model consistency for
robust LLM ensemble, which can be seamlessly integrated with diverse ensemble
methods. Token-level consistency captures fine-grained disagreements by
applying a low-pass filter to downweight uncertain tokens with high
inconsistency, often due to token misalignment, thereby improving robustness at
a granular level. Model-level consistency models global agreement by promoting
model outputs with high self-confidence and minimal divergence from others,
enhancing robustness at a coarser level. Extensive experiments across diverse
benchmarks, model combinations, and ensemble strategies demonstrate that CoRE
consistently improves ensemble performance and robustness.

</details>


### [22] [Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA](https://arxiv.org/abs/2510.13856)
*A H M Rezaul Karim,Ozlem Uzuner*

Main category: cs.CL

TL;DR: 这篇论文介绍了MasonNLP系统，该系统在MEDIQA-WV 2025医学图像问答挑战中取得了优异的成绩，并提出了一种轻量级的检索增强生成（RAG）框架，用于多模式临床自然语言处理任务。


<details>
  <summary>Details</summary>
Motivation: 医学视觉问答（MedVQA）在临床决策和患者护理中具有重要作用。然而，传统的MedVQA系统可能难以生成自由文本响应和结构化伤口属性。

Method: MasonNLP系统采用了一个通用领域、经过指令调整的大型语言模型，并结合了检索增强生成（RAG）框架。该框架整合了领域内的文本和视觉示例，通过简单的索引和融合添加相关示例，从而在推理、模式依从性和响应质量方面取得了改进。

Result: MasonNLP系统在MEDIQA-WV 2025挑战中排名第三（共19支队伍，51份提交），平均得分41.37%。该系统在dBLEU、ROUGE、BERTScore和基于LLM的指标上都表现出色。

Conclusion: 轻量级的RAG与通用大型语言模型相结合，为多模态临床自然语言处理任务提供了一个简单有效的基线方法，无需额外的训练或复杂的重排序。

Abstract: Medical Visual Question Answering (MedVQA) enables natural language queries
over medical images to support clinical decision-making and patient care. The
MEDIQA-WV 2025 shared task addressed wound-care VQA, requiring systems to
generate free-text responses and structured wound attributes from images and
patient queries. We present the MasonNLP system, which employs a
general-domain, instruction-tuned large language model with a
retrieval-augmented generation (RAG) framework that incorporates textual and
visual examples from in-domain data. This approach grounds outputs in
clinically relevant exemplars, improving reasoning, schema adherence, and
response quality across dBLEU, ROUGE, BERTScore, and LLM-based metrics. Our
best-performing system ranked 3rd among 19 teams and 51 submissions with an
average score of 41.37%, demonstrating that lightweight RAG with
general-purpose LLMs -- a minimal inference-time layer that adds a few relevant
exemplars via simple indexing and fusion, with no extra training or complex
re-ranking -- provides a simple and effective baseline for multimodal clinical
NLP tasks.

</details>


### [23] [ShishuLM: Lightweight Language Model with Hybrid Decoder-MLP Architecture and Paired Weight Sharing](https://arxiv.org/abs/2510.13860)
*Shivanshu Kumar,Gopalakrishnan Srinivasan*

Main category: cs.CL

TL;DR: ShishuLM是一种新型高效语言模型架构，通过减少参数数量和KV缓存需求，将Transformer模型的内存占用降低了25%，推理延迟提高了40%。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在自然语言处理任务中表现出色，但存在大量的内存和计算开销，其中存在冗余。

Method: 我们从AI可解释性和推理时间层剪枝的研究中获得启发，提出了ShishuLM模型。该模型在一个Transformer块内，通过多层感知器（MLP）近似归一化和注意力计算。

Result: ShishuLM在内存方面减少了25%的需求，在训练和推理过程中延迟提高了40%。

Conclusion: ShishuLM为构建更高效的小型语言模型（SLM）架构提供了新的思路。

Abstract: While the transformer architecture has achieved state-of-the-art performance
on natural language processing tasks, these models impose substantial memory
and computational overhead. Recent research has identified significant
architectural redundancies within these models, presenting opportunities for
optimization without compromising performance. Taking insights from research in
AI interpretability and inference-time layer pruning, we introduce an efficient
language model architecture, referred to as ShishuLM, which reduces both the
parameter count and Key-Value (KV) cache requirements. Given the increasing
importance of Small Language Models (SLMs) in agentic AI systems, we evaluate
our approach on two SLMs of different scales. Our analysis reveals that for
moderate-context scenarios, normalization coupled with attention computation is
roughly linear with the input, enabling entire transformer blocks to be
approximated through Multi-Layer Perceptrons (MLPs). Our results show that
ShishuLM provides up to 25% reduction in memory requirements and up to 40%
improvement in latency during both training and inference, compared to parent
models. Our experimental and analytical findings provide insights towards
building more efficient SLM architectures from a pre-training standpoint.

</details>


### [24] [Ensembling Large Language Models to Characterize Affective Dynamics in Student-AI Tutor Dialogues](https://arxiv.org/abs/2510.13862)
*Chenyu Zhang,Sharifa Alghowinem,Cynthia Breazeal*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLM）在教育环境中对学习者的情感影响，引入了首个集成LLM情感感知框架，分析了学生在与AI导师互动过程中的情感动态和转化。


<details>
  <summary>Details</summary>
Motivation: 尽管现有研究已探讨大型语言模型在教育中的学习影响，但对LLM辅助辅导中的情感动态理解不足。因此，本研究旨在通过开发集成LLM框架来大规模感知辅导对话中的情感，从而推进生成式AI在教育中负责任整合的讨论，关注学习者不断演变的情感状态。

Method: 本研究分析了261名本科生与PyTutor（一个由LLM驱动的AI导师）在两个学期内交换的16,986个对话回合。为探究学习者的情感体验，研究者使用三个前沿LLM（Gemini、GPT-4o、Claude）进行了零样本情感标注，包括效价、唤醒度和学习帮助性的标量评分，以及自由文本情感标签。这些估计通过秩加权模型内池化和跨模型多数共识进行融合，以生成稳健的情感画像。

Result: 分析结果表明，学生在与AI导师互动时通常报告轻度积极情感和中等唤醒度。然而，学习过程并非一帆风顺：困惑和好奇心在解决问题时频繁出现，而沮丧虽然不常见，但仍会阻碍进展。情感状态是短暂的，积极时刻比中性或消极时刻持续稍久，但易受干扰。令人鼓舞的是，消极情绪通常能迅速消散，有时甚至直接反弹为积极状态。中性时刻常作为转折点，更多地引导学生情绪向上而非向下，这为导师在这些关键时刻进行干预提供了机会。

Conclusion: LLM在教育辅导中能够有效感知和响应学生的情感状态。理解这些情感动态，特别是中性时刻作为干转折点的潜力，为设计更具情感智能的AI导师和优化教育干预策略提供了重要见解。未来的AI导师应关注学生情感的快速变化，并在中性情绪点及时介入，以提升学习体验和情绪体验。

Abstract: While recent studies have examined the leaning impact of large language model
(LLM) in educational contexts, the affective dynamics of LLM-mediated tutoring
remain insufficiently understood. This work introduces the first ensemble-LLM
framework for large-scale affect sensing in tutoring dialogues, advancing the
conversation on responsible pathways for integrating generative AI into
education by attending to learners' evolving affective states. To achieve this,
we analyzed two semesters' worth of 16,986 conversational turns exchanged
between PyTutor, an LLM-powered AI tutor, and 261 undergraduate learners across
three U.S. institutions. To investigate learners' emotional experiences, we
generate zero-shot affect annotations from three frontier LLMs (Gemini, GPT-4o,
Claude), including scalar ratings of valence, arousal, and
learning-helpfulness, along with free-text emotion labels. These estimates are
fused through rank-weighted intra-model pooling and plurality consensus across
models to produce robust emotion profiles. Our analysis shows that during
interaction with the AI tutor, students typically report mildly positive affect
and moderate arousal. Yet learning is not uniformly smooth: confusion and
curiosity are frequent companions to problem solving, and frustration, while
less common, still surfaces in ways that can derail progress. Emotional states
are short-lived--positive moments last slightly longer than neutral or negative
ones, but they are fragile and easily disrupted. Encouragingly, negative
emotions often resolve quickly, sometimes rebounding directly into positive
states. Neutral moments frequently act as turning points, more often steering
students upward than downward, suggesting opportunities for tutors to intervene
at precisely these junctures.

</details>


### [25] [Unlocking the Potential of Diffusion Language Models through Template Infilling](https://arxiv.org/abs/2510.13870)
*Junhoo Lee,Seungyeon Kim,Nojun Kwak*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为“Template Infilling (TI)”的条件生成方法，用于改进扩散语言模型（DLMs）的推理策略。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语言模型（DLMs）的推理策略受限于从自回归范式继承的基于前缀的提示。

Method: Template Infilling (TI)方法首先为目标响应生成一个结构模板，然后填充被掩盖的片段。为了增强结构控制的灵活性，本文引入了动态片段分配（DSA），该方法根据生成置信度自适应地调整片段长度。

Result: 在数学推理和代码生成基准测试中，该方法比基线模型取得了17.01%的持续改进。此外，TI在多token生成设置中提供了额外优势，实现了有效的加速，同时保持了生成质量。

Conclusion: Template Infilling (TI)及其动态片段分配（DSA）显著提高了扩散语言模型在数学推理和代码生成任务上的性能，并实现了生成效率的提升。

Abstract: Diffusion Language Models (DLMs) have emerged as a promising alternative to
Autoregressive Language Models, yet their inference strategies remain limited
to prefix-based prompting inherited from the autoregressive paradigm. In this
paper, we propose Template Infilling (TI), a tailored conditioning methodology
for DLMs' generation process. Unlike conventional prefix prompting, TI first
generates a structural template for the target response, then fills in the
masked segments. To enhance the flexibility of this structural control, we
introduce Dynamic Segment Allocation (DSA), which adaptively adjusts segment
lengths based on generation confidence. We demonstrate the effectiveness of our
approach on mathematical reasoning and code generation benchmarks, achieving
consistent improvements of 17.01$\%$p over baseline. Furthermore, we show that
TI provides additional advantages in multi-token generation settings, enabling
effective speedup while maintaining generation quality.

</details>


### [26] [Quechua Speech Datasets in Common Voice: The Case of Puno Quechua](https://arxiv.org/abs/2510.13871)
*Elwin Huaman,Wendi Huaman,Jorge Luis Huaman,Ninfa Quispe*

Main category: cs.CL

TL;DR: 这篇论文讨论了如何将克丘亚语（一种资源匮乏的语言）整合到Common Voice平台中，以促进开放和社区驱动的语音数据集创建，并以普诺克丘亚语为例，展示了Common Voice的潜力，并提出了未来的研究议程。


<details>
  <summary>Details</summary>
Motivation: 解决克丘亚语等资源匮乏语言在语音技术发展中面临的数据和资源稀缺问题。

Method: 将克丘亚语整合到Common Voice平台中，并以普诺克丘亚语为例，进行了语言引导和阅读及口语语料库的收集。

Result: Common Voice平台现在拥有191.1小时的克丘亚语语音数据（86%已验证），其中普诺克丘亚语贡献了12小时（77%已验证）。

Conclusion: Common Voice在促进资源匮乏语言的语音技术发展方面具有巨大潜力，并提出了解决技术挑战和伦理考虑的研究议程，以实现包容性语音技术和数字赋能。

Abstract: Under-resourced languages, such as Quechuas, face data and resource scarcity,
hindering their development in speech technology. To address this issue, Common
Voice presents a crucial opportunity to foster an open and community-driven
speech dataset creation. This paper examines the integration of Quechua
languages into Common Voice. We detail the current 17 Quechua languages,
presenting Puno Quechua (ISO 639-3: qxp) as a focused case study that includes
language onboarding and corpus collection of both reading and spontaneous
speech data. Our results demonstrate that Common Voice now hosts 191.1 hours of
Quechua speech (86\% validated), with Puno Quechua contributing 12 hours (77\%
validated), highlighting the Common Voice's potential. We further propose a
research agenda addressing technical challenges, alongside ethical
considerations for community engagement and indigenous data sovereignty. Our
work contributes towards inclusive voice technology and digital empowerment of
under-resourced language communities.

</details>


### [27] [FRACCO: A gold-standard annotated corpus of oncological entities with ICD-O-3.1 normalisation](https://arxiv.org/abs/2510.13873)
*Johann Pignat,Milena Vucetic,Christophe Gaudet-Blavignac,Jamil Zaghir,Amandine Stettler,Fanny Amrein,Jonatan Bonjour,Jean-Philippe Goldman,Olivier Michielin,Christian Lovis,Mina Bjelogrlic*

Main category: cs.CL

TL;DR: 本文介绍了FRACCO，一个包含1301个由专家注释的合成法语临床病例的语料库，用于法国肿瘤学领域的自然语言处理工具开发。


<details>
  <summary>Details</summary>
Motivation: 开发针对临床文本的自然语言处理工具需要标注数据集，但法国肿瘤学领域的资源稀缺。

Method: FRACCO语料库包含1301个合成法语临床病例，这些病例最初从西班牙CANTEMIST语料库翻译而来。语料库使用国际肿瘤疾病分类（ICD-O）作为参考，对形态学、部位和组织学分化相关的术语进行标注。此外，还对复合表达进行了归一化标注，将多个ICD-O元素组合成统一的临床概念。通过专家审查确保标注质量，两名领域专家手动标注了实体范围，五名标注人员通过自动化匹配和手动验证相结合的方式，完成了71127个ICD-O归一化。

Result: 最终数据集包含399个独特的形态学代码（2549种不同表达），272个部位代码（3143种不同表达），以及2043个独特的复合表达（11144种不同表达）。

Conclusion: 该数据集为法语肿瘤文本中的命名实体识别和概念归一化提供了参考标准。

Abstract: Developing natural language processing tools for clinical text requires
annotated datasets, yet French oncology resources remain scarce. We present
FRACCO (FRench Annotated Corpus for Clinical Oncology) an expert-annotated
corpus of 1301 synthetic French clinical cases, initially translated from the
Spanish CANTEMIST corpus as part of the FRASIMED initiative. Each document is
annotated with terms related to morphology, topography, and histologic
differentiation, using the International Classification of Diseases for
Oncology (ICD-O) as reference. An additional annotation layer captures
composite expression-level normalisations that combine multiple ICD-O elements
into unified clinical concepts. Annotation quality was ensured through expert
review: 1301 texts were manually annotated for entity spans by two domain
experts. A total of 71127 ICD-O normalisations were produced through a
combination of automated matching and manual validation by a team of five
annotators. The final dataset representing 399 unique morphology codes (from
2549 different expressions), 272 topography codes (from 3143 different
expressions), and 2043 unique composite expressions (from 11144 different
expressions). This dataset provides a reference standard for named entity
recognition and concept normalisation in French oncology texts.

</details>


### [28] [What Layers When: Learning to Skip Compute in LLMs with Residual Gates](https://arxiv.org/abs/2510.13876)
*Filipe Laitenberger,Dawid Kopiczko,Cees G. M. Snoek,Yuki M. Asano*

Main category: cs.CL

TL;DR: GateSkip是一种简单的残差门控机制，可以在解码器LMs中实现token级别的层跳过，通过门控机制筛选低重要性token，从而节省计算量并保持准确性，同时还能洞察Transformer的信息流。


<details>
  <summary>Details</summary>
Motivation: 在大模型推理过程中，计算量是一个重要的挑战，因此需要一种机制来提高LMs的推理效率，同时保持模型性能。

Method: GateSkip为每个Attention/MLP分支配备一个sigmoid-linear门，该门在输出重新进入残差流之前对其进行压缩。在推理过程中，系统根据门值对token进行排序，并使用每层预算跳过低重要性的token。

Result: 在长篇推理任务中，GateSkip可以节省高达15%的计算量，同时保持90%以上的基线准确率。在指令调优模型上，在不节省计算量的情况下，GateSkip可以提高准确性，并且在节省50%计算量的情况下，可以达到基线模型的性能。

Conclusion: GateSkip作为一种稳定且可微分的门控机制，可以在不进行大量重新训练的情况下，有效地提高大型语言模型的推理效率。该方法不仅在计算资源节约上表现出色，还能揭示Transformer内部的信息流动机制，并且易于与其他优化技术结合。

Abstract: We introduce GateSkip, a simple residual-stream gating mechanism that enables
token-wise layer skipping in decoder-only LMs. Each Attention/MLP branch is
equipped with a sigmoid-linear gate that condenses the branch's output before
it re-enters the residual stream. During inference we rank tokens by the gate
values and skip low-importance ones using a per-layer budget. While early-exit
or router-based Mixture-of-Depths models are known to be unstable and need
extensive retraining, our smooth, differentiable gates fine-tune stably on top
of pretrained models. On long-form reasoning, we save up to 15\% compute while
retaining over 90\% of baseline accuracy. On instruction-tuned models we see
accuracy gains at full compute and match baseline quality near 50\% savings.
The learned gates give insight into transformer information flow (e.g., BOS
tokens act as anchors), and the method combines easily with quantization,
pruning, and self-speculative decoding.

</details>


### [29] [TextBandit: Evaluating Probabilistic Reasoning in LLMs Through Language-Only Decision Tasks](https://arxiv.org/abs/2510.13878)
*Jimin Lim,Arjun Damerla,Arthur Jiang,Nam Le*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在不确定环境下进行序列决策的能力，引入了一个新的基准测试，其中LLMs仅通过文本反馈与多臂老虎机环境互动。研究发现，Qwen3-4B模型在没有任何数字线索的情况下，表现优于其他LLMs和传统决策算法，达到了89.2%的最佳臂选择率，表明概率推理可以仅从语言中产生。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在仅使用自然语言的情况下，在不确定性下进行序列决策的能力，特别是评估它们在没有数值提示或明确概率的情况下，仅从语言线索中推断潜在奖励结构并进行适应的能力。

Method: 引入了一个新颖的基准测试，LLMs在此基准中仅使用文本反馈（如“你获得了一个token”）与多臂老虎机环境进行交互，不提供数值线索。评估了四种开源LLMs的性能，并与Thompson Sampling、Epsilon Greedy、Upper Confidence Bound (UCB)等标准决策算法以及随机选择进行了比较。

Result: 大多数LLMs的表现不如基线模型，但Qwen3-4B模型表现出色，其最佳臂选择率达到89.2%，显著优于更大的LLMs和传统方法。

Conclusion: 研究结果表明，概率推理能力可以仅仅从语言中产生。本文提出的基准测试是评估大型语言模型在自然、非数值情境下决策能力的重要一步。

Abstract: Large language models (LLMs) have shown to be increasingly capable of
performing reasoning tasks, but their ability to make sequential decisions
under uncertainty only using natural language remains underexplored. We
introduce a novel benchmark in which LLMs interact with multi-armed bandit
environments using purely textual feedback, "you earned a token", without
access to numerical cues or explicit probabilities, resulting in the model to
infer latent reward structures purely off linguistic cues and to adapt
accordingly. We evaluated the performance of four open-source LLMs and compare
their performance to standard decision-making algorithms such as Thompson
Sampling, Epsilon Greedy, Upper Confidence Bound (UCB), and random choice.
While most of the LLMs underperformed compared to the baselines, Qwen3-4B,
achieved the best-arm selection rate of 89.2% , which significantly
outperformed both the larger LLMs and traditional methods. Our findings suggest
that probabilistic reasoning is able to emerge from language alone, and we
present this benchmark as a step towards evaluating decision-making
capabilities in naturalistic, non-numeric contexts.

</details>


### [30] [Catch Your Breath: Adaptive Computation for Self-Paced Sequence Production](https://arxiv.org/abs/2510.13879)
*Alexandre Galashov,Matt Jones,Rosemary Ke,Yuan Cao,Vaishnavh Nagarajan,Michael C. Mozer*

Main category: cs.CL

TL;DR: 该文章探索了一种新的训练目标，允许语言模型动态调整每个输入token的计算步数，从而在准确性和计算成本之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 探索一种允许语言模型动态、自主地调整每个输入token计算步数的方法，以提高效率和准确性。

Method: 文章提出了一类名为“Catch Your Breath”（CYB）的损失函数，并通过将每个输出token的选择视为一个具有时间成本的序列决策问题来训练模型。其中包括三种具体方法：CYB-AP（随时预测）、CYB-VA（变分方法）和CYB-DP（基于计算预算的惩罚）。

Result: CYB模型在达到相同性能的情况下，所需的训练数据量是基线模型（无停顿）的三分之一，是带有停顿和交叉熵损失模型的一半。模型会根据token的复杂度和上下文适应地请求额外的计算步数，从而提高准确性。

Conclusion: 该研究提出的CYB模型能够有效地平衡语言模型的计算成本和预测准确性，显著减少了训练数据需求，并能根据输入内容的复杂性自适应地调整计算资源。

Abstract: We explore a class of supervised training objectives that allow a language
model to dynamically and autonomously scale the number of compute steps used
for each input token. For any token, the model can request additional compute
steps by emitting a <don't know> output. If the model is granted a delay, a
specialized <pause> token is inserted at the next input step, providing the
model with additional compute resources to generate an output. The model can
request multiple pauses. To train the model to use <don't know> outputs
judiciously and to calibrate its uncertainty, we frame the selection of each
output token as a sequential-decision problem with a time cost. We refer to the
class of methods as $\textit{Catch Your Breath}$ losses and we study three
methods in this class: CYB-AP frames the model's task as anytime prediction,
where an output may be required at any step and accuracy is discounted over
time; CYB-VA is a variational approach that aims to maximize prediction
accuracy subject to a specified distribution over stopping times; and CYB-DP
imposes a penalty based on a computational budget. Through fine-tuning
experiments, we identify the best performing loss variant. The CYB model needs
only one third as much training data as the baseline (no pause) model needs to
achieve the same performance, and half as much data as a model with pauses and
a cross-entropy loss. We find that the CYB model requests additional steps when
doing so improves accuracy, and the model adapts its processing time to
token-level complexity and context. For example, it often pauses after plural
nouns like $\textit{patients}$ and $\textit{challenges}$ but never pauses after
the first token of contracted words like $\textit{wasn}$ and $\textit{didn}$,
and it shows high variability for ambiguous tokens like $\textit{won}$, which
could function as either a verb or part of a contraction.

</details>


### [31] [PAGE: Prompt Augmentation for text Generation Enhancement](https://arxiv.org/abs/2510.13880)
*Mauro Jose Pacchiotti,Luciana Ballejos,Mariel Ale*

Main category: cs.CL

TL;DR: PAGE是一个通过使用辅助模块来增强文本生成模型表现的框架。


<details>
  <summary>Details</summary>
Motivation: 生成模型在特定任务上表现不佳，或需要大量额外数据进行调整。

Method: PAGE使用轻量级辅助模块（如分类器、提取器）从输入文本中获取推断信息，然后将这些信息用于构建一个能够提升生成质量和可控性的丰富输入。

Result: 一个概念验证在需求工程领域被提出，其中一个带有分类器的辅助模块被用来提高软件需求生成的质量。

Conclusion: PAGE提供了一种简单、模块化的架构，易于适应不同任务，且无需辅助生成模型。

Abstract: In recent years, natural language generative models have shown outstanding
performance in text generation tasks. However, when facing specific tasks or
particular requirements, they may exhibit poor performance or require
adjustments that demand large amounts of additional data. This work introduces
PAGE (Prompt Augmentation for text Generation Enhancement), a framework
designed to assist these models through the use of simple auxiliary modules.
These modules, lightweight models such as classifiers or extractors, provide
inferences from the input text. The output of these auxiliaries is then used to
construct an enriched input that improves the quality and controllability of
the generation. Unlike other generation-assistance approaches, PAGE does not
require auxiliary generative models; instead, it proposes a simpler, modular
architecture that is easy to adapt to different tasks. This paper presents the
proposal, its components and architecture, and reports a proof of concept in
the domain of requirements engineering, where an auxiliary module with a
classifier is used to improve the quality of software requirements generation.

</details>


### [32] [Too Open for Opinion? Embracing Open-Endedness in Large Language Models for Social Simulation](https://arxiv.org/abs/2510.13884)
*Bolei Ma,Yong Cao,Indira Sen,Anna-Carolina Haensch,Frauke Kreuter,Barbara Plank,Daniel Hershcovich*

Main category: cs.CL

TL;DR: 本文提出开放式的大语言模型（LLM）社会模拟方法，以克服现有封闭式模拟的局限性，从而更真实地捕捉LLM的生成性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（LLM）在模拟公众舆论和社会现象时，大多采用选择题或简答题的封闭式设计，这限制了LLM固有的生成能力，无法真实反映其表达多样性和个体性。

Method: 借鉴了数十年的调查方法研究和自然语言处理的最新进展，提出并论证开放式文本在LLM社会模拟中的价值，包括改进测量和设计、支持探索意想不到的观点、减少研究者强加的指导性偏差，以及捕捉表达性和个体性。

Result: 开放式模拟能够提高测量的准确性和设计的灵活性，帮助发现预料之外的观点，降低研究者的主观偏见，并能更好地捕捉LLMs的表达能力和个体特征。

Conclusion: 呼吁开发新的实践方法和评估框架，以充分利用大语言模型（LLM）开放式生成的特性，而非对其进行限制，从而促进自然语言处理和经济学社会的协同发展。

Abstract: Large Language Models (LLMs) are increasingly used to simulate public opinion
and other social phenomena. Most current studies constrain these simulations to
multiple-choice or short-answer formats for ease of scoring and comparison, but
such closed designs overlook the inherently generative nature of LLMs. In this
position paper, we argue that open-endedness, using free-form text that
captures topics, viewpoints, and reasoning processes "in" LLMs, is essential
for realistic social simulation. Drawing on decades of survey-methodology
research and recent advances in NLP, we argue why this open-endedness is
valuable in LLM social simulations, showing how it can improve measurement and
design, support exploration of unanticipated views, and reduce
researcher-imposed directive bias. It also captures expressiveness and
individuality, aids in pretesting, and ultimately enhances methodological
utility. We call for novel practices and evaluation frameworks that leverage
rather than constrain the open-ended generative diversity of LLMs, creating
synergies between NLP and social science.

</details>


### [33] [Order from Chaos: Comparative Study of Ten Leading LLMs on Unstructured Data Categorization](https://arxiv.org/abs/2510.13885)
*Ariel Kamen*

Main category: cs.CL

TL;DR: 本文对比评估了10个最先进的大型语言模型在非结构化文本分类上的表现，并提出了一个基于集成的方法显著提升了分类性能并消除了幻觉。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在非结构化文本分类任务中的表现，并找出提高其性能的方法。

Method: 1. 选择了IAB 2.2分层分类法对非结构化文本进行分类。 2. 使用包含8,660个人工标注样本的统一数据集和相同的零样本提示来评估模型。 3. 采用了准确率、精确率、召回率和F1分数四种经典指标，以及幻觉率、膨胀率和分类成本三种LLM特有指标。 4. 开发并测试了一个基于集成的LLM方法。

Result: 1. 当代大型语言模型在非结构化文本分类任务中表现一般，平均准确率、精确率、召回率和F1分数分别为34%、42%、45%和41%。 2. 模型经常过度生成类别，与人类标注者相比，存在较高的幻觉率和膨胀率。 3. 在所有评估系统中，Gemini 1.5/2.0 Flash和GPT 20B/120B提供了最佳的成本效益，而GPT 120B的幻觉率最低。 4. 集成方法显著提高了准确率，降低了膨胀率，并完全消除了幻觉，表明模型之间的协同协调可能是提高文本分类性能的有效途径。

Conclusion: 单纯的模型规模和架构改进不足以确保更好的分类准确性。通过多模型协同编排的集成方法，能够显著提升大型语言模型在非结构化文本分类任务中的表现，甚至有望超越人类专家的水平。

Abstract: This study presents a comparative evaluation of ten state-of-the-art large
language models (LLMs) applied to unstructured text categorization using the
Interactive Advertising Bureau (IAB) 2.2 hierarchical taxonomy. The analysis
employed a uniform dataset of 8,660 human-annotated samples and identical
zero-shot prompts to ensure methodological consistency across all models.
Evaluation metrics included four classic measures - accuracy, precision,
recall, and F1-score - and three LLM-specific indicators: hallucination ratio,
inflation ratio, and categorization cost.
  Results show that, despite their rapid advancement, contemporary LLMs achieve
only moderate classic performance, with average scores of 34% accuracy, 42%
precision, 45% recall, and 41% F1-score. Hallucination and inflation ratios
reveal that models frequently overproduce categories relative to human
annotators. Among the evaluated systems, Gemini 1.5/2.0 Flash and GPT 20B/120B
offered the most favorable cost-to-performance balance, while GPT 120B
demonstrated the lowest hallucination ratio. The findings suggest that scaling
and architectural improvements alone do not ensure better categorization
accuracy, as the task requires compressing rich unstructured text into a
limited taxonomy - a process that challenges current model architectures.
  To address these limitations, a separate ensemble-based approach was
developed and tested. The ensemble method, in which multiple LLMs act as
independent experts, substantially improved accuracy, reduced inflation, and
completely eliminated hallucinations. These results indicate that coordinated
orchestration of models - rather than sheer scale - may represent the most
effective path toward achieving or surpassing human-expert performance in
large-scale text categorization.

</details>


### [34] [Reliable Fine-Grained Evaluation of Natural Language Math Proofs](https://arxiv.org/abs/2510.13888)
*Wenjie Ma,Andrei Cojocaru,Neel Kolhe,Bradley Louie,Robin Said Sharif,Haihan Zhang,Vincent Zhuang,Matei Zaharia,Sewon Min*

Main category: cs.CL

TL;DR: 该论文介绍了一种大规模语言模型（LLM）数学证明的分数评估方法，并提出了ProofGrader，其在评估LLM生成的数学证明方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 目前，LLM在数学推理方面的研究主要集中在易于验证最终答案的任务上，而生成和验证自然语言数学证明仍然是一个开放的挑战。同时，缺乏可靠、细粒度的LLM生成的数学证明评估器是一个关键的空白。

Method: 本文提出了一种系统化的方法来开发和验证评估器，该评估器以0-7的细粒度分数评估模型生成的数学证明。为此，我们引入了ProofBench，一个专家标注的细粒度证明评级数据集，涵盖了来自六个主要数学竞赛的145个问题以及来自Gemini-2.5-pro、o3和DeepSeek-R1的435个LLM生成的解决方案。利用ProofBench，我们系统地探索了评估器设计空间，包括骨干模型、输入上下文、指令和评估工作流程。最终，我们得到了ProofGrader，它结合了强大的推理骨干LM、来自参考解决方案和评分方案的丰富上下文以及简单的集成方法。

Result: ProofGrader在专家分数上的平均绝对误差（MAE）为0.926，显著优于简单的基线方法。在“n选一”任务中，当n=16时，ProofGrader的平均得分为4.14（满分7分），弥补了天真的二元评估器（2.48分）与人类专家（4.62分）之间78%的差距。

Conclusion: ProofGrader的实用性及其在高分证明生成方面的巨大潜力，有望推动LLM在数学证明领域的发展。

Abstract: Recent advances in large language models (LLMs) for mathematical reasoning
have largely focused on tasks with easily verifiable final answers; however,
generating and verifying natural language math proofs remains an open
challenge. We identify the absence of a reliable, fine-grained evaluator for
LLM-generated math proofs as a critical gap. To address this, we propose a
systematic methodology for developing and validating evaluators that assign
fine-grained scores on a 0-7 scale to model-generated math proofs. To enable
this study, we introduce ProofBench, the first expert-annotated dataset of
fine-grained proof ratings, spanning 145 problems from six major math
competitions (USAMO, IMO, Putnam, etc) and 435 LLM-generated solutions from
Gemini-2.5-pro, o3, and DeepSeek-R1. %with expert gradings. Using ProofBench as
a testbed, we systematically explore the evaluator design space across key
axes: the backbone model, input context, instructions and evaluation workflow.
Our analysis delivers ProofGrader, an evaluator that combines a strong
reasoning backbone LM, rich context from reference solutions and marking
schemes, and a simple ensembling method; it achieves a low Mean Absolute Error
(MAE) of 0.926 against expert scores, significantly outperforming naive
baselines. Finally, we demonstrate its practical utility in a best-of-$n$
selection task: at $n=16$, ProofGrader achieves an average score of 4.14 (out
of 7), closing 78% of the gap between a naive binary evaluator (2.48) and the
human oracle (4.62), highlighting its potential to advance downstream proof
generation.

</details>


### [35] [A Survey on Collaborating Small and Large Language Models for Performance, Cost-effectiveness, Cloud-edge Privacy, and Trustworthiness](https://arxiv.org/abs/2510.13890)
*Fali Wang,Jihai Chen,Shuhua Yang,Ali Al-Lawati,Linli Tang,Hui Liu,Suhang Wang*

Main category: cs.CL

TL;DR: 这篇论文对大型语言模型（LLM）和小型语言模型（SLM）的协作进行了系统性调查。


<details>
  <summary>Details</summary>
Motivation: LLM在许多领域和应用中取得了进展，但面临高微调成本、推理延迟、有限的边缘部署能力和可靠性问题。SLM作为补充，具有紧凑、高效和适应性强的特点。最近的研究探索了融合SLM的专业性和效率与LLM的泛化和推理能力的协作框架，以满足不同任务和部署场景的需求。

Method: 本研究提出了一个以协作目标为导向的SLM-LLM协作分类法，包含四个目标：性能提升、成本效益、云边隐私和可信度。

Result: 论文回顾了代表性的方法，总结了设计范式，并概述了现有挑战和未来方向，以实现高效、安全和可扩展的SLM-LLM协作。

Conclusion: SLM和LLM的协同工作能够有效弥补彼此的不足，是未来语言模型发展的一个重要方向。

Abstract: Large language models (LLMs) have advanced many domains and applications but
face high fine-tuning costs, inference latency, limited edge deployability, and
reliability concerns. Small language models (SLMs), compact, efficient, and
adaptable, offer complementary remedies. Recent work explores collaborative
frameworks that fuse SLMs' specialization and efficiency with LLMs'
generalization and reasoning to meet diverse objectives across tasks and
deployment scenarios. Motivated by these developments, this paper presents a
systematic survey of SLM-LLM collaboration organized by collaboration
objectives. We propose a taxonomy with four goals: performance enhancement,
cost-effectiveness, cloud-edge privacy, and trustworthiness. Within this
framework, we review representative methods, summarize design paradigms, and
outline open challenges and future directions toward efficient, secure, and
scalable SLM-LLM collaboration.

</details>


### [36] [The Harder The Better: Maintaining Supervised Fine-tuning Generalization with Less but Harder Data](https://arxiv.org/abs/2510.13892)
*Zhaoyang Shang,Sibo Wei,Jianbin Guo,Rui Zhou,Lifeng Dong,Yin Luo*

Main category: cs.CL

TL;DR: THTB是一种受认知科学启发的指令数据选择和注释指导框架，它通过结合质量过滤与内外在难度评分来优先处理更高级别的认知指令。


<details>
  <summary>Details</summary>
Motivation: 如何将大型语言模型应用于专业领域，这需要高质量的监督微调（SFT）数据。现有的方法在选择高质量数据上存在过度依赖大型语言模型内部知识、解释性弱和泛化能力有限的问题。

Method: THTB（The Harder The Better）框架，通过结合质量过滤与内在和外在难度评分，优先选择更高级别的认知指令。

Result: 为了解决这些限制，我们提出了THTB，一个受认知科学启发的指令数据选择和注释指导框架。THTB通过结合质量过滤与内在和外在难度评分，优先选择更高级别的认知指令，为高效SFT提供了可解释和可量化的标准。实验表明，仅使用5%的数据进行训练的模型，其性能优于在完整数据集上训练的模型，并且与仅使用大型语言模型进行选择相比，THTB实现了更好的泛化能力。此外，THTB在垂直领域提供了有效的注释指导，使得仅用2%数据训练的模型就能超越在更大规模数据集上训练的模型。

Conclusion: THTB框架通过选择更具认知难度的指令数据，显著提高了大型语言模型在专业领域的SFT效率和泛化能力，即使在数据量极少的情况下也能取得优异表现，展现了强大的领域适应潜力。

Abstract: Large Language Models (LLMs) excel in general tasks, but adapting them to
specialized domains relies on high-quality supervised fine-tuning (SFT) data.
Although existing methods can identify subsets of high-quality data and reduce
training cost to some extent, their selection process still suffers from
over-reliance on LLMs' internal knowledge, weak interpretability, and limited
generalization. To address these limitations, we propose THTB (The Harder The
Better), a cognitive science-inspired framework for instruction data selection
and annotation guidance. THTB prioritizes higher-level cognitive instructions
by combining quality filtering with intrinsic and extrinsic hardness scoring,
offering interpretable and quantifiable criteria for efficient SFT, both in
data selection and annotation guidance. Experiments show that THTB enables
models trained on only 5% of the data to outperform full-dataset training,
while achieving superior generalization compared with LLM-only selection. In
addition, THTB provides effective annotation guidance in vertical domains,
enabling a model trained on just 2% of the data to surpass models trained on
much larger datasets, demonstrating strong potential for domain adaptation. Our
code, datasets, and models are available on
https://github.com/DYJG-research/THTB.

</details>


### [37] [Guarding the Guardrails: A Taxonomy-Driven Approach to Jailbreak Detection](https://arxiv.org/abs/2510.13893)
*Olga E. Sorokoletova,Francesco Giarrusso,Vincenzo Suriani,Daniele Nardi*

Main category: cs.CL

TL;DR: 研究了越狱大型语言模型的策略，开发了一个包含50种策略的综合分层分类，并创建了一个新的意大利语多轮对抗性对话数据集。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的越狱技术对LLMs的安全性构成了重大威胁。现有的防御通常侧重于单轮攻击，缺乏跨语言的覆盖，并且依赖于有限的分类法。这些分类法要么未能捕捉攻击策略的全部多样性，要么强调风险类别而不是越狱技术。

Method: 1. 开发了一个包含50种越狱策略的综合分层分类，将先前的分类整合并扩展为七大家族，包括模仿、说服、特权升级、认知过载、混淆、目标冲突和数据中毒。
2. 分析了从挑战中收集的数据，以检查不同攻击类型的流行度和成功率，深入了解特定的越狱策略如何利用模型漏洞并导致不对齐。
3. 对流行的LLM进行了越狱检测基准测试，评估了分类法引导的提示对改进自动检测的益处。
4. 编译了一个包含1364个多轮对抗性对话的新意大利语数据集，并使用所提出的分类法进行标注。

Result: 1. 建立了包含50种越狱策略的综合分层分类法。
2. 分析了不同攻击类型的流行度和成功率，揭示了越狱策略如何利用模型漏洞。
3. 评估了分类法引导的提示在越狱检测中的有效性。
4. 构建了一个新的意大利语多轮对抗性对话数据集。

Conclusion: 这项研究通过开发全面的越狱策略分类法、分析攻击成功率、评估检测方法以及构建新的多轮对抗性数据集，显著推进了对LLM越狱技术的理解和防御。

Abstract: Jailbreaking techniques pose a significant threat to the safety of Large
Language Models (LLMs). Existing defenses typically focus on single-turn
attacks, lack coverage across languages, and rely on limited taxonomies that
either fail to capture the full diversity of attack strategies or emphasize
risk categories rather than the jailbreaking techniques. To advance the
understanding of the effectiveness of jailbreaking techniques, we conducted a
structured red-teaming challenge. The outcome of our experiments are manifold.
First, we developed a comprehensive hierarchical taxonomy of 50 jailbreak
strategies, consolidating and extending prior classifications into seven broad
families, including impersonation, persuasion, privilege escalation, cognitive
overload, obfuscation, goal conflict, and data poisoning. Second, we analyzed
the data collected from the challenge to examine the prevalence and success
rates of different attack types, providing insights into how specific jailbreak
strategies exploit model vulnerabilities and induce misalignment. Third, we
benchmark a popular LLM for jailbreak detection, evaluating the benefits of
taxonomy-guided prompting for improving automatic detection. Finally, we
compiled a new Italian dataset of 1364 multi-turn adversarial dialogues,
annotated with our taxonomy, enabling the study of interactions where
adversarial intent emerges gradually and succeeds in bypassing traditional
safeguards.

</details>


### [38] [Attribution Quality in AI-Generated Content:Benchmarking Style Embeddings and LLM Judges](https://arxiv.org/abs/2510.13898)
*Misam Abbas*

Main category: cs.CL

TL;DR: 这篇论文评估了两种归因机制（固定风格嵌入和指令调整的LLM判断）在人类-AI并行语料库上的表现，以区分人类和机器生成的内容。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLMs）时代，由于机器生成的散文与人类写作水平相当，区分作者变得越来越具有挑战性。

Method: 作者基准测试了两种互补的归因机制：固定风格嵌入（Style Embeddings）和指令微调的LLM判断器（GPT-4o）。实验在Human AI Parallel Corpus数据集上进行，该数据集包含600个平衡实例，涵盖六个领域，每个实例都包含人类提示及其对应的“黄金”人工续写和LLM（GPT-4o或LLaMA-70B-Instruct）生成的续写。

Result: 在GPT生成的续写上，风格嵌入基线达到了更高的总体准确率（82%对68%）。在LLaMA生成的续写上，LLM判断器略优于风格嵌入（85%对81%），但统计学上不显著。LLM判断器在小说和学术散文中表现显著优异，表明其语义敏感性；而风格嵌入在口语和脚本对话中占主导地位，反映其结构优势。

Conclusion: 这两种互补的模式表明，归因是一个多维度的问题，需要混合策略。该研究为AI生成内容的归因质量评估提供了一个可重复的基准。

Abstract: Attributing authorship in the era of large language models (LLMs) is
increasingly challenging as machine-generated prose rivals human writing. We
benchmark two complementary attribution mechanisms , fixed Style Embeddings and
an instruction-tuned LLM judge (GPT-4o) on the Human AI Parallel Corpus, an
open dataset of 600 balanced instances spanning six domains (academic, news,
fiction, blogs, spoken transcripts, and TV/movie scripts). Each instance
contains a human prompt with both a gold continuation and an LLM-generated
continuation from either GPT-4o or LLaMA-70B-Instruct. The Style Embedding
baseline achieves stronger aggregate accuracy on GPT continuations (82 pct vs.
68 pct). The LLM Judge is slightly better than the Style embeddings on LLaMA
continuations (85 pct vs. 81 pct) but the results are not statistically
significant. Crucially, the LLM judge significantly outperforms in fiction and
academic prose, indicating semantic sensitivity, whereas embeddings dominate in
spoken and scripted dialogue, reflecting structural strengths. These
complementary patterns highlight attribution as a multidimensional problem
requiring hybrid strategies. To support reproducibility we provide code on
GitHub and derived data on Hugging Face under the MIT license. This open
framework provides a reproducible benchmark for attribution quality assessment
in AI-generated content, along with a review of related literature influencing
this work.

</details>


### [39] [RAID: Refusal-Aware and Integrated Decoding for Jailbreaking LLMs](https://arxiv.org/abs/2510.13901)
*Tuan T. Nguyen,John Le,Thai T. Vu,Willy Susilo,Heath Cooper*

Main category: cs.CL

TL;DR: RAID(Refusal-Aware and Integrated Decoding)是一种通过生成对抗性后缀来绕过大型语言模型（LLM）安全机制的越狱攻击框架。RAID在实现攻击成功率、查询效率和计算成本方面均优于现有基线。RAID使用连续嵌入空间优化和拒绝感知正则化来生成既有效又自然的对抗性后缀。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在各种任务中表现出色，但容易受到绕过安全机制的越狱攻击。现有的攻击方法在攻击成功率、查询效率和计算成本方面存在局限性。

Method: RAID（Refusal-Aware and Integrated Decoding）框架通过以下方法生成对抗性后缀：
1. 将离散的token松弛为连续嵌入，并通过联合目标进行优化。
2. 联合目标包含三个部分：
    • 鼓励生成受限响应。
    • 结合拒绝感知正则化，使激活远离嵌入空间中的拒绝方向。
    • 应用连贯性项，以保持语义合理性和非冗余性。
3. 优化后，通过批评指导的解码过程，平衡嵌入亲和性与语言模型似然性，将嵌入映射回token。

Result: 在多个开源LLMs上的实验表明，RAID在攻击成功率、查询次数和计算成本方面均优于现有的白盒和黑盒基线方法，能够更有效地绕过LLMs的防御。

Conclusion: RAID框架通过在嵌入空间中进行正则化，为理解和缓解LLM越狱漏洞提供了重要见解。该方法生成的对抗性后缀既有效又自然，对LLM安全防护提出了新的挑战。

Abstract: Large language models (LLMs) achieve impressive performance across diverse
tasks yet remain vulnerable to jailbreak attacks that bypass safety mechanisms.
We present RAID (Refusal-Aware and Integrated Decoding), a framework that
systematically probes these weaknesses by crafting adversarial suffixes that
induce restricted content while preserving fluency. RAID relaxes discrete
tokens into continuous embeddings and optimizes them with a joint objective
that (i) encourages restricted responses, (ii) incorporates a refusal-aware
regularizer to steer activations away from refusal directions in embedding
space, and (iii) applies a coherence term to maintain semantic plausibility and
non-redundancy. After optimization, a critic-guided decoding procedure maps
embeddings back to tokens by balancing embedding affinity with language-model
likelihood. This integration yields suffixes that are both effective in
bypassing defenses and natural in form. Experiments on multiple open-source
LLMs show that RAID achieves higher attack success rates with fewer queries and
lower computational cost than recent white-box and black-box baselines. These
findings highlight the importance of embedding-space regularization for
understanding and mitigating LLM jailbreak vulnerabilities.

</details>


### [40] [Investigating Political and Demographic Associations in Large Language Models Through Moral Foundations Theory](https://arxiv.org/abs/2510.13902)
*Nicole Smith-Vaniz,Harper Lyon,Lorraine Steigner,Ben Armstrong,Nicholas Mattei*

Main category: cs.CL

TL;DR: 本文分析了大型语言模型（LLMs）在政治和道德领域可能存在的偏见，并评估了它们在不同政治意识形态和人口统计学角色扮演下的回应。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在日常生活中扮演着越来越重要的角色，特别是在提供建议方面，这使得评估其在政治和道德领域的潜在偏见变得至关重要。

Method: 本文应用道德基础理论（MFT）来分析LLMs的回应，并将其与现有的人类研究数据进行直接比较。研究将通过内在回应、政治意识形态的直接表征以及构建人类角色扮演等方式，评估LLMs是否表现出意识形态倾向。

Result: 本文将评估LLMs是否会产生与某种政治意识形态更一致的回应，并检验LLMs在显式提示和基于人口统计学的角色扮演中代表意识形态视角的准确性。

Conclusion: 通过系统分析LLMs在不同条件和实验下的行为，本研究旨在深入了解AI生成的回应中政治和人口统计学依赖性的程度。

Abstract: Large Language Models (LLMs) have become increasingly incorporated into
everyday life for many internet users, taking on significant roles as advice
givers in the domains of medicine, personal relationships, and even legal
matters. The importance of these roles raise questions about how and what
responses LLMs make in difficult political and moral domains, especially
questions about possible biases. To quantify the nature of potential biases in
LLMs, various works have applied Moral Foundations Theory (MFT), a framework
that categorizes human moral reasoning into five dimensions: Harm, Fairness,
Ingroup Loyalty, Authority, and Purity. Previous research has used the MFT to
measure differences in human participants along political, national, and
cultural lines. While there has been some analysis of the responses of LLM with
respect to political stance in role-playing scenarios, no work so far has
directly assessed the moral leanings in the LLM responses, nor have they
connected LLM outputs with robust human data. In this paper we analyze the
distinctions between LLM MFT responses and existing human research directly,
investigating whether commonly available LLM responses demonstrate ideological
leanings: either through their inherent responses, straightforward
representations of political ideologies, or when responding from the
perspectives of constructed human personas. We assess whether LLMs inherently
generate responses that align more closely with one political ideology over
another, and additionally examine how accurately LLMs can represent ideological
perspectives through both explicit prompting and demographic-based
role-playing. By systematically analyzing LLM behavior across these conditions
and experiments, our study provides insight into the extent of political and
demographic dependency in AI-generated responses.

</details>


### [41] [Schema for In-Context Learning](https://arxiv.org/abs/2510.13905)
*Pan Chen,Shaohong Chen,Mark Wang,Shi Xuan Leong,Priscilla Fung,Varinia Bernales,Alan Aspuru-Guzik*

Main category: cs.CL

TL;DR: SA-ICL 是一种受认知科学启发的上下文学习框架，通过提取抽象图式来增强 LLM 的推理能力，在化学和物理问题上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的上下文学习缺乏显式的知识检索和抽象层面的知识迁移模块，而人类通过激活预先存在的心理框架（图式）来解释新信息。

Method: 引入 SA-ICL 框架，该框架从现有示例中提取认知构建块的表示，创建抽象图式（关键推理步骤的轻量级、结构化模板），然后用于增强模型在面对新问题时的推理过程。

Result: SA-ICL 在 GPQA 数据集的化学和物理问题上将 LLM 的性能提升高达 36.19%，尤其是在高质量的单一演示示例下。它减少了对演示数量的依赖，并增强了可解释性。

Conclusion: SA-ICL 不仅弥合了不同 ICL 策略之间的鸿沟，也为增强 LLM 的类人推理能力开辟了新途径。LLMs 缺乏隐式形成和利用内部基于图式的学习表示的能力，但能从显式的基于图式的支架中显著受益。

Abstract: In-Context Learning (ICL) enables transformer-based language models to adapt
to new tasks by conditioning on demonstration examples. However, traditional
example-driven in-context learning lacks explicit modules for knowledge
retrieval and transfer at the abstraction level. Inspired by cognitive science,
specifically schema theory, which holds that humans interpret new information
by activating pre-existing mental frameworks (schemas) to structure
understanding, we introduce SCHEMA ACTIVATED IN CONTEXT LEARNING (SA-ICL). This
framework extracts the representation of the building blocks of cognition for
the reasoning process instilled from prior examples, creating an abstracted
schema, a lightweight, structured template of key inferential steps and their
relationships, which is then used to augment a model's reasoning process when
presented with a novel question. We demonstrate that a broad range of large
language models (LLMs) lack the capacity to form and utilize internal
schema-based learning representations implicitly, but instead benefit
significantly from explicit schema-based scaffolding. Across chemistry and
physics questions from the GPQA dataset, our experiments show that SA-ICL
consistently boosts performance, up to 36.19 percent, when the single
demonstration example is of high quality, which simultaneously reduces reliance
on the number of demonstrations and enhances interpretability. SCHEMA ACTIVATED
IN CONTEXT LEARNING not only bridges disparate ICL strategies ranging from
pattern priming to Chain-of-Thought prompting, but also paves a new path for
enhancing human-like reasoning in LLMs.

</details>


### [42] [Interpreting the Latent Structure of Operator Precedence in Language Models](https://arxiv.org/abs/2510.13908)
*Dharunish Yugeswardeenoo,Harshil Nukala,Cole Blondin,Sean O Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 本文研究了LLMs在算术任务中编码运算符优先级的方式，发现中间计算结果存在于残差流中，并且模型在线性注意层之后编码了运算符优先级。


<details>
  <summary>Details</summary>
Motivation: LLMs在算术任务中表现不佳，以往工作主要关注输出或提示策略，但内部结构如何进行算术计算仍是未解之谜。

Method: 本文构建了一个包含三个操作数和两个运算符的算术表达式数据集，通过改变括号的顺序和位置来追踪中间结果是否出现在指令调优的LLaMA 3.2-3B模型的残差流中。使用了logit lens、线性分类探针和UMAP几何可视化等可解释性技术。

Result: 中间计算存在于残差流中，特别是在MLP块之后。模型在线性注意层之后编码了每个运算符嵌入的优先级。引入了部分嵌入交换技术，通过交换运算符之间的高影响嵌入维度来修改运算符优先级。

Conclusion: LLaMA 3.2-3B模型在内部表示中编码了运算符优先级，中间计算结果存在于残差流中，并且可以通过修改嵌入维度来改变运算符优先级。

Abstract: Large Language Models (LLMs) have demonstrated impressive reasoning
capabilities but continue to struggle with arithmetic tasks. Prior works
largely focus on outputs or prompting strategies, leaving the open question of
the internal structure through which models do arithmetic computation. In this
work, we investigate whether LLMs encode operator precedence in their internal
representations via the open-source instruction-tuned LLaMA 3.2-3B model. We
constructed a dataset of arithmetic expressions with three operands and two
operators, varying the order and placement of parentheses. Using this dataset,
we trace whether intermediate results appear in the residual stream of the
instruction-tuned LLaMA 3.2-3B model. We apply interpretability techniques such
as logit lens, linear classification probes, and UMAP geometric visualization.
Our results show that intermediate computations are present in the residual
stream, particularly after MLP blocks. We also find that the model linearly
encodes precedence in each operator's embeddings post attention layer. We
introduce partial embedding swap, a technique that modifies operator precedence
by exchanging high-impact embedding dimensions between operators.

</details>


### [43] [Knowledge Reasoning Language Model: Unifying Knowledge and Language for Inductive Knowledge Graph Reasoning](https://arxiv.org/abs/2510.13909)
*Xingrui Zhuo,Jiapu Wang,Gongqing Wu,Zhongyuan Wang,Jichen Zhang,Shirui Pan,Xindong Wu*

Main category: cs.CL

TL;DR: 该文章提出了一种知识推理语言模型（KRLM）来解决归纳式知识图谱推理（KGR）中LLM知识失真和生成幻觉的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱基础模型（KGFMs）在处理不确定知识图谱组件时面临挑战，而大型语言模型（LLMs）的内在知识可能被稀疏的知识图谱上下文所掩盖，导致LLM知识失真和生成幻觉。

Method: 设计了KRL指令格式和KRL tokenizer来对齐LLM知识和KG表示。提出了KRL注意力层，通过动态知识记忆机制协调LLM知识和KG上下文。提出了结构感知的下一实体预测器，约束推理结果。

Result: 在25个真实世界的归纳式KGR数据集上，KRLM在零样本推理和微调场景中都表现出显著的优越性。

Conclusion: KRLM通过统一协调LLM知识和KG上下文，有效解决了LLM知识失真和生成幻觉问题，显著提高了归纳式KGR的性能和可信度。

Abstract: Inductive Knowledge Graph Reasoning (KGR) aims to discover facts in
open-domain KGs containing unknown entities and relations, which poses a
challenge for KGR models in comprehending uncertain KG components. Existing
studies have proposed Knowledge Graph Foundation Models (KGFMs) that learn
structural invariances across KGs to handle this uncertainty. Recently, Large
Language Models (LLMs) have demonstrated strong capabilities for open-domain
knowledge reasoning. As a result, the latest research has focused on LLM-based
KGFMs that integrate LLM knowledge with KG context for inductive KGR. However,
the intrinsic knowledge of LLMs may be overshadowed by sparse KG context,
leading to LLM knowledge distortion, which can cause irreversible damage to
model reasoning. Moreover, existing LLM-based KGR methods still struggle to
fully constrain generative hallucinations in LLMs, severely limiting the
credibility of reasoning results. To address these limitations, we propose a
Knowledge Reasoning Language Model (KRLM) that achieves unified coordination
between LLM knowledge and KG context throughout the KGR process. Specifically,
we design a Knowledge Reasoning Language (KRL) instruction format and a KRL
tokenizer to align LLM knowledge with KG representations. Then, we propose a
KRL attention layer that coordinates intrinsic LLM knowledge with additional KG
context through a dynamic knowledge memory mechanism. Finally, a
structure-aware next-entity predictor is proposed, which strictly constrains
the reasoning results within a trustworthy knowledge domain. Extensive
experimental results on 25 real-world inductive KGR datasets demonstrate the
significant superiority of the proposed KRLM\footnote{Our source codes are
available at https://anonymous.4open.science/r/KRLM-EA36 in both zero-shot
reasoning and fine-tuning scenarios.

</details>


### [44] [RAGCap-Bench: Benchmarking Capabilities of LLMs in Agentic Retrieval Augmented Generation Systems](https://arxiv.org/abs/2510.13910)
*Jingru Lin,Chen Zhang,Stephen Y. Liu,Haizhou Li*

Main category: cs.CL

TL;DR: 该论文介绍了RAGCap-Bench，这是一个用于评估检索增强生成（RAG）系统中大型语言模型（LLM）中间任务的基准测试，旨在解决传统RAG在多跳问题上的不足，并通过识别常见错误和所需核心能力来改进RAG系统的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）在面对复杂查询和多跳问题时，出现的如事实错误、知识过时和幻觉等局限性。

Method: 提出了RAGCap-Bench，一个面向能力的基准测试，用于细粒度评估智能RAG工作流中的中间任务。通过分析现有系统的输出，识别常见任务及其执行所需的核心能力，并构建LLM常见错误分类法，设计有针对性的评估问题。

Result: 实验表明，“慢思考”模型在RAGCap基准测试中表现出色，即中间能力越强，端到端的结果也越好，验证了该基准测试的有效性以及提升这些中间能力的重要性。

Conclusion: RAGCap-Bench 为评估和改进智能RAG系统中的中间推理能力提供了一个有效工具，通过提升这些能力，可以显著提高LLM在处理复杂查询时的准确性和可靠性。

Abstract: Retrieval-Augmented Generation (RAG) mitigates key limitations of Large
Language Models (LLMs)-such as factual errors, outdated knowledge, and
hallucinations-by dynamically retrieving external information. Recent work
extends this paradigm through agentic RAG systems, where LLMs act as agents to
iteratively plan, retrieve, and reason over complex queries. However, these
systems still struggle with challenging multi-hop questions, and their
intermediate reasoning capabilities remain underexplored. To address this, we
propose RAGCap-Bench, a capability-oriented benchmark for fine-grained
evaluation of intermediate tasks in agentic RAG workflows. We analyze outputs
from state-of-the-art systems to identify common tasks and the core
capabilities required for their execution, then construct a taxonomy of typical
LLM errors to design targeted evaluation questions. Experiments show that
"slow-thinking" models with stronger RAGCap performance achieve better
end-to-end results, underscoring the benchmark's validity and the importance of
enhancing these intermediate capabilities.

</details>


### [45] [AI Debaters are More Persuasive when Arguing in Alignment with Their Own Beliefs](https://arxiv.org/abs/2510.13912)
*María Victoria Carro,Denise Alejandra Mester,Facundo Nieto,Oscar Agustín Stanchi,Guido Ernesto Bergman,Mario Alejandro Leiva,Eitan Sprejer,Luca Nicolás Forziati Gangi,Francisca Gauna Selasco,Juan Gustavo Corvalán,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.CL

TL;DR: 本文探讨了AI辩论作为可扩展监督技术的核心前提，并通过实验评估了大型语言模型在主观问题辩论中的表现，特别是它们在坚持先验信念与迎合评委偏好之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 目前AI辩论实验依赖于有事实真相的数据集，忽视了主观维度和模型“相信”所辩护主张为假的因素。本研究旨在通过引入主观问题和测量模型的先验信念来弥补这一不足。

Method: 1. 应用辩论于主观问题，并明确测量大型语言模型的先验信念。2. 设计评委角色与辩论者先验信念相冲突。3. 比较两种辩论协议：顺序辩论和同时辩论，以评估潜在的系统偏差。4. 评估模型在捍卫与先验信念一致或不一致立场时的说服力和论证质量。

Result: 1. 模型倾向于维护与评委角色一致的立场，而非其先验信念。2. 顺序辩论引入了显著的偏差，有利于第二位辩论者。3. 模型在捍卫与其先验信念一致的立场时更具说服力。4. 矛盾的是，与先验信念不符的论点在成对比较中被评价为更高质量。

Conclusion: 本研究结果有助于指导人类评委提供高质量的训练信号，促进AI系统对齐，并揭示了语言模型在说服动态方面人机交互的重要方面。模型在辩论中存在迎合评委的倾向，且辩论协议的选择会影响结果。

Abstract: The core premise of AI debate as a scalable oversight technique is that it is
harder to lie convincingly than to refute a lie, enabling the judge to identify
the correct position. Yet, existing debate experiments have relied on datasets
with ground truth, where lying is reduced to defending an incorrect
proposition. This overlooks a subjective dimension: lying also requires the
belief that the claim defended is false. In this work, we apply debate to
subjective questions and explicitly measure large language models' prior
beliefs before experiments. Debaters were asked to select their preferred
position, then presented with a judge persona deliberately designed to conflict
with their identified priors. This setup tested whether models would adopt
sycophantic strategies, aligning with the judge's presumed perspective to
maximize persuasiveness, or remain faithful to their prior beliefs. We
implemented and compared two debate protocols, sequential and simultaneous, to
evaluate potential systematic biases. Finally, we assessed whether models were
more persuasive and produced higher-quality arguments when defending positions
consistent with their prior beliefs versus when arguing against them. Our main
findings show that models tend to prefer defending stances aligned with the
judge persona rather than their prior beliefs, sequential debate introduces
significant bias favoring the second debater, models are more persuasive when
defending positions aligned with their prior beliefs, and paradoxically,
arguments misaligned with prior beliefs are rated as higher quality in pairwise
comparison. These results can inform human judges to provide higher-quality
training signals and contribute to more aligned AI systems, while revealing
important aspects of human-AI interaction regarding persuasion dynamics in
language models.

</details>


### [46] [Readability $\ne$ Learnability: Rethinking the Role of Simplicity in Training Small Language Models](https://arxiv.org/abs/2510.13915)
*Ivan Lee,Taylor Berg-Kirkpatrick*

Main category: cs.CL

TL;DR: 这篇论文挑战了关于可读性在小型语言模型（SLM）中连贯文本生成能力中的作用的解释。


<details>
  <summary>Details</summary>
Motivation: 以往研究认为，可读性（易懂的词汇、熟悉的叙事结构、简单句法）是小型语言模型（SLM）生成连贯文本的关键。但这篇论文对此解释提出了质疑。

Method: 本研究构建了结构匹配但可读性不同的合成数据集，用以训练模型，并比较它们在连贯性或学习效率方面的表现。此外，该研究还通过N-gram多样性来衡量统计简单性，并探讨其与可学习性的关系。

Result: 研究发现模型在复杂、成人级别文本上的表现与在简化语言上的表现相当，甚至在训练过程中能更快地发展出连贯性。同时，研究表明统计简单性（通过N-gram多样性衡量）是可学习性更强的预测指标。

Conclusion: 可读性本身并不能预测SLM的连贯性或学习效率。相反，统计简单性是更强的预测指标。研究结果提醒人们不要将语言模型训练拟人化，应更精确地推理哪些属性真正支持小型模型能力的出现。

Abstract: Recent studies suggest that very small language models (SLMs) can generate
surprisingly coherent text when trained on simplified, child-directed corpora
such as TinyStories. These findings have been interpreted as evidence that
readability -- characterized by accessible vocabulary, familiar narrative
structure, and simple syntax -- plays a key role in enabling such capabilities
to emerge. In this paper, we challenge that interpretation. We construct
synthetic datasets with matched structure but varied readability, and find that
readability alone does not predict coherence or learning efficiency in SLMs.
Models trained on complex, adult-level text perform comparably to those trained
on simplified language, and even exhibit faster development of coherence during
training. Instead, we show that statistical simplicity, as measured by n-gram
diversity, is a stronger predictor of learnability. Our findings caution
against the growing trend of anthropomorphizing language model training --
drawing parallels to human cognitive development without empirical basis -- and
argue for more precise reasoning about what properties actually support
capability emergence in small models.

</details>


### [47] [Element2Vec: Build Chemical Element Representation from Text for Property Prediction](https://arxiv.org/abs/2510.13916)
*Yuanhao Li,Keyuan Lai,Tianqi Wang,Qihao Liu,Jiawei Ma,Yuan-Chao Hu*

Main category: cs.CL

TL;DR: 本文介绍了一种名为Element2Vect的方法，用于从自然语言中有效表示化学元素，以支持自然科学研究。


<details>
  <summary>Details</summary>
Motivation: 化学元素的准确属性数据对于材料设计和制造至关重要，但许多数据由于设备限制难以直接测量。传统方法难以模拟复杂关系，且AI工具存在幻觉和缺乏可解释性问题。

Method: 我们利用语言模型从维基百科页面文本中生成通用嵌入（Global）和属性突出向量（Local）。针对文本分布差异和数据稀疏性，我们设计了一种基于自注意力的测试时训练方法来缓解预测误差。

Result: Element2Vect方法能够有效表示化学元素，以支持自然科学研究。测试时训练方法能缓解预测误差。

Conclusion: 本研究为AI驱动的材料科学发现铺平了道路。

Abstract: Accurate property data for chemical elements is crucial for materials design
and manufacturing, but many of them are difficult to measure directly due to
equipment constraints. While traditional methods use the properties of other
elements or related properties for prediction via numerical analyses, they
often fail to model complex relationships. After all, not all characteristics
can be represented as scalars. Recent efforts have been made to explore
advanced AI tools such as language models for property estimation, but they
still suffer from hallucinations and a lack of interpretability. In this paper,
we investigate Element2Vecto effectively represent chemical elements from
natural languages to support research in the natural sciences. Given the text
parsed from Wikipedia pages, we use language models to generate both a single
general-purpose embedding (Global) and a set of attribute-highlighted vectors
(Local). Despite the complicated relationship across elements, the
computational challenges also exist because of 1) the discrepancy in text
distribution between common descriptions and specialized scientific texts, and
2) the extremely limited data, i.e., with only 118 known elements, data for
specific properties is often highly sparse and incomplete. Thus, we also design
a test-time training method based on self-attention to mitigate the prediction
error caused by Vanilla regression clearly. We hope this work could pave the
way for advancing AI-driven discovery in materials science.

</details>


### [48] [Optimal Aggregation of LLM and PRM Signals for Efficient Test-Time Scaling](https://arxiv.org/abs/2510.13918)
*Peng Kuang,Yanli Wang,Xiaoyu Han,Yaowenqi Liu,Kaidi Xu,Haohan Wang*

Main category: cs.CL

TL;DR: 本文探讨了如何有效利用大型语言模型（LLM）和过程奖励模型（PRM）的验证信号进行测试时间扩展（TTS）。通过开发理论框架和实证研究，提出了优化权重的聚合策略，显著提升了TTS效率。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型（PRM）在测试时间扩展（TTS）中的应用面临挑战，简单的多数投票有时优于PRM。这引发了如何有效利用PRM验证信号的关键问题。

Method: 本文首先开发了一个理论框架，用于优化结合LLM和PRM的信号。该框架揭示了最佳策略是响应的加权聚合，并通过实证研究发现最佳权重函数在不同的LLM-PRM对之间差异显著，并且通常分配显著的负权重。在此基础上，提出了高效的预计算方法来校准这些加权函数。

Result: 在5个LLM和7个PRM上的大量实验表明，本文提出的校准方法显著提升了TTS效率，超越了普通的加权多数投票，而计算量仅为后者的21.3%。

Conclusion: 本研究表明，投资于更智能的聚合策略是比简单地扩展测试时间计算更有效的性能提升途径。

Abstract: Process reward models (PRMs) are a cornerstone of test-time scaling (TTS),
designed to verify and select the best responses from large language models
(LLMs). However, this promise is challenged by recent benchmarks where simple
majority voting, which ignores PRM signals, occasionally outperforms standard
PRM-based selection. This raises a critical question: How can we effectively
utilize verification signals from PRMs for TTS? To address this, we start by
developing a theoretical framework for optimally combining signals from both
the LLM and the PRM. Our framework reveals that the optimal strategy is a
weighted aggregation of responses, a strategy whose effectiveness hinges on
estimating weights that capture the complex interplay between the models. Based
on our theoretical results, we empirically show that these optimal weighting
functions differ significantly across LLM-PRM pairs and, notably, often assign
substantial negative weights. Motivated by these insights, we propose efficient
pre-computation methods to calibrate these weighting functions. Extensive
experiments across 5 LLMs and 7 PRMs demonstrate that our calibration method
significantly boosts the TTS efficiency, surpassing the performance of vanilla
weighted majority voting while using only $21.3\%$ of the computation.
Ultimately, our work demonstrates that investing in a more intelligent
aggregation strategy can be a more convincing path to performance gains than
simply scaling test-time computation.

</details>


### [49] [Robust or Suggestible? Exploring Non-Clinical Induction in LLM Drug-Safety Decisions](https://arxiv.org/abs/2510.13931)
*Siying Liu,Shisheng Zhang,Indu Bala*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在药物安全预测中对社会人口统计学信息的整合，发现模型对弱势群体存在系统性偏见，并提出了在临床应用前需要关注公平性评估和缓解策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在生物医学领域的应用日益广泛，但其在药物安全预测中的可靠性，特别是在处理社会人口统计学信息方面的表现尚未得到充分探索。研究旨在评估LLMs在对不良事件（AE）进行预测时是否会纳入与临床不相关的社会人口统计学属性，以及这些属性如何影响预测结果。

Method: 本研究使用了来自美国食品药品监督管理局不良事件报告系统（FAERS）的结构化数据。研究采用基于人物角色的评估框架，对ChatGPT-4o和Bio-Medical-Llama-3.8B这两个最先进的模型进行了评估。人物角色根据教育、婚姻状况、就业、保险、语言、住房稳定性和宗教等属性进行定义。此外，研究还评估了模型在三种用户角色（全科医生、专科医生、患者）下的表现，以模拟真实世界的部署场景。

Result: 研究结果显示，在不良事件预测准确性方面存在系统性差异。弱势群体（例如，受教育程度低、住房不稳定）被赋予的不良事件预测可能性显着高于特权群体（例如，研究生学历、私人保险）。除了结果上的差异，研究还发现了两种不同的偏见模式：显性偏见（预测直接引用人物角色属性）和隐性偏见（预测不一致，但未明确提及人物角色）。

Conclusion: 这项研究揭示了在将大型语言模型应用于药物警戒领域时存在的关键风险，并强调了在临床部署之前，迫切需要制定以公平性为导向的评估协议和缓解策略，以确保模型的公正性和可靠性。

Abstract: Large language models (LLMs) are increasingly applied in biomedical domains,
yet their reliability in drug-safety prediction remains underexplored. In this
work, we investigate whether LLMs incorporate socio-demographic information
into adverse event (AE) predictions, despite such attributes being clinically
irrelevant. Using structured data from the United States Food and Drug
Administration Adverse Event Reporting System (FAERS) and a persona-based
evaluation framework, we assess two state-of-the-art models, ChatGPT-4o and
Bio-Medical-Llama-3.8B, across diverse personas defined by education, marital
status, employment, insurance, language, housing stability, and religion. We
further evaluate performance across three user roles (general practitioner,
specialist, patient) to reflect real-world deployment scenarios where
commercial systems often differentiate access by user type. Our results reveal
systematic disparities in AE prediction accuracy. Disadvantaged groups (e.g.,
low education, unstable housing) were frequently assigned higher predicted AE
likelihoods than more privileged groups (e.g., postgraduate-educated, privately
insured). Beyond outcome disparities, we identify two distinct modes of bias:
explicit bias, where incorrect predictions directly reference persona
attributes in reasoning traces, and implicit bias, where predictions are
inconsistent, yet personas are not explicitly mentioned. These findings expose
critical risks in applying LLMs to pharmacovigilance and highlight the urgent
need for fairness-aware evaluation protocols and mitigation strategies before
clinical deployment.

</details>


### [50] [Big Reasoning with Small Models: Instruction Retrieval at Inference Time](https://arxiv.org/abs/2510.13935)
*Kenan Alkiek,David Jurgens,Vinod Vydiswaran*

Main category: cs.CL

TL;DR: 该论文介绍了一种通过“指令干预”来解决小型语言模型（SLM）在复杂推理任务中表现不佳的问题。通过检索预先构建的指令而不是从头生成，SLM能够获得结构化的推理指导。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）在本地硬件上高效运行，具有隐私性强、成本低和环境影响小等优点。然而，它们在需要多步骤推理或领域特定知识的任务中表现不佳。

Method: 该方法通过将相似的训练问题分组并使用GPT-5创建指令来构建“指令语料库”。在推理过程中，SLM检索最相关的指令并遵循其步骤。与检索增强生成不同，该方法检索结构化推理指导而非文本段落。

Result: 该框架在MedQA、MMLU Professional Law和MathQA等数据集上进行了评估，使用的模型参数范围从3B到14B，且未进行额外微调。指令检索在MedQA上带来了9.4%的提升，在MMLU Law上带来了7.9%的提升，在MathQA上带来了5.1%的提升。简洁的指令效果优于冗长的指令，并且性能提升的幅度强烈依赖于模型家族和固有的推理能力。

Conclusion: 指令干预能够有效地增强小型语言模型在复杂推理任务中的表现，为SLMs在本地计算场景下进行大规模推理提供了新的思路。

Abstract: Can we bring large-scale reasoning to local-scale compute? Small language
models (SLMs) are increasingly attractive because they run efficiently on local
hardware, offering strong privacy, low cost, and reduced environmental impact.
Yet they often struggle with tasks that require multi-step reasoning or
domain-specific knowledge. We address this limitation through instruction
intervention at inference time, where an SLM retrieves structured reasoning
procedures rather than generating them from scratch. Our method builds an
Instruction Corpus by grouping similar training questions and creating
instructions via GPT-5. During inference, the SLM retrieves the most relevant
instructions and follows their steps. Unlike retrieval-augmented generation,
which retrieves text passages, instruction retrieval gives the model structured
guidance for reasoning. We evaluate this framework on MedQA (medical board
exams), MMLU Professional Law, and MathQA using models from 3B to 14B
parameters without any additional fine-tuning. Instruction retrieval yields
consistent gains: 9.4% on MedQA, 7.9% on MMLU Law, and 5.1% on MathQA. Concise
instructions outperform longer ones, and the magnitude of improvement depends
strongly on model family and intrinsic reasoning ability.

</details>


### [51] [FinDeepResearch: Evaluating Deep Research Agents in Rigorous Financial Analysis](https://arxiv.org/abs/2510.13936)
*Fengbin Zhu,Xiang Yao Ng,Ziyang Liu,Chang Liu,Xianwei Zeng,Chao Wang,Tianhui Tan,Xuan Yao,Pengyang Shao,Min Xu,Zixuan Wang,Jing Wang,Xin Lin,Junfeng Li,Jingxian Zhu,Yang Zhang,Wenjie Wang,Fuli Feng,Richang Hong,Huanbo Luan,Ke-Wei Huang,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文提出了HisRubric评估框架和FinDeepResearch基准，用于严格评估DR Agent在企业财务分析方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对DR Agent在关键研究分析能力方面严格和系统的评估。

Method: 1. 提出HisRubric评估框架：具有分层分析结构和细粒度评分标准，用于评估DR Agent在企业财务分析方面的能力。该框架模仿专业分析师的工作流程，从数据识别到指标计算，再到战略总结和解读。
2. 构建FinDeepResearch基准：包含8个金融市场的64家上市公司，涵盖4种语言，共计15,808个评分项。
3. 进行广泛实验：在FinDeepResearch上使用16种代表性方法，包括6种DR Agent、5种具备深度推理和搜索能力的LLM，以及5种仅具备深度推理能力的LLM。

Result: 实验结果揭示了这些方法在不同能力、金融市场和语言方面的优势和局限性。

Conclusion: 本文提出的HisRubric评估框架和FinDeepResearch基准为未来DR Agent的研究和开发提供了有价值的见解。

Abstract: Deep Research (DR) agents, powered by advanced Large Language Models (LLMs),
have recently garnered increasing attention for their capability in conducting
complex research tasks. However, existing literature lacks a rigorous and
systematic evaluation of DR Agent's capabilities in critical research analysis.
To address this gap, we first propose HisRubric, a novel evaluation framework
with a hierarchical analytical structure and a fine-grained grading rubric for
rigorously assessing DR agents' capabilities in corporate financial analysis.
This framework mirrors the professional analyst's workflow, progressing from
data recognition to metric calculation, and finally to strategic summarization
and interpretation. Built on this framework, we construct a FinDeepResearch
benchmark that comprises 64 listed companies from 8 financial markets across 4
languages, encompassing a total of 15,808 grading items. We further conduct
extensive experiments on the FinDeepResearch using 16 representative methods,
including 6 DR agents, 5 LLMs equipped with both deep reasoning and search
capabilities, and 5 LLMs with deep reasoning capabilities only. The results
reveal the strengths and limitations of these approaches across diverse
capabilities, financial markets, and languages, offering valuable insights for
future research and development. The benchmark and evaluation code will be made
publicly available.

</details>


### [52] [Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers](https://arxiv.org/abs/2510.13939)
*Tuhin Chakrabarty,Jane C. Ginsburg,Paramveer Dhillon*

Main category: cs.CL

TL;DR: 该研究探讨了AI模仿作者风格生成文学文本的能力。结果显示，经过微调的AI模型在风格保真度和写作质量方面优于人类专家作品，并显著降低了成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决作者们对AI生成衍生内容引发的版权诉讼的担忧，并探究AI模型在模仿作者风格和生成高质量文学文本方面的能力。

Method: 研究对比了MFA培训的专家作家与ChatGPT、Claude和Gemini这三个前沿AI模型。在预注册研究中，AI模型被要求模仿50位获奖作家的风格，生成450字的文学节选。159名专家和普通读者对AI生成文本和人类专家作品进行了盲评。研究还比较了上下文提示和对单个作者完整作品进行微调的ChatGPT模型的表现。

Result: 专家评审发现，通过上下文提示生成的AI文本在风格保真度（OR=0.16, p<10^8）和写作质量（OR=0.13, p<10^7）方面均不受欢迎。然而，经过对单个作者作品进行微调后，专家评审开始偏爱AI生成的文本，认为它们在风格保真度（OR=8.16, p<10^13）和写作质量（OR=1.87, p=0.010）方面更优。普通读者的评价也显示出类似的变化。微调后的AI输出被AI检测器识别为AI生成的概率仅为3%。调解分析表明，微调消除了AI文本中可检测到的风格怪癖。

Conclusion: 针对特定作者进行微调的AI模型能够生成读者认为优于人类专家作品的非逐字AI文本。这为版权法中“对潜在市场或价值的影响”这一合理使用第四因素提供了经验证据。尽管未考虑后期人工编辑成本，但微调和推理成本显著低于专业作家报酬。

Abstract: The use of copyrighted books for training AI models has led to numerous
lawsuits from authors concerned about AI's ability to generate derivative
content.Yet it's unclear whether these models can generate high quality
literary text while emulating authors' styles. To answer this we conducted a
preregistered study comparing MFA-trained expert writers with three frontier AI
models: ChatGPT, Claude & Gemini in writing up to 450 word excerpts emulating
50 award-winning authors' diverse styles. In blind pairwise evaluations by 159
representative expert & lay readers, AI-generated text from in-context
prompting was strongly disfavored by experts for both stylistic fidelity
(OR=0.16, p<10^8) & writing quality (OR=0.13, p<10^7) but showed mixed results
with lay readers. However, fine-tuning ChatGPT on individual authors' complete
works completely reversed these findings: experts now favored AI-generated text
for stylistic fidelity (OR=8.16, p<10^13) & writing quality (OR=1.87, p=0.010),
with lay readers showing similar shifts. These effects generalize across
authors & styles. The fine-tuned outputs were rarely flagged as AI-generated
(3% rate v. 97% for in-context prompting) by best AI detectors. Mediation
analysis shows this reversal occurs because fine-tuning eliminates detectable
AI stylistic quirks (e.g., cliche density) that penalize in-context outputs.
While we do not account for additional costs of human effort required to
transform raw AI output into cohesive, publishable prose, the median
fine-tuning & inference cost of $81 per author represents a dramatic 99.7%
reduction compared to typical professional writer compensation. Author-specific
fine-tuning thus enables non-verbatim AI writing that readers prefer to expert
human writing, providing empirical evidence directly relevant to copyright's
fourth fair-use factor, the "effect upon the potential market or value" of the
source works.

</details>


### [53] [Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention](https://arxiv.org/abs/2510.13940)
*Zhen Yang,Mingyang Zhang,Feng Chen,Ganggui Ding,Liang Hou,Xin Tao,Pengfei Wan,Ying-Cong Chen*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为MTI（Minimal Test-Time Intervention）的无训练框架，通过选择性CFG干预和轻量级负面提示引导，在推理时以最小的开销提高大型语言模型的推理准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理方面的最新进展主要集中在通过增加推理计算来提高推理，但这通常以效率为代价。目前尚未充分探索的一个现象是，推理不确定性是高度局部化的，只有一小部分高熵词元会主导性地影响输出的正确性。

Method: MTI框架包含两个主要部分：1. 选择性CFG干预：只在不确定的位置应用无分类器引导；2. 轻量级负面提示引导：重复利用主模型的KV缓存以高效地近似无条件解码。

Result: MTI在通用、编码和STEM任务中都取得了显著的提升。例如，在八个基准测试中，Qwen3-8B-Base的平均性能提升了1.35%，在AIME2024上，Qwen3-32B-Reasoning的性能提升了5%，同时保持了高效率。

Conclusion: MTI框架通过识别和干预推理过程中不确定性高的局部区域，以最小的额外计算开销，显著提升了大型语言模型的推理准确性和稳定性，为提高LLMs的效率和性能提供了一个有前景的方向。

Abstract: Recent progress in large language models (LLMs) has focused on test-time
scaling to improve reasoning via increased inference computation, but often at
the cost of efficiency. We revisit test-time behavior and uncover a simple yet
underexplored phenomenon: reasoning uncertainty is highly localized-only a
small subset of high-entropy tokens dominantly affects output correctness.
Motivated by this, we propose Minimal Test-Time Intervention (MTI), a
training-free framework that enhances reasoning accuracy and stability with
minimal overhead. MTI includes: (i) Selective CFG intervention, applying
classifier-free guidance only at uncertain positions; and (ii) Lightweight
negative-prompt guidance, reusing the main model's KV cache to approximate
unconditional decoding efficiently. MTI yields consistent gains across general,
coding, and STEM tasks-e.g., +1.35% average improvement on eight benchmarks for
Qwen3-8B-Base and +5% on AIME2024 using Qwen3-32B-Reasoning-while remaining
highly efficient.

</details>


### [54] [Classifying and Addressing the Diversity of Errors in Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.13975)
*Kin Kwan Leung,Mouloud Belbahri,Yi Sui,Alex Labach,Xueying Zhang,Stephen Rose,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种针对检索增强生成（RAG）系统中错误类型的新分类方法。


<details>
  <summary>Details</summary>
Motivation: 在大规模语言模型（LLM）驱动的问答系统中，检索增强生成（RAG）被广泛应用。然而，RAG系统的复杂性导致其输出中可能存在多种错误，理解这些错误对于RAG系统的稳定部署至关重要。

Method: 本研究提出了一种针对RAG系统错误类型的新分类法，并提供了每种错误类型的实例和解决建议。此外，作者还整理了一个包含错误RAG响应的数据集，并对错误类型进行了标注。在此基础上，提出了一种与分类法对齐的自动评估方法，可用于开发过程中错误跟踪和解决。

Result: 提供了一个新的RAG系统错误分类法、带标注错误类型的数据集以及一种用于错误跟踪和解决的自动评估方法。

Conclusion: 本研究通过提出新的错误分类法和自动评估方法，旨在帮助开发者在RAG系统开发过程中更好地理解、跟踪和解决错误，从而提高系统的鲁棒性。

Abstract: Retrieval-augmented generation (RAG) is a prevalent approach for building
LLM-based question-answering systems that can take advantage of external
knowledge databases. Due to the complexity of real-world RAG systems, there are
many potential causes for erroneous outputs. Understanding the range of errors
that can occur in practice is crucial for robust deployment. We present a new
taxonomy of the error types that can occur in realistic RAG systems, examples
of each, and practical advice for addressing them. Additionally, we curate a
dataset of erroneous RAG responses annotated by error types. We then propose an
auto-evaluation method aligned with our taxonomy that can be used in practice
to track and address errors during development. Code and data are available at
https://github.com/layer6ai-labs/rag-error-classification.

</details>


### [55] [CRaFT: An Explanation-Based Framework for Evaluating Cultural Reasoning in Multilingual Language Models](https://arxiv.org/abs/2510.14014)
*Shehenaz Hossain,Haithem Afli*

Main category: cs.CL

TL;DR: CRaFT是一个基于解释的多语言评估框架，用于评估大型语言模型在不同文化背景下的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法未能反映大模型对文化的理解，仅依赖正确答案不足以评估其在不同文化背景下的推理能力，因此需要开发一种新的评估框架来解决这个问题。

Method: CRaFT框架不只根据准确性评分，而是使用文化流畅性、偏差、一致性和语言适应性四个可解释的指标来评估模型的解释。该研究将CRaFT框架应用于来自世界价值观调查的50个具有文化背景的问题，这些问题被翻译成阿拉伯语、孟加拉语和西班牙语，并评估了GPT、DeepSeek和FANAR这三个模型，共产生了2100多对答案-解释。

Result: 研究结果显示，模型在不同语言的推理能力上存在显著的跨语言差异：阿拉伯语会降低流畅性，孟加拉语能增强流畅性，而西班牙语则基本保持稳定。GPT在不同语言中表现出更强的适应性，但一致性较低；FANAR则显示出稳定但僵化的推理。

Conclusion: LLM中的文化意识并非其固有能力，而是通过语言框架形成的。CRaFT为评估多语言环境中的跨文化推理提供了一个新视角，也为构建文化适应性语言模型提供了可行的见解。

Abstract: Correct answers do not necessarily reflect cultural understanding. We
introduce CRaFT, an explanation-based multilingual evaluation framework
designed to assess how large language models (LLMs) reason across cultural
contexts. Rather than scoring outputs solely based on accuracy, CRaFT evaluates
model explanations using four interpretable metrics: Cultural Fluency,
Deviation, Consistency, and Linguistic Adaptation. We apply the framework to 50
culturally grounded questions from the World Values Survey, translated into
Arabic, Bengali, and Spanish, and evaluate three models (GPT, DeepSeek, and
FANAR) across over 2,100 answer-explanation pairs. Results reveal significant
cross-lingual variation in reasoning: Arabic reduces fluency, Bengali enhances
it, and Spanish remains largely stable. While GPT adapts more effectively
across languages, it exhibits lower consistency; FANAR shows stable but rigid
reasoning. These findings suggest that cultural awareness in LLMs is not
intrinsic but emerges through linguistic framing. CRaFT offers a new lens for
evaluating cross-cultural reasoning in multilingual settings, providing
actionable insights for building culturally adaptive language models.

</details>


### [56] [Think Globally, Group Locally: Evaluating LLMs Using Multi-Lingual Word Grouping Games](https://arxiv.org/abs/2510.14030)
*César Guerra-Solano,Zhuochun Li,Xiang Lorraine Li*

Main category: cs.CL

TL;DR: 这篇论文评估了大型语言模型在抽象推理任务中跨语言的偏见问题，引入了一个灵感来自于纽约时报Connections的新任务GlobalGroup，并构建了一个包含五种语言的游戏基准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在不同语言的推理能力上存在偏见，即使内容相似，其表现也可能不同。以往的研究多集中于常识或数学推理任务，而对抽象推理任务中的语言偏见评估较少。抽象推理在日常生活中至关重要，它依赖于跳出固有思维模式来识别和利用模式解决问题，而非公式化方法。

Method: 本文提出了一个名为GlobalGroup的抽象推理任务，灵感来源于《纽约时报》的Connections游戏。构建了一个包含五种语言（英语、西班牙语、中文、印地语和阿拉伯语）的游戏基准，并提供了每种语言的本地版本和英语翻译版本进行对比。设计了游戏难度测量方法，以便在难度相似的游戏上评估模型，从而实现更可控的比较。

Result: 实验结果表明，英语模式在抽象推理任务中通常表现更佳。此外，在开源模型和闭源模型之间也存在性能差异。

Conclusion: LLMs在抽象推理能力上存在显著的语言偏见，特别是在英语模态上表现更好。当前的评估方法仍需改进，以更公平地衡量模型在不同语言和不同抽象推理任务中的表现。未来的研究可以探索如何减少这种语言偏见，以及如何设计更鲁棒的跨语言抽象推理评估基准。

Abstract: Large language models (LLMs) can exhibit biases in reasoning capabilities due
to linguistic modality, performing better on tasks in one language versus
another, even with similar content. Most previous works evaluate this through
reasoning tasks where reliance on strategies or knowledge can ensure success,
such as in commonsense or math tasks. However, abstract reasoning is vital to
reasoning for everyday life, where people apply "out-of-the-box thinking" to
identify and use patterns for solutions, without a reliance on formulaic
approaches. Comparatively, little work has evaluated linguistic biases in this
task type. In this paper, we propose a task inspired by the New York Times
Connections: GlobalGroup, that evaluates models in an abstract reasoning task
across several languages. We constructed a game benchmark with five linguistic
backgrounds -- English, Spanish, Chinese, Hindi, and Arabic -- in both the
native language and an English translation for comparison. We also proposed
game difficulty measurements to evaluate models on games with similar
difficulty, enabling a more controlled comparison, which is particularly
important in reasoning evaluations. Through experimentation, we find English
modalities largely lead to better performance in this abstract reasoning task,
and performance disparities between open- and closed-source models.

</details>


### [57] [Quantifying Phonosemantic Iconicity Distributionally in 6 Languages](https://arxiv.org/abs/2510.14040)
*George Flint,Kaustubh Kislay*

Main category: cs.CL

TL;DR: 本文分析了跨越六种语言的语素语音和语义相似性排列，并发现了许多新的语音语义对齐方式和跨语言模式。


<details>
  <summary>Details</summary>
Motivation: 探索语音和语义之间是否存在系统性关系及其程度，尤其是在大规模量化调查中。

Method: 本文采用分布方法，通过统计测量分析了六种不同语言（英语、西班牙语、印地语、芬兰语、土耳其语和泰米尔语）中语素语音和语义相似性空间的对齐。

Result: 发现了大量以前未在文献中识别出的可解释语音语义对齐，以及跨语言模式。同时，本文还分析了五个先前假设的语音语义对齐，其中一些得到了支持，另一些则结果不一。

Conclusion: 语音和语义之间存在系统性关系，并且可以通过大规模定量研究发现新的语音语义对齐模式和跨语言模式。

Abstract: Language is, as commonly theorized, largely arbitrary. Yet, systematic
relationships between phonetics and semantics have been observed in many
specific cases. To what degree could those systematic relationships manifest
themselves in large scale, quantitative investigations--both in previously
identified and unidentified phenomena? This work undertakes a distributional
approach to quantifying phonosemantic iconicity at scale across 6 diverse
languages (English, Spanish, Hindi, Finnish, Turkish, and Tamil). In each
language, we analyze the alignment of morphemes' phonetic and semantic
similarity spaces with a suite of statistical measures, and discover an array
of interpretable phonosemantic alignments not previously identified in the
literature, along with crosslinguistic patterns. We also analyze 5 previously
hypothesized phonosemantic alignments, finding support for some such alignments
and mixed results for others.

</details>


### [58] [ERGO: Entropy-guided Resetting for Generation Optimization in Multi-turn Language Models](https://arxiv.org/abs/2510.14077)
*Haziq Mohammad Khalid,Athikash Jeyaganthan,Timothy Do,Yicheng Fu,Sean O'Brien,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: ERGO通过量化大模型（LLMs）在多轮对话中的不确定性，并在这种不确定性急剧增加时通过动态提示整合来重新调整对话上下文，从而显著提高了多轮对话任务中的性能、能力和可靠性。


<details>
  <summary>Details</summary>
Motivation: LLMs在多轮对话中，当信息增量呈现时，性能会显著下降，这严重影响了其在现实世界中的可用性。

Method: 本文提出了ERGO（Entropy-guided Resetting for Generation Optimization），通过计算下一词元分布的香农熵来量化内部不确定性。当检测到熵的急剧增加时，ERGO会触发自适应提示整合，以此来动态重新对齐对话上下文。

Result: 在信息渐进式揭示的多轮任务中，ERGO相较于基线模型，平均性能提升了56.6%，能力（峰值性能）提升了24.7%，不可靠性（性能变异性）降低了35.3%。

Conclusion: ERGO通过将不确定性作为一种信号而非需要消除的干扰，成功地提高了对话式AI的准确性和可靠性，这表明不确定性感知干预可以有效改善对话AI的性能。

Abstract: Large Language Models (LLMs) suffer significant performance degradation in
multi-turn conversations when information is presented incrementally. Given
that multi-turn conversations characterize everyday interactions with LLMs,
this degradation poses a severe challenge to real world usability. We
hypothesize that abrupt increases in model uncertainty signal misalignment in
multi-turn LLM interactions, and we exploit this insight to dynamically realign
conversational context. We introduce ERGO (Entropy-guided Resetting for
Generation Optimization), which continuously quantifies internal uncertainty
via Shannon entropy over next token distributions and triggers adaptive prompt
consolidation when a sharp spike in entropy is detected. By treating
uncertainty as a first class signal rather than a nuisance to eliminate, ERGO
embraces variability in language and modeling, representing and responding to
uncertainty. In multi-turn tasks with incrementally revealed instructions, ERGO
yields a 56.6% average performance gain over standard baselines, increases
aptitude (peak performance capability) by 24.7%, and decreases unreliability
(variability in performance) by 35.3%, demonstrating that uncertainty aware
interventions can improve both accuracy and reliability in conversational AI.

</details>


### [59] [DROID: Dual Representation for Out-of-Scope Intent Detection](https://arxiv.org/abs/2510.14110)
*Wael Rashwan,Hossam M. Zawbaa,Sourav Dutta,Haytham Assem*

Main category: cs.CL

TL;DR: 本文提出了 droid 模型来识别任务型对话系统中的超范围指令，解决了现有模型对此识别效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 在任务型对话系统中，检测超范围用户指令仍然是一个关键挑战。现有的方法通常依赖于很强的分布假设或辅助校准模块。

Method: 本文提出了 DROID（超范围意图检测双重表示），这是一个紧凑的端到端框架，结合了两个互补的编码器：用于广泛语义泛化的通用句子编码器（USE）和用于领域特定上下文区分的领域适应性基于 Transformer 的去噪自编码器（TSDAE）。它们的融合表示由一个轻量级分支分类器处理，该分类器具有单个校准阈值，可以在没有事后评分的情况下分离域内和超范围意图。为了在有限的监督下增强边界学习，DROID 结合了合成和开放域异常值增强。

Result: 尽管只使用了 1.5M 可训练参数，但在多个意图基准测试中，DROID 始终优于最近的最新基线，已知意图的宏观 F1 值提高了 6-15%，超范围意图的宏观 F1 值提高了 8-20%，在低资源设置中收益最为显著。

Conclusion: 双编码器表示与简单校准可以为神经对话系统带来稳健、可扩展和可靠的超范围检测。

Abstract: Detecting out-of-scope (OOS) user utterances remains a key challenge in
task-oriented dialogue systems and, more broadly, in open-set intent
recognition. Existing approaches often depend on strong distributional
assumptions or auxiliary calibration modules. We present DROID (Dual
Representation for Out-of-Scope Intent Detection), a compact end-to-end
framework that combines two complementary encoders -- the Universal Sentence
Encoder (USE) for broad semantic generalization and a domain-adapted
Transformer-based Denoising Autoencoder (TSDAE) for domain-specific contextual
distinctions. Their fused representations are processed by a lightweight
branched classifier with a single calibrated threshold that separates in-domain
and OOS intents without post-hoc scoring. To enhance boundary learning under
limited supervision, DROID incorporates both synthetic and open-domain outlier
augmentation. Despite using only 1.5M trainable parameters, DROID consistently
outperforms recent state-of-the-art baselines across multiple intent
benchmarks, achieving macro-F1 improvements of 6--15% for known and 8--20% for
OOS intents, with the most significant gains in low-resource settings. These
results demonstrate that dual-encoder representations with simple calibration
can yield robust, scalable, and reliable OOS detection for neural dialogue
systems.

</details>


### [60] [RLSR: Reinforcement Learning with Supervised Reward Outperforms SFT in Instruction Following](https://arxiv.org/abs/2510.14200)
*Zhichao Wang,Andy Wong,Ruslan Belkin*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为RLSR的新方法，用于在RL框架内利用现有的大型监督微调（SFT）数据集，以提高大型语言模型的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的预训练之后，通常会采用SFT、RLHF、RLVR和RFT等技术来增强指令遵循能力、减少不良响应、提高推理能力并实现高效的领域适应。SFT依赖于下一个token预测目标来加强指令遵循，而RFT采用基于强化学习（RL）的方法进行领域适应。本文的动机是受到RFT的启发，旨在用RLSR替代SFT，以更有效地利用SFT数据集来提升基础模型的指令遵循能力。

Method: RLSR方法的核心在于将大规模SFT数据集融入强化学习（RL）框架。具体而言，该方法让基础模型为每个提示生成多个响应，并计算生成的响应与人类标注响应在语义嵌入空间中的余弦相似度作为奖励分数。这使得RLSR能够利用SFT数据集的丰富信息，并通过RL机制对模型进行优化，从而学习更好的指令遵循策略。

Result: RLSR在指令遵循基准测试中展现出优越的性能。例如，在Qwen-7B (INFINITY)模型上，RLSR (SB)的AlpacaEval胜率为26.34%，超过了SFT的21.01%。此外，将SFT与RLSR结合使用可以进一步提升下游任务的性能；经过SFT + RLSR训练的Qwen-7B (INFINITY)的胜率达到了30.73%。

Conclusion: 本文提出了一种新颖的RLSR方法，通过将现有的监督微调（SFT）数据集整合到强化学习（RL）框架中，显著提升了大型语言模型（LLM）的指令遵循能力。实验结果表明，RLSR能够单独取代SFT并取得更优异的性能，同时与SFT相结合还能进一步增强模型的下游任务表现，为LLM的微调提供了一个更高效和强大的范式。

Abstract: After the pretraining stage of LLMs, techniques such as SFT, RLHF, RLVR, and
RFT are applied to enhance instruction-following ability, mitigate undesired
responses, improve reasoning capability and enable efficient domain adaptation
with minimal data. SFT relies on the next-token prediction objective to
strengthen instruction following in a base model using a large corpus of
human-labeled responses. In contrast, RFT employs a RL-based approach to adapt
fine-tuned reasoning models to specific domains with limited supervision.
Inspired by RFT, we propose replacing SFT with RLSR to leverage the extensive
SFT dataset in an RL framework, thereby improving the base model's
instruction-following ability. In RLSR, the base model generates multiple
responses for each prompt, and reward scores are computed as the cosine
similarity in the semantic embedding space between the generated and
human-labeled responses. RLSR can be utilized in multiple ways. It can directly
replace SFT, achieving superior performance on instruction-following
benchmarks-for example, RLSR (SB) on Qwen-7B (INFINITY) achieved an AlpacaEval
win rate of 26.34%, surpassing SFT's 21.01%. Furthermore, combining SFT and
RLSR further enhances downstream task performance; Qwen-7B (INFINITY) achieved
a win rate of 30.73% when trained with SFT + RLSR.

</details>


### [61] [LiteStage: Latency-aware Layer Skipping for Multi-stage Reasoning](https://arxiv.org/abs/2510.14211)
*Beomseok Kang,Jiwon Song,Jae-Joon Kim*

Main category: cs.CL

TL;DR: LiteStage 是一个针对多阶段推理的低延迟层跳过框架，它通过结合阶段性离线搜索和在线基于置信度的生成早期退出，在保证精度的前提下显著提高了小型语言模型的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的多阶段推理方法在提高小型语言模型推理能力的同时，带来了延迟增加的问题。现有的自适应加速技术（如层跳过）难以在该场景中平衡效率和准确性，主要归因于两个挑战：1）跳过敏感度的阶段性差异；2）冗余输出令牌的生成。

Method: 我们提出了 LiteStage，一个针对多阶段推理的低延迟层跳过框架。它结合了阶段性离线搜索来分配最优的层预算，以及在线基于置信度的生成早期退出机制来抑制不必要的解码。

Result: 在三个基准测试（OBQA、CSQA 和 StrategyQA）上的实验表明，LiteStage 在准确率损失低于 4.0% 的情况下，实现了高达 1.70 倍的加速，优于此前的免训练层跳过方法。

Conclusion: LiteStage 通过其独特的方法，成功解决了多阶段推理中效率与准确性之间的矛盾，为小型语言模型的推理加速提供了一种有效且实用的解决方案。

Abstract: Multi-stage reasoning has emerged as an effective strategy for enhancing the
reasoning capability of small language models by decomposing complex problems
into sequential sub-stages. However, this comes at the cost of increased
latency. We observe that existing adaptive acceleration techniques, such as
layer skipping, struggle to balance efficiency and accuracy in this setting due
to two key challenges: (1) stage-wise variation in skip sensitivity, and (2)
the generation of redundant output tokens. To address these, we propose
LiteStage, a latency-aware layer skipping framework for multi-stage reasoning.
LiteStage combines a stage-wise offline search that allocates optimal layer
budgets with an online confidence-based generation early exit to suppress
unnecessary decoding. Experiments on three benchmarks, e.g., OBQA, CSQA, and
StrategyQA, show that LiteStage achieves up to 1.70x speedup with less than
4.0% accuracy loss, outperforming prior training-free layer skipping methods.

</details>


### [62] [Flip-Flop Consistency: Unsupervised Training for Robustness to Prompt Perturbations in LLMs](https://arxiv.org/abs/2510.14242)
*Parsa Hejabi,Elnaz Rahmati,Alireza S. Ziabari,Morteza Dehghani*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Flip-Flop Consistency ($F^2C$)的无监督训练方法，旨在提高大型语言模型（LLMs）对不同提示表达方式的鲁棒性，从而在11个数据集中显著提升一致性、F1分数并降低性能方差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在面对相同提示的不同表述时，经常会产生不一致的答案，这激发了研究者开发一种提高LLM对这些扰动鲁棒性的方法。

Method: $F^2C$方法包含两个关键组成部分：1. Consensus Cross-Entropy (CCE)利用提示变体间的多数投票来创建硬伪标签。2. 表示对齐损失（representation alignment loss）将低置信度和非多数预测器拉向由高置信度、多数投票变体建立的共识。

Result: 在11个数据集和四种自然语言处理任务上的评估显示，$F^2C$平均将观察到的一致性提高了11.62%，F1平均提高了8.94%，并将格式间的性能方差降低了3.29%。在域外评估中，$F^2C$也能有效泛化，提高了F1分数和一致性，同时降低了大多数源-目标对的方差。即使仅在部分提示扰动上训练并在未见过的格式上评估，$F^2C$也能持续提高性能和一致性并减少方差。

Conclusion: 这些发现强调$F^2C$是一种有效的无监督方法，可以增强大型语言模型在提示扰动下的一致性、性能和泛化能力。

Abstract: Large Language Models (LLMs) often produce inconsistent answers when faced
with different phrasings of the same prompt. In this paper, we propose
Flip-Flop Consistency ($F^2C$), an unsupervised training method that improves
robustness to such perturbations. $F^2C$ is composed of two key components. The
first, Consensus Cross-Entropy (CCE), uses a majority vote across prompt
variations to create a hard pseudo-label. The second is a representation
alignment loss that pulls lower-confidence and non-majority predictors toward
the consensus established by high-confidence, majority-voting variations. We
evaluate our method on 11 datasets spanning four NLP tasks, with 4-15 prompt
variations per dataset. On average, $F^2C$ raises observed agreement by 11.62%,
improves mean $F_1$ by 8.94%, and reduces performance variance across formats
by 3.29%. In out-of-domain evaluations, $F^2C$ generalizes effectively,
increasing $\overline{F_1}$ and agreement while decreasing variance across most
source-target pairs. Finally, when trained on only a subset of prompt
perturbations and evaluated on held-out formats, $F^2C$ consistently improves
both performance and agreement while reducing variance. These findings
highlight $F^2C$ as an effective unsupervised method for enhancing LLM
consistency, performance, and generalization under prompt perturbations. Code
is available at
https://github.com/ParsaHejabi/Flip-Flop-Consistency-Unsupervised-Training-for-Robustness-to-Prompt-Perturbations-in-LLMs.

</details>


### [63] [MoM: Mixtures of Scenario-Aware Document Memories for Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2510.14252)
*Jihao Zhao,Zhiyuan Ji,Simin Niu,Hanyu Wang,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 该研究通过引入文档记忆提取（document memory extraction）将传统RAG（检索增强生成）范式中的被动分块转变为主动理解，并提出了MoM（Mixtures of scenario-aware document Memories）框架，旨在模拟人类认知过程，提升小型语言模型（SLMs）的知识内化和推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG范式在处理查询时，仅对相关文本块进行理解，这限制了知识内化的深度和推理能力。

Method: MoM框架通过指令大型语言模型（LLMs）模拟领域专家生成文档逻辑大纲，指导结构化分块和核心内容提取。该框架采用多路径采样和多视角评估机制，并设计了衡量块清晰度和提取完整性的综合指标来选择最佳文档记忆。此外，为了在SLMs训练中融入更深层次的类人阅读能力，该研究结合了逆向推理策略。最后，通过MoM生成多样化的内容，开发了一个基于概率建模的理论证明的三层文档记忆检索机制。

Result: MoM框架解决了现有RAG系统中文本分块的挑战，为LLMs提供了语义完整的文档记忆。同时，该框架为SLMs实现了以人为中心的智能文本处理开辟了道路。

Conclusion: MoM框架通过模拟人类认知过程和引入文档记忆提取，显著提升了RAG系统的知识处理能力，并赋予SLMs更强的智能文本处理能力。

Abstract: The traditional RAG paradigm, which typically engages in the comprehension of
relevant text chunks in response to received queries, inherently restricts both
the depth of knowledge internalization and reasoning capabilities. To address
this limitation, our research transforms the text processing in RAG from
passive chunking to proactive understanding, defining this process as document
memory extraction with the objective of simulating human cognitive processes
during reading. Building upon this, we propose the Mixtures of scenario-aware
document Memories (MoM) framework, engineered to efficiently handle documents
from multiple domains and train small language models (SLMs) to acquire the
ability to proactively explore and construct document memories. The MoM
initially instructs large language models (LLMs) to simulate domain experts in
generating document logical outlines, thereby directing structured chunking and
core content extraction. It employs a multi-path sampling and multi-perspective
evaluation mechanism, specifically designing comprehensive metrics that
represent chunk clarity and extraction completeness to select the optimal
document memories. Additionally, to infuse deeper human-like reading abilities
during the training of SLMs, we incorporate a reverse reasoning strategy, which
deduces refined expert thinking paths from high-quality outcomes. Finally,
leveraging diverse forms of content generated by MoM, we develop a three-layer
document memory retrieval mechanism, which is grounded in our theoretical proof
from the perspective of probabilistic modeling. Extensive experimental results
across three distinct domains demonstrate that the MoM framework not only
resolves text chunking challenges in existing RAG systems, providing LLMs with
semantically complete document memories, but also paves the way for SLMs to
achieve human-centric intelligent text processing.

</details>


### [64] [Rewriting History: A Recipe for Interventional Analyses to Study Data Effects on Model Behavior](https://arxiv.org/abs/2510.14261)
*Rahul Nadkarni,Yanai Elazar,Hila Gonen,Noah A. Smith*

Main category: cs.CL

TL;DR: 这篇论文提出了一种实验方法，用于研究训练数据和语言模型（LM）行为之间的关系，通过干预数据批次并重新训练模型检查点来测试数据与行为相关的假设。


<details>
  <summary>Details</summary>
Motivation: 探索训练数据如何影响语言模型的行为，并弥补现有研究在解释LM知识获取能力方面的不足。

Method: 论文提出了一种分阶段的干预方法，包括从基准中选择评估项目、将相关文档与这些项目匹配、修改文档，然后重新训练并测量效果。作者通过案例研究，利用共现统计和信息检索方法来识别有助于知识学习的文档。

Result: 研究结果补充了过去将共现与模型行为联系起来的观察性分析，并表明现有识别相关训练文档的方法并不能完全解释LM正确回答知识问题的能力。

Conclusion: 论文提供了一个研究范式，研究人员可以遵循该范式来进一步检验关于训练数据如何影响模型行为的假设。作者还公开了代码以促进未来的研究。

Abstract: We present an experimental recipe for studying the relationship between
training data and language model (LM) behavior. We outline steps for
intervening on data batches -- i.e., ``rewriting history'' -- and then
retraining model checkpoints over that data to test hypotheses relating data to
behavior. Our recipe breaks down such an intervention into stages that include
selecting evaluation items from a benchmark that measures model behavior,
matching relevant documents to those items, and modifying those documents
before retraining and measuring the effects. We demonstrate the utility of our
recipe through case studies on factual knowledge acquisition in LMs, using both
cooccurrence statistics and information retrieval methods to identify documents
that might contribute to knowledge learning. Our results supplement past
observational analyses that link cooccurrence to model behavior, while
demonstrating that extant methods for identifying relevant training documents
do not fully explain an LM's ability to correctly answer knowledge questions.
Overall, we outline a recipe that researchers can follow to test further
hypotheses about how training data affects model behavior. Our code is made
publicly available to promote future work.

</details>


### [65] [Less is More: Denoising Knowledge Graphs For Retrieval Augmented Generation](https://arxiv.org/abs/2510.14271)
*Yilun Zheng,Dan Yang,Jie Li,Lin Shang,Lihui Chen,Jiahao Xu,Sitao Luan*

Main category: cs.CL

TL;DR: DEG-RAG框架通过实体解析和三元组反射解决LLM生成知识图谱中的噪声问题，显著提高了检索增强生成系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图谱RAG系统依赖LLM自动构建知识图谱，但LLM生成的知识图谱通常包含冗余实体和不可靠关系，导致检索和生成性能下降以及计算成本增加。目前研究缺乏针对LLM生成知识图谱去噪的全面解决方案。

Method: 本文提出了DEG-RAG框架，通过以下两种方法解决噪声问题：1. 实体解析：消除冗余实体。2. 三元组反射：移除错误关系。此外，还对LLM生成的知识图谱的实体解析进行了系统评估，研究了不同的阻塞策略、嵌入选择、相似性度量和实体合并技术。

Result: DEG-RAG框架生成的知识图谱更紧凑、质量更高，显著优于未处理的知识图谱。该方法不仅大幅减小了图谱规模，还在各种流行的图谱RAG变体中持续提升了问答性能。

Conclusion: DEG-RAG框架通过有效地对LLM生成的知识图谱进行去噪，成功解决了现有图谱RAG系统面临的挑战。实体解析的系统评估也为该领域未来的研究提供了宝贵的见解，验证了其在提升图谱RAG性能方面的有效性。

Abstract: Retrieval-Augmented Generation (RAG) systems enable large language models
(LLMs) instant access to relevant information for the generative process,
demonstrating their superior performance in addressing common LLM challenges
such as hallucination, factual inaccuracy, and the knowledge cutoff.
Graph-based RAG further extends this paradigm by incorporating knowledge graphs
(KGs) to leverage rich, structured connections for more precise and inferential
responses. A critical challenge, however, is that most Graph-based RAG systems
rely on LLMs for automated KG construction, often yielding noisy KGs with
redundant entities and unreliable relationships. This noise degrades retrieval
and generation performance while also increasing computational cost. Crucially,
current research does not comprehensively address the denoising problem for
LLM-generated KGs. In this paper, we introduce DEnoised knowledge Graphs for
Retrieval Augmented Generation (DEG-RAG), a framework that addresses these
challenges through: (1) entity resolution, which eliminates redundant entities,
and (2) triple reflection, which removes erroneous relations. Together, these
techniques yield more compact, higher-quality KGs that significantly outperform
their unprocessed counterparts. Beyond the methods, we conduct a systematic
evaluation of entity resolution for LLM-generated KGs, examining different
blocking strategies, embedding choices, similarity metrics, and entity merging
techniques. To the best of our knowledge, this is the first comprehensive
exploration of entity resolution in LLM-generated KGs. Our experiments
demonstrate that this straightforward approach not only drastically reduces
graph size but also consistently improves question answering performance across
diverse popular Graph-based RAG variants.

</details>


### [66] [Retrofitting Small Multilingual Models for Retrieval: Matching 7B Performance with 300M Parameters](https://arxiv.org/abs/2510.14274)
*Lifu Tu,Yingbo Zhou,Semih Yavuz*

Main category: cs.CL

TL;DR: 克服了多语言模型在处理不同语言和任务目标时的挑战，并通过优化训练数据规模、负采样策略和数据多样性，成功开发了一个小型多语言模型，其检索性能可与大型模型媲美。


<details>
  <summary>Details</summary>
Motivation: 尽管小型多语言模型在多语言任务中表现良好，但在最普遍的用例（检索）中，它们始终落后于大型模型。这引出了一个关键问题：能否专门为检索任务改造小型模型以提高其性能？

Method: 我们研究了影响多语言嵌入有效性的关键因素，重点关注训练数据规模、负采样策略和数据多样性。

Result: 增加训练数据规模初期能带来性能提升，但很快就会趋于平稳。加入难负例对于持续提高检索准确性至关重要。训练数据中的任务多样性对性能的贡献远大于语言多样性。

Conclusion: 我们开发了一个紧凑型（约300M）多语言模型，其检索性能与当前强大的7B模型相当甚至超越。

Abstract: Training effective multilingual embedding models presents unique challenges
due to the diversity of languages and task objectives. Although small
multilingual models (<1 B parameters) perform well on multilingual tasks
generally, they consistently lag behind larger models (>1 B) in the most
prevalent use case: retrieval. This raises a critical question: Can smaller
models be retrofitted specifically for retrieval tasks to enhance their
performance? In this work, we investigate key factors that influence the
effectiveness of multilingual embeddings, focusing on training data scale,
negative sampling strategies, and data diversity. We find that while increasing
the scale of training data yields initial performance gains, these improvements
quickly plateau - indicating diminishing returns. Incorporating hard negatives
proves essential for consistently improving retrieval accuracy. Furthermore,
our analysis reveals that task diversity in the training data contributes more
significantly to performance than language diversity alone. As a result, we
develop a compact (approximately 300M) multilingual model that achieves
retrieval performance comparable to or even surpassing current strong 7B
models.

</details>


### [67] [Qwen3Guard Technical Report](https://arxiv.org/abs/2510.14276)
*Haiquan Zhao,Chenhan Yuan,Fei Huang,Xiaomeng Hu,Yichang Zhang,An Yang,Bowen Yu,Dayiheng Liu,Jingren Zhou,Junyang Lin,Baosong Yang,Chen Cheng,Jialong Tang,Jiandong Jiang,Jianwei Zhang,Jijie Xu,Ming Yan,Minmin Sun,Pei Zhang,Pengjun Xie,Qiaoyu Tang,Qin Zhu,Rong Zhang,Shibin Wu,Shuo Zhang,Tao He,Tianyi Tang,Tingyu Xia,Wei Liao,Weizhou Shen,Wenbiao Yin,Wenmeng Zhou,Wenyuan Yu,Xiaobin Wang,Xiaodong Deng,Xiaodong Xu,Xinyu Zhang,Yang Liu,Yeqiu Li,Yi Zhang,Yong Jiang,Yu Wan,Yuxin Zhou*

Main category: cs.CL

TL;DR: Qwen3Guard是由阿里巴巴开发的一种新型安全护栏模型，旨在解决现有护栏模型在适应不同安全策略和流式LLM推理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型(LLMs)输出的安全性变得越来越重要。 现有护栏模型在实际应用中存在两个主要限制：1）它们通常只输出二元的“安全/不安全”标签，这可能导致不同安全策略之间的解释不一致；2）它们需要在执行安全检查之前获得完整的模型输出，这使得它们与流式LLM推理不兼容。

Method: Qwen3Guard有两种专门的变体：生成式Qwen3Guard和流式Qwen3Guard。 生成式Qwen3Guard将安全分类视为指令遵循任务，以实现细粒度的三类判断（安全、有争议、不安全）。 流式Qwen3Guard引入了令牌级别的分类头，用于在增量文本生成期间进行实时安全监控。 两种变体都有三种尺寸（0.6B、4B和8B参数），支持多达119种语言和方言。

Result: Qwen3Guard在英语、中文和多语言基准测试中，在提示和响应安全分类方面均达到最先进的性能。

Conclusion: Qwen3Guard通过提供细粒度的安全判断、支持流式LLM推理以及处理多语言内容，解决了现有安全护栏模型的关键限制，从而为全球LLM部署提供了全面、可扩展和低延迟的安全审核。

Abstract: As large language models (LLMs) become more capable and widely used, ensuring
the safety of their outputs is increasingly critical. Existing guardrail
models, though useful in static evaluation settings, face two major limitations
in real-world applications: (1) they typically output only binary "safe/unsafe"
labels, which can be interpreted inconsistently across diverse safety policies,
rendering them incapable of accommodating varying safety tolerances across
domains; and (2) they require complete model outputs before performing safety
checks, making them fundamentally incompatible with streaming LLM inference,
thereby preventing timely intervention during generation and increasing
exposure to harmful partial outputs. To address these challenges, we present
Qwen3Guard, a series of multilingual safety guardrail models with two
specialized variants: Generative Qwen3Guard, which casts safety classification
as an instruction-following task to enable fine-grained tri-class judgments
(safe, controversial, unsafe); and Stream Qwen3Guard, which introduces a
token-level classification head for real-time safety monitoring during
incremental text generation. Both variants are available in three sizes (0.6B,
4B, and 8B parameters) and support up to 119 languages and dialects, providing
comprehensive, scalable, and low-latency safety moderation for global LLM
deployments. Evaluated across English, Chinese, and multilingual benchmarks,
Qwen3Guard achieves state-of-the-art performance in both prompt and response
safety classification. All models are released under the Apache 2.0 license for
public use.

</details>


### [68] [Rethinking Schema Linking: A Context-Aware Bidirectional Retrieval Approach for Text-to-SQL](https://arxiv.org/abs/2510.14296)
*Md Mahadi Hasan Nahid,Davood Rafiei,Weiwei Zhang,Yong Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种上下文感知的双向Schema检索框架，有效提高了Text-to-SQL系统的Schema召回率和SQL生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL方法主要关注SQL生成，但忽略了相关Schema元素的检索，这可能导致幻觉和执行失败。

Method: 本文提出了一种上下文感知的双向Schema检索框架，将Schema Linking视为独立问题。该方法结合了两种互补的策略：首先是“表优先检索”再进行列选择，其次是“列优先检索”再进行表选择。同时，该框架还通过问题分解、关键词提取和关键短语提取等技术进行了增强。

Result: 在BIRD和Spider等基准测试中，本文方法显著提高了Schema召回率并减少了误报。使用本文方法检索到的Schema生成的SQL，其性能持续优于全Schema基线，并接近预言者性能，且无需进行查询优化。值得注意的是，本文方法将全Schema和完美Schema设置之间的性能差距缩小了50%。

Conclusion: Schema Linking是提高Text-to-SQL系统准确性和效率的强大杠杆。

Abstract: Schema linking -- the process of aligning natural language questions with
database schema elements -- is a critical yet underexplored component of
Text-to-SQL systems. While recent methods have focused primarily on improving
SQL generation, they often neglect the retrieval of relevant schema elements,
which can lead to hallucinations and execution failures. In this work, we
propose a context-aware bidirectional schema retrieval framework that treats
schema linking as a standalone problem. Our approach combines two complementary
strategies: table-first retrieval followed by column selection, and
column-first retrieval followed by table selection. It is further augmented
with techniques such as question decomposition, keyword extraction, and
keyphrase extraction. Through comprehensive evaluations on challenging
benchmarks such as BIRD and Spider, we demonstrate that our method
significantly improves schema recall while reducing false positives. Moreover,
SQL generation using our retrieved schema consistently outperforms full-schema
baselines and closely approaches oracle performance, all without requiring
query refinement. Notably, our method narrows the performance gap between full
and perfect schema settings by 50\%. Our findings highlight schema linking as a
powerful lever for enhancing Text-to-SQL accuracy and efficiency.

</details>


### [69] [MathMist: A Parallel Multilingual Benchmark Dataset for Mathematical Problem Solving and Reasoning](https://arxiv.org/abs/2510.14305)
*Mahbub E Sobhani,Md. Faiyaz Abdullah Sayeedi,Tasnim Mohiuddin,Md Mofijul Islam,Swakkhar Shatabda*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为 MathMist 的多语言数学推理基准测试，旨在评估大型语言模型在不同语言环境中解决数学问题的能力。研究发现，LLMs 在跨语言数学推理方面存在不足，尤其是在低资源语言环境下表现更差。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在通用推理方面表现出色，但它们在多语言数学推理方面的能力尚未得到充分探索。目前的基准测试主要集中在英语或少数高资源语言，无法全面评估LLMs的跨语言数学推理能力。

Method: 本文引入了一个名为 MathMist 的并行多语言数学问题解决和推理基准测试。该数据集包含超过2.1万个对齐的问答对，涵盖七种语言，平衡了高、中、低资源语言环境。研究人员系统地评估了包括开源LLMs、专有系统和多语言推理模型在内的多种模型，采用了零样本、思维链（CoT）和代码转换推理范式。

Result: 评估结果表明，LLMs 在跨语言执行一致且可解释的数学推理方面存在持续性缺陷，尤其是在低资源环境下表现出明显的性能下降。

Conclusion: LLMs在多语言数学推理方面仍有显著不足，特别是在低资源语言环境中。未来的研究应关注提高LLMs在多样化语言环境下进行稳健数学推理的能力。

Abstract: Mathematical reasoning remains one of the most challenging domains for large
language models (LLMs), requiring not only linguistic understanding but also
structured logical deduction and numerical precision. While recent LLMs
demonstrate strong general-purpose reasoning abilities, their mathematical
competence across diverse languages remains underexplored. Existing benchmarks
primarily focus on English or a narrow subset of high-resource languages,
leaving significant gaps in assessing multilingual and cross-lingual
mathematical reasoning. To address this, we introduce MathMist, a parallel
multilingual benchmark for mathematical problem solving and reasoning. MathMist
encompasses over 21K aligned question-answer pairs across seven languages,
representing a balanced coverage of high-, medium-, and low-resource linguistic
settings. The dataset captures linguistic variety, multiple types of problem
settings, and solution synthesizing capabilities. We systematically evaluate a
diverse suite of models, including open-source small and medium LLMs,
proprietary systems, and multilingual-reasoning-focused models, under
zero-shot, chain-of-thought (CoT), and code-switched reasoning paradigms. Our
results reveal persistent deficiencies in LLMs' ability to perform consistent
and interpretable mathematical reasoning across languages, with pronounced
degradation in low-resource settings. All the codes and data are available at
GitHub: https://github.com/mahbubhimel/MathMist

</details>


### [70] [MERLIN: A Testbed for Multilingual Multimodal Entity Recognition and Linking](https://arxiv.org/abs/2510.14307)
*Sathyanarayanan Ramamoorthy,Vishwa Shah,Simran Khanuja,Zaid Sheikh,Shan Jie,Ann Chia,Shearman Chua,Graham Neubig*

Main category: cs.CL

TL;DR: 这篇论文介绍了 MERLIN，一个用于多语言多模态实体链接任务的新型测试平台系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决多语言多模态实体链接的挑战，特别是在文本上下文不明确或不足的情况下。

Method: MERLIN数据集包含了BBC新闻文章标题及其对应的图片，涵盖五种语言（印地语、日语、印尼语、越南语和泰米尔语），包含超过7000个命名实体提及，链接到2500个独特的Wikidata实体。论文还使用多语言和多模态实体链接方法，探索了不同的语言模型（如LLaMa-2和Aya-23），并提供了基准测试。

Result: 研究结果表明，融合视觉数据可以提高实体链接的准确性，尤其是在文本上下文模糊或不足的实体，以及对于多语言能力不强的模型。

Conclusion: MERLIN测试平台的创建和实验结果证明了视觉数据在提高多语言多模态实体链接准确性方面的有效性，尤其对那些文本信息不足的场景和多语言能力较弱的模型有显著帮助。

Abstract: This paper introduces MERLIN, a novel testbed system for the task of
Multilingual Multimodal Entity Linking. The created dataset includes BBC news
article titles, paired with corresponding images, in five languages: Hindi,
Japanese, Indonesian, Vietnamese, and Tamil, featuring over 7,000 named entity
mentions linked to 2,500 unique Wikidata entities. We also include several
benchmarks using multilingual and multimodal entity linking methods exploring
different language models like LLaMa-2 and Aya-23. Our findings indicate that
incorporating visual data improves the accuracy of entity linking, especially
for entities where the textual context is ambiguous or insufficient, and
particularly for models that do not have strong multilingual abilities. For the
work, the dataset, methods are available here at
https://github.com/rsathya4802/merlin

</details>


### [71] [Evaluating & Reducing Deceptive Dialogue From Language Models with Multi-turn RL](https://arxiv.org/abs/2510.14318)
*Marwa Abdulhai,Ryan Cheng,Aryansh Shrivastava,Natasha Jaques,Yarin Gal,Sergey Levine*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在对话中产生欺骗性输出的能力，提出了一种新的欺骗量化指标，并发现LLMs在约26%的对话轮次中表现出欺骗行为。此外，本文还提出了一种多轮强化学习方法，可将欺骗行为减少77.6%。


<details>
  <summary>Details</summary>
Motivation: LLMs在各种应用中与数百万人交互，但其产生欺骗性输出的能力带来了严重的安全问题。LLM行为的不可预测性以及针对幻觉、错误信息和用户操纵的保障措施不足，使得其滥用成为一个严重的现实风险。

Method: 本文调查了LLMs在对话中进行欺骗的程度，并提出了信念错位指标来量化欺骗。研究人员在四种不同的对话场景中，使用五种既定的欺骗检测指标和新提出的指标评估了欺骗行为。此外，本文还引入了一种多轮强化学习方法来微调LLMs，以减少欺骗行为。

Result: 研究发现，新提出的欺骗度量与人类判断的相关性高于现有指标。对八个最先进模型的基准测试表明，即使在看似良性的目标提示下，LLMs在约26%的对话轮次中也表现出欺骗行为。当被提示进行欺骗时，LLMs的欺骗性可以增加31%。接受RLHF训练的模型平均仍表现出43%的欺骗性。多轮强化学习方法可将欺骗行为减少77.6%。

Conclusion: LLMs自然且普遍地表现出欺骗行为，即使是经过RLHF训练的模型也无法幸免。传统单轮分析无法有效评估和缓解欺骗行为。本文提出的多轮强化学习方法能显著减少LLM的欺骗行为，为未来LLM的安全性研究提供了新的方向。

Abstract: Large Language Models (LLMs) interact with millions of people worldwide in
applications such as customer support, education and healthcare. However, their
ability to produce deceptive outputs, whether intentionally or inadvertently,
poses significant safety concerns. The unpredictable nature of LLM behavior,
combined with insufficient safeguards against hallucination, misinformation,
and user manipulation, makes their misuse a serious, real-world risk. In this
paper, we investigate the extent to which LLMs engage in deception within
dialogue, and propose the belief misalignment metric to quantify deception. We
evaluate deception across four distinct dialogue scenarios, using five
established deception detection metrics and our proposed metric. Our findings
reveal this novel deception measure correlates more closely with human
judgments than any existing metrics we test. Additionally, our benchmarking of
eight state-of-the-art models indicates that LLMs naturally exhibit deceptive
behavior in approximately 26% of dialogue turns, even when prompted with
seemingly benign objectives. When prompted to deceive, LLMs are capable of
increasing deceptiveness by as much as 31% relative to baselines. Unexpectedly,
models trained with RLHF, the predominant approach for ensuring the safety of
widely-deployed LLMs, still exhibit deception at a rate of 43% on average.
Given that deception in dialogue is a behavior that develops over an
interaction history, its effective evaluation and mitigation necessitates
moving beyond single-utterance analyses. We introduce a multi-turn
reinforcement learning methodology to fine-tune LLMs to reduce deceptive
behaviors, leading to a 77.6% reduction compared to other instruction-tuned
models.

</details>


### [72] [A Robust Classification Method using Hybrid Word Embedding for Early Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2510.14332)
*Yangyang Li*

Main category: cs.CL

TL;DR: 该研究开发了一种使用混合词嵌入和微调超参数的鲁棒分类方法，用于早期阿尔茨海默病（AD）检测，实现了最先进的准确性，达到了91%的分类准确率和97%的AUC。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期检测对患者有益，可以及早治疗以减轻症状并缓解医疗保健的经济负担。语言能力变化是AD的主要早期迹象之一，可用于AD的早期诊断。

Method: 该方法创建了基于Doc2Vec和ELMo词向量的混合词嵌入，以获得句子的困惑度分数，从而识别句子是否流畅并捕捉语义 G。通过添加语言特征来丰富词嵌入，以分析句法和语义。将嵌入的特征向量输入到逻辑回归中，并在整个流程中微调超参数（例如，模型正则化参数、学习率、Doc2Vec和ELMo的向量大小）。

Result: 在区分早期AD和健康受试者方面，该模型实现了91%的分类准确率和97%的曲线下面积（AUC）。该模型的性能优于现有最好的AD诊断NLP模型（准确率为88%）。通过重复实验研究模型稳定性，发现模型即使在随机分割训练数据的情况下也表现稳定（准确率标准差=0.0403；AUC标准差=0.0174）。

Conclusion: 该研究提出的方法是准确且稳定的，可作为AD的大规模筛查方法，也可作为医生检测AD的补充检查。

Abstract: Early detection of Alzheimer's Disease (AD) is greatly beneficial to AD
patients, leading to early treatments that lessen symptoms and alleviating
financial burden of health care. As one of the leading signs of AD, language
capability changes can be used for early diagnosis of AD. In this paper, I
develop a robust classification method using hybrid word embedding and
fine-tuned hyperparameters to achieve state-of-the-art accuracy in the early
detection of AD. Specifically, we create a hybrid word embedding based on word
vectors from Doc2Vec and ELMo to obtain perplexity scores of the sentences. The
scores identify whether a sentence is fluent or not and capture semantic
context of the sentences. I enrich the word embedding by adding linguistic
features to analyze syntax and semantics. Further, we input an embedded feature
vector into logistic regression and fine tune hyperparameters throughout the
pipeline. By tuning hyperparameters of the machine learning pipeline (e.g.,
model regularization parameter, learning rate and vector size of Doc2Vec, and
vector size of ELMo), I achieve 91% classification accuracy and an Area Under
the Curve (AUC) of 97% in distinguishing early AD from healthy subjects. Based
on my knowledge, my model with 91% accuracy and 97% AUC outperforms the best
existing NLP model for AD diagnosis with an accuracy of 88% [32]. I study the
model stability through repeated experiments and find that the model is stable
even though the training data is split randomly (standard deviation of accuracy
= 0.0403; standard deviation of AUC = 0.0174). This affirms our proposed method
is accurate and stable. This model can be used as a large-scale screening
method for AD, as well as a complementary examination for doctors to detect AD.

</details>


### [73] [Beyond One World: Benchmarking Super Heros in Role-Playing Across Multiversal Contexts](https://arxiv.org/abs/2510.14351)
*Perapard Ngokpol,Kun Kerdthaisong,Pasin Buakhaw,Pitikorn Khlaisamniang,Supasate Vorathammathorn,Piyalitt Ittichaiwong,Nutchanon Yongsatianchot*

Main category: cs.CL

TL;DR: 本文介绍了Beyond One World基准，用于评估大型语言模型在扮演不同版本角色时的忠实性和一致性，特别是在超级英雄领域。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在角色扮演中能力日益增强，但其忠实且一致地扮演特定版本角色的能力尚未得到充分探索。本文旨在通过分析超级英雄多版本角色扮演来填补这一空白。

Method: 本文提出了Beyond One World基准，包含30个标志性英雄和90个特定版本。该基准包括两个任务：角色生平事件（Canon Events）和道德困境（Moral Dilemmas）。本文还提出了一种 Think-Act Matching 度量，用于量化推理与行动之间的一致性。

Result: 研究结果表明，思维链提示可以改善弱模型的叙事连贯性，但会降低强模型的规范准确性；模型难以在同一角色的不同版本之间进行泛化；模型通常擅长思考或行动，但很少能两者兼顾。

Conclusion: Beyond One World 基准揭示了大型语言模型在多版本一致性和推理对齐方面的关键差距，为角色扮演语言模型提供了一个 F全面的评估。

Abstract: Large language models (LLMs) are increasingly used as role-playing agents,
yet their capacity to faithfully and consistently portray version-specific
characters -- for example, superheroes across comic and cinematic universes --
remains underexplored. Superhero canons such as Marvel and DC provide a rich
testbed: decades of storytelling yield multiple incarnations of the same
character with distinct histories, values, and moral codes. To study this
problem, we introduce Beyond One World, a benchmark for character-grounded
roleplay spanning 30 iconic heroes and 90 canon-specific versions. The
benchmark comprises two tasks: (i) Canon Events, which probes factual recall of
pivotal life stages, and (ii) Moral Dilemmas, which confronts models with
ethically charged scenarios. We score responses for canonical accuracy and
reasoning fidelity under a framework that separates internal deliberation
("thinking") from outward decisions ("acting"). We further propose Think-Act
Matching, a metric that quantifies alignment between reasons and actions and
serves as a proxy for model trustworthiness. Experiments across reasoning- and
non-reasoning-oriented models yield three findings: (1) chain-of-thought
prompting improves narrative coherence in weaker models but can reduce
canonical accuracy in stronger ones; (2) cross-version generalization within a
character remains a major obstacle; and (3) models often excel at either
thinking or acting, but rarely both. Beyond One World exposes critical gaps in
multiversal consistency and reasoning alignment, offering a challenging
evaluation for role-playing LLMs.

</details>


### [74] [CURE: Confidence-driven Unified Reasoning Ensemble Framework for Medical Question Answering](https://arxiv.org/abs/2510.14353)
*Ziad Elshaer,Essam A. Rashed*

Main category: cs.CL

TL;DR: 该研究提出了一种置信度驱动的多模型框架，无需微调即可增强医学问答性能，尤其在PubMedQA和MedMCQA上表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决高性能医学大型语言模型需要大量计算资源和微调的问题，以提高资源受限医疗机构的可及性。

Method: 该框架采用两阶段架构：置信度检测模块评估主模型的确定性，自适应路由机制将低置信度查询发送给具有补充知识的辅助模型进行协作推理。评估使用了Qwen3-30B-A3B-Instruct、Phi-4 14B和Gemma 2 12B在MedQA、MedMCQA和PubMedQA三个医学基准上。

Result: 该框架取得了有竞争力的性能，在PubMedQA上达到95.0％，在MedMCQA上达到78.0％。消融研究证实，置信度感知路由与多模型协作显著优于单模型方法和统一推理策略。

Conclusion: 战略性模型协作提供了一种实用且计算高效的途径来改进医疗AI系统，对在资源有限的环境中普及先进医疗AI具有重要意义。

Abstract: High-performing medical Large Language Models (LLMs) typically require
extensive fine-tuning with substantial computational resources, limiting
accessibility for resource-constrained healthcare institutions. This study
introduces a confidence-driven multi-model framework that leverages model
diversity to enhance medical question answering without fine-tuning. Our
framework employs a two-stage architecture: a confidence detection module
assesses the primary model's certainty, and an adaptive routing mechanism
directs low-confidence queries to Helper models with complementary knowledge
for collaborative reasoning. We evaluate our approach using
Qwen3-30B-A3B-Instruct, Phi-4 14B, and Gemma 2 12B across three medical
benchmarks; MedQA, MedMCQA, and PubMedQA. Result demonstrate that our framework
achieves competitive performance, with particularly strong results in PubMedQA
(95.0\%) and MedMCQA (78.0\%). Ablation studies confirm that confidence-aware
routing combined with multi-model collaboration substantially outperforms
single-model approaches and uniform reasoning strategies. This work establishes
that strategic model collaboration offers a practical, computationally
efficient pathway to improve medical AI systems, with significant implications
for democratizing access to advanced medical AI in resource-limited settings.

</details>


### [75] [On the Ability of LLMs to Handle Character-Level Perturbations: How Well and How?](https://arxiv.org/abs/2510.14365)
*Anyun Zhuo,Xuefei Ning,Ningyuan Li,Yu Wang,Pinyan Lu*

Main category: cs.CL

TL;DR: 这篇论文研究了大型语言模型（LLMs）对字符级别扰动的鲁棒性，特别是通过在每个输入字符后插入不可见的Unicode控制字符。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs对频繁、结构化的字符级别扰动的抵抗能力，并探讨LLMs在面临这些扰动时仍能保持显著性能的原因。

Method: 引入了\nameshort{}方法，该方法通过在文本中插入不可见的Unicode控制字符来阻止LLM在在线考试系统等场景中被滥用。该方法专门在每个输入字符后插入噪声字符。

Result: 尽管插入的噪声字符严重干扰了分词并显著降低了信噪比，但许多LLMs仍然保持了显著的性能。

Conclusion: LLMs在低级别上的鲁棒性揭示了其被滥用的风险以及在不同应用中部署LLMs的可靠性问题。作者希望他们的发现能为LLMs的滥用风险以及在各种应用中部署LLMs的可靠性提供启示。

Abstract: This work investigates the resilience of contemporary LLMs against frequent
and structured character-level perturbations, specifically through the
insertion of noisy characters after each input character. We introduce
\nameshort{}, a practical method that inserts invisible Unicode control
characters into text to discourage LLM misuse in scenarios such as online exam
systems. Surprisingly, despite strong obfuscation that fragments tokenization
and reduces the signal-to-noise ratio significantly, many LLMs still maintain
notable performance. Through comprehensive evaluation across model-, problem-,
and noise-related configurations, we examine the extent and mechanisms of this
robustness, exploring both the handling of character-level tokenization and
\textit{implicit} versus \textit{explicit} denoising mechanism hypotheses of
character-level noises. We hope our findings on the low-level robustness of
LLMs will shed light on the risks of their misuse and on the reliability of
deploying LLMs across diverse applications.

</details>


### [76] [From Binary to Bilingual: How the National Weather Service is Using Artificial Intelligence to Develop a Comprehensive Translation Program](https://arxiv.org/abs/2510.14369)
*Joseph E. Trujillo-Falcon,Monica L. Bozeman,Liam E. Llewellyn,Samuel T. Halvorson,Meryl Mizell,Stuti Deshpande,Bob Manning,Todd Fagin*

Main category: cs.CL

TL;DR: 美国国家气象局（NWS）正在开发一个由人工智能驱动的自动翻译工具，旨在为美国6880万非英语家庭人口提供气象产品，以“建设一个做好气象准备的国家”。


<details>
  <summary>Details</summary>
Motivation: 解决美国6880万非英语家庭人口在获取国家气象局气象产品时面临的语言障碍，提升气象预警信息的覆盖面和可及性。

Method: 国家气象局与LILT公司合作，利用其专利训练流程，使大型语言模型（LLMs）能够适应天气术语和信息，从而开发神经机器翻译（NMT）工具。该系统旨在跨气象预报办公室（WFOs）和国家中心进行扩展。

Result: 开发了一个支持西班牙语、简体中文、越南语及其他常用非英语语言的气象产品自动翻译系统。该系统提供准确、及时和文化相关的翻译，显著减少了人工翻译时间，减轻了操作工作量。通过GIS地图识别了不同NWS区域的语言需求，并集成了道德AI实践，确保透明度、公平性和人工监督。

Conclusion: 该项目成功开发了一个实验性的多语言NWS产品网站，包含翻译的预警、7天预报和教育宣传，使美国向一个能够覆盖所有美国人的国家预警系统迈进了一步。这一成果有助于提升多语言风险沟通的最佳实践。

Abstract: To advance a Weather-Ready Nation, the National Weather Service (NWS) is
developing a systematic translation program to better serve the 68.8 million
people in the U.S. who do not speak English at home. This article outlines the
foundation of an automated translation tool for NWS products, powered by
artificial intelligence. The NWS has partnered with LILT, whose patented
training process enables large language models (LLMs) to adapt neural machine
translation (NMT) tools for weather terminology and messaging. Designed for
scalability across Weather Forecast Offices (WFOs) and National Centers, the
system is currently being developed in Spanish, Simplified Chinese, Vietnamese,
and other widely spoken non-English languages. Rooted in best practices for
multilingual risk communication, the system provides accurate, timely, and
culturally relevant translations, significantly reducing manual translation
time and easing operational workloads across the NWS. To guide the distribution
of these products, GIS mapping was used to identify language needs across
different NWS regions, helping prioritize resources for the communities that
need them most. We also integrated ethical AI practices throughout the
program's design, ensuring that transparency, fairness, and human oversight
guide how automated translations are created, evaluated, and shared with the
public. This work has culminated into a website featuring experimental
multilingual NWS products, including translated warnings, 7-day forecasts, and
educational campaigns, bringing the country one step closer to a national
warning system that reaches all Americans.

</details>


### [77] [PluriHop: Exhaustive, Recall-Sensitive QA over Distractor-Rich Corpora](https://arxiv.org/abs/2510.14377)
*Mykolas Sveistrys,Richard Kunert*

Main category: cs.CL

TL;DR: 本文介绍了PluriHopWIND数据集和PluriHopRAG框架，旨在解决大型语言模型在处理具有重复性、干扰性强的文档集合中的多跳问题时面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和RAG在单跳和多跳问答中取得了进展，但对于需要聚合所有文档的“多跳问题”（pluri-hop questions），现有方法存在召回敏感性、穷尽性和精确性等挑战，尤其是在处理重复性报告数据时。

Method: 本文提出了PluriHopWIND数据集，一个包含48个多跳问题的诊断性多语言数据集，这些问题来源于191份真实的风能行业报告。研究人员测试了传统的RAG管线以及基于图和多模态的变体。在此基础上，提出了PluriHopRAG架构，该架构通过将查询分解为文档级子问题，并使用交叉编码器过滤器在LLM推理之前筛选掉不相关的文档。

Result: 传统RAG管线、基于图和多模态的变体在PluriHopWIND数据集上的F1分数均未超过40%。PluriHopRAG架构在F1分数上取得了18-52%的相对提升，这取决于所使用的基础LLM。PluriHopWIND数据集揭示了当前问答系统在处理重复性强、干扰文档多的语料库时的局限性。

Conclusion: PluriHopRAG的成功表明，在处理“多跳问题”时，穷尽性检索和早期过滤是一种强大的替代方案，优于传统的top-k方法。未来研究应侧重于如何进一步提高在重复性、干扰性强的语料库上问答系统的性能。

Abstract: Recent advances in large language models (LLMs) and retrieval-augmented
generation (RAG) have enabled progress on question answering (QA) when relevant
evidence is in one (single-hop) or multiple (multi-hop) passages. Yet many
realistic questions about recurring report data - medical records, compliance
filings, maintenance logs - require aggregation across all documents, with no
clear stopping point for retrieval and high sensitivity to even one missed
passage. We term these pluri-hop questions and formalize them by three
criteria: recall sensitivity, exhaustiveness, and exactness. To study this
setting, we introduce PluriHopWIND, a diagnostic multilingual dataset of 48
pluri-hop questions built from 191 real-world wind industry reports in German
and English. We show that PluriHopWIND is 8-40% more repetitive than other
common datasets and thus has higher density of distractor documents, better
reflecting practical challenges of recurring report corpora. We test a
traditional RAG pipeline as well as graph-based and multimodal variants, and
find that none of the tested approaches exceed 40% in statement-wise F1 score.
Motivated by this, we propose PluriHopRAG, a RAG architecture that follows a
"check all documents individually, filter cheaply" approach: it (i) decomposes
queries into document-level subquestions and (ii) uses a cross-encoder filter
to discard irrelevant documents before costly LLM reasoning. We find that
PluriHopRAG achieves relative F1 score improvements of 18-52% depending on base
LLM. Despite its modest size, PluriHopWIND exposes the limitations of current
QA systems on repetitive, distractor-rich corpora. PluriHopRAG's performance
highlights the value of exhaustive retrieval and early filtering as a powerful
alternative to top-k methods.

</details>


### [78] [Suicidal Comment Tree Dataset: Enhancing Risk Assessment and Prediction Through Contextual Analysis](https://arxiv.org/abs/2510.14395)
*Jun Li,Qun Zhao*

Main category: cs.CL

TL;DR: 这篇论文研究了如何利用社交媒体（Reddit）上的评论树数据来预测用户的自杀风险。


<details>
  <summary>Details</summary>
Motivation: 以往的研究较少关注用户自杀风险预测在纵向、连续评论树方面的分析，而用户通常通过历史帖子和互动评论来表达他们的意图，所以本研究旨在解决这个空白。

Method: 本研究构建了一个高质量的标注数据集，该数据集来源于Reddit，包含用户的发帖历史和评论。该数据集使用基于哥伦比亚自杀严重程度评定量表（C-SSRS）的四标签标注框架。作者对数据集进行了统计分析，并进行了大型语言模型（LLMs）实验。

Result: 研究结果表明，结合评论树数据可以显著提高用户自杀风险水平的辨别和预测能力。

Conclusion: 本研究为提高高危个体的检测准确性提供了新的见解，从而为早期自杀干预策略提供了宝贵的基础。

Abstract: Suicide remains a critical global public health issue. While previous studies
have provided valuable insights into detecting suicidal expressions in
individual social media posts, limited attention has been paid to the analysis
of longitudinal, sequential comment trees for predicting a user's evolving
suicidal risk. Users, however, often reveal their intentions through historical
posts and interactive comments over time. This study addresses this gap by
investigating how the information in comment trees affects both the
discrimination and prediction of users' suicidal risk levels. We constructed a
high-quality annotated dataset, sourced from Reddit, which incorporates users'
posting history and comments, using a refined four-label annotation framework
based on the Columbia Suicide Severity Rating Scale (C-SSRS). Statistical
analysis of the dataset, along with experimental results from Large Language
Models (LLMs) experiments, demonstrates that incorporating comment trees data
significantly enhances the discrimination and prediction of user suicidal risk
levels. This research offers a novel insight to enhancing the detection
accuracy of at-risk individuals, thereby providing a valuable foundation for
early suicide intervention strategies.

</details>


### [79] [Instructions are all you need: Self-supervised Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2510.14420)
*Qingyu Ren,Qianyu He,Bowei Zhang,Jie Zeng,Jiaqing Liang,Yanghua Xiao,Weikang Zhou,Zeye Sun,Fei Yu*

Main category: cs.CL

TL;DR: 本文提出了一种无需标签的自监督强化学习框架，旨在解决语言模型在遵循多约束指令时面临的挑战，并通过实验证明了其在多个数据集上的有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 语言模型在遵循多约束指令时表现不佳，而现有强化学习方法又受限于对外部监督的依赖以及多约束任务中稀疏的奖励信号。

Method: 本文提出了一种无需标签的自监督强化学习框架，通过直接从指令中获取奖励信号并生成伪标签用于奖励模型训练，从而摆脱了对外部监督的依赖。该方法引入了约束分解策略和高效的约束分类方法，以解决奖励稀疏性问题，同时保持计算效率。

Result: 实验结果表明，该方法泛化性良好，在3个域内数据集和5个域外数据集上取得了显著改进，其中包括对智能体和多轮指令遵循等挑战性任务的提升。

Conclusion: 本文提出的无需标签的自监督强化学习框架有效地解决了语言模型在遵循多约束指令时遇到的问题，通过创新的奖励机制和约束处理策略，显著提升了模型的性能和泛化能力。

Abstract: Language models often struggle to follow multi-constraint instructions that
are crucial for real-world applications. Existing reinforcement learning (RL)
approaches suffer from dependency on external supervision and sparse reward
signals from multi-constraint tasks. We propose a label-free self-supervised RL
framework that eliminates dependency on external supervision by deriving reward
signals directly from instructions and generating pseudo-labels for reward
model training. Our approach introduces constraint decomposition strategies and
efficient constraint-wise binary classification to address sparse reward
challenges while maintaining computational efficiency. Experiments show that
our approach generalizes well, achieving strong improvements across 3 in-domain
and 5 out-of-domain datasets, including challenging agentic and multi-turn
instruction following. The data and code are publicly available at
https://github.com/Rainier-rq/verl-if

</details>


### [80] [LiRA: Linguistic Robust Anchoring for Cross-lingual Large Language Models](https://arxiv.org/abs/2510.14466)
*Haolin Li,Haipeng Zhang,Mang Li,Yaohua Wang,Lijie Wen,Yu Zhang,Biqing Huang*

Main category: cs.CL

TL;DR: LiRA是针对LLMs的跨语言训练框架，用于提高低资源语言的性能，由Arca和LaSR两个模块组成，并在多语言检索数据集中展现出一致的性能提升和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLMs在低资源语言上的表现不佳，原因在于训练数据有限、机器翻译噪声大以及跨语言对齐不稳定。

Method: LiRA框架包含两个模块：1. Arca：通过基于锚点的对齐和多智能体协作编码，将低资源语言锚定到英语语义空间，以保持共享嵌入空间的几何稳定性。2. LaSR：在Arca的多语言表示之上添加了一个语言感知的轻量级推理头，并通过一致性正则化统一训练目标，以增强跨语言理解、检索和推理的鲁棒性。此外，还构建并发布了一个多语言产品检索数据集。

Result: 在低资源基准测试（跨语言检索、语义相似性和推理）中，LiRA在少样本和噪声放大设置下显示出一致的性能提升和鲁棒性。

Conclusion: LiRA框架通过其Arca和LaSR模块，有效解决了大型语言模型在低资源语言上的性能差距问题，显著提升了模型的跨语言理解、检索和推理能力。

Abstract: As large language models (LLMs) rapidly advance, performance on high-resource
languages (e.g., English, Chinese) is nearing saturation, yet remains
substantially lower for low-resource languages (e.g., Urdu, Thai) due to
limited training data, machine-translation noise, and unstable cross-lingual
alignment. We introduce LiRA (Linguistic Robust Anchoring for Large Language
Models), a training framework that robustly improves cross-lingual
representations under low-resource conditions while jointly strengthening
retrieval and reasoning. LiRA comprises two modules: (i) Arca (Anchored
Representation Composition Architecture), which anchors low-resource languages
to an English semantic space via anchor-based alignment and multi-agent
collaborative encoding, preserving geometric stability in a shared embedding
space; and (ii) LaSR (Language-coupled Semantic Reasoner), which adds a
language-aware lightweight reasoning head with consistency regularization on
top of Arca's multilingual representations, unifying the training objective to
enhance cross-lingual understanding, retrieval, and reasoning robustness. We
further construct and release a multilingual product retrieval dataset covering
five Southeast Asian and two South Asian languages. Experiments across
low-resource benchmarks (cross-lingual retrieval, semantic similarity, and
reasoning) show consistent gains and robustness under few-shot and
noise-amplified settings; ablations validate the contribution of both Arca and
LaSR. Code will be released on GitHub and the dataset on Hugging Face.

</details>


### [81] [Efficient Seq2seq Coreference Resolution Using Entity Representations](https://arxiv.org/abs/2510.14504)
*Matt Grenander,Shay B. Cohen,Mark Steedman*

Main category: cs.CL

TL;DR: 这篇论文提出了一种压缩表示方法，以提高Seq2seq共指消解模型在增量设置中的效率，并在OntoNotes和LitBank数据集上取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的Seq2seq共指消解模型在增量设置（如对话）中效率低下，无法有效处理顺序输入的文本。

Method: 本文提出了一种压缩表示方法，通过提取和重新组织实体级tokens，并丢弃大部分其他输入tokens，从而在不牺牲过多性能的情况下提高模型效率。

Result: 在OntoNotes数据集上，最佳模型在压缩比达到1.8的情况下，其CoNLL F1得分仅比完整的增量基线低0.6。在LitBank数据集上，该方法甚至超越了当前的最佳性能。

Conclusion: 丢弃Seq2seq解析器中的大部分tokens对于增量共指消解来说是一种可行的策略。

Abstract: Seq2seq coreference models have introduced a new paradigm for coreference
resolution by learning to generate text corresponding to coreference labels,
without requiring task-specific parameters. While these models achieve new
state-of-the-art performance, they do so at the cost of flexibility and
efficiency. In particular, they do not efficiently handle incremental settings
such as dialogue, where text must processed sequentially. We propose a
compressed representation in order to improve the efficiency of these methods
in incremental settings. Our method works by extracting and re-organizing
entity-level tokens, and discarding the majority of other input tokens. On
OntoNotes, our best model achieves just 0.6 CoNLL F1 points below a
full-prefix, incremental baseline while achieving a compression ratio of 1.8.
On LitBank, where singleton mentions are annotated, it passes state-of-the-art
performance. Our results indicate that discarding a wide portion of tokens in
seq2seq resolvers is a feasible strategy for incremental coreference
resolution.

</details>


### [82] [Beyond Correctness: Evaluating Subjective Writing Preferences Across Cultures](https://arxiv.org/abs/2510.14616)
*Shuangshuang Ying,Yunwen Li,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Xeron Du,Tianyu Zheng,Yichi Zhang,Letian Ni,Yuyang Cheng,Qiguang Chen,Jingzhe Ding,Shengda Long,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Ge Zhang,Wenhao Huang,Wanxiang Che,Chenghua Lin*

Main category: cs.CL

TL;DR: 当前的偏好学习方法在标准基准上表现出高准确性，但在排除客观质量信号后，性能显著下降。我们引入了WritingPreferenceBench，这是一个包含1,800个人工标注的偏好对的数据集，涵盖8种创意写作类型，其中响应在客观正确性、事实准确性和长度方面进行匹配。


<details>
  <summary>Details</summary>
Motivation: 当前的偏好学习方法在排除客观质量信号后性能显著下降，这表明它们可能主要学习检测客观错误，而非捕捉主观质量偏好。

Method: 引入了一个名为WritingPreferenceBench的数据集，该数据集包含1,800个人工标注的偏好对（1,200个英文，600个中文），涵盖8种创意写作类型。数据集中的响应在客观正确性、事实准确性及长度方面进行了匹配，移除了客观质量信号。

Result: 在WritingPreferenceBench基准上，基于序列的奖励模型（RLHF的标准架构）平均准确率仅为52.7%，而零样本语言模型判断器的表现为53.9%。相比之下，能够生成明确推理链的生成式奖励模型达到了81.8%的准确率。模型在不同写作类型中表现出很高的内部方差，单个模型在不同写作类别间的准确率从18.2%到81.8%不等，标准差平均为10.1%。

Conclusion: 当前RLHF方法主要学习检测客观错误，而非捕捉主观质量偏好（如创造力、文体风格和情感共鸣）。成功的偏好建模可能需要中间推理表示，而非直接分类。

Abstract: Current preference learning methods achieve high accuracy on standard
benchmarks but exhibit significant performance degradation when objective
quality signals are removed. We introduce WritingPreferenceBench, a dataset of
1,800 human-annotated preference pairs (1,200 English, 600 Chinese) across 8
creative writing genres, where responses are matched for objective correctness,
factual accuracy, and length. On this benchmark, sequence-based reward
models--the standard architecture for RLHF--achieve only 52.7% mean accuracy,
while zero-shot language model judges perform at 53.9%. In contrast, generative
reward models that produce explicit reasoning chains achieve 81.8% accuracy. We
observe high within-model variance across genres: individual models range from
18.2% to 81.8% accuracy across different writing categories, with standard
deviations averaging 10.1%. This variance persists regardless of model scale,
with 27B parameter models showing no consistent improvement over 8B variants.
Our results suggest that current RLHF methods primarily learn to detect
objective errors rather than capture subjective quality preferences (e.g.,
creativity, stylistic flair, and emotional resonance), and that successful
preference modeling may require intermediate reasoning representations rather
than direct classification.

</details>


### [83] [Code-driven Number Sequence Calculation: Enhancing the inductive Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2510.14620)
*Kedi Chen,Zhikai Lei,Xu Guo,Xuecheng Wu,Siyuan Zeng,Jianghao Yin,Yinqi Zhang,Qin Chen,Jie Zhou,Liang He,Qipeng Guo,Kai Chen,Wei Zhang*

Main category: cs.CL

TL;DR: CodeSeq是一个基于数字序列的综合后训练数据集，可以提高LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前对归纳推理的研究面临挑战，现有归纳数据主要关注肤浅的规律，缺乏复杂的内部模式。当前的工作只是提示LLM或在简单的提示-响应对上进行微调，但没有提供精确的思维过程，也没有实现难度控制。

Method: 我们引入CodeSeq，一个从数字序列构建的合成后训练数据集。我们将数字序列打包成算法问题，以发现它们的通项，并相应地定义了一个通项生成（GTG）任务。我们的管道通过反思失败的测试用例并结合迭代修正来生成监督微调数据，从而教会LLM学习自主用例生成和自检。此外，它利用强化学习和新颖的Case-Synergy可解决性扩展奖励，该奖励基于从问题通过率估计的可解决性以及自我导向用例生成的成功率，使模型能够更有效地从成功和失败中学习。

Result: 通过CodeSeq训练的模型在各种推理任务上都有所改进，并且可以保持模型的OOD性能。

Conclusion: CodeSeq通过引入复杂的内部模式和精确的思维过程，显著提高了大型语言模型（LLMs）在归纳推理任务上的表现，并解决了一系列挑战。

Abstract: Large language models (LLMs) make remarkable progress in reasoning tasks.
Among different reasoning modes, inductive reasoning, due to its better
alignment with human learning, attracts increasing interest. However, research
on inductive reasoning faces certain challenges. First, existing inductive data
mostly focuses on superficial regularities while lacking more complex internal
patterns. Second, current works merely prompt LLMs or finetune on simple
prompt-response pairs, but do not provide precise thinking processes nor
implement difficulty control. Unlike previous work, we address these challenges
by introducing \textit{CodeSeq}, a synthetic post-training dataset built from
number sequences. We package number sequences into algorithmic problems to
discover their general terms, defining a general term generation (GTG) task
correspondingly. Our pipeline generates supervised finetuning data by
reflecting on failed test cases and incorporating iterative corrections,
thereby teaching LLMs to learn autonomous case generation and self-checking.
Additionally, it leverages reinforcement learning with a novel Case-Synergy
Solvability Scaling Reward based on both solvability, estimated from the
problem pass rate, and the success rate of self-directed case generation,
enabling models to learn more effectively from both successes and failures.
Experimental results show that the models trained with \textit{CodeSeq} improve
on various reasoning tasks and can preserve the models' OOD performance.

</details>


### [84] [RLAIF-SPA: Optimizing LLM-based Emotional Speech Synthesis via RLAIF](https://arxiv.org/abs/2510.14628)
*Qing Yang,Zhenghao Liu,Junxin Wang,Yangfan Du,Pengcheng Huang,Tong Xiao*

Main category: cs.CL

TL;DR: RLAIF-SPA框架通过结合ASR和LLM技术，利用AI反馈强化学习机制，优化情感语音合成，在语义准确性和韵律情感对齐方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有文本转语音系统在情感表达方面存在挑战，现有方法依赖昂贵的情感标注或优化间接目标，导致生成语音准确但情感平淡。

Method: 提出RLAIF-SPA框架，该框架利用AI反馈强化学习（RLAIF）机制，通过ASR判断语义准确性，LLM判断韵律情感标签对齐，以此作为情感表达和可懂度优化的直接奖励。具体来说，该框架利用韵律标签对齐，从结构、情感、语速和语调四个维度共同考虑语义准确性和韵律情感对齐；此外，还结合了语义准确性反馈，确保生成清晰准确的语音。

Result: 在Libri Speech数据集上的实验表明，RLAIF-SPA在词错误率（WER）方面比Chat-TTS降低了26.1%，SIM-O得分提高了9.1%，并且在人类评估中取得了超过10%的提升。

Conclusion: RLAIF-SPA框架有效解决了情感语音合成中的挑战，显著提高了语音的语义准确性和情感表达能力，优于现有先进系统。

Abstract: Text-To-Speech synthesis has achieved near-human quality in neutral speech,
but emotional expressiveness remains a challenge. Existing methods often rely
on costly emotion annotations or optimize indirect objectives that fail to
capture the emotional expressiveness and perceptual naturalness of speech,
leading to generated speech that is accurate but emotionally flat. To address
these challenges, we propose the RLAIF-SPA framework, incorporating a
Reinforcement Learning from AI Feedback (RLAIF) mechanism to employ Automatic
Speech Recognition (ASR) and Large Language Model (LLM) techniques to
respectively judge semantic accuracy and prosodic-emotional label alignment as
a direct reward for emotional expressiveness and intelligibility optimization.
Specifically, it leverages Prosodic Label Alignment to enhance expressive
quality by jointly considering semantic accuracy and prosodic-emotional
alignment along four fine-grained dimensions: Structure, Emotion, Speed, and
Tone. In addition, it incorporates Semantic Accuracy Feedback to ensure the
generation of clear and accurate speech. Experiments on the Libri Speech
dataset show that RLAIF-SPA outperforms Chat-TTS, with a 26.1% reduction in
WER, a 9.1% increase in SIM-O, and over 10% improvement in human evaluation.

</details>


### [85] [Intent Clustering with Shared Pseudo-Labels](https://arxiv.org/abs/2510.14640)
*I-Fan Lin,Faegheh Hasibi,Suzan Verberne*

Main category: cs.CL

TL;DR: 本文提出了一种直观、免训练、免标签的意图聚类方法，该方法使用轻量级开源大型语言模型，假设最少。它在多个基准测试中表现出与最新基线相当或更好的结果，同时保持简单和计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前许多意图聚类方法依赖于昂贵的商业大型语言模型，且透明度有限；其方法通常需要预先知道聚类数量，这在实际应用中往往不切实际。

Method: 该方法不直接要求大型语言模型匹配相似文本，而是首先让大型语言模型为每个文本生成伪标签，然后在此伪标签集上为每个文本执行多标签分类。其核心假设是，属于同一聚类的文本将共享更多标签，因此在编码为嵌入时会更接近。这些伪标签比直接相似性匹配更具可读性。

Result: 在四个基准测试集上的评估表明，该方法取得了与最新基线相当或更好的结果。该方法简单且计算效率高。

Conclusion: 本文提出的方法可以在低资源场景中应用，并且在多种模型和数据集下都表现稳定，效果良好。

Abstract: In this paper, we propose an intuitive, training-free and label-free method
for intent clustering that makes minimal assumptions using lightweight and
open-source LLMs. Many current approaches rely on commercial LLMs, which are
costly, and offer limited transparency. Additionally, their methods often
explicitly depend on knowing the number of clusters in advance, which is often
not the case in realistic settings. To address these challenges, instead of
asking the LLM to match similar text directly, we first ask it to generate
pseudo-labels for each text, and then perform multi-label classification in
this pseudo-label set for each text. This approach is based on the hypothesis
that texts belonging to the same cluster will share more labels, and will
therefore be closer when encoded into embeddings. These pseudo-labels are more
human-readable than direct similarity matches. Our evaluation on four benchmark
sets shows that our approach achieves results comparable to and better than
recent baselines, while remaining simple and computationally efficient. Our
findings indicate that our method can be applied in low-resource scenarios and
is stable across multiple models and datasets.

</details>


### [86] [Semantic Prosody in Machine Translation: the English-Chinese Case of Passive Structures](https://arxiv.org/abs/2510.14662)
*Xinyue Ma,Pol Pastells,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 本文提出了一种方法，用于让机器翻译模型学习特定结构的语义韵。


<details>
  <summary>Details</summary>
Motivation: 目前的机器翻译模型无法处理语义韵问题，导致翻译不准确。

Method: 1. 构建了一个包含BEI被动结构负面语义韵的英汉句子对数据集。
2. 使用该数据集对OPUS-MT、NLLB-600M和mBART50模型进行微调，用于英汉翻译任务。

Result: 1. 微调后的机器翻译模型在翻译不利内容时，能更好地使用BEI被动结构，并避免将其用于中性和有利内容。
2. 在多语言模型NLLB-600M中，语义韵知识可以从英汉翻译迁移到其他语言对（如西汉翻译）。

Conclusion: 本文提出了一种有效的方法，使机器翻译模型能够学习和应用特定语言结构（如汉语“被”字句）的语义韵，从而提高翻译的准确性，尤其是在处理情感色彩方面。

Abstract: Semantic prosody is a collocational meaning formed through the co-occurrence
of a linguistic unit and a consistent series of collocates, which should be
treated separately from semantic meaning. Since words that are literal
translations of each other may have different semantic prosody, more attention
should be paid to this linguistic property to generate accurate translations.
However, current machine translation models cannot handle this problem. To
bridge the gap, we propose an approach to teach machine translation models
about semantic prosody of a specific structure. We focus on Chinese BEI
passives and create a dataset of English-Chinese sentence pairs with the
purpose of demonstrating the negative semantic prosody of BEI passives. Then we
fine-tune OPUS-MT, NLLB-600M and mBART50 models with our dataset for the
English-Chinese translation task. Our results show that fine-tuned MT models
perform better on using BEI passives for translating unfavourable content and
avoid using it for neutral and favourable content. Also, in NLLB-600M, which is
a multilingual model, this knowledge of semantic prosody can be transferred
from English-Chinese translation to other language pairs, such as
Spanish-Chinese.

</details>


### [87] [Speculative Model Risk in Healthcare AI: Using Storytelling to Surface Unintended Harms](https://arxiv.org/abs/2510.14718)
*Xingmeng Zhao,Dan Schumacher,Veronica Rammouz,Anthony Rios*

Main category: cs.CL

TL;DR: 该研究提出了一个以人为中心的框架，旨在通过生成用户故事并支持多智能体讨论，帮助人们在部署人工智能系统之前创造性地思考潜在的利益和危害。


<details>
  <summary>Details</summary>
Motivation: 人工智能在医疗保健领域的快速发展，导致出现了应力监测器、健康追踪器和心理健康聊天机器人等工具。然而，这种快速且低门槛的开发可能引入偏见、隐私侵犯和不平等的访问等风险，尤其是在系统忽视现实世界背景和多样化用户需求时。许多现有方法侧重于自动检测风险，但这可能降低人们对危害产生原因和受影响人群的理解。

Method: 本研究提出了一个以人为中心的框架，该框架能生成用户故事并支持多智能体讨论。这种方法旨在帮助人们在人工智能系统部署之前，创造性地思考其潜在的益处和危害。

Result: 用户研究结果表明，阅读故事的参与者能够识别更广泛的危害类型，并将他们的回应更均匀地分布在所有13种危害类型中。相比之下，没有阅读故事的参与者主要关注隐私和幸福（58.3%）。

Conclusion: 讲故事有助于参与者更广泛地推测危害和益处，并更具创造性地思考人工智能对用户的影响。

Abstract: Artificial intelligence (AI) is rapidly transforming healthcare, enabling
fast development of tools like stress monitors, wellness trackers, and mental
health chatbots. However, rapid and low-barrier development can introduce risks
of bias, privacy violations, and unequal access, especially when systems ignore
real-world contexts and diverse user needs. Many recent methods use AI to
detect risks automatically, but this can reduce human engagement in
understanding how harms arise and who they affect. We present a human-centered
framework that generates user stories and supports multi-agent discussions to
help people think creatively about potential benefits and harms before
deployment. In a user study, participants who read stories recognized a broader
range of harms, distributing their responses more evenly across all 13 harm
types. In contrast, those who did not read stories focused primarily on privacy
and well-being (58.3%). Our findings show that storytelling helped participants
speculate about a broader range of harms and benefits and think more creatively
about AI's impact on users.

</details>


### [88] [AutoRubric-R1V: Rubric-Based Generative Rewards for Faithful Multimodal Reasoning](https://arxiv.org/abs/2510.14738)
*Mengzhao Jia,Zhihan Zhang,Ignacio Cases,Zheyuan Liu,Meng Jiang,Peng Qi*

Main category: cs.CL

TL;DR: AutoRubric-R1V通过整合RLVR（只奖励最终答案正确性）和过程级监督（通过自动收集的基于评分的生成奖励），解决了MLLMs在复杂多步推理中RLVR导致的虚假推理问题。


<details>
  <summary>Details</summary>
Motivation: 在大语言模型（MLLMs）从感知任务快速发展到复杂多步推理的背景下，验证性奖励的强化学习（RLVR）常常导致虚假推理，因为只奖励最终答案的正确性。

Method: 提出AutoRubric-R1V框架，该框架将RLVR与通过自动收集的基于评分的生成奖励实现的过程级监督相结合。其关键创新在于一种可扩展的自聚合方法，该方法从成功轨迹中提取一致的推理检查点，从而无需人工标注或更强的教师模型即可构建特定问题的评分标准。

Result: AutoRubric-R1V通过共同利用基于评分的奖励和结果奖励，在六个多模态推理基准测试中取得了最先进的性能，并在专门评估中显著提高了推理的忠实性。

Conclusion: AutoRubric-R1V框架通过引入过程级监督和自动生成的评分奖励，有效解决了MLLMs中RLVR的虚假推理问题，显著提升了多模态推理任务的性能和忠实性。

Abstract: Multimodal large language models (MLLMs) have rapidly advanced from
perception tasks to complex multi-step reasoning, yet reinforcement learning
with verifiable rewards (RLVR) often leads to spurious reasoning since only the
final-answer correctness is rewarded. To address this limitation, we propose
AutoRubric-R1V, a framework that integrates RLVR with process-level supervision
through automatically collected rubric-based generative rewards. Our key
innovation lies in a scalable self-aggregation method that distills consistent
reasoning checkpoints from successful trajectories, enabling problem-specific
rubric construction without human annotation or stronger teacher models. By
jointly leveraging rubric-based and outcome rewards, AutoRubric-R1V achieves
state-of-the-art performance on six multimodal reasoning benchmarks and
substantially improves reasoning faithfulness in dedicated evaluations.

</details>


### [89] [Pluto: A Benchmark for Evaluating Efficiency of LLM-generated Hardware Code](https://arxiv.org/abs/2510.14756)
*Manar Abdelatty,Maryam Nouh,Jacob K. Rosenstein,Sherief Reda*

Main category: cs.CL

TL;DR: Pluto是一个全面的基准测试和评估框架，旨在评估大型语言模型生成的Verilog设计的效率。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能全面评估LLM生成的Verilog设计的综合指标（面积、延迟和功耗），且缺乏优化的基线或用于验证的测试平台。

Method: Pluto提供了114个问题的综合评估集，包含自检查测试平台和多个帕累托最优的参考实现。

Result: 最先进的LLM在功能正确性上达到78.3%（pass@1），但在综合效率上仍落后于专家设计，面积效率为63.8%，延迟效率为65.9%，功耗效率为64.0%（eff@1）。

Conclusion: 需要Pluto这类效率感知的评估框架来推动以硬件为中心的LLM研究进展。

Abstract: Large Language Models (LLMs) are increasingly used to automate hardware
design tasks, including the generation of Verilog code. While early benchmarks
focus primarily on functional correctness, efficient hardware design demands
additional optimization for synthesis metrics such as area, delay, and power.
Existing benchmarks fall short in evaluating these aspects comprehensively:
they often lack optimized baselines or testbenches for verification. To address
these gaps, we present Pluto, a benchmark and evaluation framework designed to
assess the efficiency of LLM-generated Verilog designs. Pluto presents a
comprehensive evaluation set of 114 problems with self-checking testbenches and
multiple Pareto-optimal reference implementations. Experimental results show
that state-of-the-art LLMs can achieve high functional correctness, reaching
78.3\% at pass@1, but their synthesis efficiency still lags behind
expert-crafted implementations, with area efficiency of 63.8\%, delay
efficiency of 65.9\%, and power efficiency of 64.0\% at eff@1. This highlights
the need for efficiency-aware evaluation frameworks such as Pluto to drive
progress in hardware-focused LLM research.

</details>


### [90] [COIG-Writer: A High-Quality Dataset for Chinese Creative Writing with Thought Processes](https://arxiv.org/abs/2510.14763)
*Yunwen Li,Shuangshuang Ying,Xingwei Qu,Xin Li,Sheng Jin,Minghao Liu,Zhoufutu Wen,Tianyu Zheng,Xeron Du,Qiguang Chen,Jiajun Shi,Wangchunshu Zhou,Jiazhan Feng,Wanjun Zhong,Libo Qin,Stephen Huang,Wanxiang Che,Chenghua Lin,Eli Zhang*

Main category: cs.CL

TL;DR: COIG-Writer是一个中文创意写作数据集，旨在解决大型语言模型在非英语创意写作中表现不佳的问题。它包含1665个三元组，涵盖51种文学体裁，每个三元组包括反向工程提示、详细的创作推理过程和最终文本。研究发现，创意写作涉及叙事逻辑和语言表达，过程监督对提高创意写作能力非常有效，但需要与通用数据结合使用。此外，创意能力具有文化 F 围性，并且词汇多样性与创意质量呈负相关。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在创意写作方面表现出系统性缺陷，尤其是在训练数据稀缺且缺乏过程级监督的非英语环境中。

Method: 本文提出了COIG-Writer，一个新颖的中文创意写作数据集。该数据集通过系统地对高质量文本进行逆向工程，捕获了多样化的输出及其潜在的思维过程。COIG-Writer包含1665个精心策划的三元组，涵盖51种文学体裁，每个三元组包含：(1) 一个逆向工程提示，(2) 详细的创作推理过程，记录了决策过程，以及(3) 最终文本。

Result: 研究确定了创意写作的两个组成部分：叙事逻辑（由过程监督提供）和语言表达（由通用数据维持）。（1）过程监督非常有效，但需要与通用数据结合使用才能稳定。需要至少1个创意样本与12个通用样本的比例才能达到最佳性能。（2）创意能力受文化 D 围限制，没有跨语言迁移。（3）词汇多样性与创意质量呈负相关，即高多样性预示着对逻辑缺陷的补偿行为。

Conclusion: 创意卓越源于逻辑 H 构和语言基础之间的相互作用，类似于数学推理增强但不能取代基础模型中的语言能力。为了实现最佳性能，过程监督与通用数据相结合是必要的。同时，需要认识到创意能力的文化 F 围性和词汇多样性与创意质量之间的复杂关系，以进一步改进大型语言模型的创意写作能力。

Abstract: Large language models exhibit systematic deficiencies in creative writing,
particularly in non-English contexts where training data is scarce and lacks
process-level supervision. We present COIG-Writer, a novel Chinese creative
writing dataset that captures both diverse outputs and their underlying thought
processes through systematic reverse-engineering of high-quality texts. Unlike
existing datasets that provide only input-output pairs, COIG-Writer comprises
1,665 meticulously curated triplets spanning 51 genres, each containing: (1) a
reverse-engineered prompt, (2) detailed creative reasoning documenting
decision-making processes, and (3) the final text. Through comprehensive
experiments, we identify a two-component model of creative writing: narrative
logic (provided by process supervision) and linguistic expression (maintained
by general-purpose data). Our findings reveal three critical insights: (1)
Process supervision is highly effective but requires stabilization with general
data. A ratio of at least one creative sample to twelve general samples is
needed to achieve optimal performance; below this threshold, the win rate
progressively degrades (from 62.75% down to 35.78%)., (2) creative capabilities
are culturally-bound with no cross-lingual transfer (89.26pp gap between
Chinese and English performance), and (3) lexical diversity inversely
correlates with creative quality (TTR paradox), suggesting high diversity
signals compensatory behavior for logical deficiencies. These findings
establish that creative excellence emerges from the interaction between logical
scaffolding and linguistic grounding, analogous to how mathematical reasoning
enhances but cannot replace linguistic competence in foundation models.

</details>


### [91] [Finding Answers in Thought Matters: Revisiting Evaluation on Large Language Models with Reasoning](https://arxiv.org/abs/2510.14773)
*Hwiyeol Jo,Joosung Lee,Jaehone Lee,Sang-Woo Lee,Joonsuk Park,Kang Min Yoo*

Main category: cs.CL

TL;DR: 该研究探讨了生成模型（如大型语言模型LLMs）评估中的答案提取问题，提出了一种名为“答案再生”的框架，旨在提高推理模型在问答任务中的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在评估生成模型时，特别是需要推理的模型，答案提取算法对模型性能和最终答案分布有显著影响，现有方法存在敏感性问题。

Method: 提出“答案再生”（Answer Regeneration）框架：通过额外的模型推理，在原始输入和输出前加上“Answer:”提示词，然后从再生输出中选择或提取最终答案。

Result: “答案再生”方法表现出更好的性能和增强的鲁棒性，且与具体的提取规则无关。该框架已成功应用于一般数学问题和开放式问答任务。

Conclusion: 答案再生框架为模型评估提供了一种更可靠的方法，能有效缓解答案提取算法对推理模型评估结果的影响。

Abstract: Evaluating generative models, such as large language models (LLMs), commonly
involves question-answering tasks where the final answer is selected based on
probability of answer choices. On the other hand, for models requiring
reasoning, the method of answer extraction plays a critical role. Our research
reveals that the performance of reasoning models and their final answer
distributions are highly sensitive to the answer extraction algorithm employed.
In order to mitigate this, we propose a basic framework: Answer Regeneration.
The method uses an additional model inference, providing the prior input and
output prefaced by the prompt "Answer:". The final answer is then selected or
extracted from the regenerated output. We show that this
extraction-rule-agnostic approach exhibits improved performance and enhanced
robustness. Furthermore, we have applied this framework to general math
problems and open-ended question answering tasks. Our analysis and this
framework could offer a more reliable results for model evaluation.

</details>


### [92] [Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking](https://arxiv.org/abs/2510.14824)
*Ziqi Dai,Xin Zhang,Mingxin Li,Yanzhao Zhang,Dingkun Long,Pengjun Xie,Meishan Zhang,Wenjie Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在信息检索重排序任务中，对比学习（CL）与监督微调（SFT）两种训练目标之间的优劣，并深入分析了其内在机制。


<details>
  <summary>Details</summary>
Motivation: 在信息检索领域，BERT类编码器在重排序任务中对比学习（CL）优于判别学习（分类），而大语言模型（LLMs）在重排序任务中监督微调（SFT）表现更佳。论文旨在探究哪种目标更适合基于LLM的重排序，以及造成这种差异的潜在机制。

Method: 本文以通用多模态检索（UMR）作为实验平台，对CL和SFT在重排序任务中进行了全面比较和分析。作者将训练目标分解为“权重”和“方向”两个组件，并提出了一个统一的框架来理解它们之间的相互作用。通过探究性实验，作者比较了两种方法的表现。

Result: 探究性实验表明，SFT提供了比CL更强的加权方案，而首选的评分方向没有明确的赢家。这些结果一致表明，在LLM重排序中SFT优于CL。

Conclusion: SFT在LLM重排序中相对于CL具有显著优势，这主要归因于SFT更强的加权机制。这些发现为未来该领域的研究和应用提供了指导。

Abstract: In information retrieval, training reranking models mainly focuses on two
types of objectives: metric learning (e.g. contrastive loss to increase the
predicted scores on relevant query-document pairs) and classification (binary
label prediction of relevance vs. irrelevance). For BERT-style encoders,
various studies have shown that contrastive learning (CL) can be more effective
than discriminative (classification) learning. However, for large language
models (LLMs), classification via supervised fine-tuning (SFT), which predicts
''yes'' (resp. ''no'') token for relevant (resp. irrelevant) pairs, appears
more promising as it aligns well with the generative nature of LLMs. This
divergence raises a central question: which objective is intrinsically better
suited to LLM-based reranking, and what mechanism underlies the difference? In
this work, we conduct a comprehensive comparison and analysis between CL and
SFT for reranking, taking the universal multimodal retrieval (UMR) as the
experimental playground. We first decompose the objectives into two components:
weight, which controls the magnitude of those updates, and direction, which
guides the model updates, then present a unified framework for understanding
their interactions. Through probing experiments, we find that SFT provides a
substantially stronger weighting scheme than CL, whereas the preferred scoring
direction shows no clear winner. Taken together, these results point to a
consistent advantage of SFT over CL for LLM reranking. To further validate our
findings, we conduct large-scale training with SFT and present new
state-of-the-art rerankers on the MRB benchmark. We also provide ablations on
SFT settings and expect our findings to benefit future research and
applications in this area.

</details>


### [93] [Rewiring Experts on the Fly:Continuous Rerouting for Better Online Adaptation in Mixture-of-Expert models](https://arxiv.org/abs/2510.14853)
*Guinan Su,Yanwu Yang,Li Shen,Lu Yin,Shiwei Liu,Jonas Geiping*

Main category: cs.CL

TL;DR: 为了解决MoE模型在实际部署中路由决策不佳的问题，本文提出了一种无需数据、在线的测试时自适应框架，通过利用已生成的序列进行自监督优化路由决策，在推理任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: MoE模型在部署过程中面临由分布变化导致的路由决策次优问题，现有测试时自适应方法主要针对密集模型且需要外部数据，不适用于MoE模型。

Method: 本文提出了一种无数据、在线测试时自适应框架，通过在预填充阶段以及后续的固定间隔时间，利用已生成的序列进行自监督优化模型路由决策。然后，模型照常生成文本，并保持修改后的路由器直到下一次自适应。该方法通过轻量级 additive vectors 实现，仅更新选定层中的路由器 logits，从而在保持计算效率的同时防止过度适应。

Result: 在具有挑战性的推理任务中持续获得性能提升，同时对上下文变化保持鲁棒性。例如，使用 OLMoE 在 HumanEval 上取得了 5.5% 的改进。此外，该方法具有即插即用特性，可以与现有测试时扩展技术结合，例如在 DeepSeek-V2-Lite 上与自洽性结合时平均增益达到 6%。

Conclusion: 本文提出了一种新颖的无数据、在线测试时 MoE 路由自适应框架，有效地解决了 MoE 模型在实际部署中路由决策次优的问题，并在多个推理任务中取得了显著的性能提升和良好的泛化能力。

Abstract: Mixture-of-Experts (MoE) models achieve efficient scaling through sparse
expert activation, but often suffer from suboptimal routing decisions due to
distribution shifts in deployment. While existing test-time adaptation methods
could potentially address these issues, they primarily focus on dense models
and require access to external data, limiting their practical applicability to
MoE architectures. However, we find that, instead of relying on reference data,
we can optimize MoE expert selection on-the-fly based only on input context. As
such, we propose \textit{a data-free, online test-time framework} that
continuously adapts MoE routing decisions during text generation without
external supervision or data. Our method cycles between two phases: During the
prefill stage, and later in regular intervals, we optimize the routing
decisions of the model using self-supervision based on the already generated
sequence. Then, we generate text as normal, maintaining the modified router
until the next adaption. We implement this through lightweight additive vectors
that only update router logits in selected layers, maintaining computational
efficiency while preventing over-adaptation. The experimental results show
consistent performance gains on challenging reasoning tasks while maintaining
robustness to context shifts. For example, our method achieves a 5.5\%
improvement on HumanEval with OLMoE. Furthermore, owing to its plug-and-play
property, our method naturally complements existing test-time scaling
techniques, e.g., achieving 6\% average gains when incorporated with
self-consistency on DeepSeek-V2-Lite.

</details>


### [94] [Midtraining Bridges Pretraining and Posttraining Distributions](https://arxiv.org/abs/2510.14865)
*Emmy Liu,Graham Neubig,Chenyan Xiong*

Main category: cs.CL

TL;DR: 本文对大语言模型中的“中训练”（midtraining）阶段进行了系统性研究，发现它在数学和代码领域最有效，能减少句法鸿沟，并且比持续预训练更能减少遗忘，提高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型预训练中的“中训练”阶段很流行，但对其有效性及工作原理缺乏科学理解。

Method: 通过从头预训练并在不同领域进行监督微调的受控实验，系统地研究了“中训练”阶段。

Result: 中训练在数学和代码领域最有效，能减少预训练和后训练数据之间的句法鸿沟。与持续预训练相比，中训练在域内验证损失和后训练后的预训练数据遗忘方面表现更好。较早引入专业数据比混合权重对性能影响更大，可以带来更大的域内收益并更好地保留通用语言建模能力。

Conclusion: 中训练是一种有效的领域适应技术，与持续预训练相比，它能通过减少遗忘实现更好的性能。

Abstract: Recently, many language models have been pretrained with a "midtraining"
phase, in which higher quality, often instruction-formatted data, is mixed in
at the end of pretraining. Despite the popularity of this practice, there is
little scientific understanding of this phase of model training or why it is
effective. In this work, we conduct the first systematic investigation of
midtraining through controlled experiments with language models pretrained from
scratch and fine-tuned on supervised finetuning datasets in different domains.
We find that when compared after supervised fine-tuning, the effectiveness of
midtraining is highest in the math and code domains, where midtraining can best
reduce the syntactic gap between pretraining and posttraining data. In these
cases, midtraining consistently outperforms continued pretraining in both
in-domain validation loss as well as pretraining data forgetting after
posttraining. We conduct ablations on the starting time of the midtraining
phase and mixture weights of the midtraining data, using code midtraining as a
case study, and find that timing has a greater impact than mixture weights,
with earlier introduction of specialized data, yielding greater benefits
in-domain as well as preserving general language modeling better. These
findings establish midtraining as a domain adaptation technique that compared
to continued pretraining yields better performance through reduced forgetting.

</details>


### [95] [From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR](https://arxiv.org/abs/2510.14871)
*Erwei Wang,Samuel Bayliss,Andra Bisca,Zachary Blair,Sangeeta Chowdhary,Kristof Denolf,Jeff Fifield,Brandon Freiberger,Erika Hunhoff,Phil James-Roxby,Jack Lo,Joseph Melber,Stephen Neuendorffer,Eddie Richter,Andre Rosti,Javier Setoain,Gagandeep Singh,Endri Taka,Pranathi Vasireddy,Zhewen Yu,Niansong Zhang,Jinming Zhuang*

Main category: cs.CL

TL;DR: MLIR-AIR是一个基于MLIR的编译器栈，它通过AIR方言为空间架构提供细粒度的控制，实现了高效的矩阵乘法和LLaMA 2多头注意力模块。


<details>
  <summary>Details</summary>
Motivation: 现代空间架构需要对数据移动、执行顺序和计算位置进行细粒度控制以提高性能，而通用编译器在此方面存在局限性。

Method: MLIR-AIR引入AIR方言，为计算和内存资源提供异步和分层操作的结构化表示。AIR原语允许编译器协调空间调度、在硬件区域分配计算并将通信与计算重叠。

Result: 在矩阵乘法方面，MLIR-AIR实现了高达78.7%的计算效率，并且性能与手工优化的MLIR-AIE框架几乎相同。在多头注意力方面，MLIR-AIR通过大约150行代码实现了融合实现，支持高效映射到空间硬件。

Conclusion: MLIR-AIR将高级结构化控制流转换为空间程序，通过编译器管理的调度，有效利用NPU的计算结构和内存层次结构，实现异步执行、分块和通信重叠。

Abstract: General-purpose compilers abstract away parallelism, locality, and
synchronization, limiting their effectiveness on modern spatial architectures.
As modern computing architectures increasingly rely on fine-grained control
over data movement, execution order, and compute placement for performance,
compiler infrastructure must provide explicit mechanisms for orchestrating
compute and data to fully exploit such architectures. We introduce MLIR-AIR, a
novel, open-source compiler stack built on MLIR that bridges the semantic gap
between high-level workloads and fine-grained spatial architectures such as
AMD's NPUs. MLIR-AIR defines the AIR dialect, which provides structured
representations for asynchronous and hierarchical operations across compute and
memory resources. AIR primitives allow the compiler to orchestrate spatial
scheduling, distribute computation across hardware regions, and overlap
communication with computation without relying on ad hoc runtime coordination
or manual scheduling. We demonstrate MLIR-AIR's capabilities through two case
studies: matrix multiplication and the multi-head attention block from the
LLaMA 2 model. For matrix multiplication, MLIR-AIR achieves up to 78.7% compute
efficiency and generates implementations with performance almost identical to
state-of-the-art, hand-optimized matrix multiplication written using the
lower-level, close-to-metal MLIR-AIE framework. For multi-head attention, we
demonstrate that the AIR interface supports fused implementations using
approximately 150 lines of code, enabling tractable expression of complex
workloads with efficient mapping to spatial hardware. MLIR-AIR transforms
high-level structured control flow into spatial programs that efficiently
utilize the compute fabric and memory hierarchy of an NPU, leveraging
asynchronous execution, tiling, and communication overlap through
compiler-managed scheduling.

</details>


### [96] [Harmonizing Diverse Models: A Layer-wise Merging Strategy for Consistent Generation](https://arxiv.org/abs/2510.14915)
*Xujun Peng,Anoop Kumar,Jingyu Wu,Parker Glenn,Daben Liu*

Main category: cs.CL

TL;DR: 本文提出了一个新方法，通过结合系统合成数据生成、用于更好嵌入的三元组损失和新颖的逐层模型合并方法，显著提高RAG系统输出的一致性。


<details>
  <summary>Details</summary>
Motivation: 目前的RAG系统使用LLMs生成基于检索上下文的准确可靠的响应，但LLMs在语义等效输入下输出不一致。此外，缺乏以一致性为重点的训练数据以及当前微调技术在增强输出一致性方面的局限性使得问题更加复杂。

Method: 本文提出了一种结合系统合成数据生成、用于更好嵌入的三元组损失和新颖的逐层模型合并方法的新方法。通过使用源自中间层激活的一致性感知权重，该方法有效地整合了来自专业模型的知识。

Result: 实验结果表明，本文合并后的模型显著增强了输出一致性，响应相似性比基线提高了约47.5%。

Conclusion: 本文提出了一种提高工业RAG系统可靠性的实用解决方案，有效解决了LLM输出不一致的问题。

Abstract: Retrieval-Augmented Generation (RAG) systems leverage Large Language Models
(LLMs) to generate accurate and reliable responses that are grounded in
retrieved context. However, LLMs often generate inconsistent outputs for
semantically equivalent inputs, a problem compounded by the scarcity of
consistency-focused training data and the limitations of current fine-tuning
techniques in enhancing output consistency. We propose a new approach combining
systematic synthetic data generation, triplet loss for better embeddings, and a
novel layer-wise model merging approach. Using consistency-aware weights
derived from intermediate layer activations, our method effectively integrates
knowledge from specialized models. Experimental results how that our merged
model significantly enhances output consistency, achieving a ~47.5\%
improvement in response similarity over the baseline, thus offering a practical
solution for increasing the reliability of an industrial RAG system.

</details>


### [97] [Predicting Task Performance with Context-aware Scaling Laws](https://arxiv.org/abs/2510.14919)
*Kyle Montgomery,David Park,Jianhong Tu,Michael Bendersky,Beliz Gunel,Dawn Song,Chenguang Wang*

Main category: cs.CL

TL;DR: 本文提出一个简单、可解释的框架，用于联合建模下游性能与训练计算和上下文之间的关系，并在Llama-2-7B和Llama-2-13B的扩展上下文变体上进行验证。


<details>
  <summary>Details</summary>
Motivation: 传统的扩展定律未能捕捉下游任务性能，因为上下文在其中起着关键作用。

Method: 本文提出了一个简单、可解释的框架，将下游性能联合建模为训练计算量和所提供上下文的函数。并通过在Llama-2-7B和Llama-2-13B模型的扩展上下文变体上进行拟合，对框架进行了实证验证，这些模型涉及算术推理、常识推理和机器翻译三项任务的65,500个独特实例。

Result: 实验结果表明，该框架能准确模拟分布内的下游性能，在训练计算量上泛化了三个数量级，并能随着上下文量的增加可靠地推断性能。

Conclusion: 这些发现为训练计算和上下文利用之间的相互作用提供了有价值的见解，为设计用于各种下游任务的更高效长上下文大型语言模型提供了指导。

Abstract: Scaling laws have transformed our understanding of large language models by
linking upstream metrics like cross-entropy loss to design factors such as
model size, training data, and compute. However, these conventional laws fail
to capture downstream task performance, where context plays a critical role. In
this work, we propose a straightforward, interpretable framework that jointly
models downstream performance as a function of the training compute and the
provided context. We empirically validate our framework by fitting it on the
observed downstream performance of extended-context variants of Llama-2-7B and
Llama-2-13B across 65,500 unique instances spanning three tasks: arithmetic
reasoning, common sense reasoning, and machine translation. Our results
demonstrate that our framework accurately models in-distribution downstream
performance, generalizes across three orders of magnitude in training compute,
and reliably extrapolates performance as the amount of context increases. These
findings offer valuable insights into the interplay between training compute
and context utilization, providing guidance for designing more efficient
long-context LLMs for diverse downstream tasks. Our code is available at
https://github.com/wang-research-lab/context-scaling.

</details>


### [98] [AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations](https://arxiv.org/abs/2510.14937)
*Jianfeng Zhu,Julina Maharjan,Xinyu Li,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

TL;DR: 这篇论文评估了机器学习模型，特别是大型语言模型（LLMs），在精神健康筛查方面的有效性，通过分析真实世界的半结构化访谈数据，旨在解决当前精神疾病诊断中存在的挑战，并强调了LLMs在实现早期、低门槛诊断方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 精神健康障碍是全球致残的主要原因，但由于主观评估、临床资源有限、污名化和认知不足，抑郁症、焦虑症和创伤后应激障碍（PTSD）等疾病经常被漏诊或误诊。初级保健环境中提供者对抑郁症或焦虑症的误诊率超过60%，这突出表明了对可扩展、可访问和情境感知的诊断工具的迫切需求，以支持早期检测和干预。

Method: 本研究使用包含553个真实世界半结构化访谈的独特数据集来评估机器学习模型在精神健康筛查中的有效性，每个访谈都配有重度抑郁发作（MDE）、焦虑症和PTSD的真实诊断。研究基准测试了多种模型类别，包括使用GPT-4.1 Mini和MetaLLaMA的零样本提示，以及使用低秩适应（LoRA）的微调RoBERTa模型。

Result: 模型在所有诊断类别上达到了超过80%的准确率，在PTSD上的表现尤其出色（最高89%的准确率和98%的召回率）。研究还发现，使用更短、更集中的上下文片段可以提高召回率。LoRA微调被证明既高效又有效，低秩配置（例如，秩8和16）在各项评估指标上保持了有竞争力的性能。

Conclusion: LLM驱动的模型可以显著改善传统自我报告筛查工具，为实现低门槛、人工智能辅助的早期诊断提供了途径。这项工作为将机器学习整合到现实世界的临床工作流程中奠定了基础，特别是在资源匮乏或污名化严重、及时精神健康护理可及性最受限制的环境中。

Abstract: Mental health disorders remain among the leading cause of disability
worldwide, yet conditions such as depression, anxiety, and Post-Traumatic
Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to
subjective assessments, limited clinical resources, and stigma and low
awareness. In primary care settings, studies show that providers misidentify
depression or anxiety in over 60% of cases, highlighting the urgent need for
scalable, accessible, and context-aware diagnostic tools that can support early
detection and intervention. In this study, we evaluate the effectiveness of
machine learning models for mental health screening using a unique dataset of
553 real-world, semistructured interviews, each paried with ground-truth
diagnoses for major depressive episodes (MDE), anxiety disorders, and PTSD. We
benchmark multiple model classes, including zero-shot prompting with GPT-4.1
Mini and MetaLLaMA, as well as fine-tuned RoBERTa models using LowRank
Adaptation (LoRA). Our models achieve over 80% accuracy across diagnostic
categories, with especially strongperformance on PTSD (up to 89% accuracy and
98% recall). We also find that using shorter context, focused context segments
improves recall, suggesting that focused narrative cues enhance detection
sensitivity. LoRA fine-tuning proves both efficient and effective, with
lower-rank configurations (e.g., rank 8 and 16) maintaining competitive
performance across evaluation metrics. Our results demonstrate that LLM-based
models can offer substantial improvements over traditional self-report
screening tools, providing a path toward low-barrier, AI-powerd early
diagnosis. This work lays the groundwork for integrating machine learning into
real-world clinical workflows, particularly in low-resource or high-stigma
environments where access to timely mental health care is most limited.

</details>


### [99] [LaSeR: Reinforcement Learning with Last-Token Self-Rewarding](https://arxiv.org/abs/2510.14943)
*Wenkai Yang,Weijie Liu,Ruobing Xie,Yiju Guo,Lulu Wu,Saiyong Yang,Yankai Lin*

Main category: cs.CL

TL;DR: 本文提出了一种名为LaSeR（Reinforcement Learning with Last-Token Self-Rewarding）的新算法，通过在原始RLVR损失中增加一个MSE损失，使LLM的自奖励分数与基于验证器的推理奖励对齐，从而在不显著降低效率的情况下，联合优化LLM的推理和自奖励能力。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在测试时缺乏验证信号，因此通常需要训练模型进行自我验证。然而，当前的做法需要LLM使用两个独立的提示模板按顺序生成解决方案和自我验证，这显著降低了效率。

Method: 本文理论上揭示了自验证RL目标的闭式解可以简化为一个简单的形式：解决方案的真实推理奖励等于其最后令牌的自奖励分数。基于这一洞察，作者提出了LaSeR算法。LaSeR通过在原始RLVR损失中增加一个MSE损失，该损失将最后令牌的自奖励分数与基于验证器的推理奖励对齐，共同优化LLM的推理和自奖励能力。该算法仅需在生成后立即推断一个额外令牌，以最小的额外成本获得这些分数。

Result: 实验结果表明，LaSeR不仅提高了模型的推理性能，还赋予模型显著的自奖励能力，从而提升了其推理时间的扩展性能。

Conclusion: LaSeR算法通过将LLM的推理和自奖励能力统一在一个LLM中，并利用最后令牌的自奖励分数来提高效率，成功解决了现有RLVR方法的效率问题。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a core paradigm for enhancing the reasoning capabilities of Large Language
Models (LLMs). To address the lack of verification signals at test time, prior
studies incorporate the training of model's self-verification capability into
the standard RLVR process, thereby unifying reasoning and verification
capabilities within a single LLM. However, previous practice requires the LLM
to sequentially generate solutions and self-verifications using two separate
prompt templates, which significantly reduces efficiency. In this work, we
theoretically reveal that the closed-form solution to the RL objective of
self-verification can be reduced to a remarkably simple form: the true
reasoning reward of a solution is equal to its last-token self-rewarding score,
which is computed as the difference between the policy model's next-token
log-probability assigned to any pre-specified token at the solution's last
token and a pre-calculated constant, scaled by the KL coefficient. Based on
this insight, we propose LaSeR (Reinforcement Learning with Last-Token
Self-Rewarding), an algorithm that simply augments the original RLVR loss with
a MSE loss that aligns the last-token self-rewarding scores with verifier-based
reasoning rewards, jointly optimizing the reasoning and self-rewarding
capabilities of LLMs. The optimized self-rewarding scores can be utilized in
both training and testing to enhance model performance. Notably, our algorithm
derives these scores from the predicted next-token probability distribution of
the last token immediately after generation, incurring only the minimal extra
cost of one additional token inference. Experiments show that our method not
only improves the model's reasoning performance but also equips it with
remarkable self-rewarding capability, thereby boosting its inference-time
scaling performance.

</details>


### [100] [MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics](https://arxiv.org/abs/2510.14944)
*Yuxing Lu,Xukai Zhao,J. Ben Tamo,Micky C. Nnamdi,Rui Peng,Shuang Zeng,Xingyu Hu,Jinzhuo Wang,May D. Wang*

Main category: cs.CL

TL;DR: MetaBench是首个用于评估大型语言模型在代谢组学领域能力的基准测试，它揭示了LLM在该领域面临的挑战，并为未来的AI系统开发提供了基础设施。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在通用文本方面表现出色，但在需要深度互联知识的专业科学领域（如代谢组学）中的能力尚未得到充分评估。代谢组学面临着复杂的生化途径、异构识别系统和分散数据库的独特挑战。

Method: 本文引入了MetaBench，这是第一个用于代谢组学评估的基准测试。MetaBench从权威公共资源中精选数据，评估了代谢组学研究所需的五种基本能力：知识、理解、归因、推理和研究。

Result: 对25个开源和闭源LLM的评估显示，模型在代谢组学任务中表现出不同的性能模式：在文本生成任务上表现良好，但即使通过检索增强，跨数据库标识符归因仍然具有挑战性。模型在稀疏注释的长尾代谢物上的性能也有所下降。

Conclusion: MetaBench为开发和评估代谢组学AI系统提供了必要的基础设施，有助于在代谢组学研究中实现可靠计算工具的系统化进展。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities on
general text; however, their proficiency in specialized scientific domains that
require deep, interconnected knowledge remains largely uncharacterized.
Metabolomics presents unique challenges with its complex biochemical pathways,
heterogeneous identifier systems, and fragmented databases. To systematically
evaluate LLM capabilities in this domain, we introduce MetaBench, the first
benchmark for metabolomics assessment. Curated from authoritative public
resources, MetaBench evaluates five capabilities essential for metabolomics
research: knowledge, understanding, grounding, reasoning, and research. Our
evaluation of 25 open- and closed-source LLMs reveals distinct performance
patterns across metabolomics tasks: while models perform well on text
generation tasks, cross-database identifier grounding remains challenging even
with retrieval augmentation. Model performance also decreases on long-tail
metabolites with sparse annotations. With MetaBench, we provide essential
infrastructure for developing and evaluating metabolomics AI systems, enabling
systematic progress toward reliable computational tools for metabolomics
research.

</details>


### [101] [DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation](https://arxiv.org/abs/2510.14949)
*Yu Zhou,Sohyun An,Haikang Deng,Da Yin,Clark Peng,Cho-Jui Hsieh,Kai-Wei Chang,Nanyun Peng*

Main category: cs.CL

TL;DR: 本文研究了多模态生成模型在处理方言文本输入时面临的挑战，并提出了一种新的基准测试和一种通用的编码器缓解策略，以提高模型对方言的理解能力，同时保持标准美式英语性能。


<details>
  <summary>Details</summary>
Motivation: 探索多模态生成模型在处理方言文本输入时是否存在性能下降以及如何缓解这些下降。

Method: 1. 构建了一个包含六种常见英语方言的大规模基准数据集，收集并验证了4200多个独特的提示。 2. 在17种图像和视频生成模型上进行了评估。 3. 进行了自动和人工评估。 4. 设计了一种通用的基于编码器的缓解策略。

Result: 1. 当前最先进的多模态生成模型在使用单个方言词作为提示时，性能会下降32.26%到48.17%。 2. 常见的缓解方法（如微调和提示重写）只能将方言性能提高不到7%，并可能导致标准美式英语性能显著下降。 3. 作者提出的方法能够使模型的方言性能与标准美式英语S AE性能持平，同时对SAE性能的损失几乎为零。

Conclusion: 多模态生成模型在处理方言输入时存在显著的性能下降。本文提出的基于编码器的缓解策略，通过教授模型识别新的方言特征，在保持标准美式英语性能的同时，显著提高了模型在方言上的表现。

Abstract: Contact languages like English exhibit rich regional variations in the form
of dialects, which are often used by dialect speakers interacting with
generative models. However, can multimodal generative models effectively
produce content given dialectal textual input? In this work, we study this
question by constructing a new large-scale benchmark spanning six common
English dialects. We work with dialect speakers to collect and verify over 4200
unique prompts and evaluate on 17 image and video generative models. Our
automatic and human evaluation results show that current state-of-the-art
multimodal generative models exhibit 32.26% to 48.17% performance degradation
when a single dialect word is used in the prompt. Common mitigation methods
such as fine-tuning and prompt rewriting can only improve dialect performance
by small margins (< 7%), while potentially incurring significant performance
degradation in Standard American English (SAE). To this end, we design a
general encoder-based mitigation strategy for multimodal generative models. Our
method teaches the model to recognize new dialect features while preserving SAE
performance. Experiments on models such as Stable Diffusion 1.5 show that our
method is able to simultaneously raise performance on five dialects to be on
par with SAE (+34.4%), while incurring near zero cost to SAE performance.

</details>


### [102] [TokDrift: When LLM Speaks in Subwords but Code Speaks in Grammar](https://arxiv.org/abs/2510.14972)
*Yinxi Li,Yuntian Deng,Pengyu Nie*

Main category: cs.CL

TL;DR: 本文介绍了TokDrift框架，用于评估代码大模型中子词 tokenization 的影响。研究发现，即使是微小的格式更改，也会导致模型行为的显著变化。这个问题源于早期嵌入层中子词分割未能捕获语法 token 边界。


<details>
  <summary>Details</summary>
Motivation: 目前代码LLMs依赖的子词分词器，是基于统计而非语法，导致语义相同的代码片段可能因表面因素（如空格、命名）而被不同地分词。这促使我们探究此错位的影响。

Method: 我们引入了TokDrift框架，该框架应用语义保留的重写规则来创建仅在tokenization上有所不同的代码变体。我们对九个代码LLM（包括超过300亿参数的大型LLM）进行了评估，并进行了分层分析。

Result: 研究发现，即使是微小的格式更改，也会导致九个代码LLM的模型行为发生显著变化。分层分析表明，问题源于早期嵌入层中子词分割未能捕获语法token边界。

Conclusion: 本文发现，错位的tokenization是代码理解和生成中一个隐蔽的障碍。这凸显了未来的代码LLM需要语法感知的tokenization。

Abstract: Large language models (LLMs) for code rely on subword tokenizers, such as
byte-pair encoding (BPE), learned from mixed natural language text and
programming language code but driven by statistics rather than grammar. As a
result, semantically identical code snippets can be tokenized differently
depending on superficial factors such as whitespace or identifier naming. To
measure the impact of this misalignment, we introduce TokDrift, a framework
that applies semantic-preserving rewrite rules to create code variants
differing only in tokenization. Across nine code LLMs, including large ones
with over 30B parameters, even minor formatting changes can cause substantial
shifts in model behavior. Layer-wise analysis shows that the issue originates
in early embeddings, where subword segmentation fails to capture grammar token
boundaries. Our findings identify misaligned tokenization as a hidden obstacle
to reliable code understanding and generation, highlighting the need for
grammar-aware tokenization for future code LLMs.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [103] [Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks](https://arxiv.org/abs/2510.13979)
*Supriti Sinhamahapatra,Jan Niehues*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的多模态自动语音识别（ASR）系统，该系统利用视觉信息（包括说话人图像和演示幻灯片）来提高识别准确性，尤其是在特定领域术语方面。


<details>
  <summary>Details</summary>
Motivation: 现有的最先进自动语音识别（ASR）系统主要依赖声学信息，忽略了多模态上下文，而视觉信息在消除歧义和适应性方面至关重要。

Method: 本研究首先创建了一个多模态演示文稿基准，并自动分析了特定领域术语的转录。然后，探索了使用多模态信息增强语音模型的方法，并通过数据增强来解决缺乏带幻灯片数据集的问题。最后，使用增强数据集训练模型。

Result: 与基线模型相比，该模型在所有词汇上的词错误率相对降低了约34%，在特定领域术语上的词错误率相对降低了35%。

Conclusion: 通过将演示幻灯片和说话人图像等多模态信息融入ASR系统，可以显著提高语音识别的准确性，尤其是在处理特定领域术语时。

Abstract: State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily
rely on acoustic information while disregarding additional multi-modal context.
However, visual information are essential in disambiguation and adaptation.
While most work focus on speaker images to handle noise conditions, this work
also focuses on integrating presentation slides for the use cases of scientific
presentation.
  In a first step, we create a benchmark for multi-modal presentation including
an automatic analysis of transcribing domain-specific terminology. Next, we
explore methods for augmenting speech models with multi-modal information. We
mitigate the lack of datasets with accompanying slides by a suitable approach
of data augmentation. Finally, we train a model using the augmented dataset,
resulting in a relative reduction in word error rate of approximately 34%,
across all words and 35%, for domain-specific terms compared to the baseline
model.

</details>


### [104] [Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment](https://arxiv.org/abs/2510.13985)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Giovanni Franco Gabriel Marraffini,Mario Alejandro Leiva,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLMs）在因果判断任务中是否存在因果错觉。研究发现，LLMs在缺乏支持证据的情况下系统性地推断出不合理的因果关系，表明它们易受因果错觉的影响。


<details>
  <summary>Details</summary>
Motivation: 因果学习是认知过程中的重要组成部分，但容易出现因果错觉。因果错觉是许多社会问题的根源，如社会偏见、刻板印象、错误信息和迷信思想。目前尚不清楚大型语言模型（LLMs）是否也存在这种认知偏差。

Method: 本文构建了一个包含1,000个零偶发场景的数据集，这些场景在医疗背景下缺乏足够的证据来建立变量之间的因果关系。然后，使用这些场景提示LLMs评估潜在原因的有效性。

Result: 所有评估模型都系统地推断出不合理的因果关系，显示出对因果错觉的强烈敏感性。

Conclusion: LLMs似乎不真正理解因果关系，而只是在没有真正理解的情况下复制因果语言。这项研究对在需要准确因果推理以做出明智决策的领域中使用语言模型提出了担忧。

Abstract: Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this work,
we examine whether large language models are prone to developing causal
illusions when faced with a classic cognitive science paradigm: the contingency
judgment task. To investigate this, we constructed a dataset of 1,000 null
contingency scenarios (in which the available information is not sufficient to
establish a causal relationship between variables) within medical contexts and
prompted LLMs to evaluate the effectiveness of potential causes. Our findings
show that all evaluated models systematically inferred unwarranted causal
relationships, revealing a strong susceptibility to the illusion of causality.
While there is ongoing debate about whether LLMs genuinely understand causality
or merely reproduce causal language without true comprehension, our findings
support the latter hypothesis and raise concerns about the use of language
models in domains where accurate causal reasoning is essential for informed
decision-making.

</details>


### [105] [STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management](https://arxiv.org/abs/2510.14112)
*Huiliang Zhang,Di Wu,Arnaud Zinflou,Benoit Boulet*

Main category: cs.AI

TL;DR: 该论文提出了一个名为STEMS的框架，用于协调多建筑能源管理。该框架融合了GCN-Transformer和避障控制，实现了显著的成本和排放降低，并增强了安全性。


<details>
  <summary>Details</summary>
Motivation: 建筑能源管理对于实现碳减排目标至关重要。目前多建筑能源系统在利用时空依赖性、确保运行安全和系统复杂性方面面临挑战。

Method: 本研究提出了一个名为STEMS（Spatial-Temporal Enhanced Safe Multi-Agent Coordination）的框架。该框架包含两个核心组件：1.一个使用GCN-Transformer融合架构的时空图表示学习框架，用于捕获建筑间的关系和时间模式。2.一个结合控制障碍函数的安全约束多智能体强化学习算法，以提供数学安全保证。

Result: 在真实世界建筑数据集上的广泛实验表明，STEMS的性能优于现有方法。该框架实现了21%的成本降低和18%的排放减少，并将安全违规从35.1%大幅降低到5.6%，同时将不适比例维持在0.13的水平。

Conclusion: STEMS框架在极端天气条件下也表现出强大的鲁棒性，并且在不同类型的建筑中都保持了有效性。

Abstract: Building energy management is essential for achieving carbon reduction goals,
improving occupant comfort, and reducing energy costs. Coordinated building
energy management faces critical challenges in exploiting spatial-temporal
dependencies while ensuring operational safety across multi-building systems.
Current multi-building energy systems face three key challenges: insufficient
spatial-temporal information exploitation, lack of rigorous safety guarantees,
and system complexity. This paper proposes Spatial-Temporal Enhanced Safe
Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent
reinforcement learning framework for coordinated building energy management.
STEMS integrates two core components: (1) a spatial-temporal graph
representation learning framework using a GCN-Transformer fusion architecture
to capture inter-building relationships and temporal patterns, and (2) a
safety-constrained multi-agent RL algorithm incorporating Control Barrier
Functions to provide mathematical safety guarantees. Extensive experiments on
real-world building datasets demonstrate STEMS's superior performance over
existing methods, showing that STEMS achieves 21% cost reduction, 18% emission
reduction, and dramatically reduces safety violations from 35.1% to 5.6% while
maintaining optimal comfort with only 0.13 discomfort proportion. The framework
also demonstrates strong robustness during extreme weather conditions and
maintains effectiveness across different building types.

</details>


### [106] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 该文章提出了一种轻量级多模态架构，融合传感器数据和视觉图像，用于预测文化遗产地的退化程度，并在斯特拉斯堡大教堂的数据集上取得了显著的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 传统监测方法依赖单一模态分析，未能捕捉环境压力源与材料劣deng化之间复杂的相互作用，从而无法有效应对气候变化对文化遗产地造成的加速退deng化问题。

Method: 本文提出了一种轻量级多模态架构，该架构将传感器数据（温度、湿度）与视觉图像融合，以预测文化遗产地的退deng化程度。该方法在 PerceiverIO 的基础上进行了两项创新：1) 简化的编码器（64D 潜在空间）以防止在小型数据集上过拟合；2) 自适应 Barlow Twins 损失，以鼓励模态互补而非冗余。

Result: 在斯特拉斯堡大教堂的数据上，该模型取得了 76.9% 的准确率，比标准多模态架构（VisualBERT、Transformer）提高了 43%，比 vanilla PerceiverIO 提高了 25%。消融研究表明，仅使用传感器数据准确率为 61.5%，仅使用图像数据准确率为 46.2%，这证实了多模态协同作用的成功。系统性的超参数研究确定了最佳的适度相关目标（τ=0.3），在对齐和互补性之间取得了平衡，准确率达到 69.2%。

Conclusion: 结构简洁性与对比正则化相结合，可以在数据稀缺的文化遗产监测场景中实现有效的多模态学习，为人工智能驱动的保护决策支持系统奠定基础。

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [107] [JEDA: Query-Free Clinical Order Search from Ambient Dialogues](https://arxiv.org/abs/2510.14169)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Amitabh Saikia,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: JEDA是一种领域初始化的双编码器，它直接检索规范的临床医嘱，并在免查询模式下编码一小段环境对话，以触发检索。JEDA的训练采用受限的LLM指导，将签署的医嘱与互补的表述（仅命令、仅上下文、命令+上下文、上下文+推理）联系起来，从而产生更清晰的医嘱间分离、更紧密的查询-医嘱耦合和更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 许多系统依赖于大型语言模型（LLM）的重写，这增加了延迟、不稳定性和不透明性，阻碍了实时医嘱的发布。

Method: JEDA（Joint Embedding for Direct and Ambient clinical orders）是一种领域初始化的双编码器，它直接检索规范的医嘱，并在免查询模式下编码一小段环境对话以触发检索。JEDA从PubMedBERT初始化，并通过重复安全对比目标进行微调，将异构意图表达与共享医嘱概念对齐。训练使用受限的LLM指导将每个签署的医嘱与互补的表述（仅命令、仅上下文、命令+上下文、上下文+推理）联系起来。

Result: JEDA在实际部署中取得了显著的成果，性能远超其基础编码器和最近的开放嵌入器（如Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma）。其免查询模式具有抗噪能力，通过对短时间窗口而非单一话语进行条件处理，降低了对不流畅和ASR错误的敏感性。

Conclusion: JEDA提供了一个快速、可解释、无需LLM的检索层，能够实时将环境上下文与可执行的临床医嘱关联起来。

Abstract: Clinical conversations mix explicit directives (order a chest X-ray) with
implicit reasoning (the cough worsened overnight, we should check for
pneumonia). Many systems rely on LLM rewriting, adding latency, instability,
and opacity that hinder real-time ordering. We present JEDA (Joint Embedding
for Direct and Ambient clinical orders), a domain-initialized bi-encoder that
retrieves canonical orders directly and, in a query-free mode, encodes a short
rolling window of ambient dialogue to trigger retrieval. Initialized from
PubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA
aligns heterogeneous expressions of intent to shared order concepts. Training
uses constrained LLM guidance to tie each signed order to complementary
formulations (command only, context only, command+context, context+reasoning),
producing clearer inter-order separation, tighter query extendash order
coupling, and stronger generalization. The query-free mode is noise-resilient,
reducing sensitivity to disfluencies and ASR errors by conditioning on a short
window rather than a single utterance. Deployed in practice, JEDA yields large
gains and substantially outperforms its base encoder and recent open embedders
(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The
result is a fast, interpretable, LLM-free retrieval layer that links ambient
context to actionable clinical orders in real time.

</details>


### [108] [ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning](https://arxiv.org/abs/2510.14176)
*Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth*

Main category: cs.AI

TL;DR: ARM-FM是一个利用基础模型自动构建奖励机器的RL框架，用于解决奖励函数规范的敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 强化学习算法对奖励函数规范高度敏感，这限制了其广泛应用。

Method: ARM-FM框架通过基础模型自动构建奖励机器（RMs），RMs是一种基于自动机的奖励规范形式。具体方法包括：1) 使用基础模型从自然语言规范中自动生成RMs；2) 将语言嵌入与每个RM自动机状态关联，以实现跨任务泛化。

Result: ARM-FM在各种具有挑战性的环境中表现出有效性，包括零样本泛化能力。

Conclusion: ARM-FM通过利用基础模型和奖励机器，实现了RL中自动化、组合式的奖励设计，解决了奖励函数规范的挑战，并展现了良好的泛化能力。

Abstract: Reinforcement learning (RL) algorithms are highly sensitive to reward
function specification, which remains a central challenge limiting their broad
applicability. We present ARM-FM: Automated Reward Machines via Foundation
Models, a framework for automated, compositional reward design in RL that
leverages the high-level reasoning capabilities of foundation models (FMs).
Reward machines (RMs) -- an automata-based formalism for reward specification
-- are used as the mechanism for RL objective specification, and are
automatically constructed via the use of FMs. The structured formalism of RMs
yields effective task decompositions, while the use of FMs enables objective
specifications in natural language. Concretely, we (i) use FMs to automatically
generate RMs from natural language specifications; (ii) associate language
embeddings with each RM automata-state to enable generalization across tasks;
and (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse
suite of challenging environments, including evidence of zero-shot
generalization.

</details>


### [109] [Implementation of AI in Precision Medicine](https://arxiv.org/abs/2510.14194)
*Göktuğ Bender,Samer Faraj,Anand Bhardwaj*

Main category: cs.AI

TL;DR: 人工智能在精准医疗领域日益重要，但临床实施有限。本研究旨在通过范围界定审查，识别2019-2024年人工智能在精准医疗实施中的关键障碍和促成因素，并提出未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 人工智能在精准医疗领域的作用日益增强，能够整合和解释多模态数据，但其在临床环境中的实施仍然有限。

Method: 本文对2019-2024年期间关于人工智能在精准医疗中实施的文献进行了范围界定审查，并通过一个基于生态系统的框架，识别了数据质量、临床可靠性、工作流程整合和治理方面的关键障碍和促成因素。

Result: 通过生态系统框架，本研究强调了影响现实世界转化的相互依赖关系。

Conclusion: 为了支持值得信赖和可持续的实施，本研究提出了未来的发展方向。

Abstract: Artificial intelligence (AI) has become increasingly central to precision
medicine by enabling the integration and interpretation of multimodal data, yet
implementation in clinical settings remains limited. This paper provides a
scoping review of literature from 2019-2024 on the implementation of AI in
precision medicine, identifying key barriers and enablers across data quality,
clinical reliability, workflow integration, and governance. Through an
ecosystem-based framework, we highlight the interdependent relationships
shaping real-world translation and propose future directions to support
trustworthy and sustainable implementation.

</details>


### [110] [Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](https://arxiv.org/abs/2510.14207)
*Trilok Padhi,Pinxian Lu,Abdulkadir Erol,Tanmay Sutar,Gauri Sharma,Mina Sonmez,Munmun De Choudhury,Ugur Kursuncu*

Main category: cs.AI

TL;DR: 本文介绍了在线骚扰智能体基准，包括合成的多轮骚扰对话数据集、基于重复博弈论的多智能体模拟、针对LLM智能体的三种越狱方法以及混合方法评估框架。研究发现，越狱调优可以显著提高骚扰成功率，并导致智能体表现出类似人类的攻击行为模式。


<details>
  <summary>Details</summary>
Motivation: 目前针对大型语言模型（LLM）智能体的越狱研究主要集中在单轮提示上，而真实的骚扰行为往往发生在多轮交互中。

Method: 1. 构建了在线骚扰智能体基准，包含：合成多轮骚扰对话数据集、基于重复博弈论的多智能体模拟、三种针对智能体的越狱方法（攻击内存、规划和微调）。
2. 使用两个LLM模型（LLaMA-3.1-8B-Instruct和Gemini-2.0-flash）进行实验。
3. 采用混合方法进行评估。

Result: 1. 越狱调优显著提高了骚扰成功率：Llama模型中从57.25%–64.19%提高到95.78%–96.89%，Gemini模型中从98.46%提高到99.33%。
2. 越狱调优将两个模型的拒绝率大幅降低至1%-2%。
3. 最普遍的有毒行为是侮辱（84.9%–87.8% vs. 未调优时的44.2%–50.8%）和煽动（81.2%–85.1% vs. 未调优时的31.5%–38.8%），表明这些方面防护较弱。
4. 被攻击的智能体表现出类似人类的攻击行为模式，如马基雅维利/精神病式规划和自恋记忆倾向。
5. 闭源和开源模型在多轮交互中表现出不同的升级轨迹，闭源模型显示出显著的脆弱性。

Conclusion: 多轮和基于理论的攻击不仅成功率高，而且能模拟类似人类的骚扰动态，这促使我们开发更强大的安全防护措施，以确保在线平台的安全性和责任性。

Abstract: Large Language Model (LLM) agents are powering a growing share of interactive
web applications, yet remain vulnerable to misuse and harm. Prior jailbreak
research has largely focused on single-turn prompts, whereas real harassment
often unfolds over multi-turn interactions. In this work, we present the Online
Harassment Agentic Benchmark consisting of: (i) a synthetic multi-turn
harassment conversation dataset, (ii) a multi-agent (e.g., harasser, victim)
simulation informed by repeated game theory, (iii) three jailbreak methods
attacking agents across memory, planning, and fine-tuning, and (iv) a
mixed-methods evaluation framework. We utilize two prominent LLMs,
LLaMA-3.1-8B-Instruct (open-source) and Gemini-2.0-flash (closed-source). Our
results show that jailbreak tuning makes harassment nearly guaranteed with an
attack success rate of 95.78--96.89% vs. 57.25--64.19% without tuning in Llama,
and 99.33% vs. 98.46% without tuning in Gemini, while sharply reducing refusal
rate to 1-2% in both models. The most prevalent toxic behaviors are Insult with
84.9--87.8% vs. 44.2--50.8% without tuning, and Flaming with 81.2--85.1% vs.
31.5--38.8% without tuning, indicating weaker guardrails compared to sensitive
categories such as sexual or racial harassment. Qualitative evaluation further
reveals that attacked agents reproduce human-like aggression profiles, such as
Machiavellian/psychopathic patterns under planning, and narcissistic tendencies
with memory. Counterintuitively, closed-source and open-source models exhibit
distinct escalation trajectories across turns, with closed-source models
showing significant vulnerability. Overall, our findings show that multi-turn
and theory-grounded attacks not only succeed at high rates but also mimic
human-like harassment dynamics, motivating the development of robust safety
guardrails to ultimately keep online platforms safe and responsible.

</details>


### [111] [Towards Agentic Self-Learning LLMs in Search Environment](https://arxiv.org/abs/2510.14253)
*Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: 本文探讨了LLM（大型语言模型）智能体在没有人为标注数据或预定义规则奖励的情况下，如何通过自学习进行规模化。
研究发现，生成式奖励模型（GRM）的回报优于刚性的基于规则的信号，并且GRM与策略的共同进化能进一步提升性能。增加智能体任务数据的量也能显著增强智能体能力。本文提出了一个名为“Agentic Self-Learning”（ASL）的完全闭环、多角色强化学习框架。ASL通过协调“Prompt Generator”、“Policy Model”和“Generative Reward Model”形成一个良性循环。实验证明，ASL持续改进，超越了其他基线模型，并且在零标记数据条件下依然表现出色。


<details>
  <summary>Details</summary>
Motivation: 研究LLM智能体如何在没有人工标注数据或预定义规则奖励的情况下，实现规模化的自学习。

Method: 本文提出了一个名为“Agentic Self-Learning”（ASL）的完全闭环、多角色强化学习框架。该框架统一了任务生成、策略执行和评估，并通过协调“Prompt Generator”、“Policy Model”和“Generative Reward Model”形成一个良性循环。

Result: ASL实现了持续的、逐轮的性能提升，超越了强RLVR基线模型，并且在零标记数据条件下也能持续改进，这表明其具有卓越的样本效率和鲁棒性。研究还发现，GRM的验证能力是主要的瓶颈：如果GRM固定不变，会导致奖励作弊并阻碍进展；通过持续训练GRM以适应不断演变的数据分布，可以缓解这一问题；在后期注入少量真实验证数据可以提高性能上限。

Conclusion: 奖励来源和数据规模是开放域智能体学习的关键因素，多角色协同进化对于可伸缩、自改进的智能体是有效的。

Abstract: We study whether self-learning can scale LLM-based agents without relying on
human-curated datasets or predefined rule-based rewards. Through controlled
experiments in a search-agent setting, we identify two key determinants of
scalable agent training: the source of reward signals and the scale of agent
task data. We find that rewards from a Generative Reward Model (GRM) outperform
rigid rule-based signals for open-domain learning, and that co-evolving the GRM
with the policy further boosts performance. Increasing the volume of agent task
data-even when synthetically generated-substantially enhances agentic
capabilities. Building on these insights, we propose \textbf{Agentic
Self-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning
framework that unifies task generation, policy execution, and evaluation within
a shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,
a Policy Model, and a Generative Reward Model to form a virtuous cycle of
harder task setting, sharper verification, and stronger solving. Empirically,
ASL delivers steady, round-over-round gains, surpasses strong RLVR baselines
(e.g., Search-R1) that plateau or degrade, and continues improving under
zero-labeled-data conditions, indicating superior sample efficiency and
robustness. We further show that GRM verification capacity is the main
bottleneck: if frozen, it induces reward hacking and stalls progress; continual
GRM training on the evolving data distribution mitigates this, and a small
late-stage injection of real verification data raises the performance ceiling.
This work establishes reward source and data scale as critical levers for
open-domain agent learning and demonstrates the efficacy of multi-role
co-evolution for scalable, self-improving agents. The data and code of this
paper are released at
https://github.com/forangel2014/Towards-Agentic-Self-Learning

</details>


### [112] [MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning](https://arxiv.org/abs/2510.14265)
*Xukai Wang,Xuanbo Liu,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Bohan Zeng,Jinbo Hu,Hao Liang,Junbo Niu,Xuchen Li,Ruitao Wu,Ruichuan An,Yang Shi,Liu Liu,Xu-Yao Zhang,Qiang Liu,Zhouchen Lin,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: 本文提出了MorphoBench，这是一个多学科推理基准，它能够根据大型模型的推理能力调整问题难度，以更有效地评估模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型模型推理能力评估基准范围有限，且缺乏根据模型推理能力演变调整难度的灵活性，无法有效评估模型的推理能力。

Method: 通过整合来自现有基准和奥林匹克竞赛等来源的复杂推理问题构建，并利用模型推理过程中生成的关键语句自适应地修改分析挑战，同时结合模拟软件生成问题，以动态调整基准难度。

Result: MorphoBench收集了超过1300个测试问题，并根据o3和GPT-5等模型的推理能力迭代调整了难度。

Conclusion: MorphoBench提高了模型推理评估的全面性和有效性，为提升大型模型的推理能力和科学稳健性提供了可靠指导。

Abstract: With the advancement of powerful large-scale reasoning models, effectively
evaluating the reasoning capabilities of these models has become increasingly
important. However, existing benchmarks designed to assess the reasoning
abilities of large models tend to be limited in scope and lack the flexibility
to adapt their difficulty according to the evolving reasoning capacities of the
models. To address this, we propose MorphoBench, a benchmark that incorporates
multidisciplinary questions to evaluate the reasoning capabilities of large
models and can adjust and update question difficulty based on the reasoning
abilities of advanced models. Specifically, we curate the benchmark by
selecting and collecting complex reasoning questions from existing benchmarks
and sources such as Olympiad-level competitions. Additionally, MorphoBench
adaptively modifies the analytical challenge of questions by leveraging key
statements generated during the model's reasoning process. Furthermore, it
includes questions generated using simulation software, enabling dynamic
adjustment of benchmark difficulty with minimal resource consumption. We have
gathered over 1,300 test questions and iteratively adjusted the difficulty of
MorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.
MorphoBench enhances the comprehensiveness and validity of model reasoning
evaluation, providing reliable guidance for improving both the reasoning
abilities and scientific robustness of large models. The code has been released
in https://github.com/OpenDCAI/MorphoBench.

</details>


### [113] [Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies](https://arxiv.org/abs/2510.14312)
*Mason Nakamura,Abhinav Kumar,Saaduddin Mahmud,Sahar Abdelnabi,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: Terrarium是一个用于研究基于大语言模型的多智能体系统安全性、隐私性和安全性的框架，提供了可配置的测试平台来识别和抵御各种攻击。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）驱动的多智能体系统尽管能够自动化复杂任务，但其设计引入了新的风险，如不对齐问题、恶意攻击以及用户数据泄露。

Method: 我们提出了Terrarium框架，该框架借鉴了多智能体系统中的“黑板设计”理念，构建了一个模块化、可配置的测试平台，用于细致地研究基于LLM的多智能体系统中的安全性、隐私性和安全性问题。

Result: Terrarium框架识别了不对齐、恶意智能体、受损通信和数据投毒等关键攻击向量。我们通过实现三种协作多智能体系统场景和四种代表性攻击，展示了该框架的灵活性。

Conclusion: Terrarium旨在通过提供快速原型开发、评估和迭代防御及设计的工具，加速可信多智能体系统领域的发展。

Abstract: A multi-agent system (MAS) powered by large language models (LLMs) can
automate tedious user tasks such as meeting scheduling that requires
inter-agent collaboration. LLMs enable nuanced protocols that account for
unstructured private data, user constraints, and preferences. However, this
design introduces new risks, including misalignment and attacks by malicious
parties that compromise agents or steal user data. In this paper, we propose
the Terrarium framework for fine-grained study on safety, privacy, and security
in LLM-based MAS. We repurpose the blackboard design, an early approach in
multi-agent systems, to create a modular, configurable testbed for multi-agent
collaboration. We identify key attack vectors such as misalignment, malicious
agents, compromised communication, and data poisoning. We implement three
collaborative MAS scenarios with four representative attacks to demonstrate the
framework's flexibility. By providing tools to rapidly prototype, evaluate, and
iterate on defenses and designs, Terrarium aims to accelerate progress toward
trustworthy multi-agent systems.

</details>


### [114] [Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction](https://arxiv.org/abs/2510.14319)
*Xu Shen,Qi Zhang,Song Wang,Zhen Tan,Xinyu Zhao,Laura Yao,Vaishnav Tadiparthi,Hossein Nourkhiz Mahjoub,Ehsan Moradi Pari,Kwonjoon Lee,Tianlong Chen*

Main category: cs.AI

TL;DR: 本文介绍了一个名为 MASC 的元认知框架，旨在为基于大型语言模型的多智能体系统提供实时、无监督、步骤级的错误检测和自校正能力，有效解决了错误传播问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型的多智能体系统在协作解决问题方面表现出色，但容易出现级联错误，即单个错误步骤可能在智能体之间传播并破坏整个执行路径。

Method: MASC 框架通过两种互补设计重新定义了错误检测为历史条件下的异常评分：1. 下一步执行重建（Next-Execution Reconstruction），通过查询和交互历史预测下一步骤的嵌入，以捕捉因果一致性；2. 原型引导增强（Prototype-Guided Enhancement），学习正常步骤嵌入的原型先验，并在上下文稀疏（例如，早期步骤）时稳定重建和异常评分。当异常步骤被标记时，MASC 会触发一个校正智能体，在信息向下游流动之前修正 acting 智能体的输出。

Result: 在 Who&When 基准测试中，MASC 始终优于所有基线，将步骤级错误检测的 AUC-ROC 提高了高达 8.47%；当应用于不同的多智能体框架时，它在各种架构中都提供了持续的端到端增益。

Conclusion: MASC 通过元认知监控和有针对性的校正，能够以最小的开销有效缓解错误传播问题，显著提高了多智能体系统的鲁棒性。

Abstract: Large Language Model based multi-agent systems (MAS) excel at collaborative
problem solving but remain brittle to cascading errors: a single faulty step
can propagate across agents and disrupt the trajectory. In this paper, we
present MASC, a metacognitive framework that endows MAS with real-time,
unsupervised, step-level error detection and self-correction. MASC rethinks
detection as history-conditioned anomaly scoring via two complementary designs:
(1) Next-Execution Reconstruction, which predicts the embedding of the next
step from the query and interaction history to capture causal consistency, and
(2) Prototype-Guided Enhancement, which learns a prototype prior over
normal-step embeddings and uses it to stabilize reconstruction and anomaly
scoring under sparse context (e.g., early steps). When an anomaly step is
flagged, MASC triggers a correction agent to revise the acting agent's output
before information flows downstream. On the Who&When benchmark, MASC
consistently outperforms all baselines, improving step-level error detection by
up to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers
consistent end-to-end gains across architectures, confirming that our
metacognitive monitoring and targeted correction can mitigate error propagation
with minimal overhead.

</details>


### [115] [AI for Service: Proactive Assistance with AI Glasses](https://arxiv.org/abs/2510.14359)
*Zichen Wen,Yiyu Wang,Chenfei Liao,Boxue Yang,Junxian Li,Weifeng Liu,Haocong He,Bolong Feng,Xuyang Liu,Yuanhuiyi Lyu,Xu Zheng,Xuming Hu,Linfeng Zhang*

Main category: cs.AI

TL;DR: AI4Service是一个通过主动和实时协助人们日常生活的AI新范式。


<details>
  <summary>Details</summary>
Motivation: 现有的AI服务大多是被动的，只响应明确的用户命令。我们认为一个真正智能和有帮助的助手应该能够预测用户需求，并在适当的时候主动采取行动。

Method: 我们提出了Alpha-Service，一个统一的框架，解决了两个基本挑战：知道何时通过从自我中心视频流中检测服务机会进行干预，以及知道如何提供通用和个性化服务。Alpha-Service由五个关键组件组成：用于感知的输入单元、用于任务调度的中央处理单元、用于工具利用的算术逻辑单元、用于长期个性化的内存单元和用于自然人机交互的输出单元。我们通过在AI眼镜上部署多智能体系统来实现Alpha-Service。

Result: 案例研究，包括一个实时二十一点顾问、一个博物馆导游和一个购物搭配助手，展示了它无缝感知环境、推断用户意图和在没有明确提示的情况下提供及时有用协助的能力。

Conclusion: AI4Service通过Alpha-Service框架，实现了AI从被动工具到主动和自适应伙伴的转变，为日常生活提供主动和实时的帮助。

Abstract: In an era where AI is evolving from a passive tool into an active and
adaptive companion, we introduce AI for Service (AI4Service), a new paradigm
that enables proactive and real-time assistance in daily life. Existing AI
services remain largely reactive, responding only to explicit user commands. We
argue that a truly intelligent and helpful assistant should be capable of
anticipating user needs and taking actions proactively when appropriate. To
realize this vision, we propose Alpha-Service, a unified framework that
addresses two fundamental challenges: Know When to intervene by detecting
service opportunities from egocentric video streams, and Know How to provide
both generalized and personalized services. Inspired by the von Neumann
computer architecture and based on AI glasses, Alpha-Service consists of five
key components: an Input Unit for perception, a Central Processing Unit for
task scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit
for long-term personalization, and an Output Unit for natural human
interaction. As an initial exploration, we implement Alpha-Service through a
multi-agent system deployed on AI glasses. Case studies, including a real-time
Blackjack advisor, a museum tour guide, and a shopping fit assistant,
demonstrate its ability to seamlessly perceive the environment, infer user
intent, and provide timely and useful assistance without explicit prompts.

</details>


### [116] [Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?](https://arxiv.org/abs/2510.14387)
*Yijie Hu,Zihao Zhou,Kaizhu Huang,Xiaowei Huang,Qiufeng Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为 IP-Merging 的方法，旨在弥合多模态大语言模型（MLLMs）和数学大语言模型（Math LLMs）在数学推理能力上的差距，该方法无需微调即可提高 MLLMs 的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前，大语言模型在数学推理方面取得了显著进展，但多模态大语言模型的数学推理能力仍显不足。由于多模态大语言模型通常由一个大语言模型和一个视觉模块组成，作者想知道多模态大语言模型是否可以直接从现成的数学大语言模型中吸收数学推理能力，而无需进行调整。

Method: 作者提出了 IP-Merging 方法。首先识别 MLLM 和 Math LLM 中与推理相关的参数，然后将它们投影到 MLLM 的子空间中，旨在保持对齐，最后在该子空间中合并参数。IP-Merging 是一种无需调整的方法，因为参数是直接调整的。

Result: 实验证明 IP-Merging 方法可以显著增强多模态大语言模型的数学推理能力，而不会损害其其他能力。

Conclusion: IP-Merging 方法通过识别和合并与推理相关的参数，有效地将数学大语言模型的数学推理能力转移到多模态大语言模型中，且无需进行微调，为提高多模态大语言模型的数学推理能力提供了一种有效途径。

Abstract: Math reasoning has been one crucial ability of large language models (LLMs),
where significant advancements have been achieved in recent years. However,
most efforts focus on LLMs by curating high-quality annotation data and
intricate training (or inference) paradigms, while the math reasoning
performance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM
typically consists of an LLM and a vision block, we wonder: Can MLLMs directly
absorb math reasoning abilities from off-the-shelf math LLMs without tuning?
Recent model-merging approaches may offer insights into this question. However,
they overlook the alignment between the MLLM and LLM, where we find that there
is a large gap between their parameter spaces, resulting in lower performance.
Our empirical evidence reveals two key factors behind this issue: the
identification of crucial reasoning-associated layers in the model and the
mitigation of the gaps in parameter space. Based on the empirical insights, we
propose IP-Merging that first identifies the reasoning-associated parameters in
both MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to
maintain the alignment, and finally merges parameters in this subspace.
IP-Merging is a tuning-free approach since parameters are directly adjusted.
Extensive experiments demonstrate that our IP-Merging method can enhance the
math reasoning ability of MLLMs directly from Math LLMs without compromising
their other capabilities.

</details>


### [117] [IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning](https://arxiv.org/abs/2510.14406)
*Xikai Zhang,Bo Wang,Likang Xiao,Yongzhi Li,Quan Chen,Wenju Wu,Liu Liu*

Main category: cs.AI

TL;DR: IMAGINE框架将多智能体系统的推理和规划能力集成到单个模型中，并通过端到端训练显著超越了多智能体系统的性能，在TravelPlanner数据集上将Qwen3-8B-Instruct的准确率从5.9%提升到82.7%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理和规划方面面临挑战，即使是GPT-4o在特定任务上也表现不佳，而多智能体系统虽然能改善集体推理，但存在推理成本高、延迟长和难以端到端训练的问题。

Method: 提出IMAGINE框架，将多智能体系统的推理和规划能力集成到单个紧凑模型中，并通过简单的端到端训练显著提升其能力。

Result: 使用IMAGINE框架训练Qwen3-8B-Instruct模型后，在TravelPlanner基准测试中达到了82.7%的最终通过率，远超DeepSeek-R1-671B的40%，且模型规模更小。

Conclusion: IMAGINE框架成功地将多智能体系统的优势融入到单一模型中，解决了LLMs在复杂推理和规划上的不足以及MAS的高成本问题，取得了显著的性能提升。

Abstract: Although large language models (LLMs) have made significant strides across
various tasks, they still face significant challenges in complex reasoning and
planning. For example, even with carefully designed prompts and prior
information explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on
the TravelPlanner dataset in the sole-planning mode. Similarly, even in the
thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass
Rates of 5.9% and 40%, respectively. Although well-organized Multi-Agent
Systems (MAS) can offer improved collective reasoning, they often suffer from
high reasoning costs due to multi-round internal interactions, long
per-response latency, and difficulties in end-to-end training. To address these
challenges, we propose a general and scalable framework called IMAGINE, short
for Integrating Multi-Agent System into One Model. This framework not only
integrates the reasoning and planning capabilities of MAS into a single,
compact model, but also significantly surpass the capabilities of the MAS
through a simple end-to-end training. Through this pipeline, a single
small-scale model is not only able to acquire the structured reasoning and
planning capabilities of a well-organized MAS but can also significantly
outperform it. Experimental results demonstrate that, when using
Qwen3-8B-Instruct as the base model and training it with our method, the model
achieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding
the 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.

</details>


### [118] [Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms](https://arxiv.org/abs/2510.14412)
*Claudia Grundke,Gabriele Röger*

Main category: cs.AI

TL;DR: PDDL公理中可以消除派生谓词的负向出现。


<details>
  <summary>Details</summary>
Motivation: PDDL标准限制了公理体中谓词的负向出现，但文献中常有偏离，仅要求公理集可分层。这两种变体都可以表达与最小不动点逻辑完全相同的查询。

Method: 提出了一种变换方法来消除派生谓词的负向出现。

Result: 通过这个变换，可以消除PDDL公理中派生谓词的负向出现。

Conclusion: PDDL公理中派生谓词的负向出现可以通过所提出的变换方法消除。

Abstract: Axioms are a feature of the Planning Domain Definition Language PDDL that can
be considered as a generalization of database query languages such as Datalog.
The PDDL standard restricts negative occurrences of predicates in axiom bodies
to predicates that are directly set by actions and not derived by axioms. In
the literature, authors often deviate from this limitation and only require
that the set of axioms is stratifiable. Both variants can express exactly the
same queries as least fixed-point logic, indicating that negative occurrences
of derived predicates can be eliminated. We present the corresponding
transformation.

</details>


### [119] [Beyond Hallucinations: The Illusion of Understanding in Large Language Models](https://arxiv.org/abs/2510.14665)
*Rikard Rosenbacke,Carl Rosenbacke,Victor Rosenbacke,Martin McKee*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个名为Rose-Frame的三维框架，用于诊断人机交互中大型语言模型的认知和认知漂移，旨在提高人工智能部署的透明度和批判性意识。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在人类交流和决策中日益普及，但它们继承了语言固有的模糊性、偏见和缺乏真相直接获取能力的问题。LLM的输出虽然流畅、情感共鸣且连贯，但它们是通过统计预测而不是基于推理生成的，这导致了幻觉的风险，即听起来令人信服但缺乏事实有效性的响应。

Method: 本文引入了一个名为Rose-Frame的三维框架来诊断人机交互中的认知和认知漂移。该框架的三个维度是：(i) 地图与疆域，区分现实的表征（认识论）与现实本身（本体论）；(ii) 直觉与理性，借鉴双过程理论将快速、情感判断与缓慢、反思性思维区分开来；(iii) 冲突与确认，检查观点是通过异议进行批判性测试还是通过相互验证简单地得到强化。

Result: Rose-Frame框架为诊断人机交互中的认知和认知漂移提供了一个工具。每个维度都捕捉到一种独特的失败模式，它们的组合会放大不对齐。Rose-Frame不试图通过更多数据或规则来修复LLM，而是提供一个反思工具，使模型的局限性和用户的假设都可见，从而实现更透明和更具批判性意识的AI部署。

Conclusion: 只有通过嵌入反思性的、可证伪的监督，我们才能使机器的流畅性与人类的理解保持一致。人类或人工智能的直觉必须始终受人类理性的支配。

Abstract: Large language models (LLMs) are becoming deeply embedded in human
communication and decision-making, yet they inherit the ambiguity, bias, and
lack of direct access to truth inherent in language itself. While their outputs
are fluent, emotionally resonant, and coherent, they are generated through
statistical prediction rather than grounded reasoning. This creates the risk of
hallucination, responses that sound convincing but lack factual validity.
Building on Geoffrey Hinton's observation that AI mirrors human intuition
rather than reasoning, this paper argues that LLMs operationalize System 1
cognition at scale: fast, associative, and persuasive, but without reflection
or falsification. To address this, we introduce the Rose-Frame, a
three-dimensional framework for diagnosing cognitive and epistemic drift in
human-AI interaction. The three axes are: (i) Map vs. Territory, which
distinguishes representations of reality (epistemology) from reality itself
(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to
separate fast, emotional judgments from slow, reflective thinking; and (iii)
Conflict vs. Confirmation, which examines whether ideas are critically tested
through disagreement or simply reinforced through mutual validation. Each
dimension captures a distinct failure mode, and their combination amplifies
misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.
Instead, it offers a reflective tool that makes both the model's limitations
and the user's assumptions visible, enabling more transparent and critically
aware AI deployment. It reframes alignment as cognitive governance: intuition,
whether human or artificial, must remain governed by human reason. Only by
embedding reflective, falsifiable oversight can we align machine fluency with
human understanding.

</details>


### [120] [Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review](https://arxiv.org/abs/2510.14669)
*Sara Altamirano,Arjan Vreeken,Sennay Ghebreab*

Main category: cs.AI

TL;DR: 该研究系统地回顾了2021-2025年荷兰公共卫生机器学习研究中算法偏差的识别、讨论和报告情况，并提出了RABAT工具和ACAR框架，旨在帮助研究人员解决机器学习生命周期中的公平性问题，并为公共卫生机器学习实践者提供相关建议。


<details>
  <summary>Details</summary>
Motivation: 机器学习在公共卫生领域具有巨大潜力，但算法偏差可能加剧现有健康不平等。因此，本研究旨在系统地分析和解决公共卫生机器学习研究中的算法偏差问题。

Method: 1. 开发了“算法偏差风险评估工具”（RABAT），该工具整合了Cochrane偏倚风险、PROBAST和Microsoft负责任AI清单等现有框架的要素。 2. 将RABAT应用于35项经过同行评审的研究。 3. 基于分析结果，提出了一个名为ACAR（意识、概念化、应用、报告）的四阶段公平导向框架，并提供了指导性问题。

Result: 1. 荷兰公共卫生机器学习研究在算法偏差处理方面存在普遍不足。 2. 数据抽样和缺失数据处理得到了较好记录，但大多数研究忽略了明确的公平性框架、亚组分析以及对潜在危害的透明讨论。

Conclusion: 本研究旨在提高公共卫生机器学习实践者对算法偏差的认识，并通过ACAR框架和RABAT工具，促进机器学习应用的公平性和透明度，以确保算法创新能够促进而非损害健康公平。研究还为实践者提供了系统性地考虑算法偏差并提高透明度的可行性建议。

Abstract: Machine learning (ML) promises to revolutionize public health through
improved surveillance, risk stratification, and resource allocation. However,
without systematic attention to algorithmic bias, ML may inadvertently
reinforce existing health disparities. We present a systematic literature
review of algorithmic bias identification, discussion, and reporting in Dutch
public health ML research from 2021 to 2025. To this end, we developed the Risk
of Algorithmic Bias Assessment Tool (RABAT) by integrating elements from
established frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible
AI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals
pervasive gaps: although data sampling and missing data practices are well
documented, most studies omit explicit fairness framing, subgroup analyses, and
transparent discussion of potential harms. In response, we introduce a
four-stage fairness-oriented framework called ACAR (Awareness,
Conceptualization, Application, Reporting), with guiding questions derived from
our systematic literature review to help researchers address fairness across
the ML lifecycle. We conclude with actionable recommendations for public health
ML practitioners to consistently consider algorithmic bias and foster
transparency, ensuring that algorithmic innovations advance health equity
rather than undermine it.

</details>


### [121] [Practical, Utilitarian Algorithm Configuration](https://arxiv.org/abs/2510.14683)
*Devon Graham,Kevin Leyton-Brown*

Main category: cs.AI

TL;DR: 本文介绍了对COUP算法的改进，使其在保持理论保证的同时，提高了实用性能，并使其与启发式配置方法具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 最大化用户效用，因为旧的COUP算法在实用性能方面表现不佳。

Method: 通过一系列改进来提升COUP算法的经验性能，但同时不损害其理论保证，并通过实验证明其改进效果。并探讨了给定解决方案对算法选择问题中效用函数变化的鲁棒性。

Result: 改进后的COUP算法在实用性能上与广泛使用的启发式配置程序具有竞争力。

Conclusion: COUP算法的改进使其在理论和实践之间取得了更好的平衡，使其在效用算法配置方面更具竞争力。

Abstract: Utilitarian algorithm configuration identifies a parameter setting for a
given algorithm that maximizes a user's utility. Utility functions offer a
theoretically well-grounded approach to optimizing decision-making under
uncertainty and are flexible enough to capture a user's preferences over
algorithm runtimes (e.g., they can describe a sharp cutoff after which a
solution is no longer required, a per-hour cost for compute, or diminishing
returns from algorithms that take longer to run). COUP is a recently-introduced
utilitarian algorithm configuration procedure which was designed mainly to
offer strong theoretical guarantees about the quality of the configuration it
returns, with less attention paid to its practical performance. This paper
closes that gap, bringing theoretically-grounded, utilitarian algorithm
configuration to the point where it is competitive with widely used, heuristic
configuration procedures that offer no performance guarantees. We present a
series of improvements to COUP that improve its empirical performance without
degrading its theoretical guarantees and demonstrate their benefit
experimentally. Using a case study, we also illustrate ways of exploring the
robustness of a given solution to the algorithm selection problem to variations
in the utility function.

</details>


### [122] [Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging](https://arxiv.org/abs/2510.14697)
*Bang An,Yibo Yang,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: 这篇文章介绍了一种名为 PAVE (Purifying TAsk Vectors) 的方法，旨在通过在知识感知子空间中提炼任务向量，解决模型合并过程中因任务向量中的冗余信息引起性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法中，任务向量是基本构建模块，但合并后的模型常因任务向量中任务不相关的冗余信息导致的冲突而显著降低性能。现有的消除冗余的方法涉及随机性且缺乏知识感知。

Method: PAVE 方法通过对每个任务的微调模型，利用训练样本获取线性层前的协方差矩阵，然后进行上下文导向的奇异值分解，以突出与目标知识最相关的权重分量。通过这种方式，可以将微调模型权重分解为任务相关和冗余组件，并在知识感知子空间中通过修剪冗余组件来净化任务向量。为了在不同模型之间实现公平的修剪，PAVE 引入了一种通过优化归一化激活修剪误差来实现的谱秩分配策略。

Result: PAVE 作为一种即插即用的方案，可以应用于各种基于任务向量的合并方法，以提高其性能。实验结果表明 PAVE 在不同的合并方法、任务和模型架构上都有效。

Conclusion: PAVE 方法通过在知识感知子空间中净化任务向量，有效解决了模型合并中冗余信息导致的性能下降问题，提高了合并模型的性能和鲁棒性。

Abstract: Model merging aims to integrate task-specific abilities from individually
fine-tuned models into a single model without extra training. In recent model
merging methods, task vector has become a fundamental building block, as it can
encapsulate the residual information from finetuning. However, the merged model
often suffers from notable performance degradation due to the conflicts caused
by task-irrelevant redundancy in task vectors. Existing efforts in overcoming
redundancy by randomly dropping elements in the parameter space involves
randomness and lacks knowledge awareness. To address these challenges, in this
study, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.
Concretely, we sample some training examples from each task, and feed them into
their corresponding fine-tuned models to acquire the covariance matrices before
linear layers. We then perform a context-oriented singular value decomposition,
which accentuates the weight components most relevant to the target knowledge.
As a result, we can split fine-tuned model weights into task-relevant and
redundant components in the knowledge-aware subspace, and purify the task
vector by pruning the redundant components. To induce fair pruning efforts
across models, we further introduce a spectral rank allocation strategy by
optimizing a normalized activated pruning error. The task vector purification
by our method as a plug-and-play scheme is applicable across various task
vector-based merging methods to improve their performance. In experiments, we
demonstrate the effectiveness of PAVE across a diverse set of merging methods,
tasks, and model architectures.

</details>


### [123] [Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](https://arxiv.org/abs/2510.14702)
*Penglong Zhai,Jie Li,Fanyi Di,Yue Liu,Yifang Yuan,Jie Huang,Peng Wu,Sicong Wang,Mingyang Yin,Tingting Hu,Yao Xu,Xin Li*

Main category: cs.AI

TL;DR: 本文提出了CoAST框架，它利用大型语言模型（LLMs）结合世界知识、时空轨迹模式、用户画像和情境信息，通过知识获取和认知对齐两个阶段来提高POI推荐的准确性和用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有的LLMs在POI推荐任务中缺乏对地理实体和时序移动模式的理解。在工业级的POI预测应用中，结合世界知识和人类认知（如季节、天气、节假日、用户档案等）可以提升推荐性能和用户体验。

Method: CoAST框架主要分为两个阶段：1. 推荐知识获取：通过对脱敏用户的时空轨迹数据进行持续预训练。2. 认知对齐：利用SFT和RL阶段，通过丰富的训练数据使认知判断与人类偏好对齐。

Result: 在多个真实世界数据集上的离线实验和在AMAP App首页的“猜你去哪”中的在线实验都证明了CoAST的有效性。

Conclusion: CoAST框架通过结合世界知识、时空轨迹模式和用户画像，并利用两阶段方法（知识获取和认知对齐）来克服现有LLMs在POI推荐中的不足，显著提升了推荐效果。

Abstract: The next point-of-interest (POI) recommendation task aims to predict the
users' immediate next destinations based on their preferences and historical
check-ins, holding significant value in location-based services. Recently,
large language models (LLMs) have shown great potential in recommender systems,
which treat the next POI prediction in a generative manner. However, these
LLMs, pretrained primarily on vast corpora of unstructured text, lack the
native understanding of structured geographical entities and sequential
mobility patterns required for next POI prediction tasks. Moreover, in
industrial-scale POI prediction applications, incorporating world knowledge and
alignment of human cognition, such as seasons, weather conditions, holidays,
and users' profiles (such as habits, occupation, and preferences), can enhance
the user experience while improving recommendation performance. To address
these issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a
framework employing natural language as an interface, allowing for the
incorporation of world knowledge, spatio-temporal trajectory patterns,
profiles, and situational information. Specifically, CoAST mainly comprises of
2 stages: (1) Recommendation Knowledge Acquisition through continued
pretraining on the enriched spatial-temporal trajectory data of the
desensitized users; (2) Cognitive Alignment to align cognitive judgments with
human preferences using enriched training data through Supervised Fine-Tuning
(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline
experiments on various real-world datasets and online experiments deployed in
"Guess Where You Go" of AMAP App homepage demonstrate the effectiveness of
CoAST.

</details>


### [124] [ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling](https://arxiv.org/abs/2510.14703)
*Jianghao Lin,Yuanyuan Shi,Xin Peng,Renjie Ding,Hairui Wang,Yuxuan Peng,Bizhe Bai,Weixi Song,Fengshuo Bai,Huacan Chai,Weinan Zhang,Fei Huang,Ying Wen*

Main category: cs.AI

TL;DR: 该论文提出了一个结合细粒度集束搜索和过程奖励模型ToolPRM的推理扩展框架，以提高大语言模型在函数调用任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 目前对大语言模型的推理扩展研究主要集中在非结构化输出生成任务上，而其在函数调用等结构化输出中的应用尚未得到充分探索。

Method: 提出了一个结合细粒度集束搜索和过程奖励模型ToolPRM的推理扩展框架。ToolPRM通过对每个函数调用的内部步骤进行评分。为了训练ToolPRM，构建了第一个细粒度的内部调用过程监督数据集，该数据集通过函数掩蔽技术自动标注，为结构化工具使用推理提供步骤级奖励。

Result: ToolPRM在预测准确性方面优于粗粒度奖励模型和结果奖励模型。配备ToolPRM的推理扩展技术显著提高了主干模型在各种函数调用任务和基准上的性能。

Conclusion: 为结构化输出应用推理扩展技术揭示了一个关键原则：“多探索，少保留”，这源于结构化函数调用生成不可恢复的特性。

Abstract: Large language models (LLMs) are increasingly demonstrating strong
capabilities as autonomous agents, with function calling serving as a core
mechanism for interaction with the environment. Meanwhile, inference scaling
has become a cutting-edge technique to enhance LLM performance by allocating
more computational resources during the inference process. However, current
research on inference scaling primarily focuses on unstructured output
generation tasks, leaving its application in structured outputs, like function
calling, largely underexplored. To bridge this gap, we propose an inference
scaling framework that combines fine-grained beam search with a process reward
model, ToolPRM, which scores the internal steps of each single function call.
To train ToolPRM, we construct the first fine-grained intra-call process
supervision dataset, automatically annotated with function-masking techniques
to provide step-level rewards for structured tool-use reasoning. Extensive
experiments demonstrate that ToolPRM beats the coarse-grained and outcome
reward models in terms of predictive accuracy, indicating its stronger
capability in supervising the function calling inference process. Inference
scaling technique equipped with ToolPRM also significantly improves the
backbone model performance across various function calling tasks and
benchmarks. More importantly, we reveal a key principle for applying inference
scaling techniques to structured outputs: "explore more but retain less" due to
the unrecoverability characteristics of structured function calling generation.

</details>


### [125] [SimKO: Simple Pass@K Policy Optimization](https://arxiv.org/abs/2510.14807)
*Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen*

Main category: cs.AI

TL;DR: RLVR方法在通过率@1上表现良好，但在通过率@K（K>1）上表现不佳，SimKO方法通过不对称地调整语言模型输出概率来解决RLVR方法过度集中的问题，从而提高了通过率@K。


<details>
  <summary>Details</summary>
Motivation: RLVR（可验证奖励强化学习）方法在通过率@1上表现良好，但在通过率@K（K>1）上表现不佳，这表明其存在过度利用而非探索的系统性偏差。

Method: 本文分析了RLVR方法的训练动态，发现“概率集中效应”，即前1个候选词的概率质量不断累积，抑制了其他候选词。作者提出SimKO（Simple Pass@K Optimization）方法，通过不对称地调整语言模型输出概率来缓解过度集中问题。对于经验证正确的响应，SimKO会提高前K个候选词的概率。对于经验证不正确的响应，它会对前1个候选词施加更强的惩罚。

Result: SimKO方法在各种数学和逻辑推理基准测试中，在很大范围的K值下持续提高了通过率@K，为改善RLVR的探索提供了一种简单的方法。

Conclusion: SimKO通过不对称地调整语言模型输出概率，成功缓解了RLVR方法中存在的过度集中问题，从而提高了模型在多种任务上的探索能力和整体性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has advanced the
reasoning capabilities of large language models (LLMs). However, prevailing
RLVR methods exhibit a systematic bias toward exploitation over exploration, as
evidenced by improved pass@1 but reduced pass@K (K>1) performance. To
understand this issue, we analyze training dynamics of RLVR methods by tracking
the token-level probability distributions over vocabulary candidates. Our
analysis reveals a consistent probability concentration effect where the top-1
candidate increasingly accumulates probability mass and suppresses that of
other candidates. More importantly, stronger over-concentration correlates with
worse pass@K performance. Inspired by this finding, we propose Simple Pass@K
Optimization (SimKO), a method designed to mitigate the over-concentration
issue, thereby encouraging exploration. SimKO operates in an asymmetrical
manner. For verified-correct responses, it boosts the probabilities of the
top-K candidates. For verified-incorrect responses, it applies stronger
penalties to the top-1 candidate. We observe that this asymmetric design is
particularly effective at mitigating over-concentration when applied at tokens
with high entropy. Across various math and logical-reasoning benchmarks, SimKO
consistently yields higher pass@K for a wide range of K, providing a simple way
to improve RLVR's exploration.

</details>


### [126] [Agentic NL2SQL to Reduce Computational Costs](https://arxiv.org/abs/2510.14808)
*Dominik Jehle,Lennart Purucker,Frank Hutter*

Main category: cs.AI

TL;DR: Datalake Agent是一个agentic系统，它能够帮助LLMs更高效地解决NL2SQL任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在将自然语言查询转换为SQL查询（NL2SQL或Text-to-SQL）方面取得了显著进展。然而，在大规模SQL数据库上使用LLMs进行NL2SQL方法时，需要处理大量的数据库元信息，这会导致提示过长、token数量多以及处理成本高。

Method: 本文引入了Datalake Agent，一个agentic系统，旨在使LLM更有效地解决NL2SQL任务。Datalake Agent采用交互式循环来减少使用的元信息，而不是使用直接的NL2SQL求解器一次性将所有元信息包含在prompt中调用LLM。在循环中，LLM在一个推理框架中使用，该框架选择性地只请求解决表格问答任务所需的必要信息。

Result: Datalake Agent在包含23个数据库和100个表格问答任务的集合上进行了评估。结果表明，Datalake Agent可以将LLM使用的token数量减少高达87%，从而在保持竞争性能的同时大幅降低成本。

Conclusion: Datalake Agent通过交互式循环和选择性信息请求，有效地解决了LLMs在NL2SQL任务中处理大量元信息导致成本高昂的问题，实现了显著的token减少和成本降低，同时保持了良好的性能。

Abstract: Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)
has recently been empowered by large language models (LLMs). Using LLMs to
perform NL2SQL methods on a large collection of SQL databases necessitates
processing large quantities of meta-information about the databases, which in
turn results in lengthy prompts with many tokens and high processing costs. To
address this challenge, we introduce Datalake Agent, an agentic system designed
to enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing
direct solvers for NL2SQL that call the LLM once with all meta-information in
the prompt, the Datalake Agent employs an interactive loop to reduce the
utilized meta-information. Within the loop, the LLM is used in a reasoning
framework that selectively requests only the necessary information to solve a
table question answering task. We evaluate the Datalake Agent on a collection
of 23 databases with 100 table question answering tasks. The Datalake Agent
reduces the tokens used by the LLM by up to 87\% and thus allows for
substantial cost reductions while maintaining competitive performance.

</details>


### [127] [RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning](https://arxiv.org/abs/2510.14828)
*Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li*

Main category: cs.AI

TL;DR: 本文提出了RoboGPT-R1，一个两阶段具身规划微调框架，通过监督学习和强化学习，提升机器人在复杂真实环境中完成长期操作任务的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管基于SFT的大型语言模型和视觉语言模型在规划任务中取得成功，但它们在复杂真实环境中的长期操作任务中面临挑战，原因在于其有限的常识和推理能力，以及在机器人规划任务中泛化性差和物理理解不足。

Method: 本文提出了RoboGPT-R1，一个两阶段具身规划微调框架。第一阶段通过专家序列进行监督训练，获取基础知识；第二阶段利用强化学习解决模型在视觉空间理解和推理方面的不足。为了实现多步推理任务中的物理理解和动作序列一致性，设计了一个同时考虑长期性能和环境中动作约束的基于规则的奖励函数。

Result: 在EmbodiedBench基准测试中，基于Qwen2.5-VL-3B训练的推理模型RoboGPT-R1，显著优于更大规模的GPT-4o-mini模型21.33%，并超越其他基于Qwen2.5-VL-7B训练的工作20.33%。

Conclusion: RoboGPT-R1框架通过结合监督学习和强化学习，以及设计有效的奖励函数，显著提升了具身智能体在长期操作任务中的推理能力和泛化性，在EmbodiedBench基准测试中表现出色。

Abstract: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.

</details>


### [128] [Boosting Instruction Following at Scale](https://arxiv.org/abs/2510.14842)
*Ben Elder,Evelyn Duesterwald,Vinod Muthusamy*

Main category: cs.AI

TL;DR: Instruction Boosting是一种后处理方法，可以提高LLM指令遵循的可靠性，而SCALEDIF是一个用于衡量指令遵循性能的基准。


<details>
  <summary>Details</summary>
Motivation: 开发人员常常通过精心编写提示来影响LLM的行为，但单纯增加指令并不能保证其被遵循。

Method: 本文提出了一种名为Instruction Boosting的后生成方法，旨在提高LLM提示指令的可靠性。同时，引入了SCALEDIF基准，该基准具有高达每个数据样本十条指令的扩展指令量。此外，还提出了一个量化冲突评分工具。

Result: Instruction Boosting将两条指令的遵循率提高了7个点，将十条指令的遵循率提高了4个点。分析表明，指令数量增加导致的性能下降，一个重要因素是指令之间产生的紧张和冲突程度。量化冲突评分工具能够解释观察到的性能趋势。

Conclusion: Instruction Boosting可以有效提高LLM指令遵循的可靠性，并且指令间的冲突是影响LLM性能的关键因素。量化冲突评分工具有助于开发者理解额外提示指令对模型性能的影响。

Abstract: A typical approach developers follow to influence an LLM's behavior in an
application is through careful manipulation of the prompt, such as by adding or
modifying instructions. However, merely adding more instructions provides
little assurance that they will actually be followed. We introduce Instruction
Boosting as a post-generation method to increase the reliability of LLM prompt
instructions. We show that Instruction Boosting improves the instruction
following rate by up to 7 points for two instructions and up to 4 points for
ten instructions. To demonstrate these results we introduce SCALEDIF, a
benchmark with a scaled instruction volume of up to ten instructions per data
sample. We also present an analysis of the commonly observed trend that
performance degrades as more instructions are added. We show that an important
factor contributing to this trend is the degree of tension and conflict that
arises as the number of instructions is increased. We contribute a quantitative
conflict scoring tool that explains the observed performance trends and
provides feedback to developers on the impact that additional prompt
instructions have on a model's performance.

</details>


### [129] [Where to Search: Measure the Prior-Structured Search Space of LLM Agents](https://arxiv.org/abs/2510.14846)
*Zhuo-Yang Song*

Main category: cs.AI

TL;DR: 这篇论文提出了一种紧凑的形式理论，用于描述和衡量由领域先验引导的LLM辅助迭代搜索，并通过模糊关系算子表示智能体，引入连续性参数来衡量可达性难度，并提供了可测试的推论。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在AI+Science领域的推理、编程和程序发现方面取得了进展，但搜索效率受限于如何将领域先验编码到操作性结构化的假设空间中。

Method: 通过将智能体表示为输入和输出上的模糊关系算子，以捕捉可行的转换，并将其约束在固定的安全范围内。通过对所有可达路径加权，并引入一个连续性参数求和，得到一个覆盖生成函数，从而衡量可达性难度。

Result: 提供了一种可工作的语言和操作工具来衡量智能体及其搜索空间，并对LLM构建的迭代搜索进行了系统的形式化描述。通过多数投票实例化验证了最简单的可测试推论。

Conclusion: 该理论提供了一种系统化的方法来理解和优化LLM在迭代搜索中的应用，通过形式化描述和量化搜索过程，有望提升基于LLM的搜索效率和可靠性。

Abstract: The generate-filter-refine (iterative paradigm) based on large language
models (LLMs) has achieved progress in reasoning, programming, and program
discovery in AI+Science. However, the effectiveness of search depends on where
to search, namely, how to encode the domain prior into an operationally
structured hypothesis space. To this end, this paper proposes a compact formal
theory that describes and measures LLM-assisted iterative search guided by
domain priors. We represent an agent as a fuzzy relation operator on inputs and
outputs to capture feasible transitions; the agent is thereby constrained by a
fixed safety envelope. To describe multi-step reasoning/search, we weight all
reachable paths by a single continuation parameter and sum them to obtain a
coverage generating function; this induces a measure of reachability
difficulty; and it provides a geometric interpretation of search on the graph
induced by the safety envelope. We further provide the simplest testable
inferences and validate them via a majority-vote instantiation. This theory
offers a workable language and operational tools to measure agents and their
search spaces, proposing a systematic formal description of iterative search
constructed by LLMs.

</details>


### [130] [Budget-aware Test-time Scaling via Discriminative Verification](https://arxiv.org/abs/2510.14913)
*Kyle Montgomery,Sijun Tan,Yuqi Chen,Siyuan Zhuang,Tianjun Zhang,Raluca Ada Popa,Chenguang Wang*

Main category: cs.AI

TL;DR: 本文提出了一种结合判别式验证器和自洽性的混合方法，可以在固定计算预算下，显著提高大型语言模型在复杂推理任务上的性能，超越了生成式验证器。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理任务中，测试时缩放是一种有效的提升性能的策略，但现有最先进的生成式验证器方法计算成本过高，限制了其实用性。

Method: 本文提出了一种判别式验证与自洽性相结合的混合方法，用于提高大型语言模型在复杂推理任务中的性能。

Result: 在固定计算预算下，该混合方法在AIME2025数据集上的准确率比最先进的生成式验证方法高出15.3%。

Conclusion: 对于实际的真实世界应用，结合判别式验证器的预算感知缩放不仅是自洽性方法的“免费”升级，而且是比昂贵的生成技术更有效、更高效的替代方案。

Abstract: Test-time scaling is a powerful strategy for boosting the performance of
large language models on complex reasoning tasks. While state-of-the-art
approaches often employ generative verifiers to select the best solution from a
pool of candidates, this method incurs prohibitive computational costs,
limiting its practicality. In this work, we shift the focus to a more
budget-aware paradigm: discriminative verification. We conduct a thorough
empirical analysis and demonstrate that while discriminative verifiers may
underperform in isolation, combining them with self-consistency in a hybrid
approach creates a powerful and efficient test-time scaling mechanism. Notably,
under a fixed compute budget, this hybrid approach surpasses state-of-the-art
generative verification by a significant margin: achieving up to 15.3\% higher
accuracy on AIME2025. Our findings establish that for practical, real-world
applications, budget-aware scaling with discriminative verifiers is not only a
"free" upgrade over self-consistency, but also a more effective and efficient
alternative to costly generative techniques. Code is available at
https://github.com/wang-research-lab/verification.

</details>


### [131] [TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](https://arxiv.org/abs/2510.14922)
*Annisaa Fitri Nurfidausi,Eleonora Mancini,Paolo Torroni*

Main category: cs.AI

TL;DR: 这篇论文系统地探讨了脑电图、语音和文本在抑郁症自动检测中的特征表示和建模策略，并通过多模态融合实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管抑郁症是一种普遍的精神疾病，但其自动检测仍然具有挑战性。现有的研究在范围上有限，缺乏特征的系统比较，并且评估协议不一致。

Method: 通过使用一致的独立受试者分割，系统地探索了脑电图、语音和文本的特征表示和建模策略。评估了手工特征与预训练嵌入，比较了不同神经编码器的有效性，并分析了单模态、双模态和三模态配置以及融合策略，特别关注了脑电图的作用。

Result: 1. 脑电图、语音和文本模态的结合增强了多模态检测。2. 预训练嵌入优于手工特征。3. 精心设计的三模态模型实现了最先进的性能。

Conclusion: 这项工作为多模态抑郁症检测的未来研究奠定了基础。

Abstract: Depression is a widespread mental health disorder, yet its automatic
detection remains challenging. Prior work has explored unimodal and multimodal
approaches, with multimodal systems showing promise by leveraging complementary
signals. However, existing studies are limited in scope, lack systematic
comparisons of features, and suffer from inconsistent evaluation protocols. We
address these gaps by systematically exploring feature representations and
modelling strategies across EEG, together with speech and text. We evaluate
handcrafted features versus pre-trained embeddings, assess the effectiveness of
different neural encoders, compare unimodal, bimodal, and trimodal
configurations, and analyse fusion strategies with attention to the role of
EEG. Consistent subject-independent splits are applied to ensure robust,
reproducible benchmarking. Our results show that (i) the combination of EEG,
speech and text modalities enhances multimodal detection, (ii) pretrained
embeddings outperform handcrafted features, and (iii) carefully designed
trimodal models achieve state-of-the-art performance. Our work lays the
groundwork for future research in multimodal depression detection.

</details>


### [132] [Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models](https://arxiv.org/abs/2510.14925)
*Akira Okutomi*

Main category: cs.AI

TL;DR: 这篇论文将康德的《纯粹理性批判》重新解读为一种反馈稳定性理论，并提出H-Risk指数来衡量推理系统中的不稳定性和过度自信。研究发现，不稳定的内部动力学与大型语言模型中的错误校准和幻觉相关。


<details>
  <summary>Details</summary>
Motivation: 作者旨在通过反馈稳定性的视角重新解释康德的《纯粹理性批判》，并为推理系统（包括大型语言模型）中的过度自信和幻觉提供一种诊断和减少的方法。

Method: 论文提出了一种复合不稳定性指数（H-Risk），该指数结合了频谱裕度、条件、时间敏感性和创新放大。作者首先在线性高斯模拟中验证了H-Risk指数预测过度自信错误的能力，然后将其扩展到大型语言模型，研究其内部动力学与校准和幻觉之间的关系。

Result: 研究发现，在线性高斯模拟中，即使在形式稳定的情况下，较高的H-Risk也能预测过度自信的错误。对于大型语言模型，不稳定的内部动力学与错误校准和幻觉相关。而批判式提示对校准和幻觉的影响复杂多变。

Conclusion: 这项研究在康德的自我限制概念和反馈控制之间建立了一个结构性桥梁，为诊断和有选择地减少推理系统中的过度自信提供了一个原则性的视角。

Abstract: We reinterpret Kant's Critique of Pure Reason as a theory of feedback
stability, viewing reason as a regulator that keeps inference within the bounds
of possible experience. We formalize this intuition via a composite instability
index (H-Risk) combining spectral margin, conditioning, temporal sensitivity,
and innovation amplification. In linear-Gaussian simulations, higher H-Risk
predicts overconfident errors even under formal stability, revealing a gap
between nominal and epistemic stability. Extending to large language models
(LLMs), we find that fragile internal dynamics correlate with miscalibration
and hallucination, while critique-style prompts show mixed effects on
calibration and hallucination. These results suggest a structural bridge
between Kantian self-limitation and feedback control, offering a principled
lens for diagnosing -- and selectively reducing -- overconfidence in reasoning
systems. This is a preliminary version; supplementary experiments and broader
replication will be reported in a future revision.

</details>


### [133] [GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning](https://arxiv.org/abs/2510.14942)
*Yao Zhang,Yu Wu,Haowei Zhang,Weiguo Li,Haokun Chen,Jingpei Wu,Guohao Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: GroundedPRM: 一个基于MCTS和外部工具验证的自动过程监督框架，它解决了现有过程奖励模型（PRM）中奖励噪声、事实保真度低和与分步推理目标不一致的问题，在ProcessBench上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的过程奖励模型（PRM）在构建过程中面临挑战，主要原因是缺乏可扩展、高质量的标注。目前的方法依赖于昂贵的人工标注、易产生幻觉的LLM自我评估或蒙特卡洛（MC）估计（容易引入噪声和信用归因错误），导致奖励噪声、事实保真度低以及与分步推理目标不一致。

Method: GroundedPRM通过蒙特卡洛树搜索（MCTS）构建结构化的推理路径，以减少奖励噪声并实现细粒度的信用分配。它使用外部工具验证每个中间步骤，以消除幻觉监督并提供基于执行的正确性信号。该方法设计了一种混合奖励聚合机制，将基于工具的验证与MCTS反馈融合。最后，它将奖励信号格式化为一种增强理据的生成结构。

Result: GroundedPRM仅使用4万个自动标注样本（仅占性能最佳的PRM所需数据的10%），在ProcessBench上的平均性能相对提高了26%。当用于奖励引导的贪婪搜索时，GroundedPRM甚至优于使用人工标注监督训练的PRM。

Conclusion: GroundedPRM为高质量过程级推理提供了一种可扩展且可验证的路径，解决了现有PRM在奖励生成和准确性方面存在的问题。它通过MCTS和外部工具验证的结合，显著提升了多步推理任务中LLMs的性能。

Abstract: Process Reward Models (PRMs) aim to improve multi-step reasoning in Large
Language Models (LLMs) by supervising intermediate steps and identifying
errors. However, building effective PRMs remains challenging due to the lack of
scalable, high-quality annotations. Existing approaches rely on costly human
labeling, LLM-based self-evaluation that is prone to hallucination, or Monte
Carlo (MC) estimation, which infers step quality solely from rollout outcomes
and often introduces noisy, misaligned supervision due to credit
misattribution. These issues result in three core limitations: noisy rewards,
low factual fidelity, and misalignment with step-level reasoning objectives. To
address these challenges, we introduce GroundedPRM, a tree-guided and
fidelity-aware framework for automatic process supervision. To reduce reward
noise and enable fine-grained credit assignment, we construct structured
reasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated
supervision, we validate each intermediate step using an external tool,
providing execution-grounded correctness signals. To combine both step-level
validation and global outcome assessment, we design a hybrid reward aggregation
mechanism that fuses tool-based verification with MCTS-derived feedback.
Finally, we format the reward signal into a rationale-enhanced, generative
structure to promote interpretability and compatibility with instruction-tuned
LLMs. GroundedPRM is trained on only 40K automatically labeled samples,
amounting to just 10% of the data used by the best-performing PRM trained with
auto-labeled supervision. Nevertheless, it achieves up to a 26% relative
improvement in average performance on ProcessBench. When used for reward-guided
greedy search, GroundedPRM outperforms even PRMs trained with human-labeled
supervision, offering a scalable and verifiable path toward high-quality
process-level reasoning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [134] [Self-Training with Dynamic Weighting for Robust Gradual Domain Adaptation](https://arxiv.org/abs/2510.13864)
*Zixi Wang,Yushe Cao,Yubo Huang,Jinzhu Wei,Jingzehua Xu,Shuai Zhang,Xin Lai*

Main category: cs.LG

TL;DR: 该论文提出了一种名为STDW的新方法，通过在训练过程中自适应地平衡源域和目标域的损失贡献，以增强渐进式域适应（GDA）中的鲁棒性，并在多个数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统的GDA方法通过中间域和自训练来缓解域漂移，但往往存在知识迁移效率低下或中间数据不完整的问题，因此需要一种新的方法来解决这些挑战。

Method: 本研究提出了一种名为自训练与动态加权（STDW）的新方法。该方法引入了一种动态加权机制，在训练过程中自适应地平衡源域和目标域的损失贡献。具体来说，设计了一个由时变超参数$\varrho$（从0到1）控制的优化框架，该框架控制域特定学习的强度并确保稳定的适应。该方法利用自训练生成伪标签，并优化加权目标函数以进行迭代模型更新，从而在中间域中保持鲁棒性。

Result: 在旋转MNIST、颜色偏移MNIST、肖像数据集和Cover Type数据集上的实验表明，STDW优于现有基线。消融研究进一步验证了$\varrho$的动态调度在实现渐进适应中的关键作用，证实了其在减少域偏差和提高泛化性方面的有效性。

Conclusion: 这项工作为鲁棒渐进式域适应提供了理论见解和实用框架，在动态现实世界场景中具有潜在应用。

Abstract: In this paper, we propose a new method called Self-Training with Dynamic
Weighting (STDW), which aims to enhance robustness in Gradual Domain Adaptation
(GDA) by addressing the challenge of smooth knowledge migration from the source
to the target domain. Traditional GDA methods mitigate domain shift through
intermediate domains and self-training but often suffer from inefficient
knowledge migration or incomplete intermediate data. Our approach introduces a
dynamic weighting mechanism that adaptively balances the loss contributions of
the source and target domains during training. Specifically, we design an
optimization framework governed by a time-varying hyperparameter $\varrho$
(progressing from 0 to 1), which controls the strength of domain-specific
learning and ensures stable adaptation. The method leverages self-training to
generate pseudo-labels and optimizes a weighted objective function for
iterative model updates, maintaining robustness across intermediate domains.
Experiments on rotated MNIST, color-shifted MNIST, portrait datasets, and the
Cover Type dataset demonstrate that STDW outperforms existing baselines.
Ablation studies further validate the critical role of $\varrho$'s dynamic
scheduling in achieving progressive adaptation, confirming its effectiveness in
reducing domain bias and improving generalization. This work provides both
theoretical insights and a practical framework for robust gradual domain
adaptation, with potential applications in dynamic real-world scenarios. The
code is available at https://github.com/Dramwig/STDW.

</details>


### [135] [Joint Discriminative-Generative Modeling via Dual Adversarial Training](https://arxiv.org/abs/2510.13872)
*Xuwang Yin,Claire Zhang,Julie Steele,Nir Shavit,Tony T. Wang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的训练框架，通过整合对抗训练原则，实现了鲁棒分类和高保真生成建模的同步，解决了现有混合方法在稳定性和样本质量方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有混合方法（如JEM）在将分类器解释为EBM时，常常受限于SGLD训练的不稳定性和较差的样本质量，难以同时实现鲁棒分类和高保真生成建模。

Method: 1. 提出了一种基于对抗训练的稳定JEM学习方法，使用BCE损失区分真实数据和PGD生成的对比样本来优化能量函数。
2. 将对抗训练引入判别器，增强了分类鲁棒性，并消除了对显式梯度惩罚的需求。
3. 采用了两阶段训练过程，解决了批量归一化与EBM训练之间的不兼容性。

Result: 在CIFAR-10、CIFAR-100和ImageNet上的实验表明，该方法显著提高了对抗鲁棒性，同时保持了有竞争力的生成性能。在ImageNet上，生成保真度超越了BigGAN，并接近扩散模型，是首个在复杂高分辨率数据集上实现高质量生成的MCMC-based EBM方法。

Conclusion: 本研究解决了JEM扩展中的关键稳定性问题，并证明对抗训练可以作为统一框架的有效基础，该框架能够生成和鲁棒地分类视觉数据。

Abstract: Simultaneously achieving robust classification and high-fidelity generative
modeling within a single framework presents a significant challenge. Hybrid
approaches, such as Joint Energy-Based Models (JEM), interpret classifiers as
EBMs but are often limited by the instability and poor sample quality inherent
in SGLD-based training. We address these limitations by proposing a novel
training framework that integrates adversarial training (AT) principles for
both discriminative robustness and stable generative learning. The proposed
method introduces three key innovations: (1) the replacement of SGLD-based JEM
learning with a stable, AT-based approach that optimizes the energy function by
discriminating between real data and PGD-generated contrastive samples using
the BCE loss; (2) synergistic adversarial training for the discriminative
component that enhances classification robustness while eliminating the need
for explicit gradient penalties; and (3) a two-stage training procedure to
resolve the incompatibility between batch normalization and EBM training.
Experiments on CIFAR-10, CIFAR-100, and ImageNet demonstrate that our method
substantially improves adversarial robustness over existing hybrid models while
maintaining competitive generative performance. On ImageNet, when optimized for
generative modeling, our model's generative fidelity surpasses that of BigGAN
and approaches diffusion models, representing the first MCMC-based EBM approach
to achieve high-quality generation on complex, high-resolution datasets. Our
approach addresses key stability issues that have limited JEM scaling and
demonstrates that adversarial training can serve as an effective foundation for
unified frameworks capable of generating and robustly classifying visual data.

</details>


### [136] [Near-Optimal Regret-Queue Length Tradeoff in Online Learning for Two-Sided Markets](https://arxiv.org/abs/2510.14097)
*Zixian Yang,Sushil Mahavir Varma,Lei Ying*

Main category: cs.LG

TL;DR: 本文主要研究了一个双边市场，其中平台的目标是设计定价和匹配算法，以在保持合理队列长度的同时，最大化平台利润。为此，我们设计了一种新颖的基于在线学习的定价策略，并在理论上证明了其近似最优性，同时在后悔、平均队列长度和最大队列长度之间建立了权衡关系。


<details>
  <summary>Details</summary>
Motivation: 在双边市场中，平台面临着如何设计定价和匹配算法以最大化利润的挑战，尤其是在需求和供给曲线未知的情况下。现有的研究可能无法很好地平衡利润最大化和队列长度控制，因此需要一种新的在线学习方法来解决这个问题。

Method: 我们设计了一种新颖的在线学习定价策略。该策略包含两个关键组成部分：一个动态组件用于优化低后悔和短队列长度之间的权衡，一个概率组件用于平衡获取有用样本以进行快速学习和保持短队列长度之间的矛盾。

Result: 我们证明了在后悔、平均队列长度和最大队列长度之间存在一个权衡关系，具体为：$	ilde{O}(T^{1-\gamma})$的后悔、$	ilde{O}(T^{\gamma/2})$的平均队列长度以及$	ilde{O}(T^{\gamma})$的最大队列长度，其中$\gamma \in (0, 1/6]$。这显著改进了现有结果。此外，在允许的$\gamma$范围内，我们证明了后悔和平均队列长度之间的这种权衡是渐进最优的。

Conclusion: 本文提出了一种新颖的在线学习定价策略，该策略在双边市场中能够有效地平衡平台利润最大化和队列长度控制。通过理论分析，我们证明了该策略在后悔、平均队列长度和最大队列长度之间达到了近似最优的权衡，并且在一定条件下达到了最优性。

Abstract: We study a two-sided market, wherein, price-sensitive heterogeneous customers
and servers arrive and join their respective queues. A compatible
customer-server pair can then be matched by the platform, at which point, they
leave the system. Our objective is to design pricing and matching algorithms
that maximize the platform's profit, while maintaining reasonable queue
lengths. As the demand and supply curves governing the price-dependent arrival
rates may not be known in practice, we design a novel online-learning-based
pricing policy and establish its near-optimality. In particular, we prove a
tradeoff among three performance metrics: $\tilde{O}(T^{1-\gamma})$ regret,
$\tilde{O}(T^{\gamma/2})$ average queue length, and $\tilde{O}(T^{\gamma})$
maximum queue length for $\gamma \in (0, 1/6]$, significantly improving over
existing results [1]. Moreover, barring the permissible range of $\gamma$, we
show that this trade-off between regret and average queue length is optimal up
to logarithmic factors under a class of policies, matching the optimal one as
in [2] which assumes the demand and supply curves to be known. Our proposed
policy has two noteworthy features: a dynamic component that optimizes the
tradeoff between low regret and small queue lengths; and a probabilistic
component that resolves the tension between obtaining useful samples for fast
learning and maintaining small queue lengths.

</details>


### [137] [K-frames: Scene-Driven Any-k Keyframe Selection for long video understanding](https://arxiv.org/abs/2510.13891)
*Yifeng Yao,Yike Yun,Jing Wang,Huishuai Zhang,Dongyan Zhao,Ke Tian,Zhihao Wang,Minghui Qiu,Tao Wang*

Main category: cs.LG

TL;DR: 本文介绍了一种新颖的场景驱动关键帧选择方法K-frames，旨在解决多模态大模型在处理长视频时面临的挑战，通过选择语义连贯的视频片段来保持时间连续性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型在处理长视频时，受限于上下文窗口和计算成本，统一帧采样会导致大量信息丢失。而现有的关键帧选择方法（如文本-帧检索或基于强化学习的帧优化）通常会生成稀疏、时间不连续的帧，忽略了场景连续性，并且缺乏多尺度帧选择的灵活性。

Method: K-frames引入了一种新颖的场景驱动关键帧选择范式，通过预测语义连贯、与查询相关的视频片段，实现任意k关键帧选择。该方法首先构建了一个包含20万个查询条件视频亮点的PeakClips数据集。基于该数据集，K-frames采用三阶段渐进式课程学习clip2frame选择：包括两个用于时间定位和关键片段感知的监督微调阶段，以及一个用于直接优化场景驱动预测策略的强化学习阶段。

Result: 在主要的长视频理解基准测试中，K-frames表现出有效、可解释且即插即用的多尺度关键帧选择能力。

Conclusion: K-frames为长视频的关键帧选择提供了一个有效、可解释且即插即用的解决方案，并且能够以各种规模进行关键帧选择，解决了当前多模态大模型在处理长视频时面临的挑战。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
capabilities in image understanding, but long-video are constrained by context
windows and computational cost. Uniform frame sampling often leads to
substantial information loss. Meanwhile existing keyframe selection methods
such as text-frame retrieval or RL-based frame optimization typically yield
sparse and temporally disjointed frames, overlooking scene continuity and
lacking flexibility for multi-scale frame selection. To address these
limitations, we introduce K-frames, a novel paradigm for scene-driven keyframe
selection that preserves temporal continuity. Instead of selecting individual
frames, K-frames predicts semantically coherent, query-relevant clips, which
enables any-k keyframes selection to meet diverse user budgets. To achieve this
approach, we first introduce PeakClips, a dataset of 200K video highlights
conditioned by query. Building on this dataset, K-frames learns clip2frame
selection using a three-stage progressive curriculum. It involves two
Supervised Fine-Tuning stages for temporal grounding and key-clip perception,
followed by a Reinforcement Learning stage that directly optimizes the
scene-driven prediction policy for downstream task without further annotations.
Extensive experiments on major long-video understanding benchmarks demonstrate
that K-frames provides an effective, interpretable, and plug-and-play solution
for keyframe selection at various scales. Our dataset and model will be
available.

</details>


### [138] [Multi-View Semi-Supervised Label Distribution Learning with Local Structure Complementarity](https://arxiv.org/abs/2510.13917)
*Yanshan Xiao,Kaihong Wu,Bo Liu*

Main category: cs.LG

TL;DR: 本文提出了MVSS-LDL方法，通过利用每个视图的局部最近邻结构并强调多视图中局部最近邻结构的互补性，解决了多视图半监督标签分布学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有的标签分布学习（LDL）方法主要针对标注数据的单视图LDL问题，而未考虑带标注和未标注数据的多视图LDL问题。

Method: MVSS-LDL方法首先计算每个视图的k-最近邻以探索局部结构，然后通过结合其他视图中的最近邻来补充每个视图的最近邻集，最后，基于补充后的最近邻集构建一个基于图学习的多视图半监督LDL模型。

Result: 数值研究表明，MVSS-LDL取得了比现有单视图LDL方法更好的分类性能。

Conclusion: MVSS-LDL是首次尝试解决多视图LDL问题，通过考虑局部最近邻结构的互补性，使得不同视图可以相互提供局部结构信息，从而提升了性能。

Abstract: Label distribution learning (LDL) is a paradigm that each sample is
associated with a label distribution. At present, the existing approaches are
proposed for the single-view LDL problem with labeled data, while the
multi-view LDL problem with labeled and unlabeled data has not been considered.
In this paper, we put forward the multi-view semi-supervised label distribution
learning with local structure complementarity (MVSS-LDL) approach, which
exploits the local nearest neighbor structure of each view and emphasizes the
complementarity of local nearest neighbor structures in multiple views.
Specifically speaking, we first explore the local structure of view $v$ by
computing the $k$-nearest neighbors. As a result, the $k$-nearest neighbor set
of each sample $\boldsymbol{x}_i$ in view $v$ is attained. Nevertheless, this
$k$-nearest neighbor set describes only a part of the nearest neighbor
information of sample $\boldsymbol{x}_i$. In order to obtain a more
comprehensive description of sample $\boldsymbol{x}_i$'s nearest neighbors, we
complement the nearest neighbor set in view $v$ by incorporating sample
$\boldsymbol{x}_i$'s nearest neighbors in other views. Lastly, based on the
complemented nearest neighbor set in each view, a graph learning-based
multi-view semi-supervised LDL model is constructed. By considering the
complementarity of local nearest neighbor structures, different views can
mutually provide the local structural information to complement each other. To
the best of our knowledge, this is the first attempt at multi-view LDL.
Numerical studies have demonstrated that MVSS-LDL attains explicitly better
classification performance than the existing single-view LDL methods.

</details>


### [139] [Weight Weaving: Parameter Pooling for Data-Free Model Merging](https://arxiv.org/abs/2510.13921)
*Levy Chaves,Eduardo Valle,Sandra Avila*

Main category: cs.LG

TL;DR: Weight Weaving是一种即插即用的模型合并优化技术，它通过汇总用户定义的池化函数在λ值搜索空间中进行模型权重调整，从而在无需访问数据的情况下显著提高了各种图像任务中现有模型合并方法的性能。我们的方法具有高模块性，对搜索空间的限制最小，并且消除了评估数据要求。在数据不受限的情况下，我们的方法将几种模型合并方法的平均准确率提高了多达15.9%.


<details>
  <summary>Details</summary>
Motivation: 大多数模型合并方法都依赖于缩放超参数λ，这些超参数在全局或单独的维度上衡量每个模型的贡献。目前，在不访问任何数据（即“无数据”）的情况下设置缩放因子，会使得模型合并方法缺乏原则性的方法，这往往导致研究人员使用评估集中的特权数据调整λ，这在实践中是不可行的。因此，为了解决这种局限性，我们设计了Weight Weaving算法。

Method: 本文介绍了Weight Weaving，这是一种即插即用的技术，它通过使用用户定义的池化函数（例如平均、随机选择，甚至是现有的模型合并方法）来汇集跨λ值搜索空间的模型权重。本文的方法对搜索空间施加的限制最小。它与现有的模型合并方法正交运行，并消除了评估数据要求。

Result: 作者在三种实验设置中，对三种ViT变体验证了Weight Weaving：视觉多任务学习、视觉持续学习和领域泛化。本文的方法通过消除对评估数据的依赖，在无数据设置中，始终将几种模型合并方法的平均准确率提高了多达15.9%。

Conclusion: 本文提出的Weight Weaving算法在不需要额外数据访问或评估的情况下，通过有效调整模型合并的超参数λ，显著提升了现有模型合并方法在多任务和持续学习场景下的性能。这一方法不仅具有高度的模块化和灵活性，还为模型合并领域提供了一个实用且有效的解决方案，从而使得模型合并技术在实际应用中更具可行性和效率。

Abstract: Model merging provides a cost-effective and data-efficient combination of
specialized deep neural networks through parameter integration. This technique
leverages expert models across downstream tasks without requiring retraining.
Most model merging approaches critically depend on scaling hyper-parameters
$\lambda$, which weight each model's contribution globally or individually.
Principled approaches for setting scaling factors without accessing any data
(data-free) are scarce, often leading researchers to tune $\lambda$ using
privileged data from the evaluation set, which is obviously unfeasible in
practice. To address this limitation, we introduce Weight Weaving, a
plug-and-play technique that pools model weights across $\lambda$ values search
space using user-defined pooling functions, such as averaging, random
selection, or even existing model merging methods. Our method demonstrates high
modularity, imposing minimal constraints on the search space. It operates
orthogonally to existing model merging methods and eliminates evaluation data
requirements. We validate Weight Weaving across three ViT variants in three
experimental setups: vision multi-task learning, vision continual learning, and
domain generalization. Our method consistently improves the performance of
several model merging methods, achieving average accuracy gains of up to 15.9
percentage points in a data-free setting.

</details>


### [140] [LTR-ICD: A Learning-to-Rank Approach for Automatic ICD Coding](https://arxiv.org/abs/2510.13922)
*Mohammad Mansoori,Amira Soliman,Farzaneh Etminani*

Main category: cs.LG

TL;DR: 本文提出了一种从检索系统的角度进行ICD编码分类和排序的方法，解决了传统方法中忽略ICD编码顺序的问题，并在识别高优先级编码方面取得了显著优于现有技术的效果。


<details>
  <summary>Details</summary>
Motivation: 临床笔记中的ICD编码分配和排序对于医疗诊断和报销至关重要，但自动化该任务仍然具有挑战性。现有方法将此问题视为分类任务，忽略了ICD代码的顺序。

Method: 本文首次尝试将ICD编码任务视为一个检索系统问题，并将其表述为分类和排序任务，以考虑ICD代码的顺序。

Result: 与现有技术相比，所提出的框架在识别高优先级代码方面具有卓越的能力。例如，模型正确排序主要诊断代码的准确率为47%，而现有分类器的准确率为20%。在分类指标方面，该模型在微观和宏观F1分数上分别达到0.6065和0.2904，优于之前最佳模型的0.597和0.2660。

Conclusion: 本文提出的将ICD编码视为分类和排序任务的方法，能够有效解决传统方法中忽略编码顺序的问题，并在主要诊断代码排序和整体分类性能上显著优于现有技术。

Abstract: Clinical notes contain unstructured text provided by clinicians during
patient encounters. These notes are usually accompanied by a sequence of
diagnostic codes following the International Classification of Diseases (ICD).
Correctly assigning and ordering ICD codes are essential for medical diagnosis
and reimbursement. However, automating this task remains challenging.
State-of-the-art methods treated this problem as a classification task, leading
to ignoring the order of ICD codes that is essential for different purposes. In
this work, as a first attempt, we approach this task from a retrieval system
perspective to consider the order of codes, thus formulating this problem as a
classification and ranking task. Our results and analysis show that the
proposed framework has a superior ability to identify high-priority codes
compared to other methods. For instance, our model accuracy in correctly
ranking primary diagnosis codes is 47%, compared to 20% for the
state-of-the-art classifier. Additionally, in terms of classification metrics,
the proposed model achieves a micro- and macro-F1 scores of 0.6065 and 0.2904,
respectively, surpassing the previous best model with scores of 0.597 and
0.2660.

</details>


### [141] [Distributional Consistency Loss: Beyond Pointwise Data Terms in Inverse Problems](https://arxiv.org/abs/2510.13972)
*George Webber,Andrew J. Reader*

Main category: cs.LG

TL;DR: “逆问题”中的一个核心挑战是从噪声测量中恢复真实信号，传统的数据保真损失函数（如均方误差）可能会导致对噪声的过拟合。而本文提出的“分布一致性（DC）损失”通过用基于模型的概率分数进行分布级校准，替代了点对点匹配，从而有效地将数据保真度作为一个整体进行评估。


<details>
  <summary>Details</summary>
Motivation: 在处理如医学成像、地球物理学、信号处理等“逆问题”时，从噪声测量中恢复真实信号是一个核心挑战。现有的解决方案需要在真实信号的先验假设（正则化）与噪声测量数据的一致性（数据保真）之间取得平衡。传统的诸如均方误差（MSE）或负对数似然的数据保真损失函数，通常会导致对噪声的过拟合，这促使研究者寻求一种新的数据损失函数来避免这个问题。

Method: 本文提出了一种名为“分布一致性（DC）损失”的数据保真目标函数。它通过使用基于模型的概率分数对每个测量进行分布级校准，替代了点对点匹配，从而将数据保真度作为一个整体进行评估。DC损失函数利用了测量噪声分布已知以及测量数据集包含许多独立的噪声值这一特点。此外，DC损失函数可以直接替代标准数据一致性项，并且与现代正则化器兼容，优化方式与传统损失函数相同，即使不使用先验条件也能避免测量噪声的过拟合。

Result: DC损失在两个关键应用领域展现了其有效性：1. 在使用深度图像先验进行图像去噪时，DC损失替代MSE损失消除了对早期停止的需求，并获得了更高的峰值信噪比（PSNR）。2. 在从泊松噪声数据进行医学图像重建时，DC损失减少了高度迭代重建中的伪影，并增强了手工正则化的效果。

Conclusion: DC损失为逆问题中的传统保真损失提供了一种统计学上合理且能提升性能的替代方案。

Abstract: Recovering true signals from noisy measurements is a central challenge in
inverse problems spanning medical imaging, geophysics, and signal processing.
Current solutions balance prior assumptions regarding the true signal
(regularization) with agreement to noisy measured data (data-fidelity).
Conventional data-fidelity loss functions, such as mean-squared error (MSE) or
negative log-likelihood, seek pointwise agreement with noisy measurements,
often leading to overfitting to noise. In this work, we instead evaluate
data-fidelity collectively by testing whether the observed measurements are
statistically consistent with the noise distributions implied by the current
estimate. We adopt this aggregated perspective and introduce distributional
consistency (DC) loss, a data-fidelity objective that replaces pointwise
matching with distribution-level calibration using model-based probability
scores for each measurement. DC loss acts as a direct and practical plug-in
replacement for standard data consistency terms: i) it is compatible with
modern regularizers, ii) it is optimized in the same way as traditional losses,
and iii) it avoids overfitting to measurement noise even without the use of
priors. Its scope naturally fits many practical inverse problems where the
measurement-noise distribution is known and where the measured dataset consists
of many independent noisy values. We demonstrate efficacy in two key example
application areas: i) in image denoising with deep image prior, using DC
instead of MSE loss removes the need for early stopping and achieves higher
PSNR; ii) in medical image reconstruction from Poisson-noisy data, DC loss
reduces artifacts in highly-iterated reconstructions and enhances the efficacy
of hand-crafted regularization. These results position DC loss as a
statistically grounded, performance-enhancing alternative to conventional
fidelity losses for inverse problems.

</details>


### [142] [BitNet Distillation](https://arxiv.org/abs/2510.13998)
*Xun Wu,Shaohan Huang,Wenhui Wang,Ting Song,Li Dong,Yan Xia,Furu Wei*

Main category: cs.LG

TL;DR: 本文介绍了一种名为 BitNet Distillation (BitDistill) 的轻量级流程，可以将全精度大型语言模型（LLMs）微调为 1.58 比特精度的模型，从而在特定下游任务上实现强大的性能，同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在特定下游任务上，将全精度LLMs压缩为1.58比特精度，以实现强大的任务特定性能和最小的计算成本。

Method: BitDistill 结合了三项关键技术：BitNet 中引入的 SubLN 模块、基于 MiniLM 的多头注意力蒸馏，以及作为重要预热步骤的持续预训练。持续预训练旨在缓解微调全精度和 1.58 比特 LLM 之间在特定任务上性能差距的扩展性问题。

Result: BitDistill 在不同模型尺寸下实现了与全精度模型相当的性能，同时实现了高达 10 倍的内存节省和在 CPU 上 2.65 倍的推理速度提升。

Conclusion:   BitDistill 提供了一种在特定任务上有效压缩 LLMs 的方法，通过 1.58 比特量化，在保持性能的同时，显著降低了内存占用和提升了推理速度。

Abstract: In this paper, we present BitNet Distillation (BitDistill), a lightweight
pipeline that fine-tunes off-the-shelf full-precision LLMs (e.g., Qwen) into
1.58-bit precision (i.e., ternary weights {-1, 0, 1}) for specific downstream
tasks, achieving strong task-specific performance with minimal computational
cost. Specifically, BitDistill incorporates three key techniques: the SubLN
module, as introduced in BitNet; multi-head attention distillation, based on
MiniLM; and continual pre-training, which serves as a crucial warm-up step to
mitigate the scalability issue of the performance gap between finetuned
full-precision and 1.58-bit LLMs on specific tasks. Experimental results show
that BitDistill achieves performance comparable to the full-precision
counterpart models across model size, while enabling up to 10x memory savings
and 2.65x faster inference on CPUs. Code is available at
https://github.com/microsoft/BitNet.

</details>


### [143] [Conditional Clifford-Steerable CNNs with Complete Kernel Basis for PDE Modeling](https://arxiv.org/abs/2510.14007)
*Bálint László Szarvas,Maksim Zhdanov*

Main category: cs.LG

TL;DR: 本文提出了一种条件 Clifford 可控核（Conditional Clifford-Steerable Kernels），解决了现有 Clifford 可控 CNN（CSCNNs）核基不完备导致模型表达能力受限的问题，并在多个 PDE 预测任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的 Clifford 可控 CNN（CSCNNs）虽然提供了一个统一的框架来处理任意伪欧几里德群的等变性，但其核基不完备，从而限制了模型的表达能力。

Method: 本文提出了条件 Clifford 可控核，通过输入特征场计算的等变表示来增强核。为此，作者推导了这些依赖于输入的核的等变性约束，并展示了如何通过隐式参数化有效地解决该问题。

Result: 在流体动力学和相对论电动力学等多个 PDE 预测任务中，本文方法始终优于基线方法，证明了其表达能力的提升。

Conclusion: 本文通过引入条件 Clifford 可控核，克服了现有 Clifford 可控 CNN 核基不完备的局限性，提高了模型在处理复杂物理任务时的表达能力和性能。

Abstract: Clifford-Steerable CNNs (CSCNNs) provide a unified framework that allows
incorporating equivariance to arbitrary pseudo-Euclidean groups, including
isometries of Euclidean space and Minkowski spacetime. In this work, we
demonstrate that the kernel basis of CSCNNs is not complete, thus limiting the
model expressivity. To address this issue, we propose Conditional
Clifford-Steerable Kernels, which augment the kernels with equivariant
representations computed from the input feature field. We derive the
equivariance constraint for these input-dependent kernels and show how it can
be solved efficiently via implicit parameterization. We empirically demonstrate
an improved expressivity of the resulting framework on multiple PDE forecasting
tasks, including fluid dynamics and relativistic electrodynamics, where our
method consistently outperforms baseline methods.

</details>


### [144] [Policy Regularized Distributionally Robust Markov Decision Processes with Linear Function Approximation](https://arxiv.org/abs/2510.14246)
*Jingwen Gu,Yiting He,Zhishuai Liu,Pan Xu*

Main category: cs.LG

TL;DR: 本文提出了一种名为DR-RPO的无模型在线策略优化算法，用于在存在分布偏移的强化学习环境中学习鲁棒策略，并在理论和实践中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在强化学习（RL）中，训练和部署环境之间的差异是决策面临的核心挑战。本文通过鲁棒马尔可夫决策过程（RMDPs）的视角来研究这个问题，RMDPs旨在针对对抗性转移动力学优化性能。作者专注于在线设置，其中智能体与环境的交互有限，使得样本效率和探索变得尤为关键。在鲁棒强化学习领域，策略优化仍有理论和实证上的不足。

Method: 本文提出了一种“分布鲁棒正则化策略优化算法”（DR-RPO），这是一种无模型的在线策略优化方法，能够学习次线性遗憾的鲁棒策略。为了在softmax策略类中实现可处理的优化，DR-RPO引入了参考策略正则化，产生了在转移和策略上都受到双重约束的鲁棒马尔可夫决策过程（RMDP）变体。为了扩展到大型状态-动作空间，作者采用了d-矩形线性MDP公式，并将线性函数逼近与用于乐观探索的上限置信奖励相结合。

Result: DR-RPO算法在理论上可以实现多项式次优界和样本效率，与基于价值的方法性能匹配。在不同的领域进行的实证结果也证实了理论的有效性，并展示了DR-RPO的鲁棒性。

Conclusion: 本文提出了一种新的算法DR-RPO，有效地解决了在分布偏移下强化学习的挑战。理论和实证结果都证实了DR-RPO在鲁棒强化学习中的有效性，使其成为在该领域的一个有前景的解决方案。

Abstract: Decision-making under distribution shift is a central challenge in
reinforcement learning (RL), where training and deployment environments differ.
We study this problem through the lens of robust Markov decision processes
(RMDPs), which optimize performance against adversarial transition dynamics.
Our focus is the online setting, where the agent has only limited interaction
with the environment, making sample efficiency and exploration especially
critical. Policy optimization, despite its success in standard RL, remains
theoretically and empirically underexplored in robust RL. To bridge this gap,
we propose \textbf{D}istributionally \textbf{R}obust \textbf{R}egularized
\textbf{P}olicy \textbf{O}ptimization algorithm (DR-RPO), a model-free online
policy optimization method that learns robust policies with sublinear regret.
To enable tractable optimization within the softmax policy class, DR-RPO
incorporates reference-policy regularization, yielding RMDP variants that are
doubly constrained in both transitions and policies. To scale to large
state-action spaces, we adopt the $d$-rectangular linear MDP formulation and
combine linear function approximation with an upper confidence bonus for
optimistic exploration. We provide theoretical guarantees showing that policy
optimization can achieve polynomial suboptimality bounds and sample efficiency
in robust RL, matching the performance of value-based approaches. Finally,
empirical results across diverse domains corroborate our theory and demonstrate
the robustness of DR-RPO.

</details>


### [145] [CausalVerse: Benchmarking Causal Representation Learning with Configurable High-Fidelity Simulations](https://arxiv.org/abs/2510.14049)
*Guangyi Chen,Yunlong Deng,Peiyuan Zhu,Yan Li,Yifan Sheng,Zijian Li,Kun Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一个新的因果表示学习（CRL）基准，旨在弥合评估的严谨性与实际应用之间的鸿沟。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法在真实性和评估精度之间存在两难。该论文旨在通过使用高保真模拟视觉数据，提供一个既具有真实视觉复杂性，又可访问真实因果生成过程的CRL新基准来解决这个问题。

Method: 该论文引入了一个新的CRL基准，使用了高保真模拟视觉数据。该数据集包含大约20万张图像和300万视频帧，涵盖四个领域的24个子场景：静态图像生成、动态物理模拟、机器人操作和交通状况分析。这些场景涵盖了从静态到动态、从简单到复杂以及从单智能体到多智能体交互的各种设置。

Result: 该基准能够灵活访问底层的因果结构，允许用户修改或配置它们以符合CRL中的假设，例如可用的领域标签、时间依赖性或干预历史。该论文还使用该基准评估了代表性的CRL方法，并提供了经验性见解。

Conclusion: 该论文成功地建立了一个全面的CRL测试平台，有望弥合严格评估与实际适用性之间的差距，并为从业者和新手在选择或扩展合适的CRL框架以解决特定类型的实际问题时提供帮助。

Abstract: Causal Representation Learning (CRL) aims to uncover the data-generating
process and identify the underlying causal variables and relations, whose
evaluation remains inherently challenging due to the requirement of known
ground-truth causal variables and causal structure. Existing evaluations often
rely on either simplistic synthetic datasets or downstream performance on
real-world tasks, generally suffering a dilemma between realism and evaluative
precision. In this paper, we introduce a new benchmark for CRL using
high-fidelity simulated visual data that retains both realistic visual
complexity and, more importantly, access to ground-truth causal generating
processes. The dataset comprises around 200 thousand images and 3 million video
frames across 24 sub-scenes in four domains: static image generation, dynamic
physical simulations, robotic manipulations, and traffic situation analysis.
These scenarios range from static to dynamic settings, simple to complex
structures, and single to multi-agent interactions, offering a comprehensive
testbed that hopefully bridges the gap between rigorous evaluation and
real-world applicability. In addition, we provide flexible access to the
underlying causal structures, allowing users to modify or configure them to
align with the required assumptions in CRL, such as available domain labels,
temporal dependencies, or intervention histories. Leveraging this benchmark, we
evaluated representative CRL methods across diverse paradigms and offered
empirical insights to assist practitioners and newcomers in choosing or
extending appropriate CRL frameworks to properly address specific types of real
problems that can benefit from the CRL perspective. Welcome to visit our:
Project page:https://causal-verse.github.io/,
Dataset:https://huggingface.co/CausalVerse.

</details>


### [146] [Nonparametric Data Attribution for Diffusion Models](https://arxiv.org/abs/2510.14269)
*Yutian Zhao,Chao Du,Xiaosen Zheng,Tianyu Pang,Min Lin*

Main category: cs.LG

TL;DR: 该论文提出了一种非参数的数据归因方法，用于生成模型，通过测量生成图像和训练图像之间的块级相似性来量化训练数据对模型输出的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型数据归因方法通常需要访问模型梯度或进行再训练，这限制了它们在专有或大规模设置中的适用性。

Method: 提出了一种完全基于数据的非参数归因方法，通过测量生成图像和训练图像之间的块级相似性来量化影响。该方法基于最优分数函数的分析形式，并自然地扩展到多尺度表示，同时通过基于卷积的加速保持计算效率。

Result: 该框架不仅生成空间可解释的归因，而且揭示了反映训练数据和输出之间内在关系的模式，这些模式独立于任何特定模型。实验表明，该方法实现了强大的归因性能，与基于梯度的SOTA方法非常匹配，并显著优于现有的非参数基线。

Conclusion: 该论文提出了一种新颖的非参数数据归因方法，有效解决了现有方法的局限性，并在性能上取得了显著提升，为生成模型的数据归因提供了一个有前景的解决方案。

Abstract: Data attribution for generative models seeks to quantify the influence of
individual training examples on model outputs. Existing methods for diffusion
models typically require access to model gradients or retraining, limiting
their applicability in proprietary or large-scale settings. We propose a
nonparametric attribution method that operates entirely on data, measuring
influence via patch-level similarity between generated and training images. Our
approach is grounded in the analytical form of the optimal score function and
naturally extends to multiscale representations, while remaining
computationally efficient through convolution-based acceleration. In addition
to producing spatially interpretable attributions, our framework uncovers
patterns that reflect intrinsic relationships between training data and
outputs, independent of any specific model. Experiments demonstrate that our
method achieves strong attribution performance, closely matching gradient-based
approaches and substantially outperforming existing nonparametric baselines.
Code is available at https://github.com/sail-sg/NDA.

</details>


### [147] [FedHFT: Efficient Federated Finetuning with Heterogeneous Edge Clients](https://arxiv.org/abs/2510.14054)
*Fatih Ilhan,Selim Furkan Tekin,Tiansheng Huang,Gaowen Liu,Ramana Kompella,Greg Eisenhauer,Yingyan Celine Lin,Calton Pu,Ling Liu*

Main category: cs.LG

TL;DR: FedHFT是一个高效且个性化的联邦微调框架，解决了联邦设置中预训练大语言模型微调的数据和资源异构性挑战。


<details>
  <summary>Details</summary>
Motivation: 在下游任务和特定领域数据集上，对预训练的大语言模型进行微调是常见的做法，但面临数据有限/异构和计算资源不同的挑战。

Method: FedHFT引入了混合掩码适配器来处理客户端资源异构性，并提出了一种双层优化方法，结合掩码个性化和客户端聚类来处理非独立同分布数据。

Result: FedHFT在数据和资源异构性下的各种自然语言理解任务上，相比现有异构联邦学习方法，在性能和效率上都有显著提升。

Conclusion: FedHFT通过混合掩码适配器和双层优化方法，有效地解决了联邦微调中数据和资源异构性问题，提高了模型性能和效率。

Abstract: Fine-tuning pre-trained large language models (LLMs) has become a common
practice for personalized natural language understanding (NLU) applications on
downstream tasks and domain-specific datasets. However, there are two main
challenges: (i) limited and/or heterogeneous data for fine-tuning due to
proprietary data confidentiality or privacy requirements, and (ii) varying
computation resources available across participating clients such as edge
devices. This paper presents FedHFT - an efficient and personalized federated
fine-tuning framework to address both challenges. First, we introduce a mixture
of masked adapters to handle resource heterogeneity across participating
clients, enabling high-performance collaborative fine-tuning of pre-trained
language model(s) across multiple clients in a distributed setting, while
keeping proprietary data local. Second, we introduce a bi-level optimization
approach to handle non-iid data distribution based on masked personalization
and client clustering. Extensive experiments demonstrate significant
performance and efficiency improvements over various natural language
understanding tasks under data and resource heterogeneity compared to
representative heterogeneous federated learning methods.

</details>


### [148] [Jet Functors and Weil Algebras in Automatic Differentiation: A Geometric Analysis](https://arxiv.org/abs/2510.14342)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 本文提出了一种使用射流丛和Weil代数进行自动微分（AD）的几何公式。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过微分几何的视角来解释自动微分理论，并为深度学习和科学计算中开发结构保持微分方法奠定基础。

Method: 本文提出了一种使用射流丛和Weil代数进行自动微分（AD）的几何公式。反向模式AD表现为余切回拉，而泰勒模式对应于Weil代数中的评估。本文还展示了张量化的Weil代数可以一次性计算所有混合导数。

Result: 本文从理论上推导出了关于正确性、稳定性和复杂性的简洁说明：反向模式的函子恒等式、高阶导数的代数精确性以及截断误差的明确界限。张量化的Weil代数能够以代数维度线性成本一次性计算所有混合导数，避免了嵌套JVP/VJP调度带来的组合爆炸。

Conclusion: 本文通过微分几何的视角解释了AD理论，并为深度学习和科学计算中开发结构保持微分方法提供了基础。

Abstract: We present a geometric formulation of automatic differentiation (AD) using
jet bundles and Weil algebras. Reverse-mode AD emerges as cotangent-pullback,
while Taylor-mode corresponds to evaluation in a Weil algebra. From these
principles, we derive concise statements on correctness, stability, and
complexity: a functorial identity for reverse-mode, algebraic exactness of
higher-order derivatives, and explicit bounds on truncation error. We further
show that tensorized Weil algebras permit one-pass computation of all mixed
derivatives with cost linear in the algebra dimension, avoiding the
combinatorial blow-up of nested JVP/VJP schedules. This framework interprets AD
theory through the lens of differential geometry and offers a foundation for
developing structure-preserving differentiation methods in deep learning and
scientific computing. Code and examples are available at
https://git.nilu.no/geometric-ad/jet-weil-ad.

</details>


### [149] [Exploratory Causal Inference in SAEnce](https://arxiv.org/abs/2510.14073)
*Tommaso Mencattini,Riccardo Cadei,Francesco Locatello*

Main category: cs.LG

TL;DR: 该文章提出了一种名为神经效应搜索（Neural Effect Search）的新方法，通过结合预训练基础模型和稀疏自编码器，从非结构化数据中发现治疗的未知因果效应，并解决了多重测试和效应纠缠问题。


<details>
  <summary>Details</summary>
Motivation: RCT（随机对照试验）依赖于手工假设和昂贵的分析，限制了大规模的因果效应估计，可能导致对流行但不完整的假设的固着。

Method: 将试验中的非结构化数据通过预训练基础模型转化为有意义的表示，然后通过稀疏自编码器进行解释。引入了一种新颖的递归过程——神经效应搜索（Neural Effect Search），通过逐步分层解决多重测试和效应纠缠问题。

Result: 在半合成实验中验证了算法的鲁棒性。在实验生态学背景下，首次成功实现了在真实科学试验中无监督的因果效应识别。

Conclusion: 神经效应搜索为从非结构化数据中大规模发现因果效应提供了一个有前景的解决方案，克服了传统RCT的局限性并解决了神经层面因果效应识别的挑战。

Abstract: Randomized Controlled Trials are one of the pillars of science; nevertheless,
they rely on hand-crafted hypotheses and expensive analysis. Such constraints
prevent causal effect estimation at scale, potentially anchoring on popular yet
incomplete hypotheses. We propose to discover the unknown effects of a
treatment directly from data. For this, we turn unstructured data from a trial
into meaningful representations via pretrained foundation models and interpret
them via a sparse autoencoder. However, discovering significant causal effects
at the neural level is not trivial due to multiple-testing issues and effects
entanglement. To address these challenges, we introduce Neural Effect Search, a
novel recursive procedure solving both issues by progressive stratification.
After assessing the robustness of our algorithm on semi-synthetic experiments,
we showcase, in the context of experimental ecology, the first successful
unsupervised causal effect identification on a real-world scientific trial.

</details>


### [150] [Interaction Concordance Index: Performance Evaluation for Interaction Prediction Methods](https://arxiv.org/abs/2510.14419)
*Tapio Pahikkala,Riikka Numminen,Parisa Movahedi,Napsu Karmitsa,Antti Airola*

Main category: cs.LG

TL;DR: 本文介绍了相互作用一致性指数（IC指数），这是一种用于评估药物-靶点亲和力（DTA）预测性能的新指标，它衡量了相互作用效果方向预测的准确性，并探讨了预测器在不同情况下的局限性。


<details>
  <summary>Details</summary>
Motivation: 在药物-靶点亲和力（DTA）预测中，现有方法侧重于预测DTA值，但未能充分评估药物和靶点之间相互作用的影响方向。了解相互作用对于优化药物分配和决策至关重要，因此需要一个新的评估指标来弥补这一空白。

Method: 本文提出了一种名为相互作用一致性指数（IC指数）的新指标，用于评估DTA相互作用方向的预测性能。IC指数通过衡量数据中相互作用效果方向的正确预测比例来补充现有的DTA预测性能评估指标。研究首先证明了IC指数对于无法捕捉相互作用的预测器的不变性。其次，研究表明，当药物、靶点或两者在训练期间未见过时，学习算法在药物和靶点身份方面的置换等变性意味着其无法捕捉相互作用。在实际应用中，通过纳入药物和靶点的适当辅助信息来弥补这种等变性。

Result: 通过对多个生物医学相互作用数据集和各种最先进的机器学习算法进行全面的实证评估，实验结果表明了不同类型的亲和力强度预测方法在IC指数方面的表现，从而补充了现有的预测性能评估指标。特别是，IC指数揭示了现有模型在预测相互作用方向方面的局限性，尤其是在处理未见过的药物或靶点时。

Conclusion: IC指数为药物-靶点相互作用预测提供了一个有价值的补充评估工具，揭示了现有模型在捕捉相互作用方向方面的能力和局限性。未来的研究可以探索如何设计更有效的模型来提高IC指数，并在处理稀疏数据和新实体时更好地捕捉相互作用。

Abstract: Consider two sets of entities and their members' mutual affinity values, say
drug-target affinities (DTA). Drugs and targets are said to interact in their
effects on DTAs if drug's effect on it depends on the target. Presence of
interaction implies that assigning a drug to a target and another drug to
another target does not provide the same aggregate DTA as the reversed
assignment would provide. Accordingly, correctly capturing interactions enables
better decision-making, for example, in allocation of limited numbers of drug
doses to their best matching targets. Learning to predict DTAs is popularly
done from either solely from known DTAs or together with side information on
the entities, such as chemical structures of drugs and targets. In this paper,
we introduce interaction directions' prediction performance estimator we call
interaction concordance index (IC-index), for both fixed predictors and machine
learning algorithms aimed for inferring them. IC-index complements the
popularly used DTA prediction performance estimators by evaluating the ratio of
correctly predicted directions of interaction effects in data. First, we show
the invariance of IC-index on predictors unable to capture interactions.
Secondly, we show that learning algorithm's permutation equivariance regarding
drug and target identities implies its inability to capture interactions when
either drug, target or both are unseen during training. In practical
applications, this equivariance is remedied via incorporation of appropriate
side information on drugs and targets. We make a comprehensive empirical
evaluation over several biomedical interaction data sets with various
state-of-the-art machine learning algorithms. The experiments demonstrate how
different types of affinity strength prediction methods perform in terms of
IC-index complementing existing prediction performance estimators.

</details>


### [151] [On the Identifiability of Tensor Ranks via Prior Predictive Matching](https://arxiv.org/abs/2510.14523)
*Eliezer da Silva,Arto Klami,Diego Mesquita,Iñigo Urteaga*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种基于先验预测矩匹配的概率张量模型中秩识别的严格方法，并将其应用于四种基本张量模型。研究发现，PARAFAC/CP、张量链和张量环模型的秩是可识别的，而Tucker模型的秩是不可识别的。


<details>
  <summary>Details</summary>
Motivation: 在张量分解中，选择潜在维度（秩）是一个核心挑战，通常依赖启发式方法。本论文旨在为概率张量模型提供一种严谨的秩识别方法。

Method: 该论文将一系列矩匹配条件转化为一个关于边际矩、先验超参数和秩的对数线性方程组，并建立了秩识别与该系统可解性之间的等价关系。

Result: 研究表明，PARAFAC/CP模型的线性结构、张量链模型的链式结构和张量环模型的闭环结构会产生可解系统，从而使其秩可识别。相反，Tucker模型的对称拓扑会导致欠定系统，使得其秩通过该方法不可识别。对于可识别模型，论文推导出了仅基于观测数据矩的显式闭式秩估计器。

Conclusion: 本研究提出了一种严谨的方法来确定概率张量模型中的秩识别性，并成功应用于多种张量模型。研究结果为张量分解中的秩选择问题提供了理论依据和实用的估计算法。

Abstract: Selecting the latent dimensions (ranks) in tensor factorization is a central
challenge that often relies on heuristic methods. This paper introduces a
rigorous approach to determine rank identifiability in probabilistic tensor
models, based on prior predictive moment matching. We transform a set of moment
matching conditions into a log-linear system of equations in terms of marginal
moments, prior hyperparameters, and ranks; establishing an equivalence between
rank identifiability and the solvability of such system. We apply this
framework to four foundational tensor-models, demonstrating that the linear
structure of the PARAFAC/CP model, the chain structure of the Tensor Train
model, and the closed-loop structure of the Tensor Ring model yield solvable
systems, making their ranks identifiable. In contrast, we prove that the
symmetric topology of the Tucker model leads to an underdetermined system,
rendering the ranks unidentifiable by this method. For the identifiable models,
we derive explicit closed-form rank estimators based on the moments of observed
data only. We empirically validate these estimators and evaluate the robustness
of the proposal.

</details>


### [152] [Seesaw: Accelerating Training by Balancing Learning Rate and Batch Size Scheduling](https://arxiv.org/abs/2510.14717)
*Alexandru Meterez,Depen Morwani,Jingfeng Wu,Costin-Andrei Oncescu,Cengiz Pehlevan,Sham Kakade*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为“Seesaw”的批次大小调度策略，通过在学习率减半时倍增批次大小，从而保持损失动态并减少训练步骤，最终加快大型语言模型的预训练过程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型预训练中，增加批次大小（batch ramp）是一种有前景的加速策略。然而，对于Adam等自适应优化器，批次大小调度的最优策略尚不明确，通常依赖启发式调整。

Method: 本文提出了一种原则性的批次大小调度框架——Seesaw。当标准调度器将学习率减半时，Seesaw将其乘以$1/\sqrt{2}$并同时将批次大小加倍。理论上，论文首次为SGD在带噪声线性回归上的学习率衰减和批次大小增加提供了有限样本等效性证明，并将其扩展到Adam的近似——归一化SGD，在实践中观察到的方差主导机制下也适用。

Result: 在Chinchilla规模的1.5亿/3亿/6亿参数模型上，Seesaw在相同FLOPs下与余弦衰减（cosine decay）方案表现相当，同时将实际训练时间缩短了约36%，接近于理论分析所暗示的极限。

Conclusion: Seesaw通过在学习率衰减时同步增加批次大小，有效地加速了大型语言模型的预训练过程，并在理论和实践中均显示出显著的性能提升。

Abstract: Increasing the batch size during training -- a ''batch ramp'' -- is a
promising strategy to accelerate large language model pretraining. While for
SGD, doubling the batch size can be equivalent to halving the learning rate,
the optimal strategy for adaptive optimizers like Adam is less clear. As a
result, any batch-ramp scheduling, if used at all, is typically tuned
heuristically. This work develops a principled framework for batch-size
scheduling and introduces Seesaw: whenever a standard scheduler would halve the
learning rate, Seesaw instead multiplies it by $1/\sqrt{2}$ and doubles the
batch size, preserving loss dynamics while reducing serial steps.
Theoretically, we provide, to our knowledge, the first finite-sample proof of
equivalence between learning-rate decay and batch-size ramp-up for SGD on noisy
linear regression, and we extend this equivalence to normalized SGD, a
tractable proxy for Adam, under a variance-dominated regime observed in
practice. Empirically, on 150M/300M/600M-parameter models trained at Chinchilla
scale using a constant (critical) batch size, Seesaw matches cosine decay at
equal FLOPs while reducing wall-clock time by $\approx 36\%$, approaching the
theoretical limit implied by our analysis.

</details>


### [153] [TENDE: Transfer Entropy Neural Diffusion Estimation](https://arxiv.org/abs/2510.14096)
*Simon Pedro Galeano Munoz,Mustapha Bounoua,Giulio Franzese,Pietro Michiardi,Maurizio Filippone*

Main category: cs.LG

TL;DR: TENDE是一种基于分数的扩散模型，用于估计条件互信息，从而克服了现有方法在维度灾难、分布假设和数据量方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有的传递熵估计方法存在维度灾难、严格的分布假设和收敛所需指数级大数据集的问题。

Method: TENDE利用基于分数的扩散模型，通过估计条件互信息来计算传递熵。它学习相关条件分布的分数函数，从而实现灵活、可扩展的估计，并且对数据生成过程做出最小的假设。

Result: 与现有神经估计器和其他最先进方法相比，TENDE在合成基准和真实数据上表现出卓越的准确性和鲁棒性。

Conclusion: TENDE为传递熵的估计提供了一种新颖、准确、鲁棒且可扩展的解决方案，克服了现有方法的局限性。

Abstract: Transfer entropy measures directed information flow in time series, and it
has become a fundamental quantity in applications spanning neuroscience,
finance, and complex systems analysis. However, existing estimation methods
suffer from the curse of dimensionality, require restrictive distributional
assumptions, or need exponentially large datasets for reliable convergence. We
address these limitations in the literature by proposing TENDE (Transfer
Entropy Neural Diffusion Estimation), a novel approach that leverages
score-based diffusion models to estimate transfer entropy through conditional
mutual information. By learning score functions of the relevant conditional
distributions, TENDE provides flexible, scalable estimation while making
minimal assumptions about the underlying data-generating process. We
demonstrate superior accuracy and robustness compared to existing neural
estimators and other state-of-the-art approaches across synthetic benchmarks
and real data.

</details>


### [154] [Causal Discovery for Linear DAGs with Dependent Latent Variables via Higher-order Cumulants](https://arxiv.org/abs/2510.14780)
*Ming Cai,Penggang Gao,Hisayuki Hara*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的算法，用于在存在潜在混杂因素的线性非高斯无环模型（LvLiNGAM）中识别因果有向无环图，该算法能够处理潜在变量之间、观测变量之间以及两者之间的因果结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LvLiNGAM中识别因果DAG时存在局限性，它们假设潜在混杂因素相互独立，或者无法正确处理观测变量之间存在因果关系的模型。

Method: 本论文提出了一种新颖的算法来识别LvLiLiNGAM中的因果DAG，该算法允许潜在变量之间、观测变量之间以及两者之间存在因果结构。它利用观测数据的高阶累积量来识别因果结构。

Result: 广泛的模拟和真实世界数据实验证明了所提出算法的有效性和实用性。

Conclusion: 本论文提出了一种新的算法，该算法能够有效地在存在潜在混杂因素的线性非高斯无环模型（LvLiNGAM）中识别因果有向无环图，并且能够处理更复杂的因果结构（包括潜在变量之间、观测变量之间以及两者之间的因果关系）。

Abstract: This paper addresses the problem of estimating causal directed acyclic graphs
in linear non-Gaussian acyclic models with latent confounders (LvLiNGAM).
Existing methods assume mutually independent latent confounders or cannot
properly handle models with causal relationships among observed variables.
  We propose a novel algorithm that identifies causal DAGs in LvLiNGAM,
allowing causal structures among latent variables, among observed variables,
and between the two. The proposed method leverages higher-order cumulants of
observed data to identify the causal structure. Extensive simulations and
experiments with real-world data demonstrate the validity and practical utility
of the proposed algorithm.

</details>


### [155] [Briding Diffusion Posterior Sampling and Monte Carlo methods: a survey](https://arxiv.org/abs/2510.14114)
*Yazid Janati,Alain Durmus,Jimmy Olsson,Eric Moulines*

Main category: cs.LG

TL;DR: 这篇综述探讨了利用预训练扩散模型和蒙特卡罗方法解决贝叶斯逆问题，无需额外训练，通过扭曲扩散过程中的中间分布来指导模拟。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模中非常重要，最近在解决贝叶斯逆问题方面显示出巨大潜力，因此有必要对利用预训练扩散模型解决这些问题的方法进行全面回顾。

Method: 本文综述了利用预训练扩散模型与蒙特卡罗方法相结合的方法。这些方法主要通过“扭曲”扩散过程中的中间分布来引导模拟趋向后验分布，然后采用各种蒙特卡罗方法从这些扭曲分布中进行采样。

Result: 现有的方法利用预训练扩散模型结合蒙特卡罗方法，通过扭曲扩散过程中的中间分布，成功地在无需额外训练的情况下解决了贝叶斯逆问题并辅助采样。

Conclusion: 预训练扩散模型结合蒙特卡罗方法，通过扭曲机制，为解决贝叶斯逆问题提供了一条无需额外训练的有效途径。

Abstract: Diffusion models enable the synthesis of highly accurate samples from complex
distributions and have become foundational in generative modeling. Recently,
they have demonstrated significant potential for solving Bayesian inverse
problems by serving as priors. This review offers a comprehensive overview of
current methods that leverage \emph{pre-trained} diffusion models alongside
Monte Carlo methods to address Bayesian inverse problems without requiring
additional training. We show that these methods primarily employ a
\emph{twisting} mechanism for the intermediate distributions within the
diffusion process, guiding the simulations toward the posterior distribution.
We describe how various Monte Carlo methods are then used to aid in sampling
from these twisted distributions.

</details>


### [156] [On Evaluating Loss Functions for Stock Ranking: An Empirical Analysis With Transformer Model](https://arxiv.org/abs/2510.14156)
*Jan Kwiatkowski,Jarosław A. Chudziak*

Main category: cs.LG

TL;DR: 深入研究了Transformer模型在股价预测与投资组合选择中的表现，特别侧重于不同训练损失函数（点式、对式、列表式）对模型学习股票收益排序能力的影响。


<details>
  <summary>Details</summary>
Motivation: 量化交易策略严重依赖股票的准确排序。虽然Transformer模型在金融时间序列分析中展现出潜力，但目前尚未充分理解不同的训练损失函数如何影响其股票排序能力。现有标准损失函数在股票收益预测和排序方面存在局限性，导致模型未能有效学习到正确的股票收益顺序。

Method: 本文系统地评估了包括点式、对式、列表式在内的多种高级损失函数，用于日收益预测，以优化基于S&P 500数据的投资组合选择。

Result: 通过全面的基准测试，揭示了不同损失函数如何影响模型学习截面和时间模式的能力，这些模式对于投资组合选择至关重要。

Conclusion: 本研究为优化基于排序的交易策略提供了实践指导，强调了损失函数在Transformer模型中对股票排序能力的关键影响。

Abstract: Quantitative trading strategies rely on accurately ranking stocks to identify
profitable investments. Effective portfolio management requires models that can
reliably order future stock returns. Transformer models are promising for
understanding financial time series, but how different training loss functions
affect their ability to rank stocks well is not yet fully understood. Financial
markets are challenging due to their changing nature and complex relationships
between stocks. Standard loss functions, which aim for simple prediction
accuracy, often aren't enough. They don't directly teach models to learn the
correct order of stock returns. While many advanced ranking losses exist from
fields such as information retrieval, there hasn't been a thorough comparison
to see how well they work for ranking financial returns, especially when used
with modern Transformer models for stock selection. This paper addresses this
gap by systematically evaluating a diverse set of advanced loss functions
including pointwise, pairwise, listwise for daily stock return forecasting to
facilitate rank-based portfolio selection on S&P 500 data. We focus on
assessing how each loss function influences the model's ability to discern
profitable relative orderings among assets. Our research contributes a
comprehensive benchmark revealing how different loss functions impact a model's
ability to learn cross-sectional and temporal patterns crucial for portfolio
selection, thereby offering practical guidance for optimizing ranking-based
trading strategies.

</details>


### [157] [Data Understanding Survey: Pursuing Improved Dataset Characterization Via Tensor-based Methods](https://arxiv.org/abs/2510.14161)
*Matthew D. Merris,Tim Andersen*

Main category: cs.LG

TL;DR: 该研究探讨了机器学习和数据分析领域中，张量方法如何克服传统数据集表征技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集表征方法（如统计、结构和模型分析）无法提供深入理解和洞察力，阻碍了创新和可解释性。

Method: 通过调查当前最先进的传统数据分析技术并检验其局限性，然后讨论张量方法及其如何提供更强大的替代方案。

Result: 张量方法揭示了细致的数据特征，提供了增强的可解释性和可操作的情报。

Conclusion: 倡导采用基于张量的表征方法，以增进对复杂数据集的理解，并为智能、可解释的数据驱动发现铺平道路。

Abstract: In the evolving domains of Machine Learning and Data Analytics, existing
dataset characterization methods such as statistical, structural, and
model-based analyses often fail to deliver the deep understanding and insights
essential for innovation and explainability. This work surveys the current
state-of-the-art conventional data analytic techniques and examines their
limitations, and discusses a variety of tensor-based methods and how these may
provide a more robust alternative to traditional statistical, structural, and
model-based dataset characterization techniques. Through examples, we
illustrate how tensor methods unveil nuanced data characteristics, offering
enhanced interpretability and actionable intelligence. We advocate for the
adoption of tensor-based characterization, promising a leap forward in
understanding complex datasets and paving the way for intelligent, explainable
data-driven discoveries.

</details>


### [158] [Towards Reversible Model Merging For Low-rank Weights](https://arxiv.org/abs/2510.14163)
*Mohammadsajad Alipour,Mohammad Mohammadi Amiri*

Main category: cs.LG

TL;DR: 本文提出了一种可逆模型合并（RMM）方法，旨在解决低秩模型合并时的性能下降问题。RMM通过构建一个可重建的模型空间来代替生成单一合并模型，从而允许在需要时恢复到原始的单个模型。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法在将模型压缩为低秩表示（如通过LoRA或SVD）时，会导致合并模型出现严重的性能下降。

Method: RMM通过构建一个紧凑的基（例如，相当于持有两个或更多模型），并允许通过线性组合恢复原始任务特定模型来重构模型空间。该方法提供了一个封闭形式的解决方案，用于选择模型权重的最优基和任务特定的线性组合系数。

Result: RMM在各种数据集和模型规模上都显著优于现有的合并方法，可以更好地保持低秩压缩模型的性能。

Conclusion: RMM通过构建可重建的模型空间，有效地解决了低秩模型合并的性能下降问题，并能在需要时恢复到原始的单个模型，从而提供了一种高效、无数据且灵活的模型合并方法。

Abstract: Model merging aims to combine multiple fine-tuned models into a single set of
weights that performs well across all source tasks. While prior work has shown
that merging can approximate the performance of individual fine-tuned models
for each task, it largely overlooks scenarios where models are compressed into
low-rank representations, either through low-rank adaptation (LoRA) or
post-training singular value decomposition (SVD). We first demonstrate that
applying conventional merging methods to low-rank weights leads to severe
performance degradation in the merged model. Motivated by this phenomenon, we
propose a fundamentally different approach: instead of collapsing all adapters
into one set of weights, we construct a compact basis (e.g., an equivalent of
holding two or more models) from which original task-specific models can be
recovered via linear combination. This reframes merging as generating a
reconstruction-capable model space rather than producing a single merged model.
Crucially, this allows us to ``revert'' to each individual model when needed,
recognizing that no merged model can consistently outperform one specialized
for its task. Building on this insight, we introduce our method, Reversible
Model Merging (RMM), an efficient, data-free, and flexible method that provides
a closed-form solution for selecting the optimal basis of model weights and
task-specific coefficients for linear combination. Extensive experiments across
diverse datasets and model scales demonstrate that RMM consistently outperforms
existing merging approaches, preserving the performance of low-rank compressed
models by a significant margin.

</details>


### [159] [MAFA: A Multi-Agent Framework for Enterprise-Scale Annotation with Configurable Task Adaptation](https://arxiv.org/abs/2510.14184)
*Mahmood Hegazy,Aaron Rodrigues,Azzam Naeem*

Main category: cs.LG

TL;DR: 本文介绍了MAFA（多智能体标注框架），这是一个已投入生产的系统，它通过可配置的多智能体协作来改进企业级标注工作流程。


<details>
  <summary>Details</summary>
Motivation: 解决金融服务领域中注释积压的挑战，其中数百万客户话语需要准确分类。

Method: MAFA结合了专门的智能体、结构化推理和基于判断的共识机制，支持动态任务适应，允许组织通过配置而不是代码更改来定义自定义注释类型。

Result: MAFA成功消除了100万个话语积压，与人工标注员的平均一致性达到86%，每年节省5000多小时的手动标注工作。系统处理的话语标注置信度分类通常为85%高、10%中和5%低。与传统和单智能体标注基线相比，Top-1准确率提高了13.8%，Top-5准确率提高了15.1%，F1值提高了16.9%。

Conclusion: MAFA将理论上的多智能体系统与实际的企业部署相结合，为面临类似标注挑战的组织提供了解决方案。

Abstract: We present MAFA (Multi-Agent Framework for Annotation), a production-deployed
system that transforms enterprise-scale annotation workflows through
configurable multi-agent collaboration. Addressing the critical challenge of
annotation backlogs in financial services, where millions of customer
utterances require accurate categorization, MAFA combines specialized agents
with structured reasoning and a judge-based consensus mechanism. Our framework
uniquely supports dynamic task adaptation, allowing organizations to define
custom annotation types (FAQs, intents, entities, or domain-specific
categories) through configuration rather than code changes. Deployed at JP
Morgan Chase, MAFA has eliminated a 1 million utterance backlog while
achieving, on average, 86% agreement with human annotators, annually saving
over 5,000 hours of manual annotation work. The system processes utterances
with annotation confidence classifications, which are typically 85% high, 10%
medium, and 5% low across all datasets we tested. This enables human annotators
to focus exclusively on ambiguous and low-coverage cases. We demonstrate MAFA's
effectiveness across multiple datasets and languages, showing consistent
improvements over traditional and single-agent annotation baselines: 13.8%
higher Top-1 accuracy, 15.1% improvement in Top-5 accuracy, and 16.9% better F1
in our internal intent classification dataset and similar gains on public
benchmarks. This work bridges the gap between theoretical multi-agent systems
and practical enterprise deployment, providing a blueprint for organizations
facing similar annotation challenges.

</details>


### [160] [Contrastive Diffusion Alignment: Learning Structured Latents for Controllable Generation](https://arxiv.org/abs/2510.14190)
*Ruchi Sandilya,Sumaira Perez,Charles Lynch,Lindsay Victoria,Benjamin Zebley,Derrick Matthew Buchanan,Mahendra T. Bhati,Nolan Williams,Timothy J. Spellman,Faith M. Gunning,Conor Liston,Logan Grosenick*

Main category: cs.LG

TL;DR: ConDA是一个将对比学习应用于扩散模型嵌入中的框架，旨在使潜在空间与系统动力学对齐，从而实现可解释的控制和更结构化的表示。


<details>
  <summary>Details</summary>
Motivation: 目前的扩散模型在生成方面表现出色，但其潜在空间并未明确组织以实现可解释的控制。现有的研究表明，对比目标可以恢复更解耦和结构化的表示，这促使ConDA利用对比学习来组织扩散潜在空间，使其遍历方向能够反映潜在的动力学因素。

Method: ConDA框架在扩散嵌入中应用对比学习，以对齐潜在几何与系统动力学。它通过组织扩散潜在空间，使得遍历方向能够反映潜在的动力学因素，从而在对比结构化的空间中实现非线性轨迹遍历。

Result: ConDA在流体动力学、神经钙成像、治疗性神经刺激和面部表情等基准测试中，相较于线性遍历和基于条件的方法，能够生成具有改进可控性的可解释潜在表示。

Conclusion: 这些结果表明扩散潜在空间编码了与动力学相关的结构，但要利用这种结构，需要对潜在空间进行组织并沿着潜在流形进行遍历。

Abstract: Diffusion models excel at generation, but their latent spaces are not
explicitly organized for interpretable control. We introduce ConDA (Contrastive
Diffusion Alignment), a framework that applies contrastive learning within
diffusion embeddings to align latent geometry with system dynamics. Motivated
by recent advances showing that contrastive objectives can recover more
disentangled and structured representations, ConDA organizes diffusion latents
such that traversal directions reflect underlying dynamical factors. Within
this contrastively structured space, ConDA enables nonlinear trajectory
traversal that supports faithful interpolation, extrapolation, and controllable
generation. Across benchmarks in fluid dynamics, neural calcium imaging,
therapeutic neurostimulation, and facial expression, ConDA produces
interpretable latent representations with improved controllability compared to
linear traversals and conditioning-based baselines. These results suggest that
diffusion latents encode dynamics-relevant structure, but exploiting this
structure requires latent organization and traversal along the latent manifold.

</details>


### [161] [Incentive-Based Federated Learning](https://arxiv.org/abs/2510.14208)
*Chanuka A. S. Hewa Kaluannakkage,Rajkumar Buyya*

Main category: cs.LG

TL;DR: 这篇论文探讨了联邦学习中的激励机制，强调其在解决参与困境和促进实际应用中的重要性。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的实际应用受限于参与困境，即参与者不愿贡献或存在搭便车行为。

Method: 将经济学和博弈论的基础概念应用于联邦学习，并结合区块链和深度强化学习等技术驱动的解决方案。提出了一个全面的分类法，涵盖了基于理论概念的中心化和去中心化架构。

Result: 设计良好的激励机制对于联邦学习的实际成功至关重要。分析揭示了现有解决方案的潜力和仍需克服的挑战，以构建可持续、公平和强大的联邦学习生态系统。

Conclusion: 有效的激励机制是联邦学习从理论走向实际成功的关键，需要综合经济学、博弈论和新兴技术来解决参与者贡献的公平性和可持续性问题。

Abstract: Federated learning promises to revolutionize machine learning by enabling
collaborative model training without compromising data privacy. However,
practical adaptability can be limited by critical factors, such as the
participation dilemma. Participating entities are often unwilling to contribute
to a learning system unless they receive some benefits, or they may pretend to
participate and free-ride on others. This chapter identifies the fundamental
challenges in designing incentive mechanisms for federated learning systems. It
examines how foundational concepts from economics and game theory can be
applied to federated learning, alongside technology-driven solutions such as
blockchain and deep reinforcement learning. This work presents a comprehensive
taxonomy that thoroughly covers both centralized and decentralized
architectures based on the aforementioned theoretical concepts. Furthermore,
the concepts described are presented from an application perspective, covering
emerging industrial applications, including healthcare, smart infrastructure,
vehicular networks, and blockchain-based decentralized systems. Through this
exploration, this chapter demonstrates that well-designed incentive mechanisms
are not merely optional features but essential components for the practical
success of federated learning. This analysis reveals both the promising
solutions that have emerged and the significant challenges that remain in
building truly sustainable, fair, and robust federated learning ecosystems.

</details>


### [162] [Spectral Analysis of Molecular Kernels: When Richer Features Do Not Guarantee Better Generalization](https://arxiv.org/abs/2510.14217)
*Asma Jamali,Tin Sum Cheng,Rodrigo A. Vargas-Hernández*

Main category: cs.LG

TL;DR: 该文章首次对分子核函数进行了全面的谱分析，发现谱的丰富度与预测精度之间存在复杂的关系，有时甚至呈负相关。


<details>
  <summary>Details</summary>
Motivation: 深入理解核函数的谱特性对于解释模型的泛化能力和表示质量至关重要。尽管深度学习在分子性质预测中取得了领先成果，但核方法因其在数据量较少时的稳健性和坚实的理论基础而仍被广泛应用。

Method: 本文在QM9数据集上，对分子指纹、预训练的Transformer模型、全局和局部3D表示以及七种分子性质的核脊回归进行了全面的谱分析。研究中使用了四种不同的谱度量来衡量谱特征，并通过Pearson相关性检验分析了谱特征与性能之间的关系。此外，作者还实现了截断核，以探究谱与预测性能之间的关系。

Result: 研究发现更丰富的谱特征（通过四种不同的谱度量衡量）并不总是能提高准确性。Pearson相关性检验表明，对于基于Transformer和局部3D表示的模型，谱的丰富度甚至可能与性能呈负相关。通过截断核的实验发现，在许多核中，仅保留前2%的特征值就能恢复几乎所有的性能，这表明主要的特征值捕获了信息量最大的特征。

Conclusion: 该研究挑战了“谱越丰富，泛化能力越好”的普遍启发式认知，并揭示了表示、核特征和预测性能之间细致入微的关系。这些发现不仅对分子性质预测领域有重要意义，也为数据受限的科学和实际任务中核方法和自监督学习方法的评估提供了新的思路。

Abstract: Understanding the spectral properties of kernels offers a principled
perspective on generalization and representation quality. While deep models
achieve state-of-the-art accuracy in molecular property prediction, kernel
methods remain widely used for their robustness in low-data regimes and
transparent theoretical grounding. Despite extensive studies of kernel spectra
in machine learning, systematic spectral analyses of molecular kernels are
scarce. In this work, we provide the first comprehensive spectral analysis of
kernel ridge regression on the QM9 dataset, molecular fingerprint, pretrained
transformer-based, global and local 3D representations across seven molecular
properties. Surprisingly, richer spectral features, measured by four different
spectral metrics, do not consistently improve accuracy. Pearson correlation
tests further reveal that for transformer-based and local 3D representations,
spectral richness can even have a negative correlation with performance. We
also implement truncated kernels to probe the relationship between spectrum and
predictive performance: in many kernels, retaining only the top 2% of
eigenvalues recovers nearly all performance, indicating that the leading
eigenvalues capture the most informative features. Our results challenge the
common heuristic that "richer spectra yield better generalization" and
highlight nuanced relationships between representation, kernel features, and
predictive performance. Beyond molecular property prediction, these findings
inform how kernel and self-supervised learning methods are evaluated in
data-limited scientific and real-world tasks.

</details>


### [163] [Scaling Test-Time Compute to Achieve IOI Gold Medal with Open-Weight Models](https://arxiv.org/abs/2510.14232)
*Mehrzad Samadi,Aleksander Ficek,Sean Narenthiran,Siddhartha Jain,Wasi Uddin Ahmad,Somshubra Majumdar,Vahid Noroozi,Boris Ginsburg*

Main category: cs.LG

TL;DR: 本文提出了GenCluster，一个可扩展的测试时计算框架，使用开放权重的模型实现了IOI金牌级别的表现，并通过实验证明了其性能随计算资源的增加而稳定提升，缩小了开放系统和封闭系统之间的差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在竞争性编程中的表现是评估其推理和解决问题能力的重要标准。IOI是衡量人类和AI编程能力的关键基准，但目前开放权重模型难以达到IOI金牌水平。

Method: GenCluster结合了大规模生成、行为聚类、排名和循环提交策略，在有限的验证预算下高效探索多样化的解决方案空间。

Result: 实验表明，GenCluster的性能随可用计算资源的增加而稳定提升，缩小了开放系统和封闭系统之间的差距。使用开放权重的gpt-oss-120b模型，GenCluster在IOI 2025中首次获得了金牌。

Conclusion: GenCluster为LLM的透明和可复现评估设定了新的基准，证明了开放权重模型也能达到IOI金牌水平。

Abstract: Competitive programming has become a rigorous benchmark for evaluating the
reasoning and problem-solving capabilities of large language models (LLMs). The
International Olympiad in Informatics (IOI) stands out as one of the most
prestigious annual competitions in competitive programming and has become a key
benchmark for comparing human and AI-level programming ability. While several
proprietary models have been claimed to achieve gold medal-level performance at
the IOI, often with undisclosed methods, achieving comparable results with
open-weight models remains a significant challenge. In this paper, we present
\gencluster, a scalable and reproducible test-time compute framework that
attains IOI gold-level performance using open-weight models. It combines
large-scale generation, behavioral clustering, ranking, and a round-robin
submission strategy to efficiently explore diverse solution spaces under
limited validation budgets. Our experiments show that the performance of our
proposed approach scales consistently with available compute, narrowing the gap
between open and closed systems. Notably, we will show that GenCluster can
achieve a gold medal at IOI 2025 for the first time with an open-weight model
gpt-oss-120b, setting a new benchmark for transparent and reproducible
evaluation of reasoning in LLMs.

</details>


### [164] [Generalist vs Specialist Time Series Foundation Models: Investigating Potential Emergent Behaviors in Assessing Human Health Using PPG Signals](https://arxiv.org/abs/2510.14254)
*Saurabh Kataria,Yi Wu,Zhaoliang Chen,Hyunjung Gloria Kwak,Yuhao Xu,Lovely Yeswanth Panchumarthi,Ran Xiao,Jiaying Lu,Ayca Ermis,Anni Zhao,Runze Yan,Alex Federov,Zewen Liu,Xu Wu,Wei Jin,Carl Yang,Jocelyn Grunwell,Stephanie R. Brown,Amit Shah,Craig Jabaley,Tim Buchman,Sivasubramanium V Bhavani,Randall J. Lee,Xiao Hu*

Main category: cs.LG

TL;DR: 本文对通用和专用时间序列基础模型在生理信号（尤其是PPG信号）方面的性能进行了全面的基准测试研究。结果显示，在完全调整的情况下，专用模型的胜率高出27%。


<details>
  <summary>Details</summary>
Motivation: 基础模型在时间序列分析，特别是生理传感领域受到越来越多的关注。然而，大多数现有模型是专用的。本文旨在全面比较通用和专用模型，特别关注PPG信号。

Method: 本文对通用和专用时间序列基础模型进行了全面的基准测试研究。通过51项任务，涵盖心脏状态评估、实验室值估计和跨模态推断，在胜率、平均性能、特征质量、调整增益、性能方差、可迁移性和可扩展性七个维度上对模型进行了评估。

Result: 在完全调整的情况下，专用模型的胜率比通用模型高出27%。

Conclusion: 专用模型在生理信号处理方面表现出显著优势，本文还对泛化性、公平性、注意力可视化和训练数据选择的重要性进行了进一步分析。

Abstract: Foundation models are large-scale machine learning models that are
pre-trained on massive amounts of data and can be adapted for various
downstream tasks. They have been extensively applied to tasks in Natural
Language Processing and Computer Vision with models such as GPT, BERT, and
CLIP. They are now also increasingly gaining attention in time-series analysis,
particularly for physiological sensing. However, most time series foundation
models are specialist models - with data in pre-training and testing of the
same type, such as Electrocardiogram, Electroencephalogram, and
Photoplethysmogram (PPG). Recent works, such as MOMENT, train a generalist time
series foundation model with data from multiple domains, such as weather,
traffic, and electricity. This paper aims to conduct a comprehensive
benchmarking study to compare the performance of generalist and specialist
models, with a focus on PPG signals. Through an extensive suite of total 51
tasks covering cardiac state assessment, laboratory value estimation, and
cross-modal inference, we comprehensively evaluate both models across seven
dimensions, including win score, average performance, feature quality, tuning
gain, performance variance, transferability, and scalability. These metrics
jointly capture not only the models' capability but also their adaptability,
robustness, and efficiency under different fine-tuning strategies, providing a
holistic understanding of their strengths and limitations for diverse
downstream scenarios. In a full-tuning scenario, we demonstrate that the
specialist model achieves a 27% higher win score. Finally, we provide further
analysis on generalization, fairness, attention visualizations, and the
importance of training data choice.

</details>


### [165] [CAST: Compositional Analysis via Spectral Tracking for Understanding Transformer Layer Functions](https://arxiv.org/abs/2510.14262)
*Zihao Fu,Ming Liao,Chris Russell,Zhenguang G. Cai*

Main category: cs.LG

TL;DR: CAST是一个探究大型语言模型内部机制的框架，它提供了一种无探针的方法，通过直接估计转换矩阵和全面的频谱分析来分析Transformer层函数。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型取得了显著成功，但在内部机制方面仍然是一个黑箱。为了解决这一限制，许多研究人员提出了各种可解释性方法，但每种方法都从不同角度提供有价值的见解。

Method: CAST框架通过使用Moore-Penrose伪逆估计每个层的实现转换矩阵，并应用具有六个可解释指标的频谱分析来表征层行为，从而分析Transformer层函数。此外，还使用核分析进一步证明了层之间的功能关系模式。

Result: 分析揭示了编码器模型和解码器模型之间存在明显的行为差异，解码器模型表现出压缩-扩展周期，而编码器模型模型保持一致的高秩处理。核分析表明，层之间存在功能关系模式，CKA相似性矩阵将层清晰地划分为三个阶段：特征提取、压缩和专业化。

Conclusion: CAST框架通过直接转换矩阵估计和全面的频谱分析，为理解大型语言模型的内部机制提供了一个新颖的视角。它揭示了不同模型架构的独特行为，并识别了层功能的不同阶段。

Abstract: Large language models have achieved remarkable success but remain largely
black boxes with poorly understood internal mechanisms. To address this
limitation, many researchers have proposed various interpretability methods
including mechanistic analysis, probing classifiers, and activation
visualization, each providing valuable insights from different perspectives.
Building upon this rich landscape of complementary approaches, we introduce
CAST (Compositional Analysis via Spectral Tracking), a probe-free framework
that contributes a novel perspective by analyzing transformer layer functions
through direct transformation matrix estimation and comprehensive spectral
analysis. CAST offers complementary insights to existing methods by estimating
the realized transformation matrices for each layer using Moore-Penrose
pseudoinverse and applying spectral analysis with six interpretable metrics
characterizing layer behavior. Our analysis reveals distinct behaviors between
encoder-only and decoder-only models, with decoder models exhibiting
compression-expansion cycles while encoder models maintain consistent high-rank
processing. Kernel analysis further demonstrates functional relationship
patterns between layers, with CKA similarity matrices clearly partitioning
layers into three phases: feature extraction, compression, and specialization.

</details>


### [166] [Stable Prediction of Adverse Events in Medical Time-Series Data](https://arxiv.org/abs/2510.14286)
*Mayank Keoliya,Seewon Choi,Rajeev Alur,Mayur Naik,Eric Wong*

Main category: cs.LG

TL;DR: CAREBench是一个早期事件预测（EEP）基准，它使用多模态输入评估系统的可部署性，并评估时间稳定性以及预测准确性。


<details>
  <summary>Details</summary>
Motivation: 目前的基准测试忽略了风险评分的稳定性，并且主要在表格输入上进行评估，导致轨迹行为未经测试。

Method: CAREBench是一个早期事件预测（EEP）基准，它使用多模态输入（表格电子病历、心电图波形和临床文本）评估系统的可部署性，并评估时间稳定性以及预测准确性。本文提出了一种稳定性度量，可以量化每位患者风险的短期变异性，并根据局部Lipschitz常数惩罚突然的波动。

Result: 现有的方法，特别是大型语言模型（LLMs），难以 F同时优化准确性和稳定性，在 Some高精度操作点上召回率 YL很低。

Conclusion: 为了在连续监测环境中赢得临床医生的信任，需要开发能够生成与证据对齐的稳定轨迹的模型。

Abstract: Early event prediction (EEP) systems continuously estimate a patient's
imminent risk to support clinical decision-making. For bedside trust, risk
trajectories must be accurate and temporally stable, shifting only with new,
relevant evidence. However, current benchmarks (a) ignore stability of risk
scores and (b) evaluate mainly on tabular inputs, leaving trajectory behavior
untested. To address this gap, we introduce CAREBench, an EEP benchmark that
evaluates deployability using multi-modal inputs-tabular EHR, ECG waveforms,
and clinical text-and assesses temporal stability alongside predictive
accuracy. We propose a stability metric that quantifies short-term variability
in per-patient risk and penalizes abrupt oscillations based on local-Lipschitz
constants. CAREBench spans six prediction tasks such as sepsis onset and
compares classical learners, deep sequence models, and zero-shot LLMs. Across
tasks, existing methods, especially LLMs, struggle to jointly optimize accuracy
and stability, with notably poor recall at high-precision operating points.
These results highlight the need for models that produce evidence-aligned,
stable trajectories to earn clinician trust in continuous monitoring settings.
(Code: https://github.com/SeewonChoi/CAREBench.)

</details>


### [167] [Enhancing Time-Series Anomaly Detection by Integrating Spectral-Residual Bottom-Up Attention with Reservoir Computing](https://arxiv.org/abs/2510.14287)
*Hayato Nihei,Sou Nobukawa,Yusuke Sakemi,Kazuyuki Aihara*

Main category: cs.LG

TL;DR: 本文提出了一种结合谱残差（SR）方法和储备池计算（RC）的SR-RC模型，用于时间序列异常检测，旨在提高性能并保持学习效率，尤其适用于资源受限的边缘AI设备。


<details>
  <summary>Details</summary>
Motivation: 在边缘AI应用中，实时时间序列异常检测至关重要，但传统的储备池计算（RC）在资源受限设备上可能需要过大的储备池才能达到理想的检测性能。虽然注意力机制可以提高准确性，但可能会增加计算量并降低RC的学习效率。因此，本文旨在无需牺牲学习效率的前提下，提高RC的异常检测性能。

Method: 本文提出了一种谱残差储备池计算（SR-RC）模型。SR-RC将谱残差（SR）方法（一种无需学习的自底向上注意力机制）与储备池计算（RC）相结合。

Result: SR-RC在基准任务和真实世界时间序列数据集上，表现优于传统的RC模型和基于SR方法提取值的逻辑回归模型。

Conclusion: SR-RC为在时间序列异常检测的边缘AI部署RC提供了一个实用的方向，因为SR方法和RC本身都非常适合硬件实现。

Abstract: Reservoir computing (RC) establishes the basis for the processing of
time-series data by exploiting the high-dimensional spatiotemporal response of
a recurrent neural network to an input signal. In particular, RC trains only
the output layer weights. This simplicity has drawn attention especially in
Edge Artificial Intelligence (AI) applications. Edge AI enables time-series
anomaly detection in real time, which is important because detection delays can
lead to serious incidents. However, achieving adequate anomaly-detection
performance with RC alone may require an unacceptably large reservoir on
resource-constrained edge devices. Without enlarging the reservoir, attention
mechanisms can improve accuracy, although they may require substantial
computation and undermine the learning efficiency of RC. In this study, to
improve the anomaly detection performance of RC without sacrificing learning
efficiency, we propose a spectral residual RC (SR-RC) that integrates the
spectral residual (SR) method - a learning-free, bottom-up attention mechanism
- with RC. We demonstrated that SR-RC outperformed conventional RC and
logistic-regression models based on values extracted by the SR method across
benchmark tasks and real-world time-series datasets. Moreover, because the SR
method, similarly to RC, is well suited for hardware implementation, SR-RC
suggests a practical direction for deploying RC as Edge AI for time-series
anomaly detection.

</details>


### [168] [LLM-ERM: Sample-Efficient Program Learning via LLM-Guided Search](https://arxiv.org/abs/2510.14331)
*Shivam Singhal,Eran Malach,Tomaso Poggio,Tomer Galanti*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为LLM-ERM的程序学习框架，它通过LLM引导的搜索和ERM风格的选择，解决了传统方法在样本效率和计算成本方面的局限性，实现了在少量样本下对复杂任务的学习。


<details>
  <summary>Details</summary>
Motivation: 传统的程序学习方法要么样本效率高但计算成本高昂（如长度优先枚举），要么计算可行但样本效率低（如梯度训练）。因此，需要一种新的算法来平衡样本效率和计算可行性。

Method: 本文提出LLM-ERM框架，它结合了预训练的LLM（用于生成候选程序）和ERM风格的选择（在保留数据上验证）。具体而言，LLM-ERM生成k个候选程序，编译并检查每个程序，然后返回最佳验证假设。这一过程不涉及反馈、自适应或梯度。

Result: 理论上，本文证明了坐标在线mini-batch SGD在学习某些短程序时需要大量样本。经验上，LLM-ERM能够以最少200个样本解决奇偶校验变体、模式匹配和素性测试等任务，而SGD训练的Transformer即使在100,000个样本下也会过拟合。

Conclusion: LLM-ERM通过语言引导的程序合成，在保持计算可行性的同时，恢复了有限类ERM的统计效率。这为学习简洁的假设提供了一种实用的途径，超出了基于梯度训练的范围。

Abstract: We seek algorithms for program learning that are both sample-efficient and
computationally feasible. Classical results show that targets admitting short
program descriptions (e.g., with short ``python code'') can be learned with a
``small'' number of examples (scaling with the size of the code) via
length-first program enumeration, but the search is exponential in description
length. Consequently, Gradient-based training avoids this cost yet can require
exponentially many samples on certain short-program families.
  To address this gap, we introduce LLM-ERM, a propose-and-verify framework
that replaces exhaustive enumeration with an LLM-guided search over candidate
programs while retaining ERM-style selection on held-out data. Specifically, we
draw $k$ candidates with a pretrained reasoning-augmented LLM, compile and
check each on the data, and return the best verified hypothesis, with no
feedback, adaptivity, or gradients. Theoretically, we show that coordinate-wise
online mini-batch SGD requires many samples to learn certain short programs.
{\em Empirically, LLM-ERM solves tasks such as parity variants, pattern
matching, and primality testing with as few as 200 samples, while SGD-trained
transformers overfit even with 100,000 samples}. These results indicate that
language-guided program synthesis recovers much of the statistical efficiency
of finite-class ERM while remaining computationally tractable, offering a
practical route to learning succinct hypotheses beyond the reach of
gradient-based training.

</details>


### [169] [DARTS-GT: Differentiable Architecture Search for Graph Transformers with Quantifiable Instance-Specific Interpretability Analysis](https://arxiv.org/abs/2510.14336)
*Shruti Sarika Chakraborty,Peter Minary*

Main category: cs.LG

TL;DR: DARTS-GT通过非对称注意力机制和可微分架构搜索，为图Transformer实现了深度异构性，并在性能和可解释性方面取得了显著提升，同时通过因果归因量化了可解释性。


<details>
  <summary>Details</summary>
Motivation: 目前的图Transformer（GTs）受限于固定的GNN类型和缺乏可量化的可解释性。现有的SOTA GTs在所有层中都采用固定的GNN类型，未能充分利用深度特定组件选择的潜在优势。此外，其复杂的架构使得性能提升的原因难以区分是来自有意义的模式还是虚假关联。

Method: 本文通过引入非对称性重新设计了GT的注意力机制，将结构编码与特征表示解耦：查询来自于节点特征，而键和值来自于GNN变换。在此框架内，利用可微分架构搜索（DARTS）为每一层选择最优的GNN操作符，从而在Transformer注意力内部实现了深度异构性（DARTS-GT）。此外，开发了第一个针对GTs的量化可解释性框架，该框架通过因果消融法进行量化，并引入了Head-deviation、Specialization和Focus等指标来识别哪些注意力头和节点驱动预测，并支持模型比较。

Result: DARTS-GT在八个基准测试中的四个数据集上取得了最先进的性能，并在其他数据集上保持了竞争力。通过DARTS-GT发现的架构揭示了数据集特定的模式。可解释性分析表明，视觉注意力显著性与因果重要性不总是相关，这暗示广泛使用的可视化方法可能忽略了真正重要的组件。

Conclusion: DARTS-GT发现的异构架构始终比基线模型产生更具可解释性的模型，这表明图Transformer无需在性能和可解释性之间做出权衡。本文通过非对称注意力机制和可微分架构搜索，为图Transformer实现了深度异构性，并在性能和可解释性方面取得了显著提升，同时通过因果归因量化了可解释性。

Abstract: Graph Transformers (GTs) have emerged as powerful architectures for
graph-structured data, yet remain constrained by rigid designs and lack
quantifiable interpretability. Current state-of-the-art GTs commit to fixed GNN
types across all layers, missing potential benefits of depth-specific component
selection, while their complex architectures become opaque where performance
gains cannot be distinguished between meaningful patterns and spurious
correlations. We redesign GT attention through asymmetry, decoupling structural
encoding from feature representation: queries derive from node features while
keys and values come from GNN transformations. Within this framework, we use
Differentiable ARchiTecture Search (DARTS) to select optimal GNN operators at
each layer, enabling depth-wise heterogeneity inside transformer attention
itself (DARTS-GT). To understand discovered architectures, we develop the first
quantitative interpretability framework for GTs through causal ablation. Our
metrics (Head-deviation, Specialization, and Focus), identify which heads and
nodes drive predictions while enabling model comparison. Experiments across
eight benchmarks show DARTS-GT achieves state-of-the-art on four datasets while
remaining competitive on others, with discovered architectures revealing
dataset-specific patterns. Our interpretability analysis reveals that visual
attention salience and causal importance do not always correlate, indicating
widely used visualization approaches may miss components that actually matter.
Crucially, heterogeneous architectures found by DARTS-GT consistently produced
more interpretable models than baselines, establishing that Graph Transformers
need not choose between performance and interpretability.

</details>


### [170] [Stop-RAG: Value-Based Retrieval Control for Iterative RAG](https://arxiv.org/abs/2510.14337)
*Jaewan Park,Solbee Cho,Jay-Yoon Lee*

Main category: cs.LG

TL;DR: Stop-RAG通过价值函数，在检索增强生成时进行自适应停止，在多跳问答中效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有的迭代检索增强生成（RAG）方法在回答复杂的多跳问题时，会增加延迟、成本，并可能引入干扰信息。虽然一些方法使用预设的迭代次数，但它们无法准确判断何时停止检索才能真正有益。

Method: 本文将迭代RAG建模为一个有限范围的马尔可夫决策过程，并引入了Stop-RAG。这是一个基于价值的控制器，能够自适应地决定何时停止检索。Stop-RAG通过使用完整轨迹中的全宽前向Q($ecdummy$)值目标进行训练，从而学习有效的停止策略。该方法兼容黑盒API和现有管道。

Result: 在多跳问答基准测试中，Stop-RAG的表现始终优于固定迭代基线和基于大语言模型提示的停止方法。

Conclusion: 自适应停止是当前智能体系统缺失的关键组件，基于价值的控制可以提高RAG系统的准确性。

Abstract: Iterative retrieval-augmented generation (RAG) enables large language models
to answer complex multi-hop questions, but each additional loop increases
latency, costs, and the risk of introducing distracting evidence, motivating
the need for an efficient stopping strategy. Existing methods either use a
predetermined number of iterations or rely on confidence proxies that poorly
reflect whether more retrieval will actually help. We cast iterative RAG as a
finite-horizon Markov decision process and introduce Stop-RAG, a value-based
controller that adaptively decides when to stop retrieving. Trained with
full-width forward-view Q($\lambda$) targets from complete trajectories,
Stop-RAG learns effective stopping policies while remaining compatible with
black-box APIs and existing pipelines. On multi-hop question-answering
benchmarks, Stop-RAG consistently outperforms both fixed-iteration baselines
and prompting-based stopping with LLMs. These results highlight adaptive
stopping as a key missing component in current agentic systems, and demonstrate
that value-based control can improve the accuracy of RAG systems.

</details>


### [171] [Revisit Modality Imbalance at the Decision Layer](https://arxiv.org/abs/2510.14411)
*Xiaoyu Ma,Hao Chen*

Main category: cs.LG

TL;DR: 这篇论文揭示了多模态学习中模态不平衡的问题，它不仅发生在表征学习阶段，而且在决策层也存在。研究表明，即使经过预训练和平衡优化，模型仍然对某些模态（如音频）存在系统性偏差。这种偏差源于特征空间和决策权重分布的内在差异，而不是优化动态。论文提出未来的多模态系统应更多地关注在决策层引入自适应权重分配机制，以实现每个模态能力的相对平衡。


<details>
  <summary>Details</summary>
Motivation: 多模态学习通过整合不同模态的信息来提升模型性能，但经常受到模态不平衡问题的困扰，即在联合优化过程中，主导模态会掩盖较弱的模态。本文旨在揭示这种不平衡不仅出现在表征学习中，而且在决策层也显著存在，并探究其根本原因。

Method: 通过在音视频数据集（CREMAD和Kinetic-Sounds）上进行实验，论文展示了即使经过广泛的预训练和平衡优化，模型仍表现出对某些模态（如音频）的系统性偏差。进一步的分析表明，这种偏差来源于特征空间和决策权重分布的内在差异。

Result: 实验结果表明，多模态模型即使在优化后，仍然对特定模态（如音频）存在偏好。这种偏好并非简单地由优化引起，而是深层地源于不同模态在特征空间和决策权重分布上的固有差异。融合阶段未校准的模态输出导致决策层加权偏差，阻碍了较弱模态的有效贡献。

Conclusion: 多模态学习中的模态不平衡问题在决策层显著存在，且根源于特征空间和决策权重的内在差异。未来的多模态系统应着重在决策层引入自适应权重分配机制，以平衡各模态的贡献，从而实现更鲁棒和有效的多模态融合。

Abstract: Multimodal learning integrates information from different modalities to
enhance model performance, yet it often suffers from modality imbalance, where
dominant modalities overshadow weaker ones during joint optimization. This
paper reveals that such an imbalance not only occurs during representation
learning but also manifests significantly at the decision layer. Experiments on
audio-visual datasets (CREMAD and Kinetic-Sounds) show that even after
extensive pretraining and balanced optimization, models still exhibit
systematic bias toward certain modalities, such as audio. Further analysis
demonstrates that this bias originates from intrinsic disparities in
feature-space and decision-weight distributions rather than from optimization
dynamics alone. We argue that aggregating uncalibrated modality outputs at the
fusion stage leads to biased decision-layer weighting, hindering weaker
modalities from contributing effectively. To address this, we propose that
future multimodal systems should focus more on incorporate adaptive weight
allocation mechanisms at the decision layer, enabling relative balanced
according to the capabilities of each modality.

</details>


### [172] [MergeMoE: Efficient Compression of MoE Models via Expert Output Merging](https://arxiv.org/abs/2510.14436)
*Ruijie Miao,Yilun Yao,Zihan Wang,Zhiming Wang,Bairen Yi,LingJun Liu,Yikai Zhao,Tong Yang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为MergeMoE的新方法，用于压缩MoE模型，通过将专家合并解释为在正向计算中插入额外的矩阵，并利用数学优化来构建压缩矩阵，从而在相同压缩比下优于基线方法。


<details>
  <summary>Details</summary>
Motivation: MoE技术在扩展LLM模型尺寸方面表现出前景，但其巨大的内存开销使得模型压缩成为重要的研究方向。

Method: MergeMoE方法： 1. 将专家合并从参数聚合的传统视角转变为合并专家输出的视角。 2. 将合并过程解释为在正向计算中插入额外的矩阵。 3. 利用数学优化来构建压缩矩阵。

Result: MergeMoE算法在多个MoE模型上进行了评估，并显示出在相同压缩比下始终优于基线方法。

Conclusion: MergeMoE通过创新的专家合并解释和数学优化方法，有效地解决了MoE模型的压缩问题，并在实验中取得了优异的性能。

Abstract: The Mixture-of-Experts (MoE) technique has proven to be a promising solution
to efficiently scale the model size, which has been widely applied in recent
LLM advancements. However, the substantial memory overhead of MoE models has
made their compression an important research direction. In this work, we
provide a theoretical analysis of expert merging, a recently proposed technique
for compressing MoE models. Rather than interpreting expert merging from the
conventional perspective of parameter aggregation, we approach it from the
perspective of merging experts' outputs. Our key insight is that the merging
process can be interpreted as inserting additional matrices into the forward
computation, which naturally leads to an optimization formulation. Building on
this analysis, we introduce MergeMoE, a method that leverages mathematical
optimization to construct the compression matrices. We evaluate MergeMoE on
multiple MoE models and show that our algorithm consistently outperforms the
baselines with the same compression ratios.

</details>


### [173] [A Free Lunch in LLM Compression: Revisiting Retraining after Pruning](https://arxiv.org/abs/2510.14444)
*Moritz Wagner,Christophe Roux,Max Zimmer,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 这篇论文研究了大型语言模型（LLMs）剪枝后权重重构或再训练的关键设计选择，发现将注意力机制和多层感知器（MLP）组件在每个Transformer块内分开重构，在资源效率和困惑度方面表现最优，甚至优于完全再训练，并且简单的剪枝标准在正确执行重构步骤时也能表现出色。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLMs）剪枝方法通常通过在少量校准数据上解决层级掩码选择和重构问题来避免完全再训练，因为对LLMs进行完全再训练在计算上是不可行的。尽管孤立地重构单个矩阵具有良好的特性，但在实践中，重构通常在更粗糙的粒度上实现，例如重构整个Transformer块。因此，本文旨在研究剪枝后剩余权重重构或再训练的关键设计选择。

Method: 作者对最先进的GPT架构进行了广泛的计算研究，以探讨剪枝后重构或再训练剩余权重的关键设计选择。

Result: 作者发现，将每个Transformer块内的注意力机制和MLP组件分开重构，是资源效率最高且困惑度最佳的方法，甚至优于完全再训练，并且所需内存仅占一小部分。此外，简单的剪枝标准（如Wanda）在正确执行重构步骤时，可以胜过更复杂的方法。

Conclusion: 这篇论文的发现挑战了“应不惜一切代价避免再训练”的观点，并为LLMs剪枝后的性能恢复提供了重要见解。研究表明，在LLMs剪枝后，精心设计的重构策略能够以更低的成本获得更好的性能，甚至超越完全再训练。

Abstract: While Neural Network pruning typically requires retraining the model to
recover pruning-induced performance degradation, state-of-the-art Large
Language Models (LLMs) pruning methods instead solve a layer-wise mask
selection and reconstruction problem on a small set of calibration data to
avoid full retraining, as it is considered computationally infeasible for LLMs.
Reconstructing single matrices in isolation has favorable properties, such as
convexity of the objective and significantly reduced memory requirements
compared to full retraining. In practice, however, reconstruction is often
implemented at coarser granularities, e.g., reconstructing a whole transformer
block against its dense activations instead of a single matrix. In this work,
we study the key design choices when reconstructing or retraining the remaining
weights after pruning. We conduct an extensive computational study on
state-of-the-art GPT architectures, and report several surprising findings that
challenge common intuitions about retraining after pruning. In particular, we
observe a free lunch scenario: reconstructing attention and MLP components
separately within each transformer block is nearly the most resource-efficient
yet achieves the best perplexity. Most importantly, this Pareto-optimal setup
achieves better performance than full retraining, despite requiring only a
fraction of the memory. Furthermore, we demonstrate that simple and efficient
pruning criteria such as Wanda can outperform much more complex approaches when
the reconstruction step is properly executed, highlighting its importance. Our
findings challenge the narrative that retraining should be avoided at all costs
and provide important insights into post-pruning performance recovery for LLMs.

</details>


### [174] [Feature Selection and Regularization in Multi-Class Classification: An Empirical Study of One-vs-Rest Logistic Regression with Gradient Descent Optimization and L1 Sparsity Constraints](https://arxiv.org/abs/2510.14449)
*Jahidul Arafat,Fariha Tasmin,Md Kaosar Uddin,Sanjaya Poudel,Eftakhar Ahmed Arnob*

Main category: cs.LG

TL;DR: 本文探讨了多类别葡萄酒分类中模型准确性、特征维度和可解释性之间的权衡，并通过实证研究评估了L1正则化对特征稀疏性的影响，旨在为资源受限环境下的实践者提供可操作的指导。


<details>
  <summary>Details</summary>
Motivation: 在分析化学领域，多类别葡萄酒分类在实际应用中需要平衡模型准确性、特征维度和可解释性。

Method: 本文在UCI葡萄酒数据集上对“一对多”逻辑回归进行了全面的实证研究，比较了从头开始实现的梯度下降法与scikit-learn优化求解器的性能，并量化了L1正则化对特征稀疏性的影响。

Result: 手动梯度下降实现了92.59%的平均测试准确率，scikit-learn提供了24倍的训练加速和98.15%的准确率。L1正则化实现了54-69%的特征缩减，准确率仅下降4.63%，表现出良好的可解释性-性能权衡。本文提出了一个最优的5特征子集，实现了62%的复杂度降低和92-94%的估计准确性，每样本可节省80美元，时间缩短56%。

Conclusion: 本文的研究结果为实践者在资源受限的环境中平衡全面的化学分析与有针对性的特征测量提供了可操作的指导方针。

Abstract: Multi-class wine classification presents fundamental trade-offs between model
accuracy, feature dimensionality, and interpretability - critical factors for
production deployment in analytical chemistry. This paper presents a
comprehensive empirical study of One-vs-Rest logistic regression on the UCI
Wine dataset (178 samples, 3 cultivars, 13 chemical features), comparing
from-scratch gradient descent implementation against scikit-learn's optimized
solvers and quantifying L1 regularization effects on feature sparsity. Manual
gradient descent achieves 92.59 percent mean test accuracy with smooth
convergence, validating theoretical foundations, though scikit-learn provides
24x training speedup and 98.15 percent accuracy. Class-specific analysis
reveals distinct chemical signatures with heterogeneous patterns where color
intensity varies dramatically (0.31 to 16.50) across cultivars. L1
regularization produces 54-69 percent feature reduction with only 4.63 percent
accuracy decrease, demonstrating favorable interpretability-performance
trade-offs. We propose an optimal 5-feature subset achieving 62 percent
complexity reduction with estimated 92-94 percent accuracy, enabling
cost-effective deployment with 80 dollars savings per sample and 56 percent
time reduction. Statistical validation confirms robust generalization with
sub-2ms prediction latency suitable for real-time quality control. Our findings
provide actionable guidelines for practitioners balancing comprehensive
chemical analysis against targeted feature measurement in resource-constrained
environments.

</details>


### [175] [From Guess2Graph: When and How Can Unreliable Experts Safely Boost Causal Discovery in Finite Samples?](https://arxiv.org/abs/2510.14488)
*Sujai Hiremath,Dominik Janzing,Philipp Faller,Patrick Blöbaum,Elke Kirschbaum,Shiva Prasad Kasiviswanathan,Kyra Gan*

Main category: cs.LG

TL;DR: Guess2Graph (G2G)框架，该框架利用专家猜测，而非替代统计测试，来指导测试序列。开发了PC-Guess和gPC-Guess，两者均能从专家准确性中获益，且gPC-Guess表现出显著提升。


<details>
  <summary>Details</summary>
Motivation: 因果发现算法在样本有限时表现不佳，而现有方法在整合专家知识时需要完美的预测或不确定性估计，这在实践中并不可靠。

Method: 提出了Guess2Graph (G2G)框架，该框架使用专家猜测来指导统计测试的序列，而不是取代它们。开发了两种G2G的实例化：PC-Guess（增强了PC算法）和gPC-Guess（一个学习增强的变体）。

Result: 理论上，G2G框架的两种实例化（PC-Guess和gPC-Guess）在专家出错的情况下也能保持正确性。当专家“优于随机”时，gPC-Guess在有限样本中能显著优于其非增强的对应算法。实证结果显示，这两种方法都随着专家准确性的提高而单调改进，其中gPC-Guess取得了显著更强的增益。

Conclusion: Guess2Graph (G2G)框架，特别是其gPC-Guess变体，通过有效整合专家知识（即使专家存在误差）显著提升了因果发现算法在有限样本条件下的性能，同时保持了统计学的正确性。

Abstract: Causal discovery algorithms often perform poorly with limited samples. While
integrating expert knowledge (including from LLMs) as constraints promises to
improve performance, guarantees for existing methods require perfect
predictions or uncertainty estimates, making them unreliable for practical use.
We propose the Guess2Graph (G2G) framework, which uses expert guesses to guide
the sequence of statistical tests rather than replacing them. This maintains
statistical consistency while enabling performance improvements. We develop two
instantiations of G2G: PC-Guess, which augments the PC algorithm, and
gPC-Guess, a learning-augmented variant designed to better leverage
high-quality expert input. Theoretically, both preserve correctness regardless
of expert error, with gPC-Guess provably outperforming its non-augmented
counterpart in finite samples when experts are "better than random."
Empirically, both show monotonic improvement with expert accuracy, with
gPC-Guess achieving significantly stronger gains.

</details>


### [176] [Learning to Undo: Rollback-Augmented Reinforcement Learning with Reversibility Signals](https://arxiv.org/abs/2510.14503)
*Andrejs Sorstkins,Omer Tariq,Muhammad Bilal*

Main category: cs.LG

TL;DR: 这篇论文提出了一个可逆学习框架，通过引入一个可逆性度量Phi和一个选择性状态回滚操作，提高了基于价值的强化学习agent的鲁棒性和效率，减少了价值过高估计和部分不可逆环境中的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决基于价值的强化学习agent在部分不可逆环境中易受价值过高估计和不稳定性影响的问题。

Method: 该框架包含两个核心机制：1. 过渡可逆性度量Phi，用于量化在固定时间 K 内返回先前状态的可能性，并动态调整时序差分更新中的惩罚项。2. 选择性状态回滚操作，当某个动作的预期回报远低于瞬时估计值并超过预设阈值时，agent会受到惩罚并返回到上一个状态，以中断次优的高风险轨迹，避免灾难性步骤。

Result: 在 CliffWalking v0 环境中，该框架将灾难性跌落减少了99.8%以上，并将平均episode回报提高了55%。 在 Taxi v3 环境中，它抑制了99.9%的非法操作，并将累积奖励提高了65.7%，同时也显著降低了两种环境中的奖励方差。 消融研究证实回滚机制是这些安全和性能提升的关键组成部分。

Conclusion: 该可逆学习框架通过结合可逆性感知评估和有针对性的回滚机制，显著提高了强化学习agent的安全性、性能和稳定性，是实现安全可靠的序贯决策的有力一步。

Abstract: This paper proposes a reversible learning framework to improve the robustness
and efficiency of value based Reinforcement Learning agents, addressing
vulnerability to value overestimation and instability in partially irreversible
environments. The framework has two complementary core mechanisms: an
empirically derived transition reversibility measure called Phi of s and a, and
a selective state rollback operation. We introduce an online per state action
estimator called Phi that quantifies the likelihood of returning to a prior
state within a fixed horizon K. This measure is used to adjust the penalty term
during temporal difference updates dynamically, integrating reversibility
awareness directly into the value function. The system also includes a
selective rollback operator. When an action yields an expected return markedly
lower than its instantaneous estimated value and violates a predefined
threshold, the agent is penalized and returns to the preceding state rather
than progressing. This interrupts sub optimal high risk trajectories and avoids
catastrophic steps. By combining reversibility aware evaluation with targeted
rollback, the method improves safety, performance, and stability. In the
CliffWalking v0 domain, the framework reduced catastrophic falls by over 99.8
percent and yielded a 55 percent increase in mean episode return. In the Taxi
v3 domain, it suppressed illegal actions by greater than or equal to 99.9
percent and achieved a 65.7 percent improvement in cumulative reward, while
also sharply reducing reward variance in both environments. Ablation studies
confirm that the rollback mechanism is the critical component underlying these
safety and performance gains, marking a robust step toward safe and reliable
sequential decision making.

</details>


### [177] [Enhancing Time Series Forecasting through Selective Representation Spaces: A Patch Perspective](https://arxiv.org/abs/2510.14510)
*Xingjian Wu,Xiangfei Qiu,Hanyin Cheng,Zhengyu Li,Jilin Hu,Chenjuan Guo,Bin Yang*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为选择性表示空间（SRS）的新方法，通过选择性分块和动态重组技术构建灵活的表示空间，以改进时间序列预测中长程依赖性建模。


<details>
  <summary>Details</summary>
Motivation: 现有的Patching技术在时间序列预测中取得了显著进展，但其将时间序列划分为相邻的分块导致表示空间固定，从而限制了表示的表达能力。

Method: 本研究提出了选择性表示空间（SRS）模块，该模块包含可学习的选择性分块和动态重组技术。它能够自适应地选择并重新排列上下文时间序列中的分块，从而充分利用上下文信息以提高基于分块的模型的预测性能。

Result: 通过将SRS模块与一个简单的多层感知器（MLP）头部结合，形成了SRSNet模型，在多个领域的真实世界数据集上取得了最先进的性能。此外，SRS模块作为一个即插即用的组件，还可以增强现有基于分块的模型的性能。

Conclusion: 选择性表示空间（SRS）模块通过引入灵活的表示空间，有效地解决了传统Patching技术中表示能力不足的问题，显著提升了时间序列预测模型的性能。

Abstract: Time Series Forecasting has made significant progress with the help of
Patching technique, which partitions time series into multiple patches to
effectively retain contextual semantic information into a representation space
beneficial for modeling long-term dependencies. However, conventional patching
partitions a time series into adjacent patches, which causes a fixed
representation space, thus resulting in insufficiently expressful
representations. In this paper, we pioneer the exploration of constructing a
selective representation space to flexibly include the most informative patches
for forecasting. Specifically, we propose the Selective Representation Space
(SRS) module, which utilizes the learnable Selective Patching and Dynamic
Reassembly techniques to adaptively select and shuffle the patches from the
contextual time series, aiming at fully exploiting the information of
contextual time series to enhance the forecasting performance of patch-based
models. To demonstrate the effectiveness of SRS module, we propose a simple yet
effective SRSNet consisting of SRS and an MLP head, which achieves
state-of-the-art performance on real-world datasets from multiple domains.
Furthermore, as a novel plugin-and-play module, SRS can also enhance the
performance of existing patch-based models. The resources are available at
https://github.com/decisionintelligence/SRSNet.

</details>


### [178] [MX+: Pushing the Limits of Microscaling Formats for Efficient Large Language Model Serving](https://arxiv.org/abs/2510.14557)
*Jungi Lee,Junyong Park,Soohyun Cha,Jaehoon Cho,Jaewoong Sim*

Main category: cs.LG

TL;DR: 本文分析了块浮点（BFP）格式的局限性，并提出了一种名为 MX+ 的扩展，以提高大型语言模型（LLM）服务的效率和性能，它在不显著增加存储开销和减慢速度的情况下，显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索块浮点（BFP）格式的极限，以期高效服务大型语言模型（LLM），并解决现有超低位 BFP 变体因块中异常值而导致的语言模型性能不佳的问题。

Method: 分析了现有的超低位 BFP 变体在处理异常值时的不足，并提出了 MX+。MX+ 是一种经济高效且非侵入性的扩展，它利用异常值不需要使用其元素数据类型中的指数域的特性，将指数域重新用作扩展尾数，以增加异常值元素的精度。

Result: MX+ 相较于 4 位 MX 格式（MXFP4）实现了显著更高的模型性能，同时存储开销和速度降低可忽略不计。

Conclusion: MX+ 为高效的 LLM 推理提供了一个有吸引力的替代方案，可替代 MXFP4 或 MXFP6。

Abstract: Reduced-precision data formats are crucial for cost-effective serving of
large language models (LLMs). While numerous reduced-precision formats have
been introduced thus far, they often require intrusive modifications to the
software frameworks or are rather unconventional for widespread adoption across
hardware vendors. In this paper, we instead focus on recent industry-driven
variants of block floating-point (BFP) formats and conduct a comprehensive
analysis to push their limits for efficient LLM serving. Our analysis shows
that existing ultra low-bit BFP variants struggle to provide reasonable
language model performance due to outlier values in blocks. To address the
outliers with BFPs, we propose MX+, a cost-effective and non-intrusive
extension designed for seamless integration into the microscaling (MX) formats.
MX+ builds on the key insight that the outlier does not need to use its
exponent field in the element data type, which allows us to repurpose the
exponent field as an extended mantissa to increase the precision of the outlier
element. Our evaluation shows that MX+ achieves significantly higher model
performance compared to the 4-bit MX format (MXFP4) with negligible storage
overhead and slowdown, thus offering a compelling alternative to MXFP4 or MXFP6
for efficient LLM inference.

</details>


### [179] [Redundancy-Aware Test-Time Graph Out-of-Distribution Detection](https://arxiv.org/abs/2510.14562)
*Yue Hou,He Zhu,Ruomei Liu,Yingke Su,Junran Wu,Ke Xu*

Main category: cs.LG

TL;DR: 该文章提出了RedOUT，一个在图分类中用于测试时 OOD 检测的无监督框架，旨在通过集成结构熵来解决现有方法中结构冗余导致的性能下降问题，并在真实世界数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的图 OOD 检测方法受到结构冗余导致语义偏移的影响，从而在处理 OOD 样本时产生不准确的预测。

Method: 提出了一种无监督框架 RedOUT，将结构熵整合到图分类的测试时 OOD 检测中。引入了冗余感知图信息瓶颈（ReGIB），将目标分解为基本信息和不相关冗余。通过最小化结构熵来减少解耦的冗余，并提出了理论上受限的优化上下界。

Result: 在真实世界数据集上的广泛实验表明，RedOUT 在 OOD 检测方面表现优异。具体来说，该方法平均提高了 6.7%，在 ClinTox/LIPO 数据集对上，性能比最佳竞争对手高出 17.3%。

Conclusion: RedOUT 通过整合结构熵和冗余感知图信息瓶颈，有效解决了图 OOD 检测中的结构冗余问题，显著提升了 OOD 检测的性能。

Abstract: Distributional discrepancy between training and test data can lead models to
make inaccurate predictions when encountering out-of-distribution (OOD) samples
in real-world applications. Although existing graph OOD detection methods
leverage data-centric techniques to extract effective representations, their
performance remains compromised by structural redundancy that induces semantic
shifts. To address this dilemma, we propose RedOUT, an unsupervised framework
that integrates structural entropy into test-time OOD detection for graph
classification. Concretely, we introduce the Redundancy-aware Graph Information
Bottleneck (ReGIB) and decompose the objective into essential information and
irrelevant redundancy. By minimizing structural entropy, the decoupled
redundancy is reduced, and theoretically grounded upper and lower bounds are
proposed for optimization. Extensive experiments on real-world datasets
demonstrate the superior performance of RedOUT on OOD detection. Specifically,
our method achieves an average improvement of 6.7%, significantly surpassing
the best competitor by 17.3% on the ClinTox/LIPO dataset pair.

</details>


### [180] [Selective Labeling with False Discovery Rate Control](https://arxiv.org/abs/2510.14581)
*Huipeng Huang,Wenbo Liao,Huajun Xi,Hao Zeng,Mengchen Zhao,Hongxin Wei*

Main category: cs.LG

TL;DR: 本文介绍了一种名为“共形标注”的新方法，可以在保持低错误率的同时，用AI模型对大量数据进行标注。


<details>
  <summary>Details</summary>
Motivation: 在大规模数据集中获取高质量标签的成本高昂，且现有AI辅助标注方法缺乏理论保证，导致AI标注的子集中错误率不可接受。

Method: 通过计算每个测试实例的共形p值，并与一个数据依赖的阈值进行比较，以控制错误发现率（FDR）。p值是通过比较AI模型预测的置信度与AI模型错误标注的校准实例的置信度来构建的。

Result: 实验证明该方法在图像和文本标注以及大型语言模型问答等任务中实现了严格的FDR控制和高功效。

Conclusion: 共形标注方法能有效地控制AI标注中的错误发现率，从而在保证质量的同时，提高大规模数据集标注的效率和可靠性。

Abstract: Obtaining high-quality labels for large datasets is expensive, requiring
massive annotations from human experts. While AI models offer a cost-effective
alternative by predicting labels, their label quality is compromised by the
unavoidable labeling errors. Existing methods mitigate this issue through
selective labeling, where AI labels a subset and human labels the remainder.
However, these methods lack theoretical guarantees on the quality of
AI-assigned labels, often resulting in unacceptably high labeling error within
the AI-labeled subset. To address this, we introduce \textbf{Conformal
Labeling}, a novel method to identify instances where AI predictions can be
provably trusted. This is achieved by controlling the false discovery rate
(FDR), the proportion of incorrect labels within the selected subset. In
particular, we construct a conformal $p$-value for each test instance by
comparing AI models' predicted confidence to those of calibration instances
mislabeled by AI models. Then, we select test instances whose $p$-values are
below a data-dependent threshold, certifying AI models' predictions as
trustworthy. We provide theoretical guarantees that Conformal Labeling controls
the FDR below the nominal level, ensuring that a predefined fraction of
AI-assigned labels is correct on average. Extensive experiments demonstrate
that our method achieves tight FDR control with high power across various
tasks, including image and text labeling, and LLM QA.

</details>


### [181] [Matcha: Multi-Stage Riemannian Flow Matching for Accurate and Physically Valid Molecular Docking](https://arxiv.org/abs/2510.14586)
*Daria Frolova,Talgat Daulbaev,Egor Sevryugov,Sergei A. Nikolenko,Dmitry N. Ivankov,Ivan Oseledets,Marina A. Pak*

Main category: cs.LG

TL;DR: Matcha是一种新颖的多阶段流匹配分子对接方法，它结合了学习评分和物理有效性过滤，在对接成功率和物理合理性方面表现出色，且速度比现有方法快约25倍。


<details>
  <summary>Details</summary>
Motivation: 现有的蛋白质-配体结合姿态预测方法难以平衡速度、准确性和物理合理性。

Method: Matcha是一个三阶段的分子对接流程，每个阶段都作为在相应几何空间（$\mathbb{R}^3$, $\mathrm{SO}(3)$, 和 $\mathrm{SO}(2)$）上操作的流匹配模型，并结合专门的评分模型和无监督物理有效性过滤器来优化预测并去除不切实际的姿态。

Result: Matcha在Astex和PDBbind测试集上的对接成功率和物理合理性方面表现出卓越的性能，比现代大规模共折叠模型快约25倍。

Conclusion: Matcha通过其多阶段流匹配、学习评分和物理有效性过滤，显著提高了蛋白质-配体结合姿态预测的速度、准确性和物理合理性，为结构引导的药物设计提供了有效工具。

Abstract: Accurate prediction of protein-ligand binding poses is crucial for
structure-based drug design, yet existing methods struggle to balance speed,
accuracy, and physical plausibility. We introduce Matcha, a novel molecular
docking pipeline that combines multi-stage flow matching with learned scoring
and physical validity filtering. Our approach consists of three sequential
stages applied consecutively to refine docking predictions, each implemented as
a flow matching model operating on appropriate geometric spaces
($\mathbb{R}^3$, $\mathrm{SO}(3)$, and $\mathrm{SO}(2)$). We enhance the
prediction quality through a dedicated scoring model and apply unsupervised
physical validity filters to eliminate unrealistic poses. Compared to various
approaches, Matcha demonstrates superior performance on Astex and PDBbind test
sets in terms of docking success rate and physical plausibility. Moreover, our
method works approximately 25 times faster than modern large-scale co-folding
models. The model weights and inference code to reproduce our results are
available at https://github.com/LigandPro/Matcha.

</details>


### [182] [Multimodal RAG for Unstructured Data:Leveraging Modality-Aware Knowledge Graphs with Hybrid Retrieval](https://arxiv.org/abs/2510.14592)
*Rashmi R,Vidyadhar Upadhya*

Main category: cs.LG

TL;DR: 本文提出了MAHA，一种专为多模态问答设计的检索增强生成系统，它通过结合密集向量检索和结构化图遍历，实现了跨模态语义和关系的有效编码和检索。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）系统主要处理单模态文本数据，这限制了它们在非结构化多模态文档上的效率。多模态文档通常包含文本、图像、表格、公式和图表，每种模态都提供独特的信息，因此需要一种能处理多模态信息的RAG系统。

Method: 本文提出了一个模态感知混合检索架构（MAHA），该架构专为通过模态感知知识图谱进行推理的多模态问答而设计。MAHA将密集向量检索与结构化图遍历相结合，其中知识图谱编码了跨模态语义和关系，从而实现语义丰富和上下文感知的跨模态检索。

Result: 在多个基准数据集上进行的评估表明，MAHA的表现显著优于基线方法，ROUGE-L得分达到0.486，并提供完整的模态覆盖。

Conclusion: MAHA通过结合嵌入和明确的文档结构，实现了有效的多模态检索，并建立了一个可扩展和可解释的检索框架，通过在非结构化多模态数据上实现模态感知推理，推动了RAG系统的发展。

Abstract: Current Retrieval-Augmented Generation (RAG) systems primarily operate on
unimodal textual data, limiting their effectiveness on unstructured multimodal
documents. Such documents often combine text, images, tables, equations, and
graphs, each contributing unique information. In this work, we present a
Modality-Aware Hybrid retrieval Architecture (MAHA), designed specifically for
multimodal question answering with reasoning through a modality-aware knowledge
graph. MAHA integrates dense vector retrieval with structured graph traversal,
where the knowledge graph encodes cross-modal semantics and relationships. This
design enables both semantically rich and context-aware retrieval across
diverse modalities. Evaluations on multiple benchmark datasets demonstrate that
MAHA substantially outperforms baseline methods, achieving a ROUGE-L score of
0.486, providing complete modality coverage. These results highlight MAHA's
ability to combine embeddings with explicit document structure, enabling
effective multimodal retrieval. Our work establishes a scalable and
interpretable retrieval framework that advances RAG systems by enabling
modality-aware reasoning over unstructured multimodal data.

</details>


### [183] [First Attentions Last: Better Exploiting First Attentions for Efficient Transformer Training](https://arxiv.org/abs/2510.14614)
*Gyudong Kim,Hyukju Na,Jin Hyeon Kim,Hyunsung Jang,Jaemin Park,Jaegi Hwang,Namkoo Ha,Seungryong Kim,Young Geun Kim*

Main category: cs.LG

TL;DR: 这篇论文提出了FAL和FAL+，两种新的Transformer架构，通过消除MHA-MLP连接中的all-reduce通信来减少多GPU训练时间和提高单GPU吞吐量，同时保持或提高模型质量。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer设计在张量并行（TP）中存在显著的通信开销，其中每个块的MHA-MLP连接需要all-reduce通信。

Method: 本文提出FAL（First Attentions Last），它将第一个MHA的输出重定向到后续层的MLP输入，从而消除了每块MHA-MLP连接，并使MHA和MLP能够在单个GPU上并行执行。在此基础上，本文进一步提出了FAL+，它将归一化的第一个注意力输出添加到后续层的MHA输出中，以增强MLP输入，从而提高模型质量。

Result: FAL将多GPU训练时间减少了44%，单GPU吞吐量提高了1.18倍，并且与基线GPT相比取得了更好的困惑度。FAL+在不增加训练时间的情况下实现了比基线更低的困惑度。

Conclusion: 通过重定向第一个MHA输出，FAL和FAL+架构显著降低了Transformer模型的通信开销，提高了训练效率和模型性能。

Abstract: As training billion-scale transformers becomes increasingly common, employing
multiple distributed GPUs along with parallel training methods has become a
standard practice. However, existing transformer designs suffer from
significant communication overhead, especially in Tensor Parallelism (TP),
where each block's MHA-MLP connection requires an all-reduce communication.
Through our investigation, we show that the MHA-MLP connections can be bypassed
for efficiency, while the attention output of the first layer can serve as an
alternative signal for the bypassed connection. Motivated by the observations,
we propose FAL (First Attentions Last), an efficient transformer architecture
that redirects the first MHA output to the MLP inputs of the following layers,
eliminating the per-block MHA-MLP connections. This removes the all-reduce
communication and enables parallel execution of MHA and MLP on a single GPU. We
also introduce FAL+, which adds the normalized first attention output to the
MHA outputs of the following layers to augment the MLP input for the model
quality. Our evaluation shows that FAL reduces multi-GPU training time by up to
44%, improves single-GPU throughput by up to 1.18x, and achieves better
perplexity compared to the baseline GPT. FAL+ achieves even lower perplexity
without increasing the training time than the baseline.

</details>


### [184] [LeapFactual: Reliable Visual Counterfactual Explanation Using Conditional Flow Matching](https://arxiv.org/abs/2510.14623)
*Zhuo Cao,Xuan Zhao,Lena Krieger,Hanno Scharr,Ira Assent*

Main category: cs.LG

TL;DR: LeapFactual是一种基于条件流匹配的新型反事实解释算法，旨在解决现有反事实生成方法中存在的梯度消失、潜在空间不连续以及过度依赖学习与真实决策边界对齐等局限性。


<details>
  <summary>Details</summary>
Motivation: 机器学习（ML）和人工智能（AI）模型越来越多地被整合到医疗保健和科学研究等高风险领域，这要求模型不仅要准确，还要具有可解释性。反事实解释通过识别能够改变模型预测的最小输入变化来提供可解释性，从而提供更深层次的见解。

Method: 提出了一种名为LeapFactual的新型反事实解释算法，该算法基于条件流匹配。LeapFactual能够生成可靠且信息丰富的反事实解释，即使在真实和学习到的决策边界不一致的情况下也是如此。LeapFactual采用模型无关的方法，不局限于具有可微损失函数的模型，甚至可以处理需要人工参与的系统。

Result: LeapFactual在基准数据集和真实世界数据集上进行了广泛的实验，结果表明它能生成准确且在分布内的反事实解释，并提供可操作的见解。例如，可靠的反事实样本可以通过与真实标签对齐，用作新的训练数据来增强模型。

Conclusion: LeapFactual是一种新颖的反事实解释算法，它克服了现有方法的局限性，提高了反事实解释的可靠性和信息量。它具有广泛的适用性，可以应用于各种领域，增强科学知识发现和非专业人士的可解释性。

Abstract: The growing integration of machine learning (ML) and artificial intelligence
(AI) models into high-stakes domains such as healthcare and scientific research
calls for models that are not only accurate but also interpretable. Among the
existing explainable methods, counterfactual explanations offer
interpretability by identifying minimal changes to inputs that would alter a
model's prediction, thus providing deeper insights. However, current
counterfactual generation methods suffer from critical limitations, including
gradient vanishing, discontinuous latent spaces, and an overreliance on the
alignment between learned and true decision boundaries. To overcome these
limitations, we propose LeapFactual, a novel counterfactual explanation
algorithm based on conditional flow matching. LeapFactual generates reliable
and informative counterfactuals, even when true and learned decision boundaries
diverge. Following a model-agnostic approach, LeapFactual is not limited to
models with differentiable loss functions. It can even handle human-in-the-loop
systems, expanding the scope of counterfactual explanations to domains that
require the participation of human annotators, such as citizen science. We
provide extensive experiments on benchmark and real-world datasets showing that
LeapFactual generates accurate and in-distribution counterfactual explanations
that offer actionable insights. We observe, for instance, that our reliable
counterfactual samples with labels aligning to ground truth can be beneficially
used as new training data to enhance the model. The proposed method is broadly
applicable and enhances both scientific knowledge discovery and non-expert
interpretability.

</details>


### [185] [Galaxy Morphology Classification with Counterfactual Explanation](https://arxiv.org/abs/2510.14655)
*Zhuo Cao,Lena Krieger,Hanno Scharr,Ira Assent*

Main category: cs.LG

TL;DR: 这篇论文提出了一种结合可逆流的编码器-解码器架构，用于星系形态分类，旨在提高可解释性并提供反事实解释。


<details>
  <summary>Details</summary>
Motivation: 星系形态在星系演化研究中至关重要，但数据量庞大导致分类工作量大，而现有的机器学习方法缺乏对模型工作原理的洞察和结果解释。

Method: 提出了一种扩展了经典编码器-解码器架构的可逆流模型。

Result: 该方法不仅能获得良好的预测性能，还能通过反事实解释提供决策过程的附加信息。

Conclusion: 通过引入可逆流，弥补了现有机器学习方法在星系形态分类中可解释性不足的问题，提高了模型的可理解性。

Abstract: Galaxy morphologies play an essential role in the study of the evolution of
galaxies. The determination of morphologies is laborious for a large amount of
data giving rise to machine learning-based approaches. Unfortunately, most of
these approaches offer no insight into how the model works and make the results
difficult to understand and explain. We here propose to extend a classical
encoder-decoder architecture with invertible flow, allowing us to not only
obtain a good predictive performance but also provide additional information
about the decision process with counterfactual explanations.

</details>


### [186] [Geometric Moment Alignment for Domain Adaptation via Siegel Embeddings](https://arxiv.org/abs/2510.14666)
*Shayan Gharib,Marcelo Hartmann,Arto Klami*

Main category: cs.LG

TL;DR: 本文提出了一种基于黎曼距离的无监督域适应方法，通过西格尔嵌入将一阶和二阶矩表示为SPD矩阵，从而在SPD流形上同时对两个矩进行对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用特殊的相似性度量在嵌入空间中对齐源域和目标域分布的低阶统计矩，但这忽略了分布的内在几何结构。

Method: 通过西格尔嵌入将一阶和二阶矩表示为单个对称正定（SPD）矩阵，并利用SPD矩阵共享流形上的自然几何距离来同时对齐这两个矩。

Result: 所提出的方法可以保持源域和目标域分布的均值和协方差结构，并为跨域比较提供更可靠的度量。此外，黎曼流形距离与目标域误差界相关联，并在图像去噪和图像分类基准上验证了方法的有效性。

Conclusion: 通过利用分布的内在几何结构和黎曼距离，本方法为无监督域适应提供了一种更原则性的替代方案，从而在领域适应中实现了更精确的矩对齐和更好的性能。

Abstract: We address the problem of distribution shift in unsupervised domain
adaptation with a moment-matching approach. Existing methods typically align
low-order statistical moments of the source and target distributions in an
embedding space using ad-hoc similarity measures. We propose a principled
alternative that instead leverages the intrinsic geometry of these
distributions by adopting a Riemannian distance for this alignment. Our key
novelty lies in expressing the first- and second-order moments as a single
symmetric positive definite (SPD) matrix through Siegel embeddings. This
enables simultaneous adaptation of both moments using the natural geometric
distance on the shared manifold of SPD matrices, preserving the mean and
covariance structure of the source and target distributions and yielding a more
faithful metric for cross-domain comparison. We connect the Riemannian manifold
distance to the target-domain error bound, and validate the method on image
denoising and image classification benchmarks. Our code is publicly available
at https://github.com/shayangharib/GeoAdapt.

</details>


### [187] [FedPPA: Progressive Parameter Alignment for Personalized Federated Learning](https://arxiv.org/abs/2510.14698)
*Maulidi Adi Prasetia,Muhamad Risqi U. Saputra,Guntur Dharma Putra*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的联邦学习方法FedPPA，通过逐步对齐公共权重并结合基于熵的加权平均来应对模型和数据异构性问题，从而在个性化和全局模型性能方面均取得了优越的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化联邦学习（PFL）方法往往忽略了计算能力不同的客户端带来的模型和数据异构性共存的问题，导致在真实场景中模型训练面临挑战。

Method: 本文提出了一种名为渐进参数对齐（FedPPA）的新方法，它逐步将客户端公共层的权重与全局模型的权重对齐。此外，为了进一步提高全局模型性能，同时保持强大的个性化，我们将基于熵的加权平均集成到FedPPA框架中。

Result: 在MNIST、FMNIST和CIFAR-10三个图像分类数据集上进行的实验表明，FedPPA始终优于现有的联邦学习算法，在个性化适应方面取得了卓越的性能。

Conclusion: FedPPA通过有效解决模型和数据异构性共存的问题，显著提升了个性化联邦学习的性能。

Abstract: Federated Learning (FL) is designed as a decentralized, privacy-preserving
machine learning paradigm that enables multiple clients to collaboratively
train a model without sharing their data. In real-world scenarios, however,
clients often have heterogeneous computational resources and hold
non-independent and identically distributed data (non-IID), which poses
significant challenges during training. Personalized Federated Learning (PFL)
has emerged to address these issues by customizing models for each client based
on their unique data distribution. Despite its potential, existing PFL
approaches typically overlook the coexistence of model and data heterogeneity
arising from clients with diverse computational capabilities. To overcome this
limitation, we propose a novel method, called Progressive Parameter Alignment
(FedPPA), which progressively aligns the weights of common layers across
clients with the global model's weights. Our approach not only mitigates
inconsistencies between global and local models during client updates, but also
preserves client's local knowledge, thereby enhancing personalization
robustness in non-IID settings. To further enhance the global model performance
while retaining strong personalization, we also integrate entropy-based
weighted averaging into the FedPPA framework. Experiments on three image
classification datasets, including MNIST, FMNIST, and CIFAR-10, demonstrate
that FedPPA consistently outperforms existing FL algorithms, achieving superior
performance in personalized adaptation.

</details>


### [188] [Tawa: Automatic Warp Specialization for Modern GPUs with Asynchronous References](https://arxiv.org/abs/2510.14719)
*Hongzheng Chen,Bin Fan,Alexander Collins,Bastian Hagedorn,Evghenii Gaburov,Masahiro Masuda,Matthew Brookhart,Chris Sullivan,Jason Knight,Zhiru Zhang,Vinod Grover*

Main category: cs.LG

TL;DR: Tawa是一种自动编译器，它能将高级的、基于tile的程序转换为高性能的、warp-specialized的代码，从而解决GPU编程中由于SIMT模型与任务并行硬件不匹配导致的编程难题。


<details>
  <summary>Details</summary>
Motivation: 现代GPU拥有专用的硬件单元，支持高性能、异步的数据流执行。然而，传统的SIMT编程模型与这种任务并行硬件根本不匹配，导致了显著的可编程性差距。虽然硬件级warp specialization是实现峰值性能的关键，但它却迫使开发者手动协调复杂的、低级的通信和软件管道，这是一个劳动密集、容易出错且不可持续的过程。

Method: Tawa是一种自动编译器，它能将高级的、基于tile的程序转换为高性能的、warp-specialized代码。该方法的核心是一个新颖的IR抽象，即异步引用（aref），它能在不暴露底层硬件细节的情况下表达warp级别的通信。Tawa利用这种抽象自动将程序划分为生产者-消费者角色，并管理复杂的数据流管道。

Result: 在NVIDIA H100 GPU上对代表性的LLM内核进行评估显示，Tawa实现了高硬件利用率，在高度优化的cuBLAS GEMM内核上实现了高达1.1倍的加速。对于attention工作负载，Tawa比Triton快1.2倍，并且在编程工作量大大减少的情况下，其性能与手动优化的CUTLASS C++ FlashAttention-3内核相当。

Conclusion: Tawa通过自动化编译器解决了GPU编程中SIMT模型与任务并行硬件不匹配的难题，通过引入异步引用（aref）抽象，实现了高性能、warp-specialized的代码生成，并在LLM和attention任务上展现了卓越的性能提升，同时显著降低了开发者的编程负担。

Abstract: Modern GPUs feature specialized hardware units that enable high-performance,
asynchronous dataflow execution. However, the conventional SIMT programming
model is fundamentally misaligned with this task-parallel hardware, creating a
significant programmability gap. While hardware-level warp specialization is
the key to unlocking peak performance, it forces developers to manually
orchestrate complex, low-level communication and software pipelines--a process
that is labor-intensive, error-prone, and unsustainable. To address this
challenge, we present Tawa, an automated compiler that systematically generates
high-performance, warp-specialized code from a high-level, tile-based program.
Central to our approach is a novel IR abstraction, asynchronous references
(aref), which expresses warp-level communication without exposing low-level
hardware details. Using this abstraction, Tawa automatically partitions
programs into producer-consumer roles and manages the intricate dataflow
pipeline, relieving developers of invasive kernel rewriting. Evaluation on
NVIDIA H100 GPUs across representative LLM kernels shows that Tawa delivers
high hardware utilization, achieving up to 1.1$\times$ speedup over highly
optimized cuBLAS GEMM kernels. For attention workloads, Tawa attains
1.2$\times$ speedup over Triton and matches the performance of the
hand-optimized CUTLASS C++ FlashAttention-3 kernel with far less programming
effort.

</details>


### [189] [The Pursuit of Diversity: Multi-Objective Testing of Deep Reinforcement Learning Agents](https://arxiv.org/abs/2510.14727)
*Antony Bartlett,Cynthia Liem,Annibale Panichella*

Main category: cs.LG

TL;DR: 本文介绍了INDAGO-Nexus，一种多目标搜索方法，用于测试深度强化学习（DRL）智能体，旨在发现多样化的失败场景。


<details>
  <summary>Details</summary>
Motivation: 现有的DRL测试工具（如INDAGO）侧重于最大化失败计数，但未能确保发现场景的多样性或揭示不同的错误类型。

Method: INDAGO-Nexus使用多目标进化算法，结合多种多样性度量和帕累托前沿选择策略，共同优化失败可能性和测试场景多样性。

Result: 在自动驾驶汽车（SDC）和停车场景中，INDAGO-Nexus发现的独特故障比INDAGO多83%和40%，同时将所有智能体的故障发生时间缩短了67%。

Conclusion: INDAGO-Nexus通过多目标优化显著提高了DRL智能体故障测试的效率和多样性。

Abstract: Testing deep reinforcement learning (DRL) agents in safety-critical domains
requires discovering diverse failure scenarios. Existing tools such as INDAGO
rely on single-objective optimization focused solely on maximizing failure
counts, but this does not ensure discovered scenarios are diverse or reveal
distinct error types. We introduce INDAGO-Nexus, a multi-objective search
approach that jointly optimizes for failure likelihood and test scenario
diversity using multi-objective evolutionary algorithms with multiple diversity
metrics and Pareto front selection strategies. We evaluated INDAGO-Nexus on
three DRL agents: humanoid walker, self-driving car, and parking agent. On
average, INDAGO-Nexus discovers up to 83% and 40% more unique failures (test
effectiveness) than INDAGO in the SDC and Parking scenarios, respectively,
while reducing time-to-failure by up to 67% across all agents.

</details>


### [190] [Beyond Multi-Token Prediction: Pretraining LLMs with Future Summaries](https://arxiv.org/abs/2510.14751)
*Divyat Mahajan,Sachin Goyal,Badr Youbi Idrissi,Mohammad Pezeshki,Ioannis Mitliagkas,David Lopez-Paz,Kartik Ahuja*

Main category: cs.LG

TL;DR: 未来的摘要预测 (FSP) 是一种新的训练范式，旨在通过预测长期未来的紧凑表示来提高大型语言模型 (LLM) 的长文本生成能力。


<details>
  <summary>Details</summary>
Motivation: 下一词元预测 (NTP) 虽然推动了大型语言模型 (LLM) 的成功，但在长程推理、规划和创造性写作方面存在不足，这主要归因于教师强制训练。多词元预测 (MTP) 部分缓解了这些问题，但其主要捕捉短程依赖，改进有限。

Method: 本文提出了未来摘要预测 (FSP)。该方法训练一个辅助头来预测长期未来的紧凑表示，从而保留与长文本生成相关的信息。研究探索了两种 FSP 变体：手动摘要（例如，序列未来词袋摘要）和学习摘要（使用从右到左训练的逆向语言模型生成的嵌入）。

Result: 大规模预训练实验（3B 和 8B 参数模型）表明，FSP 在数学、推理和编码基准测试中均优于 NTP 和 MTP。

Conclusion: 未来摘要预测 (FSP) 通过引入对长期未来信息的预测，显著提升了大型语言模型在处理复杂任务时的表现，克服了传统预测方法的局限性。

Abstract: Next-token prediction (NTP) has driven the success of large language models
(LLMs), but it struggles with long-horizon reasoning, planning, and creative
writing, with these limitations largely attributed to teacher-forced training.
Multi-token prediction (MTP) partially mitigates these issues by predicting
several future tokens at once, but it mostly captures short-range dependencies
and offers limited improvement. We propose future summary prediction (FSP),
which trains an auxiliary head to predict a compact representation of the
long-term future, preserving information relevant for long-form generations. We
explore two variants of FSP: handcrafted summaries, for example, a bag of words
summary of the future of the sequence, and learned summaries, which use
embeddings produced by a reverse language model trained from right to left.
Large-scale pretraining experiments (3B and 8B-parameter models) demonstrate
that FSP provides improvements over both NTP and MTP across math, reasoning,
and coding benchmarks.

</details>


### [191] [Efficient Dynamic Structured Sparse Training with Learned Shuffles](https://arxiv.org/abs/2510.14812)
*Abhishek Tyagi,Arjun Iyer,Liam Young,William H Renninger,Christopher Kanan,Yuhao Zhu*

Main category: cs.LG

TL;DR: 这篇论文提出了一种通过学习排列矩阵来增强结构化稀疏训练（PA-DST）的方法，使其在保持硬件效率的同时，达到与非结构化动态稀疏训练相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管结构化稀疏在现代GPU上加速了训练和推理，但其准确性仍落后于非结构化动态稀疏训练（DST），原因在于表达能力的损失。

Method: 本文提出为每个层学习一个排列矩阵，并与结构化权重矩阵联合训练。在块稀疏、N:M稀疏和对角稀疏三种典型结构上应用了这种方法。

Result: 在ImageNet-1K (ViT-B/16) 和 WikiText-103 (GPT-2) 数据集上，PA-DST在90-95%的稀疏度下与非结构化基线（RigL, SET）的准确性相匹配，同时训练速度提高了1.21倍，推理速度提高了2.9倍。

Conclusion: 结构化稀疏与学习排列相结合的方法在准确性和效率之间达到了一个平衡点。

Abstract: Structured sparsity accelerates training and inference on modern GPUs, yet it
still trails unstructured dynamic sparse training (DST) in accuracy. The
shortfall stems from a loss of expressivity: whereas a dense layer can realize
every possible mask obtained by choosing any $w$ active weights out of $n$, a
fixed block or N:M layout explores only a subset of those possibilities. We
propose to close this gap by learning, for each layer, a single permutation
matrix jointly with the structured weight matrix. Applied to three canonical
structures -- block, N:M, and diagonals -- we show that permutation-augmented
DST (PA-DST) matches unstructured baselines (RigL, SET) at 90--95\% sparsity on
ImageNet-1K (ViT-B/16) and WikiText-103 (GPT-2), yet trains up to $1.21\times$
and infers up to $2.9\times$ faster. The results position structure + learned
permutation as a sweet spot between accuracy and efficiency.

</details>


### [192] [Tackling Time-Series Forecasting Generalization via Mitigating Concept Drift](https://arxiv.org/abs/2510.14814)
*Zhiyuan Zhao,Haoxin Liu,B. Aditya Prakash*

Main category: cs.LG

TL;DR: 该论文提出了一种名为ShifTS的框架，通过软注意力机制解决时间序列预测中的概念漂移和时间漂移问题，实验证明其能有效提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据具有动态性，现有研究主要关注时间漂移问题，而对概念漂移的关注较少，传统不变学习方法在时间序列预测中存在挑战。

Method: 提出了一种软注意力机制，从回溯和展望时间序列中寻找不变模式。引入了ShifTS框架，首先解决时间漂移，然后解决概念漂移。

Result: ShifTS框架有效提升了多种数据集上不可知模型的预测精度。

Conclusion: ShifTS框架提供了一种统一的方法来解决时间序列预测中的时间漂移和概念漂移问题，并通过实验验证了其有效性。

Abstract: Time-series forecasting finds broad applications in real-world scenarios. Due
to the dynamic nature of time series data, it is important for time-series
forecasting models to handle potential distribution shifts over time. In this
paper, we initially identify two types of distribution shifts in time series:
concept drift and temporal shift. We acknowledge that while existing studies
primarily focus on addressing temporal shift issues in time series forecasting,
designing proper concept drift methods for time series forecasting has received
comparatively less attention.
  Motivated by the need to address potential concept drift, while conventional
concept drift methods via invariant learning face certain challenges in
time-series forecasting, we propose a soft attention mechanism that finds
invariant patterns from both lookback and horizon time series. Additionally, we
emphasize the critical importance of mitigating temporal shifts as a
preliminary to addressing concept drift. In this context, we introduce ShifTS,
a method-agnostic framework designed to tackle temporal shift first and then
concept drift within a unified approach. Extensive experiments demonstrate the
efficacy of ShifTS in consistently enhancing the forecasting accuracy of
agnostic models across multiple datasets, and outperforming existing concept
drift, temporal shift, and combined baselines.

</details>


### [193] [Reinforcement Learning with Stochastic Reward Machines](https://arxiv.org/abs/2510.14837)
*Jan Corazza,Ivan Gavran,Daniel Neider*

Main category: cs.LG

TL;DR: 该论文介绍了一种新的随机奖励机，它允许有噪声的奖励，并提出了一种基于约束求解的算法来学习它们，以克服现有奖励机算法的局限性，即需要无噪声的奖励。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励机制定型算法假设奖励是无噪声的，这在实际中难以实现。因此，作者旨在开发一种能够处理带噪声奖励的奖励机制定型方法。

Method: 作者引入了一种新型的随机奖励机制定型（stochastic reward machines），并提出了一种基于约束求解的算法来学习最小的随机奖励机制定型。该算法可以与现有的强化学习算法结合，并保证收敛到最优策略。

Result: 该算法在两个案例研究中表现出了有效性，并且优于现有方法和处理噪声奖励函数的简单方法。

Conclusion: 该论文提出了一种新的随机奖励机制定型及其学习算法，有效解决了现有奖励机制定型算法无法处理噪声奖励的实际限制，并能学习到最优策略。

Abstract: Reward machines are an established tool for dealing with reinforcement
learning problems in which rewards are sparse and depend on complex sequences
of actions. However, existing algorithms for learning reward machines assume an
overly idealized setting where rewards have to be free of noise. To overcome
this practical limitation, we introduce a novel type of reward machines, called
stochastic reward machines, and an algorithm for learning them. Our algorithm,
based on constraint solving, learns minimal stochastic reward machines from the
explorations of a reinforcement learning agent. This algorithm can easily be
paired with existing reinforcement learning algorithms for reward machines and
guarantees to converge to an optimal policy in the limit. We demonstrate the
effectiveness of our algorithm in two case studies and show that it outperforms
both existing methods and a naive approach for handling noisy reward functions.

</details>


### [194] [Backdoor Unlearning by Linear Task Decomposition](https://arxiv.org/abs/2510.14845)
*Amel Abdelraheem,Alessandro Favero,Gerome Bovet,Pascal Frossard*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法，旨在应对大型基础模型中存在的后门攻击。通过识别模型权重空间中后门与正常任务之间的分离，开发出一种能够有效消除后门影响同时保持模型整体性能的技术，从而解决了目前后门消除方法所面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 目前大型基础模型在计算机视觉领域取得了革命性的进展，但其仍然容易受到对抗性扰动和后门攻击的影响。以前的后门消除方法需要昂贵的微调，并且可能会降低模型在其他不相关任务上的性能。因此，本文旨在解决如何在不损害模型通用能力的情况下消除后门的问题。

Method: 本文首先研究了后门在模型权重空间中的编码方式，发现后门与其他良性任务是 disentangled 的。具体来说，这种分离使得在对模型良性任务性能影响最小的情况下，可以分离和清除后门对模型的影响。在此基础上，本文提出了一种简单的 unlearning 方法，该方法利用了这种 disentanglement。

Result: 通过对基于 CLIP 的模型和常见的对抗性触发器进行大量实验，结果表明，在已知攻击的情况下，该方法可以实现将近完美的 unlearning，同时平均保留 96％的良性任务准确性。此外，本文发现，即使攻击及其存在未知，该方法也可以通过使用逆向工程触发器进行适当估计来成功地 unlearn 后门。

Conclusion: 本文提出的方法相比目前的 SOTA 防御方法，在 unlearning 和良性任务准确性权衡方面始终取得更好的效果，实现了在不损害模型通用能力的情况下消除后门的目的。

Abstract: Foundation models have revolutionized computer vision by enabling broad
generalization across diverse tasks. Yet, they remain highly susceptible to
adversarial perturbations and targeted backdoor attacks. Mitigating such
vulnerabilities remains an open challenge, especially given that the
large-scale nature of the models prohibits retraining to ensure safety.
Existing backdoor removal approaches rely on costly fine-tuning to override the
harmful behavior, and can often degrade performance on other unrelated tasks.
This raises the question of whether backdoors can be removed without
compromising the general capabilities of the models. In this work, we address
this question and study how backdoors are encoded in the model weight space,
finding that they are disentangled from other benign tasks. Specifically, this
separation enables the isolation and erasure of the backdoor's influence on the
model with minimal impact on clean performance. Building on this insight, we
introduce a simple unlearning method that leverages such disentanglement.
Through extensive experiments with CLIP-based models and common adversarial
triggers, we show that, given the knowledge of the attack, our method achieves
approximately perfect unlearning, while retaining, on average, 96% of clean
accuracy. Additionally, we demonstrate that even when the attack and its
presence are unknown, our method successfully unlearns backdoors by proper
estimation using reverse-engineered triggers. Overall, our method consistently
yields better unlearning and clean accuracy tradeoffs when compared to present
state-of-the-art defenses.

</details>


### [195] [Predicting kernel regression learning curves from only raw data statistics](https://arxiv.org/abs/2510.14878)
*Dhruva Karkada,Joseph Turnbull,Yuxi Liu,James B. Simon*

Main category: cs.LG

TL;DR: 该文章研究了在真实数据集（如CIFAR-5m、SVHN和ImageNet）上使用常见旋转不变核的核回归。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在提出一个理论框架，仅从两个测量值（经验数据协方差矩阵和目标函数的经验多项式分解）来预测学习曲线（测试风险与样本大小的关系）。文章的核心新思想是核的特征值和特征函数在各向异性数据分布下的分析近似。

Method: 该文章提出了Hermite特征结构假说（HEA），该假说认为特征函数类似于数据的Hermite多项式。研究人员证明了高斯数据的HEA，并发现实际图像数据通常“足够高斯”，使得HEA在实践中能够很好地成立。通过将核特征结构与测试风险相关联的先前结果，研究人员能够预测学习曲线。此外，该研究还通过实验发现，在特征学习阶段的多层感知器（MLP）按照HEA预测的顺序学习Hermite多项式。

Result: 该研究提供了一个理论框架，可以预测在真实数据集上使用旋转不变核的核回归的学习曲线。 Hermite特征结构假说（HEA）被证明对高斯数据成立，并且在实际图像数据上表现良好。实验结果表明，MLP在特征学习阶段学习Hermite多项式，其顺序与HEA预测的一致。

Conclusion: HEA框架是一个概念验证，表明将数据集结构映射到模型性能的端到端学习理论对于真实数据集上的非平凡学习算法是可行的。

Abstract: We study kernel regression with common rotation-invariant kernels on real
datasets including CIFAR-5m, SVHN, and ImageNet. We give a theoretical
framework that predicts learning curves (test risk vs. sample size) from only
two measurements: the empirical data covariance matrix and an empirical
polynomial decomposition of the target function $f_*$. The key new idea is an
analytical approximation of a kernel's eigenvalues and eigenfunctions with
respect to an anisotropic data distribution. The eigenfunctions resemble
Hermite polynomials of the data, so we call this approximation the Hermite
eigenstructure ansatz (HEA). We prove the HEA for Gaussian data, but we find
that real image data is often "Gaussian enough" for the HEA to hold well in
practice, enabling us to predict learning curves by applying prior results
relating kernel eigenstructure to test risk. Extending beyond kernel
regression, we empirically find that MLPs in the feature-learning regime learn
Hermite polynomials in the order predicted by the HEA. Our HEA framework is a
proof of concept that an end-to-end theory of learning which maps dataset
structure all the way to model performance is possible for nontrivial learning
algorithms on real datasets.

</details>


### [196] [Reasoning with Sampling: Your Base Model is Smarter Than You Think](https://arxiv.org/abs/2510.14901)
*Aayush Karan,Yilun Du*

Main category: cs.LG

TL;DR: 本文提出了一种迭代采样算法，可以在不进行额外训练的情况下，从基础模型中提取出与强化学习相当的推理能力，并在多种单次任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前前沿的推理模型通过强化学习（RL）在大型语言模型（LLM）上进行后训练，取得了广泛成功。然而，很多研究致力于剖析在RL过程中出现的、但基础模型中不存在的真正新颖行为。本文则从一个不同的角度探讨，即在不进行任何额外训练的情况下，是否可以通过纯粹的采样，在推理时从基础模型中引出可比较的推理能力。

Method: 本文提出了一种简单的迭代采样算法，其灵感来源于马尔可夫链蒙特卡罗（MCMC）技术，用于从尖锐分布中进行采样，并利用基础模型自身的似然性。

Result: 在不同的基础模型上，本文的算法显著提升了推理能力，在多种单次任务（包括MATH500、HumanEval和GPQA）上，其表现几乎与强化学习相当甚至超越强化学习。此外，本文的采样器避免了强化学习后训练中常见的多样本多样性崩溃问题。

Conclusion: 本文的方法不需要训练、精选数据集或验证器，这意味着它在易于验证的领域之外也具有广泛的适用性。

Abstract: Frontier reasoning models have exhibited incredible capabilities across a
wide array of disciplines, driven by posttraining large language models (LLMs)
with reinforcement learning (RL). However, despite the widespread success of
this paradigm, much of the literature has been devoted to disentangling truly
novel behaviors that emerge during RL but are not present in the base models.
In our work, we approach this question from a different angle, instead asking
whether comparable reasoning capabilites can be elicited from base models at
inference time by pure sampling, without any additional training. Inspired by
Markov chain Monte Carlo (MCMC) techniques for sampling from sharpened
distributions, we propose a simple iterative sampling algorithm leveraging the
base models' own likelihoods. Over different base models, we show that our
algorithm offers substantial boosts in reasoning that nearly match and even
outperform those from RL on a wide variety of single-shot tasks, including
MATH500, HumanEval, and GPQA. Moreover, our sampler avoids the collapse in
diversity over multiple samples that is characteristic of RL-posttraining.
Crucially, our method does not require training, curated datasets, or a
verifier, suggesting broad applicability beyond easily verifiable domains.

</details>


### [197] [Circuit Insights: Towards Interpretability Beyond Activations](https://arxiv.org/abs/2510.14936)
*Elena Golimblevskaia,Aakriti Jain,Bruno Puri,Ammar Ibrahim,Wojciech Samek,Sebastian Lapuschkin*

Main category: cs.LG

TL;DR: 本文提出了WeightLens和CircuitLens，这两种方法旨在超越基于激活的分析，提高可解释性，并促进可扩展的电路机制分析。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释人工智能方法依赖于手动检查或受限于玩具任务，自动化可解释方法虽然具有可伸缩性，但忽视了特征间的相互作用，并受外部大型语言模型和数据集质量的影响。

Method: 本文提出了WeightLens和CircuitLens两种互补方法。WeightLens直接从学习到的权重中解释特征，无需解释模型或数据集，并且在上下文无关的特征上性能与现有方法相当或更优。CircuitLens则捕捉特征激活如何从组件间的相互作用中产生，揭示了仅靠激活方法无法识别的电路级动态。

Result: WeightLens在上下文无关特征上的表现与现有方法相当或更优。CircuitLens揭示了仅靠激活方法无法识别的电路级动态。

Conclusion: 这两种方法共同提高了可解释性的鲁棒性，增强了电路的可扩展机制分析，同时保持了效率和质量。

Abstract: The fields of explainable AI and mechanistic interpretability aim to uncover
the internal structure of neural networks, with circuit discovery as a central
tool for understanding model computations. Existing approaches, however, rely
on manual inspection and remain limited to toy tasks. Automated
interpretability offers scalability by analyzing isolated features and their
activations, but it often misses interactions between features and depends
strongly on external LLMs and dataset quality. Transcoders have recently made
it possible to separate feature attributions into input-dependent and
input-invariant components, providing a foundation for more systematic circuit
analysis. Building on this, we propose WeightLens and CircuitLens, two
complementary methods that go beyond activation-based analysis. WeightLens
interprets features directly from their learned weights, removing the need for
explainer models or datasets while matching or exceeding the performance of
existing methods on context-independent features. CircuitLens captures how
feature activations arise from interactions between components, revealing
circuit-level dynamics that activation-only approaches cannot identify.
Together, these methods increase interpretability robustness and enhance
scalable mechanistic analysis of circuits while maintaining efficiency and
quality.

</details>


### [198] [Efficient Parallel Samplers for Recurrent-Depth Models and Their Connection to Diffusion Language Models](https://arxiv.org/abs/2510.14961)
*Jonas Geiping,Xinyu Yang,Guinan Su*

Main category: cs.LG

TL;DR: 该文章提出了一种用于循环深度语言模型的新型扩散强制采样器，可以加速生成过程，并将其与扩散语言模型联系起来。


<details>
  <summary>Details</summary>
Motivation: 探索循环深度模型与扩散语言模型之间的关系，并开发一种方法来加速循环深度模型的文本生成。

Method: 开发了一种新的扩散强制采样器，通过在模型每次前向传播时解码新token，并通过循环并行细化这些token的潜在状态来加速生成。

Result: 与基线自回归生成相比，该采样器在相同的时间预算下具有更强的表达能力，并且可以将现有3.5B循环深度Transformer模型的生成速度提高高达5倍，无需任何调优。

Conclusion: 循环深度模型可以被自然地视为强大的连续（尽管是因果的）扩散语言模型，并且所提出的采样器为在推理时并行化循环深度模型中的额外计算提供了一种有效机制。

Abstract: Language models with recurrent depth, also referred to as universal or looped
when considering transformers, are defined by the capacity to increase their
computation through the repetition of layers. Recent efforts in pretraining
have demonstrated that these architectures can scale to modern language
modeling tasks while exhibiting advantages in reasoning tasks. In this work, we
examine the relationship between recurrent-depth models and diffusion language
models. Building on their similarities, we develop a new diffusion forcing
sampler for these models to accelerate generation. The sampler advances by
decoding new tokens at every forward pass of the model, while the latent states
of these tokens can be further refined in parallel through recurrence.
Theoretically, generation with our sampler is strictly more expressive than the
baseline autoregressive generation using the same time budget on modern
hardware. Moreover, this sampler, based on principles from diffusion
literature, can be directly applied to existing 3.5B recurrent-depth
transformers without any tuning, leading to up to a 5x speedup. Consequently,
our findings not only provide an efficient mechanism for parallelizing the
extra computation in recurrent-depth models at inference, but also suggest that
such models can be naturally viewed as strong continuous, though causal,
diffusion language models.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [199] [Structure-Preserving Error-Correcting Codes for Polynomial Frames](https://arxiv.org/abs/2510.13882)
*Baigang Chen,Dongfang Zhao*

Main category: cs.IT

TL;DR: 本文提出了一种保护多项式环中数据免受错误影响的方法，其开销低且性能高，适用于现代数据传输场景。


<details>
  <summary>Details</summary>
Motivation: 在FFT/NTT分析、编码计算和隐私保护机器学习接口中，多项式帧的传输容易受到静默数据损坏（SDC）的影响，导致下游计算错误。传统的错误检测和纠正方法不适用于低延迟管道。

Method: 我们提出了两种结构保持的可靠性方案。第一种是针对奇数长度N_odd，采用Hensel提升的BCH理想与幂等编码器。第二种是针对2的幂长度N_2^m，采用重复根负循环码与导数式解码。此外，通过环自同构实现原地交织，以分散突发错误。

Result: 在四种帧大小下，本文方法在符号错误率为10^-6到10^-5时，实现了10^-9的每帧故障目标。开销仅为0.20%到1.56%，并且在交织后能够容忍大约32-72字节的未知错误突发，如果标记为擦除，则容忍能力大约翻倍。

Conclusion: 通过将错误校正与环语义对齐，本文从代数编码的角度向可部署的多项式帧计算的鲁棒性迈出了实用的一步。

Abstract: Modern FFT/NTT analytics, coded computation, and privacy-preserving ML
interface routinely move polynomial frames across NICs, storage, and
accelerators. However, even rare silent data corruption (SDC) can flip a few
ring coefficients and cascade through downstream arithmetic. Conventional
defenses are ill-matched to current low-latency pipelines:
detect-and-retransmit adds RTTs, while byte-stream ECC ignores the algebraic
structure and forces format conversions. To that end, we propose a
structure-preserving reliability layer that operates in the encoded data's
original polynomial ring, adds a small amount of systematic redundancy, and
corrects symbol errors/flagged erasures without round-trip or format changes.
We construct two complementary schemes: one for odd length $N_{odd}$ via a
Hensel-lifted BCH ideal with an idempotent encoder, and one for power-of-two
length $N_{2^m}$ via a repeated-root negacyclic code with derivative-style
decoding. In particular, to stay robust against clustered errors, a ring
automorphism provides in-place interleaving to disperse bursts. Implementation
wise, on four frame sizes $N\!=\!1024, 2048, 4096, 8192$, we meet a per-frame
failure target of $10^{-9}$ at symbol error rates $10^{-6}\text{--}10^{-5}$
with $t\!=\!8\text{--}9$, incurring only $0.20\%\text{--}1.56\%$ overhead and
tolerating $\sim\!32\text{--}72$\,B unknown-error bursts (roughly doubled when
flagged as erasures) after interleaving. By aligning error correction with ring
semantics, we take a practical step toward deployable robustness for
polynomial-frame computations from an algebraic coding perspective.

</details>


### [200] [Location-Aided Distributed Beamforming for Near-Field Communications with Element-Wise RIS](https://arxiv.org/abs/2510.14226)
*Xiao Zheng,Wenchi Cheng,Jingqing Wang,Zhuohui Yao,Jiangzhou Wang*

Main category: cs.IT

TL;DR: 零功耗有源可重构智能表面（RIS）在部署中存在信道估计（CE）和离散相移约束等挑战。本文提出了一种新的逐元素RIS架构和分布式位置辅助传输方案，以增强近场通信的反射增益。


<details>
  <summary>Details</summary>
Motivation: 现有的零功耗有源可重构智能表面（RIS）研究忽略了RIS辅助系统固有的信道估计（CE）难度以及实际部署中的离散相移约束。

Method: 本文设计了一种新的逐元素RIS架构，并提出了一种分布式位置辅助传输方案。该方案利用菲涅尔衍射理论，构建了从空间域位置到相位域波相位分布的映射，并揭示了用于能量收集和反射的元素的优先级。随后，提出了确定-对齐式的分布式波束成形设计，通过免除基站（BS）的RIS相关CE需求来减少估计开销。新的逐元素RIS提供了以低硬件资源进行动态元素选择的能力。

Result: 渐近分析表明，当RIS较大时，所提出的方案可以在固定比例的反射元件下实现最佳增益。仿真结果验证了该方案相对于其他协议的优越性。

Conclusion: 本文提出的逐元素RIS架构和分布式位置辅助传输方案，有效解决了零功耗有源RIS在近场通信中的信道估计难题和离散相移约束问题。该方案通过低复杂度的设计实现了优越的反射增益性能，为RIS的实际部署提供了新的思路。

Abstract: Active reconfigurable intelligent surface (RIS) emerges as an effective
technique to resist the double-fading attenuation of passive RIS. By embedding
with power harvesting function, it further evolves to zero-power active RIS,
which can effectively enhance the flexibility of RIS deployment without
external power demand. Nevertheless, existing works neglected the inherent
difficulty of channel estimation (CE) for RIS-assisted systems, and the
discrete phase shift constraint in practical deployment. In this paper we
design a new element-wise RIS architecture and propose a distributed
location-aided transmission scheme with low complexity to enhance the reflected
gain for channel state information (CSI)-limited RIS-assisted near-field
communications. Specifically, the new element-wise RIS provides dynamic element
selection capability with low hardware resources. Based on Fresnel diffraction
theory, we construct the mapping from locations in space-domain to phase
distributions of waves in phase-domain and reveal the priority of elements for
harvesting and reflecting. {Then, the distributed beamforming design with the
phase of determine-then-align is proposed, where the estimation overhead
reduction stems from exempted requirements of RIS-associated CE at base station
(BS).} The asymptotic analysis indicates that the proposed scheme can achieve
the optimal gain with a fixed proportion of reflective elements when RIS is
large, followed by simulations to verify its superiority to other protocols.

</details>


### [201] [The asymptotic number of equivalence classes of linear codes with given dimension](https://arxiv.org/abs/2510.14424)
*Andrea Di Giusto,Alberto Ravagnani*

Main category: cs.IT

TL;DR: 本文研究了给定长度和维度线性码等价类的渐近数量。


<details>
  <summary>Details</summary>
Motivation: 以往研究只关注给定长度不等价码的总数，而未考虑维度随长度变化的情况，本文旨在填补这一空白。

Method: 本文推导了固定字母表大小和增加长度下三种标准等价概念下等价类数量的显式渐近公式，并得到了q-二项式系数和的精确渐近表达式。

Result: 得到了等价类数量的渐近公式和q-二项式系数和的精确渐近表达式。此外，研究还揭示了这些渐近量与布朗运动产生的离散高斯分布之间的联系。

Conclusion: 本文成功地为线性码等价类的数量提供了渐近分析，并为q-二项式系数和提供了一个答案，同时建立了这些数量与概率论中的布朗运动之间的联系。

Abstract: We investigate the asymptotic number of equivalence classes of linear codes
with prescribed length and dimension. While the total number of inequivalent
codes of a given length has been studied previously, the case where the
dimension varies as a function of the length has not yet been considered. We
derive explicit asymptotic formulas for the number of equivalence classes under
three standard notions of equivalence, for a fixed alphabet size and increasing
length. Our approach also yields an exact asymptotic expression for the sum of
all q-binomial coefficients, which is of independent interest and answers an
open question in this context. Finally, we establish a natural connection
between these asymptotic quantities and certain discrete Gaussian distributions
arising from Brownian motion, providing a probabilistic interpretation of our
results.

</details>


### [202] [Rotatable Antenna-Enhanced Beamforming: Signal Enhancement and Interference Suppression](https://arxiv.org/abs/2510.14574)
*Jie Feng,Zhenbing Liu,Junjie Dai,Hongbin Chen,Fangjiong Chen*

Main category: cs.IT

TL;DR: 本文提出了一种可旋转天线（RA）增强的单/多波束形成方案，通过优化天线旋转来提高阵列增益，优于传统的固定方向天线（FOA）和各向同性天线（IA）方案。


<details>
  <summary>Details</summary>
Motivation: 传统的固定方向天线（FOA）阵列在不同转向角下天线方向性增益变化显著，导致其在有效增强信号和/或抑制干扰方面表现不佳。

Method: 本文提出通过优化天线的旋转来利用新的空间自由度，从而实现可旋转天线（RA）增强的单/多波束形成。具体来说，天线旋转矢量（ARV）和天线权向量（AWV）被联合优化，以在干扰方向上的最大阵列增益受给定约束的情况下，最大化信号方向上的最小阵列增益。对于没有干扰的单波束形成特例，在AWV应用最大比合并（MRC）波束赋形器的情况下，导出了最优ARV的闭合形式。对于多波束形成的一般情况，本文提出了一种有效的交替优化（AO）算法来找到一个高质量的次优解，通过迭代优化ARV和AWV中的一个，同时固定另一个。

Result: 仿真结果表明，所提出的基于RA的方案在阵列增益方面可以显著优于传统的基于FOA和基于各向同性天线（IA）的方案。

Conclusion: 可旋转天线（RA）通过引入新的空间自由度并对天线旋转矢量和天线权向量进行联合优化，能够有效地提高波束形成性能，在信号增强和干扰抑制方面表现出优越性。

Abstract: Conventional beamforming with fixed-orientation antenna (FOA) arrays may
struggle to effectively enhance signal and/or suppress interference due to
significant variations in antenna directive gains over different steering
angles. To break this limitation, we investigate in this paper the rotatable
antenna (RA)-enhanced single/multi-beam forming by exploiting the new spatial
degrees of freedom (DoFs) via antennas' rotation optimization. Specifically,
the antenna rotation vector (ARV) and antenna weight vector (AWV) are jointly
optimized to maximize the minimum array gain over signal directions, subject to
a given constraint on the maximum array gain over interference directions. For
the special case of single-beam forming without interference, the optimal ARV
is derived in closed-form with the maximum ratio combining (MRC) beamformer
applied to the AWV. For the general case of multi-beam forming, we propose an
efficient alternating optimization (AO) algorithm to find a high-quality
suboptimal solution by iteratively optimizing one of the ARV and AWV with the
other being fixed. Simulation results demonstrate that the proposed RA-based
scheme can significantly outperform the traditional FOA-based and isotropic
antenna (IA)-based schemes in terms of array gain.

</details>


### [203] [Task-Based Quantization for Channel Estimation in RIS Empowered MmWave Systems](https://arxiv.org/abs/2510.14649)
*Gyoseung Lee,In-soo Kim,Yonina C. Eldar,A. Lee Swindlehurst,Hyeongtaek Lee,Minje Kim,Junil Choi*

Main category: cs.IT

TL;DR: 本文研究了低分辨率量化下可重构智能表面（RIS）增强毫米波（mmWave）多用户单输入多输出（SIMO）通信系统的信道估计问题。


<details>
  <summary>Details</summary>
Motivation: 在大规模天线阵列和宽信号带宽中，模数转换器（ADC）成本高且功耗大，因此设计采用低分辨率ADC的毫米波系统是有益的。

Method: 本文提出了一种基于任务的量化信道估计算法，该算法考虑了底层混合模拟和数字架构，以在有限比特分辨率约束下提高系统性能。本文开发了两种类型的信道估计算法：一种是针对纯无源RIS的级联信道估计算法，另一种是针对RIS相关信道的估计算法，该算法利用了RIS上少量半无源元件的额外信息，这些元件能够用射频链处理接收到的信号。

Result: 数值结果表明，本文提出的利用基于任务的量化信道估计设计优于纯数字方法，并且可以有效地接近具有无限分辨率ADC的系统性能。此外，结果还表明所提出的信道估计算法在训练开销较小的情况下优于基线。

Conclusion: 本文提出的基于任务的量化信道估计方法能够显著提高低分辨率量化下RIS增强毫米波MIMO通信系统的信道估计性能，并弥补了与全数字方法和无限分辨率ADC系统之间的差距。

Abstract: In this paper, we investigate channel estimation for reconfigurable
intelligent surface (RIS) empowered millimeter-wave (mmWave) multi-user
single-input multiple-output communication systems using low-resolution
quantization. Due to the high cost and power consumption of analog-to-digital
converters (ADCs) in large antenna arrays and for wide signal bandwidths,
designing mmWave systems with low-resolution ADCs is beneficial. To tackle this
issue, we propose a channel estimation design using task-based quantization
that considers the underlying hybrid analog and digital architecture in order
to improve the system performance under finite bit-resolution constraints. Our
goal is to accomplish a channel estimation task that minimizes the mean squared
error distortion between the true and estimated channel. We develop two types
of channel estimators: a cascaded channel estimator for an RIS with purely
passive elements, and an estimator for the separate RIS-related channels that
leverages additional information from a few semi-passive elements at the RIS
capable of processing the received signals with radio frequency chains.
Numerical results demonstrate that the proposed channel estimation designs
exploiting task-based quantization outperform purely digital methods and can
effectively approach the performance of a system with unlimited resolution
ADCs. Furthermore, the proposed channel estimators are shown to be superior to
baselines with small training overhead.

</details>


### [204] [Rate-Adaptive Spatially Coupled MacKay-Neal Codes with Thresholds Close to Capacity](https://arxiv.org/abs/2510.14843)
*Ayman Zahr,Gianluigi Liva*

Main category: cs.IT

TL;DR: 该论文分析了速率自适应MacKay-Neal（MN）码集与原型空时耦合（SC）低密度奇偶校验码结合的渐近性能。


<details>
  <summary>Details</summary>
Motivation: 探索SC MN码集在AWGN信道下的性能潜力，以接近香农极限。

Method: 通过密度演化和自定义的并行信道模型，计算置信传播解码阈值。

Result: SC MN码集在[0,1]的整个速率范围内，性能可达二进制输入加性高斯白噪声信道容量的0.15 dB以内。

Conclusion: SC MN码集表现出优异的性能，非常接近理论极限，在通信系统中具有潜在应用价值。

Abstract: We analyze by density evolution the asymptotic performance of rate-adaptive
MacKay-Neal (MN) code ensembles, where the inner code is a protograph spatially
coupled (SC) low-density parity-check code. By resorting to a suitably-defined
parallel channel model, we compute belief propagation decoding thresholds,
showing that SC MN code ensembles can perform within 0.15 dB from the
binary-input additive white Gaussian noise capacity over the full [0,1] rate
range.

</details>


### [205] [Rate-Adaptive Protograph-Based MacKay-Neal Codes](https://arxiv.org/abs/2510.14856)
*Ayman Zahr,Emna Ben Yacoub,Balázs Matuz,Gianluigi Liva*

Main category: cs.IT

TL;DR: 本文分析了基于原图的速率自适应 MacKay-Neal (MN) 码，该码通过外部分布匹配器 (DM) 调整速率，并与内部基于原图的低密度奇偶校验 (LDPC) 码耦合。


<details>
  <summary>Details</summary>
Motivation: 研究速率自适应 MacKay-Neal (MN) 码的性能，以实现恒定块长和固定LDPC码作为内码的速率灵活性，从而为超高吞吐量无线（光）链路提供有吸引力的解决方案。

Method: 通过等效通信模型分析了所得码结构的性能，该模型将问题简化为对内部（线性）LDPC码的分析，传输在通信信道和适当定义的二元对称信道上并行进行。本文概述了原图MN码集的密度演化分析，并通过误差平层分析对其进行了补充，该分析依赖于内部LDPC码集的平均输入-输出权重分布的推导。定义了归一化对数渐近输入-输出权重分布形状的条件，从而可以在码设计阶段丢弃具有不良误差平层属性的码集。

Result: 通过使用单个LDPC码集，在宽范围码率下，通过调整DM参数选择码率，可以在1 dB的香农极限内工作。

Conclusion: 所提出的速率自适应MN码结构为采用二进制输入调制的超高吞吐量无线（光）链路提供了一种有吸引力的解决方案，因为它实现了恒定块长下的速率灵活性，并使用了固定的LDPC码作为内码。

Abstract: Rate-adaptive MacKay-Neal (MN) codes based on protographs are analyzed. The
code construction employs an outer distribution matcher (DM) to adapt the rate
of the scheme. The DM is coupled with an inner protograph-based low-density
parity-check (LDPC) code. The performance achievable by the resulting code
structure, that is nonlinear, is studied by means of an equivalent
communication model that reduces the problem to the analysis of the inner
(linear) LDPC code with transmission that takes place in parallel over the
communication channel, and over a suitably defined binary symmetric channel. A
density evolution analysis of protograph MN code ensembles is outlined, and it
is complemented by an error floor analysis that relies on the derivation of the
average input-output weight distribution of the inner LDPC code ensemble.
Conditions on the shape of the normalized logarithmic asymptotic input-output
weight distribution are defined, which allow discarding code ensembles with bad
error floor properties during the code design phase. Examples of code designs
are provided, showing how the use of a single LDPC code ensemble allows
operating within 1 dB from the Shannon limit over a wide range of code rates,
where the code rate is selected by tuning the DM parameters. By enabling rate
flexibility with a constant blocklength, and with a fixed LDPC code as inner
code, the construction provides an appealing solution for very high-throughput
wireless (optical) links that employ binary-input modulations.

</details>


### [206] [The Whole Is Less than the Sum of Parts: Subsystem Inconsistency in Partial Information Decomposition](https://arxiv.org/abs/2510.14864)
*Aobo Lyu,Andrew Clark,Netanel Raviv*

Main category: cs.IT

TL;DR: 该论文讨论了部分信息分解（PID）框架在分析多变量系统信息交互方面的局限性，特别是在“整体等于部分之和”（WESP）原则上的违背。论文提出了系统信息分解（SID）作为一种新的公理框架来解决三变量系统中的WESP违规，但指出对于四个或更多变量的系统，基于格的分解存在固有的不足。


<details>
  <summary>Details</summary>
Motivation: 部分信息分解（PID）作为一种分析多变量间精细交互的工具，已在多个领域得到应用。然而，由于概念和技术挑战，其统一理论框架仍未确立。该研究旨在解决PID框架在“整体等于部分之和”（WESP）原则上的违背问题，并探索多变量系统信息分解的固有局限性。

Method: 1. 识别并说明了PID违反集合论原则“整体等于部分之和”（WESP）的关键问题。2. 通过一个三变量系统中的反例，展示了这种违规是如何产生的，揭示了当前基于格的PID框架的基本局限性。3. 引入了一种新的公理框架，称为系统信息分解（SID），专门用于三变量系统，通过重新定义基于协同关系的分解信息原子的求和规则来解决WESP违规。4. 进一步证明，对于具有四个或更多变量的系统，现有基于格结构中的部分求和方法无法完全消除WESP的不一致性。

Result: 1. 发现并具体化了现有PID框架在“整体等于部分之和”（WESP）原则上的违背。2. 提出了系统信息分解（SID）框架，成功解决了三变量系统中的WESP违规问题。3. 揭示了对于四个或更多变量的系统，基于（反链）格的分解在解决WESP不一致性方面存在固有的不足和不适用性。

Conclusion: 现有的部分信息分解（PID）框架在分析多变量系统时，存在违反“整体等于部分之和”（WESP）原则的根本性局限性。尽管系统信息分解（SID）为三变量系统提供了一个解决方案，但对于更复杂的系统，基于格的分解仍然无法完全消除WESP的不一致性。这表明，对于一般的多变量系统，基于格的分解在信息分析方面存在固有的不足。

Abstract: Partial Information Decomposition (PID) was proposed by Williams and Beer in
2010 as a tool for analyzing fine-grained interactions between multiple random
variables, and has since found numerous applications ranging from neuroscience
to privacy. However, a unified theoretical framework remains elusive due to key
conceptual and technical challenges. We identify and illustrate a crucial
problem: PID violates the set-theoretic principle that the whole equals the sum
of its parts (WESP). Through a counterexample in a three-variable system, we
demonstrate how such violations naturally arise, revealing a fundamental
limitation of current lattice-based PID frameworks. To address this issue, we
introduce a new axiomatic framework, termed System Information Decomposition
(SID), specifically tailored for three-variable systems. SID resolves the WESP
violation by redefining the summation rules of decomposed information atoms
based on synergistic relationships. However, we further show that for systems
with four or more variables, no partial summation approach within the existing
lattice-based structures can fully eliminate WESP inconsistencies. Our results
thus highlight the inherent inadequacy of (antichain) lattice-based
decompositions for general multivariate systems.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [207] [Exact Dynamics of Multi-class Stochastic Gradient Descent](https://arxiv.org/abs/2510.14074)
*Elizabeth Collins-Woodfin,Inbar Seroussi*

Main category: stat.ML

TL;DR: 该文章提出了一个框架，用于分析使用单次随机梯度下降（SGD）在高维优化问题中训练和学习速率的动态。


<details>
  <summary>Details</summary>
Motivation: 探索SGD在高维优化问题中，特别是在存在各向异性数据时，训练和学习速率的动态。

Method: 开发了一个框架，通过常微分方程组的确定性解，精确表达了限制动态的大类函数的表达式。将现有理论扩展到高斯混合数据和大量类别。详细研究了各向异性数据协方差结构对二元逻辑回归和最小二乘损失问题的影响，考虑了各向同性协方差、零特征值占比较大的数据协方差矩阵（零一模型）以及谱遵循幂律分布的协方差矩阵三种情况。

Result: 存在一个结构相变。对于零一模型和具有足够大幂的幂律模型，SGD倾向于与投影到“干净方向”（即方差较小的方向）上的类别均值对齐。数值模拟和分析研究支持了这一发现。

Conclusion: 该研究揭示了在高维SGD训练中，数据协方差的各向异性结构会导致结构相变，并且SGD倾向于关注数据中“较干净”的方向。

Abstract: We develop a framework for analyzing the training and learning rate dynamics
on a variety of high- dimensional optimization problems trained using one-pass
stochastic gradient descent (SGD) with data generated from multiple anisotropic
classes. We give exact expressions for a large class of functions of the
limiting dynamics, including the risk and the overlap with the true signal, in
terms of a deterministic solution to a system of ODEs. We extend the existing
theory of high-dimensional SGD dynamics to Gaussian-mixture data and a large
(growing with the parameter size) number of classes. We then investigate in
detail the effect of the anisotropic structure of the covariance of the data in
the problems of binary logistic regression and least square loss. We study
three cases: isotropic covariances, data covariance matrices with a large
fraction of zero eigenvalues (denoted as the zero-one model), and covariance
matrices with spectra following a power-law distribution. We show that there
exists a structural phase transition. In particular, we demonstrate that, for
the zero-one model and the power-law model with sufficiently large power, SGD
tends to align more closely with values of the class mean that are projected
onto the "clean directions" (i.e., directions of smaller variance). This is
supported by both numerical simulations and analytical studies, which show the
exact asymptotic behavior of the loss in the high-dimensional limit.

</details>


### [208] [deFOREST: Fusing Optical and Radar satellite data for Enhanced Sensing of Tree-loss](https://arxiv.org/abs/2510.14092)
*Julio Enrique Castrillon-Candas,Hanfeng Gu,Caleb Meredith,Yulin Li,Xiaojing Tang,Pontus Olofsson,Mark Kon*

Main category: stat.ML

TL;DR: 本文提出了一种结合光学和合成孔径雷达（SAR）数据的森林砍伐检测方法，并利用离散KL展开的残差空间构建异常图，通过隐马尔可夫模型（HMM）进行分类，该方法在亚马逊森林区域取得了比现有技术更高的准确性，尤其在光学数据稀疏的云量大区域表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一种结合光学和合成孔径雷达（SAR）数据的高效森林砍伐检测方法，以克服传统方法对数据分布先验知识的依赖，并解决高云量地区光学数据稀疏的问题。

Method: 该方法主要分为两个阶段：一是利用离散Karhunen-Loève（KL）展开的残差空间构建光学数据的异常图，并通过残差分量分布的浓度界限量化异常，该界限不依赖于数据分布的先验知识。二是将计算出的光学异常图与SAR数据结合，使用隐马尔可夫模型（HMM）对森林状态进行分类。

Result: 在亚马逊森林$92.19 \,km \times 91.80\,km$区域，使用Sentinel-1（SAR）和Sentinel-2（光学）数据进行了测试。结果表明，混合光学-雷达方法和纯光学方法都达到了比现有最先进的混合方法更高的精度。此外，混合方法在光学数据稀疏的高云量区域表现出显著更强的鲁棒性。

Conclusion: 本文提出的结合光学和SAR数据的森林砍伐检测管道，通过利用非参数的异常检测方法和HMM分类，在检测精度和对稀疏光学数据的鲁棒性方面均优于现有技术，特别适用于高云量地区的森林砍伐监测。

Abstract: In this paper we develop a deforestation detection pipeline that incorporates
optical and Synthetic Aperture Radar (SAR) data. A crucial component of the
pipeline is the construction of anomaly maps of the optical data, which is done
using the residual space of a discrete Karhunen-Lo\`{e}ve (KL) expansion.
Anomalies are quantified using a concentration bound on the distribution of the
residual components for the nominal state of the forest. This bound does not
require prior knowledge on the distribution of the data. This is in contrast to
statistical parametric methods that assume knowledge of the data distribution,
an impractical assumption that is especially infeasible for high dimensional
data such as ours. Once the optical anomaly maps are computed they are combined
with SAR data, and the state of the forest is classified by using a Hidden
Markov Model (HMM). We test our approach with Sentinel-1 (SAR) and Sentinel-2
(Optical) data on a $92.19\,km \times 91.80\,km$ region in the Amazon forest.
The results show that both the hybrid optical-radar and optical only methods
achieve high accuracy that is superior to the recent state-of-the-art hybrid
method. Moreover, the hybrid method is significantly more robust in the case of
sparse optical data that are common in highly cloudy regions.

</details>


### [209] [High-Dimensional BWDM: A Robust Nonparametric Clustering Validation Index for Large-Scale Data](https://arxiv.org/abs/2510.14145)
*Mohammed Baragilly,Hend Gabr*

Main category: stat.ML

TL;DR: 该文章提出一个新的鲁棒的非参数聚类验证框架，即高维组间-组内距离中位数（HD-BWDM），旨在解决传统方法在高维或受污染数据中表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 传统聚类有效性指标在高维或受污染数据中表现不佳，因为它们依赖于基于质心的距离。

Method: HD-BWDM框架通过整合随机投影和主成分分析来缓解维度灾难，并应用截尾聚类和基于中心点的距离，以确保对异常值的鲁棒性。

Result: HD-BWDM在高维投影和污染下保持稳定和可解释，提供了一个替代传统基于质心验证标准的鲁棒方法。

Conclusion: HD-BWDM为现代高维应用中的非参数聚类提供了一个理论基础强且计算高效的停止规则。

Abstract: Determining the appropriate number of clusters in unsupervised learning is a
central problem in statistics and data science. Traditional validity indices
such as Calinski-Harabasz, Silhouette, and Davies-Bouldin-depend on
centroid-based distances and therefore degrade in high-dimensional or
contaminated data. This paper proposes a new robust, nonparametric clustering
validation framework, the High-Dimensional Between-Within Distance Median
(HD-BWDM), which extends the recently introduced BWDM criterion to
high-dimensional spaces. HD-BWDM integrates random projection and principal
component analysis to mitigate the curse of dimensionality and applies trimmed
clustering and medoid-based distances to ensure robustness against outliers. We
derive theoretical results showing consistency and convergence under
Johnson-Lindenstrauss embeddings. Extensive simulations demonstrate that
HD-BWDM remains stable and interpretable under high-dimensional projections and
contamination, providing a robust alternative to traditional centroid-based
validation criteria. The proposed method provides a theoretically grounded,
computationally efficient stopping rule for nonparametric clustering in modern
high-dimensional applications.

</details>


### [210] [A novel Information-Driven Strategy for Optimal Regression Assessment](https://arxiv.org/abs/2510.14222)
*Benjamín Castro,Camilo Ramírez,Sebastián Espinosa,Jorge F. Silva,Marcos E. Orchard,Heraldo Rozas*

Main category: stat.ML

TL;DR: 本文介绍了一种新颖的数据驱动框架“信息教师”，用于评估回归算法，具有评估全局最优性的正式性能保证。


<details>
  <summary>Details</summary>
Motivation: 在机器学习中，回归算法旨在根据数据最小化损失函数。在无法访问真实数据生成机制的情况下，评估学习到的回归器的质量仍然具有挑战性，因为没有数据驱动的评估方法可以确保实现全局最优性。

Method: 信息教师建立在估计输入变量和残差之间的香农互信息（MI）的基础上，适用于各种加性噪声模型。

Result: 通过数值实验，我们证实信息教师能够检测全局最优性，这与针对真实模型的零估计误差条件一致，可作为基本事实评估损失的替代度量，并为传统经验性能指标提供了原则性的替代方案。

Conclusion: 信息教师能够以数据驱动的方式评估回归算法的全局最优性，为回归模型的评估提供了一个有原则的替代方法。

Abstract: In Machine Learning (ML), a regression algorithm aims to minimize a loss
function based on data. An assessment method in this context seeks to quantify
the discrepancy between the optimal response for an input-output system and the
estimate produced by a learned predictive model (the student). Evaluating the
quality of a learned regressor remains challenging without access to the true
data-generating mechanism, as no data-driven assessment method can ensure the
achievability of global optimality. This work introduces the Information
Teacher, a novel data-driven framework for evaluating regression algorithms
with formal performance guarantees to assess global optimality. Our novel
approach builds on estimating the Shannon mutual information (MI) between the
input variables and the residuals and applies to a broad class of additive
noise models. Through numerical experiments, we confirm that the Information
Teacher is capable of detecting global optimality, which is aligned with the
condition of zero estimation error with respect to the -- inaccessible, in
practice -- true model, working as a surrogate measure of the ground truth
assessment loss and offering a principled alternative to conventional empirical
performance metrics.

</details>


### [211] [Personalized federated learning, Row-wise fusion regularization, Multivariate modeling, Sparse estimation](https://arxiv.org/abs/2510.14413)
*Runlin Zhou,Letian Li,Zemin Zheng*

Main category: stat.ML

TL;DR: 本文提出了一种名为SROF的稀疏行融合正则化器，用于解决个性化联邦学习中多变量响应的异构模型问题，并通过RowFed算法实现了通信效率和隐私保护下的变量级别组恢复，理论和实证结果均表明其在降低误差和加强变量级别聚类方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的逐项惩罚忽略了交叉响应依赖性，而矩阵融合又过度耦合了客户端，导致在个性化联邦学习中处理多变量响应时存在局限性。

Method: 本文提出稀疏行融合（SROF）正则化器，该正则化器能对跨客户端的行向量进行聚类并引入行内稀疏性。在此基础上，开发了RowFed，这是一种通信高效的联邦算法，它将SROF嵌入到线性化的ADMM（交替方向乘子法）框架中，并支持隐私保护的部分参与。

Result: 理论上，SROF具有正确的变量级别组恢复能力和渐近正态性，RowFed被证明能收敛到一个平稳解。在随机客户端参与下，迭代间隙的收敛速度随参与概率的增加而提高。在异构状态下的模拟结果表明，RowFed比NonFed、FedAvg和个性化矩阵融合基线在估计和预测误差方面更低，变量级别聚类恢复能力更强。实际数据研究也证实了这些优势，同时保持了可解释性。

Conclusion: 行式融合是解决大规模个性化联邦多变量学习中一个有效且透明的范式，它弥合了逐项和矩阵式公式之间的鸿沟。

Abstract: We study personalized federated learning for multivariate responses where
client models are heterogeneous yet share variable-level structure. Existing
entry-wise penalties ignore cross-response dependence, while matrix-wise fusion
over-couples clients. We propose a Sparse Row-wise Fusion (SROF) regularizer
that clusters row vectors across clients and induces within-row sparsity, and
we develop RowFed, a communication-efficient federated algorithm that embeds
SROF into a linearized ADMM framework with privacy-preserving partial
participation. Theoretically, we establish an oracle property for
SROF-achieving correct variable-level group recovery with asymptotic
normality-and prove convergence of RowFed to a stationary solution. Under
random client participation, the iterate gap contracts at a rate that improves
with participation probability. Empirically, simulations in heterogeneous
regimes show that RowFed consistently lowers estimation and prediction error
and strengthens variable-level cluster recovery over NonFed, FedAvg, and a
personalized matrix-fusion baseline. A real-data study further corroborates
these gains while preserving interpretability. Together, our results position
row-wise fusion as an effective and transparent paradigm for large-scale
personalized federated multivariate learning, bridging the gap between
entry-wise and matrix-wise formulations.

</details>


### [212] [Local Causal Discovery for Statistically Efficient Causal Inference](https://arxiv.org/abs/2510.14582)
*Mátyás Schubert,Tom Claassen,Sara Magliacane*

Main category: stat.ML

TL;DR: 介绍了LOAD方法，该方法结合了局部方法的计算效率和全局方法的统计最优性，以识别因果效应估计的最佳调整集。


<details>
  <summary>Details</summary>
Motivation: 开发一种兼具局部方法的可扩展性和全局方法统计最优性的因果发现方法。

Method: LOAD方法首先识别目标变量之间的因果关系，并使用局部信息测试因果效应是否可识别。如果可识别，它会利用局部因果发现来推断中介变量及其父节点，从而找到最优调整集。否则，它会根据学习到的局部结构返回局部有效的父节点调整集。

Result: 在合成数据和真实数据上的实验表明，与全局方法相比，LOAD在可扩展性方面表现更好，并且比局部方法提供更准确的效应估计。

Conclusion: LOAD是一种有效的因果发现方法，可以高效且准确地识别最优调整集，平衡了计算效率和统计最优性。

Abstract: Causal discovery methods can identify valid adjustment sets for causal effect
estimation for a pair of target variables, even when the underlying causal
graph is unknown. Global causal discovery methods focus on learning the whole
causal graph and therefore enable the recovery of optimal adjustment sets,
i.e., sets with the lowest asymptotic variance, but they quickly become
computationally prohibitive as the number of variables grows. Local causal
discovery methods offer a more scalable alternative by focusing on the local
neighborhood of the target variables, but are restricted to statistically
suboptimal adjustment sets. In this work, we propose Local Optimal Adjustments
Discovery (LOAD), a sound and complete causal discovery approach that combines
the computational efficiency of local methods with the statistical optimality
of global methods. First, LOAD identifies the causal relation between the
targets and tests if the causal effect is identifiable by using only local
information. If it is identifiable, it then finds the optimal adjustment set by
leveraging local causal discovery to infer the mediators and their parents.
Otherwise, it returns the locally valid parent adjustment sets based on the
learned local structure. In our experiments on synthetic and realistic data
LOAD outperforms global methods in scalability, while providing more accurate
effect estimation than local methods.

</details>


### [213] [Fast and Scalable Score-Based Kernel Calibration Tests](https://arxiv.org/abs/2510.14711)
*Pierre Glaser,David Widmann,Fredrik Lindsten,Arthur Gretton*

Main category: stat.ML

TL;DR: KCCSD检验是一种用于评估概率模型校准的非参数、基于核的检验，无需昂贵的期望近似即可控制其I型错误。


<details>
  <summary>Details</summary>
Motivation: 以往的方法在评估概率模型校准时，需要昂贵的期望近似。

Method: 通过使用一组新的核函数（它们可以通过无概率密度样本的方式进行估计）和一个条件拟合优度准则，避免了昂贵的期望近似。

Result: 在各种合成设置上验证了KCCSD检验的性能。

Conclusion: KCCSD检验在评估概率模型校准方面有效且性能良好。

Abstract: We introduce the Kernel Calibration Conditional Stein Discrepancy test (KCCSD
test), a non-parametric, kernel-based test for assessing the calibration of
probabilistic models with well-defined scores. In contrast to previous methods,
our test avoids the need for possibly expensive expectation approximations
while providing control over its type-I error. We achieve these improvements by
using a new family of kernels for score-based probabilities that can be
estimated without probability density samples, and by using a conditional
goodness-of-fit criterion for the KCCSD test's U-statistic. We demonstrate the
properties of our test on various synthetic settings.

</details>


### [214] [A Geometric Approach to Optimal Experimental Design](https://arxiv.org/abs/2510.14848)
*Gavin Kerrigan,Christian A. Naesseth,Tom Rainforth*

Main category: stat.ML

TL;DR: 该文章提出了一种新颖的几何框架，用于优化实验设计，通过引入互信息传输依赖性（MTD）来克服传统方法的局限性，MTD提供了一种几何目标来优化设计。


<details>
  <summary>Details</summary>
Motivation: 传统的优化实验设计（OED）方法依赖于概率密度，导致限制性的不变性，所以需要一种新的方法来解决这些局限性。

Method: 提出了一种基于最优输运理论的统计依赖性度量——互输运依赖性（MTD），它为优化设计提供了一个几何目标。MTD可以通过选择基础空间上的几何结构来针对特定的下游估计问题进行调整。

Result: 该框架能够生成高质量的设计。

Conclusion: MTD作为一种灵活且可替代标准信息论技术的方法，可以根据特定的下游估计问题进行调整。

Abstract: We introduce a novel geometric framework for optimal experimental design
(OED). Traditional OED approaches, such as those based on mutual information,
rely explicitly on probability densities, leading to restrictive invariance
properties. To address these limitations, we propose the mutual transport
dependence (MTD), a measure of statistical dependence grounded in optimal
transport theory which provides a geometric objective for optimizing designs.
Unlike conventional approaches, the MTD can be tailored to specific downstream
estimation problems by choosing appropriate geometries on the underlying
spaces. We demonstrate that our framework produces high-quality designs while
offering a flexible alternative to standard information-theoretic techniques.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [215] [Why Instant-Runoff Voting Is So Resilient to Coalitional Manipulation: Phase Transitions in the Perturbed Culture](https://arxiv.org/abs/2510.14450)
*François Durand*

Main category: cs.GT

TL;DR: 这篇论文研究了即时径流投票（IRV）对抗联合操纵（CM）的能力。


<details>
  <summary>Details</summary>
Motivation: 以往研究表明IRV对联合操纵有很强的抵抗力，但其理论原因尚不清楚。本文旨在填补这一空白。

Method: 作者在扰动文化模型中，分析了三种主要投票规则（多数制、两轮制和IRV）对联合操纵的敏感性。引入了“超级康多塞特赢家”（SCW）的概念。

Result: 研究发现，每种规则都在一个关键的偏好集中度阈值θ_c处发生相变：对于大型选民，当偏好集中度低于θ_c时，联合操纵的概率指数级收敛到1；当高于θ_c时，收敛到0。超级康多塞特赢家的存在是IRV抵抗联合操纵的关键因素。研究证明，对于IRV，θ_c = 0。

Conclusion: IRV对联合操纵具有很强的抵抗力，即使是最小的偏好集中度也能使其抵抗联合操纵，这主要归因于超级康多塞特赢家的存在。

Abstract: Previous studies have shown that Instant-Runoff Voting (IRV) is highly
resistant to coalitional manipulation (CM), though the theoretical reasons for
this remain unclear. To address this gap, we analyze the susceptibility to CM
of three major voting rules-Plurality, Two-Round System, and IRV-within the
Perturbed Culture model. Our findings reveal that each rule undergoes a phase
transition at a critical value theta\_c of the concentration of preferences:
the probability of CM for large electorates converges exponentially fast to 1
below theta\_c and to 0 above theta\_c. We introduce the Super Condorcet Winner
(SCW), showing that its presence is a key factor of IRV's resistance to
coalitional manipulation, both theoretically and empirically. Notably, we use
this notion to prove that for IRV, theta\_c = 0, making it resistant to CM with
even minimal preference concentration.

</details>


### [216] [Co-Investment under Revenue Uncertainty Based on Stochastic Coalitional Game Theory](https://arxiv.org/abs/2510.14555)
*Amal Sakr,Andrea Araldo,Tijani Chahed,Daniel Kofman*

Main category: cs.GT

TL;DR: 本文提出了一种针对移动边缘计算（MEC）部署的联合投资方案，通过随机联盟博弈模型解决了收益不确定性下的成本和收益分享问题，并分析了该方案在稳定性和盈利能力方面的表现。


<details>
  <summary>Details</summary>
Motivation: 由于移动边缘计算（MEC）等新服务的引入需要巨大的投资，单个基础设施提供商（InP）难以独自承担。鉴于服务提供商（SP）也对此类服务的部署感兴趣，因此需要一种联合投资方案来分摊成本和收益，并最大化所有利益相关者的收益。

Method: 本文提出了一种新颖的随机联盟博弈模型，该模型建立在鲁棒博弈论的基础上，以应对未来收益的不确定性。该模型旨在形成一个由所有利益相关者（InP和SP）组成的“大联盟”，以共享成本和收益，并最大化收益。此外，当收益波动具有相关性时，还引入了盈利能力作为联合投资的必要条件。

Result: 数值结果表明，当服务提供商（SP）的收益规模相似且投资期足够长时，即使存在高度不确定性，大联盟稳定概率的下限也很高。然而，在收益高度可变的情况下，稳定性的下限可能非常低，但联合投资仍然有利可图。

Conclusion: 本文提出的联合投资框架以及随机联盟博弈模型，为MEC等新服务的部署提供了有效途径，尤其在收益不确定性下，通过结合稳定性和盈利能力，能够更好地指导利益相关方的合作决策。

Abstract: The introduction of new services, such as Mobile Edge Computing (MEC),
requires a massive investment that cannot be assumed by a single stakeholder,
for instance the Infrastructure Provider (InP). Service Providers (SPs) however
also have an interest in the deployment of such services. We hence propose a
co-investment scheme in which all stakeholders, i.e., the InP and the SPs, form
the so-called grand coalition composed of all the stakeholders with the aim of
sharing costs and revenues and maximizing their payoffs. The challenge comes
from the fact that future revenues are uncertain. We devise in this case a
novel stochastic coalitional game formulation which builds upon robust game
theory and derive a lower bound on the probability of the stability of the
grand coalition, wherein no player can be better off outside of it. In the
presence of some correlated fluctuations of revenues however, stability can be
too conservative. In this case, we make use also of profitability, in which
payoffs of players are non-negative, as a necessary condition for
co-investment. The proposed framework is showcased for MEC deployment, where
computational resources need to be deployed in nodes at the edge of a
telecommunication network. Numerical results show high lower bound on the
probability of stability when the SPs' revenues are of similar magnitude and
the investment period is sufficiently long, even with high levels of
uncertainty. In the case where revenues are highly variable however, the lower
bound on stability can be trivially low whereas co-investment is still
profitable.

</details>


### [217] [Learnable Mixed Nash Equilibria are Collectively Rational](https://arxiv.org/abs/2510.14907)
*Geelon So,Yi-An Ma*

Main category: cs.GT

TL;DR: 本文研究了学习博弈论中非渐进稳定性的动态G。”，其中“个体寻优动态”的均衡概念为“一致稳定性”。


<details>
  <summary>Details</summary>
Motivation: 将博弈学习的研究扩展到表现出非渐近稳定性的动态。

Method: 本文在一致稳定性的概念下，研究了个体寻优动态的均衡。

Result: 在温和的非退化条件下，如果一个混合均衡不是一致稳定的，那么它就不是弱帕累托最优的，这意味着所有参与者都可以通过共同偏离均衡来改进。相反，如果它是局部一致稳定的，那么均衡必须是弱帕累托最优的。

Conclusion: 个体寻优行为在混合纳什均衡附近导致集体理性，“一致稳定性”决定了增量平滑最佳响应动态的最终迭代收敛行为。

Abstract: We extend the study of learning in games to dynamics that exhibit
non-asymptotic stability. We do so through the notion of uniform stability,
which is concerned with equilibria of individually utility-seeking dynamics.
Perhaps surprisingly, it turns out to be closely connected to economic
properties of collective rationality. Under mild non-degeneracy conditions and
up to strategic equivalence, if a mixed equilibrium is not uniformly stable,
then it is not weakly Pareto optimal: there is a way for all players to improve
by jointly deviating from the equilibrium. On the other hand, if it is locally
uniformly stable, then the equilibrium must be weakly Pareto optimal. Moreover,
we show that uniform stability determines the last-iterate convergence behavior
for the family of incremental smoothed best-response dynamics, used to model
individual and corporate behaviors in the markets. Unlike dynamics around
strict equilibria, which can stabilize to socially-inefficient solutions,
individually utility-seeking behaviors near mixed Nash equilibria lead to
collective rationality.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [218] [Benefits and Limitations of Communication in Multi-Agent Reasoning](https://arxiv.org/abs/2510.13903)
*Michael Rizvi-Martel,Satwik Bhattamishra,Neil Rathi,Guillaume Rabusseau,Michael Hahn*

Main category: cs.MA

TL;DR: 本文分析了多智能体系统的表达能力，解决了复杂任务中大型语言模型性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理复杂问题和长上下文时性能会下降，而多智能体范式可以分解任务从而解决这个问题。

Method: 提出了一个理论框架来分析多智能体系统的表达能力，并将其应用于状态跟踪、回忆和 k-跳推理这三个算法家族。

Result: 推导了解决任务所需的智能体数量、智能体间通信的数量和结构以及问题规模和上下文缩放时的可实现加速的界限。

Conclusion: 该分析为设计可扩展的多智能体推理系统提供了指导。

Abstract: Chain-of-thought prompting has popularized step-by-step reasoning in large
language models, yet model performance still degrades as problem complexity and
context length grow. By decomposing difficult tasks with long contexts into
shorter, manageable ones, recent multi-agent paradigms offer a promising
near-term solution to this problem. However, the fundamental capacities of such
systems are poorly understood. In this work, we propose a theoretical framework
to analyze the expressivity of multi-agent systems. We apply our framework to
three algorithmic families: state tracking, recall, and $k$-hop reasoning. We
derive bounds on (i) the number of agents required to solve the task exactly,
(ii) the quantity and structure of inter-agent communication, and (iii) the
achievable speedups as problem size and context scale. Our results identify
regimes where communication is provably beneficial, delineate tradeoffs between
agent count and bandwidth, and expose intrinsic limitations when either
resource is constrained. We complement our theoretical analysis with a set of
experiments on pretrained LLMs using controlled synthetic benchmarks. Empirical
outcomes confirm the tradeoffs between key quantities predicted by our theory.
Collectively, our analysis offers principled guidance for designing scalable
multi-agent reasoning systems.

</details>


### [219] [Static Sandboxes Are Inadequate: Modeling Societal Complexity Requires Open-Ended Co-Evolution in LLM-Based Multi-Agent Simulations](https://arxiv.org/abs/2510.13982)
*Jinkun Chen,Sher Badshah,Xuemin Yu,Sijia Han,Jiechao Gao*

Main category: cs.MA

TL;DR: 这篇论文批判了当前多智能体系统和社交模拟中静态、任务特定的基准，并提出了一个以开放性、持续共同演进和开发有弹性的、社会对齐的AI生态系统为中心的研究路线图。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统和社交模拟受限于静态沙盒，无法捕捉真实世界社会的复杂性。作者认为静态、任务特定的基准不足以应对开放式、不断变化的环境。

Method: 文章评论了将大型语言模型与多智能体动力学相结合的新兴架构，并提出了一种新的分类方法。

Result: 作者指出，需要平衡稳定性与多样性、评估意外行为以及扩展到更复杂的系统。

Conclusion: 作者呼吁社区超越静态范式，共同塑造下一代自适应、具有社会意识的多智能体模拟。

Abstract: What if artificial agents could not just communicate, but also evolve, adapt,
and reshape their worlds in ways we cannot fully predict? With llm now powering
multi-agent systems and social simulations, we are witnessing new possibilities
for modeling open-ended, ever-changing environments. Yet, most current
simulations remain constrained within static sandboxes, characterized by
predefined tasks, limited dynamics, and rigid evaluation criteria. These
limitations prevent them from capturing the complexity of real-world societies.
In this paper, we argue that static, task-specific benchmarks are fundamentally
inadequate and must be rethought. We critically review emerging architectures
that blend llm with multi-agent dynamics, highlight key hurdles such as
balancing stability and diversity, evaluating unexpected behaviors, and scaling
to greater complexity, and introduce a fresh taxonomy for this rapidly evolving
field. Finally, we present a research roadmap centered on open-endedness,
continuous co-evolution, and the development of resilient, socially aligned AI
ecosystems. \textbf{We call on the community to move beyond static paradigms
and help shape the next generation of adaptive, socially-aware multi-agent
simulations.}

</details>


### [220] [Stop Reducing Responsibility in LLM-Powered Multi-Agent Systems to Local Alignment](https://arxiv.org/abs/2510.14008)
*Jinwei Hu,Yi Dong,Shuang Ao,Zhuoyun Li,Boxuan Wang,Lokesh Singh,Guangliang Cheng,Sarvapali D. Ramchurn,Xiaowei Huang*

Main category: cs.MA

TL;DR: 本文探讨了大型语言模型驱动的多智能体系统 (LLM-MAS) 中的责任问题，并提出了一种从局部到全局的范式转变，以确保系统的负责任行为。


<details>
  <summary>Details</summary>
Motivation: LLM-MAS 在分布式推理、协作和任务泛化方面具有巨大潜力，但同时也带来了未 M能保证的一致性、级联不确定性和对抗性漏洞等额外风险。为了应对这些风险，确保系统负责任的行为至关重要。

Method: 本文提出了一种将责任视为贯穿整个生命周期的属性，包括一致性、不确定性和安全性。该方法强调将主观的人本价值观与客观的可验证性进行互补整合。此外，文章还提出了一个结合跨学科设计和人机协作监督的双视角治理框架，以在 LLM-MAS 的整个生命周期中追踪和确保责任。

Result: 通过将 LLM-MAS 视为统一的、动态的社会技术系统，并支持责任的各个维度，可以实现符合伦理、可验证的连贯和有弹性的行为，从而实现持续的、系统范围的一致性。

Conclusion: 为了确保 LLM-MAS 的负责任行为，需要从局部、表层的智能体级对齐转变为全局、系统的共识。责任应被视为一个生命周期范围的属性，并通过双视角治理框架和原则性机制来支持，以实现系统范围的一致性。

Abstract: LLM-powered Multi-Agent Systems (LLM-MAS) unlock new potentials in
distributed reasoning, collaboration, and task generalization but also
introduce additional risks due to unguaranteed agreement, cascading
uncertainty, and adversarial vulnerabilities. We argue that ensuring
responsible behavior in such systems requires a paradigm shift: from local,
superficial agent-level alignment to global, systemic agreement. We
conceptualize responsibility not as a static constraint but as a lifecycle-wide
property encompassing agreement, uncertainty, and security, each requiring the
complementary integration of subjective human-centered values and objective
verifiability. Furthermore, a dual-perspective governance framework that
combines interdisciplinary design with human-AI collaborative oversight is
essential for tracing and ensuring responsibility throughout the lifecycle of
LLM-MAS. Our position views LLM-MAS not as loose collections of agents, but as
unified, dynamic socio-technical systems that demand principled mechanisms to
support each dimension of responsibility and enable ethically aligned,
verifiably coherent, and resilient behavior for sustained, system-wide
agreement.

</details>
