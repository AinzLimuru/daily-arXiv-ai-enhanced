<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]
- [cs.LG](#cs.LG) [Total: 10]
- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python](https://arxiv.org/abs/2512.10865)
*Lilin Qiu*

Main category: cs.CL

TL;DR: 本文分析了《霍比特人》对话的情感基调。


<details>
  <summary>Details</summary>
Motivation: 利用计算文本分析方法，分析J. R. R. Tolkien的《霍比特人》中对话的情感基调，旨在揭示文本中微妙的情感结构。

Method: 使用正则表达式提取对话，进行预处理，并利用NRC-VAD词典对情感维度进行评分。

Result: 对话总体保持积极（高愉悦度）和S平静（低激活度）的基调，随着故事发展，掌控感（主导度）逐渐增强。情绪轨迹图和词云展示了紧张与舒适之间的语言循环。该模式反映了小说情绪上的有节奏变化：通过幽默、友情和宽慰来平衡危险和兴奋，以揭示故事讲述上的稳定节奏和情感调节。

Conclusion: 计算工具与文学诠释相结合，数字方法可以揭示文学作品中微妙的情感结构，揭示《霍比特人》中塑造故事讲述的稳定节奏和情感调节。

Abstract: This study analyzes the emotional tone of dialogue in J. R. R. Tolkien's The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel's emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations -- including emotional trajectory graphs and word clouds -- highlight how Tolkien's language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.

</details>


### [2] [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)
*Hauke Licht*

Main category: cs.CL

TL;DR: 本文评估了多模态大语言模型（mLLM）在视频情感唤醒分析中的表现，发现在理想条件下其可靠性高且无人口统计学偏见，但在真实世界议会辩论视频中表现不佳，强调了对生成式AI方法进行持续评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 研究越来越多地利用音视频材料分析情感表达，多模态生成式AI的出现有望带来巨大进步，但目前缺乏关于多模态AI在情感分析中有效性的证据。

Method: 通过在两个互补的人工标注视频数据集上评估当前多模态大语言模型（mLLM）在视频情感唤醒分析中的表现。

Result: 在理想条件下，mLLM的情感唤醒评分高度可靠，且几乎没有人**偏见；但在真实世界议会辩论的录音中，mLLM的唤醒评分无法达到预期，可能对后续的统计推断产生负面影响。

Conclusion: 本研究强调了在政治分析中持续、彻底评估新兴生成式AI方法的必要性，并为此贡献了一个合适的、可复制的框架。

Abstract: Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [3] [Decoupled Q-Chunking](https://arxiv.org/abs/2512.10926)
*Qiyang Li,Seohong Park,Sergey Levine*

Main category: cs.LG

TL;DR: 这篇文章介绍了一种名为DQC的新算法，它通过解耦批评器的块长度和策略的块长度，解决了在利用分块评论器进行强化学习时，策略提取困难和分块策略次优的问题。


<details>
  <summary>Details</summary>
Motivation: 时序差分（TD）学习方法通过从自身未来的价值预测中进行自举来高效地学习状态和行动价值，但这种自举机制容易产生自举偏差，即价值目标中的误差会在多个步骤中累积，导致价值估计出现偏差。近期工作提出了使用分块评论器，它估计短行动序列（“块”）而非单个行动的价值，从而加速了价值备份。然而，从分块评论器中提取策略（policy）具有挑战性：策略必须开环地输出整个行动块，这对于需要策略反应性的环境来说可能是次优的，并且在块长度增加时，建模也变得尤为困难。

Method: 我们提出的算法通过优化针对部分行动块的蒸馏评论器来解决上述问题。这个蒸馏评论器是通过从原始的分块评论器中乐观地反向传播，以近似当部分行动块扩展到完整行动块时可以达到的最大价值来构建的。这种设计保留了多步价值传播的好处，同时避免了开环的次优性以及学习长行动块的分块策略的困难。

Result: DQC算法在具有挑战性的、长期的离线目标条件任务上进行了评估，结果表明它显著优于现有方法。

Conclusion: 本文提出了一种新颖的算法DQC，它通过解耦评论器和策略的块长度，并优化针对蒸馏评论器的部分行动块策略，成功解决了现有分块评论器方法的局限性。该算法在保持多步价值传播优势的同时，避免了开环次优性和学习长行动块策略的难度，并在实验中取得了 SOTA 效果。

Abstract: Temporal-difference (TD) methods learn state and action values efficiently by bootstrapping from their own future value predictions, but such a self-bootstrapping mechanism is prone to bootstrapping bias, where the errors in the value targets accumulate across steps and result in biased value estimates. Recent work has proposed to use chunked critics, which estimate the value of short action sequences ("chunks") rather than individual actions, speeding up value backup. However, extracting policies from chunked critics is challenging: policies must output the entire action chunk open-loop, which can be sub-optimal for environments that require policy reactivity and also challenging to model especially when the chunk length grows. Our key insight is to decouple the chunk length of the critic from that of the policy, allowing the policy to operate over shorter action chunks. We propose a novel algorithm that achieves this by optimizing the policy against a distilled critic for partial action chunks, constructed by optimistically backing up from the original chunked critic to approximate the maximum value achievable when a partial action chunk is extended to a complete one. This design retains the benefits of multi-step value propagation while sidestepping both the open-loop sub-optimality and the difficulty of learning action chunking policies for long action chunks. We evaluate our method on challenging, long-horizon offline goal-conditioned tasks and show that it reliably outperforms prior methods. Code: github.com/ColinQiyangLi/dqc.

</details>


### [4] [Asynchronous Reasoning: Training-Free Interactive Thinking LLMs](https://arxiv.org/abs/2512.10931)
*George Yakushev,Nataliia Babina,Masoud Vahid Dastgerdi,Vyacheslav Zhdanovskiy,Alina Shutova,Denis Kuznedelev*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种允许大型语言模型（LLMs）同时进行思考、听取输入和生成输出的方法，从而提高了LLMs在实时交互场景中的响应速度和效率。


<details>
  <summary>Details</summary>
Motivation: 许多先进的LLMs在给出答案之前会进行思考，这虽然能提高其能力和安全性，但却降低了交互性，因为模型必须在响应之前完成思考。这与实时应用（如语音助手）的需求不符。人类可以异步地思考、倾听和行动，这启发了作者改进LLMs的交互方式。

Method: 本文提出了一种无需额外训练的方法，通过利用旋转嵌入的特性，使原本为顺序交互设计的LLMs能够同时进行思考、听取和生成输出。

Result: 该方法在数学、常识和安全推理任务上进行了评估，结果表明它能够实时生成准确的、经过思考增强的答案，将首次非思考token的生成时间从几分钟缩短到5秒以内，并将总的实时延迟降低了6-11倍。

Conclusion: 这项工作成功地使LLMs能够像人类一样异步地思考、倾听和行动，显著提升了LLMs在需要实时交互的应用场景中的性能和用户体验。

Abstract: Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to <= 5s. and the overall real-time delays by 6-11x.

</details>


### [5] [Stronger Normalization-Free Transformers](https://arxiv.org/abs/2512.10938)
*Mingzhi Chen,Taiming Lu,Jiachen Zhu,Mingjie Sun,Zhuang Liu*

Main category: cs.LG

TL;DR: 本文介绍了一种名为Derf的新型激活函数，它在不使用归一化层的情况下，在多种深度学习任务中优于现有的归一化方法和动态Tanh激活函数。


<details>
  <summary>Details</summary>
Motivation: 探索超越动态Tanh (DyT) 的激活函数设计，旨在寻找更有效的点态函数来替代深度学习架构中的归一化层。

Method: 首先研究了点态函数的内在特性如何影响训练和性能。在此基础上，进行大规模搜索以寻找更有效的函数设计，并最终引入了 \(\mathrm{Derf}(x) = \mathrm{erf}(\alpha x + s)\) 函数。

Result: Derf 在图像识别、图像生成、语音表示和 DNA 序列建模等广泛领域中，均优于 LayerNorm、RMSNorm 和 DyT。研究发现 Derf 的性能提升主要源于其改进的泛化能力。

Conclusion: Derf 是一种简单且性能更强的激活函数，使其成为无归一化Transformer架构的实用选择。

Abstract: Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\mathrm{Derf}(x) = \mathrm{erf}(αx + s)$, where $\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.

</details>


### [6] [UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting](https://arxiv.org/abs/2512.10866)
*Ruslan Gokhman*

Main category: cs.LG

TL;DR: 本文研究了使用线性和Transformer家族模型进行长视角、仅外生变量的室内温度预测。


<details>
  <summary>Details</summary>
Motivation: 在长视角、仅外生变量的室内温度预测这一挑战性单变量设置中，探究线性和Transformer家族模型的性能。

Method: 本文在标准化的训练、验证和测试集上，评估了Linear、NLinear、DLinear、Transformer、Informer和Autoformer模型。

Result: 线性基线模型（Linear、NLinear、DLinear）的性能始终优于更复杂的Transformer家族架构，其中DLinear在所有划分中取得了最佳的整体准确性。

Conclusion: 精心设计的线性模型在具有挑战性的仅外生变量设置中，仍然是时间序列预测的强大基线。

Abstract: We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under standardized train, validation, and test splits. Results show that linear baselines (Linear, NLinear, DLinear) consistently outperform more complex Transformer-family architectures, with DLinear achieving the best overall accuracy across all splits. These findings highlight that carefully designed linear models remain strong baselines for time series forecasting in challenging exogenous-only settings.

</details>


### [7] [Guided Transfer Learning for Discrete Diffusion Models](https://arxiv.org/abs/2512.10877)
*Julian Kleutgens,Claudio Battiloro,Lingkai Kong,Benjamin Grewe,Francesca Dominici,Mauricio Tec*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为引导迁移学习（GTL）的新方法，用于在不修改预训练去噪器的情况下，将离散扩散模型适应到新的目标分布。它还提出了一种高效的采样器，以解决GTL在大型词汇和长序列上的计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 离散扩散模型在语言和其他离散领域表现出色，但其性能依赖于大型训练数据集，这在适应新领域时成本高昂或存在风险。现有的迁移学习方法需要对大型扩散模型进行微调，这在计算上是昂贵的且不切实际的。

Method: 本文提出了一种基于比率的迁移学习方法，名为引导迁移学习（GTL），用于离散扩散模型。它可以在不修改预训练去噪器的情况下，实现从目标分布中采样。GTL适用于离散时间扩散和连续时间基于分数的离散扩散。为解决在大型词汇和长序列上的计算效率问题，本文还提出了一种高效的引导采样器，该采样器将评估集中在规划器选择的位置和最佳候选词元上。

Result: GTL在序列数据（包括合成马尔可夫链和语言建模）上进行了评估。结果表明，该方法能够有效地将预训练的离散扩散模型应用于新领域。高效的采样器使得引导语言建模在大词汇和长序列上变得实用。

Conclusion: 引导迁移学习（GTL）为离散扩散模型的迁移学习提供了一种有效且统一的解决方案，避免了昂贵的模型微调。通过引入高效的采样器，该方法在处理大型词汇和长序列时也具有实用性，为语言建模等应用提供了新的途径。

Abstract: Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.

</details>


### [8] [Classifier Reconstruction Through Counterfactual-Aware Wasserstein Prototypes](https://arxiv.org/abs/2512.10878)
*Xuan Zhao,Zhuo Cao,Arya Bangun,Hanno Scharr,Ira Assent*

Main category: cs.LG

TL;DR: 该论文提出了一种利用反事实解释来改进模型重构的方法，通过将原始数据样本与反事实相结合，并使用 Wasserstein barycenter 近似类别原型，从而在有限标注数据下提高替代模型的保真度并减轻决策边界偏移问题。


<details>
  <summary>Details</summary>
Motivation: 在有限标注数据的情况下，利用反事实解释提升模型重构效果，解决传统方法中反事实作为普通训练实例时导致的决策边界偏移问题。

Method: 该方法将原始数据样本与反事实解释相结合，使用 Wasserstein barycenter 近似类别原型，旨在保留每个类别的潜在分布结构，从而构建更准确的替代模型。

Result: 在多个数据集上的实验结果表明，该方法显著提高了替代模型与目标模型之间的保真度。

Conclusion: 通过结合原始数据和反事实解释，并利用 Wasserstein barycenter 近似类别原型，可以有效地提高模型重构的质量，尤其是在数据受限的环境中。

Abstract: Counterfactual explanations provide actionable insights by identifying minimal input changes required to achieve a desired model prediction. Beyond their interpretability benefits, counterfactuals can also be leveraged for model reconstruction, where a surrogate model is trained to replicate the behavior of a target model. In this work, we demonstrate that model reconstruction can be significantly improved by recognizing that counterfactuals, which typically lie close to the decision boundary, can serve as informative though less representative samples for both classes. This is particularly beneficial in settings with limited access to labeled data. We propose a method that integrates original data samples with counterfactuals to approximate class prototypes using the Wasserstein barycenter, thereby preserving the underlying distributional structure of each class. This approach enhances the quality of the surrogate model and mitigates the issue of decision boundary shift, which commonly arises when counterfactuals are naively treated as ordinary training instances. Empirical results across multiple datasets show that our method improves fidelity between the surrogate and target models, validating its effectiveness.

</details>


### [9] [SparseSwaps: Tractable LLM Pruning Mask Refinement at Scale](https://arxiv.org/abs/2512.10922)
*Max Zimmer,Christophe Roux,Moritz Wagner,Deborah Hendrych,Sebastian Pokutta*

Main category: cs.LG

TL;DR: 这篇论文提出了一种针对大型语言模型（LLMs）的剪枝方法，通过解耦每行权重并利用Gram矩阵高效计算最优1-swaps，显著降低了剪枝误差并提升了LLMs的性能。


<details>
  <summary>Details</summary>
Motivation: 在大规模语言模型（LLMs）中，剪枝可以显著减少资源需求，但传统的剪枝方法在Transformer架构上表现不佳，且完全重新训练以恢复性能代价高昂。现有的最优剪枝掩码选择方法由于其组合性质和巨大的搜索空间在计算上是不可行的，因此需要更高效的近似或启发式方法。

Method: 本文提出了一种可行的单交换（1-swap）算法来解决层级掩码选择问题。通过强制每行的稀疏度相同，从而解耦行。这使得可以利用校准数据的Gram矩阵高效计算最优1-swaps（交换一个保留权重和一个剪枝权重）。该算法从任意剪枝掩码开始，可在LLM规模的GPU上高效运行，并且基本没有超参数。

Result: 与Wanda（Sun et al., 2023）相比，该方法将每层剪枝误差降低了高达60%。在最先进的GPT架构上，它持续改进了困惑度和零样本准确性。

Conclusion: 本文提出了一种高效且无需超参数的1-swap剪枝算法，解决了LLM剪枝中层级掩码选择的计算挑战。实验证明该方法在降低剪枝误差和提升LLM性能方面取得了显著效果。

Abstract: The resource requirements of Neural Networks can be significantly reduced through pruning -- the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.

</details>


### [10] [Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation](https://arxiv.org/abs/2512.10925)
*Zamirddine Mari,Mohamad Motasem Nawaf,Pierre Drap*

Main category: cs.LG

TL;DR: 本文提出了一种基于深度强化学习（PPO算法）的水下机器人自主导航方法，通过结合目标导航信息、虚拟占据网格和射线投射，使其在复杂水下环境中表现出色，并在仿真和真实环境中验证了其优越性和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 在水下环境中，由于缺乏GPS、能见度差和存在水下障碍物，自主导航仍然是一个重大挑战。

Method: 本文提出了一种基于近端策略优化（PPO）算法的深度强化学习方法，其观测空间结合了面向目标的导航信息、虚拟占用网格和沿操作区域边界的射线投射。

Result: 结果表明，PPO策略在高度混乱的环境中始终优于DWA，尤其是在更好的局部适应性和减少碰撞方面。

Conclusion: 实验证明了所学行为从仿真到现实世界的可迁移性，证实了深度强化学习在水下机器人自主导航中的相关性。

Abstract: Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.

</details>


### [11] [Hierarchical Dataset Selection for High-Quality Data Sharing](https://arxiv.org/abs/2512.10952)
*Xiaona Zhou,Yingyan Zeng,Ran Jin,Ismini Lourentzou*

Main category: cs.LG

TL;DR: 研究了异构数据池中的数据集选择问题，提出DaSH方法，通过对数据集和组级别的效用建模，在有限观测下实现高效泛化，并在两个公共基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在许多现实场景中，数据被组织成离散的数据集，这些数据集在相关性、质量和效用方面存在差异。选择哪些存储库或机构来搜索有用的数据集，以及选择哪些数据集来纳入模型训练是关键决策，然而大多数现有方法选择单个样本，并将所有数据视为同等相关，忽略了数据集及其来源之间的差异。

Method: 本文将数据集选择任务形式化：从大型异构数据池中选择整个数据集，以在资源约束下提高下游性能。我们提出了通过层次结构进行数据集选择（DaSH）方法，该方法在数据集和组（例如，集合、机构）级别上对效用进行建模，从而S能够从有限的观测中实现高效泛化。

Result: 在两个公共基准测试（Digit-Five和DomainNet）中，DaSH在准确性方面优于最先进的数据选择基线高达26.2％，同时需要的探索步骤显著减少。消融实验表明，DaSH对低资源设置和缺乏相关数据集的情况具有鲁棒性，使其适用于实际多源学习工作流中可扩展和自适应的数据集选择。

Conclusion: DaSH方法通过对数据集和组级别的效用建模，解决了从异构数据池中选择数据集的关键问题。该方法在实验中表现出色，显著提高了模型的准确性，并具有较强的鲁棒性和可扩展性，使其在多源学习场景中具有广泛的应用前景。

Abstract: The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.

</details>


### [12] [Bidirectional Normalizing Flow: From Data to Noise and Back](https://arxiv.org/abs/2512.10953)
*Yiyang Lu,Qiao Sun,Xianbang Wang,Zhicheng Jiang,Hanhong Zhao,Kaiming He*

Main category: cs.LG

TL;DR: BiFlow是一种无需精确解析逆变换的双向归一化流框架，通过学习一个近似的逆模型，在ImageNet上实现了更好的生成质量和更快的采样速度。


<details>
  <summary>Details</summary>
Motivation: 现有的Normalizing Flows（NFs）方法，特别是TARFlow及其变体，受到因果解码的瓶颈限制，需要显式可逆的变换，这限制了模型架构和损失函数的灵活性。

Method: 本文提出了一种双向归一化流（BiFlow）框架，它不再需要精确的解析逆变换。BiFlow通过学习一个逆模型来近似底层的噪声到数据的逆映射。

Result: 在ImageNet上的实验表明，与因果解码的对应方法相比，BiFlow在提高生成质量的同时，将采样速度提升了两个数量级。

Conclusion: BiFlow在基于NF的方法中取得了最先进的结果，并在单评估（“1-NFE”）方法中表现出竞争力，有望进一步推动NF范式的发展。

Abstract: Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation ("1-NFE") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [13] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型（LLM）如何改进大型用户设施的提案选择过程，提供了一种可扩展、一致且经济高效的替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统的提案评审方法存在评审人员偏倚和不一致性，并且在比较大量提案时工作量巨大，因此需要一种更有效、一致的提案选择方法。

Method: 利用LLM，通过对散裂中子源（SNS）三个束线的提案和出版记录进行分析，评估LLM在提案排名和识别高出版潜力提案方面的表现。

Result: LLM排名与人类排名显示出强相关性（Spearman $ρ\simeq 0.2-0.8$），并且在识别高出版潜力提案方面的表现不逊于人类评审员，成本也大幅降低。此外，LLM还能进行提案相似性评估等高级分析。

Conclusion: LLM能够显著改进大型用户设施的提案选择过程，提供更高效、一致且经济的解决方案，并能进行人类难以完成的高级分析。

Abstract: We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [14] [On Decision-Making Agents and Higher-Order Causal Processes](https://arxiv.org/abs/2512.10937)
*Matt Wilson*

Main category: cs.AI

TL;DR: 本文探讨了部分可观测马尔可夫决策过程（POMDPs）中的决策智能体与高阶量子操作的经典极限——单输入过程函数之间的精确对应关系，并将其扩展到多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于为POMDPs中的决策智能体提供一种新的、基于过程函数的视角，并揭示其与物理学中量子操作的深层联系，从而为理解和设计智能系统提供新的理论框架。此外，研究还旨在将这一理论扩展到多智能体系统，以应对更复杂的决策环境。

Method: 作者通过建立POMDPs中的智能体策略和记忆更新与单输入过程函数 w 之间的精确对应关系来实现。智能体的策略和记忆更新结合成一个过程函数 w，并通过连接积与POMDP环境交互。作者还提出了双重解释：在物理学视角下，过程函数是环境，局部操作（智能体干预）插入其中；在AI视角下，过程函数编码智能体，插入的函数代表环境。进一步，通过将独立于观测的分散式POMDPs识别为多输入过程函数的自然领域，将此观点推广到多智能体系统。

Result: 研究结果建立了POMDPs中的决策智能体与单输入过程函数的精确对应关系，并提出了二者的双重解释。在物理学视角下，过程函数w充当环境，AI视角下，它编码了智能体。这项工作还把这个观点推向了多智能体系统。

Conclusion: 本文成功地在POMDPs中的决策智能体与过程函数之间建立了精确的理论对应，并为多智能体系统提供了扩展。这为理解和设计复杂的决策系统提供了一个统一的框架，并为未来在人工智能和量子信息交叉领域的研究开辟了新的道路。

Abstract: We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent's policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.

</details>
