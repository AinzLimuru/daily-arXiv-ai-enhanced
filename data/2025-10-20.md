<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 42]
- [cs.IT](#cs.IT) [Total: 4]
- [stat.ML](#stat.ML) [Total: 15]
- [cs.GT](#cs.GT) [Total: 7]
- [cs.LG](#cs.LG) [Total: 60]
- [cs.AI](#cs.AI) [Total: 19]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 该论文提出了三个新的多标签毒性检测基准（Q-A-MLL、R-A-MLL 和 H-X-MLL），并提供了一种基于伪标签的毒性检测方法，可以显著超越现有基线，从而实现对LLM生成内容中多标签毒性的更准确和可靠的评估。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言处理任务中取得了显著成果，但其生成有害内容的潜力引发了严重的安全问题。当前的毒性检测器主要依赖于单标签基准，无法充分捕捉现实世界中 HFLP（有害、虚假、冒犯性、偏见）提示固有的模糊性和多维性。这导致评估存在偏差，包括遗漏的 HFLP 检测和误报，从而损害了现有检测器的可靠性。此外，收集跨细粒度毒性类别的全面多标签标注成本过高，进一步阻碍了有效的评估和开发。

Method: 本文引入了三个新颖的多标签毒性检测基准：Q-A-MLL、R-A-MLL 和 H-X-MLL，它们源自公共毒性数据集，并根据详细的 15 个类别分类法进行标注。本文进一步提供了理论证明，证明在发布的数据集上，使用伪标签进行训练比直接从单标签监督中学习能产生更好的性能。此外，本文开发了一种基于伪标签的毒性检测方法。

Result: 广泛的实验结果表明，该方法显著超越了先进的基线，包括 GPT-4o 和 DeepSeek。

Conclusion: 本文的检测方法和新的数据集能够实现对LLM生成内容中多标签毒性的更准确和可靠的评估。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [2] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 本文评估了通用AI模型在有习语和无习语文章中的评分表现。研究发现，Gemini在与人类评分者的一致性方面表现最佳，尤其是在处理习语方面。


<details>
  <summary>Details</summary>
Motivation: 研究现有通用AI模型在自动化学生论文评估方面的潜在局限性，特别是在处理习语时的表现。

Method: 从语料库中选取了348篇学生文章，创建了两组等量的文章列表：一组每篇文章包含多个习语，另一组不包含习语。使用与人类评分者相同的评分标准，要求ChatGPT、Gemini和Deepseek这三个通用AI模型对两组文章分别进行三次评分。

Result: 所有模型都表现出出色的一致性，但Gemini在与人类评分者的评分一致性方面优于其他竞争者。AI评估中没有发现对任何人口群体的偏见。对于包含多个习语的文章，Gemini与人类评分者的模式最相似。

Conclusion: Gemini在处理比喻性语言方面表现出最佳能力，并有望在未来独立承担论文评分任务，因此是混合评估方法的最佳候选者。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [3] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 该论文提出了一个利用大型语言模型（LLMs）自动生成和标注合成辩论数据的新框架，该框架基于一个四部分的修辞类型学，并使用此数据集微调了基于transformer的分类器。该模型在多个外部语料库上取得了高性能和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的修辞策略分析受限于人工标注的成本高、不一致、难以规模化以及数据集主题和策略的局限性，这给鲁棒模型开发带来了挑战。

Method: 提出一个新颖的框架，利用大型语言模型（LLMs）根据四种修辞类型（因果、经验、情感、道德）自动生成和标注合成辩论数据。然后，使用此LLM标注数据集微调基于transformer的分类器。

Result: 模型在人类标注数据和多个外部语料库上实现了高性能和强大的泛化能力。通过结合修辞策略标签，提高了说服力预测的能力。分析了1960-2020年美国总统辩论中修辞策略的时间和党派变化，揭示了情感论证在美国总统辩论中使用增加的趋势。

Conclusion: 该研究成功地利用LLMs解决了修辞策略分析中人工标注的局限性，并通过自动化的方法提高了分析效率和模型泛化能力，为理解政治话语等领域的说服性沟通提供了新视角。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [4] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: 该论文指出，多语言大模型知识评估基准MLAMA因模板翻译问题导致语法错误和措辞不当，影响结果解读。作者通过机器翻译和LLM纠正，显著提高了知识检索分数，并呼吁社区关注多语言数据集的语法正确性。


<details>
  <summary>Details</summary>
Motivation: MLAMA等多语言事实知识评估基准在进行模板翻译时，未充分考虑插入句中的命名实体的语法和语义信息，导致最终提示存在大量不符合语法或措辞错误的情况，这使得结果解读复杂化，尤其是对于形态丰富的语言。

Method: 作者从MLAMA数据集中抽取了4种斯拉夫语言样本，并比较了初始（模板化）MLAMA数据集与通过Google Translate和ChatGPT进行句子级翻译后的知识检索分数。此外，还对来自不同语系的另外5种语言进行了额外分析。

Result: 知识检索分数显著提高。作者还提供了对分数提高背后可能原因的定性分析。在其他5种语言中也观察到了类似的模式。

Conclusion: 为了获得更高且更具解释性的结果，鼓励社区控制高度多语言数据集的语法正确性，而使用神经机器翻译或大型语言模型系统进行整句翻译能很好地近似解决此问题。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [5] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个端到端框架，用于从无标签语料库中自动生成可解释的主题分类法，该方法结合了无监督聚类和基于提示的标签，利用大型语言模型迭代构建分类法，而无需种子集或领域专业知识。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台在塑造政治话语方面发挥着关键作用，但分析其庞大且快速演变的内容仍然是一个重大挑战。

Method: 该框架结合了无监督聚类和基于提示的标签，利用大型语言模型（LLM）迭代构建分类法，无需种子集或领域专业知识。

Result: 投票和移民广告在总支出和展示次数中占主导地位，而堕胎和选举诚信广告则获得了 disproportionate 的覆盖面。资金模式同样两极分化：经济诉求主要由保守派 PAC 推动，堕胎信息在支持和反对堕胎权利的联盟之间分裂，犯罪与司法运动在地方委员会中分散。这些诉求的框架也存在差异——堕胎广告强调自由/压迫言论，而经济信息则融合了关怀/伤害、公平/欺骗和自由/压迫叙事。主题显著性进一步揭示了道德基础与问题之间的强相关性。人口统计学目标也随之出现。

Conclusion: 这项工作支持对社交媒体上的政治信息进行可扩展、可解释的分析，使研究人员、政策制定者和公众能够更好地理解新兴叙事、两极分化动态以及数字政治传播的道德基础。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [6] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文介绍了FarsiMCQGen，一个用于生成波斯语多项选择题（MCQs）的创新方法。该方法结合了候选生成、过滤和排序技术，并利用了Transformers、知识图谱和基于规则的方法来创建高质量的干扰项。同时，本文还推出了一个包含10,289个问题的波斯语MCQ数据集。


<details>
  <summary>Details</summary>
Motivation: 在教育测试中，多项选择题（MCQs）被广泛使用，因为它们能有效地评估学习者的知识。然而，生成高质量的MCQs，尤其是在波斯语等低资源语言中，仍然是一个巨大的挑战。

Method: FarsiMCQGen方法结合了候选生成、过滤和排序技术。通过利用Transformers和知识图谱等先进方法，并结合基于规则的方法，构建了一个能生成类似真实MCQs答案选项的模型。该模型致力于创建可信的干扰项，以增加测试难度。

Result: 本研究介绍了FarsiMCQGen模型，该模型能够有效生成波斯语MCQs。此外，本研究还发布了一个新的波斯语MCQ数据集，其中包含10,289个问题。该数据集已通过不同的最先进大型语言模型（LLMs）进行评估，结果表明所生成数据集的质量很高。

Conclusion: 本文提出的FarsiMCQGen模型及其生成的数据集是波斯语MCQ生成领域的一个重要进展。FarsiMCQGen模型能够有效生成高质量的波斯语MCQs。所生成的大规模数据集为未来的MCQ研究提供了宝贵的资源，具有激发该领域进一步研究的潜力。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [7] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: 本文介绍了一种名为 \textsc{Structure-R1} 的新型检索增强生成框架，它将检索到的内容转化为结构化表示，以优化大型语言模型的推理能力。通过强化学习和自奖励结构验证机制， \textsc{Structure-R1} 能够生成适应多步推理的动态结构化数据，并在多个知识密集型基准测试中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理能力上取得了显著进展，但受限于对显式和结构化领域知识的有限访问。传统的检索增强生成（RAG）系统通常处理非结构化和零碎的文本，导致信息密度低和推理次优。

Method: 本文提出了 \textsc{Structure-R1} 框架，该框架通过强化学习学习内容表示策略，动态生成和调整结构化格式，以满足多步推理的需求。该方法采用生成范式，能够生成针对特定查询的任务特定结构。为确保表示的质量和可靠性，引入了自奖励结构验证机制，以检查生成的结构是否正确和自包含。

Result: 在七个知识密集型基准测试中，\textsc{Structure-R1} 始终表现出 SOTA 性能，其 7B 大小的主干模型达到了与更大模型相当的性能。

Conclusion: \textsc{Structure-R1} 通过将检索到的内容转化为结构化表示，显著提升了大型语言模型的推理能力，并通过提高信息密度和上下文清晰度来增强推理。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [8] [Extending Audio Context for Long-Form Understanding in Large Audio-Language Models](https://arxiv.org/abs/2510.15231)
*Yuatyong Chaichana,Pittawat Taveekitworachai,Warit Sirichotedumrong,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种名为“部分YaRN”的上下文扩展方法和一种名为“虚拟长时音频训练（VLAT）”的训练策略，旨在解决大型音频语言模型（LALMs）在长音频理解方面受限于短音频上下文窗口的问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型音频语言模型（LALMs）在长音频理解方面受限于短音频上下文窗口的限制。

Method: 1. 部分YaRN：基于RoPE的上下文扩展方法，无需训练，仅修改音频token的位置，保持文本位置不变以保留基础LLM的文本能力。2. 虚拟长时音频训练（VLAT）：一种训练策略，将部分YaRN扩展为训练时的位置增强，通过模拟不同的音频长度进行训练，使其能够泛化到比训练时更长的输入，并提高长上下文音频理解的鲁棒性。

Result: 在SALMONN和Qwen2-Audio上的实验表明，部分YaRN在各种设置下都优于原始模型，而VLAT训练策略提供了显著的改进，在未见过长度的长音频上实现了强大的性能。

Conclusion: 部分YaRN和VLAT训练策略有效地解决了LALMs长音频理解的上下文限制问题，展现了强大的泛化能力和鲁棒性。

Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.

</details>


### [9] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 本文探讨了自回归语言模型（ARMs）和离散扩散语言模型（DDLMs）的混合架构。研究发现，将DDLM到ARM的通信从文本空间转移到潜在空间可以显著提高准确性，同时大幅节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 当前的自回归语言模型（ARMs）虽然准确性高，但需要较长的token序列，导致成本较高。离散扩散语言模型（DDLMs）能够在固定步数内实现并行和灵活的生成，并在复杂推理和长期规划任务中表现出色。本文旨在探索将DDLMs与ARMs结合的混合架构，评估它们协同工作是否能产生互补效益。

Method: 1. 文本空间协作：一个模型规划推理过程，另一个模型根据规划执行最终答案。2. 潜在空间通信：引入一个学习到的投影器，将DDLM的潜在空间映射到ARM的嵌入空间，以规避扩散模型在文本生成方面的一些限制。

Result: 1. 将DDLM到ARM的通信从文本空间转移到潜在空间显著提高了准确性。例如，在DART-5数据集上，准确率从27.0%提高到54.0%；在AIME24数据集上，准确率从0.0%提高到14.0%。2. 将DDLM规划器与ARM执行器结合可以显著节省计算资源，同时对准确性影响很小甚至没有影响。例如，潜在空间管道在DART-5和AIME数据集上超越了Qwen3.1-7B，尽管Qwen使用的token数量是其44倍。

Conclusion: 本研究为使用DDLMs进行推理提供了新见解，并强调了它们在混合架构中的潜力。通过潜在空间通信实现的高效和高精度规划-执行的潜力。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [10] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TraceCoder是一个新的框架，它整合了多源外部知识，通过丰富代码表示、弥合语义鸿沟和处理稀有及模糊代码，提高了ICD编码的可追溯性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化国际疾病分类（ICD）编码方法存在挑战，例如临床文本与ICD代码之间的语义鸿沟、在稀有和长尾代码上表现不佳以及可解释性有限。

Method: TraceCoder通过动态整合UMLS、维基百科和大型语言模型等多种知识源，丰富代码表示，弥合语义鸿沟，并处理稀有和模糊代码。它还引入了一种混合注意力机制，以模拟标签、临床语境和知识之间的相互作用，从而改善长尾代码识别，并通过外部证据使预测可解释。

Result: 在MIMIC-III-ICD9、MIMIC-IV-ICD9和MIMIC-IV-ICD10数据集上的实验表明，TraceCoder达到了最先进的性能，并通过消融研究验证了其组件的有效性。

Conclusion: TraceCoder为自动化ICD编码提供了一个可扩展且鲁棒的解决方案，符合临床对准确性、可解释性和可靠性的需求。

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [11] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种名为 TACL（Threshold-Adaptive Curriculum Learning）的新型框架，旨在通过动态调整模型在训练过程中与医疗文本的交互方式来解决医疗文本理解中的挑战。


<details>
  <summary>Details</summary>
Motivation: 医疗文本（特别是电子病历）在现代医疗保健中至关重要，但其非结构化性质、领域特定语言和上下文差异使得自动化理解成为一个复杂挑战。尽管自然语言处理取得了进步，但现有方法常常忽略临床记录复杂性的内在差异，限制了模型在罕见或复杂病例上的泛化能力和表现。

Method: TACL（Threshold-Adaptive Curriculum Learning）框架。受渐进式学习原则的启发，TACL 根据个体样本的复杂性动态调整训练过程。通过将数据分类为不同的难度级别，并在训练早期优先处理简单病例，模型在处理更复杂的记录之前建立坚实的基础。

Result: 将 TACL 应用于多语言医疗数据（包括英语和中文临床记录），在各种临床任务中观察到显著改进，包括自动 ICD 编码、再入院预测和中医证候鉴别。

Conclusion: TACL 不仅提高了自动化系统的性能，还展示了统一不同医疗领域方法的潜力，为更准确、可扩展和全球适用的医疗文本理解解决方案铺平了道路。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [12] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: CoordGen是一个移动推理框架，通过结合推测解码和动态硬件调度，加速了移动设备上上下文感知文本生成，显著提高了生成速度和能效。


<details>
  <summary>Details</summary>
Motivation: 在移动设备上增强设备上的大型语言模型（LLMs）以实现个性化和任务感知的生成，但其面临高延迟和有限硬件利用率的挑战。

Method: CoordGen框架包含三个协同组件：1) 自适应执行调度，动态平衡预填充和解码阶段的计算图；2) 上下文对齐草稿，通过轻量级在线校准提高推测效率；3) 硬件高效草稿扩展，重用和扩展中间序列以提高处理并行性并降低验证成本。

Result: 在多个智能手机和代表性工作负载上的实验表明，与现有移动推理解决方案相比，生成速度提高了3.8倍，能效提高了4.7倍。

Conclusion: CoordGen通过其独特的方法有效解决了移动设备上LLMs生成过程中的延迟和硬件利用率问题，为移动端LLMs的推理提供了一个高效的解决方案。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [13] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文介绍了AutoGraph-R1，这是一个使用强化学习优化知识图谱（KG）构建的框架，旨在提高检索增强生成（RAG）系统中问答任务的性能。它通过将图生成视为策略学习问题来训练LLM构建器，并使用图在RAG管道中的功能效用作为奖励。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱（KG）构建过程与下游应用（如检索增强生成RAG）脱节，导致图结构次优，影响问答系统性能。

Method: AutoGraph-R1框架使用强化学习（RL）直接优化KG构建以提高任务性能。它将图生成视为策略学习问题，通过LLM构建器进行训练。奖励函数来源于图在RAG管道中的功能效用，并设计了两种新颖的、任务感知的奖励函数，分别针对知识载体和知识索引。

Result: 在多个问答基准测试中，AutoGraph-R1使图RAG方法相对于使用任务无关的基线图取得了显著的性能提升。

Conclusion: AutoGraph-R1证明了连接知识图谱构建和应用之间循环的可能性，将知识图谱的范式从构建“好”的图转变为构建“有用”的图。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [14] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 现有的可读性评估方法存在不足，本文研究了影响人类可读性感知的因素，并评估了多种可读性指标，发现基于模型的指标与人类判断更吻合。


<details>
  <summary>Details</summary>
Motivation: 尽管自动可读性评估取得了进展，但该领域仍受可读性定义不一致和仅依赖表层文本属性的测量方法的阻碍。

Method: 通过分析897个人工判断，调查影响人类可读性感知的因素，发现信息内容和主题在文本可理解性中起着重要作用。此外，在五个英文数据集上评估了15种流行的可读性指标和6种更细致的、基于模型的指标。

Result: 四种基于模型的指标在与人类判断的相关性排名中始终位居前四名，而表现最好的传统指标平均排名为8.6。

Conclusion: 目前的可读性指标与人类感知之间存在不匹配，基于模型的方法是更有前途的方向。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [15] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SAFE的LLM集成框架，通过选择性地集成和概率锐化策略，在长文本生成任务中提高了性能和效率，克服了现有集成方法在长文本生成中的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前LLM集成方法在短文本回复中表现良好，但在长文本生成中的应用仍未被充分探索。现有方法在长文本生成中，如果对每个token都进行集成，性能反而会下降。

Method: 本文提出SAFE（Stable And Fast LLM Ensembling）框架，通过联合考虑模型间tokenization不匹配和next-token概率分布共识，选择性地进行集成。为了提高稳定性，还引入了概率锐化策略，将分散在多个子词token上的概率整合到一个代表性token中。

Result: 在MATH500和BBH等多个基准测试中，SAFE在准确性和效率方面均优于现有方法，即使在集成不到1%的token时也能获得性能提升。

Conclusion: SAFE框架通过选择性集成和概率锐化策略，有效解决了LLM集成在长文本生成中的挑战，显著提高了集成LLM的性能和效率。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [16] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为 LayoutRL 的强化学习框架，该框架通过复合奖励优化文档布局理解，并提出了 Infinity-Doc-400K 数据集和 Infinity-Parser 模型，该模型在多种文档类型、语言和结构复杂度上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的监督微调方法在不同文档类型上的泛化能力差，尤其是在处理 OOD 数据时性能不佳，且高质量的布局感知解析任务训练数据有限。

Method: 本文引入了 LayoutRL，这是一个通过复合奖励（整合了归一化编辑距离、段落计数精度和阅读顺序保留）来优化布局理解的强化学习框架。为了支持训练，构建了 Infinity-Doc-400K 数据集，并用其训练了 Infinity-Parser，这是一个能在各种领域中展现稳健泛化能力的视觉-语言模型。

Result: 在 OmniDocBench、olmOCR-Bench、PubTabNet 和 FinTabNet 等基准测试中进行的广泛评估表明，Infinity-Parser 在各种文档类型、语言和结构复杂性方面始终 HIACHIEVES 最先进的性能，显著优于专用文档解析系统和通用视觉-语言模型。

Conclusion: LayoutRL 强化学习框架和 Infinity-Parser 模型有效解决了文档解析中泛化性差和数据稀缺的问题，并在多个基准测试中取得了最先进的性能。研究成果。作者将发布代码、数据集和模型以促进可重复研究。

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [17] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文评估了 22 个主流语音大语言模型在有言语障碍的用户交互时的表现，发现由于语音流利度问题，它们的性能显著下降，主要瓶颈在于音素级别的处理和长上下文建模。


<details>
  <summary>Details</summary>
Motivation: 评估当前语音大语言模型在有言语障碍的用户交互时能否保持性能，因为现有评估常依赖理想输入，忽略常见言语不流畅问题，尤其是帕金森病等相关问题。

Method: 引入 VocalBench-DF 框架，用于根据多维度分类法系统评估言语不流畅性。评估了 22 个主流语音大语言模型。

Result: 22 个主流语音大语言模型表现出显著的性能下降，表明其在实际应用中的准备不足。深入分析发现音素级别的处理和长上下文建模是导致这些失败的主要瓶颈。

Conclusion: 迫切需要新的方法来改善言语不流畅的处理，并构建真正具有包容性的语音大语言模型；从组件和管道层面加强识别和推理能力可以显著提高鲁棒性。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [18] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: 该文章提出了一种名为用户游戏生命周期（UGL）的新型表示学习方法，旨在解决游戏推荐和广告中存在的游戏稀疏性和不平衡性问题。通过丰富用户行为和采用逆概率掩码策略，UGL显著提升了离线AUC和在线CVR/ARPU。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统表示学习方法不适用于游戏广告和推荐，主要由于游戏数量少导致的稀疏性问题，以及少数热门游戏主导用户行为导致的游戏不平衡问题。

Method: 1. 引入用户游戏生命周期（UGL）以丰富游戏中的用户行为。2. 提出两种创新策略来处理用户行为，以更有效地提取短期和长期兴趣。3. 采用逆概率掩码策略解决UGL表示学习过程中的游戏不平衡问题。

Result: 离线实验结果显示，UGL表示使游戏广告模型的AUC平均提升1.83%，游戏内物品推荐模型的AUC平均提升0.5%。在线实验结果显示，UGL使游戏广告模型的CVR平均提升21.67%，游戏内物品推荐模型的ARPU平均提升0.82%。

Conclusion: UGL表示学习方法通过解决游戏稀疏性和不平衡性问题，显著提升了游戏广告和游戏内物品推荐系统的性能。

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [19] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 这篇论文提出并验证了一个框架，用于专门化 MedGemma 模型，以生成高质量的图像标题，从而为检索增强生成系统提供更好的查询。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成系统（RAGs）在处理基于图像的查询时，由于通用视觉语言模型（VLMs）生成的标题缺乏临床特异性和事实依据，效果有限。

Method: 本研究提出了一个框架来专门化 MedGemma 模型，以生成高质量的标题。为了克服数据稀缺问题，研究人员采用知识蒸馏管道在皮肤病学、眼底和胸部X光领域创建合成数据集，并使用参数高效的 QLoRA 方法对 MedGemma 进行微调。

Result: 微调后的模型在分类性能方面表现出显著改进。RAGAS 评估证实，标题的忠实性和正确性显著提高，验证了模型生成可靠、基于事实描述的能力。

Conclusion: 这项工作建立了一个专门化医学视觉语言模型的强大管道，并验证了所得模型作为高质量查询生成器的能力，为增强循证临床决策支持中的多模态 RAG 系统奠定了基础。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [20] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文主要探讨了多模态大型语言模型（MLLMs）在主动推理方面的能力，并提出了一个名为GuessBench的基准来评估其在不完全信息下主动获取缺失证据的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs评估主要关注被动推理，这与实际应用中需要主动获取信息的情况不符。因此，本文旨在探究MLLMs在不完全信息下主动获取缺失证据并迭代优化决策的能力。

Method: 本文提出了GuessBench基准，包含感知导向和知识导向的图片，用于评估MLLMs的主动推理能力。

Result: 评估结果显示，MLLMs在主动推理方面的表现远低于被动推理，表明有很大的提升空间。进一步分析发现，细粒度感知和及时决策是主要挑战。消融研究表明，感知增强对小型模型有益，而思维导向的方法对所有模型尺寸都持续有效。

Conclusion: MLLMs在主动推理方面存在不足，但在细粒度感知、及时决策以及感知增强和思维导向方法的应用上，仍有很大的研究空间和发展潜力。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [21] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 本文提出了一种基于提示工程的可控抽象摘要生成方法，解决了传统方法的摘要质量和可控性问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在摘要质量和可控性方面的不足。

Method: 设计了一个多阶段提示生成框架，通过语义分析、主题建模和噪声控制生成不同抽象级别的摘要。

Result: 提示长度对摘要质量有显著影响，过短或过长的提示都会降低摘要质量。数据噪声对摘要生成过程有负面影响，ROUGE-L分数随噪声水平增加而下降。模型在处理新闻文本时表现最佳，在处理学术文章时表现较差。

Conclusion: 本研究为使用大型语言模型改进摘要生成提供了新见解，特别是在控制提示策略和优化文本预处理方面。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [22] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: DeceptionBench是第一个系统评估大型语言模型欺骗行为的基准，涵盖了社会领域、内在模式和外在因素，揭示了模型在强化动态下欺骗行为的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）能力的快速提升带来了新兴的欺骗行为，这可能在高风险部署中引发严重风险，而现有研究对现实世界场景中欺骗行为的刻画不足。

Method: 建立了DeceptionBench基准，包含150个精心设计的场景和1000多个样本，涵盖经济、医疗、教育、社会互动和娱乐五个社会领域。从内在维度，探讨模型是否表现出自利或迎合用户的行为。从外在维度，研究中性条件、基于奖励的激励和强制压力如何调节欺骗性输出。此外，纳入了持续的多轮交互循环以模拟现实世界的反馈动态。

Result: 在LLMs和LRMs上的大量实验揭示了关键的脆弱性，特别是在强化动态下欺骗行为显著增加，表明当前模型缺乏对操纵性情境线索的 M 币鲁棒抵抗力。

Conclusion: 迫切需要针对各种欺骗行为的高级安全措施，以增强模型对操纵性情境线索的抵抗力。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


### [23] [Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?](https://arxiv.org/abs/2510.15513)
*Ashutosh Bajpai,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文介绍了一种新基准TEMP-ReCon，用于评估大型语言模型（LLMs）的时间参照一致性，并提出了一个名为UnTRaP的模型来提高LLMs在这方面的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在时间敏感领域（如法律、医疗保健和金融）中的应用越来越广泛，需要LLMs不仅事实准确，而且在时间维度上保持一致性。然而，目前在这方面的研究很少。

Method: 本文引入了一个名为TEMP-ReCon的新型基准，旨在评估大型语言模型（LLMs）在不同语言背景（包括英语、法语和罗马尼亚语）下的时间参照一致性。此外，本文还提出了一个名为UnTRaP的模型，该模型基于推理路径对齐，旨在增强LLMs的时间参照一致性。

Result: 研究结果表明，LLMs确实存在时间参照一致性不足的问题。通过实证实验，本文证实了UnTRaP模型在提高LLMs时间参照一致性方面的有效性，它优于其他基线模型。

Conclusion: 本文通过引入TEMP-ReCon基准和UnTRaP模型，有效地揭示并改善了大型语言模型在时间敏感查询中时间参照一致性不足的问题。

Abstract: The increasing acceptance of large language models (LLMs) as an alternative
to knowledge sources marks a significant paradigm shift across various domains,
including time-sensitive fields such as law, healthcare, and finance. To
fulfill this expanded role, LLMs must not only be factually accurate but also
demonstrate consistency across temporal dimensions, necessitating robust
temporal reasoning capabilities. Despite this critical requirement, efforts to
ensure temporal consistency in LLMs remain scarce including noticeable absence
of endeavors aimed at evaluating or augmenting LLMs across temporal references
in time-sensitive inquiries. In this paper, we seek to address this gap by
introducing a novel benchmark entitled temporal referential consistency,
accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both
open-source and closed-source LLMs with various linguistic contexts
characterized by differing resource richness (including English, French, and
Romanian). The findings emphasis that LLMs do exhibit insufficient temporal
referent consistency. To address this, we propose \newmodel, a reasoning path
alignment-based model that aims to enhance the temporal referential consistency
of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared
to several baseline models.

</details>


### [24] [From Characters to Tokens: Dynamic Grouping with Hierarchical BPE](https://arxiv.org/abs/2510.15517)
*Rares Dolga,Lucas Maystre,Tudor Berariu,David Barber*

Main category: cs.CL

TL;DR: 这篇论文提出了一种动态字符分组方法，利用现有BPE分词结构，实现高效、灵活且语言无关的表示，并在保持词汇紧凑性的前提下，在性能上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的子词分词方法（如BPE）在表示稀有词时效率低下，需要大型嵌入矩阵。字符级模型虽然解决了这些问题，但带来了性能瓶颈。最近的分层模型试图结合两者的优点，但现有的修补策略要么依赖于空格，限制了其适用性，要么需要引入新的辅助模型。

Method: 本文提出了一种动态字符分组方法，该方法利用现有BPE分词的结构，但不需要额外的模型。通过在BPE令牌后面附加明确的补丁结束标记，并引入二级BPE压缩阶段来控制补丁粒度。

Result: 实验结果表明，该方法在性能上与现有的基于熵和空格的动态修补策略相当或超越，同时保持了词汇的紧凑性。

Conclusion: 所提出的动态字符分组方法在没有额外模型的情况下，实现了高效、灵活且语言无关的表示，并且在性能上优于现有方法，同时保持了词汇的紧凑性。

Abstract: Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in
large language models due to their balance of vocabulary compactness and
representational power. However, they suffer from inefficiencies in
representing rare words and require large embedding matrices. Character-level
models address these issues but introduce performance bottlenecks, particularly
in Transformer-based architectures. Recent hierarchical models attempt to merge
the benefits of both paradigms by grouping characters into patches, but
existing patching strategies either rely on whitespace-limiting applicability
to certain languages, or require auxiliary models that introduce new
dependencies. In this paper, we propose a dynamic character grouping method
that leverages the structure of existing BPE tokenization without requiring
additional models. By appending explicit end-of-patch markers to BPE tokens and
introducing a second-level BPE compression stage to control patch granularity,
our method offers efficient, flexible, and language-agnostic representations.
Empirical results demonstrate that our approach matches or exceeds the
performance of dynamic entropy- and whitespace-based patching strategies, while
maintaining a compact vocabulary.

</details>


### [25] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 这篇论文提出了一种模态组合感知框架，以解决多模态大语言模型在统一编码器中学习模态捷径的问题，从而提高在分布偏移下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在多模态检索方面取得了进展，但它们在使用统一编码器和传统对比学习进行训练时，容易学习模态捷径，导致在分布偏移下鲁棒性较差。

Method: 本文提出了一个模态组合感知框架来缓解模态捷径问题。具体来说，通过偏好损失强制多模态嵌入优于单模态嵌入，并通过组合正则化目标将多模态嵌入与其单模态部分组成的原型对齐。这些目标明确地建模了组合表示与其单模态对应物之间的结构关系。

Result: 在各种基准上的实验表明，该方法在分布外检索方面取得了显著提升，强调了模态组合感知作为一种有效原则，可以在使用MLLMs作为统一编码器时实现鲁棒的组合多模态检索。

Conclusion: 模态组合感知是提高多模态大语言模型在多模态检索中鲁棒性的有效原则，尤其是在处理分布偏移数据时。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [26] [TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs](https://arxiv.org/abs/2510.15545)
*Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou*

Main category: cs.CL

TL;DR: 本文提出了一种名为TokenTiming的通用推测解码算法，它通过重新编码草稿token序列并使用DTW来传输概率分布，从而在不重新训练或修改现有模型的情况下，解决了推测解码中草稿模型和目标模型词汇不匹配的问题，并实现了1.57倍的推理加速。


<details>
  <summary>Details</summary>
Motivation: 加速大型语言模型（LLM）的推理是生成式AI中的一个关键挑战。推测解码（SD）显著提高了LLM推理效率，但其受限于草稿模型和目标模型必须共享相同词汇的约束，这限制了可用草稿模型的选择，并通常需要从头开始训练新模型。

Method: 作者提出了TokenTiming算法。该算法通过重新编码草稿token序列以获得新的目标token序列，然后使用动态时间规整（DTW）建立映射，以传输概率分布进行推测采样。这种方法可以适应不匹配的词汇，并且无需重新训练和修改即可与任何现成模型配合使用。

Result: 实验结果表明，该方法实现了1.57倍的加速。

Conclusion: 本文提出了一种通用的草稿模型选择方法，使得推测解码成为LLM加速中更通用和实用的工具。

Abstract: Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.

</details>


### [27] [Rethinking Cross-lingual Gaps from a Statistical Viewpoint](https://arxiv.org/abs/2510.15551)
*Vihari Piratla,Purvam Jain,Darshan Singh,Partha Talukdar,Trevor Cohn*

Main category: cs.CL

TL;DR: 这篇论文探讨了大型语言模型中的跨语言差距，并提出该差距主要来源于目标语言响应中的方差，而非潜在表征的差异。


<details>
  <summary>Details</summary>
Motivation: 以往研究认为大型语言模型中的跨语言差距源于源语言和目标语言之间潜在表征的差异。本文旨在提出并验证一种新的观点，即响应方差是造成跨语言差距的主要原因。

Method: 本文首次将跨语言差距形式化为偏差-方差分解问题。通过大量的实验证据支持所提出的公式和假设。作者还通过多种推理时干预措施来控制方差并缩小跨语言差距。

Result: 实验结果表明，通过一个简单的提示指令来减少响应方差，可以将不同模型的准确性提高20-25%，从而显著缩小了跨语言差距。

Conclusion: 跨语言差距的主要原因在于目标语言响应的方差。通过减少这种方差，可以有效提高大型语言模型在目标语言查询中的准确性。

Abstract: Any piece of knowledge is usually expressed in one or a handful of natural
languages on the web or in any large corpus. Large Language Models (LLMs) act
as a bridge by acquiring knowledge from a source language and making it
accessible when queried from target languages. Prior research has pointed to a
cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a
target language compared to when the query is in the source language. Existing
research has rationalized divergence in latent representations in source and
target languages as the source of cross-lingual gap. In this work, we take an
alternative view and hypothesize that the variance of responses in the target
language is the main cause of this gap. For the first time, we formalize the
cross-lingual gap in terms of bias-variance decomposition. We present extensive
experimental evidence which support proposed formulation and hypothesis. We
then reinforce our hypothesis through multiple inference-time interventions
that control the variance and reduce the cross-lingual gap. We demonstrate a
simple prompt instruction to reduce the response variance, which improved
target accuracy by 20-25% across different models.

</details>


### [28] [Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15552)
*Jinliang Liu*

Main category: cs.CL

TL;DR: ParallaxRAG框架通过将查询和图三元组解耦到多视图空间中，解决了检索增强生成（RAG）中大型语言模型（LLM）幻觉和多跳推理困难的问题。它利用注意力头在不同推理阶段的专业化来构建更清晰的子图，从而实现更可靠的推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在语言理解方面表现出色，但在多跳推理中经常出现幻觉并面临困难。现有的知识图谱检索增强生成（KG-RAG）方法依赖于扁平嵌入和嘈杂的路径探索。

Method: ParallaxRAG框架将查询和图三元组对称地解耦到多视图空间中。该方法通过明确强制头部多样性来构建鲁棒的检索架构，同时约束弱相关路径。其核心在于利用不同的注意力头在不同推理阶段专门处理语义关系，从而构建更清晰的子图，并指导LLM进行有根据的逐步推理。

Result: 在WebQSP和CWQ数据集上，ParallaxRAG在统一的可重现设置下（使用BGE-M3 + Llama3.1-8B）展示了具有竞争力的检索和问答性能。它显著减少了幻觉并表现出良好的泛化能力。

Conclusion: 多视图头部专业化是知识图谱多跳推理的一个原则性方向。ParallaxRAG通过其独特的多视图解耦和注意力头专业化方法，为解决大型语言模型中的幻觉和复杂推理问题提供了有效方案。

Abstract: Large language models (LLMs) excel at language understanding but often
hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based
retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely
on flat embeddings and noisy path exploration. We propose ParallaxRAG, a
framework that symmetrically decouples queries and graph triples into
multi-view spaces, enabling a robust retrieval architecture that explicitly
enforces head diversity while constraining weakly related paths. Central to our
approach is the observation that different attention heads specialize in
semantic relations at distinct reasoning stages, contributing to different hops
of the reasoning chain. This specialization allows ParallaxRAG to construct
cleaner subgraphs and guide LLMs through grounded, step-wise reasoning.
Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 +
Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside
reduced hallucination and good generalization. Our results highlight multi-view
head specialization as a principled direction for knowledge-grounded multi-hop
reasoning. Our implementation will be released as soon as the paper is
accepted.

</details>


### [29] [KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models](https://arxiv.org/abs/2510.15558)
*Dongjun Kim,Chanhee Park,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个名为KITE的新的基准测试，用于评估大型语言模型（LLMs）的韩语指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 目前评估大型语言模型（LLMs）主要集中在英语模型，忽略了其他语言的语言和文化细微差别，尤其是韩语缺乏专门用于评估开放式指令遵循能力的基准测试。

Method: 本文引入了韩语指令遵循任务评估（KITE）基准，旨在评估通用和韩语特定的指令。KITE直接针对多样化的开放式指令遵循任务，并通过自动化指标和人工评估相结合的评估流程来揭示模型性能差异。

Result: KITE揭示了不同模型之间的性能差异，并深入了解了它们的优势和劣势。

Conclusion: 通过公开KITE数据集和代码，作者旨在促进对文化和语言包容性LLM开发的进一步研究，并激励其他代表性不足的语言进行类似的努力。

Abstract: The instruction-following capabilities of large language models (LLMs) are
pivotal for numerous applications, from conversational agents to complex
reasoning systems. However, current evaluations predominantly focus on English
models, neglecting the linguistic and cultural nuances of other languages.
Specifically, Korean, with its distinct syntax, rich morphological features,
honorific system, and dual numbering systems, lacks a dedicated benchmark for
assessing open-ended instruction-following capabilities. To address this gap,
we introduce the Korean Instruction-following Task Evaluation (KITE), a
comprehensive benchmark designed to evaluate both general and Korean-specific
instructions. Unlike existing Korean benchmarks that focus mainly on factual
knowledge or multiple-choice testing, KITE directly targets diverse, open-ended
instruction-following tasks. Our evaluation pipeline combines automated metrics
with human assessments, revealing performance disparities across models and
providing deeper insights into their strengths and weaknesses. By publicly
releasing the KITE dataset and code, we aim to foster further research on
culturally and linguistically inclusive LLM development and inspire similar
endeavors for other underrepresented languages.

</details>


### [30] [Finetuning LLMs for EvaCun 2025 token prediction shared task](https://arxiv.org/abs/2510.15561)
*Josef Jon,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文介绍了EvaCun 2025在token预测任务中的提交，该提交基于对LLM（Command-R、Mistral和Aya Expanse）进行微调。


<details>
  <summary>Details</summary>
Motivation: 作者对主题领域和任务语言的了解非常肤浅，因此他们选择在不进行任何任务特定调整、预处理或过滤的情况下使用训练数据。

Method: 本文比较了LMM模型（Command-R、Mistral和Aya Expanse）进行微调。通过三种不同的提示方法，获得预测结果，并在数据的保留部分进行评估。

Result: 本文评估了基于三种不同提示方法的预测效果。

Conclusion: 本文展示了在不具备特定领域知识的情况下，通过微调大型语言模型也能在特定任务上获得有竞争力的性能。

Abstract: In this paper, we present our submission for the token prediction task of
EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya
Expanse) fine-tuned on the task data provided by the organizers. As we only
pos-sess a very superficial knowledge of the subject field and the languages of
the task, we simply used the training data without any task-specific
adjustments, preprocessing, or filtering. We compare 3 different approaches
(based on 3 different prompts) of obtaining the predictions, and we evaluate
them on a held-out part of the data.

</details>


### [31] [From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages](https://arxiv.org/abs/2510.15569)
*Syed Mohammad Sualeh Ali*

Main category: cs.CL

TL;DR: 这篇论文研究了乌尔都语诗歌中“爱”的相关词语，通过多义性分析揭示了其细微差别。


<details>
  <summary>Details</summary>
Motivation: 探索乌尔都语诗歌中“爱”相关词语（pyaar, muhabbat, ishq）的细微差别，因为它们在英语中没有直接等价的词。

Method: 采用多义性案例研究方法，分析这些词在乌尔都语诗歌中的用法和语境。同时，通过生成乌尔都语和英语中与“爱”相关的词嵌入，进行比较分析，量化并可视化这些词的语义空间。

Result: 揭示了乌尔都语中“爱”相关词语之间隐藏的深层含义和细微差别，这些差别在英语文学中没有直接的对应。

Conclusion: 本研究通过多方面的方法，加深了对乌尔都语诗歌中“爱”及其丰富表达的理解和欣赏。

Abstract: This paper delves into the intricate world of Urdu poetry, exploring its
thematic depths through a lens of polysemy. By focusing on the nuanced
differences between three seemingly synonymous words (pyaar, muhabbat, and
ishq) we expose a spectrum of emotions and experiences unique to the Urdu
language. This study employs a polysemic case study approach, meticulously
examining how these words are interwoven within the rich tapestry of Urdu
poetry. By analyzing their usage and context, we uncover a hidden layer of
meaning, revealing subtle distinctions which lack direct equivalents in English
literature. Furthermore, we embark on a comparative analysis, generating word
embeddings for both Urdu and English terms related to love. This enables us to
quantify and visualize the semantic space occupied by these words, providing
valuable insights into the cultural and linguistic nuances of expressing love.
Through this multifaceted approach, our study sheds light on the captivating
complexities of Urdu poetry, offering a deeper understanding and appreciation
for its unique portrayal of love and its myriad expressions

</details>


### [32] [The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works](https://arxiv.org/abs/2510.15594)
*Antoine Bourgois,Thierry Poibeau*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个新的法语小说共指解析语料库，并提出了一个模块化的共指解析流水线，该流水线在长文档上表现出色，并可用于推断虚构人物的性别。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏用于完全注释长文档的代表性共指解析数据集。

Method: 本文引入了一个包含三部完整法语小说的新的带注释语料库，总计超过285,000个标记，并提出了一个模块化的共指解析流水线。

Result: 该方法具有竞争力，可以有效地扩展到长文档，并且可以有效地推断虚构人物的性别。

Conclusion: 该语料库和方法对于文学分析和下游NLP任务都具有相关性。

Abstract: While coreference resolution is attracting more interest than ever from
computational literature researchers, representative datasets of fully
annotated long documents remain surprisingly scarce. In this paper, we
introduce a new annotated corpus of three full-length French novels, totaling
over 285,000 tokens. Unlike previous datasets focused on shorter texts, our
corpus addresses the challenges posed by long, complex literary works, enabling
evaluation of coreference models in the context of long reference chains. We
present a modular coreference resolution pipeline that allows for fine-grained
error analysis. We show that our approach is competitive and scales effectively
to long documents. Finally, we demonstrate its usefulness to infer the gender
of fictional characters, showcasing its relevance for both literary analysis
and downstream NLP tasks.

</details>


### [33] [HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination](https://arxiv.org/abs/2510.15614)
*Tingting Chen,Beibei Lin,Zifeng Yuan,Qiran Zou,Hongyu He,Yew-Soon Ong,Anirudh Goyal,Dianbo Liu*

Main category: cs.CL

TL;DR: 本文介绍了HypoSpace，一个用于评估大型语言模型（LLMs）生成解释集能力的诊断工具，旨在解决科学问题中欠定性问题，即多个假设与相同观测结果一致的情况。


<details>
  <summary>Details</summary>
Motivation: 在大模型越来越多地应用于科学工作流程的背景下，评估它们提出解释集（而不仅仅是单一正确答案）的能力变得至关重要，因为许多科学问题是欠定的，即多个机制上不同的假设与相同的观察结果一致。

Method: HypoSpace将LLMs视为有限假设集的采样器，并测量三个互补指标：有效性（提案与观测结果一致的精确度）、独特性（提案之间的非冗余性）和恢复性（枚举的可接受集合的覆盖率）。研究在三个具有确定性验证器和精确枚举假设空间的结构化领域中实例化了HypoSpace：(i) 来自扰动的因果图，(ii) 从自上而下投影的重力约束3D体素重建，以及(iii) 布尔遗传相互作用。

Result: 在经过指令微调和注重推理的模型中，有效性通常保持较高，而独特性和恢复性随着可接受空间的增长而下降，这揭示了模式崩溃，而这种崩溃在仅关注正确性的指标中是不可见的。

Conclusion: HypoSpace提供了一种受控的探测方法，而非排行榜，用于评估明确探索和覆盖可接受解释空间的方法。

Abstract: As language models are increasingly used in scientific workflows, evaluating
their ability to propose sets of explanations-not just a single correct
answer-becomes critical. Many scientific problems are underdetermined:
multiple, mechanistically distinct hypotheses are consistent with the same
observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as
samplers of finite hypothesis sets and measures three complementary indicators:
Validity (precision of proposals consistent with observations), Uniqueness
(non-redundancy among proposals), and Recovery (coverage of the enumerated
admissible set). We instantiate HypoSpace in three structured domains with
deterministic validators and exactly enumerated hypothesis spaces: (i) causal
graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction
from top-down projections, and (iii) Boolean genetic interactions. Across
instruction-tuned and reasoning-focused models, Validity often remains high
while Uniqueness and Recovery degrade as the admissible space grows, revealing
mode collapse that is invisible to correctness-only metrics. HypoSpace offers a
controlled probe-rather than a leaderboard-for methods that explicitly explore
and cover admissible explanation spaces. Code is available at:
https://github.com/CTT-Pavilion/_HypoSpace.

</details>


### [34] [Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection](https://arxiv.org/abs/2510.15685)
*Joshua Wolfe Brook,Ilia Markov*

Main category: cs.CL

TL;DR: 该研究提出了一种利用大型语言模型（LLM）作为动态知识库来生成背景信息，并将其整合到Hate Speech Detection（HSD）分类器输入中的新方法，在文本和多模态设置中均取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 在Hate Speech Detection（HSD）任务中，为了提高分类器的性能，该研究旨在利用大型语言模型（LLM）作为动态知识库，生成背景上下文信息，并将其融入到HSD分类器的输入中。

Method: 研究检验了两种上下文生成策略：一种侧重于命名实体，另一种侧重于全文提示。同时，比较了四种将上下文融入分类器输入的方法：文本拼接、嵌入拼接、基于层次Transformer的融合以及LLM驱动的文本增强。

Result: 实验在文本形式的Latent Hatred隐性仇恨言论数据集和多模态形式的MAMI厌女模因数据集上进行。结果表明，上下文信息及其整合方式都至关重要，相对于零上下文基线，性能最佳的系统（基于嵌入拼接）在文本设置中F1分数提升了3个点，在多模态设置中提升了6个点。

Conclusion: 利用大型语言模型生成的背景上下文信息可以显著提升仇恨言论检测的性能，其中上下文的生成策略和集成方法对最终效果至关重要，特别是嵌入拼接方法表现最佳。

Abstract: This research introduces a novel approach to textual and multimodal Hate
Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge
bases to generate background context and incorporate it into the input of HSD
classifiers. Two context generation strategies are examined: one focused on
named entities and the other on full-text prompting. Four methods of
incorporating context into the classifier input are compared: text
concatenation, embedding concatenation, a hierarchical transformer-based
fusion, and LLM-driven text enhancement. Experiments are conducted on the
textual Latent Hatred dataset of implicit hate speech and applied in a
multimodal setting on the MAMI dataset of misogynous memes. Results suggest
that both the contextual information and the method by which it is incorporated
are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups
respectively, from a zero-context baseline to the highest-performing system,
based on embedding concatenation.

</details>


### [35] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 这篇论文提出了一种检索增强推理模型，该模型可以根据查询和检索结果动态调整检索到的文档列表的长度，以降低计算成本并提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的推理模型，特别是那些经过检索增强的，往往计算成本高昂，因为检索和推理都消耗大量资源。

Method: 1. 提出了一种检索增强推理模型，该模型根据查询和检索结果动态调整检索文档列表的长度。2. 开发了一种成本感知优势函数，用于通过强化学习训练高效的检索增强推理模型。3. 探索了所提出的成本感知框架在记忆和延迟绑定实现方面，用于近端和组相对策略优化算法。

Result: 在七个公共问答数据集上，模型延迟降低了约16-20%，而准确率（精确匹配）平均提高了约5%。

Conclusion: 该研究提出了一种成本效益高的检索增强推理模型，在不影响有效性的前提下，显著提高了效率（降低了延迟）并提高了准确性。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [36] [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731)
*Maximo Eduardo Rulli,Simone Petruzzi,Edoardo Michielon,Fabrizio Silvestri,Simone Scardapane,Alessio Devoto*

Main category: cs.CL

TL;DR: 本文探讨了掩蔽扩散语言模型（DLMs）中的注意力下沉现象，发现与自回归模型（ARMs）不同，DLMs的注意力下沉位置是动态变化的，并且对移除注意力下沉不敏感。


<details>
  <summary>Details</summary>
Motivation: 尽管掩蔽扩散语言模型（DLMs）在效率和有效性方面表现出色，但其内部机制，特别是注意力模式，仍然不甚明了。

Method: 本文通过实证分析DLM的注意力模式来研究注意力下沉现象，并与传统自回归模型（ARMs）进行比较。

Result: 研究发现DLMs也存在注意力下沉现象，但其特点与ARMs不同：1. DLMs中的下沉位置在生成过程中会动态变化。 2. 移除注意力下沉对DLMs的性能影响很小，而ARMs则高度敏感。

Conclusion: 这些发现揭示了扩散语言模型内部工作原理的新见解，并强调了DLMs在注意力分配和利用方面与自回归模型的根本差异。

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising
alternative to traditional Autoregressive Models (ARMs). DLMs employ
transformer encoders with bidirectional attention, enabling parallel token
generation while maintaining competitive performance. Although their efficiency
and effectiveness have been extensively studied, the internal mechanisms that
govern DLMs remain largely unexplored. In this work, we conduct an empirical
analysis of DLM attention patterns, focusing on the attention sinking
phenomenon, an effect previously observed in various transformer-based
architectures. Our findings reveal that DLMs also exhibit attention sinks, but
with distinct characteristics. First, unlike in ARMs, the sink positions in
DLMs tend to shift throughout the generation process, displaying a dynamic
behaviour. Second, while ARMs are highly sensitive to the removal of attention
sinks, DLMs remain robust: masking sinks leads to only a minor degradation in
performance. These results provide new insights into the inner workings of
diffusion-based language models and highlight fundamental differences in how
they allocate and utilize attention compared to autoregressive models.

</details>


### [37] [LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2510.15746)
*Gao Yang,Yuhang Liu,Siyu Miao,Xinyue Liang,Zhengyang Liu,Heyan Huang*

Main category: cs.CL

TL;DR: 本文探讨了将博弈论原理应用于大型语言模型（LLM）评估的可行性，提出了一种名为自动互评的新方法，通过LLM之间的自博弈和同行评审来评估它们的输出，并利用博弈论投票算法将同行评审结果与人类投票行为进行比较，以评估LLM能力。


<details>
  <summary>Details</summary>
Motivation: 传统的评估方法在捕捉现代LLM行为的细微、主观和开放性方面存在不足，这促使作者寻求新的评估范式。

Method: 本文提出了一种新的自动交互评估方法，其中LLM通过自博弈和同伴评审相互评估彼此的输出。这些同伴评估接着与人类投票行为进行系统比较，以评估它们与人类判断的一致性。这个框架结合了博弈论投票算法来聚合同伴评审，从而能够原则性地研究模型生成的排名是否反映人类偏好。

Result: 经验结果揭示了理论预测与人类评估之间存在趋同和分歧，为交互评估的潜力和局限性提供了有价值的见解。

Conclusion: 这项工作首次将互评、博弈论聚合和以人为本的验证相结合，用于评估LLM的能力。

Abstract: Ideal or real - that is the question.In this work, we explore whether
principles from game theory can be effectively applied to the evaluation of
large language models (LLMs). This inquiry is motivated by the growing
inadequacy of conventional evaluation practices, which often rely on
fixed-format tasks with reference answers and struggle to capture the nuanced,
subjective, and open-ended nature of modern LLM behavior. To address these
challenges, we propose a novel alternative: automatic mutual evaluation, where
LLMs assess each other's output through self-play and peer review. These peer
assessments are then systematically compared with human voting behavior to
evaluate their alignment with human judgment. Our framework incorporates
game-theoretic voting algorithms to aggregate peer reviews, enabling a
principled investigation into whether model-generated rankings reflect human
preferences. Empirical results reveal both convergences and divergences between
theoretical predictions and human evaluations, offering valuable insights into
the promises and limitations of mutual evaluation. To the best of our
knowledge, this is the first work to jointly integrate mutual evaluation,
game-theoretic aggregation, and human-grounded validation for evaluating the
capabilities of LLMs.

</details>


### [38] [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)
*Orr Paradise,David F. Gruber,Adam Tauman Kalai*

Main category: cs.CL

TL;DR: 这篇文章探讨了在没有参考翻译的情况下，评估AI鲸鱼到英语翻译器性能的方法，甚至可能不需要与动物互动或进行地面观察。


<details>
  <summary>Details</summary>
Motivation: 在AI鲸鱼到英语翻译器等情境下，传统评估方法（如与动物互动或地面观察）可能不适用或效率低下，尤其是在没有参考翻译的情况下。因此，需要一种新的、无需参考的评估方法。

Method: 本文提出了一种结合分段翻译和经典NLP洗牌测试的评估方法。其核心思想是逐段翻译动物交流，并通过比较翻译结果的顺序和乱序版本，评估其意义的连贯性。

Result: 在数据稀缺的人类语言和构建语言上的概念验证实验表明，该评估方法是有效的。它与基于参考翻译的标准评估方法高度相关。理论分析也表明，在学习翻译的早期阶段，互动可能不是必需的，也不是高效的。

Conclusion: 本文提出了一种无需参考翻译的机器翻译质量评估方法，该方法在概念验证实验中表现出潜力，尤其适用于数据稀缺或难以获得参考翻译的场景。这种方法可能在安全性、伦理和成本方面具有优势。

Abstract: If you had an AI Whale-to-English translator, how could you validate whether
or not it is working? Does one need to interact with the animals or rely on
grounded observations such as temperature? We provide theoretical and
proof-of-concept experimental evidence suggesting that interaction and even
observations may not be necessary for sufficiently complex languages. One may
be able to evaluate translators solely by their English outputs, offering
potential advantages in terms of safety, ethics, and cost. This is an instance
of machine translation quality evaluation (MTQE) without any reference
translations available. A key challenge is identifying ``hallucinations,''
false translations which may appear fluent and plausible. We propose using
segment-by-segment translation together with the classic NLP shuffle test to
evaluate translators. The idea is to translate animal communication, turn by
turn, and evaluate how often the resulting translations make more sense in
order than permuted. Proof-of-concept experiments on data-scarce human
languages and constructed languages demonstrate the potential utility of this
evaluation methodology. These human-language experiments serve solely to
validate our reference-free metric under data scarcity. It is found to
correlate highly with a standard evaluation based on reference translations,
which are available in our experiments. We also perform a theoretical analysis
suggesting that interaction may not be necessary nor efficient in the early
stages of learning to translate.

</details>


### [39] [Paper2Web: Let's Make Your Paper Alive!](https://arxiv.org/abs/2510.15842)
*Yuhang Chen,Tianpeng Lv,Siyi Zhang,Yixiang Yin,Yao Wan,Philip S. Yu,Dongping Chen*

Main category: cs.CL

TL;DR: Paper2Web 是一个用于评估学术网页生成的大型基准数据集和多维度评估框架，它可以通过规则、人工验证和 PaperQuiz 来量化评估网页质量。我们还提出了一个名为 PWAgent 的自主管道，可以将科学论文转化为交互式多媒体学术主页。PWAgent 通过迭代细化内容和布局，以增强重点、平衡和呈现质量。通过实验证明，PWAgent 在保持低成本的同时，显著优于现有的端到端基线。


<details>
  <summary>Details</summary>
Motivation: 学术项目网站在传播研究成果方面面临挑战，现有方法难以生成布局合理、交互性强的网站，且缺乏全面的评估套件。

Method: Paper2Web 是一个基准数据集和多维度评估框架，包含 Connectivity、Completeness 等基于规则的度量指标，以及由人工验证的 LLM-as-a-Judge （评估交互性、美观性和信息量）。另外，PaperQuiz 用于衡量论文级别的知识保留。PWAgent 是一个自动化管道，通过 MCP 工具迭代优化内容和布局，将科学论文转化为交互式多媒体学术主页。

Result: PWAgent 在保持低成本的同时，显著优于基于模板的网页和 arXiv/alphaXiv 等基线。

Conclusion: Paper2Web 是一个用于评估学术网页生成的基准数据集和多维度评估框架，PWAgent 是一种自动生成高质量、交互式学术主页的有效方法，显著优于现有基线。

Abstract: Academic project websites can more effectively disseminate research when they
clearly present core content and enable intuitive navigation and interaction.
However, current approaches such as direct Large Language Model (LLM)
generation, templates, or direct HTML conversion struggle to produce
layout-aware, interactive sites, and a comprehensive evaluation suite for this
task has been lacking. In this paper, we introduce Paper2Web, a benchmark
dataset and multi-dimensional evaluation framework for assessing academic
webpage generation. It incorporates rule-based metrics like Connectivity,
Completeness and human-verified LLM-as-a-Judge (covering interactivity,
aesthetics, and informativeness), and PaperQuiz, which measures paper-level
knowledge retention. We further present PWAgent, an autonomous pipeline that
converts scientific papers into interactive and multimedia-rich academic
homepages. The agent iteratively refines both content and layout through MCP
tools that enhance emphasis, balance, and presentation quality. Our experiments
show that PWAgent consistently outperforms end-to-end baselines like
template-based webpages and arXiv/alphaXiv versions by a large margin while
maintaining low cost, achieving the Pareto-front in academic webpage
generation.

</details>


### [40] [Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework](https://arxiv.org/abs/2510.15843)
*Shayan Rokhva,Mousa Alizadeh,Maryam Abdollahi Shamami*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新颖的混合词典-模糊-Transformer框架，用于准确检测产品评论和社交媒体帖子中的情感极性和强度。该框架结合了基于规则的启发式方法、上下文深度学习和模糊逻辑，以生成反映极性和强度的连续情感分数。


<details>
  <summary>Details</summary>
Motivation: 由于非正式和特定领域的语言，准确检测产品评论和社交媒体帖子中的情感极性和强度仍然具有挑战性。

Method: 该框架首先使用基于VADER的初始情感估计，然后通过两阶段调整过程进行细化。这包括利用来自DistilBERT的置信度分数，并应用模糊逻辑原则来减轻过度中性偏差并增强粒度。一个自定义的模糊推理系统将细化的分数映射到0到1的连续体上，产生类似专家的判断。

Result: 在四个特定领域的数据集（食品配送、电子商务、旅游和时尚）上进行了严格评估。结果显示，与用户评分的一致性有所提高，情感极值识别更好，并且误分类减少。定量指标（分布对齐、混淆矩阵）和定性见解（案例研究、运行时分析）都证实了模型的鲁棒性和效率。

Conclusion: 这项工作证明了将符号推理与神经模型相结合的价值，以实现语言动态领域中可解释的细粒度情感分析。

Abstract: Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.

</details>


### [41] [SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling](https://arxiv.org/abs/2510.15851)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 这篇论文探讨了如何利用语音大语言模型（speechLLMs）来改进口语理解（SLU）中的槽填充任务，旨在提高性能、鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的槽填充任务通过语音识别和自然语言理解组件的级联实现，效率低下。语音大语言模型的出现为实现更统一、生成式和遵循指令的语音理解任务提供了新途径，并有望通过零样本能力实现数据和计算效率，泛化到未见过的槽标签。

Method: 本文通过为槽填充任务创建经验上限，识别性能、鲁棒性和泛化差距，并提出改进训练数据、架构和训练策略来缩小与上限结果的差距。

Result: 本文展示了每项措施都大幅提高了性能，同时突出了实际挑战，并为利用这些新兴模型提供了经验指导和见解。

Conclusion: 利用语音大语言模型改进槽填充任务是可行的，通过优化训练数据、架构和策略可以显著提高模型性能，并有望在零样本学习方面取得突破。

Abstract: Slot filling is a crucial subtask in spoken language understanding (SLU),
traditionally implemented as a cascade of speech recognition followed by one or
more natural language understanding (NLU) components. The recent advent of
speech-based large language models (speechLLMs), which integrate speech and
textual foundation models, has opened new avenues for achieving speech
understanding tasks in a more unified, generative, and instruction-following
manner while promising data and compute efficiency with zero-shot abilities,
generalizing to unseen slot labels. We address the slot-filling task by
creating an empirical upper bound for the task, identifying performance,
robustness, and generalization gaps, and proposing improvements to the training
data, architecture, and training strategies to narrow the gap with the upper
bound result. We show that each of these measures improve performance
substantially, while highlighting practical challenges and providing empirical
guidance and insights for harnessing these emerging models.

</details>


### [42] [InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training](https://arxiv.org/abs/2510.15859)
*Pengkai Wang,Qi Zuo,Pengwei Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: 该论文介绍了一个名为ORBIT的框架，它利用基于规则的增量训练和动态生成的评估标准，显著提升了大型语言模型在医疗对话等开放性领域的表现，尤其是在缺乏明确奖励函数的场景下。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和编程等奖励可编程验证的领域取得了显著进展，但在创意写作、科学推理和医疗咨询等开放性领域，由于奖励模糊、主观或依赖于上下文，缺乏鲁棒的奖励函数，这限制了现有强化学习策略的应用。

Method: ORBIT框架通过以下方法弥补了现有技术的不足： 1. **合成对话生成**：框架能够生成模拟的对话数据。 2. **动态创建评估标准（rubrics）**：ORBIT不依赖外部医学知识或手动规则，而是动态生成用于评估模型表现的评估标准。 3. **增量强化学习过程**：利用这些评估标准来指导一个增量式的强化学习过程，逐步优化模型。 这种方法旨在应对开放性领域中奖励函数不明确的挑战，通过内部生成的反馈来塑造学习过程。

Result: 在Qwen3-4B-Instruct模型上实施ORBIT框架后，仅使用2k样本，模型在HealthBench-Hard基准上的性能从7.0显著提升至27.2。这一成绩在该规模的模型中达到了最先进的水平，并且分析证实，这种基于评估标准的强化学习在不同的咨询场景中都能持续提升性能。

Conclusion: 该研究强调了基于评估标准的反馈是一种可扩展的策略，能够有效推动大型语言模型在复杂、开放性任务（如医疗对话）中的发展。ORBIT框架的成功证明了在缺乏明确奖励函数的领域中，通过内部生成反馈来指导强化学习的可行性和高效性。

Abstract: Large Language Models (LLMs) have shown substantial advances through
reinforcement learning (RL), particularly in domains where rewards can be
programmatically verified, such as mathematics and code. In these areas, models
benefit from a well-defined operational base guided by explicit rule-based
objectives. However, this progress reveals a significant limitation: in
open-ended domains where rewards are ambiguous, subjective, or
context-dependent, such as creative writing, scientific reasoning, and notably
medical consultation, robust reward functions are lacking, making these areas
challenging for current RL strategies. To bridge this gap, we introduce ORBIT,
an open-ended rubric-based incremental training framework specifically designed
for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue
generation with the dynamic creation of rubrics, employing these rubrics to
direct an incremental RL process. In particular, this approach does not depend
on external medical knowledge or manual rules, instead utilizing rubric-guided
feedback to shape learning. When implemented on the Qwen3-4B-Instruct model,
our method can greatly enhance its performance on the HealthBench-Hard
benchmark from 7.0 to 27.2 using only 2k samples, thus achieving
state-of-the-art results for models of this scale. Our analysis confirms that
rubric-driven RL fos-ters consistent performance gains across diverse
consultation scenarios, going beyond simple numerical improvements. These
findings underscore rubric-based feedback as a scalable strategy for advancing
LLMs in intricate, open-ended tasks.

</details>


<div id='cs.IT'></div>

# cs.IT [[Back]](#toc)

### [43] [Adaptive Base Representation Theorem: An Alternative to Binary Number System](https://arxiv.org/abs/2510.15099)
*Ravin Kumar*

Main category: cs.IT

TL;DR: 本文介绍了自适应基表示（ABR）定理，并提出了一种新颖的数制，为数字计算机中的二进制数制提供了一种结构化的替代方案。


<details>
  <summary>Details</summary>
Motivation: 探索一种新型数制来替代二进制系统，以优化数字计算机中的数据表示。

Method: 提出了自适应基表示（ABR）数制，该数制能够唯一地表示每个十进制数，并使用与二进制编码相同数量的比特（n）。通过理论基础和数学公式证明ABR可以编码与二进制相同的整数范围。

Result: ABR数制可以唯一且等长地表示十进制数，编码范围与二进制相同，并且兼容现有的数据压缩算法（如霍夫曼编码和算术编码）以及错误检测和纠正机制（如汉明码）。

Conclusion: ABR数制在信息论和数字编码领域具有潜在应用，有望为数字数据表示和计算设计带来新方法。

Abstract: This paper introduces the Adaptive Base Representation (ABR) Theorem and
proposes a novel number system that offers a structured alternative to the
binary number system for digital computers. The ABR number system enables each
decimal number to be represented uniquely and using the same number of bits,
$n$, as the binary encoding. Theoretical foundations and mathematical
formulations demonstrate that ABR can encode the same integer range as binary,
validating its potential as a viable alternative. Additionally, the ABR number
system is compatible with existing data compression algorithms like Huffman
coding and arithmetic coding, as well as error detection and correction
mechanisms such as Hamming codes. We further explore practical applications,
including digital steganography, to illustrate the utility of ABR in
information theory and digital encoding, suggesting that the ABR number system
could inspire new approaches in digital data representation and computational
design.

</details>


### [44] [Outage-Aware Sum Rate Maximization in Movable Antennas-Enabled Systems](https://arxiv.org/abs/2510.15292)
*Guojie Hu,Qingqing Wu,Ming-Min Zhao,Wen Chen,Zhenyu Xiao,Kui Xu,Jiangbo Si*

Main category: cs.IT

TL;DR: 本文研究了可移动天线（MAs）在多输入单输出（MISO）系统中的应用，旨在通过联合优化天线位置和发射波束成形来最大化所有用户的中断感知和速率，同时满足每个用户的目标中断概率要求。


<details>
  <summary>Details</summary>
Motivation: 在时延敏感的场景中，用户避免周期性地发送训练信号进行信道估计，以避免额外的延迟。因此，基站（BS）仅依靠统计信道状态信息（CSI）以固定速率传输数据。

Method: 本文首先采用基于统计CSI的迫零波束成形设计。然后，引入一个重要引理来推导出信噪比（SINR）的紧密均值和方差。利用这些结果，进一步利用拉盖尔级数逼近，成功推导出SINR的封闭式和紧密CDF。最后，设计了投影梯度上升（PGA）方法来迭代更新天线位置，直到收敛。

Result: 数值结果表明，与传统固定位置天线（FPA）和其他竞争基准相比，本文提出的方案是有效的。

Conclusion: 本文通过联合优化天线位置和发射波束成形，在可移动天线MISO系统中实现了中断感知和速率的最大化，为时延敏感场景下的无线通信提供了有效的解决方案。

Abstract: In this paper, we investigate the movable antennas (MAs)-enabled
multiple-input-single-output (MISO) systems, where the base station (BS)
equipped with multiple MAs serves multiple single-antenna user. The
delay-sensitive scenario is considered, where users refrain from periodically
sending training signals to the BS for channel estimations to avoid additional
latency. As a result, the BS relies solely on the statistical channel state
information (CSI) to transmit data with a fixed rate. Under this setup, we aim
to maximize the outage-aware sum rate of all users, by jointly optimizing
antenna positions and the transmit beamforming at the BS, while satisfying the
given target outage probability requirement at each user. The problem is highly
non-convex, primarily because the exact cumulative distribution function (CDF)
of the received signal-to-interference-plus-noise ratio (SINR) of each user is
difficult to derive. To simplify analysis and without comprising performance,
we adopt the statistical CSI based zero-forcing beamforming design. We then
introduce one important lemma to derive the tight mean and variance of the
SINR. Leveraging these results, we further exploit the Laguerre series
approximation to successfully derive the closedform and tight CDF of the SINR.
Subsequently, the outageaware sum rate expression is presented but still
includes complex structure with respect to antenna positions. Facing this
challenge, the projected gradient ascent (PGA) method is developed to
iteratively update antenna positions until convergence. Numerical results
demonstrate the effectiveness of our proposed schemes compared to conventional
fixed-position antenna (FPA) and other competitive benchmarks.

</details>


### [45] [Subverting Flexible Multiuser Communications via Movable Antenna-Enabled Jammer](https://arxiv.org/abs/2510.15298)
*Guojie Hu,Qingqing Wu,Lipeng Zhu,Kui Xu,Guoxin Li,Jiangbo Si,Jian Ouyang,Tong-Xing Zheng*

Main category: cs.IT

TL;DR: 本文提出了一种利用可移动天线合法干扰机（MAJ）颠覆可疑多用户下行通信的方法。通过联合优化天线位置和干扰波束成形，MAJ可以最小化可疑通信的收益，同时考虑到可疑发射机（ST）的响应行为。文章提出了两种不同的收益函数，并开发了相应的基于交替优化的算法来解决问题。


<details>
  <summary>Details</summary>
Motivation: 可移动天线（MA）技术能够通过自适应天线位置调整来重新配置无线信道，为提高系统性能带来了额外的空间自由度。本文旨在从安全角度出发，利用MA合法干扰机（MAJ）颠覆可疑的多用户下行通信，从而提高安全性。

Method: 本文提出了一种针对两种不同收益函数（所有可疑接收机（SRs）的总速率或所有SRs中的最小速率）的优化方法。首先，针对MAJ的行动，确定ST的最优反应行为。其次，将问题简化为两个子问题，并开发了有效的基于交替优化的算法进行迭代求解。此外，还研究了两个SRs的特殊情况，并分析了MAJ实现全局性能下限的理想天线部署方案。

Result: 数值结果表明，与传统固定位置天线（FPA）和其他竞争基准相比，本文提出的方案是有效的。

Conclusion: 本文成功地利用可移动天线合法干扰机（MAJ）颠覆了可疑的多用户下行通信。通过联合优化天线位置和干扰波束成形，并考虑到可疑发射机（ST）的反应行为，MAJ能够有效最小化可疑通信的收益。提出的算法和分析结果为MA在无线安全领域的应用提供了有价值的见解。

Abstract: Movable antenna (MA) is an emerging technology which can reconfigure wireless
channels via adaptive antenna position adjustments at transceivers, thereby
bringing additional spatial degrees of freedom for improving system
performance. In this paper, from a security perspective, we exploit the
MAenabled legitimate jammer (MAJ) to subvert suspicious multiuser downlink
communications consisting of one suspicious transmitter (ST) and multiple
suspicious receivers (SRs). Specifically, our objective is to minimize the
benefit (the sum rate of all SRs or the minimum rate among all SRs) of such
suspicious communications, by jointly optimizing antenna positions and the
jamming beamforming at the MAJ. However, the key challenge lies in that given
the MAJ's actions, the ST can reactively adjust its power allocations to
instead maximize its benefit for mitigating the unfavorable interference. Such
flexible behavior of the ST confuses the optimization design of the MAJ to a
certain extent. Facing this difficulty, corresponding to the above two
different benefits: i) we respectively determine the optimal behavior of the ST
given the MAJ's actions; ii) armed with these, we arrive at two simplified
problems and then develop effective alternating optimization based algorithms
to iteratively solve them. In addition to these, we also focus on the special
case of two SRs, and reveal insightful conclusions about the deployment rule of
antenna positions at the MAJ. Furthermore, we analyze the ideal antenna
deployment scheme at the MAJ for achieving the globally performance lower
bound. Numerical results demonstrate the effectiveness of our proposed schemes
compared to conventional fixed-position antenna (FPA) and other competitive
benchmarks.

</details>


### [46] [New generalizations of circular complex fuzzy sets and Gaussian weighted aggregation operators](https://arxiv.org/abs/2510.15605)
*Yelda Gülfırat,Mehmet Ünver*

Main category: cs.IT

TL;DR: 本文介绍了一种新的模糊集推广：圆形复数q-阶正交对模糊集（CCq-ROFS），它统一了现有的圆形复数直觉模糊集和复数q-阶正交对模糊集。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的广义模糊集——圆形复数q-阶正交对模糊集（CCq-ROFS），以统一现有框架，并通过高斯框架扩展实现更平滑和统计学意义上的不确定性表示。

Method: 本文提出了圆形复数q-阶正交对模糊集（CCq-ROFS），其具体方法是：1. 统一了现有的圆形复数直觉模糊集（CCIFSs）和复数q-阶正交对模糊集。2. 将高斯框架推广到CCq-ROFSs，旨在实现更平滑且具有统计学意义的不确定性表示。3. 运用高斯三角范数和余范数，构建了新的基于高斯聚合算子。4. 引入了高斯加权算术和高斯加权几何聚合算子，以实现模糊建模和决策制定中隶属度和非隶属度信息的一致集成。

Result: 推广了圆形复数q-阶正交对模糊集（CCq-ROFS），并通过扩展高斯框架，实现了更平滑、统计意义更强的不确定性表示。构建了新的基于高斯的聚合算子以及高斯加权算术和高斯加权几何聚合算子。

Conclusion: 本文提出了圆形复数q-阶正交对模糊集（CCq-ROFS）这一新的广义模糊集，为不确定性建模提供了更灵活和稳健的工具，通过引入高斯框架和新的聚合算子，显著提升了模糊系统在决策制定和信息集成方面的性能。

Abstract: In this paper, we introduce the concept of the circular complex $q$-rung
orthopair fuzzy set (CC$q$-ROFS) as a novel generalization that unifies the
existing frameworks of circular complex intuitionistic fuzzy sets (CCIFSs) and
complex $q$-rung orthopair fuzzy sets. If $q = 2$, the structure is referred to
as a circular complex Pythagorean fuzzy set, and if $q = 3$, it is called a
circular complex Fermatean fuzzy set. The proposed approach extends the
Gaussian-based framework to the CC$q$-ROFSs, aiming to achieve a smoother and
statistically meaningful representation of uncertainty. Within this setting,
new Gaussian-based aggregation operators for CC$q$-ROFSs are constructed by
employing the Gaussian triangular norm and conorm. Furthermore,
Gaussian-weighted arithmetic and Gaussian-weighted geometric aggregation
operators are formulated to enable consistent integration of membership and
non-membership information for fuzzy modeling and decision-making.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [47] [The Tree-SNE Tree Exists](https://arxiv.org/abs/2510.15014)
*Jack Kendrick*

Main category: stat.ML

TL;DR: 本文探讨了高维数据聚类和可视化的“尺度问题”，并提出了一种名为t-SNE树（tree-SNE）的新方法，通过增加一个尺度参数来解决标准t-SNE和UMAP等方法在处理不同尺度聚类需求时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的高维数据聚类和可视化技术（如t-SNE和UMAP）在处理不同尺度的聚类任务时存在局限性，即“尺度问题”，不同的任务可能需要区分不同粒度的数据特征，而这些方法缺乏对这种尺度变化的有效建模。

Method: 本文重新审视了Robinson & Pierce-Hoffman提出的利用t-SNE底层尺度对称性的思想，将2维嵌入扩展到(2+1)维嵌入，其中新增的参数用于表示尺度。由此提出了t-SNE树（tree-SNE）方法。

Result: 本文证明了在测量为0的集合之外的所有初始条件下，最优嵌入连续地依赖于尺度参数，这意味着t-SNE树是存在的。该方法可以扩展到其他吸引-排斥方法，并通过多个例子进行了验证。

Conclusion: t-SNE树（tree-SNE）通过引入尺度参数，有效地解决了高维数据聚类和可视化中的“尺度问题”，提高了数据分析的灵活性和准确性。未来研究可以探索其在更多吸引-排斥方法中的应用。

Abstract: The clustering and visualisation of high-dimensional data is a ubiquitous
task in modern data science. Popular techniques include nonlinear
dimensionality reduction methods like t-SNE or UMAP. These methods face the
`scale-problem' of clustering: when dealing with the MNIST dataset, do we want
to distinguish different digits or do we want to distinguish different ways of
writing the digits? The answer is task dependent and depends on scale. We
revisit an idea of Robinson & Pierce-Hoffman that exploits an underlying
scaling symmetry in t-SNE to replace 2-dimensional with (2+1)-dimensional
embeddings where the additional parameter accounts for scale. This gives rise
to the t-SNE tree (short: tree-SNE). We prove that the optimal embedding
depends continuously on the scaling parameter for all initial conditions
outside a set of measure 0: the tree-SNE tree exists. This idea conceivably
extends to other attraction-repulsion methods and is illustrated on several
examples.

</details>


### [48] [The Coverage Principle: How Pre-training Enables Post-Training](https://arxiv.org/abs/2510.15020)
*Fan Chen,Audrey Huang,Noah Golowich,Sadhika Malladi,Adam Block,Jordan T. Ash,Akshay Krishnamurthy,Dylan J. Foster*

Main category: stat.ML

TL;DR: 本文提出一个“覆盖率原则”，用以解释大型语言模型预训练阶段的目标函数（交叉熵）与下游任务表现之间的关系。


<details>
  <summary>Details</summary>
Motivation: 预训练阶段成功的量化指标（如交叉熵损失）与下游任务表现之间关系 poorly understood。

Method: 本文从理论角度提出了“覆盖率”的概念，并深入探讨了“覆盖率原则”，即下一词元预测如何隐式地优化模型以获得良好的覆盖率。

Result: 本文揭示了“覆盖率”在预测下游性能方面的作用，即覆盖率比交叉熵能更快更好地泛化，避免了对序列长度等问题相关参数的虚假依赖。

Conclusion: 本文提出了几种提高覆盖率的实用算法干预措施，包括模型/检查点选择程序、梯度归一化方案和测试时解码策略。

Abstract: Language models demonstrate remarkable abilities when pre-trained on large
text corpora and fine-tuned for specific tasks, but how and why pre-training
shapes the success of the final model remains poorly understood. Notably,
although pre-training success is often quantified by cross entropy loss,
cross-entropy can be a poor predictor of downstream performance. Instead, we
provide a theoretical perspective on this relationship through the lens of
\emph{coverage}, which quantifies the probability mass the pre-trained model
places on high-quality responses and which is necessary and sufficient for
post-training and test-time scaling methods such as Best-of-N to succeed. Our
main results develop an understanding of \emph{the coverage principle}, a
phenomenon whereby next-token prediction implicitly optimizes toward a model
with good coverage. In particular, we uncover a mechanism that explains the
power of coverage in predicting downstream performance: \emph{coverage
generalizes faster than cross entropy}, avoiding spurious dependence on
problem-dependent parameters such as the sequence length. We also study
practical algorithmic interventions with provable benefits for improving
coverage, including (i) model/checkpoint selection procedures, (ii) gradient
normalization schemes, and (iii) test-time decoding strategies.

</details>


### [49] [The Minimax Lower Bound of Kernel Stein Discrepancy Estimation](https://arxiv.org/abs/2510.15058)
*Jose Cribeiro-Ramallo,Agnideep Aich,Florian Kalinke,Ashit Baran Aich,Zoltán Szabó*

Main category: stat.ML

TL;DR: 本文分析了核Stein差异（KSD）估计器，建立了其Minimax下限，并揭示了KSD估计的难度可能随维度d呈指数增长。


<details>
  <summary>Details</summary>
Motivation: 作者旨在解决现有KSD估计器收敛速度的优化问题，并通过理论分析证明其最优性。

Method: 通过两种不同的证明策略，作者建立了KSD估计的Minimax下限，并具体分析了Langevin-Stein算子在$\\mathbb R^d$上的KSD估计。

Result: 建立了KSD估计的Minimax下限为$n^{-1/2}$，证明了现有估计器的最优性。研究发现，在高维空间中，KSD估计的难度可能会随维度呈指数增长。

Conclusion: 本文通过建立KSD估计的Minimax下限，解决了KSD估计器收敛速度的优化问题，并强调了高维数据下KSD估计的挑战性。

Abstract: Kernel Stein discrepancies (KSDs) have emerged as a powerful tool for
quantifying goodness-of-fit over the last decade, featuring numerous successful
applications. To the best of our knowledge, all existing KSD estimators with
known rate achieve $\sqrt n$-convergence. In this work, we present two
complementary results (with different proof strategies), establishing that the
minimax lower bound of KSD estimation is $n^{-1/2}$ and settling the optimality
of these estimators. Our first result focuses on KSD estimation on $\mathbb
R^d$ with the Langevin-Stein operator; our explicit constant for the Gaussian
kernel indicates that the difficulty of KSD estimation may increase
exponentially with the dimensionality $d$. Our second result settles the
minimax lower bound for KSD estimation on general domains.

</details>


### [50] [Beyond PCA: Manifold Dimension Estimation via Local Graph Structure](https://arxiv.org/abs/2510.15141)
*Zelong Bi,Pierre Lafaye de Micheaux*

Main category: stat.ML

TL;DR: 本文提出了一种新的流形维度估计框架，该框架通过将PCA与基于回归的技术相结合来捕获流形的局部图结构。


<details>
  <summary>Details</summary>
Motivation: 局部PCA在估计流形本征维度方面表现出色，但其假设局部平坦性。曲率调整PCA（CA-PCA）通过明确考虑底层流形的曲率改进了这一点。本文在此基础上，旨在进一步提高流形维度估计的准确性。

Method: 本文提出了一种将PCA与基于回归的技术相结合的通用框架，以捕获流形的局部图结构。在此框架内，引入了两种代表性估计器：二次嵌入（QE）和全最小二乘（TLS）。

Result: 在合成数据集和真实世界数据集上的实验表明，本文提出的方法与现有最先进的方法相比，具有竞争力，并且通常表现更好。

Conclusion: 本文提出的通用框架，通过结合PCA和回归技术，有效地提高了流形维度估计的准确性，并有望在实际应用中取得更好的效果。

Abstract: Local principal component analysis (Local PCA) has proven to be an effective
tool for estimating the intrinsic dimension of a manifold. More recently,
curvature-adjusted PCA (CA-PCA) has improved upon this approach by explicitly
accounting for the curvature of the underlying manifold, rather than assuming
local flatness. Building on these insights, we propose a general framework for
manifold dimension estimation that captures the manifold's local graph
structure by integrating PCA with regression-based techniques. Within this
framework, we introduce two representative estimators: quadratic embedding (QE)
and total least squares (TLS). Experiments on both synthetic and real-world
datasets demonstrate that these methods perform competitively with, and often
outperform, state-of-the-art alternatives.

</details>


### [51] [Transfer Learning for Benign Overfitting in High-Dimensional Linear Regression](https://arxiv.org/abs/2510.15337)
*Yeichan Kim,Ilmun Kim,Seyoung Park*

Main category: stat.ML

TL;DR: 本文提出了一种新颖的“两步式迁移最小二范数插值器”（Transfer MNI）方法，并对其在不同条件下的非渐近超额风险进行了理论分析和实验验证。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习中，迁移学习和过参数化模型（如最小二范数插值器MNI）都显示出卓越的性能和泛化能力。然而，这两者的结合尚未得到充分研究。

Method: 提出了一种新颖的“两步式迁移最小二范数插值器”（Transfer MNI）方法，该方法通过两个步骤实现知识迁移。此外，我们开发了一种数据驱动的程序来识别信息源，并引入了一种集成方法来结合多个信息丰富的Transfer MNI。

Result: 我们量化了Transfer MNI的非渐近超额风险，并确定了其优于仅使用目标数据训练的MNI的条件。分析揭示了在“免费午餐”协变量偏移情况下，利用异构数据可以在有限成本下实现知识迁移的好处。有限样本实验证明了我们方法对模型和数据异构性的鲁棒性，并证实了其优势。

Conclusion: 通过结合迁移学习和MNI，我们提出的Transfer MNI方法在特定条件下能够显著提高目标任务的性能，尤其是在存在协变量偏移的情况下。该方法为在过参数化模型中有效利用异构数据提供了新的视角和实用工具。

Abstract: Transfer learning is a key component of modern machine learning, enhancing
the performance of target tasks by leveraging diverse data sources.
Simultaneously, overparameterized models such as the minimum-$\ell_2$-norm
interpolator (MNI) in high-dimensional linear regression have garnered
significant attention for their remarkable generalization capabilities, a
property known as benign overfitting. Despite their individual importance, the
intersection of transfer learning and MNI remains largely unexplored. Our
research bridges this gap by proposing a novel two-step Transfer MNI approach
and analyzing its trade-offs. We characterize its non-asymptotic excess risk
and identify conditions under which it outperforms the target-only MNI. Our
analysis reveals free-lunch covariate shift regimes, where leveraging
heterogeneous data yields the benefit of knowledge transfer at limited cost. To
operationalize our findings, we develop a data-driven procedure to detect
informative sources and introduce an ensemble method incorporating multiple
informative Transfer MNIs. Finite-sample experiments demonstrate the robustness
of our methods to model and data heterogeneity, confirming their advantage.

</details>


### [52] [RankSEG-RMA: An Efficient Segmentation Algorithm via Reciprocal Moment Approximation](https://arxiv.org/abs/2510.15362)
*Zixun Wang,Ben Dai*

Main category: stat.ML

TL;DR: 这篇论文提出了一种通过倒数矩近似（RMA）来改进RankSEG框架的方法，解决了其计算复杂度和对重叠分割设置的限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有的语义分割方法通常通过像素级类别概率和argmax操作来获得最终预测，但这往往导致不一致或次优的结果，因为它们没有直接最大化分割指标。RankSEG框架被提出以直接优化Dice和IoU指标，但其计算成本高且仅适用于重叠分割设置。

Method: 本文通过倒数矩近似（RMA）改进了RankSEG算法，提出了RankSEG-RMA。RankSEG-RMA将RankDice和RankIoU的复杂度都降低到O(d)。此外，通过RMA的启发，开发了一种像素级评分函数，使其能够适用于非重叠分割设置。

Result: RankSEG-RMA在保持与RankSEG相当性能的同时，显著降低了计算复杂度（从O(d log d)或O(d^2)降至O(d)）。此外，该方法可以应用于非重叠分割设置，扩展了RankSEG的适用范围。

Conclusion: RankSEG-RMA框架有效解决了RankSEG的计算效率低和适用范围受限的问题，使其在实际应用中更具可行性和广泛性。

Abstract: Semantic segmentation labels each pixel in an image with its corresponding
class, and is typically evaluated using the Intersection over Union (IoU) and
Dice metrics to quantify the overlap between predicted and ground-truth
segmentation masks. In the literature, most existing methods estimate
pixel-wise class probabilities, then apply argmax or thresholding to obtain the
final prediction. These methods have been shown to generally lead to
inconsistent or suboptimal results, as they do not directly maximize
segmentation metrics. To address this issue, a novel consistent segmentation
framework, RankSEG, has been proposed, which includes RankDice and RankIoU
specifically designed to optimize the Dice and IoU metrics, respectively.
Although RankSEG almost guarantees improved performance, it suffers from two
major drawbacks. First, it is its computational expense-RankDice has a
complexity of O(d log d) with a substantial constant factor (where d represents
the number of pixels), while RankIoU exhibits even higher complexity O(d^2),
thus limiting its practical application. For instance, in LiTS, prediction with
RankSEG takes 16.33 seconds compared to just 0.01 seconds with the argmax rule.
Second, RankSEG is only applicable to overlapping segmentation settings, where
multiple classes can occupy the same pixel, which contrasts with standard
benchmarks that typically assume non-overlapping segmentation. In this paper,
we overcome these two drawbacks via a reciprocal moment approximation (RMA) of
RankSEG with the following contributions: (i) we improve RankSEG using RMA,
namely RankSEG-RMA, reduces the complexity of both algorithms to O(d) while
maintaining comparable performance; (ii) inspired by RMA, we develop a
pixel-wise score function that allows efficient implementation for
non-overlapping segmentation settings.

</details>


### [53] [Kernel Regression in Structured Non-IID Settings: Theory and Implications for Denoising Score Learning](https://arxiv.org/abs/2510.15363)
*Dechen Zhang,Zhenmei Shi,Yi Zhang,Yingyu Liang,Difan Zou*

Main category: stat.ML

TL;DR: 本文探讨了核岭回归（KRR）在非独立同分布（non-i.i.d.）数据上的泛化能力，特别是在信号-噪声因果结构存在的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有KRR理论主要针对独立同分布数据，但现实世界数据常具有结构化依赖，如去噪得分学习中多 Denoising score learning 中，多个噪声观测值来源于共享的底层信号。

Method: 开发了一种新颖的块分解方法，实现了对依赖数据的精确集中度分析。

Result: 推导了KRR的超额风险 H C （ S （ R ） ） H_C(S(R)) 界限，这些界限明确依赖于核谱、因果结构参数和采样机制。

Conclusion: 这项工作推进了KRR理论，并为分析现代机器学习应用中的依赖数据提供了实用工具。

Abstract: Kernel ridge regression (KRR) is a foundational tool in machine learning,
with recent work emphasizing its connections to neural networks. However,
existing theory primarily addresses the i.i.d. setting, while real-world data
often exhibits structured dependencies - particularly in applications like
denoising score learning where multiple noisy observations derive from shared
underlying signals. We present the first systematic study of KRR generalization
for non-i.i.d. data with signal-noise causal structure, where observations
represent different noisy views of common signals. By developing a novel
blockwise decomposition method that enables precise concentration analysis for
dependent data, we derive excess risk bounds for KRR that explicitly depend on:
(1) the kernel spectrum, (2) causal structure parameters, and (3) sampling
mechanisms (including relative sample sizes for signals and noises). We further
apply our results to denoising score learning, establishing generalization
guarantees and providing principled guidance for sampling noisy data points.
This work advances KRR theory while providing practical tools for analyzing
dependent data in modern machine learning applications.

</details>


### [54] [Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction](https://arxiv.org/abs/2510.15422)
*Lin Wang*

Main category: stat.ML

TL;DR: 这篇论文全面回顾了开放世界机器学习中信息论方法，探讨了其在开放世界机器学习中的应用、不足以及未来的发展方向。


<details>
  <summary>Details</summary>
Motivation: 尽管在开放集识别、新颖性检测和持续学习方面取得了显著进展，但该领域仍缺乏一个统一的理论基础，无法量化不确定性、表征信息传递并解释动态非平稳环境中的学习适应性。

Method: 本文从信息理论的角度对开放世界机器学习进行了全面综述，重点介绍了熵、互信息和Kullback-Leibler散度等核心概念如何为描述开放世界条件下的知识获取、不确定性抑制和风险控制提供数学语言。文章将最近的研究成果归纳为三个主要研究方向：1. 信息理论开放集识别，实现对未知事物的安全拒绝；2. 信息驱动的新颖性发现，引导新概念的形成；3. 信息保持的持续学习，确保稳定的长期适应。此外，本文还讨论了信息论与可证明学习框架之间的理论联系，包括PAC-贝叶斯界、开放空间风险理论和因果信息流等，以期为可证明和值得信赖的开放世界智能奠定基础。

Result: 通过对信息论方法的综述，本文强调了其在描述开放世界条件下知识获取、不确定性抑制和风险控制方面的作用。文章将研究归纳为信息论开放集识别、信息驱动的新颖性发现和信息保持的持续学习三大方向。同时，阐明了信息论与可证明学习框架之间的理论联系，包括PAC-贝叶斯界、开放空间风险理论和因果信息流等。

Conclusion: 本文指出了开放世界机器学习中信息论方法的应用与不足，并展望了未来的研究方向，例如信息风险的量化、动态互信息界的开发、多模态信息融合以及信息论与因果推理和世界模型学习的整合等。

Abstract: Open world Machine Learning (OWML) aims to develop intelligent systems
capable of recognizing known categories, rejecting unknown samples, and
continually learning from novel information. Despite significant progress in
open set recognition, novelty detection, and continual learning, the field
still lacks a unified theoretical foundation that can quantify uncertainty,
characterize information transfer, and explain learning adaptability in
dynamic, nonstationary environments. This paper presents a comprehensive review
of information theoretic approaches in open world machine learning, emphasizing
how core concepts such as entropy, mutual information, and Kullback Leibler
divergence provide a mathematical language for describing knowledge
acquisition, uncertainty suppression, and risk control under open world
conditions. We synthesize recent studies into three major research axes:
information theoretic open set recognition enabling safe rejection of unknowns,
information driven novelty discovery guiding new concept formation, and
information retentive continual learning ensuring stable long term adaptation.
Furthermore, we discuss theoretical connections between information theory and
provable learning frameworks, including PAC Bayes bounds, open-space risk
theory, and causal information flow, to establish a pathway toward provable and
trustworthy open world intelligence. Finally, the review identifies key open
problems and future research directions, such as the quantification of
information risk, development of dynamic mutual information bounds, multimodal
information fusion, and integration of information theory with causal reasoning
and world model learning.

</details>


### [55] [Robust Optimization in Causal Models and G-Causal Normalizing Flows](https://arxiv.org/abs/2510.15458)
*Gabriele Visentin,Patrick Cheridito*

Main category: stat.ML

TL;DR: 该论文提出了一种新的归一化流架构，用于处理因果模型中的干预鲁棒优化问题，并在数据增强方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 在因果模型中，干预鲁棒优化问题在G-因果Wasserstein距离下是连续的，但在标准Wasserstein距离下可能是不连续的。这表明在为此类任务进行数据增强时，使用尊重因果结构的生成模型非常重要。

Method: 提出了一种新的归一化流架构，该架构满足因果结构模型的通用近似性质，并且可以有效地训练以最小化G-因果Wasserstein距离。

Result: 经验证明，该模型在因果回归和因果因子模型中的均值-方差投资组合优化数据增强方面优于标准（非因果）生成模型。

Conclusion: 该研究强调了在处理因果模型中的干预鲁棒优化问题时，使用尊重因果结构的生成模型的重要性，并提出了一种有效的归一化流架构来解决这一问题。

Abstract: In this paper, we show that interventionally robust optimization problems in
causal models are continuous under the $G$-causal Wasserstein distance, but may
be discontinuous under the standard Wasserstein distance. This highlights the
importance of using generative models that respect the causal structure when
augmenting data for such tasks. To this end, we propose a new normalizing flow
architecture that satisfies a universal approximation property for causal
structural models and can be efficiently trained to minimize the $G$-causal
Wasserstein distance. Empirically, we demonstrate that our model outperforms
standard (non-causal) generative models in data augmentation for causal
regression and mean-variance portfolio optimization in causal factor models.

</details>


### [56] [Online Policy Learning via a Self-Normalized Maximal Inequality](https://arxiv.org/abs/2510.15483)
*Samuel Girard,Aurélien Bibaut,Houssam Zenati*

Main category: stat.ML

TL;DR: 这篇论文提出了一种新的自正则化极大不等式，用于鞅经验过程，解决了适应性实验中数据依赖性导致的标准学习保证失效的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的独立同分布假设在适应性实验产生的相关数据面前失效，导致经典的集中界和标准学习保证不再有效。

Method: 论文开发了一种用于鞅经验过程的自正则化极大不等式。在此基础上，提出了一种自适应样本方差惩罚程序，平衡了经验损失和样本方差。进而推导出一个新的方差正则化悲观离策略学习目标。

Result: 推导出的方差正则化悲观离策略学习目标具有超越风险保证。当与序列更新结合，并在标准复杂度与边缘条件下，所产生的估计器在参数和非参数区间都能实现快速收敛，优于通常的$1/\sqrt{n}$基线。数值模拟也验证了这种方法的实际增益。

Conclusion: 该研究提出了一种有效处理适应性实验相关数据的方法，通过引入自正则化极大不等式和方差正则化学习目标，显著提升了学习算法的收敛速度和保证。

Abstract: Adaptive experiments produce dependent data that break i.i.d. assumptions
that underlie classical concentration bounds and invalidate standard learning
guarantees. In this paper, we develop a self-normalized maximal inequality for
martingale empirical processes. Building on this, we first propose an adaptive
sample-variance penalization procedure which balances empirical loss and sample
variance, valid for general dependent data. Next, this allows us to derive a
new variance-regularized pessimistic off-policy learning objective, for which
we establish excess-risk guarantees. Subsequently, we show that, when combined
with sequential updates and under standard complexity and margin conditions,
the resulting estimator achieves fast convergence rates in both parametric and
nonparametric regimes, improving over the usual $1/\sqrt{n}$
  baseline. We complement our theoretical findings with numerical simulations
that illustrate the practical gains of our approach.

</details>


### [57] [Geometric Convergence Analysis of Variational Inference via Bregman Divergences](https://arxiv.org/abs/2510.15548)
*Sushil Bohara,Amedeo Roberto Esposito*

Main category: stat.ML

TL;DR: 本文提出了一种新的变分推断（VI）收敛性分析理论框架。


<details>
  <summary>Details</summary>
Motivation: 变分推断（VI）通过优化证据下界（ELBO）为贝叶斯推断提供了一个可扩展的框架，但由于目标在欧几里得空间中的非凸性和非光滑性，收敛性分析仍然具有挑战性。

Method: 通过利用分布的指数族结构，将负ELBO表示为相对于对数分区函数的Bregman散度，从而对优化前景进行几何分析。 Bregman表示允许弱单调性特性，这为严格的收敛性分析提供了足够的结构。通过在参数空间中的射线上推导目标函数的界限，建立了由Fisher信息矩阵的谱特征控制的属性。

Result: 建立了具有恒定和递减步长的梯度下降算法的非渐近收敛速度。

Conclusion: 所提出的几何框架为梯度下降算法提供了非渐近收敛保证。

Abstract: Variational Inference (VI) provides a scalable framework for Bayesian
inference by optimizing the Evidence Lower Bound (ELBO), but convergence
analysis remains challenging due to the objective's non-convexity and
non-smoothness in Euclidean space. We establish a novel theoretical framework
for analyzing VI convergence by exploiting the exponential family structure of
distributions. We express negative ELBO as a Bregman divergence with respect to
the log-partition function, enabling a geometric analysis of the optimization
landscape. We show that this Bregman representation admits a weak monotonicity
property that, while weaker than convexity, provides sufficient structure for
rigorous convergence analysis. By deriving bounds on the objective function
along rays in parameter space, we establish properties governed by the spectral
characteristics of the Fisher information matrix. Under this geometric
framework, we prove non-asymptotic convergence rates for gradient descent
algorithms with both constant and diminishing step sizes.

</details>


### [58] [Kernel-Based Evaluation of Conditional Biological Sequence Models](https://arxiv.org/abs/2510.15601)
*Pierre Glaser,Steffanie Paul,Alissa M. Hummer,Charlotte M. Deane,Debora S. Marks,Alan N. Amin*

Main category: stat.ML

TL;DR: 本文提出了一种基于核函数的方法，用于评估条件序列模型的设计并调整其超参数，主要关注计算生物学问题。


<details>
  <summary>Details</summary>
Motivation: 开发一套基于核函数的工具来评估条件序列模型的设计并调整其超参数，特别是在计算生物学领域。现有的模型评估方法可能不足以准确衡量真实条件分布与模型估计之间的差异。

Method: 本文提出了一种新的度量方法，称为增强条件最大均值差异（ACMMD），用于衡量真实条件分布与模型估计之间的差异。ACMMD可以从数据中进行无偏估计，以量化模型的绝对拟合度，并可用于假设检验和评估模型可靠性。

Result: 通过分析流行的蛋白质设计模型ProteinMPNN，我们发现可以拒绝ProteinMPNN适合其各种蛋白质家族数据的假设，并且可以通过调整模型的温度超参数来实现更好的拟合。

Conclusion: ACMMD是一种有效的工具，可以用来评估条件序列模型的拟合度，并能帮助调优模型超参数，尤其在计算生物学问题中展现出其价值。

Abstract: We propose a set of kernel-based tools to evaluate the designs and tune the
hyperparameters of conditional sequence models, with a focus on problems in
computational biology. The backbone of our tools is a new measure of
discrepancy between the true conditional distribution and the model's estimate,
called the Augmented Conditional Maximum Mean Discrepancy (ACMMD). Provided
that the model can be sampled from, the ACMMD can be estimated unbiasedly from
data to quantify absolute model fit, integrated within hypothesis tests, and
used to evaluate model reliability. We demonstrate the utility of our approach
by analyzing a popular protein design model, ProteinMPNN. We are able to reject
the hypothesis that ProteinMPNN fits its data for various protein families, and
tune the model's temperature hyperparameter to achieve a better fit.

</details>


### [59] [Disentanglement of Sources in a Multi-Stream Variational Autoencoder](https://arxiv.org/abs/2510.15669)
*Veranika Boukun,Jörg Lücke*

Main category: stat.ML

TL;DR: 本文提出了一种多流变分自动编码器（MS-VAE）方法，该方法利用离散潜在变量组合来自不同源的VAE表示，并应用于手写数字分离和说话人日志任务，取得了良好的分离效果。


<details>
  <summary>Details</summary>
Motivation: 传统的VAE在连续潜在空间中寻求解缠表示，但本文旨在探索使用离散潜在变量结合单个源的VAE表示，以解决学习解缠表示的问题。

Method: 本文提出了一种多流VAE（MS-VAE）方法，通过离散潜在变量结合单个源的VAE表示。具体地，该方法基于一个明确的源组合模型，并使用线性组合模型，这对于声学数据非常适用。文章详细推导了其推断和学习方程。

Result: 在叠加手写数字的分离任务中，MS-VAE实现了清晰的数字分离。在说话人日志任务中，该方法表现出特别低的漏检率。数值实验进一步强调了该方法在不同监督量和训练数据下的灵活性。

Conclusion: MS-VAE是一种领域无关的方法，能够有效地将来源分离到不同的流中。它在手写数字分离和说话人日志任务中表现出色，尤其是在声学数据方面具有良好的应用前景。

Abstract: Variational autoencoders (VAEs) are a leading approach to address the problem
of learning disentangled representations. Typically a single VAE is used and
disentangled representations are sought in its continuous latent space. Here we
explore a different approach by using discrete latents to combine
VAE-representations of individual sources. The combination is done based on an
explicit model for source combination, and we here use a linear combination
model which is well suited, e.g., for acoustic data. We formally define such a
multi-stream VAE (MS-VAE) approach, derive its inference and learning
equations, and we numerically investigate its principled functionality. The
MS-VAE is domain-agnostic, and we here explore its ability to separate sources
into different streams using superimposed hand-written digits, and mixed
acoustic sources in a speaker diarization task. We observe a clear separation
of digits, and on speaker diarization we observe an especially low rate of
missed speakers. Numerical experiments further highlight the flexibility of the
approach across varying amounts of supervision and training data.

</details>


### [60] [Error analysis of a compositional score-based algorithm for simulation-based inference](https://arxiv.org/abs/2510.15817)
*Camille Touron,Gabriel V. Cardoso,Julyan Arbel,Pedro L. C. Rodrigues*

Main category: stat.ML

TL;DR: 本文探讨了模拟依赖推断 (SBI) 中组合多个观测值以改善参数推断的问题。特别关注了分数扩散方法中组合分数因误差累积可能导致的采样质量下降问题。


<details>
  <summary>Details</summary>
Motivation: 模拟依赖推断 (SBI) 在应用科学中广泛用于估计随机模型参数，但如何有效结合多个观测值以提高参数推断和获得更清晰的后验分布是一个核心问题。

Method: 本文研究了 Linhart 等人（2024）提出的 GAUSS 算法产生的组合分数，并建立了其均方误差的上限，该上限与个体分数误差和观测数量有关。

Result: 在误差累积问题尚未被探索的背景下，本文建立了组合分数均方误差的上限，并使用高斯示例验证了理论发现。

Conclusion: 本文通过理论分析，建立了组合分数的均方误差上限，揭示了随着观测数量增加，误差累积对采样质量的影响，为SBI领域提供了新的见解。

Abstract: Simulation-based inference (SBI) has become a widely used framework in
applied sciences for estimating the parameters of stochastic models that best
explain experimental observations. A central question in this setting is how to
effectively combine multiple observations in order to improve parameter
inference and obtain sharper posterior distributions. Recent advances in
score-based diffusion methods address this problem by constructing a
compositional score, obtained by aggregating individual posterior scores within
the diffusion process. While it is natural to suspect that the accumulation of
individual errors may significantly degrade sampling quality as the number of
observations grows, this important theoretical issue has so far remained
unexplored. In this paper, we study the compositional score produced by the
GAUSS algorithm of Linhart et al. (2024) and establish an upper bound on its
mean squared error in terms of both the individual score errors and the number
of observations. We illustrate our theoretical findings on a Gaussian example,
where all analytical expressions can be derived in a closed form.

</details>


### [61] [Blackwell's Approachability for Sequential Conformal Inference](https://arxiv.org/abs/2510.15824)
*Guillaume Principato,Gilles Stoltz*

Main category: stat.ML

TL;DR: 本文分析了Blackwell方法理论框架下非交换环境中的共形推断。


<details>
  <summary>Details</summary>
Motivation: 作者将自适应共形推断（ACI）重新定义为重复二人矢量有限博弈，并描述了可实现的覆盖-效率权衡。

Method: 作者在对手策略可能受限的情况下，构建了覆盖率和效率目标，并设计了基于校准的可接近性策略来实现这些目标。

Result: 所提出的算法在理论上具有很强的保证。

Conclusion: 该算法在实践中可能受限于计算负荷。

Abstract: We study conformal inference in non-exchangeable environments through the
lens of Blackwell's theory of approachability. We first recast adaptive
conformal inference (ACI, Gibbs and Cand\`es, 2021) as a repeated two-player
vector-valued finite game and characterize attainable coverage--efficiency
tradeoffs. We then construct coverage and efficiency objectives under potential
restrictions on the adversary's play, and design a calibration-based
approachability strategy to achieve these goals. The resulting algorithm enjoys
strong theoretical guarantees and provides practical insights, though its
computational burden may limit deployment in practice.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [62] [Beyond Outcome-Based Imperfect-Recall: Higher-Resolution Abstractions for Imperfect-Information Games](https://arxiv.org/abs/2510.15094)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.GT

TL;DR: 本文介绍了信号观察有序博弈（SOOGs），这是一种不完全信息博弈的子类，它为手牌抽象提供了一个精确的数学基础。文章提出了一种分辨率上限来评估不同抽象方法，并引入了全回忆结果同构（FROI）来克服现有方法的局限性，实验结果表明FROI优于现有的基于结果的算法。


<details>
  <summary>Details</summary>
Motivation: 手牌抽象对于扩展不完全信息博弈（IIGs）至关重要，但目前缺乏形式化的任务模型，且评估需要耗费大量资源的策略求解。

Method: 1. 引入了信号观察有序博弈（SOOGs），这是一种不完全信息博弈的子类，旨在为手牌抽象提供精确的数学基础。
2. 定义了分辨率上限，这是一种信息论上的上限，用于衡量在给定信号抽象下可达到的性能。
3. 提出了潜力感知结果同构（PAOI），用于形式化主流的基于结果的不完全回忆算法在任意丢弃历史信息时造成的性能损失，并证明PAOI表征了这些算法的分辨率上限。
4. 为了克服PAOI的局限性，提出了全回忆结果同构（FROI），它整合了历史信息以提高分辨率上限并改善策略质量。

Result: 1. 信号观察有序博弈（SOOGs）为手牌抽象提供了一个清晰且精确的数学基础。
2. 主流的基于结果的不完全回忆算法会由于任意丢弃历史信息而导致显著的性能损失。
3. 潜力感知结果同构（PAOI）能够表征这些算法的分辨率上限。
4. 全回忆结果同构（FROI）能够提高分辨率上限并提升策略质量。
5. 在德扑式基准测试中的实验结果表明，FROI始终优于基于结果的不完全回忆基线方法。

Conclusion: 本文对手牌抽象进行了统一的正式处理，并为设计更高分辨率的不完全信息博弈抽象提供了实用的指导。FROI方法通过整合历史信息，有效地提高了抽象的分辨率和策略质量，优于现有方法，为不完全信息博弈中的手牌抽象问题提供了新的解决方案。

Abstract: Hand abstraction is crucial for scaling imperfect-information games (IIGs)
such as Texas Hold'em, yet progress is limited by the lack of a formal task
model and by evaluations that require resource-intensive strategy solving. We
introduce signal observation ordered games (SOOGs), a subclass of IIGs tailored
to hold'em-style games that cleanly separates signal from player action
sequences, providing a precise mathematical foundation for hand abstraction.
Within this framework, we define a resolution bound-an information-theoretic
upper bound on achievable performance under a given signal abstraction. Using
the bound, we show that mainstream outcome-based imperfect-recall algorithms
suffer substantial losses by arbitrarily discarding historical information; we
formalize this behavior via potential-aware outcome Isomorphism (PAOI) and
prove that PAOI characterizes their resolution bound. To overcome this
limitation, we propose full-recall outcome isomorphism (FROI), which integrates
historical information to raise the bound and improve policy quality.
Experiments on hold'em-style benchmarks confirm that FROI consistently
outperforms outcome-based imperfect-recall baselines. Our results provide a
unified formal treatment of hand abstraction and practical guidance for
designing higher-resolution abstractions in IIGs.

</details>


### [63] [How to Sell High-Dimensional Data Optimally](https://arxiv.org/abs/2510.15214)
*Andrew Li,R. Ravi,Karan Singh,Zihong Yi,Weizhong Zhang*

Main category: cs.GT

TL;DR: 本文提出了一种信息定价问题，即在决策制定买方和垄断卖方之间，卖方可以向买方提供补充信息，以帮助买方做出更好的决策。


<details>
  <summary>Details</summary>
Motivation: 探索一种数据产品设计问题，以解决卖方可能不完全了解买方私人偏好的情况，从而实现收益最大化。

Method: 提出了一种算法，该算法在只给定状态空间采样访问的情况下，能够生成一个接近最优的菜单，且样本数量与状态空间无关。此外，还分析了高维高斯数据的特殊情况，并提出了一个通过半定规划有效找到最优菜单的方法。

Result: 成功地在仅有状态空间采样访问的情况下，生成了一个接近最优的菜单，且样本数量与状态空间无关。在高维高斯数据的特殊情况下，证明了只需考虑标量高斯实验，并且可以通过半定规划有效地找到最优菜单。

Conclusion: 本文提出了一种解决信息定价问题的新方法，并通过理论分析和算法设计，为数据产品设计提供了一种有效的解决方案。特别是在高维高斯数据的情况下，该方法能够实现完全的剩余提取。

Abstract: Motivated by the problem of selling large, proprietary data, we consider an
information pricing problem proposed by Bergemann et al. that involves a
decision-making buyer and a monopolistic seller. The seller has access to the
underlying state of the world that determines the utility of the various
actions the buyer may take. Since the buyer gains greater utility through
better decisions resulting from more accurate assessments of the state, the
seller can therefore promise the buyer supplemental information at a price. To
contend with the fact that the seller may not be perfectly informed about the
buyer's private preferences (or utility), we frame the problem of designing a
data product as one where the seller designs a revenue-maximizing menu of
statistical experiments.
  Prior work by Cai et al. showed that an optimal menu can be found in time
polynomial in the state space, whereas we observe that the state space is
naturally exponential in the dimension of the data. We propose an algorithm
which, given only sampling access to the state space, provably generates a
near-optimal menu with a number of samples independent of the state space. We
then analyze a special case of high-dimensional Gaussian data, showing that (a)
it suffices to consider scalar Gaussian experiments, (b) the optimal menu of
such experiments can be found efficiently via a semidefinite program, and (c)
full surplus extraction occurs if and only if a natural separation condition
holds on the set of potential preferences of the buyer.

</details>


### [64] [HOB: A Holistically Optimized Bidding Strategy under Heterogeneous Auction Mechanisms with Organic Traffic](https://arxiv.org/abs/2510.15238)
*Qi Li,Wendong Huang,Qichen Ye,Wutong Xu,Cheems Wang,Rongquan Bai,Wei Yuan,Guan Wang,Chuan Yu,Jian Xu*

Main category: cs.GT

TL;DR: 本文探讨了电商广告平台中第二价格拍卖（SPA）和第一价格拍卖（FPA）两种主要的流量销售方式。针对广告主向全站推广（QuanZhanTui）模式的转变，以及由此带来的自动化竞价系统在异构拍卖渠道中制定最优策略的挑战，本文提出了两个核心贡献：一是在FPA渠道下，考虑了自然流量（免费流量）的存在，推导出了最优竞价的有效解决方案；二是引入了一种边际成本对齐（MCA）策略，以确保在异构拍卖机制下的竞价效率。通过离线实验和大规模在线A/B测试，验证了所提出框架的性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电商广告平台中，第二价格拍卖（SPA）和第一价格拍卖（FPA）是主要的流量销售方式。传统上，SPA因其占优策略激励相容性（DSIC）而流行，尤其是在预算非约束条件下。然而，FPA因其能为发布商带来更高的收入潜力和避免个性化保留价格中的歧视性待遇而日益受到关注。同时，广告主正日益采用类似于全站推广（QuanZhanTui）的平台级营销解决方案，这意味着他们不再仅仅关注商业流量，而是对所有流量进行竞价以最大化整体销售额。对于自动化竞价系统而言，这种转变带来了一个关键挑战：如何在异构拍卖渠道中确定最优策略以实现广告主的不同目标，例如最大化回报（MaxReturn）或达到目标广告支出回报（TargetROAS）。

Method: 本文提出了两种方法来解决上述挑战：
1. FPA渠道下的最优竞价解决方案：针对FPA渠道，本文考虑了自然流量（即可以免费获得的流量）的存在，并推导出了一个有效的方法来计算最优竞价策略。该解决方案旨在帮助广告主在考虑到免费流量的情况下，更有效地在FPA渠道中进行竞价。
2. 边际成本对齐（MCA）策略：为了解决异构拍卖机制下的竞价效率问题，本文引入了边际成本对齐（MCA）策略。该策略能够有效地平衡不同拍卖机制下的竞价效率，从而确保广告主在混合拍卖环境中也能够获得最优的竞价效果。

Result: 通过全面的离线实验（在公共数据集上进行）和大规模在线A/B测试，本文提出的框架在性能上显著优于现有方法。这表明所开发的方法在实际应用中具有更好的效果和更高的效率，能够更好地满足广告主在全站推广模式下的需求。

Conclusion: 本文针对电商广告平台中广告主向全站推广模式转变所带来的挑战，提出了FPA渠道下的最优竞价解决方案和边际成本对齐（MCA）策略。这些方法有效地解决了在存在自然流量的情况下，如何在异构拍卖机制下实现最优竞价的问题。离线实验和在线A/B测试的结果验证了所提出框架的有效性和优越性。这些贡献为自动化竞价系统提供了新的思路和工具，帮助广告主在日益复杂的电商广告环境中实现更好的营销效果。

Abstract: The E-commerce advertising platforms typically sell commercial traffic
through either second-price auction (SPA) or first-price auction (FPA). SPA was
historically prevalent due to its dominant strategy incentive-compatible (DSIC)
for bidders with quasi-linear utilities, especially when budgets are not a
binding constraint, while FPA has gained more prominence for offering higher
revenue potential to publishers and avoiding the possibility for discriminatory
treatment in personalized reserve prices. Meanwhile, on the demand side,
advertisers are increasingly adopting platform-wide marketing solutions akin to
QuanZhanTui, shifting from spending budgets solely on commercial traffic to
bidding on the entire traffic for the purpose of maximizing overall sales. For
automated bidding systems, such a trend poses a critical challenge: determining
optimal strategies across heterogeneous auction channels to fulfill diverse
advertiser objectives, such as maximizing return (MaxReturn) or meeting target
return on ad spend (TargetROAS). To overcome this challenge, this work makes
two key contributions. First, we derive an efficient solution for optimal
bidding under FPA channels, which takes into account the presence of organic
traffic - traffic can be won for free. Second, we introduce a marginal cost
alignment (MCA) strategy that provably secures bidding efficiency across
heterogeneous auction mechanisms. To validate performance of our developed
framework, we conduct comprehensive offline experiments on public datasets and
large-scale online A/B testing, which demonstrate consistent improvements over
existing methods.

</details>


### [65] [A Renegotiable contract-theoretic incentive mechanism for Federated learning](https://arxiv.org/abs/2510.15344)
*Xavier Tan,Xiaoli Tang,Han Yu*

Main category: cs.GT

TL;DR: 本文提出了可重议的契约理论激励机制（RC-TIM），以解决联邦学习中数据所有者行为和预算变化的问题，并通过支持合同再协商提供灵活动态的激励。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习激励机制通常假设合同一旦签订就不会改变，但实际中数据所有者可能因不可预见的情况无法履行合同，导致数据消费者预算利用效率低下。

Method: 本文提出了一种可重议的契约理论激励机制（RC-TIM），该机制允许在数据所有者行为和预算约束发生变化时重新协商合同，从而提供灵活动态的激励。

Result: 在三个基准数据集上进行的大量实验表明，RC-TIM的性能显著优于四种最先进的相关方法，平均效用提高了45.76%。

Conclusion: RC-TIM机制能够使联邦学习系统更好地适应操作环境中不可预测的变化，提高数据所有者提供服务的质量，并显著提高系统效用。

Abstract: Federated learning (FL) has gained prominence due to heightened concerns over
data privacy. Privacy restrictions limit the visibility for data consumers
(DCs) to accurately assess the capabilities and efforts of data owners (DOs).
Thus, for open collaborative FL markets to thrive, effective incentive
mechanisms are key as they can motivate data owners (DOs) to contribute to FL
tasks. Contract theory is a useful technique for developing FL incentive
mechanisms. Existing approaches generally assume that once the contract between
a DC and a DO is signed, it remains unchanged until the FL task is finished.
However, unforeseen circumstances might force a DO to be unable to fulfill the
current contract, resulting in inefficient utilization of DCs' budgets. To
address this limitation, we propose the Renegotiable Contract-Theoretic
Incentive Mechanism (RC-TIM) for FL. Unlike previous approaches, it adapts to
changes in DOs' behavior and budget constraints by supporting the renegotiation
of contracts, providing flexible and dynamic incentives. Under RC-TIM, an FL
system is more adaptive to unpredictable changes in the operating environment
that can affect the quality of the service provided by DOs. Extensive
experiments on three benchmark datasets demonstrate that RC-TIM significantly
outperforms four state-of-the-art related methods, delivering up to a 45.76%
increase in utility on average.

</details>


### [66] [Co-Investment with Dynamic Participation under Unforeseeable Opportunity Costs: A Coalitional Game Approach](https://arxiv.org/abs/2510.15384)
*Amal Sakr,Andrea Araldo,Tijani Chahed,Daniel Kofman*

Main category: cs.GT

TL;DR: 本文提出了一种基于合作博弈论的动态协同投资方案，以鼓励参与者投资移动边缘计算（MEC）基础设施。该方案允许参与者加入、退出和调整投资，并通过进入费和退出罚金来补偿留守的参与者。


<details>
  <summary>Details</summary>
Motivation: 解决移动边缘计算（MEC）基础设施部署中基础设施提供商（InP）投资意愿不足的问题。由于基础设施部署需要大量投资，InP可能不愿独自承担，而长期协同投资对参与者而言可能限制过多，存在机会成本。

Method: 本文提出了一种基于合作博弈论的动态协同投资方案。该方案具有以下特点：1. 动态性：允许参与者加入、留在或退出协同投资，并随时间调整基础设施容量和资源共享。2. 补偿机制：通过计算进入费和退出罚金来适当补偿留在协同投资中的参与者。

Result: 数值结果表明，在机会成本较高的情况下，本文提出的动态方案能够鼓励参与者投资，并提高利润。

Conclusion: 本文提出的基于合作博弈论的动态协同投资方案，通过解决投资意愿、灵活性和公平性等问题，有效地促进了MEC基础设施的部署和发展。

Abstract: Technologies such as Mobile Edge Computing (MEC) depend on the availability
of infrastructure. We define the Infrastructure Provider (InP) as the actor
responsible for deploying and maintaining this infrastructure, while Service
Providers (SPs) operate applications over it to serve end users and earn
revenues. Deploying such infrastructure requires however a significant
investment, and the InP may be reluctant to bear it alone. We propose
co-investment to overcome this barrier, allowing players, the InP and multiple
SPs, to share costs and revenues. However, committing to a co-investment over a
long period may be too constraining for players: in an unforeseeable future,
players may realize that they could make more profit outside the co-investment
(such a profit is called opportunity cost). For this reason, we propose a
scheme, based on coalitional game theory, which is dynamic in terms of
(i)allowing players to join, remain in, or leave the co-investment, (ii)
adjusting the infrastructure capacity and resource sharing over time. We
propose a method to compute entry fees and exit penalties in order to
appropriately compensate players remaining in the co-investment. We numerically
show that our dynamic scheme encourages player participation and increases
profit (in case of high opportunity cost).

</details>


### [67] [Reviving, reproducing, and revisiting Axelrod's second tournament](https://arxiv.org/abs/2510.15438)
*Vincent Knight,Owen Campbell,Marc Harper,T. J. Gaffney,Nikoleta E. Glynatsi*

Main category: cs.GT

TL;DR: 这篇论文再现了Axelrod的第二次迭代囚徒困境计算机竞赛，并验证了TFT策略的成功。作者通过在更多样化的设置和噪声下评估了原始策略的稳健性。


<details>
  <summary>Details</summary>
Motivation: 直接互惠，特别是通过迭代囚徒困境（IPD）研究的互惠，对于理解合作如何演变至关重要。Robert Axelrod在20世纪80年代组织的两次有影响力的IPD计算机竞赛中，以牙还牙（TFT）策略脱颖而出成为赢家。然而，档案记录不完整：第一次竞赛只有一份报告留存，第二次竞赛的提交的Fortran策略仍在，但最终的竞赛代码却佚失了。这一空白引发了人们对这些具有历史影响力的结果可重现性的质疑。

Method: 作者通过将现存的Fortran实现恢复到与现代编译器兼容，并构建一个Python接口来调用原始策略函数而不进行修改，从而重新创建了第二次竞赛。利用开源的Axelrod-Python库运行竞赛，作者重现了Axelrod的主要发现。

Result: 作者再现了Axelrod的主要发现：TFT策略获胜，成功的玩法倾向于合作、对背叛做出反应并愿意宽恕。策略排名基本保持不变。然而，作者发现最初的竞赛对TFT特别有利，并且当原始提交的策略占大多数时，TFT很难被推翻。作者还观察到，一些鲜为人知的策略在更多样化的设置和噪声下表现强劲。

Conclusion: 作者的贡献在于：(i) 首次系统地再现了Axelrod的第二次竞赛；(ii) 结合新的策略和设置，对原始结果进行了当代重新评估；(iii) 在Axelrod-Python中保存了一个易于使用的第二次竞赛策略实现，以支持未来的研究。

Abstract: Direct reciprocity, typically studied using the Iterated Prisoner's Dilemma
(IPD), is central to understanding how cooperation evolves. In the 1980s,
Robert Axelrod organized two influential IPD computer tournaments, where Tit
for Tat (TFT) emerged as the winner. Yet the archival record is incomplete: for
the first tournament only a report survives, and for the second the submitted
Fortran strategies remain but not the final tournament code. This gap raises
questions about the reproducibility of these historically influential results.
We recreate the second tournament by restoring the surviving Fortran
implementations to compile with modern compilers and by building a Python
interface that calls the original strategy functions without modification.
Using the open-source Axelrod-Python library to run tournaments, we reproduce
Axelrod's main findings: TFT prevails, and successful play tends to be
cooperative, responsive to defection, and willing to forgive. Strategy rankings
remain mostly unchanged. We then assess the robustness of the originally
submitted strategies by incorporating additional strategies, and we run one of
the largest IPD tournaments to date. We find that the original tournament was
especially favorable to TFT and that it is difficult to dethrone TFT when the
original submissions make up the majority of the field. We also observe that
several lesser-known submissions perform strongly in more diverse settings and
under noise. Our contributions are: (i) the first systematic reproduction of
Axelrod's second tournament; (ii) a contemporary reassessment of the original
results in light of new strategies and settings; and (iii) a preserved,
easy-to-use implementation of the second-tournament strategies within
Axelrod-Python to support future research.

</details>


### [68] [Active Inverse Methods in Stackelberg Games with Bounded Rationality](https://arxiv.org/abs/2510.15582)
*Jianguo Chen,Jinlong Lei,Biqiang Mu,Yiguang Hong,Hongsheng Qi*

Main category: cs.GT

TL;DR: 本文提出了一种主动逆推博弈论方法，用于在Stackelberg博弈中学习追随者的成本函数。


<details>
  <summary>Details</summary>
Motivation: 现有的逆推博弈论方法没有将学习者视为博弈中的积极参与者，这会显著影响学习过程。

Method: 本文提出了一种利用Fisher信息的主动学习方法，以最大化关于未知参数的信息增益，并证明了其一致性和渐近正态性。此外，当领导者考虑成本时，本文提出了一种主动逆向博弈方法来平衡探索和利用，并证明了其在二次成本函数下的一致性和渐近Stackelberg均衡。

Result: 通过仿真验证了这些方法的性质，并证明主动逆向博弈方法可以通过主动探索更快地达到Stackelberg均衡。

Conclusion: 主动逆推博弈论方法可以有效提高Stackelberg博弈中追随者成本函数的学习效率。

Abstract: Inverse game theory is utilized to infer the cost functions of all players
based on game outcomes. However, existing inverse game theory methods do not
consider the learner as an active participant in the game, which could
significantly enhance the learning process. In this paper, we extend inverse
game theory to active inverse methods. For Stackelberg games with bounded
rationality, the leader, acting as a learner, actively chooses actions to
better understand the follower's cost functions. First, we develop a method of
active learning by leveraging Fisher information to maximize information gain
about the unknown parameters and prove the consistency and asymptotic
normality. Additionally, when leaders consider its cost, we develop a method of
active inverse game to balance exploration and exploitation, and prove the
consistency and asymptotic Stackelberg equilibrium with quadratic cost
functions. Finally, we verify the properties of these methods through
simulations in the quadratic case and demonstrate that the active inverse game
method can achieve Stackelberg equilibrium more quickly through active
exploration.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [69] [Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators](https://arxiv.org/abs/2510.14983)
*Oskar Triebe,Fletcher Passow,Simon Wittner,Leonie Wagner,Julio Arend,Tao Sun,Chad Zanocco,Marek Miltner,Arezou Ghesmati,Chen-Hao Tsai,Christoph Bergmeir,Ram Rajagopal*

Main category: cs.LG

TL;DR: 本文提出了一种分层电力负荷预测系统，以应对可再生能源发展带来的电网负荷不确定性。该系统旨在提高预测的空间分辨率，从而支持输电系统运营商（TSO）从区域聚合预测转向更精细的节点负荷预测，同时保持可管理性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 电力负荷的不确定性增加对局部电网基础设施的可靠性构成挑战，输电系统运营商（TSO）需要更高空间分辨率的负荷预测，从区域聚合扩展到单独的节点。然而，节点负荷预测的准确性较低，且需要大量的独立预测，这给控制室日常运营中的人工风险评估带来了管理难度。

Method: 本文与一个输电系统运营商（TSO）合作，设计了一个多层次系统，以满足操作员对日前每小时负荷预测的需求。该系统利用独特的、大量的区域和节点净负荷数据集，对系统组件进行了实验评估。首先，开发了一个可解释和可扩展的预测模型，使TSO能够逐步将区域运营扩展到包含节点预测。其次，评估了解决节点负荷异质性和波动性的折衷方案。第三，系统通过完全并行化的单一模型预测工作流实现可管理性。

Result: 研究结果表明，该系统提高了区域预测的准确性和可解释性，并显著改善了节点预测。

Conclusion: 在实践中，该多层次预测系统使操作员能够以前所未有的信心和准确性调整预测，并精确诊断原本不透明的错误。

Abstract: The reliability of local power grid infrastructure is challenged by
sustainable energy developments increasing electric load uncertainty.
Transmission System Operators (TSOs) need load forecasts of higher spatial
resolution, extending current forecasting operations from zonal aggregates to
individual nodes. However, nodal loads are less accurate to forecast and
require a large number of individual forecasts, which are hard to manage for
the human experts assessing risks in the control room's daily operations
(operator). In collaboration with a TSO, we design a multi-level system that
meets the needs of operators for hourly day-ahead load forecasting. Utilizing a
uniquely extensive dataset of zonal and nodal net loads, we experimentally
evaluate our system components. First, we develop an interpretable and scalable
forecasting model that allows for TSOs to gradually extend zonal operations to
include nodal forecasts. Second, we evaluate solutions to address the
heterogeneity and volatility of nodal load, subject to a trade-off. Third, our
system is manageable with a fully parallelized single-model forecasting
workflow. Our results show accuracy and interpretability improvements for zonal
forecasts, and substantial improvements for nodal forecasts. In practice, our
multi-level forecasting system allows operators to adjust forecasts with
unprecedented confidence and accuracy, and to diagnose otherwise opaque errors
precisely.

</details>


### [70] [Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information](https://arxiv.org/abs/2506.07829)
*Jan Corazza,Hadi Partovi Aria,Hyohun Kim,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 本文探讨了在去中心化多智能体强化学习（DMARL）中，通过提供高级符号知识来解决兼容性约束、隐私、通信和性能挑战，并提出了扩展形式化工具以在更多场景中保证理论正确性，同时实证证明了符号知识能显著加速学习过程。


<details>
  <summary>Details</summary>
Motivation: 在去中心化多智能体强化学习（DMARL）中，智能体独立学习并结合策略以实现共同目标，但这通常需要满足策略兼容性约束。传统方法面临隐私限制、通信障碍和性能问题。本文旨在通过引入高级符号知识来解决这些挑战，以确保在多智能体协作中实现全局任务。

Method: 本文通过扩展形式化工具来检查局部策略与团队任务的兼容性，从而使具有理论保证的去中心化训练能够在更多场景中使用。此外，文章还通过提供关于环境中事件时间演变的高级符号知识来加快学习过程。

Result: 本文扩展了检查局部策略与团队任务兼容性的形式化工具，使得具有理论保证的去中心化训练在更多场景中可用。实证结果表明，关于环境中事件时间演变的高级符号知识可以显著加快DMARL的学习过程。

Conclusion: 通过引入高级符号知识，本文有效地解决了去中心化多智能体强化学习中的诸多挑战，包括策略兼容性、隐私和通信限制，显著加速了学习过程，并扩展了理论保证的适用范围，为多智能体系统的实际应用提供了有力支持。

Abstract: Reinforcement learning (RL) algorithms can find an optimal policy for a
single agent to accomplish a particular task. However, many real-world problems
require multiple agents to collaborate in order to achieve a common goal. For
example, a robot executing a task in a warehouse may require the assistance of
a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL
(DMARL), agents learn independently and then combine their policies at
execution time, but often must satisfy constraints on compatibility of local
policies to ensure that they can achieve the global task when combined. In this
paper, we study how providing high-level symbolic knowledge to agents can help
address unique challenges of this setting, such as privacy constraints,
communication limitations, and performance concerns. In particular, we extend
the formal tools used to check the compatibility of local policies with the
team task, making decentralized training with theoretical guarantees usable in
more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge
about the temporal evolution of events in the environment can significantly
expedite the learning process in DMARL.

</details>


### [71] [TangledFeatures: Robust Feature Selection in Highly Correlated Spaces](https://arxiv.org/abs/2510.15005)
*Allen Daniel Sunny*

Main category: cs.LG

TL;DR: TangledFeatures是一个在相关特征空间中进行特征选择的框架。它从纠缠的预测变量组中识别代表性特征，减少冗余，同时保留解释力。


<details>
  <summary>Details</summary>
Motivation: 目前广泛使用的特征选择方法主要关注预测准确性，并且在存在相关预测变量的情况下性能会下降。

Method: TangledFeatures框架用于在相关特征空间中进行特征选择。它从纠缠的预测变量组中识别代表性特征，从而减少冗余并保留解释力。

Result: 与传统选择技术相比，TangledFeatures筛选出的特征子集可以直接应用于下游模型，为分析提供了更具解释性和稳定性的基础。TangledFeatures在丙氨酸二肽上的表现是有效的，它被应用于预测主链扭转角，并且选择的特征对应于解释这些角度变化的结构上有意义的原子内距离。

Conclusion: TangledFeatures框架能够有效地在相关特征空间中选择特征，提高模型的可解释性和稳定性。

Abstract: Feature selection is a fundamental step in model development, shaping both
predictive performance and interpretability. Yet, most widely used methods
focus on predictive accuracy, and their performance degrades in the presence of
correlated predictors. To address this gap, we introduce TangledFeatures, a
framework for feature selection in correlated feature spaces. It identifies
representative features from groups of entangled predictors, reducing
redundancy while retaining explanatory power. The resulting feature subset can
be directly applied in downstream models, offering a more interpretable and
stable basis for analysis compared to traditional selection techniques. We
demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying
it to the prediction of backbone torsional angles and show that the selected
features correspond to structurally meaningful intra-atomic distances that
explain variation in these angles.

</details>


### [72] [ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm](https://arxiv.org/abs/2510.15006)
*Rijul Tandon,Peter Vamplew,Cameron Foale*

Main category: cs.LG

TL;DR: ES-C51是一种改进的C51算法，它用Expected Sarsa更新取代了贪婪的Q-learning更新，以解决当多个动作具有相似预期奖励但分布不同时C51可能出现的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 在大多数基于价值的强化学习算法中，智能体只估计每个动作的预期奖励并选择奖励最高的动作。相比之下，分布强化学习（DRL）估计所有可能奖励的整个概率分布，提供关于不确定性和变异性更丰富的信息。解决C51在处理具有相似预期奖励但不同分布的多个动作时可能出现的不稳定性问题。

Method: C51是离散动作空间中流行的DRL算法。它使用Q-learning方法，通过贪婪的贝尔曼更新来学习分布。本研究提出了一种修改版的C51（ES-C51），用Expected Sarsa更新取代了贪婪的Q-learning更新。Expected Sarsa更新使用softmax计算来结合来自状态所有可能动作的信息，而不是依赖于单个最佳动作。为了公平比较，我们将标准C51的探索策略从e-greedy修改为softmax，称之为QL-C51（基于Q-Learning的C51）。

Result: 结果表明，ES-C51在许多环境中都优于QL-C51。

Conclusion: ES-C51通过引入Expected Sarsa更新，有效解决了标准C51在处理动作预期奖励相似但分布不同时可能出现的稳定性问题，从而使智能体能够学习更高性能的策略，并在多个环境中表现出优越性。

Abstract: In most value-based reinforcement learning (RL) algorithms, the agent
estimates only the expected reward for each action and selects the action with
the highest reward. In contrast, Distributional Reinforcement Learning (DRL)
estimates the entire probability distribution of possible rewards, providing
richer information about uncertainty and variability. C51 is a popular DRL
algorithm for discrete action spaces. It uses a Q-learning approach, where the
distribution is learned using a greedy Bellman update. However, this can cause
problems if multiple actions at a state have similar expected reward but with
different distributions, as the algorithm may not learn a stable distribution.
This study presents a modified version of C51 (ES-C51) that replaces the greedy
Q-learning update with an Expected Sarsa update, which uses a softmax
calculation to combine information from all possible actions at a state rather
than relying on a single best action. This reduces instability when actions
have similar expected rewards and allows the agent to learn higher-performing
policies. This approach is evaluated on classic control environments from Gym,
and Atari-10 games. For a fair comparison, we modify the standard C51's
exploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q-
Learning based C51). The results demonstrate that ES-C51 outperforms QL-C51
across many environments.

</details>


### [73] [Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines](https://arxiv.org/abs/2510.15010)
*Rekha R Nair,Tina Babu,Alavikunhu Panthakkan,Balamurugan Balusamy,Wathiq Mansoor*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新颖的集成深度学习框架，用于风力涡轮机的无监督异常检测，该框架结合了VAE、LSTM自动编码器和Transformer，并在CARE数据集上取得了0.947的AUC-ROC，实现了提前48小时的故障检测。


<details>
  <summary>Details</summary>
Motivation: 风力涡轮机的可靠性对可再生能源行业至关重要，早期故障检测可以显著减少停机时间和维护成本。

Method: 本研究引入了一种基于集成的深度学习框架，用于风力涡轮机的无监督异常检测。该方法集成了变分自动编码器（VAE）、LSTM自动编码器和Transformer架构，每种架构都从高维SCADA数据中捕获不同的时间®上下文模式。独特的特征工程流程提取时间®统计和频域指标，然后由深度模型处理。集成评分结合了模型预测，随后是自适应阈值处理，以在不需要标记故障数据的情况下检测操作异常。

Result: 在包含三个风力发电场89年真实涡轮机数据的CARE数据集上进行评估，所提出的方法实现了0.947的AUC-ROC，并在故障发生前48小时内实现了早期故障检测。

Conclusion: 该方法通过实现预测性维护、减少涡轮机故障和提高大规模风能部署的运行效率，提供了显著的社会价值。

Abstract: Wind turbine reliability is critical to the growing renewable energy sector,
where early fault detection significantly reduces downtime and maintenance
costs. This paper introduces a novel ensemble-based deep learning framework for
unsupervised anomaly detection in wind turbines. The method integrates
Variational Autoencoders (VAE), LSTM Autoencoders, and Transformer
architectures, each capturing different temporal and contextual patterns from
high-dimensional SCADA data. A unique feature engineering pipeline extracts
temporal, statistical, and frequency-domain indicators, which are then
processed by the deep models. Ensemble scoring combines model predictions,
followed by adaptive thresholding to detect operational anomalies without
requiring labeled fault data. Evaluated on the CARE dataset containing 89 years
of real-world turbine data across three wind farms, the proposed method
achieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to
failure. This approach offers significant societal value by enabling predictive
maintenance, reducing turbine failures, and enhancing operational efficiency in
large-scale wind energy deployments.

</details>


### [74] [AlignFlow: Improving Flow-based Generative Models with Semi-Discrete Optimal Transport](https://arxiv.org/abs/2510.15038)
*Lingkai Kong,Molei Tao,Yang Liu,Bryan Wang,Jinmiao Fu,Chien-Chih Wang,Huidong Liu*

Main category: cs.LG

TL;DR: AlignFlow通过使用半离散最优传输（SDOT）在噪声和数据之间建立明确、最优的对齐，以增强流生成模型（FGMs）的训练，解决了现有基于最优传输（OT）的方法在FGMs中可扩展性受限的问题。


<details>
  <summary>Details</summary>
Motivation: 目前基于OT的方法在FGMs中可扩展性受到限制。

Method: AlignFlow利用半离散最优传输（SDOT）来增强FGMs的训练，通过将噪声空间划分为Laguerre单元，并将每个单元映射到相应的数据点。

Result: AlignFlow在计算开销可忽略不计的情况下，能很好地扩展到大型数据集和模型架构，并提高了各种最先进FGM算法的性能。

Conclusion: AlignFlow通过引入SDOT为FGMs训练带来了显著改进，解决了现有OT方法的扩展性问题，并可作为即插即用的组件集成。

Abstract: Flow-based Generative Models (FGMs) effectively transform noise into complex
data distributions. Incorporating Optimal Transport (OT) to couple noise and
data during FGM training has been shown to improve the straightness of flow
trajectories, enabling more effective inference. However, existing OT-based
methods estimate the OT plan using (mini-)batches of sampled noise and data
points, which limits their scalability to large and high-dimensional datasets
in FGMs. This paper introduces AlignFlow, a novel approach that leverages
Semi-Discrete Optimal Transport (SDOT) to enhance the training of FGMs by
establishing an explicit, optimal alignment between noise distribution and data
points with guaranteed convergence. SDOT computes a transport map by
partitioning the noise space into Laguerre cells, each mapped to a
corresponding data point. During FGM training, i.i.d. noise samples are paired
with data points via the SDOT map. AlignFlow scales well to large datasets and
model architectures with negligible computational overhead. Experimental
results show that AlignFlow improves the performance of a wide range of
state-of-the-art FGM algorithms and can be integrated as a plug-and-play
component. Code is available at: https://github.com/konglk1203/AlignFlow.

</details>


### [75] [Internalizing World Models via Self-Play Finetuning for Agentic RL](https://arxiv.org/abs/2510.15047)
*Shiqi Chen,Tongyao Zhu,Zian Wang,Jinghan Zhang,Kangrui Wang,Siyang Gao,Teng Xiao,Yee Whye Teh,Junxian He,Manling Li*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为SPA的简单强化学习框架，旨在解决大型语言模型（LLMs）在OOD场景中作为智能体时遇到的困难，通过引入内部世界模型来提高决策能力和泛化性，并在多个环境中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: LLMs作为智能体在OOD场景中表现不佳，难以将内部知识与复杂的环境动态结合，导致RL训练效果差，探索能力弱，泛化性有限。

Method: SPA框架通过将世界模型分解为状态表示和转换建模两部分进行编码，并通过自博弈监督微调（SFT）阶段与环境交互来学习世界模型，然后利用该模型在策略优化之前模拟未来状态，从而冷启动策略。

Result: SPA框架显著提升了LLM智能体的训练性能，例如在Sokoban任务中，成功率从25.6%提高到59.8%，在FrozenLake任务中，分数从22.1%提高到70.9%（对于Qwen2.5-1.5B-Instruct模型）。

Conclusion: 通过引入内部世界模型并采用SPA框架的策略冷启动和世界模型学习方法，可以有效解决LLMs在OOD场景中的适应性问题，显著提升其在多种复杂环境中的决策和泛化能力。

Abstract: Large Language Models (LLMs) as agents often struggle in out-of-distribution
(OOD) scenarios. Real-world environments are complex and dynamic, governed by
task-specific rules and stochasticity, which makes it difficult for LLMs to
ground their internal knowledge in those dynamics. Under such OOD conditions,
vanilla RL training often fails to scale; we observe Pass@k--the probability
that at least one of (k) sampled trajectories succeeds--drops markedly across
training steps, indicating brittle exploration and limited generalization.
Inspired by model-based reinforcement learning, we hypothesize that equipping
LLM agents with an internal world model can better align reasoning with
environmental dynamics and improve decision-making. We show how to encode this
world model by decomposing it into two components: state representation and
transition modeling. Building on this, we introduce SPA, a simple reinforcement
learning framework that cold-starts the policy via a Self-Play supervised
finetuning (SFT) stage to learn the world model by interacting with the
environment, then uses it to simulate future states prior to policy
optimization. This simple initialization outperforms the online world-modeling
baseline and greatly boosts the RL-based agent training performance.
Experiments across diverse environments like Sokoban, FrozenLake, and Sudoku
show that our approach significantly improves performance. For example, SPA
boosts the Sokoban success rate from 25.6% to 59.8% and raises the FrozenLake
score from 22.1% to 70.9% for the Qwen2.5-1.5B-Instruct model.

</details>


### [76] [Learn to Change the World: Multi-level Reinforcement Learning with Model-Changing Actions](https://arxiv.org/abs/2510.15056)
*Ziqing Lu,Babak Hassibi,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: 本文提出了一种多层可配置时变马尔可夫决策过程（MCTVMDP），允许智能体通过模型修改动作主动改变其RL模型的动态，以寻求最优策略。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习方法假设环境是给定或固定的，智能体被动适应。然而，本文考虑的智能体可以通过改变模型的主动动作来重新配置底层的转换过程，从而潜在地增加回报，因此提出了一种新的框架。

Method: 本文引入了多层可配置时变马尔可夫决策过程（MCTVMDP）。在MCTVMDP中，底层MDP具有非平稳的转换函数，可以通过上层模型修改动作进行配置。智能体的目标是优化上层MDP中的配置策略和底层MDP中的原始动作策略，以共同提高其预期的长期回报。

Result: MCTVMDP允许智能体通过主动修改RL模型的动态来优化配置策略和原始动作策略，从而提高预期的长期回报。

Conclusion: MCTVMDP框架通过引入模型修改动作和分层MDP结构，为智能体提供了一种主动改变环境动态以优化回报的新方法，超越了传统强化学习的被动适应范式。

Abstract: Reinforcement learning usually assumes a given or sometimes even fixed
environment in which an agent seeks an optimal policy to maximize its long-term
discounted reward. In contrast, we consider agents that are not limited to
passive adaptations: they instead have model-changing actions that actively
modify the RL model of world dynamics itself. Reconfiguring the underlying
transition processes can potentially increase the agents' rewards. Motivated by
this setting, we introduce the multi-layer configurable time-varying Markov
decision process (MCTVMDP). In an MCTVMDP, the lower-level MDP has a
non-stationary transition function that is configurable through upper-level
model-changing actions. The agent's objective consists of two parts: Optimize
the configuration policies in the upper-level MDP and optimize the primitive
action policies in the lower-level MDP to jointly improve its expected
long-term reward.

</details>


### [77] [Physics-informed data-driven machine health monitoring for two-photon lithography](https://arxiv.org/abs/2510.15075)
*Sixian Jia,Zhiqiao Dong,Chenhui Shao*

Main category: cs.LG

TL;DR: 本文提出了三种监测双光子光刻（TPL）机器健康状况的方法，通过结合物理信息数据驱动的预测模型和统计方法，实现了对TPL系统准确及时的健康监测，从而提高了制造质量和效率。


<details>
  <summary>Details</summary>
Motivation: 目前双光子光刻（TPL）系统的维护主要依赖经验而非机器健康监测，导致维护不及时或不必要，从而造成停机和制造质量问题。

Method: 本文提出了三种方法，通过将结构尺寸的物理信息数据驱动预测模型与统计方法相结合，以处理日益复杂、具有不同泛化能力的场景。

Result: 在包含六种工艺参数组合和六种结构尺寸的综合实验数据集中，在两种机器健康状况下，这些方法在所有测试场景中均表现出高精度，展示了出色的有效性、鲁棒性和泛化能力。

Conclusion: 所提出的方法为TPL系统的基于状态维护迈出了重要一步，显著提高了维护效率和制造质量。

Abstract: Two-photon lithography (TPL) is a sophisticated additive manufacturing
technology for creating three-dimensional (3D) micro- and nano-structures.
Maintaining the health of TPL systems is critical for ensuring consistent
fabrication quality. Current maintenance practices often rely on experience
rather than informed monitoring of machine health, resulting in either untimely
maintenance that causes machine downtime and poor-quality fabrication, or
unnecessary maintenance that leads to inefficiencies and avoidable downtime. To
address this gap, this paper presents three methods for accurate and timely
monitoring of TPL machine health. Through integrating physics-informed
data-driven predictive models for structure dimensions with statistical
approaches, the proposed methods are able to handle increasingly complex
scenarios featuring different levels of generalizability. A comprehensive
experimental dataset that encompasses six process parameter combinations and
six structure dimensions under two machine health conditions was collected to
evaluate the effectiveness of the proposed approaches. Across all test
scenarios, the approaches are shown to achieve high accuracies, demonstrating
excellent effectiveness, robustness, and generalizability. These results
represent a significant step toward condition-based maintenance for TPL
systems.

</details>


### [78] [Online Correlation Clustering: Simultaneously Optimizing All $\ell_p$-norms](https://arxiv.org/abs/2510.15076)
*Sami Davies,Benjamin Moseley,Heather Newman*

Main category: cs.LG

TL;DR: 本文提出了一种在线算法，可以在在线设置中同时近似所有$\ell_p$-范数，解决了离线设置中的“所有范数”保证问题。


<details>
  <summary>Details</summary>
Motivation: 在离线设置中，可以同时近似所有$\ell_p$-范数以实现最小化总分歧（$\ell_1$-范数）和确保个体节点公平性（$\ell_\infty$-范数）之间的权衡，但尚不清楚这在在线设置中是否可行。

Method: 本文提出了一种针对在线-带样本（AOS）模型的单一算法。该算法在给定一小部分输入作为样本的情况下，可以生成一个聚类，该聚类以高概率同时对所有$\ell_p$-范数具有$O(\log^4 n)$-竞争性，以高概率对$\ell_\infty$-范数具有$O(\log n)$-竞争性，并以期望值对$\ell_1$-范数具有$O(1)$-竞争性。

Result: 所提出的算法成功地将离线的“所有范数”保证转化为在线世界。并且，该算法在AOS模型中对$\ell_1$-和$\ell_\infty$-范数的竞争比接近紧密下界。

Conclusion: 本文首次证明了在在线设置中可以同时近似所有$\ell_p$-范数，并通过提出的AOS模型算法，在总分歧和个体公平性之间取得了很好的平衡。

Abstract: The $\ell_p$-norm objectives for correlation clustering present a fundamental
trade-off between minimizing total disagreements (the $\ell_1$-norm) and
ensuring fairness to individual nodes (the $\ell_\infty$-norm). Surprisingly,
in the offline setting it is possible to simultaneously approximate all
$\ell_p$-norms with a single clustering. Can this powerful guarantee be
achieved in an online setting? This paper provides the first affirmative
answer. We present a single algorithm for the online-with-a-sample (AOS) model
that, given a small constant fraction of the input as a sample, produces one
clustering that is simultaneously $O(\log^4 n)$-competitive for all
$\ell_p$-norms with high probability, $O(\log n)$-competitive for the
$\ell_\infty$-norm with high probability, and $O(1)$-competitive for the
$\ell_1$-norm in expectation. This work successfully translates the offline
"all-norms" guarantee to the online world.
  Our setting is motivated by a new hardness result that demonstrates a
fundamental separation between these objectives in the standard random-order
(RO) online model. Namely, while the $\ell_1$-norm is trivially
$O(1)$-approximable in the RO model, we prove that any algorithm in the RO
model for the fairness-promoting $\ell_\infty$-norm must have a competitive
ratio of at least $\Omega(n^{1/3})$. This highlights the necessity of a
different beyond-worst-case model. We complement our algorithm with lower
bounds, showing our competitive ratios for the $\ell_1$- and $\ell_\infty$-
norms are nearly tight in the AOS model.

</details>


### [79] [Operator Flow Matching for Timeseries Forecasting](https://arxiv.org/abs/2510.15101)
*Yolanne Yi Ran Lee,Kyriakos Flouris*

Main category: cs.LG

TL;DR: TempO 是一种潜在流匹配模型，使用稀疏条件和通道折叠来有效处理 3D 时空场，并通过时间条件傅里叶层捕获多尺度模式。TempO 在三个基准 PDE 数据集上超越了最先进的基线，并且在效率上优于现有的注意力或卷积回归器。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归和基于扩散的方法在生成建模中预测高维、PDE 控制的动力学时，经常出现累积误差和离散化伪影，这限制了长期、物理一致的预测。流匹配提供了一种自然的替代方案，可以实现高效、确定性的采样。

Method: 我们证明了 FNO 近似误差的上限，并提出了 TempO。TempO 利用稀疏条件和通道折叠来有效处理 3D 时空场，并使用时间条件傅里叶层捕获多尺度模式。

Result: TempO 在三个基准 PDE 数据集上超越了最先进的基线。光谱分析进一步表明其在多尺度动力学恢复方面表现出色。效率研究突出其与基于注意力或卷积的回归器相比，参数和内存占用较少的设计。

Conclusion: TempO 模型在PDE控制动力学预测方面表现出色，解决了现有方法的局限性，并在效率和多尺度动力学恢复方面均有显著优势。

Abstract: Forecasting high-dimensional, PDE-governed dynamics remains a core challenge
for generative modeling. Existing autoregressive and diffusion-based approaches
often suffer cumulative errors and discretisation artifacts that limit long,
physically consistent forecasts. Flow matching offers a natural alternative,
enabling efficient, deterministic sampling. We prove an upper bound on FNO
approximation error and propose TempO, a latent flow matching model leveraging
sparse conditioning with channel folding to efficiently process 3D
spatiotemporal fields using time-conditioned Fourier layers to capture
multi-scale modes with high fidelity. TempO outperforms state-of-the-art
baselines across three benchmark PDE datasets, and spectral analysis further
demonstrates superior recovery of multi-scale dynamics, while efficiency
studies highlight its parameter- and memory-light design compared to
attention-based or convolutional regressors.

</details>


### [80] [DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning](https://arxiv.org/abs/2510.15110)
*Shih-Yang Liu,Xin Dong,Ximing Lu,Shizhe Diao,Mingjie Liu,Min-Hung Chen,Hongxu Yin,Yu-Chiang Frank Wang,Kwang-Ting Cheng,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为DLER的训练方法，通过改进强化学习优化来减少大型语言模型的输出长度，同时提高准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成详细思考链时表现出色，但往往会产生不必要的冗长输出，因此研究者旨在提高每token的智能，即在保证准确性的前提下缩短响应长度。

Method: 本文提出了一种名为DLER（Doing Length pEnalty Right）的训练方法。该方法结合了批量奖励归一化、更高的裁剪阈值、动态采样以及简单的截断长度惩罚，以解决强化学习优化中的优势估计偏差大、熵崩溃和奖励信号稀疏等挑战。

Result: DLER在实现准确性和效率的权衡方面达到了最先进的水平，它将输出长度缩短了70%以上，同时超越了所有以前的基线准确性。与DeepSeek-R1-7B相比，DLER-7B在并行生成多个简洁响应时，将准确性提高了28%，并降低了延迟。此外，文中还提出了一个困难感知DLER，可以自适应地对简单问题进行截断以提高效率，以及一个更新选择性合并方法，在RL训练数据稀缺的情况下，既能保持基线准确性又能保留DLER模型的简洁推理能力。

Conclusion: 本文提出了一种有效的DLER训练方法，用于优化语言模型的响应长度和准确性，解决了现有强化学习方法中的关键挑战，并在多个方面展现出卓越的性能提升，提供了一种在保证性能的同时减少输出冗余的通用解决方案。

Abstract: Reasoning language models such as OpenAI-o1, DeepSeek-R1, and Qwen achieve
strong performance via extended chains of thought but often generate
unnecessarily long outputs. Maximizing intelligence per token--accuracy
relative to response length--remains an open problem. We revisit reinforcement
learning (RL) with the simplest length penalty--truncation--and show that
accuracy degradation arises not from the lack of sophisticated penalties but
from inadequate RL optimization. We identify three key challenges: (i) large
bias in advantage estimation, (ii) entropy collapse, and (iii) sparse reward
signal. We address them with Doing Length pEnalty Right (DLER), a training
recipe combining batch-wise reward normalization, higher clipping, dynamic
sampling, and a simple truncation length penalty. DLER achieves
state-of-the-art accuracy--efficiency trade-offs, cutting output length by over
70 percent while surpassing all previous baseline accuracy. It also improves
test-time scaling: compared to DeepSeek-R1-7B, DLER-7B generates multiple
concise responses in parallel with 28 percent higher accuracy and lower
latency. We further introduce Difficulty-Aware DLER, which adaptively tightens
truncation on easier questions for additional efficiency gains. We also propose
an update-selective merging method that preserves baseline accuracy while
retaining the concise reasoning ability of the DLER model, which is useful for
scenarios where RL training data is scarce.

</details>


### [81] [Navigating the consequences of mechanical ventilation in clinical intensive care settings through an evolutionary game-theoretic framework](https://arxiv.org/abs/2510.15127)
*David J. Albers,Tell D. Bennett,Jana de Wiljes,Bradford J. Smith,Peter D. Sottile,J. N. Stroh*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个分析重症监护患者机械通气（MV）数据的框架，旨在理解MV和辅助治疗决策对患者预后的影响。


<details>
  <summary>Details</summary>
Motivation: 理解和改善重症监护呼吸管理需要分析现有的二次临床数据，以对当前护理的有利变化和适应性提出假设。

Method: 本文引入了患者-呼吸机-护理联合系统（J6）视角，开发了一种可扩展的数据分析方法。利用演化博弈论（EGT）分析呼吸行为，为通过强化学习等概率和随机方法进行深入分析提供定量依据。EGT方法通过合成数据进行分析验证。

Result: EGT方法在合成数据上进行了分析验证，揭示了潜在的问题，为后续应用于真实的ICU数据奠定了基础。

Conclusion: 本文提出了一个基于演化博弈论的框架，用于分析机械通气数据，并为MV优化和个性化迈出了重要一步。未来的工作包括开发一个结合经验和博弈论元素的状态转换模型，用于模拟MV决策的效果。

Abstract: Identifying the effects of mechanical ventilation strategies and protocols in
critical care requires analyzing data from heterogeneous patient-ventilator
systems within the context of the clinical decision-making environment. This
research develops a framework to help understand the consequences of mechanical
ventilation (MV) and adjunct care decisions on patient outcome from
observations of critical care patients receiving MV. Developing an
understanding of and improving critical care respiratory management requires
the analysis of existing secondary-use clinical data to generate hypotheses
about advantageous variations and adaptations of current care. This work
introduces a perspective of the joint patient-ventilator-care systems
(so-called J6) to develop a scalable method for analyzing data and trajectories
of these complex systems. To that end, breath behaviors are analyzed using
evolutionary game theory (EGT), which generates the necessary quantitative
precursors for deeper analysis through probabilistic and stochastic machinery
such as reinforcement learning. This result is one step along the pathway
toward MV optimization and personalization. The EGT-based process is
analytically validated on synthetic data to reveal potential caveats before
proceeding to real-world ICU data applications that expose complexities of the
data-generating process J6. The discussion includes potential developments
toward a state transition model for the simulating effects of MV decision using
empirical and game-theoretic elements.

</details>


### [82] [A Simple Method for PMF Estimation on Large Supports](https://arxiv.org/abs/2510.15132)
*Alex Shtoff*

Main category: cs.LG

TL;DR: 该文章提出了一种在大型离散支持上估计多峰重尾概率质量函数（PMF）的非参数方法。


<details>
  <summary>Details</summary>
Motivation: 研究多峰重尾概率质量函数（PMF）在大型离散支持上的非参数估计问题。

Method: 将经验PMF视为线图上的信号，并应用数据依赖的低通滤波器。具体来说，构建一个对称三对角算子（路径图拉普拉斯算子，并用经验PMF构建的对角矩阵进行扰动），然后计算对应于最小特征值的特征向量。将经验PMF投影到这个低维子空间，得到一个平滑的、多峰的估计，它在抑制噪声的同时保留了粗略的结构。最后通过裁剪和重新归一化步骤得到有效的PMF。

Result: 该方法在合成和真实的重尾示例中，保留了粗略结构，同时抑制了采样噪声，与logspline和高斯KDE基线相比表现良好。计算可靠且运行时间和内存与支持大小和所需低维子空间的维度成比例。提供了一种实用的、数据驱动的维度选择规则。

Conclusion: 该方法易于实现，在不同样本量下表现稳健，适用于大规模自动化流程和探索性分析。但它存在已知的失效模式（例如，突然的不连续性）。

Abstract: We study nonparametric estimation of a probability mass function (PMF) on a
large discrete support, where the PMF is multi-modal and heavy-tailed. The core
idea is to treat the empirical PMF as a signal on a line graph and apply a
data-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal
operator, the path graph Laplacian perturbed with a diagonal matrix built from
the empirical PMF, then compute the eigenvectors, corresponding to the smallest
feq eigenvalues. Projecting the empirical PMF onto this low dimensional
subspace produces a smooth, multi-modal estimate that preserves coarse
structure while suppressing noise. A light post-processing step of clipping and
re-normalizing yields a valid PMF.
  Because we compute the eigenpairs of a symmetric tridiagonal matrix, the
computation is reliable and runs time and memory proportional to the support
times the dimension of the desired low-dimensional supspace. We also provide a
practical, data-driven rule for selecting the dimension based on an
orthogonal-series risk estimate, so the method "just works" with minimal
tuning. On synthetic and real heavy-tailed examples, the approach preserves
coarse structure while suppressing sampling noise, compares favorably to
logspline and Gaussian-KDE baselines in the intended regimes. However, it has
known failure modes (e.g., abrupt discontinuities). The method is short to
implement, robust across sample sizes, and suitable for automated pipelines and
exploratory analysis at scale because of its reliability and speed.

</details>


### [83] [Predicting the Unpredictable: Reproducible BiLSTM Forecasting of Incident Counts in the Global Terrorism Database (GTD)](https://arxiv.org/abs/2510.15136)
*Oluwasegun Adegoke*

Main category: cs.LG

TL;DR: 这篇文章研究了使用GTD数据库对每周恐怖事件进行短期预测。


<details>
  <summary>Details</summary>
Motivation: 研究每周恐怖事件次数的短期预测，并使用GTD数据库作为数据源。

Method: 本文构建了一个可复现的流程，采用固定的基于时间的分割。使用双向LSTM（BiLSTM）与季节性朴素模型、线性/ARIMA模型以及深度LSTM-Attention基线模型进行比较。

Result: 在保留测试集上，BiLSTM的RMSE达到6.38，优于LSTM-Attention（9.19；+30.6%）和线性滞后回归基线（+35.4% RMSE增益），并且在MAE和MAPE方面也有类似的改进。消融实验表明，在长历史数据上训练的模型泛化能力最好；适度的回溯（20-30周）提供了强大的上下文；双向编码对于捕捉窗口内的累积和后果模式至关重要。特征组分析表明，短期结构（滞后计数和滚动统计）贡献最大，地理和伤亡特征提供了增量提升。

Conclusion: 这项研究为GTD事件预测提供了一个透明的、超越基线的参考。

Abstract: We study short-horizon forecasting of weekly terrorism incident counts using
the Global Terrorism Database (GTD, 1970--2016). We build a reproducible
pipeline with fixed time-based splits and evaluate a Bidirectional LSTM
(BiLSTM) against strong classical anchors (seasonal-naive, linear/ARIMA) and a
deep LSTM-Attention baseline. On the held-out test set, the BiLSTM attains RMSE
6.38, outperforming LSTM-Attention (9.19; +30.6\%) and a linear lag-regression
baseline (+35.4\% RMSE gain), with parallel improvements in MAE and MAPE.
Ablations varying temporal memory, training-history length, spatial grain,
lookback size, and feature groups show that models trained on long historical
data generalize best; a moderate lookback (20--30 weeks) provides strong
context; and bidirectional encoding is critical for capturing both build-up and
aftermath patterns within the window. Feature-group analysis indicates that
short-horizon structure (lagged counts and rolling statistics) contributes
most, with geographic and casualty features adding incremental lift. We release
code, configs, and compact result tables, and provide a data/ethics statement
documenting GTD licensing and research-only use. Overall, the study offers a
transparent, baseline-beating reference for GTD incident forecasting.

</details>


### [84] [Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization](https://arxiv.org/abs/2510.15165)
*Xin Guo,Zijiu Lyu*

Main category: cs.LG

TL;DR: 该论文研究了连续时间强化学习中的策略迁移，提出了一种新的策略学习算法，并首次从理论上证明了连续时间强化学习中策略迁移的有效性。


<details>
  <summary>Details</summary>
Motivation: RL在复杂任务中从头训练效率低下，需要通过迁移学习提高效率。

Method: 本文研究了连续时间线性二次调节器（LQR）中带熵正则化的策略迁移，并提出了一种新的策略学习算法。

Result: 本文首次提供了连续时间RL策略迁移的理论证明，证明了最优策略对于相关LQR的次优初始化，并保持了收敛速度。新算法实现了全局线性和局部超线性收敛。同时，通过LQR与连续时间分数扩散模型的联系，推导了一类连续时间分数扩散模型的稳定性。

Conclusion: 本文弥补了现有文献的空白，将离散时间环境的现有工作扩展到连续时间环境，在连续时间RL中提供了迁移学习的理论保证和算法优势。

Abstract: Reinforcement Learning (RL) enables agents to learn optimal decision-making
strategies through interaction with an environment, yet training from scratch
on complex tasks can be highly inefficient. Transfer learning (TL), widely
successful in large language models (LLMs), offers a promising direction for
enhancing RL efficiency by leveraging pre-trained models.
  This paper investigates policy transfer, a TL approach that initializes
learning in a target RL task using a policy from a related source task, in the
context of continuous-time linear quadratic regulators (LQRs) with entropy
regularization. We provide the first theoretical proof of policy transfer for
continuous-time RL, proving that a policy optimal for one LQR serves as a
near-optimal initialization for closely related LQRs, while preserving the
original algorithm's convergence rate. Furthermore, we introduce a novel policy
learning algorithm for continuous-time LQRs that achieves global linear and
local super-linear convergence. Our results demonstrate both theoretical
guarantees and algorithmic benefits of transfer learning in continuous-time RL,
addressing a gap in existing literature and extending prior work from discrete
to continuous time settings.
  As a byproduct of our analysis, we derive the stability of a class of
continuous-time score-based diffusion models via their connection with LQRs.

</details>


### [85] [Finding geodesics with the Deep Ritz method](https://arxiv.org/abs/2510.15177)
*Conor Rowan*

Main category: cs.LG

TL;DR: 该文章介绍了测地线问题在各种领域中的应用，并指出科学机器学习（SciML）领域对这类问题的研究相对较少。作者认为，由于测地线问题具有简单的几何结构、变分结构和自然非线性，因此非常适合使用深度里兹方法。文章通过三个数值例子验证了这一观点，并旨在为深度里兹方法的应用和SciML未来的研究提供一个有前景的方向。


<details>
  <summary>Details</summary>
Motivation: 测地线问题在物理学和工程学中广泛存在，但科学机器学习领域对这类问题的研究相对较少。文章旨在探索深度里兹方法在解决测地线问题方面的潜力。

Method: 文章提出使用深度里兹方法来解决测地线问题。通过分析测地线问题的几何结构、变分结构和自然非线性，论证了深度里兹方法在该领域的适用性。

Result: 通过路径规划、光学和固体力学中的三个数值例子，验证了深度里兹方法在解决测地线问题上的有效性。

Conclusion: 测地线问题是深度里兹方法的一个有前景的应用方向，也为未来的科学机器学习研究提供了一个有益的方向。

Abstract: Geodesic problems involve computing trajectories between prescribed initial
and final states to minimize a user-defined measure of distance, cost, or
energy. They arise throughout physics and engineering -- for instance, in
determining optimal paths through complex environments, modeling light
propagation in refractive media, and the study of spacetime trajectories in
control theory and general relativity. Despite their ubiquity, the scientific
machine learning (SciML) community has given relatively little attention to
investigating its methods in the context of these problems. In this work, we
argue that given their simple geometry, variational structure, and natural
nonlinearity, geodesic problems are particularly well-suited for the Deep Ritz
method. We substantiate this claim with three numerical examples drawn from
path planning, optics, and solid mechanics. Our goal is not to provide an
exhaustive study of geodesic problems, but rather to identify a promising
application of the Deep Ritz method and a fruitful direction for future SciML
research.

</details>


### [86] [An Advanced Two-Stage Model with High Sensitivity and Generalizability for Prediction of Hip Fracture Risk Using Multiple Datasets](https://arxiv.org/abs/2510.15179)
*Shuo Sun,Meiling Zhou,Chen Zhao,Joyce H. Keyak,Nancy E. Lane,Jeffrey D. Deng,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Kui Zhang,Weihua Zhou*

Main category: cs.LG

TL;DR: 该研究提出了一种序贯两阶段模型，通过整合临床和影像信息，提高了髋部骨折风险预测的准确性，尤其对于传统工具容易漏诊的高风险人群。


<details>
  <summary>Details</summary>
Motivation: 髋部骨折是老年人致残、致死和医疗负担的主要原因，目前常用的DXA T评分和FRAX工具在敏感性方面存在不足，常漏诊高风险个体，特别是无骨折史或骨量减少的患者。

Method: 该模型分为两个阶段：第一阶段（筛查）利用临床、人口统计学和功能变量评估基线风险；第二阶段（影像学）引入DXA衍生的特征进行风险细化。模型在MrOS、SOF和英国生物银行的数据中进行了内部和外部验证。

Result: 与T评分和FRAX相比，该两阶段框架具有更高的敏感性，减少了漏诊病例。

Conclusion: 该两阶段模型为早期髋部骨折风险评估提供了一种经济高效且个性化的方法。

Abstract: Hip fractures are a major cause of disability, mortality, and healthcare
burden in older adults, underscoring the need for early risk assessment.
However, commonly used tools such as the DXA T-score and FRAX often lack
sensitivity and miss individuals at high risk, particularly those without prior
fractures or with osteopenia. To address this limitation, we propose a
sequential two-stage model that integrates clinical and imaging information to
improve prediction accuracy. Using data from the Osteoporotic Fractures in Men
Study (MrOS), the Study of Osteoporotic Fractures (SOF), and the UK Biobank,
Stage 1 (Screening) employs clinical, demographic, and functional variables to
estimate baseline risk, while Stage 2 (Imaging) incorporates DXA-derived
features for refinement. The model was rigorously validated through internal
and external testing, showing consistent performance and adaptability across
cohorts. Compared to T-score and FRAX, the two-stage framework achieved higher
sensitivity and reduced missed cases, offering a cost-effective and
personalized approach for early hip fracture risk assessment.
  Keywords: Hip Fracture, Two-Stage Model, Risk Prediction, Sensitivity, DXA,
FRAX

</details>


### [87] [Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection](https://arxiv.org/abs/2510.15202)
*Denis Janiak,Jakub Binkowski,Tomasz Kajdanowicz*

Main category: cs.LG

TL;DR: 本文分析了表示几何和归一化对 OOD 性能的影响，并提出了一种新的归一化方法，通过调整特征空间的径向几何来改进 OOD 检测。


<details>
  <summary>Details</summary>
Motivation: Mahalanobis 距离方法在 OOD 检测中广泛使用，但表示几何和归一化对其性能的影响尚不完全清楚，这限制了其下游应用。

Method: 本文对多种图像基础模型、数据集和距离归一化方案进行了全面的实证研究，分析了 Mahalanobis 方法的可靠性、数据表示的理想几何以及归一化对 OOD 性能的影响。在此基础上，提出了一种径向缩放的 \(\ell_2\) 归一化方法。

Result: Mahalanobis 方法并非普遍可靠。光谱和内在维度指标可以准确预测模型的 OOD 性能。提出的径向缩放 \(\ell_2\) 归一化方法，通过引入可调参数来直接控制特征空间的径向几何，系统地收缩或扩展表示，显著提高了 OOD 检测性能。

Conclusion: 本文弥合了表示几何、归一化和 OOD 性能之间的鸿沟，为设计更有效和可靠的深度学习模型提供了新见解。

Abstract: Out-of-distribution (OOD) detection is critical for the reliable deployment
of deep learning models. hile Mahalanobis distance methods are widely used, the
impact of representation geometry and normalization on their performance is not
fully understood, which may limit their downstream application. To address this
gap, we conducted a comprehensive empirical study across diverse image
foundation models, datasets, and distance normalization schemes. First, our
analysis shows that Mahalanobis-based methods aren't universally reliable.
Second, we define the ideal geometry for data representations and demonstrate
that spectral and intrinsic-dimensionality metrics can accurately predict a
model's OOD performance. Finally, we analyze how normalization impacts OOD
performance. Building upon these studies, we propose radially scaled $\ell_2$
normalization, a method that generalizes the standard $\ell_2$ normalization
recently applied to Mahalanobis-based OOD detection. Our approach introduces a
tunable parameter to directly control the radial geometry of the feature space,
systematically contracting or expanding representations to significantly
improve OOD detection performance. By bridging the gap between representation
geometry, normalization, and OOD performance, our findings offer new insights
into the design of more effective and reliable deep learning models.

</details>


### [88] [ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning](https://arxiv.org/abs/2510.15211)
*Yongchan Kwon,Shang Zhu,Federico Bianchi,Kaitlyn Zhou,James Zou*

Main category: cs.LG

TL;DR: 本文介绍了ReasonIF，一个评估大型推理模型（LRMs）遵循推理指令能力的基准，并揭示了现有模型在此方面的显著不足，同时提出了两种改进策略。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）遵循用户指令的能力对其可靠性、安全性和实用性至关重要。本文认为，大型推理模型（LRMs）在推理过程中遵循用户指令也同样关键，这能提高模型的D可控性和透明度，并减少不必要的捷径、幻觉或奖励作弊的风险。

Method: 本文引入了ReasonIF，一个系统的基准来评估推理指令遵循。ReasonIF包含六类指令提示，涵盖多语言推理、格式和长度控制。作者评估了包括GPT-OSS、Qwen3和DeepSeek-R1在内的多种开源LRM模型。此外，本文还探讨了两种增强指令遵循的策略：（1）多轮推理和（2）使用合成数据进行推理指令微调（RIF）。

Result: 研究发现，现有的大型推理模型在指令遵循方面存在显著缺陷：最高的指令遵循得分（IFS）仍低于0.25，这意味着只有不到25%的推理轨迹符合给定指令。随着任务难度的增加，推理指令遵循能力进一步下降。RIF策略将GPT-OSS-20B的IFS从0.11提高到0.27。

Conclusion: 大型推理模型在遵循推理指令方面存在显著不足，尽管像RIF这样的策略能带来可衡量的改进，但仍有很大的提升空间。未来的研究应继续探索如何提高模型在推理过程中对指令的忠实度。

Abstract: The ability of large language models (LLMs) to follow user instructions is
central to their reliability, safety, and usefulness. While prior studies
assess instruction adherence in the model's main responses, we argue that it is
also critical for large reasoning models (LRMs) to follow user instructions
throughout their reasoning process. Reasoning instruction following makes LRMs
more controllable and transparent, while reducing risks of undesirable
shortcuts, hallucinations, or reward hacking within reasoning traces. To
evaluate this dimension, we introduce ReasonIF, a systematic benchmark for
assessing reasoning instruction following. ReasonIF includes six categories of
instruction prompts, spanning multilingual reasoning, formatting and length
control. Across many open-source LRMs including GPT-OSS, Qwen3, and
DeepSeek-R1, we find substantial failures in reasoning instruction adherence:
the highest instruction following score (IFS) remains below 0.25, meaning that
fewer than $25\%$ of reasoning traces comply with the given instructions.
Notably, as task difficulty increases, reasoning instruction following degrades
further. We also explore two strategies to enhance reasoning instruction
fidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning
(RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to
0.27, indicating measurable progress but leaving ample room for improvement.

</details>


### [89] [Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential](https://arxiv.org/abs/2510.15216)
*Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen*

Main category: cs.LG

TL;DR: 本文提出了一种微观度量“Soundness-Aware Level (SAL)”，用于衡量大型语言模型区分不同推理规则声音程度的能力，并发现这一能力与模型经过RLVR后的推理性能高度相关，这表明模型在预训练阶段区分知识可靠性的能力对其推理潜力至关重要。


<details>
  <summary>Details</summary>
Motivation: 探索不同基础模型在经过RLVR后性能差异巨大的原因，特别是预训练模型的何种微观特性导致了这种差异。

Method: 将推理形式化为由LLM潜在空间特征构建的Horn子句链，通过跨层稀疏自编码器（SAE）提取特征。估计特征之间的转移概率，并用LLM将每条规则的语义可靠性级别（例如，严格、合理、嘈杂）进行分类。引入Soundness-Aware Level (SAL）作为微观度量，使用Jensen-Shannon散度来衡量不同可信度级别规则之间内部概率分布的分离程度。

Result: 高潜力模型内在具有“可靠性感知”能力，其内部概率分布会系统地随着规则的可靠性级别（严格、合理、嘈杂）而变化，在“严格”与“嘈杂”规则之间表现出高度区别。而弱模型则对可靠性不敏感，无论可靠性级别如何，其分布均趋于一致。SAL对RLVR后推理性能的预测在不同的模型家族和规模上都遵循精确的经验定律（R^2=0.87）。

Conclusion: 模型的推理潜力与其预训练阶段区分可靠和不可靠知识的内在能力密切相关。这一发现强调了模型预训练在塑造推理能力方面的关键作用，并为选择/设计更强的基础模型提供了一个基于模型内部机制的实用指标。

Abstract: Reinforcement learning with verifiable rewards (RLVR) can elicit strong
reasoning in large language models (LLMs), while their performance after RLVR
varies dramatically across different base models. This raises a fundamental
question: what microscopic property of pre-trained models leads to this
variation? To investigate, we formalize reasoning as chains of Horn clauses
("if-then" rules) built from features extracted from the LLM's latent space via
cross-layer sparse autoencoders (SAEs). We estimate the transition
probabilities between its features, and further categorize each rule by its
semantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key
discovery is that high-potential models are inherently soundness-aware: their
internal probability distributions systematically shift across rules' soundness
levels, becoming highly distinct for "strict" versus "noisy" rules. In
contrast, weaker models are soundness-agnostic, collapsing to one distribution
regardless of soundness levels. To quantify this, we introduce the
Soundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon
Divergence to measure the separation between these distributions. We show that
SAL's predictions of post-RLVR reasoning performance follow a precise empirical
law (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek)
and scales (0.5B-14B). This reveals that a model's reasoning potential is tied
to its intrinsic, pre-trained ability to distinguish sound knowledge from
unsound ones. These findings underscore the critical role of model pre-training
in shaping reasoning and offer a practical metric grounded in the model's
internal mechanisms for selecting/designing stronger base models.

</details>


### [90] [Learning to Answer from Correct Demonstrations](https://arxiv.org/abs/2510.15464)
*Nirmit Joshi,Gene Li,Siddharth Bhandari,Shiva Prasad Kasiviswanathan,Cong Ma,Nathan Srebro*

Main category: cs.LG

TL;DR: 该论文研究了从给定问题（提示）生成答案（补全）的问题，其中可能存在多个正确答案，并且在测试时任何一个都是可接受的。


<details>
  <summary>Details</summary>
Motivation: 作者研究了上下文赌博机中的离线模仿学习，其中演示来自一些最优策略，没有明确观察到的奖励。先前的研究假设演示者属于低复杂度的策略类别，这促使采用最大似然估计（即对数损失最小化）。

Method: 提出了一种新颖的方法，该方法仅依赖于低基数类别的奖励模型（指定哪些答案是正确的），并通过对数样本复杂性学习。

Result: 作者指出，在这种情况下，最大似然方法可能会失效。他们的方法在奖励类的基数上具有对数样本复杂性。

Conclusion: 这项工作促使人们在从正确演示中学习时超越最大似然最大化。

Abstract: We study the problem of learning to generate an answer (or completion) to a
question (or prompt), where there could be multiple correct answers, any one of
which is acceptable at test time. Learning is based on demonstrations of some
correct answer to each training question, as in Supervised Fine Tuning (SFT).
We formalize the problem as offline imitation learning in contextual bandits,
with demonstrations from some optimal policy, without explicitly observed
rewards. Prior work assumes that the demonstrator belongs to a low-complexity
policy class, which motivates maximum likelihood estimation (i.e., log-loss
minimization). In contrast, we propose relying only on the reward model
(specifying which answers are correct) being in a low-cardinality class, which
we argue is a weaker assumption. We show that likelihood maximization methods
can fail in this case, and instead devise an alternative novel approach that
learns with sample complexity logarithmic in the cardinality of the reward
class. Our work motivates looking beyond likelihood maximization when learning
from correct demonstrations.

</details>


### [91] [Reflections from Research Roundtables at the Conference on Health, Inference, and Learning (CHIL) 2025](https://arxiv.org/abs/2510.15217)
*Emily Alsentzer,Marie-Laure Charpignon,Bill Chen,Niharika D'Souza,Jason Fries,Yixing Jiang,Aparajita Kashyap,Chanwoo Kim,Simon Lee,Aishwarya Mandyam,Ashery Christopher Mbilinyi,Nikita Mehandru,Nitish Nagesh,Brighton Nuwagira,Emma Pierson,Arvind Pillai,Akane Sano,Tanveer Syeda-Mahmood,Shashank Yadav,Elias Adhanom,Muhammad Umar Afza,Amelia Archer,Suhana Bedi,Vasiliki Bikia,Trenton Chang,George H. Chen,Winston Chen,Erica Chiang,Edward Choi,Octavia Ciora,Paz Dozie-Nnamah,Shaza Elsharief,Matthew Engelhard,Ali Eshragh,Jean Feng,Josh Fessel,Scott Fleming,Kei Sen Fong,Thomas Frost,Soham Gadgil,Judy Gichoya,Leeor Hershkovich,Sujeong Im,Bhavya Jain,Vincent Jeanselme,Furong Jia,Qixuan,Jin,Yuxuan Jin,Daniel Kapash,Geetika Kapoor,Behdokht Kiafar,Matthias Kleiner,Stefan Kraft,Annika Kumar,Daeun Kyung,Zhongyuan Liang,Joanna Lin,Qianchu,Liu,Chang Liu,Hongzhou Luan,Chris Lunt,Leopoldo Julían Lechuga López,Matthew B. A. McDermott,Shahriar Noroozizadeh,Connor O'Brien,YongKyung Oh,Mixail Ota,Stephen Pfohl,Meagan Pi,Tanmoy Sarkar Pias,Emma Rocheteau,Avishaan Sethi,Toru Shirakawa,Anita Silver,Neha Simha,Kamile Stankeviciute,Max Sunog,Peter Szolovits,Shengpu Tang,Jialu Tang,Aaron Tierney,John Valdovinos,Byron Wallace,Will Ke Wang,Peter Washington,Jeremy Weiss,Daniel Wolfe,Emily Wong,Hye Sun Yun,Xiaoman Zhang,Xiao Yu Cindy Zhang,Hayoung Jeong,Kaveri A. Thakoor*

Main category: cs.LG

TL;DR: 介绍了第六届健康、推理与学习大会（CHIL 2025）的研究圆桌会议。


<details>
  <summary>Details</summary>
Motivation: 促进机器学习与医疗保健交叉领域关键及时主题的协作式小组对话。

Method: 由资深和初级主席团队主持研究圆桌会议，围绕八个主题进行开放交流、智力探索和包容性参与。

Result: 成功举办了八个研究圆桌会议，涵盖了可解释性、不确定性、因果关系、领域适应、基础模型、小样本医疗数据学习、多模态方法和可扩展的转化医疗解决方案等主题。

Conclusion: CHIL 2025 的研究圆桌会议为机器学习和医疗保健领域的关键挑战、新兴机遇和可操作方向的集体构思提供了平台。

Abstract: The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025),
hosted by the Association for Health Learning and Inference (AHLI), was held in
person on June 25-27, 2025, at the University of California, Berkeley, in
Berkeley, California, USA. As part of this year's program, we hosted Research
Roundtables to catalyze collaborative, small-group dialogue around critical,
timely topics at the intersection of machine learning and healthcare. Each
roundtable was moderated by a team of senior and junior chairs who fostered
open exchange, intellectual curiosity, and inclusive engagement. The sessions
emphasized rigorous discussion of key challenges, exploration of emerging
opportunities, and collective ideation toward actionable directions in the
field. In total, eight roundtables were held by 19 roundtable chairs on topics
of "Explainability, Interpretability, and Transparency," "Uncertainty, Bias,
and Fairness," "Causality," "Domain Adaptation," "Foundation Models," "Learning
from Small Medical Data," "Multimodal Methods," and "Scalable, Translational
Healthcare Solutions."

</details>


### [92] [Adversary-Free Counterfactual Prediction via Information-Regularized Representations](https://arxiv.org/abs/2510.15479)
*Shiqin Tang,Rong Feng,Shuxin Zhuang,Hongzong Li,Youzhi Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种在存在分配偏差的情况下进行反事实预测的数学信息论方法，该方法无需对抗训练即可消除治疗-协变量依赖性。


<details>
  <summary>Details</summary>
Motivation: 在存在分配偏差的情况下进行反事实预测时，消除治疗-协变量依赖性是一个挑战。传统的对抗训练方法存在训练不稳定和调优负担。

Method: 本文提出了一种信息论方法。它通过学习一个随机表示 Z 来预测结果，同时最小化 I(Z; T)。作者推导出一个可处理的变分目标，该目标上限化了信息项并将其与监督解码器耦合，从而产生了一个稳定、经证明有动机的训练准则。该框架通过将信息惩罚应用于每个决策时间的顺序表示，自然地扩展到动态设置。

Result: 在似然、反事实误差和策略评估等指标上，该方法表现出色，同时避免了对抗方案的训练不稳定性和调优负担。

Conclusion: 该研究提出了一种新颖的、信息理论驱动的反事实预测方法，解决了分配偏差下的治疗-协变量依赖性问题，并在多个评估指标上优于现有技术，且具有更好的训练稳定性。

Abstract: We study counterfactual prediction under assignment bias and propose a
mathematically grounded, information-theoretic approach that removes
treatment-covariate dependence without adversarial training. Starting from a
bound that links the counterfactual-factual risk gap to mutual information, we
learn a stochastic representation Z that is predictive of outcomes while
minimizing I(Z; T). We derive a tractable variational objective that
upper-bounds the information term and couples it with a supervised decoder,
yielding a stable, provably motivated training criterion. The framework extends
naturally to dynamic settings by applying the information penalty to sequential
representations at each decision time. We evaluate the method on controlled
numerical simulations and a real-world clinical dataset, comparing against
recent state-of-the-art balancing, reweighting, and adversarial baselines.
Across metrics of likelihood, counterfactual error, and policy evaluation, our
approach performs favorably while avoiding the training instabilities and
tuning burden of adversarial schemes.

</details>


### [93] [Theoretical Refinement of CLIP by Utilizing Linear Structure of Optimal Similarity](https://arxiv.org/abs/2510.15508)
*Naoki Yoshida,Satoshi Hayakawa,Yuhta Takida,Toshimitsu Uesaka,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.LG

TL;DR: 这篇论文提出 KME-CLIP，旨在通过利用点态互信息（PMI）的线性结构，增强多模态对比预训练框架（如 CLIP）中的相似性计算机制。


<details>
  <summary>Details</summary>
Motivation: 目前 CLIP 及其变体并未充分利用点态互信息（PMI）的潜在线性结构，从而限制了配对模态间相似性度量的优化。

Method: 提出 KME-CLIP，通过在再生核希尔伯特空间中利用内积来利用 PMI 的线性结构。

Result: 理论证明 KME-CLIP 可以任意精度近似 PMI，并在多项检索和分类任务中，KME-CLIP 的表现优于标准 CLIP。

Conclusion: KME-CLIP 通过优化相似性计算机制，显著提升了多模态对比学习的效果。

Abstract: In this study, we propose an enhancement to the similarity computation
mechanism in multi-modal contrastive pretraining frameworks such as CLIP. Prior
theoretical research has demonstrated that the optimal similarity metrics
between paired modalities should correspond to the pointwise mutual information
(PMI) between the two modalities. However, the current implementations of CLIP
and its variants fail to fully utilize the underlying linear structure of PMI.
We therefore propose KME-CLIP, which leverages this structure through the inner
product in a reproducing kernel Hilbert space. We theoretically prove that our
method can approximate PMI with arbitrary accuracy and empirically demonstrate
that our approach overall outperforms the standard CLIP formulation across
several retrieval and classification tasks.

</details>


### [94] [Integrating Product Coefficients for Improved 3D LiDAR Data Classification (Part II)](https://arxiv.org/abs/2510.15219)
*Patricia Medina,Rasika Karkare*

Main category: cs.LG

TL;DR: 该研究通过结合乘积系数与自动编码器表示和KNN分类器，提升了3D激光雷达点云分类的性能，并发现逐步增加乘积系数能系统性地提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过引入乘积系数作为额外的度量理论描述符，从而增强3D激光雷达点云的分类效果。

Method: 本研究结合了乘积系数、自动编码器表示和KNN分类器进行3D激光雷达点云分类。

Result: 结合乘积系数、自动编码器表示和KNN分类器的方法在分类性能上持续超越了基于PCA的基线和先前的框架。逐步增加乘积系数能系统性地提高类别可分离性和整体准确性。

Conclusion: 将分层乘积系数特征与自动编码器相结合，能够进一步提升激光雷达分类的性能。

Abstract: This work extends our previous study on enhancing 3D LiDAR point-cloud
classification with product coefficients
\cite{medina2025integratingproductcoefficientsimproved}, measure-theoretic
descriptors that complement the original spatial Lidar features. Here, we show
that combining product coefficients with an autoencoder representation and a
KNN classifier delivers consistent performance gains over both PCA-based
baselines and our earlier framework. We also investigate the effect of adding
product coefficients level by level, revealing a clear trend: richer sets of
coefficients systematically improve class separability and overall accuracy.
The results highlight the value of combining hierarchical product-coefficient
features with autoencoders to push LiDAR classification performance further.

</details>


### [95] [Chronos-2: From Univariate to Universal Forecasting](https://arxiv.org/abs/2510.15821)
*Abdul Fatir Ansari,Oleksandr Shchur,Jaris Küken,Andreas Auer,Boran Han,Pedro Mercado,Syama Sundar Rangapuram,Huibin Shen,Lorenzo Stella,Xiyuan Zhang,Mononito Goswami,Shubham Kapoor,Danielle C. Maddix,Pablo Guerron,Tony Hu,Junming Yin,Nick Erickson,Prateek Mutalik Desai,Hao Wang,Huzefa Rangwala,George Karypis,Yuyang Wang,Michael Bohlke-Schneider*

Main category: cs.LG

TL;DR: Chronos-2是一个预训练的时间序列模型，它通过群组注意力机制在零样本学习中处理单变量、多变量和协变量的时间序列预测任务，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练时间序列模型主要关注单变量预测，限制了它们在现实世界中处理多变量数据和协变量的能力。

Method: Chronos-2采用群组注意力机制，通过在组内（代表相关序列集、多变量序列的变量或预测任务中的目标和协变量）高效共享信息来实现上下文学习（ICL），并通过在单变量序列上施加多样化多变量结构的人工合成数据集进行训练。

Result: Chronos-2在fev-bench、GIFT-Eval和Chronos Benchmark II三个综合基准测试中均取得了最先进的性能。特别是在fev-bench上，它在多变量和协变量预测方面显著优于现有模型，并在涉及协变量的任务中持续大幅超越基线。

Conclusion: Chronos-2的上下文学习能力使其成为一个通用的预测模型，可以直接应用于现实世界的预测流程中，具有很强的实用优势。

Abstract: Pretrained time series models have enabled inference-only forecasting systems
that produce accurate predictions without task-specific training. However,
existing approaches largely focus on univariate forecasting, limiting their
applicability in real-world scenarios where multivariate data and covariates
play a crucial role. We present Chronos-2, a pretrained model capable of
handling univariate, multivariate, and covariate-informed forecasting tasks in
a zero-shot manner. Chronos-2 employs a group attention mechanism that
facilitates in-context learning (ICL) through efficient information sharing
across multiple time series within a group, which may represent sets of related
series, variates of a multivariate series, or targets and covariates in a
forecasting task. These general capabilities are achieved through training on
synthetic datasets that impose diverse multivariate structures on univariate
series. Chronos-2 delivers state-of-the-art performance across three
comprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On
fev-bench, which emphasizes multivariate and covariate-informed forecasting,
Chronos-2's universal ICL capabilities lead to substantial improvements over
existing models. On tasks involving covariates, it consistently outperforms
baselines by a wide margin. Case studies in the energy and retail domains
further highlight its practical advantages. The in-context learning
capabilities of Chronos-2 establish it as a general-purpose forecasting model
that can be used "as is" in real-world forecasting pipelines.

</details>


### [96] [Stress-Aware Learning under KL Drift via Trust-Decayed Mirror Descent](https://arxiv.org/abs/2510.15222)
*Gabriel Nixon Raj*

Main category: cs.LG

TL;DR: 本文提出了一种信息熵正则化后的信任衰减模型，旨在解决在分布漂移下的序贯决策问题。该模型通过在信念更新和镜像下降决策中引入“压力感知”的指数倾斜，并分析了其在鲁棒性、动态遗憾等方面的表现，同时探讨了其在多种扩展场景下的应用，最终形成了一个统一的、自适应的更新框架。


<details>
  <summary>Details</summary>
Motivation: 在存在分布漂移的环境下优化序贯决策的鲁棒性，并通过引入“压力感知”的指数倾斜来提高决策的适应性和效率。

Method: 熵正则化信任衰减 (entropy-regularized trust-decay) 模型：
1. 在信念更新和镜像下降决策中引入“压力感知”的指数倾斜。
2. 利用Fenchel对偶性证明在单纯形上信念倾斜和决策倾斜的一致性。
3. 通过脆弱性（KL球内的最坏情况超额风险）、信念带宽（维持目标超额的半径）和决策空间脆弱性指数（在$O(\sqrt{T})$遗憾下可容忍的漂移）来量化鲁棒性。
4. 证明了高概率敏感性界限，并在KL-漂移路径长度$S_T = \sum_{t\ge2}\sqrt{{\rm KL}(D_t|D_{t-1})/2}$下建立了$\tilde{O}(\sqrt{T})$的动态遗憾保证。
5. 引入无参数对冲机制以适应未知漂移，并探讨了过度倾斜的惩罚。

Result: 1. 熵正则化信任衰减模型在KL-漂移下能实现$\tilde{O}(\sqrt{T})$的动态遗憾，且每次切换的遗憾为$O(1)$，优于无压力的$\\Omega(1)$尾部遗憾。
2. 在单纯形上，通过Fenchel对偶性证明了信念倾斜和决策倾斜的一致性。
3. 提出了一套量化鲁棒性的指标（脆弱性、信念带宽、决策空间脆弱性指数），并得到了高概率敏感性界限。
4. 设计了无参数对冲机制以适应未知漂移，避免了过度倾斜带来的$\Omega(\lambda^2 T)$惩罚。

Conclusion: 本文提出的熵正则化信任衰减框架为分布漂移下的序贯决策提供了一个统一且自适应的解决方案。通过引入“压力感知”的指数倾斜，显著提高了决策的鲁棒性和动态遗憾性能，并成功地将动态遗憾分析、分布鲁棒目标和KL正则化控制整合到一个框架中，为未来的研究和应用奠定了基础。

Abstract: We study sequential decision-making under distribution drift. We propose
entropy-regularized trust-decay, which injects stress-aware exponential tilting
into both belief updates and mirror-descent decisions. On the simplex, a
Fenchel-dual equivalence shows that belief tilt and decision tilt coincide. We
formalize robustness via fragility (worst-case excess risk in a KL ball),
belief bandwidth (radius sustaining a target excess), and a decision-space
Fragility Index (drift tolerated at $O(\sqrt{T})$ regret). We prove
high-probability sensitivity bounds and establish dynamic-regret guarantees of
$\tilde{O}(\sqrt{T})$ under KL-drift path length $S_T = \sum_{t\ge2}\sqrt{{\rm
KL}(D_t|D_{t-1})/2}$. In particular, trust-decay achieves $O(1)$ per-switch
regret, while stress-free updates incur $\Omega(1)$ tails. A parameter-free
hedge adapts the tilt to unknown drift, whereas persistent over-tilting yields
an $\Omega(\lambda^2 T)$ stationary penalty. We further obtain
calibrated-stress bounds and extensions to second-order updates, bandit
feedback, outliers, stress variation, distributed optimization, and plug-in
KL-drift estimation. The framework unifies dynamic-regret analysis,
distributionally robust objectives, and KL-regularized control within a single
stress-adaptive update.

</details>


### [97] [Learning Correlated Reward Models: Statistical Barriers and Opportunities](https://arxiv.org/abs/2510.15839)
*Yeshwanth Cherapanamjeri,Constantinos Daskalakis,Gabriele Farina,Sobhan Mohammadpour*

Main category: cs.LG

TL;DR: 本文探讨了避免IIA假设的相关概率模型的统计和计算挑战，发现成对偏好数据不足以学习相关信息，而“三选一”偏好数据可以克服这些缺点，并提出了一种统计计算高效的估计器。


<details>
  <summary>Details</summary>
Motivation: 此研究旨在解决经典随机效用模型（RUMs）在建模用户偏好时存在独立无关替代（IIA）假设的局限性，该假设导致对人类偏好范围的粗略近似。

Method: 通过分析相关概率模型（一种避免IIA假设的基本RUM）的统计和计算挑战，研究首先指出成对偏好数据在学习相关信息方面的根本不足。然后，提出“三选一”偏好数据可以克服这一缺点，并设计了一个统计和计算高效且接近最优性能的估计器。

Result: 成对偏好数据在学习相关信息方面是根本不足的。而“三选一”偏好数据可以有效克服这些缺点，并能通过所提出的估计器实现近乎最优的性能。理论保证在多个真实世界数据集上得到了验证，显示出对人类偏好个性化建模的改进。

Conclusion: 为了更精细地建模人类偏好，学习相关效用函数时，高阶偏好数据（如“三选一”偏好数据）优于传统的成对偏好数据，并且可以设计出高效的估计算法。

Abstract: Random Utility Models (RUMs) are a classical framework for modeling user
preferences and play a key role in reward modeling for Reinforcement Learning
from Human Feedback (RLHF). However, a crucial shortcoming of many of these
techniques is the Independence of Irrelevant Alternatives (IIA) assumption,
which collapses \emph{all} human preferences to a universal underlying utility
function, yielding a coarse approximation of the range of human preferences. On
the other hand, statistical and computational guarantees for models avoiding
this assumption are scarce. In this paper, we investigate the statistical and
computational challenges of learning a \emph{correlated} probit model, a
fundamental RUM that avoids the IIA assumption. First, we establish that the
classical data collection paradigm of pairwise preference data is
\emph{fundamentally insufficient} to learn correlational information,
explaining the lack of statistical and computational guarantees in this
setting. Next, we demonstrate that \emph{best-of-three} preference data
provably overcomes these shortcomings, and devise a statistically and
computationally efficient estimator with near-optimal performance. These
results highlight the benefits of higher-order preference data in learning
correlated utilities, allowing for more fine-grained modeling of human
preferences. Finally, we validate these theoretical guarantees on several
real-world datasets, demonstrating improved personalization of human
preferences.

</details>


### [98] [FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain](https://arxiv.org/abs/2510.15232)
*Tiansheng Hu,Tongyan Hu,Liuyang Bai,Yilun Zhao,Arman Cohan,Chen Zhao*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个名为 FinTrust 的基准测试，用于评估大型语言模型（LLMs）在金融应用中的可信赖性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在金融领域的应用面临高风险和高利害关系的挑战，因此需要对其可信赖性进行评估。

Method: FinTrust 基准测试通过一系列基于实际语境的对齐问题和细粒度任务，全面评估 LLMs 在金融应用中的可信赖性。

Result: 评估结果显示，专有模型（如 o4-mini）在安全性等大多数任务中表现优异，而开源模型（如 DeepSeek-V3）在行业级公平性等特定领域具有优势。在信托对齐和披露等挑战性任务中，所有 LLMs 都表现不佳，表明它们在法律意识方面存在显著差距。

Conclusion: FinTrust 可以作为评估 LLMs 在金融领域可信赖性的一个有价值的基准。

Abstract: Recent LLMs have demonstrated promising ability in solving finance related
problems. However, applying LLMs in real-world finance application remains
challenging due to its high risk and high stakes property. This paper
introduces FinTrust, a comprehensive benchmark specifically designed for
evaluating the trustworthiness of LLMs in finance applications. Our benchmark
focuses on a wide range of alignment issues based on practical context and
features fine-grained tasks for each dimension of trustworthiness evaluation.
We assess eleven LLMs on FinTrust and find that proprietary models like o4-mini
outperforms in most tasks such as safety while open-source models like
DeepSeek-V3 have advantage in specific areas like industry-level fairness. For
challenging task like fiduciary alignment and disclosure, all LLMs fall short,
showing a significant gap in legal awareness. We believe that FinTrust can be a
valuable benchmark for LLMs' trustworthiness evaluation in finance domain.

</details>


### [99] [Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction](https://arxiv.org/abs/2510.15233)
*Amitesh Badkul,Lei Xie*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为 TESSERA 的新型不确定性量化方法，用于在药物发现中实现可靠、信息丰富且适应性强的蛋白质-配体亲和力预测。


<details>
  <summary>Details</summary>
Motivation: 目前的机器学习方法在不确定性量化方面存在不足，特别是在风险敏感领域。大多数方法在提供新数据覆盖率、区间宽度或跟踪实际误差方面表现不佳，尤其是在分布偏移下。在高风险的药物发现中，蛋白质-配体亲和力 (PLI) 预测具有挑战性，因为测定噪声异构、化学空间不平衡且庞大，并且实际评估经常涉及分布偏移。

Method: TESSERA 是一种新颖的不确定性量化方法，它结合了专家混合 (MoE) 的多样性与共形校准。该方法旨在提供具有可靠覆盖保证的每个样本不确定性，以及跟踪绝对误差的信息丰富且自适应的预测区间宽度。

Result: TESSERA 在独立同分布 (i.i.d.) 和基于支架的分布外 (OOD) 分割下，对蛋白质-配体结合亲和力预测进行了评估，并与强大的 UQ 基线进行了比较。结果表明，TESSERA 达到了接近标称的覆盖率和最佳的覆盖宽度权衡（通过覆盖宽度标准 CWC 衡量），同时保持了竞争性的适应性（最低的稀疏化误差下面积 AUSE）。尺寸分层覆盖 (SSC) 进一步证实了区间的合理大小，表明当数据稀缺或嘈杂时宽度会增加，而当预测可靠时则保持紧密。

Conclusion: TESSERA 通过将专家混合 (MoE) 的多样性与共形校准相结合，提供了值得信赖、紧密且适应性强的不确定性，非常适用于药物发现流程和其他应用中的选择性预测和下游决策。

Abstract: Reliable, informative, and individual uncertainty quantification (UQ) remains
missing in current ML community. This hinders the effective application of
AI/ML to risk-sensitive domains. Most methods either fail to provide coverage
on new data, inflate intervals so broadly that they are not actionable, or
assign uncertainties that do not track actual error, especially under a
distribution shift. In high-stakes drug discovery, protein-ligand affinity
(PLI) prediction is especially challenging as assay noise is heterogeneous,
chemical space is imbalanced and large, and practical evaluations routinely
involve distribution shift. In this work, we introduce a novel uncertainty
quantification method, Trustworthy Expert Split-conformal with Scaled
Estimation for Efficient Reliable Adaptive intervals (TESSERA), that provides
per-sample uncertainty with reliable coverage guarantee, informative and
adaptive prediction interval widths that track the absolute error. We evaluate
on protein-ligand binding affinity prediction under both independent and
identically distributed (i.i.d.) and scaffold-based out-of-distribution (OOD)
splits, comparing against strong UQ baselines. TESSERA attains near-nominal
coverage and the best coverage-width trade-off as measured by the
Coverage-Width Criterion (CWC), while maintaining competitive adaptivity
(lowest Area Under the Sparsification Error (AUSE)). Size-Stratified Coverage
(SSC) further confirms that intervals are right-sized, indicating width
increases when data are scarce or noisy, and remain tight when predictions are
reliable. By unifying Mixture of Expert (MoE) diversity with conformal
calibration, TESSERA delivers trustworthy, tight, and adaptive uncertainties
that are well-suited to selective prediction and downstream decision-making in
the drug-discovery pipeline and other applications.

</details>


### [100] [Spatiotemporal Transformers for Predicting Avian Disease Risk from Migration Trajectories](https://arxiv.org/abs/2510.15254)
*Dingya Feng,Dingyuan Xue*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个基于Transformer的框架，用于预测候鸟迁徙路径终点疾病爆发的风险，该框架整合了多源数据，并通过评估展现出强大的预测性能，可用于禽类疾病预警系统。


<details>
  <summary>Details</summary>
Motivation: 候鸟疾病爆发的准确预测对于野生动物保护和公众健康至关重要，因此有必要开发一种能够有效预测疾病风险的方法。

Method: 本研究提出了一个基于Transformer的框架，用于预测候鸟迁徙轨迹终点站的疾病风险。该框架整合了Movebank的GPS追踪数据、世界动物卫生组织（WOAH）的疫情记录以及GADM和Natural Earth的地理空间背景等多源数据集。原始坐标通过H3分层地理空间编码进行处理以捕捉空间模式，模型从鸟类移动序列中学习时空依赖性来估计终点疾病风险。

Result: 在保留测试集上的评估显示出强大的预测性能，准确率达到0.9821，ROC曲线下面积（AUC）为0.9803，平均精度（AP）为0.9299，在最佳阈值下的F1分数达到0.8836。

Conclusion: 这些结果突显了Transformer架构在支持禽类疾病监测早期预警系统方面的潜力，从而实现及时干预和预防策略。

Abstract: Accurate forecasting of avian disease outbreaks is critical for wildlife
conservation and public health. This study presents a Transformer-based
framework for predicting the disease risk at the terminal locations of
migratory bird trajectories. We integrate multi-source datasets, including GPS
tracking data from Movebank, outbreak records from the World Organisation for
Animal Health (WOAH), and geospatial context from GADM and Natural Earth. The
raw coordinates are processed using H3 hierarchical geospatial encoding to
capture spatial patterns. The model learns spatiotemporal dependencies from
bird movement sequences to estimate endpoint disease risk. Evaluation on a
held-out test set demonstrates strong predictive performance, achieving an
accuracy of 0.9821, area under the ROC curve (AUC) of 0.9803, average precision
(AP) of 0.9299, and an F1-score of 0.8836 at the optimal threshold. These
results highlight the potential of Transformer architectures to support
early-warning systems for avian disease surveillance, enabling timely
intervention and prevention strategies.

</details>


### [101] [DRO-InstructZero: Distributionally Robust Prompt Optimization for Large Language Models](https://arxiv.org/abs/2510.15260)
*Yangyang Li*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为DRO-InstructZero的新方法，它将零样本提示优化视为鲁棒贝叶斯优化，以解决大型语言模型在分布偏移和对抗性评估下性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 已有的自动提示搜索方法（如InstructZero）在分布偏移和对抗性评估下表现不佳，因为它们仅针对单一评估分布下的预期性能进行优化，导致提示的迁移性差。

Method: DRO-InstructZero方法通过f-散度球定义评估分布周围的模糊集，并采用鲁棒采集规则，在保持贝叶斯搜索查询效率的同时，最大化最坏情况下的预期效用。这种搜索方法明确针对分布偏移下的可靠性，而非仅仅平均性能。

Result: 在BIG-Bench的“信息到正式改写”任务中，准确率从61.3%提高到85-90%，绝对提升了25-30个百分点。在领域转移下的自动调试任务中，性能提高了约25个百分点。同时，在因果关系等稳定任务上，表现仍保持在96%以上，表明未损失在分布内情况下的性能。

Conclusion: DRO-InstructZero将分布鲁棒优化与提示学习相结合，为在实际不确定性下实现可靠、可迁移的提示对齐提供了一种即插即用的通用方法。

Abstract: Large language models are highly sensitive to prompt wording. However,
popular automatic prompt search methods, including InstructZero, often degrade
under distribution shift and adversarial evaluation because they optimize
expected performance under a single evaluation distribution. Consequently,
prompts that work in one setting frequently fail to transfer. To address this,
DRO-InstructZero formulates zero-shot prompt optimization as robust Bayesian
optimization. Specifically, an f-divergence ball defines an ambiguity set
around the evaluation distribution, and a robust acquisition rule maximizes
worst-case expected utility while retaining the query efficiency of Bayesian
search. Therefore, the search explicitly targets reliability under distribution
shift rather than average behavior alone. Experiments follow the
instruction-induction protocol with matched query budgets across formality
rewriting, code debugging, and translation. For example, on BIG-Bench
informative-to-formal rewriting, accuracy improves from 61.3 +/- 0.7% to
approximately 85-90%, yielding an absolute gain of about 25-30 points.
Moreover, auto-debugging shows about +25-point gains under domain shift.
Meanwhile, stable tasks such as cause-and-effect remain above 96%, indicating
no loss on in-distribution cases. Furthermore, improvements are consistent
across divergence choices and decoding temperatures. Overall, DRO-InstructZero
connects distributionally robust optimization with prompt learning, offering a
plug-and-play and general approach for reliable, transferable prompt alignment
under real-world uncertainty.

</details>


### [102] [Causal Time Series Modeling of Supraglacial Lake Evolution in Greenland under Distribution Shift](https://arxiv.org/abs/2510.15265)
*Emam Hossain,Muhammad Hasan Ferdous,Devon Dunmire,Aneesh Subramanian,Md Osman Gani*

Main category: cs.LG

TL;DR: 该文章提出了一种名为RIC-TSC的区域信息因果时间序列分类框架，通过将滞后感知的因果发现直接嵌入到序列建模中，用于时空地球观测，从而在分布变化下提高了模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在时空地球观测领域，模型通常依赖于纯粹的关联特征，这些特征无法在异构域之间进行迁移，导致因果建模的潜力未被充分利用。

Method: 提出RIC-TSC框架，该框架将滞后感知的因果发现直接嵌入到序列建模中。利用多模态卫星和再分析数据（包括Sentinel-1微波反向散射、Sentinel-2和Landsat-8光学反射率以及CARRA气象变量），使用J-PCMCI+识别格陵兰冰上湖泊演变的区域特定和不变预测因子。因果图是全局和按流域估算的，并将经过验证的预测因子及其时间滞后提供给轻量级分类器。

Result: 在2018-2019年两个对比融化季节中，对1000个手动标记的湖泊进行平衡基准测试，在 OOD 评估下，因果模型比基于相关性的基线模型准确率提高了12.59%。

Conclusion: 因果发现不仅是一种特征选择的方法，也是建立动态地球表面过程的通用且基于机制的模型的途径。该研究强调了因果建模在提高地球观测模型在分布变化下的鲁棒性和泛化能力方面的潜力。

Abstract: Causal modeling offers a principled foundation for uncovering stable,
invariant relationships in time-series data, thereby improving robustness and
generalization under distribution shifts. Yet its potential is underutilized in
spatiotemporal Earth observation, where models often depend on purely
correlational features that fail to transfer across heterogeneous domains. We
propose RIC-TSC, a regionally-informed causal time-series classification
framework that embeds lag-aware causal discovery directly into sequence
modeling, enabling both predictive accuracy and scientific interpretability.
Using multi-modal satellite and reanalysis data-including Sentinel-1 microwave
backscatter, Sentinel-2 and Landsat-8 optical reflectance, and CARRA
meteorological variables-we leverage Joint PCMCI+ (J-PCMCI+) to identify
region-specific and invariant predictors of supraglacial lake evolution in
Greenland. Causal graphs are estimated globally and per basin, with validated
predictors and their time lags supplied to lightweight classifiers. On a
balanced benchmark of 1000 manually labeled lakes from two contrasting melt
seasons (2018-2019), causal models achieve up to 12.59% higher accuracy than
correlation-based baselines under out-of-distribution evaluation. These results
show that causal discovery is not only a means of feature selection but also a
pathway to generalizable and mechanistically grounded models of dynamic Earth
surface processes.

</details>


### [103] [Semi-Supervised Regression with Heteroscedastic Pseudo-Labels](https://arxiv.org/abs/2510.15266)
*Xueqing Sun,Renzhen Wang,Quanziang Wang,Yichen Wu,Xixi Jia,Deyu Meng*

Main category: cs.LG

TL;DR: 本文提出了一种不确定性感知伪标签框架，用于半监督回归，通过动态调整伪标签影响力，有效缓解了伪标签不可靠造成的误差累积和过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 半监督回归（SSR）中的伪标签方法应用不足，原因是伪标签在连续输出和异方差噪声下难以评估可靠性，导致误差累积和过拟合。

Method: 提出了一种不确定性感知伪标签框架，从双层优化角度动态调整伪标签影响力，联合最小化所有数据的经验风险，并优化不确定性估计以增强在有标签数据上的泛化能力。

Result: 在多个基准SSR数据集上进行了广泛实验，结果表明该方法相比现有方法具有卓越的鲁棒性和性能。

Conclusion: 本文提出的不确定性感知伪标签框架能有效缓解半监督回归中伪标签不可靠带来的问题，提升模型性能和鲁棒性。

Abstract: Pseudo-labeling is a commonly used paradigm in semi-supervised learning, yet
its application to semi-supervised regression (SSR) remains relatively
under-explored. Unlike classification, where pseudo-labels are discrete and
confidence-based filtering is effective, SSR involves continuous outputs with
heteroscedastic noise, making it challenging to assess pseudo-label
reliability. As a result, naive pseudo-labeling can lead to error accumulation
and overfitting to incorrect labels. To address this, we propose an
uncertainty-aware pseudo-labeling framework that dynamically adjusts
pseudo-label influence from a bi-level optimization perspective. By jointly
minimizing empirical risk over all data and optimizing uncertainty estimates to
enhance generalization on labeled data, our method effectively mitigates the
impact of unreliable pseudo-labels. We provide theoretical insights and
extensive experiments to validate our approach across various benchmark SSR
datasets, and the results demonstrate superior robustness and performance
compared to existing methods. Our code is available at
https://github.com/sxq/Heteroscedastic-Pseudo-Labels.

</details>


### [104] [On the Generalization Properties of Learning the Random Feature Models with Learnable Activation Functions](https://arxiv.org/abs/2510.15327)
*Zailin Ma,Jiansheng Yang,Yaodong Yang*

Main category: cs.LG

TL;DR: 本文研究了可学习激活函数随机特征模型（RFLAF）的泛化特性，通过数据依赖的采样方案，在回归和分类任务中获得了特征所需数量的最优界限。


<details>
  <summary>Details</summary>
Motivation: 为了解决RFLAF模型在回归和分类任务中泛化性能的特征数量问题，本文引入了数据依赖的采样方案。

Method: 本文提出了一种数据依赖的采样方案来生成特征，并通过加权采样改进了特征数量的界限，并提供了统一的定理来描述特征数量s的复杂性。

Result: 通过加权采样，MSE损失情况下s的界限从Ω(1/ε^2)改进到通常的ที(1/ε)^(1/t)，当Gram矩阵具有有限秩时甚至可以达到Ω(1)。对于Lipschitz损失情况，界限从Ω(1/ε^2)改进到ที(1/ε^2)^(1/t)。

Conclusion: 加权RFLAF在显著减少特征数量的情况下实现了与普通采样RFLAF相同的性能，验证了该理论的有效性。

Abstract: This paper studies the generalization properties of a recently proposed
kernel method, the Random Feature models with Learnable Activation Functions
(RFLAF). By applying a data-dependent sampling scheme for generating features,
we provide by far the sharpest bounds on the required number of features for
learning RFLAF in both the regression and classification tasks. We provide a
unified theorem that describes the complexity of the feature number $s$, and
discuss the results for the plain sampling scheme and the data-dependent
leverage weighted scheme. Through weighted sampling, the bound on $s$ in the
MSE loss case is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon)^{1/t})$ in general $(t\geq 1)$, and even to
$\Omega(1)$ when the Gram matrix has a finite rank. For the Lipschitz loss
case, the bound is improved from $\Omega(1/\epsilon^2)$ to
$\tilde{\Omega}((1/\epsilon^2)^{1/t})$. To learn the weighted RFLAF, we also
propose an algorithm to find an approximate kernel and then apply the leverage
weighted sampling. Empirical results show that the weighted RFLAF achieves the
same performances with a significantly fewer number of features compared to the
plainly sampled RFLAF, validating our theories and the effectiveness of this
method.

</details>


### [105] [Towards Robust Zero-Shot Reinforcement Learning](https://arxiv.org/abs/2510.15382)
*Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xiayuan Zhan*

Main category: cs.LG

TL;DR: BREEZE，一种基于FB的零样本强化学习框架，通过行为正则化、任务条件扩散模型和注意力机制，提高了学习稳定性、策略提取能力和表示学习质量，在零样本RL任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本强化学习方法（如基于FB表示的方法）存在表达能力不足和离线学习中OOD动作导致的偏差表示问题，从而导致次优的性能。

Method: BREEZE通过引入行为正则化将策略优化转化为稳定的样本内学习范式。它使用任务条件扩散模型来提取策略，以生成高质量和多模态的动作分布。它还采用富有表现力的基于注意力的架构进行表示建模，以捕获环境动态之间复杂的关系。

Result: BREEZE在ExORL和D4RL Kitchen数据集上取得了最佳或接近最佳的性能，并且比之前的离线零样本强化学习方法表现出更优越的鲁棒性。

Conclusion: BREEZE通过在零样本强化学习中引入行为正则化、任务条件扩散模型和注意力机制，有效解决了现有方法的表达能力不足和OOD动作导致的偏差表示问题，显著提升了零样本RL的性能和鲁棒性。

Abstract: The recent development of zero-shot reinforcement learning (RL) has opened a
new avenue for learning pre-trained generalist policies that can adapt to
arbitrary new tasks in a zero-shot manner. While the popular Forward-Backward
representations (FB) and related methods have shown promise in zero-shot RL, we
empirically found that their modeling lacks expressivity and that extrapolation
errors caused by out-of-distribution (OOD) actions during offline learning
sometimes lead to biased representations, ultimately resulting in suboptimal
performance. To address these issues, we propose Behavior-REgularizEd Zero-shot
RL with Expressivity enhancement (BREEZE), an upgraded FB-based framework that
simultaneously enhances learning stability, policy extraction capability, and
representation learning quality. BREEZE introduces behavioral regularization in
zero-shot RL policy learning, transforming policy optimization into a stable
in-sample learning paradigm. Additionally, BREEZE extracts the policy using a
task-conditioned diffusion model, enabling the generation of high-quality and
multimodal action distributions in zero-shot RL settings. Moreover, BREEZE
employs expressive attention-based architectures for representation modeling to
capture the complex relationships between environmental dynamics. Extensive
experiments on ExORL and D4RL Kitchen demonstrate that BREEZE achieves the best
or near-the-best performance while exhibiting superior robustness compared to
prior offline zero-shot RL methods. The official implementation is available
at: https://github.com/Whiterrrrr/BREEZE.

</details>


### [106] [Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning](https://arxiv.org/abs/2510.15388)
*Mingyang Sun,Pengxiang Ding,Weinan Zhang,Donglin Wang*

Main category: cs.LG

TL;DR: 作者提出了SWFP框架，它通过将流匹配推理过程离散化为固定步长的欧拉方案，使其与最优传输的变分JKO原理对齐。SWFP将全局流分解为一系列小的增量变换，每个步骤对应一个JKO更新，通过熵正则化稳定在线适应。这提供了一种高效的算法，可以通过级联的小流块调整预训练流，从而显著提高稳定性、效率和适应性能。


<details>
  <summary>Details</summary>
Motivation: 行为克隆在学习复杂技能方面表现出色，但容易受到分布偏移的影响。标准的强化学习方法在微调这些模型时遇到困难，因为它们的迭代推理过程和现有解决方案的局限性。

Method: 作者提出了分步流策略（SWFP）框架，该框架基于一个关键的见解：通过固定步长欧拉方案离散化流匹配推理过程，使其与最优传输的变分Jordan-Kinderlehrer-Otto（JKO）原理固有地对齐。SWFP将全局流分解为一系列小的增量变换，这些变换介于近似分布之间。每个步骤都对应一个JKO更新，通过将策略变化保持在先前迭代附近来规范化，并通过熵正则化确保稳定的在线适应。这种分解产生了一种高效的算法，该算法通过级联的小流块微调预训练流，从而提供了显著的优势：子模型训练更简单/更快、计算/内存成本降低以及基于Wasserstein信任区域的可靠稳定性。

Result: SWFP显著提高了稳定性、效率和在各种机器人控制基准下的卓越适应性能。

Conclusion: SWFP框架通过将流匹配推理过程离散化为与JKO原理对齐的固定步长欧拉方案，有效地解决了行为克隆中分布偏移和微调困难的问题。该方法在机器人控制任务中表现出卓越的稳定性、效率和适应性能。

Abstract: While behavior cloning with flow/diffusion policies excels at learning
complex skills from demonstrations, it remains vulnerable to distributional
shift, and standard RL methods struggle to fine-tune these models due to their
iterative inference process and the limitations of existing workarounds. In
this work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on
the key insight that discretizing the flow matching inference process via a
fixed-step Euler scheme inherently aligns it with the variational
Jordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP
decomposes the global flow into a sequence of small, incremental
transformations between proximate distributions. Each step corresponds to a JKO
update, regularizing policy changes to stay near the previous iterate and
ensuring stable online adaptation with entropic regularization. This
decomposition yields an efficient algorithm that fine-tunes pre-trained flows
via a cascade of small flow blocks, offering significant advantages:
simpler/faster training of sub-models, reduced computational/memory costs, and
provable stability grounded in Wasserstein trust regions. Comprehensive
experiments demonstrate SWFP's enhanced stability, efficiency, and superior
adaptation performance across diverse robotic control benchmarks.

</details>


### [107] [Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowing](https://arxiv.org/abs/2510.15404)
*Christopher Salazar,Krithika Manohar,Ashis G. Banerjee*

Main category: cs.LG

TL;DR: 该文章介绍了一种名为WORK-DMD的新方法，用于从流数据中进行实时预测。


<details>
  <summary>Details</summary>
Motivation: 处理流数据实时预测中的非平稳动态、严格的计算限制以及在不出现灾难性遗忘的情况下快速适应。

Method: WORK-DMD（Windowed Online Random Kernel Dynamic Mode Decomposition）结合了随机傅立叶特征和在线动态模式分解，通过明确的特征映射捕获非线性动态。它在滚动窗口内使用Sherman-Morrison更新，实现对演变动态的持续适应。

Result: WORK-DMD在多个领域的基准数据集上显示出比现有最先进的在线预测方法更高的准确性，只需单次遍历数据，并在短期预测中表现出色。

Conclusion: 将核评估与自适应矩阵更新相结合，可以以最少的数据需求实现强大的预测性能，为流式预测应用提供了一种实用的深度学习替代方案。

Abstract: Real-time forecasting from streaming data poses critical challenges: handling
non-stationary dynamics, operating under strict computational limits, and
adapting rapidly without catastrophic forgetting. However, many existing
approaches face trade-offs between accuracy, adaptability, and efficiency,
particularly when deployed in constrained computing environments. We introduce
WORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method
that combines Random Fourier Features with online Dynamic Mode Decomposition to
capture nonlinear dynamics through explicit feature mapping, while preserving
fixed computational cost and competitive predictive accuracy across evolving
data. WORK-DMD employs Sherman-Morrison updates within rolling windows,
enabling continuous adaptation to evolving dynamics from only current data,
eliminating the need for lengthy training or large storage requirements for
historical data. Experiments on benchmark datasets across several domains show
that WORK-DMD achieves higher accuracy than several state-of-the-art online
forecasting methods, while requiring only a single pass through the data and
demonstrating particularly strong performance in short-term forecasting. Our
results show that combining kernel evaluations with adaptive matrix updates
achieves strong predictive performance with minimal data requirements. This
sample efficiency offers a practical alternative to deep learning for streaming
forecasting applications.

</details>


### [108] [ParaFormer: Shallow Parallel Transformers with Progressive Approximation](https://arxiv.org/abs/2510.15425)
*Wei Wang,Xiao-Yong Wei,Qing Li*

Main category: cs.LG

TL;DR: ParaFormer是一种为实现结构和计算上的真正并行性而设计的浅层Transformer架构，通过将层组织成并行分支并算法上强制实现层间协作，从而在不增加模型深度的情况下提高性能并支持模型压缩和扩展。


<details>
  <summary>Details</summary>
Motivation: 传统的“越深越好”理念导致了ResNet和Transformer等深度架构的出现，但这也带来了训练时间长、推理延迟高以及在资源受限设备上不实用等问题。

Method: 提出ParaFormer，一种浅层Transformer架构。通过将标准Transformer表述为封闭形式的函数逼近器，理论分析表明其性能依赖于层间协作的逐步逼近，而非深度本身。ParaFormer通过将层组织成并行分支来消除顺序约束，并通过算法强制实现层间协作。具体而言，它实现了渐进式逼近，确保每个新分支进一步减少前一个分支的损失，从而加快收敛速度。

Result: ParaFormer在多项实验中优于标准Transformer模型（如ViT）。 ParaFormer支持高达15.07倍的模型压缩，并促进模型扩展以实现自适应连续学习。在多GPU部署上的实验结果表明，ParaFormer比FairScale等广泛使用的并行解决方案快3.30倍。

Conclusion: ParaFormer的成功源于基于通用逼近定理的Transformer封闭形式表述，这不仅解释了“深度信念”，还为设计高效的Transformer架构开辟了新途径。

Abstract: The widespread 'deeper is better' philosophy has driven the creation of
architectures like ResNet and Transformer, which achieve high performance by
stacking numerous layers. However, increasing model depth comes with challenges
such as longer training times, higher inference latency, and impracticality on
resource-constrained devices. To address these issues, we propose ParaFormer, a
shallow Transformer architecture designed for true parallelism in both
structure and computation. By formulating standard Transformers as function
approximators in closed-form, our theoretical analysis shows that their
performance relies on inter-layer collaboration for progressive approximation,
rather than depth itself. While deep Transformers enforce this collaboration
through sequential designs, we demonstrate that such collaboration is not
inherently tied to sequential structures. ParaFormer removes the sequential
constraint by organizing layers into parallel branches, enforcing inter-layer
collaboration algorithmically. Specifically, we implement progressive
approximation, ensuring that each new branch further reduces the loss from
preceding branches, enabling faster convergence. Extensive experiments validate
ParaFormer's effectiveness, outperforming standard Transformers like ViT.
Moreover, ParaFormer supports up to 15.07x model compression and facilitates
model expansion for adaptive continuous learning. Experimental results on
multi-GPU deployment demonstrate that ParaFormer is 3.30x faster than widely
used parallelism solutions such as FairScale. These advancements stem from our
closed-form formulation of Transformers based on the Universal Approximation
Theorem, which not only explains the ``depth belief'' but also opens new
avenues for designing efficient Transformer architectures. Source code:
https://(open-upon-acceptance)

</details>


### [109] [Safe, Efficient, and Robust Reinforcement Learning for Ranking and Diffusion Models](https://arxiv.org/abs/2510.15429)
*Shashank Gupta*

Main category: cs.LG

TL;DR: 这篇论文探讨了如何设计安全、样本高效且鲁棒的强化学习方法，并将其应用于排名和推荐系统以及文本到图像扩散模型。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，如何安全、高效且鲁棒地设计方法。

Method: 本研究通过上下文老虎机强化学习的视角，开发了用于排名系统安全部署的理论和算法，包括曝光泛化界限和反事实风险最小化目标，并将其扩展至双重鲁棒估计器。针对单动作老虎机，统一了不同的离策略估计器，并提出了最优基线来最小化评估和策略梯度方差。在生成式强化学习方面，通过对PPO和REINFORCE的系统研究，提出了Leave-One-Out PPO（LOOP）算法，该算法将多个扩散轨迹与REINFORCE风格的基线结合在PPO的裁剪目标中。

Result: 推导了曝光泛化界限，得到了反事实风险最小化目标，该目标能保证在稀疏反馈下不低于日志策略的表现，并能扩展到双重鲁棒估计器。提出了闭式最优基线，能最小化评估和策略梯度方差。提出了LOOP算法，该算法在实现PPO级别的样本效率的同时，能生成与文本属性更忠实对齐的内容。

Conclusion: 本研究通过理论和算法的创新，有效提升了强化学习在安全性、样本效率和鲁棒性方面的表现，并在排名系统、单动作老虎机和生成式强化学习等领域取得了显著成果。

Abstract: This dissertation investigates how reinforcement learning (RL) methods can be
designed to be safe, sample-efficient, and robust. Framed through the unifying
perspective of contextual-bandit RL, the work addresses two major application
domains - ranking and recommendation, and text-to-image diffusion models. The
first part of the thesis develops theory and algorithms for safe deployment in
ranking systems. An exposure-based generalisation bound is derived, leading to
a counterfactual risk-minimisation objective whose solution is guaranteed not
to underperform the logging policy, even with sparse feedback. This guarantee
is extended to doubly robust estimators, enabling safety even under adversarial
or misspecified user models and offering practitioners explicit control over
permissible utility loss. The second part turns to single-action bandits, where
various off-policy estimators are unified within a baseline-correction
framework. A closed-form optimal baseline is proposed and shown to minimise
both evaluation and policy-gradient variance, thereby improving off-policy
learning reliability. The final part examines the trade-offs between efficiency
and effectiveness in generative RL. A systematic study of PPO and REINFORCE
motivates the Leave-One-Out PPO (LOOP) algorithm, which combines multiple
diffusion trajectories with a REINFORCE-style baseline inside PPO's clipped
objective. LOOP achieves PPO-level sample efficiency while producing
generations that align more faithfully with textual attributes.

</details>


### [110] [A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning](https://arxiv.org/abs/2510.15444)
*Zhi Zhou,Yuhao Tan,Zenan Li,Yuan Yao,Lan-Zhe Guo,Yu-Feng Li,Xiaoxing Ma*

Main category: cs.LG

TL;DR: 这篇论文提出了一个名为RPC的混合方法，用于提高大语言模型在测试时推理的性能，该方法结合了Perplexity Consistency和Reasoning Pruning，旨在解决现有方法（如自洽性和困惑度）的局限性，并在理论分析和实证结果中显示出强大的潜力。


<details>
  <summary>Details</summary>
Motivation: 目前基于采样的测试时缩放方法在提高大型语言模型（LLMs）的推理性能方面取得了实际成功，但其理论基础尚未得到充分探索。现有的方法，如自洽性和困惑度，存在高估计误差或显著建模误差以及估计误差收敛性可能下降的问题。

Method: 本文提出了一个名为RPC（Perplexity Consistency和Reasoning Pruning）的混合方法。Perplexity Consistency旨在结合自洽性和困惑度的优点，将估计误差的收敛速度从线性提高到指数，同时保持模型误差。Reasoning Pruning通过消除低概率的推理路径来防止性能下降。本文还提供了一个分析基于采样的测试时缩放方法的理论框架，并基于置信度估计的视角进行分析。

Result: RPC混合方法在七个基准数据集上的理论分析和实证结果表明，它在减少推理误差方面具有强大潜力。值得注意的是，RPC在提高置信度可靠性的同时，将采样成本降低了50%，并且取得了与自洽性方法相当的推理性能。

Conclusion: 本文提出了第一个分析基于采样的测试时缩放方法的理论框架，并在此基础上引入了RPC混合方法。RPC通过结合Perplexity Consistency和Reasoning Pruning，有效地解决了现有方法的局限性，提高了大语言模型在测试时推理的性能，同时降低了采样成本。

Abstract: Test-time scaling seeks to improve the reasoning performance of large
language models (LLMs) by adding computational resources. A prevalent approach
within the field is sampling-based test-time scaling methods, which enhance
reasoning by generating multiple reasoning paths for a given input during
inference. However, despite its practical success, the theoretical foundations
remain underexplored. In this paper, we provide the first theoretical framework
for analyzing sampling-based test-time scaling methods, grounded in the
perspective of confidence estimation. Based on the framework, we analyze two
dominant paradigms: self-consistency and perplexity, and reveal key
limitations: self-consistency suffers from high estimation error while
perplexity exhibits substantial modeling error and possible degradation of the
estimation error convergence. To address these limitations, we introduce RPC, a
hybrid method that leverages our theoretical insights through two key
components: Perplexity Consistency and Reasoning Pruning. Perplexity
Consistency combines the strengths of self-consistency and perplexity, boosting
the convergence rate of estimation error from linear to exponential while
preserving model error. Reasoning Pruning prevents degradation by eliminating
low-probability reasoning paths. Both theoretical analysis and empirical
results across seven benchmark datasets demonstrate that RPC has a strong
potential for reducing reasoning error. Notably, RPC achieves reasoning
performance comparable to self-consistency while not only enhancing confidence
reliability but also reducing sampling costs by 50%. The code and resources are
available at https://wnjxyk.github.io/RPC.

</details>


### [111] [Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment](https://arxiv.org/abs/2510.15456)
*Jan Corazza,Hadi Partovi Aria,Daniel Neider,Zhe Xu*

Main category: cs.LG

TL;DR: 该论文提出了一种将因果信息纳入奖励形式的新方法，以加速策略学习并帮助任务规范的迁移。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习算法在稀疏奖励和复杂事件序列的任务中表现不佳。概率奖励机（PRMs）虽然能捕捉奖励信号中的时间依赖性和不确定性，但手动修改和设计困难，阻碍了高层因果知识的利用和奖励形式向新领域的迁移。

Method: 提出了一种将因果信息以时序逻辑因果图（Temporal Logic-based Causal Diagrams）的形式整合到奖励形式中的新方法。

Result: 加速了策略学习，并有助于任务规范向新环境的迁移。同时，本文还提供了关于该方法收敛到最优策略的理论结果，并通过实验证明了其有效性。

Conclusion: 本研究通过引入时序逻辑因果图，有效解决了强化学习中稀疏奖励和任务迁移的挑战，为构建更高效和可迁移的强化学习系统提供了新途径。

Abstract: Reinforcement learning (RL) algorithms struggle with learning optimal
policies for tasks where reward feedback is sparse and depends on a complex
sequence of events in the environment. Probabilistic reward machines (PRMs) are
finite-state formalisms that can capture temporal dependencies in the reward
signal, along with nondeterministic task outcomes. While special RL algorithms
can exploit this finite-state structure to expedite learning, PRMs remain
difficult to modify and design by hand. This hinders the already difficult
tasks of utilizing high-level causal knowledge about the environment, and
transferring the reward formalism into a new domain with a different causal
structure. This paper proposes a novel method to incorporate causal information
in the form of Temporal Logic-based Causal Diagrams into the reward formalism,
thereby expediting policy learning and aiding the transfer of task
specifications to new environments. Furthermore, we provide a theoretical
result about convergence to optimal policy for our method, and demonstrate its
strengths empirically.

</details>


### [112] [OffSim: Offline Simulator for Model-based Offline Inverse Reinforcement Learning](https://arxiv.org/abs/2510.15495)
*Woo-Jin Ahn,Sang-Ryul Baek,Yong-Jun Lee,Hyun-Duck Choi,Myo-Taeg Lim*

Main category: cs.LG

TL;DR: OffSim是一个离线逆强化学习框架，能够从专家轨迹中学习环境动态和奖励函数，从而无需真实环境交互即可训练策略。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习需要耗时耗力地开发交互式模拟器和手动定义奖励函数。

Method: OffSim通过共同优化高熵转换模型和基于IRL的奖励函数来模拟环境动态和奖励结构。OffSim$^+$是其扩展，引入了边际奖励以处理多数据集设置。

Result: 在MuJoCo实验中，OffSim比现有离线IRL方法取得了显著的性能提升。

Conclusion: OffSim框架有效且鲁棒，能够通过从专家轨迹中学习来离线训练策略，解决了传统强化学习的模拟器和奖励函数定义难题。

Abstract: Reinforcement learning algorithms typically utilize an interactive simulator
(i.e., environment) with a predefined reward function for policy training.
Developing such simulators and manually defining reward functions, however, is
often time-consuming and labor-intensive. To address this, we propose an
Offline Simulator (OffSim), a novel model-based offline inverse reinforcement
learning (IRL) framework, to emulate environmental dynamics and reward
structure directly from expert-generated state-action trajectories. OffSim
jointly optimizes a high-entropy transition model and an IRL-based reward
function to enhance exploration and improve the generalizability of the learned
reward. Leveraging these learned components, OffSim can subsequently train a
policy offline without further interaction with the real environment.
Additionally, we introduce OffSim$^+$, an extension that incorporates a
marginal reward for multi-dataset settings to enhance exploration. Extensive
MuJoCo experiments demonstrate that OffSim achieves substantial performance
gains over existing offline IRL methods, confirming its efficacy and
robustness.

</details>


### [113] [The Road Less Traveled: Enhancing Exploration in LLMs via Sequential Sampling](https://arxiv.org/abs/2510.15502)
*Shijia Kang,Muhan Zhang*

Main category: cs.LG

TL;DR: SESA通过顺序采样而非并行采样的方式，解决了大型语言模型（LLMs）在强化学习（RL）中遇到的探索不足和熵崩溃问题，通过多样化的解决方案草图提高了LLMs在各种任务中的性能和策略探索。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在强化学习（RL）中进行推理时，经常面临探索不足和熵崩溃的问题。这意味着模型倾向于利用一组狭窄的解决方案，导致采样多样性丧失，并阻碍RL进一步提升性能，尤其是在并行采样方法中，该问题更为突出，因为所有输出都来自同一分布，可能导致模型收敛于相似的解决方案。

Method: 本文提出了SESA（SEquential SAmpling）框架，通过顺序生成多样化的解决方案草图，然后将其扩展为完整的推理路径，以此来缓解探索不足和熵崩溃问题。这种方法通过将每个新输出都建立在之前的输出之上，确保了更广泛的探索，从而促进了整个过程中的多样性，并防止了策略崩溃。

Result: 在合成任务上的实验表明，顺序采样在路径多样性和从崩溃中恢复方面始终优于传统的强化学习方法。在真实世界任务上的进一步评估表明，SESA提高了有效策略的探索和LLMs的整体性能。在三个智能体基准测试中，SESA将成功率较基础模型分别提高了+0.25、+0.42和+0.07（相对于基线RL，最高额外提高了211%）。

Conclusion: SESA引入了一种结构化的探索方法，为RL训练的LLMs中更有效和多样化的推理铺平了道路。

Abstract: Reinforcement learning (RL) has been pivotal in enhancing the reasoning
capabilities of large language models (LLMs), but it often suffers from limited
exploration and entropy collapse, where models exploit a narrow set of
solutions, leading to a loss of sampling diversity and subsequently preventing
RL from further improving performance. This issue is exacerbated in parallel
sampling methods, where multiple outputs are drawn from the same distribution,
potentially causing the model to converge to similar solutions. We propose
SESA, a novel SEquential SAmpling framework that mitigates this challenge by
generating diverse solution sketches sequentially before expanding them into
full reasoning paths. This approach ensures broader exploration by conditioning
each new output on previous ones, promoting diversity throughout the process
and preventing policy collapse. Our experiments on a synthetic task show that
sequential sampling consistently outperforms traditional RL methods in terms of
path diversity and recovery from collapse. Further evaluations on real-world
tasks demonstrate that SESA improves both the exploration of valid strategies
and the overall performance of LLMs. On three agent benchmarks, SESA lifts
success rates by $+0.25$, $+0.42$, and $+0.07$ absolute over the base model (up
to an additional $211\%$ relative improvement over baseline RL), underscoring
its exploration advantage. This work introduces a structured approach to
exploration, paving the way for more effective and diverse reasoning in
RL-trained LLMs. Our code is released at https://github.com/MuLabPKU/sesa.

</details>


### [114] [Language Models are Injective and Hence Invertible](https://arxiv.org/abs/2510.15511)
*Giorgos Nikolaou,Tommaso Mencattini,Donato Crisostomi,Andrea Santilli,Yannis Panagakis,Emanuele Rodola'*

Main category: cs.LG

TL;DR: 这篇论文认为 Transformer 语言模型是单射的，这意味着不同的输入不会映射到相同的输出，因此是无损的。


<details>
  <summary>Details</summary>
Motivation: Transformer 组件的非单射性（如非线性激活和归一化）使得不同的输入可能映射到相同的输出，从而阻止从模型的表示中精确恢复输入。本文对此观点提出挑战。

Method: 1. 从数学上证明了将离散输入序列映射到相应连续表示序列的 Transformer 语言模型是单射且无损的，这一特性在初始化时建立并在训练过程中保留。
2. 通过对六个最先进的语言模型进行数十亿次碰撞测试，并在经验上证实了这一结果，未观察到任何碰撞。
3. 提出了 SipIt 算法，第一个能够从隐藏激活中可证明且高效地重建精确输入文本的算法，建立了线性时间保证并在实践中展示了精确可逆性。

Result: Transformer 语言模型是单射且无损的。SipIt 算法可以从隐藏激活中精确且高效地重建输入文本。

Conclusion: 单射性是语言模型的一个基本且可利用的属性，对透明度、可解释性和安全部署具有直接影响。

Abstract: Transformer components such as non-linear activations and normalization are
inherently non-injective, suggesting that different inputs could map to the
same output and prevent exact recovery of the input from a model's
representations. In this paper, we challenge this view. First, we prove
mathematically that transformer language models mapping discrete input
sequences to their corresponding sequence of continuous representations are
injective and therefore lossless, a property established at initialization and
preserved during training. Second, we confirm this result empirically through
billions of collision tests on six state-of-the-art language models, and
observe no collisions. Third, we operationalize injectivity: we introduce
SipIt, the first algorithm that provably and efficiently reconstructs the exact
input text from hidden activations, establishing linear-time guarantees and
demonstrating exact invertibility in practice. Overall, our work establishes
injectivity as a fundamental and exploitable property of language models, with
direct implications for transparency, interpretability, and safe deployment.

</details>


### [115] [Revisiting Knowledge Distillation: The Hidden Role of Dataset Size](https://arxiv.org/abs/2510.15516)
*Giulia Lanzillotta,Felix Sarnthein,Gil Kur,Thomas Hofmann,Bobby He*

Main category: cs.LG

TL;DR: 知识蒸馏在低数据量状态下，可以提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 以往的研究都集中在模型大小和泛化性上，但本文将研究蒸馏的第三个维度:数据集大小。

Method: 本文通过在不同数据集、任务和神经架构上进行了一系列实验，证明了蒸馏在低数据量状态下的作用不仅得以保留，而且得到了放大。并检验了现有知识蒸馏理论的预测能力，最终分析了模型因素的影响。

Result: 研究结果驳斥了蒸馏可以被理解为标签平滑的假设，并为“暗知识”假说提供了进一步的证据。

Conclusion: 数据集大小可能是蒸馏机制中一个基本但被 CoV略的变量。

Abstract: The concept of knowledge distillation (KD) describes the training of a
student model from a teacher model and is a widely adopted technique in deep
learning. However, it is still not clear how and why distillation works.
Previous studies focus on two central aspects of distillation: model size, and
generalisation. In this work we study distillation in a third dimension:
dataset size. We present a suite of experiments across a wide range of
datasets, tasks and neural architectures, demonstrating that the effect of
distillation is not only preserved but amplified in low-data regimes. We call
this newly discovered property the data efficiency of distillation. Equipped
with this new perspective, we test the predictive power of existing theories of
KD as we vary the dataset size. Our results disprove the hypothesis that
distillation can be understood as label smoothing, and provide further evidence
in support of the dark knowledge hypothesis. Finally, we analyse the impact of
modelling factors such as the objective, scale and relative number of samples
on the observed phenomenon. Ultimately, this work reveals that the dataset size
may be a fundamental but overlooked variable in the mechanisms underpinning
distillation.

</details>


### [116] [An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation](https://arxiv.org/abs/2510.15541)
*Saumya B*

Main category: cs.LG

TL;DR: 该研究探讨了MC Dropout在脑肿瘤MRI图像分割中预测分割误差（尤其是肿瘤边界附近）的有效性，结果表明其不确定性估计与分割误差之间（尤其在边界区域）相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 尽管Monte Carlo (MC) Dropout被广泛用于估计模型不确定性，但其在识别分割误差（尤其是肿瘤边界附近的误差）方面的有效性尚不明确。

Method: 本研究通过使用在四种不同数据增强设置下训练的U-Net模型，对2D脑肿瘤MRI图像分割中MC Dropout生成的不确定性与分割误差之间的关系进行了实证检验。通过50次随机前向传播计算不确定性，并使用Pearson和Spearman系数将其与像素级误差进行关联。

Result: 研究结果显示，MC Dropout不确定性与分割误差之间的全局相关性较弱（r ≈ 0.30–0.38），而边界相关性则可以忽略不计（|r| < 0.05）。尽管不同数据增强设置之间的差异具有统计学意义（p < 0.001），但其在实际应用中缺乏相关性。

Conclusion: 这些发现表明MC Dropout不确定性对于定位边界误差提供的线索有限，强调了在医学图像分割中需要探索替代或混合的不确定性估计方法。

Abstract: Accurate brain tumor segmentation from MRI is vital for diagnosis and
treatment planning. Although Monte Carlo (MC) Dropout is widely used to
estimate model uncertainty, its effectiveness in identifying segmentation
errors -- especially near tumor boundaries -- remains unclear. This study
empirically examines the relationship between MC Dropout--based uncertainty and
segmentation error in 2D brain tumor MRI segmentation using a U-Net trained
under four augmentation settings: none, horizontal flip, rotation, and scaling.
Uncertainty was computed from 50 stochastic forward passes and correlated with
pixel-wise errors using Pearson and Spearman coefficients. Results show weak
global correlations ($r \approx 0.30$--$0.38$) and negligible boundary
correlations ($|r| < 0.05$). Although differences across augmentations were
statistically significant ($p < 0.001$), they lacked practical relevance. These
findings suggest that MC Dropout uncertainty provides limited cues for boundary
error localization, underscoring the need for alternative or hybrid uncertainty
estimation methods in medical image segmentation.

</details>


### [117] [Doubly Robust Estimation of Causal Effects in Strategic Equilibrium Systems](https://arxiv.org/abs/2510.15555)
*Sibo Xiao*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为SDR（Strategic Doubly Robust）的新型估计器，用于在策略环境中进行因果推断。SDR通过结合策略均衡模型和双重鲁棒估计，解决了由智能体策略行为引起的内生性处理分配问题。


<details>
  <summary>Details</summary>
Motivation: 在策略环境中，智能体的策略行为会导致处理分配的内生性，这使得传统的因果推断方法难以获得准确的结果。SDR旨在解决这一问题，通过整合策略均衡模型和双重鲁棒估计来获得更可靠的因果推断。

Method: SDR估计器。它将策略均衡建模与双重鲁棒估计相结合，以在考虑智能体策略行为的同时，进行因果推断。该方法在策略非混淆性假设下，保证了估计器的一致性和渐近正态性。

Result: SDR估计器在理论上被证明在策略非混淆性下具有一致性和渐近正态性。实证评估表明，SDR在不同策略强度下，相较于基线方法，偏误减少了7.6%-29.3%，并且随着智能体数量的增加，仍能保持鲁棒的可扩展性。

Conclusion: SDR估计器为智能体对干预措施做出策略性反应时，提供了一种进行可靠因果推断的原则性方法。它有效地解决了策略环境中内生性处理分配的问题，并显著优于现有方法。

Abstract: We introduce the Strategic Doubly Robust (SDR) estimator, a novel framework
that integrates strategic equilibrium modeling with doubly robust estimation
for causal inference in strategic environments. SDR addresses endogenous
treatment assignment arising from strategic agent behavior, maintaining double
robustness while incorporating strategic considerations. Theoretical analysis
confirms SDR's consistency and asymptotic normality under strategic
unconfoundedness. Empirical evaluations demonstrate SDR's superior performance
over baseline methods, achieving 7.6\%-29.3\% bias reduction across varying
strategic strengths and maintaining robust scalability with agent populations.
The framework provides a principled approach for reliable causal inference when
agents respond strategically to interventions.

</details>


### [118] [GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device](https://arxiv.org/abs/2510.15620)
*Jiahao Zhou,Chengliang Lin,Dingji Li,Mingkai Dong,Haibo Chen*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为GRATING的系统，用于优化边缘设备上语义top-K选择的交叉编码器重排序器的延迟和内存使用，通过序列级稀疏性和渐进式聚类剪枝，显著降低了延迟和内存占用，同时保持了精度。


<details>
  <summary>Details</summary>
Motivation: 语义top-K选择在检索增强生成、智能体记忆和个性化推荐等设备端AI服务中至关重要。然而，其高延迟和内存需求在边缘硬件上占据了大部分端到端预算，这促使研究者寻求优化方法。

Method: GRATING系统通过以下方法优化了top-K选择：1) 观察到只有相对排名而非精确的候选分数是重要的。2) 利用序列级稀疏性，即相对排名在中间层早期就稳定，从而在完成完整推理之前进行剪枝。 3) 提出单片式转发，并通过渐进式聚类剪枝减少延迟。 4) 通过双层滑动窗口和分块执行，策略性地将I/O与计算重叠，从而限制峰值内存使用。

Result: GRATING在微基准测试中，将延迟降低了高达89.0%，峰值内存降低了高达94.9%，且没有精度损失。在三个真实的设备端AI应用中，GRATING将延迟降低了11.6%-51.0%，峰值内存降低了18.6%-77.8%。

Conclusion: GRATING是一个训练无关的推理系统，它通过利用相对排名稳定性和序列级稀疏性，显著降低了边缘设备上语义top-K选择交叉编码器重排序器的延迟和内存占用，从而提高了效率和可部署性，同时保持了精度。

Abstract: Semantic top-K selection with cross-encoder rerankers underpins of on-device
AI services, such as retrieval-augmented generation, agent memory, and
personalized recommendation. However, its latency and memory demands dominate
end-to-end budgets on edge hardware. Revisiting the objective of top-K
selection, we reveal that only relative rankings matter, not exact
per-candidate scores. We further observe sequence-level sparsity: relative
rankings stabilize early in intermediate layers, allowing pruning opportunities
prior to completing full inference.
  Building on this insight, we propose monolithic forwarding and develop a
training-free inference system, GRATING. By maintaining a global view of all
candidates, it reduces latency through progressive cluster pruning. It also
bounds peak memory usage by strategically overlapping I/O with computation via
dual-layer sliding window and chunked execution. We evaluate GRATING against
state-of-the-art baselines on rerankers from 0.6B to 8B parameters across Apple
M2 and RTX 5070. GRATING consistently reduces latency by up to 89.0% and peak
memory by up to 94.9% in microbenchmarks, without any loss in precision. Across
three real-world on-device AI applications, GRATING lowers latency by
11.6%-51.0% and peak memory by 18.6%-77.8%, demonstrating substantial
improvements in efficiency and deployability.

</details>


### [119] [CQD-SHAP: Explainable Complex Query Answering via Shapley Values](https://arxiv.org/abs/2510.15623)
*Parsa Abbasi,Stefan Heindorf*

Main category: cs.LG

TL;DR: 这篇论文提出了CQD-SHAP，一个基于Shapley值的新颖框架，用于解释复杂查询应答（CQA）中每个查询部分对答案排序的贡献，从而解决了神经和神经符号CQA方法缺乏可解释性及用户信任问题。


<details>
  <summary>Details</summary>
Motivation: 目前神经和神经符号CQA方法在处理不完整知识图谱（KGs）上的复杂查询时，大多是黑盒模型，这带来了用户信任问题。尽管神经符号方法（如CQD）提供了一定的可追踪中间结果的能力，但它们仍未能解释查询不同部分的重要性，也无法有效说明利用神经预测器而非仅依赖现有事实的符号方法所带来的价值。

Method: 本文提出了CQD-SHAP框架，该框架基于合作博弈论中的Shapley值来计算查询的每个部分对特定答案排序的贡献。通过这种方式，CQD-SHAP能够解释利用神经预测器从不完整知识图谱中推断新知识的价值，而不是仅仅依赖知识图谱中现有事实的符号方法。CQD-SHAP满足所有基本的Shapley公理。

Result: 通过对必要性和充分性解释的自动化评估，以及与各种基线的比较，CQD-SHAP在大多数查询类型中显示出其方法的有效性。

Conclusion: CQD-SHAP为复杂查询应答提供了一个可解释的框架，通过量化查询各部分对答案排序的贡献，增强了用户对神经和神经符号CQA方法的信任，并证明了利用神经预测器从不完整知识图谱中推断新知识的价值。

Abstract: Complex query answering (CQA) goes beyond the well-studied link prediction
task by addressing more sophisticated queries that require multi-hop reasoning
over incomplete knowledge graphs (KGs). Research on neural and neurosymbolic
CQA methods is still an emerging field. Almost all of these methods can be
regarded as black-box models, which may raise concerns about user trust.
Although neurosymbolic approaches like CQD are slightly more interpretable,
allowing intermediate results to be tracked, the importance of different parts
of the query remains unexplained. In this paper, we propose CQD-SHAP, a novel
framework that computes the contribution of each query part to the ranking of a
specific answer. This contribution explains the value of leveraging a neural
predictor that can infer new knowledge from an incomplete KG, rather than a
symbolic approach relying solely on existing facts in the KG. CQD-SHAP is
formulated based on Shapley values from cooperative game theory and satisfies
all the fundamental Shapley axioms. Automated evaluation of these explanations
in terms of necessary and sufficient explanations, and comparisons with various
baselines, shows the effectiveness of this approach for most query types.

</details>


### [120] [Fast and Compact Tsetlin Machine Inference on CPUs Using Instruction-Level Optimization](https://arxiv.org/abs/2510.15653)
*Yefan Zeng,Shengyu Duan,Rishad Shafik,Alex Yakovlev*

Main category: cs.LG

TL;DR: 该文章提出了一种针对资源受限设备，特别是CPU，高效的Tsetlin Machine (TM)软件实现方法。



<details>
  <summary>Details</summary>
Motivation: 现有的Tsetlin Machine (TM)在CPU等资源受限设备上具有高速推理能力，其逻辑驱动操作天然适合现代CPU架构上的并行执行。

Method: 1. 提出了一种高效的TM软件实现，利用指令级的位操作进行紧凑的模型表示和加速处理。
2. 引入了一种提前退出机制（early exit mechanism），利用TM基于AND的子句评估来避免不必要的计算，从而进一步提高推理速度。
3. 提出了一种文字重排（literal Reorder）策略，旨在最大化提前退出的可能性。该策略在训练后、推理前阶段，通过对所有文字及其相关联的Tsetlin Automata (TA)动作进行统计分析来应用，引入了可忽略的运行时开销。

Result: 使用gem5模拟器在ARM处理器上的实验结果表明，与传统的基于整数的TM实现相比，优化后的实现将推理时间减少了96.71%，同时保持了可比的代码密度。

Conclusion: 该文章通过指令级位操作、提前退出机制和文字重排策略，显著提高了Tsetlin Machine在CPU上的推理效率，同时保持了模型紧凑性和代码密度。这些优化对于资源受限设备的部署具有重要意义。

Abstract: The Tsetlin Machine (TM) offers high-speed inference on resource-constrained
devices such as CPUs. Its logic-driven operations naturally lend themselves to
parallel execution on modern CPU architectures. Motivated by this, we propose
an efficient software implementation of the TM by leveraging instruction-level
bitwise operations for compact model representation and accelerated processing.
To further improve inference speed, we introduce an early exit mechanism, which
exploits the TM's AND-based clause evaluation to avoid unnecessary
computations. Building upon this, we propose a literal Reorder strategy
designed to maximize the likelihood of early exits. This strategy is applied
during a post-training, pre-inference stage through statistical analysis of all
literals and the corresponding actions of their associated Tsetlin Automata
(TA), introducing negligible runtime overhead. Experimental results using the
gem5 simulator with an ARM processor show that our optimized implementation
reduces inference time by up to 96.71% compared to the conventional
integer-based TM implementations while maintaining comparable code density.

</details>


### [121] [WARP-LUTs - Walsh-Assisted Relaxation for Probabilistic Look Up Tables](https://arxiv.org/abs/2510.15655)
*Lino Gerlach,Liv Våge,Thore Gerlach,Elliott Kauffman*

Main category: cs.LG

TL;DR: DLGNs在学习逻辑门组合方面表现出色，但在训练成本和泛化能力方面存在不足。WARP-LUTs是一种新的方法，可以在保持准确性的前提下，显著加速CIFAR-10上的收敛速度。


<details>
  <summary>Details</summary>
Motivation: DLGNs在学习逻辑门组合方面表现出色，但在训练成本和泛化能力方面存在不足。

Method: 本文介绍了Walsh-Assisted Relaxation for Probabilistic Look-Up Tables (WARP-LUTs) -- 一种新颖的基于梯度的方法。WARP-LUTs通过使用较少的可训练参数来高效学习逻辑门组合。

Result: WARP-LUTs在CIFAR-10上的收敛速度显著快于DLGNs，同时保持了可比的准确性。

Conclusion: WARP-LUTs在学习逻辑门组合方面具有更高的计算效率和更好的泛化潜力，为在现代FPGA上实现高效部署和实时科学应用提供了可能。

Abstract: Fast and efficient machine learning is of growing interest to the scientific
community and has spurred significant research into novel model architectures
and hardware-aware design. Recent hard? and software co-design approaches have
demonstrated impressive results with entirely multiplication-free models.
Differentiable Logic Gate Networks (DLGNs), for instance, provide a
gradient-based framework for learning optimal combinations of low-level logic
gates, setting state-of-the-art trade-offs between accuracy, resource usage,
and latency. However, these models suffer from high computational cost during
training and do not generalize well to logic blocks with more inputs. In this
work, we introduce Walsh-Assisted Relaxation for Probabilistic Look-Up Tables
(WARP-LUTs) - a novel gradient-based method that efficiently learns
combinations of logic gates with substantially fewer trainable parameters. We
demonstrate that WARP-LUTs achieve significantly faster convergence on CIFAR-10
compared to DLGNs, while maintaining comparable accuracy. Furthermore, our
approach suggests potential for extension to higher-input logic blocks,
motivating future research on extremely efficient deployment on modern FPGAs
and its real-time science applications.

</details>


### [122] [CarBoN: Calibrated Best-of-N Sampling Improves Test-time Reasoning](https://arxiv.org/abs/2510.15674)
*Yung-Chen Tang,Pin-Yu Chen,Andrea Cavallaro*

Main category: cs.LG

TL;DR: 本文介绍了一种名为 CarBoN（Calibrated Best-of-N）的测试时校准框架，旨在提高大型语言模型在推理任务中的效率和准确性，通过自适应地修改模型以寻找高回报的推理路径，从而在有限采样下提高预期回报的下限。CarBoN 能够减少获得相同准确性所需的计算量，同时在固定预算下实现更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 在推理任务中，增加推理时的计算量（测试时放大）可以提高语言模型的性能。然而，现有的流行方法，如 Best-of-N 采样，随着N的增加，效果会逐渐减弱。这表明在计算资源方面存在效率低下的问题，需要一种更有效的方法来指导模型生成更高质量的推理路径。

Method: 本文提出了一种名为 CarBoN（Calibrated Best-of-N）的两阶段方法。第一阶段是探索解决方案空间，第二阶段是通过输入特定的温度 T 和附加的移位向量 δ 来学习 logits 的校准，从而引导生成更可靠的推理。该方法在没有对大型语言模型（LLM）进行再训练的情况下，在理论上保证了在有限采样下提高预期回报的下限。CarBoN 还推广到了步级采样策略，如集束搜索。

Result: 在 MATH-500 和 AIME-2024 数据集上的实验表明，CarBoN 提高了效率，将达到相同准确性所需的计算量减少了多达 4 倍，同时在固定预算下通常能实现更高的准确性。研究还分析了 T 和 δ 在平衡输出多样性和正确性方面的互补作用。

Conclusion: CarBoN 框架有效地缓解了现有测试时放大方法中效率低下的问题。通过引入自适应校准机制，CarBoN 在不进行模型再训练的情况下，显著提高了语言模型在推理任务上的性能和计算效率。该方法可以减少实现相同性能所需的计算资源，同时在给定资源下获得更优的性能，具有广泛的应用前景。

Abstract: Allocating more computation during inference time (test-time scaling)
improves language model performance, especially for reasoning tasks. However,
popular methods like Best-of-$N$ sampling often show diminishing returns as $N$
increases. To address this inefficiency, we introduce a general test-time
calibration framework that adaptively modifies the model toward high-reward
reasoning paths, with theoretical guarantees of improving the lower bound of
expected reward under finite sampling, all without large language model (LLM)
retraining. Within this framework, we propose CarBoN (Calibrated Best-of-$N$),
a two-phase method that first explores the solution space and then learns a
calibration of the logits via an input-specific temperature $T$ and additive
shift vector $\delta$, guiding generation toward more reliable reasoning.
Experiments on MATH-500 and AIME-2024 show that CarBoN improves efficiency,
with up to $4\times$ fewer rollouts to reach the same accuracy, while often
achieving higher accuracy under fixed budgets. We also analyze the
complementary roles of $T$ and $\delta$ in balancing output diversity and
correctness, and demonstrate that the framework also generalizes to step-level
sampling strategies such as beam search. For more information, please refer to
our project page at huggingface.co/spaces/TrustSafeAI/Test-Time-Calibration.

</details>


### [123] [ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations](https://arxiv.org/abs/2510.15700)
*Alex Gu,Bartosz Piotrowski,Fabian Gloeckle,Kaiyu Yang,Aram H. Markosyan*

Main category: cs.LG

TL;DR: ProofOptimizer是一个无监督的语言模型，旨在通过专家迭代和强化学习来简化 Lean 证明，显著缩短了最先进的 RL 训练证明器的证明长度，并提高了下游证明器的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管神经定理证明器可以生成数千行的形式证明，但这些证明对于人类来说难以理解，限制了它们在数学洞察方面的用处。证明简化是一个关键的瓶颈，但该任务的训练数据稀缺，现有方法难以处理RL训练证明器生成的超长证明。

Method: 本文介绍了 ProofOptimizer，这是第一个在无需额外人工监督的情况下，通过专家迭代和强化学习训练来简化 Lean 证明的语言模型。它利用 Lean 来验证简化并提供训练信号。在推理时，它在迭代的证明缩短工作流程中运行，逐步减少证明长度。

Result: 实验表明，ProofOptimizer 大幅压缩了最先进的 RL 训练证明器生成的证明，在 miniF2F 上将证明长度缩短了 87%，在 PutnamBench 上缩短了 57%，在 Seed-Prover 的 IMO 2025 证明上缩短了 49%。此外，简化后的证明在 Lean 中检查速度更快，并且在作为监督微调的训练数据重复使用时，进一步提高了下游证明器的性能。

Conclusion: ProofOptimizer 显著提高了神经定理证明的可用性和可理解性，为数学家提供了更简洁、更易于理解的证明，并为未来的定理证明研究奠定了基础。

Abstract: Neural theorem proving has advanced rapidly in the past year, reaching IMO
gold-medalist capabilities and producing formal proofs that span thousands of
lines. Although such proofs are mechanically verified by formal systems like
Lean, their excessive length renders them difficult for humans to comprehend
and limits their usefulness for mathematical insight. Proof simplification is
therefore a critical bottleneck. Yet, training data for this task is scarce,
and existing methods -- mainly agentic scaffolding with off-the-shelf LLMs --
struggle with the extremely long proofs generated by RL-trained provers. We
introduce ProofOptimizer, the first language model trained to simplify Lean
proofs without requiring additional human supervision. ProofOptimizer is
trained via expert iteration and reinforcement learning, using Lean to verify
simplifications and provide training signal. At inference time, it operates
within an iterative proof-shortening workflow, progressively reducing proof
length. Experiments show that ProofOptimizer substantially compresses proofs
generated by state-of-the-art RL-trained provers on standard benchmarks,
reducing proof length by 87% on miniF2F, 57% on PutnamBench, and 49% on
Seed-Prover's IMO 2025 proofs. Beyond conciseness, the simplified proofs check
faster in Lean and further improve downstream prover performance when reused as
training data for supervised finetuning.

</details>


### [124] [ProSh: Probabilistic Shielding for Model-free Reinforcement Learning](https://arxiv.org/abs/2510.15720)
*Edwin Hamel-De le Court,Gaspard Ohlmann,Francesco Belardinelli*

Main category: cs.LG

TL;DR: ProSh是一种无模型的强化学习算法，通过风险预算和成本评论学习的策略分布来保证安全性，并且在训练期间也能保证安全性。


<details>
  <summary>Details</summary>
Motivation: 在强化学习（RL）中，安全性是一个主要问题。本文旨在开发不仅能实现最佳性能，而且能通过提供正式的安全保证，确保部署安全的强化学习系统。

Method: 本文提出了一种名为Probabilistic Shielding via Risk Augmentation（ProSh）的无模型算法，用于在成本约束下进行安全强化学习。ProSh通过风险预算扩展了约束MDP状态空间，并通过使用学习到的成本评论，对智能体的策略分布应用防护罩，从而强制执行安全性。该防护罩确保所有采样的动作在预期上都是安全的。

Result: 在环境是确定性的情况下，ProSh保留了最优性。ProSh在训练期间的安全性取决于对环境的了解程度。本文提供了一个关于预期成本的严格上限，该上限仅取决于备份评论的准确性，并且在训练期间始终得到满足。在温和的、可实践的假设下，ProSh即使在训练时也能保证安全性。

Conclusion: ProSh是一种有效的安全强化学习算法，它在保证最优性的同时，通过风险预算和防护罩机制，确保了在训练和部署过程中的安全性。

Abstract: Safety is a major concern in reinforcement learning (RL): we aim at
developing RL systems that not only perform optimally, but are also safe to
deploy by providing formal guarantees about their safety. To this end, we
introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free
algorithm for safe reinforcement learning under cost constraints. ProSh
augments the Constrained MDP state space with a risk budget and enforces safety
by applying a shield to the agent's policy distribution using a learned cost
critic. The shield ensures that all sampled actions remain safe in expectation.
We also show that optimality is preserved when the environment is
deterministic. Since ProSh is model-free, safety during training depends on the
knowledge we have acquired about the environment. We provide a tight
upper-bound on the cost in expectation, depending only on the backup-critic
accuracy, that is always satisfied during training. Under mild, practically
achievable assumptions, ProSh guarantees safety even at training time, as shown
in the experiments.

</details>


### [125] [RLAF: Reinforcement Learning from Automaton Feedback](https://arxiv.org/abs/2510.15728)
*Mahyar Alinejad,Alvaro Velasquez,Yue Wang,George Atia*

Main category: cs.LG

TL;DR: 该论文介绍了一种新颖的强化学习方法，该方法利用DFA生成的偏好来学习奖励函数，从而避免了手动设计奖励函数。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习方法在处理复杂、依赖历史的奖励结构时面临挑战。

Method: 该论文提出了一种利用确定性有限自动机（DFA）生成轨迹偏好来学习奖励函数的方法。该方法包括静态和动态两种策略优化方式，分别对应一次性学习和迭代式学习。

Result: 实验结果表明，该方法在处理具有时间依赖性的任务时，性能优于传统的奖励工程和基于自动机的基线方法，如奖励机和LTL引导方法。该方法能够处理非马尔可夫奖励，并提供了一种可扩展、高效且独立于人工的奖励建模替代方案。

Conclusion: 该论文提出了一种有效的、基于自动机偏好的强化学习框架，能够解决复杂奖励结构下的学习问题，并具有收敛性保证。

Abstract: Reinforcement Learning (RL) in environments with complex, history-dependent
reward structures poses significant challenges for traditional methods. In this
work, we introduce a novel approach that leverages automaton-based feedback to
guide the learning process, replacing explicit reward functions with
preferences derived from a deterministic finite automaton (DFA). Unlike
conventional approaches that use automata for direct reward specification, our
method employs the structure of the DFA to generate preferences over
trajectories that are used to learn a reward function, eliminating the need for
manual reward engineering. Our framework introduces a static approach that uses
the learned reward function directly for policy optimization and a dynamic
approach that involves continuous refining of the reward function and policy
through iterative updates until convergence.
  Our experiments in both discrete and continuous environments demonstrate that
our approach enables the RL agent to learn effective policies for tasks with
temporal dependencies, outperforming traditional reward engineering and
automaton-based baselines such as reward machines and LTL-guided methods. Our
results highlight the advantages of automaton-based preferences in handling
non-Markovian rewards, offering a scalable, efficient, and human-independent
alternative to traditional reward modeling. We also provide a convergence
guarantee showing that under standard assumptions our automaton-guided
preference-based framework learns a policy that is near-optimal with respect to
the true non-Markovian objective.

</details>


### [126] [Poultry Farm Intelligence: An Integrated Multi-Sensor AI Platform for Enhanced Welfare and Productivity](https://arxiv.org/abs/2510.15757)
*Pieris Panagi,Savvas Karatsiolis,Kyriacos Mosphilis,Nicholas Hadjisavvas,Andreas Kamilaris,Nicolas Nicolaou,Efstathios Stavrakis,Vassilis Vassiliades*

Main category: cs.LG

TL;DR: PoultryFI是一个模块化、经济高效的AI平台，旨在为中小型家禽养殖场提供持续监控和决策支持，通过集成六个AI模块来优化家禽养殖管理。


<details>
  <summary>Details</summary>
Motivation: 中小型家禽养殖场缺乏经济实惠的集成工具，来持续监控和辅助决策，仍依赖手动检查，导致难以在提高生产力的同时，确保动物福利和环境合规。

Method: PoultryFI平台集成了六个AI模块：摄像头布局优化器、音视频监控、分析与警报、实时鸡蛋计数、生产与盈利能力预测以及推荐模块。它利用进化算法优化摄像头布局，从音视频数据中提取福利指标，使用边缘视觉模型进行实时鸡蛋计数，并通过预测模型和天气数据提供运营建议。

Result: 系统在树莓派5上实现了100%的鸡蛋计数准确率，具有强大的异常检测能力和可靠的短期预测功能。

Conclusion: PoultryFI是首批结合低成本传感、边缘分析和规范性AI的系统之一，能够持续监控鸡群、预测生产并优化性能，弥合了孤立试点工具与可扩展农场智能之间的差距，帮助生产者主动保障动物福利和盈利能力。

Abstract: Poultry farming faces increasing pressure to meet productivity targets while
ensuring animal welfare and environmental compliance. Yet many small and
medium-sized farms lack affordable, integrated tools for continuous monitoring
and decision-making, relying instead on manual, reactive inspections. This
paper presents Poultry Farm Intelligence (PoultryFI) - a modular,
cost-effective platform that integrates six AI-powered modules: Camera
Placement Optimizer, Audio-Visual Monitoring, Analytics & Alerting, Real-Time
Egg Counting, Production & Profitability Forecasting, and a Recommendation
Module.
  Camera layouts are first optimized offline using evolutionary algorithms for
full poultry house coverage with minimal hardware. The Audio-Visual Monitoring
module extracts welfare indicators from synchronized video, audio, and feeding
data. Analytics & Alerting produces daily summaries and real-time
notifications, while Real-Time Egg Counting uses an edge vision model to
automate production tracking. Forecasting models predict egg yield and feed
consumption up to 10 days in advance, and the Recommendation Module integrates
forecasts with weather data to guide environmental and operational adjustments.
  This is among the first systems to combine low-cost sensing, edge analytics,
and prescriptive AI to continuously monitor flocks, predict production, and
optimize performance. Field trials demonstrate 100% egg-count accuracy on
Raspberry Pi 5, robust anomaly detection, and reliable short-term forecasting.
PoultryFI bridges the gap between isolated pilot tools and scalable, farm-wide
intelligence, empowering producers to proactively safeguard welfare and
profitability.

</details>


### [127] [SNOO: Step-K Nesterov Outer Optimizer - The Surprising Effectiveness of Nesterov Momentum Applied to Pseudo-Gradients](https://arxiv.org/abs/2510.15830)
*Dominik Kallusky,Vinay Rao,Vishal Nandavanam,Hao-Jun Michael Shi*

Main category: cs.LG

TL;DR: 该文章介绍了一种名为SNOO的优化器变体，它通过将Nesterov动量应用于Lookahead优化器中的伪梯度，在非分布式设置下显著提高了训练效率，尤其适用于大型模型。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）的优化技术，并深入分析DiLoCo优化器在非分布式设置下的有效性。

Method: 经验性地展示DiLoCo的有效性主要来源于将Nesterov动量应用于伪梯度。提出SNOO（Step-K Nesterov Outer Optimizer）优化器，该优化器是Lookahead的变体，将Nesterov动量应用于伪梯度，并在非分布式设置下进行实验验证。

Result: SNOO在非分布式设置下，计算因子增益达到1.5 - 2.5倍，并且随着模型尺寸的增加，性能提升更为显著。SNOO具有最小的计算和内存开销，并兼容模型分片，可以作为AdamW和Muon等内部优化器的实用增强。

Conclusion: SNOO通过将Nesterov动量应用于Lookahead优化器中的伪梯度，在非分布式设置下为LLMs的训练带来了显著的效率提升，其低开销和兼容性使其成为一种有前景的优化选择。

Abstract: The rapid development of large language models (LLMs) has driven the demand
for more efficient optimization techniques. Among these, the Lookahead family
of optimizers employs a two-loop framework, maintaining fast and slow sets of
model weights. Multiple inner optimizer steps on the fast weights produce a
trajectory - the pseudo-gradient - that is used to update the slow weights.
DiLoCo, a notable example originally designed for distributed training, applies
Nesterov momentum to the averaged pseudo-gradient from multiple workers,
claiming to even outperform AdamW in a non-distributed setup. In this paper, we
empirically show that DiLoCo's surprising effectiveness stems primarily from
applying Nesterov momentum to the pseudo-gradient, which improves training in a
non-distributed setting. We call this Lookahead variant the Step-$K$ Nesterov
Outer Optimizer (SNOO). We demonstrate that SNOO achieves compute factor gains
of 1.5 - 2.5$\times$ in a non-distributed setting up to a scale of 1e23
training FLOPs, with improvements that increase with model size. Because of its
minimal compute and memory overhead and compatibility with model sharding, SNOO
is a practical enhancement for a variety of inner optimizers, including AdamW
and Muon.

</details>


### [128] [FIDDLE: Reinforcement Learning for Quantum Fidelity Enhancement](https://arxiv.org/abs/2510.15833)
*Hoang M. Ngo,Tamer Kahveci,My T. Thai*

Main category: cs.LG

TL;DR: 该论文介绍了一种名为FIDDLE的新型学习框架，用于在量子计算的路由阶段最大化过程保真度。


<details>
  <summary>Details</summary>
Motivation: 在门控量子计算中，量子设备的噪声会降低其可靠性。因此，在转译过程（特别是路由阶段）中，提高量子电路的可靠性（通过过程保真度衡量）是一个关键挑战。

Method: FIDDLE框架包含两个模块：一个基于高斯过程的替代模型，用于在有限训练样本下估计过程保真度；一个强化学习模块，用于优化路由。

Result: FIDDLE的替代模型比现有技术能更好地估计过程保真度。整个端到端框架显著提高了各种噪声模型下量子电路的过程保真度，优于依赖间接度量（如电路深度或门计数）的传统方法。

Conclusion: FIDDLE是首个直接最大化过程保真度的方法，通过其新颖的替代模型和强化学习模块，显著提高了量子电路的可靠性。

Abstract: Quantum computing has the potential to revolutionize fields like quantum
optimization and quantum machine learning. However, current quantum devices are
hindered by noise, reducing their reliability. A key challenge in gate-based
quantum computing is improving the reliability of quantum circuits, measured by
process fidelity, during the transpilation process, particularly in the routing
stage. In this paper, we address the Fidelity Maximization in Routing Stage
(FMRS) problem by introducing FIDDLE, a novel learning framework comprising two
modules: a Gaussian Process-based surrogate model to estimate process fidelity
with limited training samples and a reinforcement learning module to optimize
routing. Our approach is the first to directly maximize process fidelity,
outperforming traditional methods that rely on indirect metrics such as circuit
depth or gate count. We rigorously evaluate FIDDLE by comparing it with
state-of-the-art fidelity estimation techniques and routing optimization
methods. The results demonstrate that our proposed surrogate model is able to
provide a better estimation on the process fidelity compared to existing
learning techniques, and our end-to-end framework significantly improves the
process fidelity of quantum circuits across various noise models.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [129] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: 该论文介绍了OpenEstimate，这是一个用于评估大型语言模型（LLMs）在不确定性下进行数值估计的基准。研究发现，目前的LLMs在处理不确定信息时的表现不佳，通常不准确且过于自信。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在许多领域得到应用，但它们在处理不完整信息和不确定性方面的能力评估不足。现有的评估多集中于有明确答案的问题，难以衡量模型在真实世界复杂情况下的表现。

Method: 论文提出了OpenEstimate基准，它通过要求模型综合背景信息并以概率先验的形式表达预测来评估LLMs的数值估计能力。该基准评估了预测的准确性和校准性，并与真实分布进行比较。

Result: 通过对六个前沿LLMs的评估，发现模型生成的先验通常不准确且过于自信。尽管不确定性信息的提取方式对性能有轻微改善，但采样策略、推理努力或提示设计方面的改变对性能影响不大。

Conclusion: OpenEstimate基准为评估和开发在概率估计和不确定性推理方面更优秀的LLMs提供了一个具有挑战性的平台。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [130] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 这篇论文提出了一种在Unity 3D环境中使用深度强化学习（DRL）进行程序化关卡设计的新方法。


<details>
  <summary>Details</summary>
Motivation: 在游戏开发中，程序化内容生成（PCG）技术越来越受欢迎，它能够减少手动工作量，生成动态、可重玩和可扩展的环境。

Method: 本研究提出了一个包含两个智能体的新方法：一个蜂鸟智能体（求解器）和一个浮岛智能体（生成和放置可收集的鲜花）。两个智能体都使用近端策略优化（PPO）算法进行训练。蜂鸟智能体学习有效地导航、定位和收集鲜花，同时适应不断变化的岛屿布局。浮岛智能体根据观察到的障碍物位置、蜂鸟的初始状态和之前回合的性能反馈来生成鲜花布局。

Result: 智能体之间的互动产生了涌现行为和对各种环境配置的鲁棒泛化。结果表明，该方法不仅产生了有效和高效的智能体行为，还为机器学习驱动的自主游戏关卡设计开辟了新机会。

Conclusion: 这项工作突出了DRL在使智能体能够在虚拟环境中生成和解决内容方面的潜力，推动了AI对创意游戏开发过程的贡献。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [131] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 这篇论文认为，通用人工智能的进展受到理论限制，而非数据或规模限制。论文挑战了柏拉图式表征假设，并提出了Causal Mechanics，这是一个以机制为先的框架，旨在通过可扩展的假设空间和结构化原则来促进错误发现和纠正。


<details>
  <summary>Details</summary>
Motivation: 作者认为当前AGI发展受限于理论而非数据或规模。通过批判性地审视柏拉图式表征假设，指出仅凭观察性充足性无法保证干预能力。因此，有必要提出一种新的理论框架来克服现有观察学习的局限性，以实现通用人工智能。

Method: 论文首先对知识、学习、智能、反事实能力和通用人工智能进行了定义。随后，分析了观察学习的局限性，提出了一种以错误为中心的转变。作者将问题重新定义为关于智能体行为下显式和隐式错误的演变、固定假设空间内不可达错误以及猜想和批评如何扩展假设空间的三个问题。在此基础上，提出了“因果力学”（Causal Mechanics），这是一种机制优先的程序，其中假设空间的变化是一等操作，并且在有用时才使用概率结构，而不是预设。此外，论文还提出了使错误发现和纠正变得可行的结构原则，包括用于模块化干预的差异局域性和自主性原则、用于可分离性的独立因果机制的规范不变形式，以及用于类比保存的组合自主性原则，并附有可操作的诊断。

Result: 论文提出了“因果力学”框架和一系列结构原则，旨在解决通用人工智能发展中的理论限制。这些原则包括差异局域性和自主性原则、独立因果机制的规范不变形式以及组合自主性原则，它们共同构成了一个可行的诊断系统，以帮助系统将不可达错误转化为可达错误并进行纠正。

Conclusion: 论文的核心结论是，通用人工智能的实现需要从根本上改变理论范式，特别是通过“因果力学”框架和其提出的结构原则来应对现有理论的限制。通过优先考虑机制和假设空间的变化，并利用特定的结构原则，可以有效地发现和纠正错误，从而推动通用人工智能的发展。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [132] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: 该文章介绍了HugAgent，这是一个用于评估语言模型如何适应个体推理风格和信仰演变的基准。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能大规模模拟人类反应，但它们倾向于群体共识，忽略了个体推理风格和信仰轨迹的独特性。因此，需要一个能够使机器进行更类人推理的工具。

Method: HugAgent采用双轨设计：（1）合成轨道，用于大规模和系统性压力测试；（2）人类轨道，用于生态学上有效、‘出声’的推理数据。这使得对智能体内保真度进行可扩展、可复现的评估成为可能。

Result: 通过对最先进的大型语言模型进行实验，发现了持续存在的适应性差距。

Conclusion: HugAgent是第一个可扩展的基准，用于将机器推理与人类思维的个体性对齐。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [133] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 该文章介绍了一个包含733,651个面部表情记录的新型数据集，该数据集从38名员工在30.5个月内收集而来，旨在解决现实工作场所情感识别中数据缺乏的挑战。


<details>
  <summary>Details</summary>
Motivation: 在真实工作场所中，由于缺乏大规模、长期的自然环境数据集，自动情感识别仍然是情感计算领域的一个难题。

Method: 主要方法是收集了38名员工在30.5个月内的733,651个面部表情记录，每个记录包含七种情感概率和综合元数据。此外，还提供了32种扩展情感指标，并通过复制已知的心理模式（如周末效应和昼夜节律）以及员工离职预测来验证数据质量。

Result: 该数据集成功复制了已知的心理模式（如周末效应使愉悦度提高192%，p < 0.001），并对员工离职具有完美的预测效度（AUC=1.0）。基线实验中，Random Forest和LSTM模型在情感分类方面达到了91.2%的准确率，在愉悦度预测方面R2达到了0.84。

Conclusion: 该数据集是目前公开可用的最大、最长的纵向工作场所情感数据集，将有助于情感识别、情感动力学建模、情感 H 染、离职预测和情感感知系统设计等方面的研究。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [134] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的AGI评估方法，通过考虑领域权重和持久性来解决现有评估方法的局限性，并提出了两种新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 目前的AGI评估方法存在两个主要问题：1. 对所有领域赋予相同的权重，而人类智能研究表明并非所有领域都同等重要；2. 快照测试无法区分持久性能力和在延迟或压力下崩溃的脆弱性能。

Method: 作者提出，通用智能（AGI）应被理解为一个内稳态属性集群：一组能力以及在扰动下保持这些能力共存的机制。AGI评估应根据领域的因果中心性（对集群稳定性的贡献）来加权，并要求提供跨会话持久性的证据。为此，论文提出了两种与现有评估兼容的扩展：1. 中心性优先分数，它引入了CHC（Cattell-Horn-Carroll）模型衍生的权重进行敏感性分析；2. 集群稳定性指数家族，它区分了概要持久性、持久性学习和错误校正。

Result: 这些新增的评估方法在保持多领域广度的同时，减少了脆弱性和避免了针对性优化。

Conclusion: 论文最后提出了可测试的预测和黑盒协议，实验室无需访问架构即可采用。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [135] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个多模态智能体系统，其灵感来源于人类记忆，能够存储和检索多模态信息，并在 ImageNet 分类和 MSC 基准测试中表现优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体系统在增强外部记忆数据库时，只关注文本信息的存储，忽略了多模态信号的重要性。

Method: AUGUSTUS 包含四个阶段：编码、存储于记忆、检索和行动。它将信息概念化为语义标签，并将标签与上下文关联起来，存储在一个图结构的多模态上下文记忆中，以实现高效的概念驱动检索。

Result: AUGUSTUS 在 ImageNet 分类任务中的性能优于传统多模态 RAG 方法，速度提升3.5倍，并在 MSC 基准测试中超越了 MemGPT。

Conclusion: AUGUSTUS 作为一个多模态智能体系统，以其独特的多模态记忆存储和检索机制，在处理复杂任务时展现出卓越的性能和效率，为智能体系统设计提供了新的思路。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [136] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS是一个SFT数据增强流水线，它将视觉先验知识和多个SOTA的LMM与统计方法相结合，以提高多模态模型SFT数据的质量。


<details>
  <summary>Details</summary>
Motivation: 当前数据增强方法由于视觉感知不足，常导致事实错误和幻觉，影响大型多模态模型（LMM）的性能。

Method: 我们提出了VERITAS，一个系统性的SFT数据增强流水线。VERITAS利用视觉识别模型（RAM++）和OCR系统（PP-OCRv4）提取结构化视觉先验知识，并将其与图像、问题和答案结合。三个LMM（GPT-4o、Gemini-2.5-Pro、Doubao-1.5-pro）评估原始答案，提供批判性理由和分数，这些分数通过统计学方法融合成高置信度共识分数作为真值。利用此共识，我们通过组相对策略优化（GRPO）训练一个轻量级评论模型，有效提升推理能力。每个LMM根据批判性理由优化原始答案，生成新的候选答案；我们选择得分最高的作为最终优化答案。

Result: 在六个多模态基准测试中的实验表明，使用VERITAS处理过的数据进行微调的模型，其性能始终优于使用原始数据的模型，特别是在文本丰富和细粒度推理任务中。我们训练的评论模型展现出与SOTA LMM相媲美的增强能力，同时效率显著更高。

Conclusion: VERITAS通过系统集成视觉先验和LMMs，并结合统计方法，有效地提升了SFT数据质量，特别是在文本丰富和细粒度推理任务中表现突出，为多模态数据优化研究提供了新的方向。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [137] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO是一种新颖的强化学习框架，旨在减少大型推理模型中低效的推理。它通过优势解耦算法、难度感知长度惩罚和优势剪辑方法，在保持或提高准确性的同时，显著缩短了模型响应的序列长度并减少了不必要的推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习算法虽然显著提高了大型推理模型的准确性，但仍存在响应过长和过度思考的问题，尤其是在简单任务上，这导致推理延迟和计算消耗增加。

Method: DEPO框架包含三个主要组件：1. 一种创新的优势解耦算法，用于引导模型减少低效的token；2. 一种难度感知的长度惩罚机制，用于降低模型响应的总体长度；3. 一种优势剪辑方法，用于防止策略优化中的偏差。

Result: 在DeepSeek-Distill-Qwen-7B和DeepSeek-Distill-Qwen-1.5B模型上的实验表明，DEPO在保持整体准确性优于基础模型的同时，显著将序列长度减少了39%，并减少了低效token中的过度推理路径。

Conclusion: DEPO成功地解决了大型推理模型中低效推理的问题，通过其独特的三大组件在缩短响应长度和减少冗余推理方面取得了显著成效，同时保持了高准确性。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [138] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: 本文提出了MARS，一个端到端强化学习框架，通过自博弈在合作和竞争游戏中激励LLMs进行多智能体推理。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，开发能够有效合作和竞争的大型语言模型（LLMs）是迈向更高级智能的关键一步。尽管强化学习（RL）在增强单智能体任务的推理能力方面已被证明是有效的，但由于长时序信用分配和智能体特定优势估计的挑战，其在多轮、多智能体场景中的应用仍未被充分探索。

Method: 我们引入了MARS，一个端到端强化学习框架，通过自博弈在合作和竞争游戏中激励LLMs进行多智能体推理。MARS具有一个回合级优势估计器，将学习信号与每次交互对齐以进行信用分配，以及一个智能体特定优势归一化，以稳定多智能体训练。

Result: 通过在合作和竞争游戏中进行自博弈学习，从Qwen3-4B训练的MARS智能体开发出强大的战略能力，在未见过的游戏中表现出高达28.7%的性能提升。更重要的是，通过自博弈获得的能力超越了游戏领域，在推理基准测试中为多智能体系统带来了持续的性能提升。当集成到领先的多智能体系统中时，我们的MARS智能体在AIME上实现了10.0%的显著性能提升，在GPQA-Diamond上则提升了12.5%。

Conclusion: 这些结果表明，在战略游戏中采用自博弈的端到端强化学习训练是开发LLMs可泛化多智能体推理能力的强大方法。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [139] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 介绍了CDR和DGR两种方法，用于解决强化学习中判断不一致和偏好循环问题，提高了训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中判断不一致导致的不稳定问题，特别关注逻辑连贯性，弥补现有研究对偏好循环问题处理不足的空白。

Method: 1. 提出冲突检测率（CDR）量化判断冲突。2. 提出去冲突图奖励（DGR）框架，通过构建偏好图，将其转化为无冲突有向无环图（DAG），并生成逻辑连贯的奖励信号。

Result: 与现有基线方法相比，显著提高了训练的稳定性和模型性能。

Conclusion: 逻辑一致性是AI反馈中一个关键且可管理的维度，本框架有效地解决了这一问题。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [140] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: 这篇文章介绍了一个名为JudgeSQL的框架，它通过结构化推理和加权共识锦标赛机制来改进Text-to-SQL任务中的SQL候选查询选择。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL任务由于语义模糊和复杂的组合推理而具有挑战性。虽然大型语言模型（LLMs）在SQL生成方面取得了进展，但测试时扩展面临新的瓶颈：从多样化的候选池中选择正确的查询。现有选择方法（如自洽性或best-of-N解码）提供的信号不足，容易导致评分不一致、推理链脆弱以及无法捕捉SQL候选查询之间细微的语义区别。

Method: JudgeSQL是一个原则性的框架，它通过结构化推理和加权共识锦标赛机制重新定义了SQL候选查询选择。JudgeSQL开发了一个基于推理的SQL判断模型，该模型通过可验证奖励引导的强化学习来提取推理轨迹，从而实现准确和可解释的判断。在此基础上，加权共识锦标赛将显式推理偏好与隐式生成器置信度相结合，从而产生更可靠、更高效的选择。

Result: 在BIRD基准测试上的大量实验表明，JudgeSQL展示了卓越的SQL判断能力，并对生成器容量具有良好的跨尺度泛化性和鲁棒性。

Conclusion: JudgeSQL框架通过结构化推理和加权共识锦标赛机制，显著提高了Text-to-SQL任务中SQL候选查询选择的准确性和效率，解决了现有方法在语义区分和推理方面的不足。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [141] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 该研究开发了一个机器学习框架，通过整合患者的历史就诊信息来改进健康监测，特别是在先前的就诊次数有限且频率可变的情况下。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域中，时间背景对于评估患者健康随时间的关键变化非常重要。现有方法在处理有限和可变频率的既往就诊数据时，可能未能充分利用这些时间信息来提高健康监测的准确性。

Method: 该模型首先利用最近一次患者就诊的医疗数据估算疾病的初始风险，然后通过整合之前收集的影像学和/或临床生物标志物信息来优化风险评估。研究将该框架应用于前列腺癌（PCa）风险预测，使用了近十年收集的大量人口数据（28,342名患者，39,013次磁共振成像扫描，68,931次血液检查）。

Result: 在预测就诊时临床显著PCa的风险方面，整合先前的背景信息直接将假阳性转化为真阴性，在保持高敏感性的同时提高了整体特异性。与仅使用单次就诊数据相比，整合多达三次既往影像学检查信息后，假阳性率从51%逐步降低到33%；如果再包含既往临床数据，假阳性率进一步降低到24%。对于预测就诊后五年内PCa的风险，结合既往背景信息使假阳性率进一步降低（从64%降至9%）。

Conclusion: 研究结果表明，随时间收集的信息提供了相关的背景，可以提高医学风险预测的特异性。对于多种进展性疾病，通过利用背景信息充分降低假阳性率，有望将纵向健康监测计划推广到基线疾病风险相对较低的大量人群中，从而实现早期检测和改善健康结果。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [142] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 该论文介绍了SciRecipe数据集和“Sketch-and-Fill”范式，并在此基础上开发了Thoth模型，旨在提高大型语言模型在生成精确、有序和可执行科学协议方面的能力，从而提升科学的可重现性。


<details>
  <summary>Details</summary>
Motivation: 目前的领先大型语言模型在生成科学协议时常常出现不完整或不一致的问题，这限制了它们在科学重现过程中的应用。

Method: 1. 引入了SciRecipe数据集：一个包含12K多个结构化协议的大规模数据集，涵盖27个生物学子领域，包含理解和问题解决任务。
2. 提出了“Sketch-and-Fill”范式：将协议生成过程分为分析、结构化和表达三个阶段，确保每一步都明确且可验证。
3. 设计了结构化基于组件的奖励机制：评估步骤粒度、动作顺序和语义保真度，使模型优化与实验可靠性保持一致。
4. 开发了Thoth模型：通过阶段性的“知识到行动”过程进行训练，从知识获取到操作推理，最终生成鲁棒、可执行的协议。

Result: Thoth模型在多个基准测试中持续超越了专有和开源的大型语言模型，在步骤对齐、逻辑排序和语义准确性方面取得了显著改进，有效提高了协议生成的可靠性。

Conclusion: 这项研究为构建可靠的科学助手奠定了基础，这些助手能够将知识与实验执行相结合，显著提升科学研究的可重现性。所有数据、代码和模型都将公开发布。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [143] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: RLHF（人类反馈强化学习）对齐大型语言模型（LLM）的主流方法。然而，此方法存在两个关键限制：人类评估者的多样性以及成对反馈的局限性。本文提出了新的方法，在理论和算法层面为生成模型对齐中多样化用户的公平性和个性化提供了框架。


<details>
  <summary>Details</summary>
Motivation: RLHF（人类反馈强化学习）在使大型语言模型与人类价值观对齐方面发挥了核心作用，但其通常的流程涉及到从偏好数据中学习奖励模型，然后利用强化学习更新模型，以及一些替代方案（如直接偏好优化DPO）直接优化偏好，都忽视了人类评估者存在多样性、成对反馈存在局限性这两个关键问题。

Method: 本文首先将RLHF中的偏好学习与计量经济学文献联系起来，证明了二元比较不足以从有限的用户数据和无限用户中识别潜在的用户偏好，而三个或更多响应的（即使不完整的）排名可以确保可识别性；其次，作者提出了将异构偏好纳入对齐算法的方法。开发了DPO的期望最大化（Expectation-Maximization）调整，该方法可以发现潜在的注释者类型，并相应地训练LLM的混合模型。然后，作者提出了一种使用最小-最大遗憾公平性准则的聚合算法，以产生具有公平性能保证的单一生成策略。

Result: 这些贡献共同为生成模型对齐中多样化用户的公平性和个性化建立了理论和算法框架。

Conclusion: 本文通过解决人类评估者的多样性以及成对反馈的局限性这两个关键问题，为解决生成模型对齐问题提供了新的思路，并为未来在多样的用户群体中实现公平和个性化的生成模型对齐奠定了基础，具有重要的理论和实践意义。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [144] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种从发票文档中提取结构化信息的方法，并提出了一套评估指标来衡量数据提取的准确性。


<details>
  <summary>Details</summary>
Motivation: 开发一种方法，可以从发票文档中有效地提取结构化信息，并建立一个稳健的评估框架来衡量提取的准确性和可靠性。

Method: 该方法包括对扫描或数字发票进行预处理，然后应用 Docling 和 LlamaCloud 服务来识别和提取关键字段。评估框架包括字段级精度、一致性检查失败和精确匹配准确性等指标。

Result: 通过使用 Docling 和 LlamaCloud 服务，能够从发票中识别和提取关键字段。该评估框架提供了一种标准化方法来比较不同的提取方法，并突出显示字段特定性能的优点和缺点。

Conclusion: 该论文提出了一种从发票中提取结构化信息的方法，并为其准确性评估提供了一套全面的指标。通过预处理和利用专门的服务，该方法旨在可靠地提取关键数据。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [145] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: 本文提出了第一个将多模态学习定义为多目标优化问题的帕金森评估系统TRIP，旨在解决多模态数据训练和推理过程中的同步性和完整性限制，并通过实验证明其在同步和异步设置下均达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 目前的帕金森病多模态评估方法存在两个主要局限性：一是在训练过程中需要同步所有模态，二是在推理过程中依赖于所有模态，这限制了其实际应用。此外，多模态信息融合过程中还存在模态坍塌问题，以及个体模态内部的不平衡问题。

Method: 本文提出了一个名为TRIP（Towards Relaxed InPuts）的帕金森评估系统。该系统将多模态学习 S 制定为一个多目标优化（MOO）问题，从而在训练和推理过程中实现更灵活的模态需求，并有效处理多模态信息融合时的模态坍塌问题。此外，为了减轻个体模态内部的不平衡性，TRIP 引入了一种基于间隔的类别再平衡策略来增强类别学习。

Result: TRIP框架在同步和异步设置下的三个公共数据集上进行了广泛实验。结果显示，TRIP在异步设置下比现有最佳基线方法分别高出16.48、6.89和11.55个百分点，在同步设置下分别高出4.86和2.30个百分点。

Conclusion: TRIP系统通过将多模态学习表述为多目标优化问题，并结合基于间隔的类别再平衡策略，成功解决了帕金森病评估中多模态数据同步性、完整性以及模态内部不平衡的挑战。实验结果证明了TRIP在不同设置下的有效性和适应性，实现了最先进的性能。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [146] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: 该论文提出了一个名为Dialectica的框架，旨在通过模拟结构化对话、记忆、自我反思和策略约束的上下文编辑，解决大型语言模型在处理“棘手问题”时缺乏通过经验发展专业知识的内生机制的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决复杂、多维、结果不可验证且缺乏单一客观正确答案的“棘手问题”时，缺乏通过经验发展专业知识的内生机制。

Method: Dialectica框架通过让智能体参与结构化对话，并辅以记忆、自我反思和策略约束的上下文编辑来解决此问题。讨论被视为一种隐式的元强化学习过程。

Result: 在两种模型架构（本地运行的Qwen3:30b和OpenAI的o4-mini）上的评估结果表明，在讨论过程中启用基于反思的上下文编辑可以使智能体在Elo分数、归一化Bradley-Terry-Davidson能力和AlphaRank质量方面优于其基线对应物。定性证据也表明，反思能够识别弱点并可靠地塑造后续陈述。

Conclusion: 对话驱动的上下文演化是实现开放、不可验证领域中目标专业知识放大的实用途径。

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [147] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 该研究开发并评估了六种RAG语料库配置，用于回答有关Long COVID临床问题，结果表明结合临床指南和高质量系统评价的RAG语料库配置表现最佳，并提出了Guide-RAG系统。


<details>
  <summary>Details</summary>
Motivation: 开发针对复杂、新兴疾病（如Long COVID）的有效AI聊天机器人框架。

Method: 开发并评估了六种检索增强生成（RAG）语料库配置，范围从专家策划的来源到大规模文献数据库，并使用LLM-as-a-judge框架，通过忠实性、相关性和全面性指标进行评估，数据来源于“LongCOVID-CQ”数据集。

Result: 结合临床指南和高质量系统评价的RAG语料库配置，其性能始终优于单一指南方法和大规模文献数据库。

Conclusion: 对于新兴疾病，基于策划的二次评价的检索在狭窄共识文件和未过滤的初级文献之间提供了最佳平衡，支持临床决策，同时避免信息过载和过度简化指导。研究提出了Guide-RAG聊天机器人系统及配套评估框架。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>
